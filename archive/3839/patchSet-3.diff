From 2a84858f3be9f5dbb610541aeaa042508f82ffbf Mon Sep 17 00:00:00 2001
From: Hans Rosenfeld <hans.rosenfeld@joyent.com>
Date: Wed, 18 Apr 2018 18:40:07 +0200
Subject: [PATCH] OS-6793 vmm malloc/free are inefficient

---
 usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c | 85 +++++++++++++++++++------
 1 file changed, 66 insertions(+), 19 deletions(-)

diff --git a/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c b/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
index a58e77bb02..c7d47cfba6 100644
--- a/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
+++ b/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
@@ -51,6 +51,7 @@
 #include <sys/id_space.h>
 #include <sys/psm_defs.h>
 #include <sys/smp_impldefs.h>
+#include <sys/modhash.h>
 
 #include <sys/x86_archext.h>
 
@@ -144,12 +145,55 @@ smp_rendezvous(void (* setup_func)(void *), void (* action_func)(void *),
 
 struct kmem_item {
 	void			*addr;
-	void			*paddr;
 	size_t			size;
-	LIST_ENTRY(kmem_item)	next;
 };
 static kmutex_t kmem_items_lock;
-static LIST_HEAD(, kmem_item) kmem_items;
+
+static mod_hash_t *alloc_hash;
+unsigned int alloc_hash_nchains = 16381;
+unsigned int alloc_hash_size = PAGESIZE;
+
+static void
+vmm_alloc_hash_valdtor(mod_hash_val_t val)
+{
+	struct kmem_item *i = (struct kmem_item *)val;
+
+	kmem_free(i->addr, i->size);
+	kmem_free(i, sizeof (struct kmem_item));
+}
+
+static void
+vmm_alloc_init(void)
+{
+	alloc_hash = mod_hash_create_ptrhash("vmm_alloc_hash",
+	    alloc_hash_nchains, vmm_alloc_hash_valdtor, alloc_hash_size);
+
+	VERIFY(alloc_hash != NULL);
+}
+
+static uint_t vmm_alloc_check(mod_hash_key_t key, mod_hash_val_t *val, void *ret)
+{
+	struct kmem_item *i = (struct kmem_item *)val;
+	boolean_t *empty = (boolean_t *)ret;
+
+	cmn_err(CE_WARN, "!vmm_alloc_check: hash not empty: %p, %d", i->addr,
+	    i->size);
+
+	*empty = B_FALSE;
+
+	return (MH_WALK_CONTINUE);
+}
+
+static void
+vmm_alloc_cleanup(void)
+{
+	boolean_t empty = B_TRUE;
+
+	mod_hash_walk(alloc_hash, vmm_alloc_check, (void *)&empty);
+	ASSERT(empty);
+
+	mod_hash_destroy_ptrhash(alloc_hash);
+}
 
 void *
 malloc(unsigned long size, struct malloc_type *mtp, int flags)
@@ -162,18 +206,28 @@ malloc(unsigned long size, struct malloc_type *mtp, int flags)
 		kmem_flag = KM_NOSLEEP;
 
 	if (flags & M_ZERO) {
-		p = kmem_zalloc(size + sizeof (struct kmem_item), kmem_flag);
+		p = kmem_zalloc(size, kmem_flag);
 	} else {
-		p = kmem_alloc(size + sizeof (struct kmem_item), kmem_flag);
+		p = kmem_alloc(size, kmem_flag);
+	}
+
+	if (p == NULL)
+		return (NULL);
+
+	i = kmem_zalloc(sizeof (struct kmem_item), kmem_flag);
+
+	if (i == NULL) {
+		kmem_free(p, size);
+		return (NULL);
 	}
 
 	mutex_enter(&kmem_items_lock);
-	i = p + size;
 	i->addr = p;
-	i->paddr = (void *)PHYS_TO_DMAP(vtophys(p));
 	i->size = size;
 
-	LIST_INSERT_HEAD(&kmem_items, i, next);
+	VERIFY(mod_hash_insert(alloc_hash,
+	    (mod_hash_key_t)PHYS_TO_DMAP(vtophys(p)), (mod_hash_val_t)i) == 0);
+
 	mutex_exit(&kmem_items_lock);
 
 	return (p);
@@ -182,19 +236,10 @@ malloc(unsigned long size, struct malloc_type *mtp, int flags)
 void
 free(void *addr, struct malloc_type *mtp)
 {
-	struct kmem_item	*i;
-
 	mutex_enter(&kmem_items_lock);
-	LIST_FOREACH(i, &kmem_items, next) {
-		if (i->addr == addr ||
-		    i->paddr == addr)
-			break;
-	}
-	VERIFY(i != NULL);
-	LIST_REMOVE(i, next);
+	VERIFY(mod_hash_destroy(alloc_hash,
+	    (mod_hash_key_t)PHYS_TO_DMAP(vtophys(addr))) == 0);
 	mutex_exit(&kmem_items_lock);
-
-	kmem_free(i->addr, i->size + sizeof (struct kmem_item));
 }
 
 extern void *contig_alloc(size_t, ddi_dma_attr_t *, uintptr_t, int);
@@ -609,6 +654,7 @@ fpusave(void *arg)
 void
 vmm_sol_glue_init(void)
 {
+	vmm_alloc_init();
 	vmm_cpuid_init();
 	fpu_save_area_init();
 	unr_idx = 0;
@@ -618,6 +664,7 @@ void
 vmm_sol_glue_cleanup(void)
 {
 	fpu_save_area_cleanup();
+	vmm_alloc_cleanup();
 }
 
 
-- 
2.21.0

