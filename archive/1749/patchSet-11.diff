From 3c01928e6bdf5cd86c9b8a921d988fb6d2fe0311 Mon Sep 17 00:00:00 2001
From: David Pacheco <dap@joyent.com>
Date: Fri, 19 May 2017 19:05:46 -0700
Subject: [PATCH] MANTA-3195 manta amon configuration could use work MANTA-3191
 nameservice zones get duplicate "logs not uploaded" probes MANTA-3194
 postgres zones get duplicate "registrar-logscan" probes MANTA-3188 common
 probes not deployed to services with no other probes MANTA-3210 manta-adm
 should honor LOG_LEVEL MANTA-3211 clean up manta-adm help and options

---
 Makefile                                      |   15 +-
 alarm_metadata/probe_templates/authcache.yaml |  181 +++
 alarm_metadata/probe_templates/common.yaml    |  182 +++
 .../probe_templates/electric-moray.yaml       |   43 +
 .../probe_templates/jobsupervisor.yaml        |   59 +
 .../probe_templates/loadbalancer.yaml         |  152 ++
 alarm_metadata/probe_templates/moray.yaml     |   44 +
 .../probe_templates/nameservice.yaml          |  129 ++
 alarm_metadata/probe_templates/ops.yaml       |  503 ++++++
 alarm_metadata/probe_templates/postgres.yaml  |  228 +++
 alarm_metadata/probe_templates/storage.yaml   |  137 ++
 .../probe_templates/storage_gzs.yaml          |  131 ++
 alarm_metadata/probe_templates/webapi.yaml    |   42 +
 boot/setup.sh                                 |    1 -
 cmd/manta-adm.js                              | 1014 +++++++++++-
 docs/man/man1/manta-adm.md                    |  209 ++-
 lib/adm.js                                    | 1447 ++++++++++++++++-
 lib/alarms/alarms.js                          |  397 +++++
 lib/alarms/amon_objects.js                    |  411 +++++
 lib/alarms/config.js                          |  544 +++++++
 lib/alarms/index.js                           |  245 +++
 lib/alarms/metadata.js                        |  951 +++++++++++
 lib/alarms/update.js                          | 1338 +++++++++++++++
 lib/common.js                                 |   37 +-
 lib/instance_info.js                          |   64 +
 lib/services.js                               |   45 +-
 man/man1/manta-adm.1                          |  223 ++-
 package.json                                  |    9 +-
 test/alarms/mock_amon.js                      |  195 +++
 test/alarms/tst.alarms.js                     |  539 ++++++
 test/alarms/tst.amon_objects.js               |  678 ++++++++
 test/alarms/tst.config.js                     |  540 ++++++
 test/alarms/tst.metadata_basic.js             |  706 ++++++++
 test/alarms/tst.metadata_files.js             |  270 +++
 test/alarms/tst.update.js                     | 1123 +++++++++++++
 test/tst.services.js                          |   12 +-
 tools/probecfgchk.js                          |   63 +
 37 files changed, 12696 insertions(+), 211 deletions(-)
 create mode 100644 alarm_metadata/probe_templates/authcache.yaml
 create mode 100644 alarm_metadata/probe_templates/common.yaml
 create mode 100644 alarm_metadata/probe_templates/electric-moray.yaml
 create mode 100644 alarm_metadata/probe_templates/jobsupervisor.yaml
 create mode 100644 alarm_metadata/probe_templates/loadbalancer.yaml
 create mode 100644 alarm_metadata/probe_templates/moray.yaml
 create mode 100644 alarm_metadata/probe_templates/nameservice.yaml
 create mode 100644 alarm_metadata/probe_templates/ops.yaml
 create mode 100644 alarm_metadata/probe_templates/postgres.yaml
 create mode 100644 alarm_metadata/probe_templates/storage.yaml
 create mode 100644 alarm_metadata/probe_templates/storage_gzs.yaml
 create mode 100644 alarm_metadata/probe_templates/webapi.yaml
 create mode 100644 lib/alarms/alarms.js
 create mode 100644 lib/alarms/amon_objects.js
 create mode 100644 lib/alarms/config.js
 create mode 100644 lib/alarms/index.js
 create mode 100644 lib/alarms/metadata.js
 create mode 100644 lib/alarms/update.js
 create mode 100644 lib/instance_info.js
 create mode 100644 test/alarms/mock_amon.js
 create mode 100644 test/alarms/tst.alarms.js
 create mode 100644 test/alarms/tst.amon_objects.js
 create mode 100644 test/alarms/tst.config.js
 create mode 100644 test/alarms/tst.metadata_basic.js
 create mode 100644 test/alarms/tst.metadata_files.js
 create mode 100644 test/alarms/tst.update.js
 create mode 100755 tools/probecfgchk.js

diff --git a/Makefile b/Makefile
index 316845a..9d9f6e3 100644
--- a/Makefile
+++ b/Makefile
@@ -5,7 +5,7 @@
 #
 
 #
-# Copyright (c) 2016, Joyent, Inc.
+# Copyright (c) 2017, Joyent, Inc.
 #
 
 #
@@ -24,6 +24,7 @@
 # Programs
 #
 CATEST		 = deps/catest/catest
+PROBECHK	 = node ./tools/probecfgchk.js
 
 #
 # Options and overrides
@@ -50,6 +51,7 @@ JSON_FILES	 = package.json \
 		   $(shell find config \
 				manifests \
 				sapi_manifests -name '*.json*')
+PROBE_FILES	 = $(wildcard alarm_metadata/probe_templates/*.yaml)
 
 include ./tools/mk/Makefile.defs
 include ./tools/mk/Makefile.node_deps.defs
@@ -90,6 +92,17 @@ manpages: $(MAN_OUTPUTS)
 
 check:: $(NODE_EXEC)
 
+#
+# We'd like to run "check-probe-files" under "check", but this requires
+# MANTA-3251 in order to work in the context of CI checks.  However, we can at
+# least put this under "prepush", which (for better or worse) already can't
+# generally be run in anonymous CI environments.
+#
+check-probe-files:
+	$(PROBECHK) $(PROBE_FILES)
+
+prepush: check-probe-files
+
 .PHONY: test
 test: | $(CATEST)
 	PATH="$(TOP)/build/node/bin:$$PATH" $(CATEST) -a
diff --git a/alarm_metadata/probe_templates/authcache.yaml b/alarm_metadata/probe_templates/authcache.yaml
new file mode 100644
index 0000000..bc8bc9a
--- /dev/null
+++ b/alarm_metadata/probe_templates/authcache.yaml
@@ -0,0 +1,181 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "authcache" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+#
+# Log scanners
+#
+
+-
+    # log scan: "mahi-replicator" SMF service
+    event: upset.manta.authcache.mahi_replicator.log_error
+    legacyName: mahi-replicator-logscan-error
+    scope:
+        service: authcache
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: mahi-replicator
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mahi-replicator" logged an error'
+        description: The "mahi-replicator" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            replication may be falling behind.  In that case, recent changes to
+            user accounts, sub-users, roles, and ssh keys may not be reflected
+            in Manta.  Newly-created accounts, users, roles, and keys may not be
+            available, and those that have recently been deleted may still be
+            working.  Service is unaffected for accounts, users, roles, and keys
+            that have not changed recently.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    # log scan: "mahi-server" SMF service
+    event: upset.manta.authcache.mahi_server.log_error
+    legacyName: mahi-server-logscan-error
+    scope:
+        service: authcache
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: mahi-server
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mahi-server" logged an error'
+        description: The "mahi-server" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Some end user requests may have failed due to authentiation
+            failures.  The problem may be ongoing.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+#
+# Periodic checks
+#
+
+-
+    # Checks whether Redis is at least responding to its own pings.
+    event: upset.manta.authcache.redis.ping_fail
+    legacyName: redis-ok
+    scope:
+        service: authcache
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/opt/local/bin/redis-cli PING"
+                stdoutMatch:
+                    pattern: PONG
+                    invert: true
+                threshold: 1
+                period: 60
+    ka:
+        title: Authcache Redis ping failed
+        description: >-
+            A periodic ping of an authentication cache's redis instance has
+            failed.
+        severity: critical
+        response: No automated response will be taken.
+        impact: >-
+            Some requests may be failing due to authentication failures.  The
+            impact is likely to be proportional to the number of "authcache"
+            instances that have experienced this problem.  Note that
+            authentication information is cached for a few minutes, so requests
+            may not start failing immediately.
+        action: >-
+            Root-cause the failure and resolve the underlying issue.  You may
+            need to restart the Redis service.
+
+-
+    # Checks for v1 are under the "v1" namespace.
+    event: upset.manta.authcache.v1.behind
+    legacyName: mahi v1 falling behind by more than 5000 changenumbers
+    scope:
+        service: authcache
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "if [ $(/opt/smartdc/mahi/bin/cn_delta) -gt 5000 ]; then exit 1; else exit 0; fi"
+                interval: 30
+                threshold: 10
+                period: 1800
+                timeout: 29
+    ka:
+        title: Authcache v1 replication has fallen behind
+        description: >-
+            Replication for the v1 authentication cache has fallen behind.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Recent changes to user accounts, sub-users, roles, and ssh keys may
+            not be reflected in Manta.  Newly-created accounts, users, roles,
+            and keys may not be available, and those that have recently been
+            deleted may still be working.  Service is unaffected for accounts,
+            users, roles, and keys that have not changed recently.
+        action: >-
+            Check the log for the "mahi" SMF service inside the affected
+            authcache zone.  If necessary, restart the service.
+
+-
+    #
+    # Checks for the current authcache version ("v2") are not under
+    # version-specific namespace.
+    #
+    event: upset.manta.authcache.replicator.behind
+    legacyName: mahi v2 falling behind by more than 5000 changenumbers
+    scope:
+        service: authcache
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "if [ $(/opt/smartdc/mahi/bin/cn_delta2) -gt 5000 ]; then exit 1; else exit 0; fi"
+                interval: 30
+                threshold: 10
+                period: 1800
+                timeout: 29
+    ka:
+        title: Authcache replication has fallen behind
+        description: Replication for the authentication cache has fallen behind
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Recent changes to user accounts, sub-users, roles, and ssh keys may
+            not be reflected in Manta.  Newly-created accounts, users, roles,
+            and keys may not be available, and those that have recently been
+            deleted may still be working.  Service is unaffected for accounts,
+            users, roles, and keys that have not changed recently.
+        action: >-
+            Check the log for the "mahi-replicator" SMF service inside the
+            affected authcache zone.  If necessary, restart the service.
+
diff --git a/alarm_metadata/probe_templates/common.yaml b/alarm_metadata/probe_templates/common.yaml
new file mode 100644
index 0000000..a1ef0b8
--- /dev/null
+++ b/alarm_metadata/probe_templates/common.yaml
@@ -0,0 +1,182 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes common to all services deployed to non-global zones
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    #
+    # The CPU utilization probe notifies operators when any server is at high
+    # overall CPU utilization for an extended period of time (currently 23
+    # per-minute samples within 30 minutes).  This might be indicative of
+    # degraded service, though it doesn't react quickly enough to usefully
+    # identify that.  It's conceivably useful for capacity planning, but that
+    # would likely be better accomplished using a metric collection system that
+    # keeps historical data.
+    #
+    # Also of note: this probe is deliberately per-zone rather than per-CN.
+    # That helps identify which components are affected by heavy CPU
+    # utilization.
+    #
+    event: upset.manta.zone.cpu_utilized
+    legacyName: cpu utilization
+    scope:
+        service: all
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test ! $(mpstat -a 1 2 | tail -n 1 | nawk '{total=$13+$14} END {print total}') -gt 80"
+                interval: 60
+                threshold: 23
+                period: 1800
+                timeout: 30
+    ka:
+        title: Excessive CPU utilization
+        description: Aggregate CPU usage has been high for several minutes
+        severity: minor
+        response: No automated response will be taken.
+        impact: Service provided by affected components may be degraded.
+        action: >-
+            Identify the source of excessive CPU utilization and resolve the
+            issue.  If components are behaving normally, consider adding
+            additional capacity using new servers.
+
+-
+    event: upset.manta.zone.filesystem_almost_full
+    legacyName: "free space on / below 20%"
+    scope:
+        service: all
+    checks:
+        -
+            type: disk-usage
+            config:
+                path: "/"
+                threshold: "20%"
+                interval: 3600
+    ka:
+        title: Filesystem almost full
+        description: A zone filesystem is running low on free space
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact, but if the filesystem fills up,
+            service may become severely degraded.  End user requests may
+            experience high error rates or increased latency.
+        action: >-
+            Identify the cause of excessive disk usage and resolve the
+            underlying issue.
+
+-
+    event: upset.manta.registrar.log_error
+    legacyName: registrar-logscan
+    scope:
+        service: all
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: registrar
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"registrar" logged an error'
+        description: The "registrar" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise, a
+            component may no longer be registered for internal service
+            discovery.  Capacity may be affected, resulting in increased latency
+            or error rates for end user requests.  If enough instances
+            experience this issue, a major service disruption could result.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.zone.logs_lingering
+    legacyName: logs not uploaded
+    scope:
+        service: all
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test ! $(find /var/log/manta/upload -type f | wc -l) -gt 0"
+                interval: 300
+                threshold: 5
+                period: 1800
+    ka:
+        title: Log files not uploaded
+        description: Some log files have not been uploaded
+        severity: minor
+        response: >-
+            The system automatically retries hourly to upload any internal log
+            files that have not yet been uploaded.
+        impact: >-
+            There is no impact to end-user service.  However, failure to upload
+            files is often indicative of problems affecting end user requests.
+
+            If the affected logs are used for metering, then metering reports
+            and access logs for end users may be unavailable or incomplete until
+            the affected logs are uploaded and the relevant metering jobs re-run
+            by an operator.
+        action: >-
+            Identify the reason for the failure and resolve the underlying
+            issue.  If logs used for metering were affected, you may need to
+            re-run the relevant metering jobs once all logs are available.
+
+            In most components, the log "/var/log/mbackup.log" has a record of
+            recent upload attempts and results.  Another common cause of log
+            upload failure is when a component or service was offline during the
+            scheduled log upload time.
+
+-
+    event: upset.manta.$service.smf_maintenance
+    legacyName: "svcs: SMF maintenance"
+    #
+    # We use the scope "each" here (rather than "all") to make sure that we get
+    # different probe groups (and therefore different alarms) when SMF services
+    # from different SAPI services go into maintenance.
+    #
+    scope:
+        service: each
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/usr/bin/svcs -x"
+                stdoutMatch:
+                    pattern: maintenance
+                    matchWord: true
+                threshold: 1
+                period: 60
+                timeout: 30
+    ka:
+        title: SMF service in maintenance
+        description: One or more SMF services are in maintenance
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            The impact depends on which services are in maintenance.  In some
+            cases, overall request handling capacity may be reduced.  If enough
+            instances are in maintenance, end users could experience errors.
+        action: >-
+            In the affected zones, use "svcs -xv" to identify the services in
+            maintenance and to see basic instructions for tracking down the
+            problem.
+
diff --git a/alarm_metadata/probe_templates/electric-moray.yaml b/alarm_metadata/probe_templates/electric-moray.yaml
new file mode 100644
index 0000000..6c22c2e
--- /dev/null
+++ b/alarm_metadata/probe_templates/electric-moray.yaml
@@ -0,0 +1,43 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "electric-moray" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.electric_moray.log_error
+    legacyName: electric-moray-logscan
+    scope:
+        service: electric-moray
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/electric-moray.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"electric-moray" logged an error'
+        description: The "electric-moray" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            A small number of end-user requests may have failed.  Some job
+            tasks may experience increased latency to dispatch.  If the problem
+            persists, many requests and tasks may be affected.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
diff --git a/alarm_metadata/probe_templates/jobsupervisor.yaml b/alarm_metadata/probe_templates/jobsupervisor.yaml
new file mode 100644
index 0000000..0db4b00
--- /dev/null
+++ b/alarm_metadata/probe_templates/jobsupervisor.yaml
@@ -0,0 +1,59 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "jobsupervisor" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.jobsupervisor.log_error
+    legacyName: jobsupervisor-logscan-error, jobsupervisor-logscan-fatal, jobsupervisor-logscan-core
+    scope:
+        service: jobsupervisor
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: jobsupervisor
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: jobsupervisor
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+        -
+            type: log-scan
+            config:
+                smfServiceName: jobsupervisor
+                match:
+                    pattern: Stopping because process dumped core.
+                threshold: 1
+                period: 60
+    ka:
+        title: '"jobsupervisor" logged an error'
+        description: The "jobsupervisor" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            some jobs may have experienced errors or additional latency.  It is
+            possible that some jobs are stuck.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
diff --git a/alarm_metadata/probe_templates/loadbalancer.yaml b/alarm_metadata/probe_templates/loadbalancer.yaml
new file mode 100644
index 0000000..b1548b1
--- /dev/null
+++ b/alarm_metadata/probe_templates/loadbalancer.yaml
@@ -0,0 +1,152 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "loadbalancer" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.loadbalancer.haproxy.memory
+    legacyName: "haproxy memory size (1G)"
+    scope:
+        service: loadbalancer
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "ps -o rss= -p \"$(pgrep -c \"$(svcs -H -o ctid haproxy)\")\" | awk '$1 > 1048576{ printf(\"haproxy rss too large\\n\"); }'"
+                stdoutMatch:
+                    pattern: haproxy rss too large
+                interval: 120
+                threshold: 2
+                period: 360
+    ka:
+        title: Loadbalancer "haproxy" using too much memory
+        description: >-
+            Loadbalancer "haproxy" processes are using more memory than
+            expected.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact.  However, if processes are leaking
+            memory, then performance may degrade and errors may be induced in
+            end-user requests.
+        action:
+            You may restart the "haproxy" service to alleviate the issue
+            temporarily, though this will impact some end user requests, and it
+            will not resolve the underlying cause of any resource leak.
+
+-
+    event: upset.manta.loadbalancer.stud.memory
+    legacyName: "stud memory size (1G)"
+    scope:
+        service: loadbalancer
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test ! $(ps -orss -p \"`pgrep stud`\" | grep -v RSS | nawk '{t+=$1}END{print t}') -gt 1048576"
+                interval: 120
+                threshold: 2
+                period: 360
+    ka:
+        title: Loadbalancer "stud" using too much memory
+        description: >-
+            Loadbalancer "stud" processes are using more memory than expected.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact.  However, if processes are leaking
+            memory, then performance may degrade and errors may be induced in
+            end-user requests.
+        action:
+            You may restart the "stud" service to alleviate the issue
+            temporarily, though this will impact some end user requests, and it
+            will not resolve the underlying cause of any resource leak.
+
+-
+    event: upset.manta.loadbalancer.muppet.memory
+    legacyName: "muppet memory size (512M)"
+    scope:
+        service: loadbalancer
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test ! $(ps -orss -p $(svcs -Hoctid -p muppet | tail -n 1 | awk '{print $2}') | tail -n 1) -gt 524288"
+                interval: 120
+                threshold: 2
+                period: 360
+    ka:
+        title: Loadbalancer "muppet" using too much memory
+        description: >-
+            Loadbalancer "muppet" processes are using more memory than expected.
+        severity: minor
+        response: No automated response will be taken.
+        impact: There is no immediate impact.
+        action: Check the "muppet" process for memory leaks.
+
+-
+    event: upset.manta.loadbalancer.muppet.log_error
+    legacyName: muppet-logscan
+    scope:
+        service: loadbalancer
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: muppet
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"muppet" logged an error'
+        description: The "muppet" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            loadbalancers may not be correctly identifying when "webapi"
+            instances have come and gone.  They may be continuing to use old
+            webapi instances or ignoring new instances.
+        action:
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.loadbalancer.no_backends
+    legacyName: no backend servers
+    scope:
+        service: loadbalancer
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test -n $(/opt/smartdc/muppet/build/node/bin/node /opt/smartdc/muppet/node_modules/.bin/haproxystat showStat /tmp/haproxy  | /opt/smartdc/muppet/build/node/bin/node -e 's=\"\"; process.stdin.resume(); process.stdin.on(\"data\",function(c){s+=c}); process.stdin.on(\"end\",function(){o=eval(\"(\"+s+\")\");console.log(JSON.stringify(o)); });' | /usr/bin/json  -c 'this.type == \"backend\" && !/stats/.test(this.pxname) && act == 0' -a pxname)"
+                interval: 30
+                threshold: 2
+                period: 120
+    ka:
+        title: Loadbalancer has no backends
+        description: A loadbalancer has no working backends
+        severity: critical
+        response: No automated response will be taken.
+        impact:
+            End user requests may be experiencing very high error rates.
+        action:
+            Determine why the loadbalancer has no backends and resolve the
+            underlying issue.  First, ensure that there are working "webapi"
+            instances.  If so, identify whether they're registered in ZooKeeper.
+            If so, see if the Muppet instance in this loadbalancer zone has
+            found them.
diff --git a/alarm_metadata/probe_templates/moray.yaml b/alarm_metadata/probe_templates/moray.yaml
new file mode 100644
index 0000000..5202ae5
--- /dev/null
+++ b/alarm_metadata/probe_templates/moray.yaml
@@ -0,0 +1,44 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "moray" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.moray.log_error
+    legacyName: moray-logscan
+    scope:
+        service: moray
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/moray.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"moray" logged an error'
+        description: The "moray" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            some end user requests may be experiencing errors or some jobs may
+            be experiencing errors or additional latency.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
diff --git a/alarm_metadata/probe_templates/nameservice.yaml b/alarm_metadata/probe_templates/nameservice.yaml
new file mode 100644
index 0000000..c56d94c
--- /dev/null
+++ b/alarm_metadata/probe_templates/nameservice.yaml
@@ -0,0 +1,129 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "nameservice" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.nameservice.zookeeper.log_error
+    legacyName: "ZK: logscan 'ERROR'"
+    scope:
+        service: nameservice
+    checks:
+        -
+            type: log-scan
+            config:
+                path: "/var/log/zookeeper/zookeeper.out"
+                match:
+                    pattern: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"zookeeper" logged an error'
+        description: The "zookeeper" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            Manatee shard fault tolerance may be affected and service discovery
+            may be offline.  Services should continue to function, but with
+            significantly reduced ability to respond to other failures.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.nameservice.zookeeper.log_connrefused
+    legacyName: "ZK: logscan 'Connection refused'"
+    scope:
+        service: nameservice
+    checks:
+        -
+            type: log-scan
+            config:
+                path: "/var/log/zookeeper/zookeeper.out"
+                match:
+                    pattern: "java.net.ConnectException: Connection refused"
+                threshold: 1
+                period: 60
+    ka:
+        title: '"zookeeper" logged a connection failure'
+        description: The "zookeeper" service logged a connection failure.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            Manatee shard fault tolerance may be affected and service discovery
+            may be offline.  Services should continue to function, but with
+            significantly reduced ability to respond to other failures.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.nameservice.binder.log_error
+    legacyName: "binder: logscan"
+    scope:
+        service: nameservice
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: binder
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"binder" logged an error'
+        description: The "binder" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            service discovery may be offline.  Services should continue to
+            function, but with significantly reduced ability to respond to other
+            failures.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.nameservice.zookeeper.notok
+    legacyName: "ZK: ruok"
+    scope:
+        service: nameservice
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "echo 'ruok' | nc localhost 2181"
+                stdoutMatch:
+                    pattern: imok
+                    invert: true
+                threshold: 1
+                period: 60
+    ka:
+        title: ZooKeeper not okay
+        description: ZooKeeper reports that it is not okay
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            Manatee shard fault tolerance may be affected and service discovery
+            may be offline.  Services should continue to function, but with
+            significantly reduced ability to respond to other failures.
+        action: >-
+            Determine the scope of the problem and resolve the underlying issue.
+
diff --git a/alarm_metadata/probe_templates/ops.yaml b/alarm_metadata/probe_templates/ops.yaml
new file mode 100644
index 0000000..355fcbd
--- /dev/null
+++ b/alarm_metadata/probe_templates/ops.yaml
@@ -0,0 +1,503 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "ops" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.ops.log_error
+    legacyName: mackerel-logscan
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mackerel.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mackerel" logged an error'
+        description: The "mackerel" subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            One or more metering reports may be missing or incomplete.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.backup_unpack.log_error
+    legacyName: mola-pg-transform-logscan-error,mola-pg-transform-logscan-fatal
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-pg-transform.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-pg-transform.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mola-pg-transform" logged an error'
+        description: The "mola-pg-transform" subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The daily metadata backups may not have been unpacked.  As a result,
+            regularly scheduled garbage collection, audit, and metering jobs may
+            not be running or their results may be incomplete.  Disk usage may
+            accumulate on metadata and storage nodes until the problem is
+            resolved.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.log_error
+    legacyName: mola-logscan-error,mola-logscan-fatal
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mola" logged an error'
+        description: The garbage collection subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata and storage nodes until the problem is
+            repaired.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.create_links_log_error
+    legacyName: mola-gc-create-links-logscan-error,mola-gc-create-links-logscan-fatal
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-gc-create-links.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-gc-create-links.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mola-gc-create-links" logged an error'
+        description: The "mola-gc-create-links" subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata and storage  nodes until the problem is
+            repaired.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.moray_gc_log_error
+    legacyName: mola-moray-gc-logscan-error,mola-moray-gc-logscan-fatal
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-moray-gc.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-moray-gc.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mola-moray-gc" logged an error'
+        description: The "mola-moray-gc" subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata nodes until the problem is repaired.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.audit.log_error
+    legacyName: mola-audit-logscan-error
+    scope:
+        service: ops
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-audit.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/mola-audit.log"
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mola-audit" logged an error'
+        description: The audit subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The regularly scheduled audit job may not have been able to run.  If
+            the job did run and complete successfully, then it may have
+            identified objects with missing copies, which would indicate a data
+            integrity issue.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.objects_lingering
+    legacyName: mola-create-link-files-piling-up
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && test $(mfind /poseidon/stor/manta_gc/all/do | wc -l) -lt 150"
+                interval: 300
+                period: 1800
+                threshold: 6
+                timeout: 20
+    ka:
+        title: Garbage collection instructions piling up
+        description: Garbage collection instruction objects are piling up
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata and storage nodes until the problem is
+            repaired.
+        action: >-
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.moray_objects_lingering
+    legacyName: mola-moray-files-piling-up
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "set -o errexit && set -o pipefail && export HOME=/root && . /root/.bashrc && mfind /poseidon/stor/manta_gc/moray | sed s,^/poseidon/stor/manta_gc/moray/,, | awk -F/ 'NF == 1 { dirs[$1] = 1; } NF == 2 { counts[$1]++; } END { for (dir in dirs) { count = counts[dir]; if (count > 150) { printf(\"%s\\t%d\\n%s\\n\", dir, count, \"fail\"); } } }'"
+                interval: 300
+                period: 1800
+                threshold: 6
+                timeout: 20
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Garbage collection Moray instructions piling up
+        description: Garbage collection Moray instruction objects are piling up
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata nodes until the problem is repaired.
+        action: >-
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.mako_objects_lingering
+    legacyName: mola-mako-files-piling-up
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "set -o errexit && set -o pipefail && export HOME=/root && . /root/.bashrc && mfind /poseidon/stor/manta_gc/mako | sed s,^/poseidon/stor/manta_gc/mako/,, | awk -F/ 'NF == 1 { dirs[$1] = 1; } NF == 2 { counts[$1]++; } END { for (dir in dirs) { count = counts[dir]; if (count > 150) { printf(\"%s\\t%d\\n%s\\n\", dir, count, \"fail\"); } } }'"
+                interval: 300
+                period: 1800
+                threshold: 6
+                timeout: 20
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Garbage collection Mako instructions piling up
+        description: Garbage collection Mako instruction objects are piling up
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on storage nodes until the problem is repaired.
+        action: >-
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.gc.job_lingering
+    legacyName: mola-job-running-too-long
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && test $(expr $(date +%s) - $(mjob get $(mjob list -n manta_gc -s running | head -1 | tr -d '/') | json timeCreated | xargs -i date --utc --date \"{}\" +%s)) -lt 10800; if [[ $? -eq 1 ]]; then echo \"fail\"; else echo \"success\"; fi"
+                interval: 300
+                threshold: 1
+                timeout: 20
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Garbage collection job running too long
+        description: >-
+            The regularly-scheduled garbage collection job has been running for
+            longer than expected.
+        severity: major
+        response: No automated response will be taken.
+        impact:
+            Garbage collection may not be completing.  Disk space used may
+            accumulate on storage nodes until the problem is repaired.
+        action: >-
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.dumps_missing
+    legacyName: manatee-backups-failed
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && export DATE=$(date +'%Y/%m/%d/00' --date='7 hours ago'); echo $DATE; for s in $(mls /poseidon/stor/manatee_backups | tr -d '/'); do /opt/local/bin/echo -n \"$s \"; until [[ \"$MLS\" != '' ]]; do export MLS=$(mls /poseidon/stor/manatee_backups/$s/$DATE 2>&1); done; echo \"$MLS\" | grep '\\(manta_delete_log-\\)\\|\\(marlin_tasks_v2-\\)' >/dev/null; if [[ $? == 0 ]]; then echo 'pass'; else echo 'fail'; fi; export MLS=''; done"
+                interval: 300
+                threshold: 1
+                period: 3600
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Unpacked metadata dumps are missing
+        description: Regularly-scheduled metadata dumps have not been unpacked
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            The regularly scheduled metadata backups may not have been unpacked.
+            As a result, regularly scheduled garbage collection, audit, and
+            metering jobs may not be running or their results may be incomplete.
+            Disk usage may accumulate on metadata and storage nodes until the
+            problem is resolved.
+        action: >-
+            The "manta-hk" tool can be used in the "ops" zone to determine
+            whether the regularly-scheduled dumps have been uploaded and
+            unpacked.
+
+-
+    event: upset.manta.ops.metering.summary_missing
+    legacyName: mackerel-summary-missing
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && export DATE=$(date +'%Y/%m/%d' --date='30 hours ago'); echo $DATE; mls /poseidon/stor/usage/summary/$DATE 2>&1 | grep .json; if [[ $? == 0 ]]; then echo 'pass'; else echo 'fail'; fi;"
+                interval: 300
+                threshold: 1
+                period: 3600
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Recent metering summary report missing
+        description: A metering summary report could not be found.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The metering subsystem may not be functioning.  Per-user access logs
+            and summary reports may be missing or incomplete.  In some
+            deployments, this can affect customer billing.
+        action:
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.metering.storage_missing
+    legacyName: mackerel-storage-missing
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && export DATE=$(date +'%Y/%m/%d/00' --date='12 hours ago'); echo $DATE; mls /poseidon/stor/usage/storage/$DATE 2>&1 | grep h00.json; if [[ $? == 0 ]]; then echo 'pass'; else echo 'fail'; fi;"
+                interval: 300
+                threshold: 1
+                period: 3600
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Recent metering storage report missing
+        description: A metering storage report could not be found.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The metering subsystem may not be functioning.  In some deployments,
+            this can affect customer billing.
+        action:
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.metering.request_missing
+    legacyName: mackerel-request-missing
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && export DATE=$(date +'%Y/%m/%d/%H' --date='2 hours ago'); echo $DATE; mls /poseidon/stor/usage/request/$DATE 2>&1 | grep .json; if [[ $? == 0 ]]; then echo 'pass'; else echo 'fail'; fi;"
+                interval: 300
+                threshold: 1
+                period: 3600
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Recent metering request report missing
+        description: A metering request report could not be found.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The metering subsystem may not be functioning.  Per-user access logs
+            and summary reports may be missing or incomplete.  In some
+            deployments, this can affect customer billing.
+        action:
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.metering.compute_missing
+    legacyName: mackerel-compute-missing
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "export HOME=/root && . /root/.bashrc && export DATE=$(date +'%Y/%m/%d/%H' --date='2 hours ago'); echo $DATE; mls /poseidon/stor/usage/compute/$DATE 2>&1 | grep .json; if [[ $? == 0 ]]; then echo 'pass'; else echo 'fail'; fi;"
+                interval: 300
+                threshold: 1
+                period: 3600
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Recent metering compute report missing
+        description: A metering compute report could not be found.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The metering subsystem may not be functioning.  Per-user access logs
+            and summary reports may be missing or incomplete.  In some
+            deployments, this can affect customer billing.
+        action:
+            Determine the scope of the problem and resolve the underlying issue.
+
+-
+    event: upset.manta.ops.jobpuller.falling_behind
+    legacyName: wrasse-behind
+    scope:
+        service: ops
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/opt/smartdc/mola/amon/checks/check-wrasse-behind"
+                timeout: 180
+                interval: 3600
+                threshold: 1
+    ka:
+        title: Job archiver is falling behind
+        description: There are too many jobs that have not been archived.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            The jobs database may be getting large, full of job data that is no
+            longer needed.  Over time, this can significantly decrease
+            performance of compute jobs.
+        action: >-
+            Check the logs for the job archiver to help debug the underlying
+            issue and then repair it.  See also known issue "MANTA-2277".
diff --git a/alarm_metadata/probe_templates/postgres.yaml b/alarm_metadata/probe_templates/postgres.yaml
new file mode 100644
index 0000000..458a8c1
--- /dev/null
+++ b/alarm_metadata/probe_templates/postgres.yaml
@@ -0,0 +1,228 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "postgres" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.postgres.db_filesystem_almost_full
+    legacyName: database dataset space running low
+    scope:
+        service: postgres
+    checks:
+        -
+            type: disk-usage
+            config:
+                path: "/manatee/pg"
+                threshold: "20%"
+                interval: 3600
+    ka:
+        title: Database filesystem almost full
+        description: A database filesystem is running low on free space
+        severity: critical
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact, but if the filesystem fills up,
+            service may become severely degraded.  End user requests may
+            experience high error rates or increased latency.
+        action: >-
+            Identify the cause of excessive disk usage and resolve the
+            underlying issue.
+
+-
+    event: upset.manta.postgres.sitter.log_error
+    legacyName: manatee-logscan
+    scope:
+        service: postgres
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: manatee-sitter
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"manatee-sitter" logged an error'
+        description: The "manatee-sitter" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: Unknown.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.postgres.snapshotter.log_error
+    legacyName: manatee-snapshotter-logscan
+    scope:
+        service: postgres
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: manatee-snapshotter
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"manatee-snapshotter" logged an error'
+        description: The "manatee-snapshotter" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact, but if snapshots are not being created
+            regularly, then it may impossible to rebuild a Manatee peer and
+            restore fault tolerance after a takeover event.  If snapshots are
+            not being destroyed, disk space may become exhausted, resulting in
+            significant service degradation.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.postgres.backupserver.log_error
+    legacyName: manatee-backupserver-logscan
+    scope:
+        service: postgres
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: manatee-backupserver
+                fields:
+                    level: FATAL
+                threshold: 1
+                period: 60
+    ka:
+        title: '"manatee-backupserver" logged an error'
+        description: The "manatee-backupserver" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            There is no immediate impact, but this service is required for
+            Manatee rebuilds, which are necessary to restore fault tolerance
+            after a takeover event.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.postgres.pg_dump.log_error
+    legacyName: "pg_dump-logscan"
+    scope:
+        service: postgres
+    checks:
+        -
+            type: log-scan
+            config:
+                path: "/var/log/manatee/pg_dump.log"
+                match:
+                    pattern: fatal
+                threshold: 1
+                period: 60
+    ka:
+        title: '"pg_dump" logged an error'
+        description: The "pg_dump" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            The daily backup for this metadata shard may be missing.  As a
+            result, the garbage collection, auditing, and metering pipelines may
+            not have completed.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    #
+    # For the shard-wide probes (like the following one that faults when the
+    # shard is unhealthy), it would be nice if this were one probe group per
+    # shard, or at least one per zone, but that's not yet supported.
+    #
+    event: upset.manta.postgres.shard_unhealthy
+    legacyName: manatee-stat
+    scope:
+        service: postgres
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/opt/smartdc/manatee/bin/manatee-stat-alarm.sh"
+                interval: 60
+                threshold: 5
+                period: 360
+                timeout: 60
+                stdoutMatch:
+                    pattern: fail
+                    type: substring
+    ka:
+        title: Metadata shard is unhealthy
+        description: A metadata shard is unhealthy
+        severity: critical
+        response: No automated response will be taken.
+        impact: >-
+            If the shard is completely offline, then end-user requests or job
+            tasks operating on objects whose metadata is on the affected shard
+            will fail.  If the shard is read-only, then new writes to
+            directories on this shard will fail, but read operations and job
+            tasks using objects on this shard will be unaffected.  If the shard
+            is online for reads and writes, then only its fault tolerance is
+            currently affected.
+        action: >-
+            Determine the scope of the problem and resolve the underying issue.
+            See the "manatee-adm" command inside the PostgreSQL zones for
+            details.
+
+-
+    #
+    # Like the above template, it would be great if this were per-shard.
+    #
+    event: upset.manta.postgres.shard_transition
+    legacyName: manatee-state-transition
+    scope:
+        service: postgres
+    checks:
+        -
+            type: log-scan
+            config:
+                path: "/var/svc/log/manta-application-manatee-sitter:default.log"
+                match:
+                    pattern: finished transition
+                threshold: 1
+                period: 60
+    ka:
+        title: Metadata shard has experienced a takeover event
+        description: >-
+            A metadata shard has gone through a takeover transition.  This may
+            be because the current synchronous peer took over for a primary that
+            it believed had failed, or the current primary peer selected a new
+            synchronous peer to replace one that had failed.  See "manatee-adm
+            history" on this shard for details.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            During the transition, some end user requests may have failed.  Some
+            job tasks may have experienced higher dispatch latency or (in rarer
+            cases) failures.  The transition has completed, and there should be
+            no ongoing impact.
+
+            If the primary peer has been deposed, then fault tolerance may be
+            compromised until that peer has been rebuilt.
+        action: >-
+            There is likely no immediate action required, but it is recommended
+            to verify the health of this shard using "manatee-adm".  You may
+            need to rebuild a deposed peer.
diff --git a/alarm_metadata/probe_templates/storage.yaml b/alarm_metadata/probe_templates/storage.yaml
new file mode 100644
index 0000000..4260013
--- /dev/null
+++ b/alarm_metadata/probe_templates/storage.yaml
@@ -0,0 +1,137 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "storage" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.storage.mako_gc.log_error
+    legacyName: mako-gc-logscan
+    scope:
+        service: storage
+    checks:
+        -
+            type: log-scan
+            config:
+                path: "/var/log/mako_gc.log"
+                match:
+                    pattern: fatal error
+                threshold: 1
+                period: 60
+    ka:
+        title: '"mako-gc" logged an error'
+        description: The "mako-gc" subsystem has logged an error.
+        severity: minor
+        response: No automated response will be taken.
+        impact: >-
+            Garbage collection may not be running.  Disk space used may
+            accumulate on metadata nodes until the problem is repaired.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.storage.minnow.logscan
+    legacyName: minnow-logscan
+    scope:
+        service: storage
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: minnow
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"minnow" logged an error'
+        description: The "minnow" service has logged an error.
+        severity: major
+        response: >-
+            No automated response will be taken.
+        impact: >-
+            One or more storage nodes may not be reporting its health.  Affected
+            nodes will not be used for new objects.
+        action:
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.storage.minnow.heartbeat_stale
+    legacyName: minnow heartbeat too old
+    scope:
+        service: storage
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/bin/bash -c 'if [[ -f /opt/smartdc/minnow/bin/check-minnow ]]; then /opt/smartdc/minnow/bin/check-minnow; exit $?; fi; let delta=$(date +%s)-$(PATH=/opt/smartdc/minnow/build/node/bin:/opt/smartdc/minnow/node_modules/.bin:$PATH findobjects -h $(cat /opt/smartdc/minnow/etc/config.json | json moray.host) manta_storage hostname=$(hostname)* | json -e _mtime=_mtime/1000 -e _mtime=~~_mtime _mtime) ; test $delta -lt 900'"
+                threshold: 3
+                period: 300
+                timeout: 30
+    ka:
+        title: Storage zone heartbeat is too old
+        description: The minnow record for a storage zone is out of date
+        severity: minor
+        response: >-
+            Manta will not use the affected storage nodes for new writes.
+        impact: >-
+            Depending on the number of affected storage nodes, the system may
+            have reduced ability to survive additional failures.  If enough
+            storage nodes are affected, the system may not be able to continue
+            accepting writes.
+        action:
+            Resolve the underlying issue.
+
+-
+    event: upset.manta.storage.mako_ping
+    legacyName: shrimp-nginx-ping
+    #
+    # The point of this probe is to identify when storage nodes go down.  For
+    # that to be useful, we need to run the check from somewhere else.  We
+    # select the "nameservice" zone, on the grounds that there should be at
+    # least one per datacenter, and not a whole lot more than that.  It would be
+    # better if Amon supported opening alarms when expected checks did not
+    # complete successfully.
+    #
+    scope:
+        service: storage
+        checkFrom: nameservice
+    checks:
+        -
+            type: cmd
+            config:
+                autoEnv:
+                    - MANTA_STORAGE_ID
+                cmd: "curl -m 5 -sf http://$MANTA_STORAGE_ID/50x.html -o /dev/null"
+                interval: 60
+                threshold: 3
+                period: 300
+    ka:
+        title: Storage node HTTP ping failed
+        description: A storage node failed to respond to an HTTP ping request.
+        severity: major
+        response: >-
+            If the storage node is down, then Manta will direct writes to other
+            storage nodes.  Reads for objects with a copy on the affected
+            storage node will be directed to other storage nodes that also have
+            a copy of the object, when possible.
+        impact: >-
+            If the storage node is down, then reads and compute jobs will fail
+            when they operate on objects having only one copy that happens to be
+            stored on the affected node.
+        action: >-
+            Resolve the underlying issue.
+
diff --git a/alarm_metadata/probe_templates/storage_gzs.yaml b/alarm_metadata/probe_templates/storage_gzs.yaml
new file mode 100644
index 0000000..5787a93
--- /dev/null
+++ b/alarm_metadata/probe_templates/storage_gzs.yaml
@@ -0,0 +1,131 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for global zones of storage nodes
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.marlin_agent.log_error
+    legacyName: marlin-agent-logscan-error, marlin-agent-logscan-fatal, marlin-agent-logscan-core
+    scope:
+        service: storage
+        global: true
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: marlin-agent
+                fields:
+                    level: error
+                threshold: 1
+                period: 60
+        -
+            type: bunyan-log-scan
+            config:
+                smfServiceName: marlin-agent
+                fields:
+                    level: fatal
+                threshold: 1
+                period: 60
+        -
+            type: log-scan
+            config:
+                smfServiceName: marlin-agent
+                match:
+                    pattern: Stopping because process dumped core.
+                threshold: 1
+                period: 60
+    ka:
+        title: '"marlin-agent" logged an error'
+        description: The "marlin-agent" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            some jobs may have experienced retries, errors, or additional
+            latency.  It is possible that some jobs are stuck.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
+
+-
+    event: upset.manta.global_zone.logs_lingering
+    legacyName: logs not uploaded
+    scope:
+        service: storage
+        global: true
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "test ! $(find /var/log/manta/upload -type f | wc -l) -gt 0"
+                interval: 300
+                threshold: 5
+                period: 1800
+                timeout: 30
+    ka:
+        title: Global zone log files not uploaded
+        description: Some global zone log files have not been uploaded
+        severity: minor
+        response: >-
+            The system automatically retries hourly to upload any internal log
+            files that have not yet been uploaded.
+        impact: >-
+            There is no impact to end-user service.  However, failure to upload
+            files is often indicative of problems affecting end user requests.
+
+            If the affected logs are used for metering, then metering reports
+            and access logs for end users may be unavailable or incomplete until
+            the affected logs are uploaded and the relevant metering jobs re-run
+            by an operator.
+        action: >-
+            Identify the reason for the failure and resolve the underlying
+            issue.  If logs used for metering were affected, you may need to
+            re-run the relevant metering jobs once all logs are available.
+
+            In most components, the log "/var/log/mbackup.log" has a record of
+            recent upload attempts and results.  Another common cause of log
+            upload failure is when a component or service was offline during the
+            scheduled log upload time.
+
+-
+    event: upset.manta.global_zone.smf_maintenance
+    legacyName: "svcs: SMF maintenance"
+    scope:
+        service: storage
+        global: true
+    checks:
+        -
+            type: cmd
+            config:
+                cmd: "/usr/bin/svcs -x"
+                stdoutMatch:
+                    pattern: maintenance
+                    matchWord: true
+                threshold: 1
+                period: 60
+                timeout: 30
+    ka:
+        title: Global zone SMF services in maintenance
+        description: One or more global zone SMF services are in maintenance
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            The impact depends on which services are in maintenance.  In some
+            cases, overall request handling capacity may be reduced.  If enough
+            instances are in maintenance, end users could experience errors.
+        action: >-
+            In the affected global zones, use "svcs -xv" to identify the
+            services in maintenance and see basic instructions for tracking down
+            the problem.
diff --git a/alarm_metadata/probe_templates/webapi.yaml b/alarm_metadata/probe_templates/webapi.yaml
new file mode 100644
index 0000000..15b13e1
--- /dev/null
+++ b/alarm_metadata/probe_templates/webapi.yaml
@@ -0,0 +1,42 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# amon probes for the "webapi" service
+#
+# For background information, see lib/alarms/index.js.  The format of this file
+# is described in lib/alarms/metadata.js.
+#
+
+-
+    event: upset.manta.webapi.log_error
+    legacyName: muskie-logscan
+    scope:
+        service: webapi
+    checks:
+        -
+            type: bunyan-log-scan
+            config:
+                path: "/var/log/muskie.log"
+                fields:
+                    level: ERROR
+                threshold: 1
+                period: 60
+    ka:
+        title: '"muskie" logged an error'
+        description: The "muskie" service has logged an error.
+        severity: major
+        response: No automated response will be taken.
+        impact: >-
+            If the problem was transient, there may be no impact.  Otherwise,
+            some end user requests may be experiencing an elevated error rate.
+        action: >-
+            Determine the scope of the problem based on the log message and
+            resolve the underlying issue.
diff --git a/boot/setup.sh b/boot/setup.sh
index 959cb51..af76609 100755
--- a/boot/setup.sh
+++ b/boot/setup.sh
@@ -34,7 +34,6 @@ chown -R nobody:nobody /opt/smartdc/manta-deployment
 # Add build/node/bin and node_modules/.bin to PATH
 echo "" >>/root/.profile
 echo "export PATH=\$PATH:/opt/smartdc/manta-deployment/build/node/bin:/opt/smartdc/manta-deployment/bin:/opt/smartdc/manta-deployment/node_modules/.bin:/opt/smartdc/sapi/node_modules/.bin" >>/root/.profile
-echo "export MANPATH=/opt/smartdc/manta-deployment/node_modules/mantamon/man:$MANPATH" >> /root/.profile
 echo 'export MANTA_DATACENTER=$(mdata-get "sdc:datacenter_name")' >> /root/.profile
 
 # All done, run boilerplate end-of-setup
diff --git a/cmd/manta-adm.js b/cmd/manta-adm.js
index b4bc330..19c6a8c 100755
--- a/cmd/manta-adm.js
+++ b/cmd/manta-adm.js
@@ -7,12 +7,14 @@
  */
 
 /*
- * Copyright (c) 2015, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /*
  * manta-adm.js: manage manta deployments.  Provides subcommands:
  *
+ *     alarm		view and configure information about alarms
+ *
  *     cn		show information about CNs
  *
  *     show		show information about all deployed services
@@ -39,6 +41,7 @@ var cmdln = require('cmdln');
 var cmdutil = require('cmdutil');
 var jsprim = require('jsprim');
 var path = require('path');
+var restifyClients = require('restify-clients');
 var util = require('util');
 var vasync = require('vasync');
 var VError = require('verror').VError;
@@ -48,6 +51,64 @@ var madm = require('../lib/adm');
 
 var maArg0 = path.basename(process.argv[1]);
 
+var maDefaultAlarmConcurrency = 10;
+
+/*
+ * These node-cmdln options are used by multiple subcommands.  They're defined
+ * in one place to ensure consistency in names, aliases, and help message.
+ */
+var maCommonOptions = {
+    'columns': {
+	'names': [ 'columns', 'o' ],
+	'type': 'arrayOfString',
+	'help': 'Select columns for output (see below).'
+    },
+    'concurrency': {
+	'names': [ 'concurrency' ],
+	'type': 'positiveInteger',
+	'help': 'Number of concurrent requests to make.',
+	'default': maDefaultAlarmConcurrency
+    },
+    'configFile': {
+	'names': [ 'config-file' ],
+	'type': 'string',
+	'help': 'Path to configuration.',
+	'default': common.CONFIG_FILE_DEFAULT
+    },
+    'confirm': {
+	'names': [ 'confirm', 'y' ],
+	'type': 'bool',
+	'help': 'Bypass all confirmations (be careful!)'
+    },
+    'dryrun': {
+	'names': [ 'dryrun', 'n' ],
+	'type': 'bool',
+	'help': 'Print what would be done without actually doing it.'
+    },
+    'logFile': {
+	'names': [ 'log_file', 'log-file', 'l' ],
+	'type': 'string',
+	'help': 'Dump logs to this file (or "stdout").',
+	'default': '/var/log/manta-adm.log'
+    },
+    'logFileDefaultNone': {
+	'names': [ 'log_file', 'log-file', 'l' ],
+	'type': 'string',
+	'help': 'Dump logs to this file (or "stdout")'
+    },
+    'omitHeader': {
+	'names': [ 'omit-header', 'H'],
+	'type': 'bool',
+	'help': 'Omit the header row for columnar output.'
+    },
+    'unconfigure': {
+	'names': [ 'unconfigure' ],
+	'type': 'bool',
+	'help': 'Remove all probes and probe groups instead of updating them.',
+	'default': false
+    }
+};
+
 /*
  * node-cmdln interface for the manta-adm tool.
  */
@@ -61,6 +122,10 @@ function MantaAdm()
 
 util.inherits(MantaAdm, cmdln.Cmdln);
 
+/*
+ * Performs common initialization steps used by most subcommands.  "opts" are
+ * the cmdln-parsed CLI options.  This function processes the "log_file" option.
+ */
 MantaAdm.prototype.initAdm = function (opts, callback)
 {
 	var logstreams;
@@ -78,7 +143,7 @@ MantaAdm.prototype.initAdm = function (opts, callback)
 		console.error('logs at ' + opts.log_file);
 	} else {
 		logstreams = [ {
-		    'level': 'fatal',
+		    'level': process.env['LOG_LEVEL'] || 'fatal',
 		    'stream': process.stderr
 		} ];
 	}
@@ -86,7 +151,7 @@ MantaAdm.prototype.initAdm = function (opts, callback)
 	this.madm_log = new bunyan({
 	    'name': maArg0,
 	    'streams': logstreams,
-	    'serializers': bunyan.stdSerializers
+	    'serializers': restifyClients.bunyan.serializers
 	});
 
 	this.madm_adm = new madm.MantaAdm(this.madm_log);
@@ -102,6 +167,8 @@ MantaAdm.prototype.finiAdm = function ()
 	this.madm_adm.close();
 };
 
+MantaAdm.prototype.do_alarm = MantaAdmAlarm;
+
 MantaAdm.prototype.do_cn = function (subcmd, opts, args, callback)
 {
 	var self = this;
@@ -167,27 +234,21 @@ MantaAdm.prototype.do_cn.help =
     '{{options}}\n' +
     'Available columns for -o:\n    ' + madm.cnColumnNames().join(', ');
 
-MantaAdm.prototype.do_cn.options = [ {
-    'names': [ 'omit-header', 'H'],
-    'type': 'bool',
-    'help': 'Omit the header row for columnar output'
-}, {
-    'names': [ 'log_file', 'l' ],
-    'type': 'string',
-    'help': 'Dump logs to this file (or "stdout")'
-}, {
-    'names': [ 'oneachnode', 'n' ],
-    'type': 'bool',
-    'help': 'Emit output suitable for "sdc-oneachnode -n"'
-}, {
-    'names': [ 'columns', 'o' ],
-    'type': 'arrayOfString',
-    'help': 'Select columns for output (see below)'
-}, {
-    'names': [ 'storage-only', 's' ],
-    'type': 'bool',
-    'help': 'Show only nodes used as storage nodes.'
-}];
+MantaAdm.prototype.do_cn.options = [
+    maCommonOptions.omitHeader,
+    maCommonOptions.logFileDefaultNone,
+    {
+	'names': [ 'oneachnode', 'n' ],
+	'type': 'bool',
+	'help': 'Emit output suitable for "sdc-oneachnode -n"'
+    },
+    maCommonOptions.columns,
+    {
+	'names': [ 'storage-only', 's' ],
+	'type': 'bool',
+	'help': 'Show only nodes used as storage nodes.'
+    }
+];
 
 MantaAdm.prototype.do_genconfig = function (subcmd, opts, args, callback)
 {
@@ -254,8 +315,7 @@ MantaAdm.prototype.do_genconfig = function (subcmd, opts, args, callback)
 };
 
 MantaAdm.prototype.do_genconfig.help =
-    'Generate a configuration for COAL or lab deployment or for \n' +
-    'a larger deployment.\n' +
+    'Generate a config for COAL, lab, or a larger deployment.\n' +
     '\n' +
     'Usage:\n' +
     '\n' +
@@ -364,23 +424,16 @@ MantaAdm.prototype.do_show.options = [ {
     'names': [ 'bycn', 'c' ],
     'type': 'bool',
     'help': 'Show results by compute node, rather than by service.'
-}, {
-    'names': [ 'omit-header', 'H'],
-    'type': 'bool',
-    'help': 'Omit the header row for columnar output'
-}, {
+},
+    maCommonOptions.omitHeader,
+{
     'names': [ 'json', 'j' ],
     'type': 'bool',
     'help': 'Show results in JSON form suitable for importing with "update".'
-}, {
-    'names': [ 'log_file', 'l' ],
-    'type': 'string',
-    'help': 'dump logs to this file (or "stdout")'
-}, {
-    'names': [ 'columns', 'o' ],
-    'type': 'arrayOfString',
-    'help': 'Select columns for output (see below)'
-}, {
+},
+    maCommonOptions.logFileDefaultNone,
+    maCommonOptions.columns,
+ {
     'names': [ 'summary', 's' ],
     'type': 'bool',
     'help': 'Show summary of deployed zones rather than each zone separately.'
@@ -481,20 +534,12 @@ MantaAdm.prototype.do_update = function (subcmd, opts, args, callback)
 MantaAdm.prototype.do_update.help =
     'Update deployment to match a JSON configuration.\n\n{{options}}';
 
-MantaAdm.prototype.do_update.options = [ {
-    'names': [ 'log_file', 'l' ],
-    'type': 'string',
-    'help': 'dump logs to this file (or "stdout")',
-    'default': '/var/log/manta-adm.log'
-}, {
-    'names': [ 'dryrun', 'n' ],
-    'type': 'bool',
-    'help': 'Print what would be done without actually doing it.'
-}, {
-    'names': [ 'confirm', 'y' ],
-    'type': 'bool',
-    'help': 'Bypass all confirmations (be careful!)'
-}, {
+MantaAdm.prototype.do_update.options = [
+    maCommonOptions.logFile,
+    maCommonOptions.dryrun,
+    maCommonOptions.confirm,
+    maCommonOptions.configFile,
+{
     'names': [ 'no-reprovision' ],
     'type': 'bool',
     'help': 'When upgrading a zone, always provision and deprovision ' +
@@ -507,7 +552,7 @@ function MantaAdmZk(parent)
 {
 	this.mn_parent = parent;
 	cmdln.Cmdln.call(this, {
-	    'name': 'zk',
+	    'name': parent.name + ' zk',
 	    'desc': 'View and modify ZooKeeper servers configuration.'
 	});
 }
@@ -562,7 +607,7 @@ MantaAdmZk.prototype.do_list = function (subcmd, opts, args, callback)
 };
 
 MantaAdmZk.prototype.do_list.help =
-    'List configured ZooKeeper servers\n\n' +
+    'List configured ZooKeeper servers.\n\n' +
     'Usage:\n\n' +
     '    manta-adm zk list OPTIONS\n\n' +
     'Examples:\n\n' +
@@ -579,20 +624,11 @@ MantaAdmZk.prototype.do_list.help =
  * as general debug logs.  But the "zk list" subcommand is read-only and only
  * applicable to this user, so we use a path in /var/tmp for the log.
  */
-MantaAdmZk.prototype.do_list.options = [ {
-    'names': [ 'omit-header', 'H'],
-    'type': 'bool',
-    'help': 'Omit the header row for columnar output'
-}, {
-    'names': [ 'log_file', 'l' ],
-    'type': 'string',
-    'help': 'dump logs to this file (or "stdout")',
-    'default': '/var/tmp/manta-adm.log'
-}, {
-    'names': [ 'columns', 'o' ],
-    'type': 'arrayOfString',
-    'help': 'Select columns for output (see below)'
-} ];
+MantaAdmZk.prototype.do_list.options = [
+    maCommonOptions.omitHeader,
+    maCommonOptions.logFileDefaultNone,
+    maCommonOptions.columns
+];
 
 MantaAdmZk.prototype.do_fixup = function (subcmd, opts, args, callback)
 {
@@ -690,7 +726,7 @@ MantaAdmZk.prototype.do_fixup = function (subcmd, opts, args, callback)
 };
 
 MantaAdmZk.prototype.do_fixup.help = [
-    'Repair ZooKeeper configuration',
+    'Repair ZooKeeper configuration.',
     '',
     'This command compares the ZooKeeper configuration (defined by the ',
     'ZK_SERVERS and ZK_ID SAPI metadata properties) to the list of deployed ',
@@ -714,19 +750,829 @@ MantaAdmZk.prototype.do_fixup.help = [
     '{{options}}'
 ].join('\n');
 
-MantaAdmZk.prototype.do_fixup.options = [ {
-    'names': [ 'confirm', 'y' ],
-    'type': 'bool',
-    'help': 'Bypass all confirmations (be careful!)'
-}, {
-    'names': [ 'dryrun', 'n' ],
-    'type': 'bool',
-    'help': 'Print what would be done without actually doing it.'
-}, {
-    'names': [ 'log_file', 'l' ],
-    'type': 'string',
-    'help': 'Dump logs to this file (or "stdout")'
-} ];
+MantaAdmZk.prototype.do_fixup.options = [
+    maCommonOptions.confirm,
+    maCommonOptions.dryrun,
+    maCommonOptions.logFile
+];
+
+function MantaAdmAlarm(parent)
+{
+	this.maa_parent = parent;
+	cmdln.Cmdln.call(this, {
+	    'name': parent.name + ' alarm',
+	    'desc': 'View and configure information about alarms.'
+	});
+}
+
+util.inherits(MantaAdmAlarm, cmdln.Cmdln);
+
+/*
+ * Performs common initialization steps used for the "manta-adm alarm"
+ * subcommands.  Named arguments:
+ *
+ *     sources      Describes which data to load.  See alarmsInit in lib/adm.js.
+ *
+ *     clioptions   Parsed CLI options, as provided by node-cmdln.  This
+ *                  function processes the "concurrency" and "config_file"
+ *                  options, plus the options processed by initAdm().
+ *
+ *     skipWarnings By default, warnings encountered while fetching alarm
+ *                  configuration are printed out.  If this option is true, then
+ *                  these warnings are ignored.
+ *
+ *     skipFetch    By default, Triton objects (VMs, CNs, and SAPI information)
+ *                  are fetched.  This takes some time, but this information is
+ *                  needed by most subcommands.  If this option is true, then
+ *                  this step is skipped.
+ */
+MantaAdmAlarm.prototype.initAdmAndFetchAlarms = function (args, callback)
+{
+	var self = this;
+	var clioptions, skipWarnings, initArgs, funcs;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.sources, 'args.sources');
+	assertplus.object(args.clioptions, 'clioptions');
+	assertplus.optionalBool(args.skipWarnings, 'args.skipWarnings');
+	assertplus.optionalBool(args.skipFetch, 'args.skipFetch');
+
+	skipWarnings = args.skipWarnings;
+	clioptions = args.clioptions;
+	initArgs = {
+	    'configFile': clioptions.config_file,
+	    'concurrency': clioptions.concurrency || maDefaultAlarmConcurrency,
+	    'sources': args.sources
+	};
+
+	funcs = [];
+	funcs.push(function initAdm(_, stepcb) {
+		self.maa_parent.initAdm(clioptions, stepcb);
+	});
+
+	if (!args.skipFetch) {
+		funcs.push(function fetch(_, stepcb) {
+			self.maa_parent.madm_adm.fetchDeployed(stepcb);
+		});
+	}
+
+	funcs.push(function fetchAmon(_, stepcb) {
+		self.maa_parent.madm_adm.alarmsInit(initArgs, stepcb);
+	});
+
+	vasync.pipeline({
+	    'funcs': funcs
+	}, function (err) {
+		var errors;
+
+		if (err) {
+			fatal(err.message);
+		}
+
+		if (!skipWarnings) {
+			errors = self.maa_parent.madm_adm.alarmWarnings();
+			errors.forEach(function (e) {
+				cmdutil.warn(e);
+			});
+		}
+
+		callback();
+	});
+};
+
+MantaAdmAlarm.prototype.do_close = function (subcmd, opts, args, callback)
+{
+	var parent;
+
+	if (args.length < 1) {
+		callback(new Error('expected ALARMID'));
+		return;
+	}
+
+	parent = this.maa_parent;
+	this.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': {}
+	}, function () {
+		var adm = parent.madm_adm;
+		adm.alarmsClose({
+		    'alarmIds': args,
+		    'concurrency': opts.concurrency
+		}, function (err) {
+			if (err) {
+				VError.errorForEach(err, function (e) {
+					console.error('error: %s', e.message);
+				});
+
+				process.exit(1);
+			}
+
+			parent.finiAdm();
+			callback();
+		});
+	});
+};
+
+MantaAdmAlarm.prototype.do_close.help = [
+    'Close open alarms.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm close ALARMID...',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarm.prototype.do_close.options = [
+    maCommonOptions.concurrency,
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarm.prototype.do_config = MantaAdmAlarmConfig;
+
+MantaAdmAlarm.prototype.do_details = function (subcmd, opts, args, callback)
+{
+	this.doAlarmPrintSubcommand(opts, 1, args, callback);
+};
+
+MantaAdmAlarm.prototype.do_details.help = [
+    'Print details about an alarm.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm details ALARMID...',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarm.prototype.do_details.options = [
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarm.prototype.do_faults = function (subcmd, opts, args, callback)
+{
+	this.doAlarmPrintSubcommand(opts, undefined, args, callback);
+};
+
+MantaAdmAlarm.prototype.do_faults.help = [
+    'Print information about all of an alarm\'s faults.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm faults ALARMID...',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarm.prototype.do_faults.options = [
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarm.prototype.doAlarmPrintSubcommand = function
+    doAlarmPrintSubcommand(opts, nmaxfaults, args, callback)
+{
+	var self = this;
+	var sources = {};
+
+	if (args.length < 1) {
+		callback(new Error('expected ALARMID'));
+		return;
+	}
+
+	sources = {
+	    'configBasic': true,
+	    'alarms': {
+		'alarmIds': args
+	    }
+	};
+
+	this.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': sources,
+	    'skipWarnings': true
+	}, function () {
+		var nerrors = 0;
+		args.forEach(function (id) {
+			var error;
+
+			error = self.maa_parent.madm_adm.alarmPrint({
+			    'id': id,
+			    'stream': process.stdout,
+			    'nmaxfaults': nmaxfaults
+			});
+
+			if (error instanceof Error) {
+				cmdutil.warn(error);
+				nerrors++;
+			}
+
+			console.log('');
+		});
+
+		if (nerrors > 0) {
+			process.exit(1);
+		}
+
+		self.maa_parent.finiAdm();
+	});
+};
+
+MantaAdmAlarm.prototype.do_list = function (subcmd, opts, args, callback)
+{
+	var self = this;
+	var options = {};
+	var sources = {};
+
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	switch (opts.state) {
+	case 'all':
+	case 'closed':
+	case 'open':
+	case 'recent':
+		break;
+
+	default:
+		callback(new VError('unsupported state: %s', opts.state));
+		return;
+	}
+
+	options = listPrepareArgs(opts, madm.alarmColumnNames());
+	if (options instanceof Error) {
+		callback(options);
+		return;
+	}
+
+	sources = {
+	    'configBasic': true,
+	    'alarms': {
+		'state': opts.state
+	    }
+	};
+
+	options.stream = process.stdout;
+	this.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': sources
+	}, function () {
+		self.maa_parent.madm_adm.alarmsList(options);
+		self.maa_parent.finiAdm();
+		callback();
+	});
+};
+
+MantaAdmAlarm.prototype.do_list.help = [
+    'List open alarms.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm list OPTIONS',
+    '',
+    '{{options}}',
+    '',
+    'Available columns for -o:\n    ' + madm.alarmColumnNames().join(', ')
+].join('\n');
+
+MantaAdmAlarm.prototype.do_list.options = [
+    maCommonOptions.configFile,
+    maCommonOptions.omitHeader,
+    maCommonOptions.columns,
+    {
+	'names': [ 'state' ],
+	'type': 'string',
+	'help': 'List only alarms in specified state',
+	'default': 'open'
+    }
+];
+
+MantaAdmAlarm.prototype.do_metadata = MantaAdmAlarmMetadata;
+
+MantaAdmAlarm.prototype.do_notify = function (subcmd, opts, args, callback)
+{
+	var parent;
+	var allowedArg0 = {
+	    'enabled': true,
+	    'enable': true,
+	    'on': true,
+	    'true': true,
+	    'yes': true,
+
+	    'disabled': false,
+	    'disable': false,
+	    'off': false,
+	    'false': false,
+	    'no': false
+	};
+
+	if (args.length < 2) {
+		callback(new Error('expected arguments'));
+		return;
+	}
+
+	if (!allowedArg0.hasOwnProperty(args[0])) {
+		callback(new Error('expected "on" or "off"'));
+		return;
+	}
+
+	parent = this.maa_parent;
+	this.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': {}
+	}, function () {
+		var adm = parent.madm_adm;
+		adm.alarmsUpdateNotification({
+		    'alarmIds': args.slice(1),
+		    'concurrency': opts.concurrency,
+		    'suppressed': !allowedArg0[args[0]]
+		}, function (err) {
+			if (err) {
+				VError.errorForEach(err, function (e) {
+					console.error('error: %s', e.message);
+				});
+
+				process.exit(1);
+			}
+
+			parent.finiAdm();
+			callback();
+		});
+	});
+};
+
+MantaAdmAlarm.prototype.do_notify.help = [
+    'Enable or disable alarm notifications.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm notify on|off ALARMID...',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarm.prototype.do_notify.options = [
+    maCommonOptions.concurrency,
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarm.prototype.do_show = function (subcmd, opts, args, callback)
+{
+	var parent, sources;
+
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	parent = this.maa_parent;
+	sources = {
+	    'configBasic': true,
+	    'alarms': {
+		'state': 'open'
+	    }
+	};
+
+	this.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': sources
+	}, function () {
+		var showArgs = { 'stream': process.stdout };
+		parent.madm_adm.alarmsShow(showArgs);
+		parent.finiAdm();
+		callback();
+	});
+};
+
+MantaAdmAlarm.prototype.do_show.help = [
+    'Summarize open alarms.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm show',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarm.prototype.do_show.options = [ maCommonOptions.configFile ];
+
+
+function MantaAdmAlarmConfig(parent)
+{
+	this.maac_parent = parent;
+	this.maac_root = parent.maa_parent;
+
+	cmdln.Cmdln.call(this, {
+	    'name': parent.name + ' config',
+	    'desc': 'Manage probe and probe group configuration.'
+	});
+}
+
+util.inherits(MantaAdmAlarmConfig, cmdln.Cmdln);
+
+MantaAdmAlarmConfig.prototype.do_probegroup = MantaAdmAlarmProbeGroup;
+
+MantaAdmAlarmConfig.prototype.do_show = function (subcmd, opts, args, callback)
+{
+	var root, parent, adm, sources;
+
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	root = this.maac_root;
+	parent = this.maac_parent;
+	sources = {
+	    'configFull': true
+	};
+
+	parent.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': sources
+	}, function () {
+		adm = root.madm_adm;
+		adm.alarmConfigShow({
+		    'stream': process.stdout
+		});
+
+		root.finiAdm();
+		callback();
+	});
+
+};
+
+MantaAdmAlarmConfig.prototype.do_show.help = [
+    'Summarize configured probes and probe groups.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm config show',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarmConfig.prototype.do_show.options = [
+    maCommonOptions.concurrency,
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarmConfig.prototype.do_update =
+    function (subcmd, opts, args, callback)
+{
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	this.amonUpdateSubcommand(opts, opts.dryrun, callback);
+};
+
+MantaAdmAlarmConfig.prototype.do_update.help = [
+    'Update and probes and probe groups that are out of date.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm config update OPTIONS',
+    '    manta-adm alarm config update OPTIONS --unconfigure',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarmConfig.prototype.do_update.options = [
+    maCommonOptions.confirm,
+    maCommonOptions.concurrency,
+    maCommonOptions.configFile,
+    maCommonOptions.dryrun,
+    maCommonOptions.unconfigure
+];
+
+MantaAdmAlarmConfig.prototype.do_verify =
+    function (subcmd, opts, args, callback)
+{
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	this.amonUpdateSubcommand(opts, true, callback);
+};
+
+MantaAdmAlarmConfig.prototype.do_verify.help = [
+    'Check that deployed probes and probe groups are up to date.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm config verify OPTIONS',
+    '',
+    '{{options}}'
+].join('\n');
+
+MantaAdmAlarmConfig.prototype.do_verify.options = [
+    maCommonOptions.concurrency,
+    maCommonOptions.configFile,
+    maCommonOptions.unconfigure
+];
+
+MantaAdmAlarmConfig.prototype.amonUpdateSubcommand =
+    function (clioptions, dryrun, callback) {
+	var self = this;
+	var root, parent, sources, adm, plan;
+
+	assertplus.object(clioptions, 'clioptions');
+	assertplus.number(clioptions.concurrency, 'clioptions.concurrency');
+	assertplus.bool(clioptions.unconfigure, 'clioptions.unconfigure');
+
+	root = self.maac_root;
+	parent = self.maac_parent;
+	sources = {
+	    'configFull': true
+	};
+	vasync.pipeline({
+	    'arg': null,
+	    'funcs': [
+		function init(_, stepcb) {
+			parent.initAdmAndFetchAlarms({
+			    'clioptions': clioptions,
+			    'sources': sources
+			}, stepcb);
+		},
+		function generateAmonPlan(_, stepcb) {
+			var options;
+
+			adm = root.madm_adm;
+			options = {
+				'unconfigure': clioptions.unconfigure
+			};
+			plan = adm.amonUpdatePlanCreate(options);
+			if (plan instanceof Error) {
+				stepcb(plan);
+				return;
+			}
+
+			adm.amonUpdatePlanDump({
+			    'plan': plan,
+			    'stream': process.stderr,
+			    'verbose': false
+			});
+
+			if (!plan.needsChanges()) {
+				console.log('no changes to make');
+				stepcb();
+				return;
+			}
+
+			if (dryrun) {
+				console.log('To apply these changes, ' +
+				    'use the "update" subcommand without ' +
+				    'the -n/--dry-run option.');
+				stepcb();
+				return;
+			}
+
+			if (clioptions.confirm) {
+				stepcb();
+				return;
+			}
+
+			common.confirm(
+			    'Are you sure you want to proceed? (y/N): ',
+			    function (proceed) {
+				if (!proceed) {
+					stepcb(new Error('aborted by user'));
+				} else {
+					stepcb();
+				}
+			    });
+		},
+		function execAmonPlan(_, stepcb) {
+			if (dryrun || !plan.needsChanges()) {
+				stepcb();
+				return;
+			}
+
+			adm.amonUpdatePlanApply({
+			    'concurrency': clioptions.concurrency,
+			    'plan': plan,
+			    'stream': process.stderr
+			}, stepcb);
+		}
+	    ]
+	}, function (err) {
+		root.finiAdm();
+		callback(err);
+	});
+};
+
+function MantaAdmAlarmMetadata(parent)
+{
+	this.maam_parent = parent;
+	this.maam_root = parent.maa_parent;
+
+	cmdln.Cmdln.call(this, {
+	    'name': parent.name + ' metadata',
+	    'desc': 'View local metadata about alarm config.'
+	});
+}
+
+util.inherits(MantaAdmAlarmMetadata, cmdln.Cmdln);
+
+MantaAdmAlarmMetadata.prototype.do_events =
+    function cmdEvents(subcmd, opts, args, callback)
+{
+	var self = this;
+
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	this.maam_parent.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': {},
+	    'skipFetch': true
+	}, function () {
+		var events = self.maam_root.madm_adm.alarmEventNames();
+		events.forEach(function (eventName) {
+			console.log(eventName);
+		});
+		self.maam_root.finiAdm();
+		callback();
+	});
+};
+
+MantaAdmAlarmMetadata.prototype.do_events.help = [
+    'List known event names.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm events'
+].join('\n');
+
+MantaAdmAlarmMetadata.prototype.do_events.options = [
+    maCommonOptions.configFile
+];
+
+MantaAdmAlarmMetadata.prototype.do_ka = function (subcmd, opts, args, callback)
+{
+	var self = this;
+
+	this.maam_parent.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': {},
+	    'skipFetch': true
+	}, function () {
+		var events, nerrors;
+		var root = self.maam_root;
+
+		if (args.length === 0) {
+			events = root.madm_adm.alarmEventNames();
+		} else {
+			events = args;
+		}
+
+		nerrors = 0;
+		events.forEach(function (eventName) {
+			var error;
+			error = root.madm_adm.alarmKaPrint({
+			    'eventName': eventName,
+			    'stream': process.stdout
+			});
+
+			if (error instanceof Error) {
+				cmdutil.warn(error);
+				nerrors++;
+			}
+
+			console.log('');
+		});
+
+		if (nerrors > 0) {
+			process.exit(1);
+		}
+		root.finiAdm();
+		callback();
+	});
+};
+
+MantaAdmAlarmMetadata.prototype.do_ka.help = [
+    'Print information about events.',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm ka',
+    '    manta-adm alarm ka EVENT_NAME'
+].join('\n');
+
+MantaAdmAlarmMetadata.prototype.do_ka.options = [ maCommonOptions.configFile ];
+
+
+function MantaAdmAlarmProbeGroup(parent)
+{
+	this.maap_parent = parent;
+	this.maap_root = parent.maac_root;
+
+	cmdln.Cmdln.call(this, {
+	    'name': parent.name + ' probegroup',
+	    'desc': 'View and configure information about amon probe groups.'
+	});
+}
+
+util.inherits(MantaAdmAlarmProbeGroup, cmdln.Cmdln);
+
+MantaAdmAlarmProbeGroup.prototype.do_list = function (subcmd,
+    opts, args, callback)
+{
+	var self = this;
+	var options = {};
+	var sources;
+
+	if (args.length > 0) {
+		callback(new Error('unexpected arguments'));
+		return;
+	}
+
+	options = listPrepareArgs(opts, madm.probeGroupColumnNames());
+	if (options instanceof Error) {
+		callback(options);
+		return;
+	}
+
+	/*
+	 * We fetch the list of open alarms in order to count the alarms for
+	 * each probe group.
+	 */
+	sources = {
+	    'configFull': true,
+	    'alarms': {
+		'state': 'open'
+	    }
+	};
+
+	options.stream = process.stdout;
+	this.maap_parent.maac_parent.initAdmAndFetchAlarms({
+	    'clioptions': opts,
+	    'sources': sources
+	}, function () {
+		self.maap_root.madm_adm.alarmsProbeGroupsList(options);
+		self.maap_root.finiAdm();
+		callback();
+	});
+};
+
+MantaAdmAlarmProbeGroup.prototype.do_list.help = [
+    'List open alarms',
+    '',
+    'Usage:',
+    '',
+    '    manta-adm alarm config probegroup list OPTIONS',
+    '',
+    '{{options}}',
+    '',
+    'Available columns for -o:\n',
+    '    ' + madm.probeGroupColumnNames().join(', ')
+].join('\n');
+
+MantaAdmAlarmProbeGroup.prototype.do_list.options = [
+    maCommonOptions.omitHeader,
+    maCommonOptions.columns,
+    maCommonOptions.configFile
+];
+
+
+/*
+ * Named arguments:
+ *
+ *     opts		options provided by cmdln
+ *
+ *     allowed		allowed column names
+ *
+ * Returns either an Error describing invalid command-line arguments or an
+ * object with "columns" and "omitHeader" set according to the options.
+ */
+function listPrepareArgs(opts, allowed)
+{
+	var options, selected;
+
+	options = {};
+	if (opts.columns) {
+		selected = checkColumns(allowed, opts.columns);
+		if (selected instanceof Error) {
+			return (selected);
+		}
+
+		options.columns = selected;
+	}
+
+	if (opts.omit_header) {
+		options.omitHeader = true;
+	} else {
+		options.omitHeader = false;
+	}
+
+	return (options);
+}
 
 function checkColumns(allowed, columns)
 {
diff --git a/docs/man/man1/manta-adm.md b/docs/man/man1/manta-adm.md
index 6c50d43..020f65c 100644
--- a/docs/man/man1/manta-adm.md
+++ b/docs/man/man1/manta-adm.md
@@ -1,4 +1,4 @@
-# MANTA-ADM 1 "2016" Manta "Manta Operator Commands"
+# MANTA-ADM 1 "2017" Manta "Manta Operator Commands"
 
 ## NAME
 
@@ -6,6 +6,8 @@ manta-adm - administer a Manta deployment
 
 ## SYNOPSIS
 
+`manta-adm alarm SUBCOMMAND... [OPTIONS...]`
+
 `manta-adm cn [-l LOG_FILE] [-H] [-o FIELD...] [-n] [-s] CN_FILTER`
 
 `manta-adm genconfig "lab" | "coal"`
@@ -30,6 +32,9 @@ deployment.  This command only operates on zones within the same datacenter.
 The command may need to be repeated in other datacenters in order to execute it
 across an entire Manta deployment.
 
+`manta-adm alarm`
+  List and configure amon-based alarms for Manta.
+
 `manta-adm cn`
   Show information about Manta servers in this DC.
 
@@ -125,6 +130,14 @@ Many commands also accept:
   Emit verbose log to LOGFILE.  The special string "stdout" causes output to be
   emitted to the program's stdout.
 
+Commands that make changes support:
+
+`-n, --dryrun`
+  Print what changes would be made without actually making them.
+
+`-y, --confirm`
+  Bypass all confirmation prompts.
+
 **Important note for programmatic users:** Except as noted below, the output
 format for this command is subject to change at any time. The only subcommands
 whose output is considered committed are:
@@ -133,13 +146,179 @@ whose output is considered committed are:
 * `manta-adm show`, only when used with either the "-o" or "-j" option
 * `manta-adm zk list`, only when used with the "-o" option
 
-The output for any other commands may change at any time. Documented
+The output for any other commands may change at any time.  The `manta-adm alarm`
+subcommand is still considered an experimental interface.  All other documented
 subcommands, options, and arguments are committed, and you can use the exit
-status of the program to determine success of failure.
+status of the program to determine success or failure.
 
 
 ## SUBCOMMANDS
 
+### "alarm" subcommand
+
+`manta-adm alarm close ALARM_ID...`
+
+`manta-adm alarm config probegroup list [-H] [-o FIELD...]`
+
+`manta-adm alarm config show`
+
+`manta-adm alarm config update [-n] [-y] [--unconfigure]`
+
+`manta-adm alarm config verify [--unconfigure]`
+
+`manta-adm alarm details ALARM_ID...`
+
+`manta-adm alarm faults ALARM_ID...`
+
+`manta-adm alarm list [-H] [-o FIELD...] [--state=STATE]`
+
+`manta-adm alarm metadata events`
+
+`manta-adm alarm metadata ka [EVENT_NAME...]`
+
+`manta-adm alarm notify on|off ALARM_ID...`
+
+`manta-adm alarm show`
+
+The `manta-adm alarm` subcommand provides several tools that allow operators to:
+
+* view and configure amon probes and probe groups (`config` subcommand)
+* view open alarms (`show`, `list`, `details`, and `faults` subcommands)
+* configure notifications for open alarms (`notify` subcommand)
+* view local metadata about alarms and probes (`metadata` subcommand)
+
+The primary commands for working with alarms are:
+
+* `manta-adm alarm config update`: typically used during initial deployment and
+  after other deployment operations to ensure that the right set of probes and
+  probe groups are configured for the deployed components
+* `manta-adm alarm show`: summarize open alarms
+* `manta-adm alarm details ALARM_ID...`: report detailed information (including
+  suggested actions) for the specified alarms
+* `manta-adm alarm close ALARM_ID...`: close open alarms, indicating that they
+  no longer represent issues
+
+For background about Amon itself, probes, probegroups, and alarms, see the
+Triton Amon reference documentation.
+
+As with other subcommands, this command only operates on the current Triton
+datacenter.  In multi-datacenter deployments, alarms are managed separately in
+each datacenter.
+
+Some of the following subcommands can operate on many alarms.  These subcommands
+exit failure if they fail for any of the specified alarms, but the operation may
+have completed successfully for other alarms.  For example, closing 3 alarms is
+not atomic.  If the operation fails, then 1, 2, or 3 alarms may still be open.
+
+`manta-adm alarm close ALARM_ID...`
+
+Close the specified alarms.  These alarms will no longer show up in the
+`manta-adm alarm list` or `manta-adm alarm show` output.  Amon purges closed
+alarms completely after some period of time.
+
+If the underlying issue that caused an alarm is not actually resolved, then a
+new alarm may be opened for the same issue.  In some cases, that can happen
+almost immediately.  In other cases, it may take many hours for the problem to
+resurface.  In the case of transient issues, a new alarm may not open again
+until the issue occurs again, which could be days, weeks, or months later.  That
+does not mean the underlying issue was actually resolved.
+
+`manta-adm alarm config probegroup list [-H] [-o FIELD...]`
+
+List configured probe groups in tabular form.  This is primarily useful in
+debugging unexpected behavior from the alarms themselves.  The `manta-adm alarm
+config show` command provides a more useful summary of the probe groups that are
+configured.
+
+`manta-adm alarm config show`
+
+Shows summary information about the probes and probe groups that are configured.
+This is not generally necessary but it can be useful to verify that probes are
+configured as expected.
+
+`manta-adm alarm config update [-n] [-y] [--unconfigure]`
+
+Examines the Manta components that are deployed and the alarm configuration
+(specifically, the probes and probe groups deployed to monitor those components)
+and compares them with the expected configuration.  If these do not match,
+prints out a summary of proposed changes to the configuration and optionally
+applies those changes.
+
+If `--unconfigure` is specified, then the tool removes all probes and probe
+groups.
+
+This is the primary tool for updating the set of deployed probes and probe
+groups.  Operators would typically use this command:
+
+- during initial deployment to deploy probes and probe groups
+- after deploying (or undeploying) any Manta components to deploy (or remove)
+  probes related to the affected components
+- after updating the `manta-adm` tool itself, which bundles the probe
+  definitions, to deploy any new or updated probes
+- at any time to verify that the configuration matches what's expected
+
+This operation is idempotent.
+
+This command supports the `-n/--dryrun` and `-y/--confirm` options described
+above.
+
+`manta-adm alarm config verify [--unconfigure]`
+
+Behaves exactly like `manta-adm alarm config update --dryrun`.
+
+`manta-adm alarm details ALARM_ID...`
+
+Prints detailed information about any number of alarms.  The detailed
+information includes the time the alarm was opened, the last time an event was
+associated with this alarm, the total number of events associated with the
+alarm, the affected components, and information about the severity, automated
+response, and suggested actions for this issue.
+
+`manta-adm alarm faults ALARM_ID...`
+
+Prints detailed information about the faults associated with any number of
+alarms.  Each fault represents a particular probe failure.  The specific
+information provided depends on the alarm.  If the alarm related to a failed
+health check command, then the exit status, terminating signal, stdout, and
+stderr of the command are provided.  If the alarm relates to an error log entry,
+the contents of the log entry are provided.  There can be many faults associated
+with a single alarm.
+
+`manta-adm alarm list [-H] [-o FIELD...] [--state=STATE]`
+
+Lists alarms in tabular form.  `STATE` controls which alarms are listed, which
+may be any of "open", "closed", "all", or "recent".  The default is "open".
+
+See also the `manta-adm alarm show` command.
+
+`manta-adm alarm metadata events`
+
+List the names for all of the events known to this version of `manta-adm`.  Each
+event corresponds to a distinct kind of problem.  For details about each one,
+see `manta-adm alarm metadata ka`.  The list of events comes from metadata
+bundled with the `manta-adm` tool.
+
+`manta-adm alarm metadata ka [EVENT_NAME...]`
+
+Print out knowledge articles about each of the specified events.  This
+information comes from metadata bundled with the `manta-adm` tool.  If no events
+are specified, prints out knowledge articles about all events.
+
+Knowledge articles include information about the severity of the problem, the
+impact, the automated response, and the suggested action.
+
+`manta-adm alarm notify on|off ALARM_ID...`
+
+Enable or disable notifications for the specified alarms.  Notifications are
+generally configured through Amon, which supports both email and XMPP
+notification for new alarms and new events on existing, open alarms.  This
+command controls whether notifications are enabled for the specified alarms.
+
+`manta-adm alarm show`
+
+Summarize open alarms.  For each alarm, use the `manta-adm alarm details`
+subcommand to view more information about it.
+
 
 ### "cn" subcommand
 
@@ -373,20 +552,13 @@ care should be taken when using it with stateful services like "postgres" or
 "storage".  See the Manta Operator's Guide for the appropriate procedures for
 upgrading all components.**
 
-Options:
-
-`-n, --dryrun`
-  Print what changes would be made without actually making them.
-
-`-y, --confirm`
-  Bypass all confirmation prompts.
+This command supports the `-l/--log_file`, `-n/--dryrun`, and `-y/--confirm`
+options described above, plus:
 
 `--no-reprovision`
   When upgrading a zone, always provision a new zone and deprovision the
   previous one, rather than reprovisioning the existing one.
 
-See above for information about the `-l/--log_file` option.
-
 If `SERVICE` is specified, then only instances of the named service are
 changed.
 
@@ -479,15 +651,8 @@ See above for information about the `-l`, `-H`, and `-o` options for
 ordinal number of each server), "datacenter", "zoneabbr", "zonename", "ip", and
 "port".
 
-The `manta-adm zk fixup` command supports options:
-
-`-n, --dryrun`
-  Print what changes would be made without actually making them.
-
-`-y, --confirm`
-  Bypass all confirmation prompts.
-
-It also supports the `-l/--log_file` option described above.
+The `manta-adm zk fixup` command supports the `-l/--log_file`, `-n/--dryrun`,
+and `-y/--confirm` options described above.
 
 
 ## EXIT STATUS
@@ -504,7 +669,7 @@ It also supports the `-l/--log_file` option described above.
 
 ## COPYRIGHT
 
-Copyright (c) 2016 Joyent Inc.
+Copyright (c) 2017 Joyent Inc.
 
 ## SEE ALSO
 
diff --git a/lib/adm.js b/lib/adm.js
index 984a7e0..cd434d7 100644
--- a/lib/adm.js
+++ b/lib/adm.js
@@ -14,6 +14,7 @@
 
 var assert = require('assert');
 var assertplus = require('assert-plus');
+var extsprintf = require('extsprintf');
 var fs = require('fs');
 var jsprim = require('jsprim');
 var net = require('net');
@@ -21,13 +22,26 @@ var path = require('path');
 var sprintf = require('sprintf-js').sprintf;
 var tab = require('tab');
 var vasync = require('vasync');
+var wordwrap = require('wordwrap');
+
 var VError = require('verror').VError;
 var MultiError = require('verror').MultiError;
-var fprintf = require('extsprintf').fprintf;
+var fprintf = extsprintf.fprintf;
+
+var alarms = require('./alarms');
 var common = require('../lib/common');
 var deploy = require('../lib/deploy');
 var layout = require('./layout');
 var svcs = require('./services');
+var instance_info = require('./instance_info');
+
+/* Public interface (used only inside this module) */
+exports.columnNames = columnNames;
+exports.alarmColumnNames = alarmColumnNames;
+exports.cnColumnNames = cnColumnNames;
+exports.probeGroupColumnNames = probeGroupColumnNames;
+exports.zkColumnNames = zkColumnNames;
+exports.MantaAdm = maAdm;
 
 var maMaxConcurrency = 50; /* concurrent requests to SDC services */
 
@@ -36,11 +50,11 @@ var maMaxConcurrency = 50; /* concurrent requests to SDC services */
  */
 var maZkConfigProp = process.env['ZK_SERVERS_PROPNAME'] || 'ZK_SERVERS';
 
-/* Public interface (used only inside this module) */
-exports.columnNames = columnNames;
-exports.cnColumnNames = cnColumnNames;
-exports.zkColumnNames = zkColumnNames;
-exports.MantaAdm = maAdm;
+/*
+ * Path to default alarm metadata.
+ */
+var maAlarmMetadataDirectory =
+    path.join(__dirname, '..', 'alarm_metadata/probe_templates');
 
 /*
  * Available output columns for the list of zones.
@@ -63,7 +77,7 @@ var maColumns = {
 	'width': 16
     },
     'shard': {
-    	'label': 'SH',
+	'label': 'SH',
 	'width': 2,
 	'align': 'right'
     },
@@ -76,7 +90,7 @@ var maColumns = {
 	'width': 36
     },
     'zoneabbr': {
-    	'label': 'ZONEABBR',
+	'label': 'ZONEABBR',
 	'width': 8
     },
 
@@ -95,7 +109,7 @@ var maColumns = {
 	'align': 'right'
     },
     'indent': {
-    	'label': '',
+	'label': '',
 	'width': 4
     },
     'version': {
@@ -111,6 +125,95 @@ function columnNames()
 	}));
 }
 
+var maAlarmColumns = {
+    'alarm': {
+	'label': 'ALARM',
+	'width': 6
+    },
+    'dateopened': {
+	'label': 'DATE_OPENED',
+	'width': 10
+    },
+    'timeopened': {
+	'label': 'TIME_OPENED',
+	'width': 24
+    },
+    'dateclosed': {
+	'label': 'DATE_CLOSED',
+	'width': 10
+    },
+    'timeclosed': {
+	'label': 'TIME_CLOSED',
+	'width': 24
+    },
+    'datelast': {
+	'label': 'DATE_LAST',
+	'width': 10
+    },
+    'timelast': {
+	'label': 'TIME_LAST',
+	'width': 24
+    },
+    'nevents': {
+	'label': 'NEVENTS',
+	'width': 5,
+	'align': 'right'
+    },
+    'nflts': {
+	'label': 'NFLTS',
+	'width': 5,
+	'align': 'right'
+    },
+    'notify': {
+	'label': 'NFY',
+	'width': 3
+    },
+    'summary': {
+	'label': 'SUMMARY',
+	'width': 30
+    }
+};
+
+function alarmColumnNames()
+{
+	return (Object.keys(maAlarmColumns));
+}
+
+var maProbeGroupColumns = {
+    'uuid': {
+	'label': 'UUID',
+	'width': 36
+    },
+    'name': {
+	'label': 'NAME',
+	'width': 20
+    },
+    'contacts': {
+	'label': 'CONTACTS',
+	'width': 15
+    },
+    'enabled': {
+	'label': 'ENAB',
+	'width': 4,
+	'align': 'right'
+    },
+    'nalarms': {
+	'label': 'NALARMS',
+	'width': 7,
+	'align': 'right'
+    },
+    'nprobes': {
+	'label': 'NPROBES',
+	'width': 7,
+	'align': 'right'
+    }
+};
+
+function probeGroupColumnNames()
+{
+	return (Object.keys(maProbeGroupColumns));
+}
+
 var maCnColumns = {
     'server_uuid': {
 	'label': 'SERVER UUID',
@@ -163,7 +266,7 @@ var maZkColumns = {
 	'width': 10
     },
     'zoneabbr': {
-    	'label': 'ZONEABBR',
+	'label': 'ZONEABBR',
 	'width': 8
     },
     'zonename': {
@@ -208,7 +311,7 @@ function zkColumnNames()
  * it doesn't matter what specific servers they're on.  This is mainly used in
  * development and testing.
  *
- * There are four supported use cases:
+ * There are several supported use cases:
  *
  *     o "genconfig" operation: call loadSdcConfig, then fetchDeployed, then
  *       one of dumpConfigCoal, dumpConfigLab, or genconfigFromFile.
@@ -224,6 +327,10 @@ function zkColumnNames()
  *       fetchDeployed, then some combination of dumpZkServers and
  *       fixupZkServers.
  *
+ *     o alarm configuration: call loadSdcConfig, then likely fetchDeployed,
+ *       then alarmsInit with an appropriate set of sources, then any of the
+ *       alarm-related functions.
+ *
  * Any other sequence of operations (skipping any of these, or duplicating those
  * the ones that can't explicitly be called more than once) is invalid.
  */
@@ -267,21 +374,82 @@ function maAdm(log)
 	 */
 	this.ma_instances_flattened = null;
 
+	/*
+	 * General-purpose information about each instance.  See InstanceInfo.
+	 */
+	this.ma_instance_info = null;
+
+	/*
+	 * Mapping of SAPI service names to the list of local (same-datacenter)
+	 * instances for this service.
+	 */
+	this.ma_instances_local_bysvcname = null;
+
 	/*
 	 * CNAPI server objects, indexed by server_uuid.
 	 */
 	this.ma_cns = null;
 
 	/*
-	 * VMAPI vm objects, indexed by instance uuid.
+	 * VMAPI vm objects for active VMs, indexed by instance uuid.
 	 */
 	this.ma_vms = null;
 
+	/*
+	 * VMAPI vm objects for destroyed VMs, indexed by instance uuid.  This
+	 * is loaded only when loading alarm probes.
+	 */
+	this.ma_vms_destroyed = null;
+
+	/*
+	 * Set of server uuids hosting destroyed VMs.  This is loaded only when
+	 * loading alarm probes.
+	 */
+	this.ma_cns_abandoned = null;
+
+	/*
+	 * Translation table from VM or CN uuid to the name of the service to
+	 * which this instance belongs.  CNs, this is just "global zone".
+	 * This only contains translations for the current datacenter.
+	 */
+	this.ma_instance_svcname = {};
+
 	/*
 	 * IMGAPI image objects, indexed by image uuid.
 	 */
 	this.ma_images = null;
 
+	/*
+	 * List of alarm sources that we initially collected data from.
+	 */
+	this.ma_alarm_sources = null;
+
+	/*
+	 * Amon alarm set
+	 */
+	this.ma_alarms = null;
+
+	/*
+	 * Deployed Amon configuration
+	 */
+	this.ma_amon_deployed = null;
+
+	/*
+	 * Warning-level issues encountered while loading alarms information.
+	 */
+	this.ma_alarm_warnings = [];
+
+	/*
+	 * Alarm metadata
+	 */
+	this.ma_alarm_metadata = null;
+
+	/*
+	 * Mapping of alarm levels to the Amon contacts to use for probe groups
+	 * at that level.
+	 */
+	this.ma_alarm_levels = {};
+
 	/*
 	 * Information about global zones, indexed by server_uuid.  This is
 	 * where we keep useful properties derived non-trivially from the CNAPI
@@ -456,12 +624,15 @@ maAdm.prototype.fetchDeployed = function (callback)
 		},
 
 		/*
-		 * XXX want a way to fetch all application instances from VMAPI.
-		 * We currently use owner_uuid as a proxy for that, but that's
-		 * not necessarily correct.
+		 * TODO want a way to fetch all application instances from
+		 * VMAPI.  We currently use owner_uuid as a proxy for that, but
+		 * that's not necessarily correct.
 		 */
 		function fetchVmInfo(_, stepcb) {
-			var params = {
+			var params;
+
+			assertplus.string(self.ma_app.owner_uuid);
+			params = {
 			    'state': 'active',
 			    'owner_uuid': self.ma_app.owner_uuid
 			};
@@ -611,6 +782,1079 @@ maAdm.prototype.loadFakeDeployed = function (config)
 	this.loadInstances();
 };
 
+var schemaAlarmConfigLevel = {
+    'type': 'array',
+    'required': true,
+    'items': {
+	'type': 'string'
+    }
+};
+
+var schemaAlarmConfig = {
+    'type': 'object',
+    'properties': {
+	'levels': {
+	    'type': 'object',
+	    'required': true,
+	    'additionalProperties': false,
+	    'properties': {
+		'alert': schemaAlarmConfigLevel,
+		'info': schemaAlarmConfigLevel
+	    }
+	}
+    }
+};
+
+/*
+ * General-purpose function for loading alarm-related data.  There are several
+ * different sources, some of which are expensive to gather, and callers must
+ * specify the data sources they want to load from.  Currently, this function
+ * should only be called once in the lifetime of this object.
+ *
+ * All of the following top-level named arguments are required:
+ *
+ *    concurrency               maximum number of concurrent requests to make
+ *    (number)
+ *
+ *    configFile                sdc-manta configuration file, which is used for
+ *    (string)                  the set of contacts used for alarms
+ *
+ *    sources                   describes which sources to load data from.  This
+ *    (object)                  object may be empty.
+ *
+ *        configBasic           load probe group information, necessary for
+ *        (boolean)             summarizing basic configuration
+ *
+ *        configFull            load probe information, necessary for actually
+ *        (boolean)             verifying or updating configuration.  This
+ *                              implicitly pulls in "configBasic" as well.
+ *
+ *        alarms                load alarm information.  Exactly one of "state"
+ *        (object)              or "alarmIds" must be specified.
+ *
+ *            state             fetch all alarms in state "state"
+ *            (string)
+ *
+ *            alarmIds          fetch the specified alarm ids
+ *            (array of string)
+ *
+ * In all cases, even if "sources" is empty, local metadata related to alarms is
+ * loaded.
+ *
+ * Callers should invoke alarmWarnings() after calling this to see if there were
+ * any non-fatal issues associated with loading alarms.  Operators should
+ * generally be notified about these issues (as warning-level messages).
+ */
+maAdm.prototype.alarmsInit = function (args, callback)
+{
+	var self = this;
+	var account, configfile, concurrency, funcs, components;
+	var alarmstate = null, alarmIds = null;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args, 'args.sources');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.string(args.configFile, 'args.configFile');
+	assertplus.func(callback, 'callback');
+	assertplus.strictEqual(this.ma_alarms, null);
+	assertplus.strictEqual(this.ma_amon_deployed, null);
+	assertplus.strictEqual(this.ma_alarm_metadata, null);
+
+	assertplus.optionalBool(args.sources.configBasic);
+	assertplus.optionalBool(args.sources.configFull);
+	assertplus.optionalObject(args.sources.alarms);
+	if (args.sources.alarms) {
+		assertplus.optionalString(args.sources.alarms.state);
+		if (typeof (args.sources.alarms.state) == 'string') {
+			if (args.sources.alarms.state != 'open' &&
+			    args.sources.alarms.state != 'all' &&
+			    args.sources.alarms.state != 'recent' &&
+			    args.sources.alarms.state != 'closed') {
+				throw (new VError('unsupported alarm state: ' +
+				    '"%s"', args.sources.alarms.state));
+			}
+
+			assertplus.ok(
+			    !args.sources.alarms.hasOwnProperty('alarmIds'),
+			    'cannot specify "sources.alarms.state" and ' +
+			    '"sources.alarms.alarmIds"');
+			alarmstate = args.sources.alarms.state;
+		} else {
+			assertplus.arrayOfString(args.sources.alarms.alarmIds,
+			    'must specify "sources.alarms.state" or ' +
+			    '"sources.alarms.alarmIds');
+			alarmIds = args.sources.alarms.alarmIds;
+		}
+	}
+
+	this.ma_alarm_sources = jsprim.deepCopy(args.sources);
+	configfile = args.configFile;
+	concurrency = args.concurrency;
+	funcs = [];
+
+	/*
+	 * We always want to load the configuration file.
+	 */
+	funcs.push(function loadConfigFile(_, stepcb) {
+		fs.readFile(configfile, function onFileRead(err, contents) {
+			var conf;
+
+			if (err) {
+				err = new VError(err, 'read "%s"', configfile);
+				stepcb(err);
+				return;
+			}
+
+			try {
+				conf = JSON.parse(contents.toString('utf8'));
+			} catch (ex) {
+				err = new VError(ex, 'parse "%s"', configfile);
+				stepcb(err);
+				return;
+			}
+
+			err = jsprim.validateJsonObject(
+			    schemaAlarmConfig, conf);
+			if (err !== null) {
+				stepcb(new VError(
+				    err, 'config "%s"', configfile));
+				return;
+			}
+
+			self.ma_alarm_levels['minor'] = conf.levels.info;
+			self.ma_alarm_levels['major'] = conf.levels.alert;
+			self.ma_alarm_levels['critical'] = conf.levels.alert;
+			stepcb();
+		});
+	});
+
+	/*
+	 * We always want to load metadata.
+	 */
+	funcs.push(function loadMetadata(_, stepcb) {
+		alarms.loadMetadata({
+		    'directory': maAlarmMetadataDirectory
+		}, function onAlarmMetadataLoaded(err, metadata) {
+			if (!err) {
+				self.ma_alarm_metadata = metadata;
+			}
+
+			stepcb(err);
+		});
+	});
+
+	/*
+	 * If the user asked for "configBasic" or "configFull", then we need the
+	 * list of probe groups.
+	 */
+	if (args.sources.configBasic || args.sources.configFull) {
+		assert.ok(this.ma_instances !== null,
+		    'must load deployed first');
+		account = this.ma_app.owner_uuid;
+		funcs.push(function fetchProbeGroups(_, stepcb) {
+			alarms.amonLoadProbeGroups({
+			    'amon': self.ma_sdc.AMON,
+			    'account': account
+			}, function (err, amonconfig) {
+				/*
+				 * This function can emit both an error and a
+				 * result.  In that case, the error represents
+				 * non-fatal (warning-level) issues associated
+				 * with the operation.
+				 */
+				if (amonconfig) {
+					self.ma_amon_deployed = amonconfig;
+				}
+
+				if (err) {
+					VError.errorForEach(err,
+					    function (e) {
+						self.ma_alarm_warnings.push(e);
+					    });
+				}
+
+				stepcb();
+			});
+		});
+	}
+
+	/*
+	 * If the user asked for "configFull", then we additionally need the
+	 * list of probes.  In order to gather a complete list of those, we need
+	 * to also list all of the VMs (and associated CNs) that have been
+	 * destroyed.  This is deeply unfortunate, since it means that this
+	 * operation will take time proportional to the total number of poseidon
+	 * VMs ever deployed.  But in the absence of pagination from the Amon
+	 * APIs, this is the only way we can identify the case of probes
+	 * deployed for zones that no longer exist.
+	 */
+	if (args.sources.configFull) {
+		var havecns = {};
+
+		components = Object.keys(this.ma_vms).map(function (vmuuid) {
+			return ({ 'type': 'vm', 'uuid': vmuuid });
+		}).concat(Object.keys(this.ma_cns).map(function (cnuuid) {
+			havecns[cnuuid] = true;
+			return ({ 'type': 'cn', 'uuid': cnuuid });
+		}));
+
+		funcs.push(function fetchDestroyedVms(_, stepcb) {
+			var params;
+
+			assertplus.string(self.ma_app.owner_uuid);
+			params = {
+			    'state': 'destroyed',
+			    'owner_uuid': self.ma_app.owner_uuid
+			};
+			self.ma_sdc.VMAPI.listVms(params, function (err, uvms) {
+				if (err) {
+					stepcb(new VError(err,
+					    'listing destroyed VMs'));
+					return;
+				}
+
+				uvms = uvms.filter(function (vm) {
+					return (vm.tags.hasOwnProperty(
+					    'manta_role'));
+				});
+
+				assertplus.strictEqual(self.ma_vms_destroyed,
+				    null);
+				self.ma_vms_destroyed = {};
+				assertplus.strictEqual(self.ma_cns_abandoned,
+				    null);
+				self.ma_cns_abandoned = {};
+				uvms.forEach(function (vm) {
+					self.ma_vms_destroyed[vm.uuid] = vm;
+					components.push({
+					    'type': 'vm',
+					    'uuid': vm.uuid
+					});
+
+					if (typeof (vm.server_uuid) ==
+					    'string' && !havecns.hasOwnProperty(
+					    vm.server_uuid)) {
+						self.ma_cns_abandoned[
+						    vm.server_uuid] = true;
+						havecns[vm.server_uuid] = true;
+						components.push({
+						    'type': 'cn',
+						    'uuid': vm.server_uuid
+						});
+					}
+				});
+
+				stepcb();
+			});
+		});
+
+		funcs.push(function fetchProbes(_, stepcb) {
+			assertplus.notStrictEqual(self.ma_amon_deployed, null);
+
+			/*
+			 * This function inserts the probe information into
+			 * self.ma_amon_deployed, so we don't need to do
+			 * anything when it completes.
+			 */
+			alarms.amonLoadComponentProbes({
+			    'amonRaw': self.ma_sdc.AMON_RAW,
+			    'amoncfg': self.ma_amon_deployed,
+			    'concurrency': concurrency,
+			    'components': components
+			}, function (err, warnings) {
+				if (warnings) {
+					VError.errorForEach(warnings,
+					    function (e) {
+						self.ma_alarm_warnings.push(e);
+					    });
+				}
+
+				stepcb(err);
+			});
+		});
+	}
+
+	/*
+	 * Finally, if the user asked for alarms, then fetch them as requested.
+	 */
+	if (alarmstate !== null) {
+		assert.ok(this.ma_instances !== null,
+		    'must load deployed first');
+		account = this.ma_app.owner_uuid;
+		funcs.push(function fetchAlarms(_, stepcb) {
+			alarms.amonLoadAlarmsForState({
+			    'amon': self.ma_sdc.AMON,
+			    'account': account,
+			    'state': alarmstate
+			}, function (err, alarmset) {
+				if (!alarmset) {
+					stepcb(err);
+					return;
+				}
+
+				self.ma_alarms = alarmset;
+				if (err) {
+					VError.errorForEach(err, function (e) {
+						self.ma_alarm_warnings.push(e);
+					});
+				}
+				stepcb();
+			});
+		});
+	} else if (alarmIds !== null) {
+		assert.ok(this.ma_instances !== null,
+		    'must load deployed first');
+		account = this.ma_app.owner_uuid;
+		funcs.push(function fetchAlarmIds(_, stepcb) {
+			alarms.amonLoadAlarmsForIds({
+			    'amon': self.ma_sdc.AMON,
+			    'account': account,
+			    'alarmIds': alarmIds,
+			    'concurrency': concurrency
+			}, function (err, alarmset) {
+				/*
+				 * This function can return warnings (in "err")
+				 * as well as a list of alarms.
+				 */
+				assertplus.strictEqual(self.ma_alarms, null);
+				self.ma_alarms = alarmset;
+				if (err) {
+					VError.errorForEach(err, function (e) {
+						self.ma_alarm_warnings.push(e);
+					});
+				}
+				stepcb();
+			});
+		});
+	}
+
+	vasync.pipeline({
+	    'funcs': funcs
+	}, function (err) {
+		callback(err);
+	});
+};
+
+maAdm.prototype.alarmWarnings = function ()
+{
+	return (this.ma_alarm_warnings);
+};
+
+/*
+ * Show information about fetched alarms.  This is intended to summarize each
+ * alarm in a multi-line form suitable for people (not programs).
+ */
+maAdm.prototype.alarmsShow = function (args)
+{
+	var self = this;
+	var out;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+	assertplus.notStrictEqual(this.ma_alarms, null,
+	    'must call alarmsInit() with "alarms" source first');
+
+	out = args.stream;
+	this.ma_alarms.eachAlarm(function (id, alarm) {
+		var details;
+		details = self.alarmDetails(alarm);
+		fprintf(out, 'ALARM %-6d  %-8s  %s\n', alarm.a_id,
+		    details.ka !== null ?
+		    details.ka.ka_severity.toUpperCase() : 'UNKNOWN',
+		    details.summary);
+		fprintf(out, '    %d event%s (last: %s)\n',
+		    alarm.a_nevents,
+		    alarm.a_nevents == 1 ? ' ' : 's',
+		    alarm.a_time_last.toISOString());
+		fprintf(out, '    affects services: %s\n',
+		    details.affects.join(', '));
+		if (alarm.a_suppressed) {
+			fprintf(out, '    NOTE: notifications are disabled ' +
+			    'for this alarm\n');
+		}
+		alarm.a_faults.forEach(function (f) {
+			var faultSummary = self.faultSummary(f);
+			if (faultSummary.messageSummary !== null) {
+				fprintf(out, '    message: %s\n',
+				    JSON.stringify(
+				    faultSummary.messageSummary));
+			}
+		});
+		fprintf(out, '\n');
+	});
+};
+
+/*
+ * List open alarms.  This is a tabular summary of alarms, one alarm per line,
+ * with selectable columns.  This may be used by people or by programs.
+ */
+maAdm.prototype.alarmsList = function (args)
+{
+	var self = this;
+	var rows;
+	var nnoprobegroup = 0;
+	var nbadprobegroup = 0;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.optionalArrayOfString(args.columns, 'args.columns');
+	assertplus.bool(args.omitHeader, 'args.omitHeader');
+
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+	assertplus.notStrictEqual(this.ma_alarms, null,
+	    'must call alarmsInit() with "alarms" source first');
+	rows = [];
+	this.ma_alarms.eachAlarm(function (id, alarm) {
+		var details;
+
+		details = self.alarmDetails(alarm);
+		if (details.nogroup) {
+			nnoprobegroup++;
+		}
+		if (details.badgroup) {
+			nbadprobegroup++;
+		}
+
+		rows.push({
+		    'ALARM': id,
+		    'DATE_OPENED': fmtDateOnly(alarm.a_time_opened),
+		    'TIME_OPENED': fmtListDateTime(alarm.a_time_opened),
+		    'DATE_CLOSED': fmtDateOnly(alarm.a_time_closed),
+		    'TIME_CLOSED': fmtListDateTime(alarm.a_time_closed),
+		    'DATE_LAST': fmtDateOnly(alarm.a_time_last),
+		    'TIME_LAST': fmtListDateTime(alarm.a_time_last),
+		    'NFLTS': alarm.a_faults.length,
+		    'NEVENTS': alarm.a_nevents,
+		    'NFY': alarm.a_suppressed ? 'no' : 'yes',
+		    'SUMMARY': details.summary
+		});
+	});
+
+	this.doList({
+	    'stream': args.stream,
+	    'columnsSelected': args.columns,
+	    'columnsDefault': [ 'alarm', 'dateLast', 'nflts', 'summary' ],
+	    'columnMetadata': maAlarmColumns,
+	    'rows': rows,
+	    'omitHeader': args.omitHeader
+	});
+
+	if (nnoprobegroup) {
+		console.error('note: %d alarm%s %s not associated with ' +
+		    'probe groups', nnoprobegroup,
+		    nnoprobegroup == 1 ? '' : 's',
+		    nnoprobegroup == 1 ? 'was' : 'were');
+	}
+
+	if (nbadprobegroup) {
+		console.error('note: %d alarm%s %s associated with ' +
+		    'non-existent probe groups', nbadprobegroup,
+		    nbadprobegroup == 1 ? '' : 's',
+		    nbadprobegroup == 1 ? 'was' : 'were');
+	}
+};
+
+/*
+ * Prints a tabular summary of configured probe groups.
+ */
+maAdm.prototype.alarmsProbeGroupsList = function (args)
+{
+	var self = this;
+	var nalarmsByGroup, rows;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.optionalArrayOfString(args.columns, 'args.columns');
+	assertplus.bool(args.omitHeader, 'args.omitHeader');
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+	assertplus.notStrictEqual(this.ma_alarms, null,
+	    'must call alarmsInit() with "alarms" source first');
+
+	/*
+	 * First, count the alarms for each probe group.
+	 */
+	nalarmsByGroup = {};
+	this.ma_alarms.eachAlarm(function (id, aa) {
+		if (aa.a_groupid === null) {
+			return;
+		}
+
+		assertplus.string(aa.a_groupid);
+		if (!nalarmsByGroup.hasOwnProperty(aa.a_groupid)) {
+			nalarmsByGroup[aa.a_groupid] = 0;
+		}
+
+		nalarmsByGroup[aa.a_groupid]++;
+	});
+
+	/*
+	 * Construct an output row for each probe group.
+	 */
+	rows = [];
+	this.ma_amon_deployed.eachProbeGroup(function (pg) {
+		var row, nprobes, nalarms;
+
+		nprobes = 0;
+		self.ma_amon_deployed.eachProbeGroupProbe(pg.pg_name,
+		    function () { nprobes++; });
+
+		nalarms = nalarmsByGroup.hasOwnProperty(pg.pg_uuid) ?
+		    nalarmsByGroup[pg.pg_uuid] : 0;
+
+		row = {
+		    'NAME': pg.pg_name,
+		    'UUID': pg.pg_uuid,
+		    'CONTACTS': pg.pg_contacts.join(','),
+		    'NPROBES': nprobes,
+		    'NALARMS': nalarms,
+		    'ENAB': pg.pg_enabled ? 'yes' : 'no'
+		};
+
+		rows.push(row);
+	});
+
+	this.doList({
+	    'stream': args.stream,
+	    'columnsSelected': args.columns,
+	    'columnsDefault': [ 'uuid', 'name' ],
+	    'columnMetadata': maProbeGroupColumns,
+	    'rows': rows,
+	    'omitHeader': args.omitHeader
+	});
+};
+
+/*
+ * Close a list of alarms, each identified by id.  Invalid alarm ids are
+ * operational errors here (resulting in warnings).
+ */
+maAdm.prototype.alarmsClose = function (args, callback)
+{
+	assertplus.object(args, 'args');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+
+	alarms.amonCloseAlarms({
+	    'amon': this.ma_sdc.AMON,
+	    'account': this.ma_app.owner_uuid,
+	    'alarmIds': args.alarmIds,
+	    'concurrency': args.concurrency
+	}, callback);
+};
+
+/*
+ * Enable or disable notifications for a list of alarms, each identified by id.
+ * Invalid alarm ids are operational errors here (resulting in warnings).
+ */
+maAdm.prototype.alarmsUpdateNotification = function (args, callback)
+{
+	assertplus.object(args, 'args');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.bool(args.suppressed, 'args.suppressed');
+
+	alarms.amonUpdateAlarmsNotification({
+	    'amonRaw': this.ma_sdc.AMON_RAW,
+	    'account': this.ma_app.owner_uuid,
+	    'alarmIds': args.alarmIds,
+	    'concurrency': args.concurrency,
+	    'suppressed': args.suppressed
+	}, callback);
+};
+
+/*
+ * Fetch a structure summarizing information about a specific alarm.  The
+ * structure has properties:
+ *
+ *     badgroup         indicates that the associated probe group is missing
+ *     (boolean)
+ *
+ *     nogroup          indicates that there is no probe group for this alarm
+ *     (boolean)
+ *
+ *     affects          array of service names whose instances have faults
+ *                      associated with this alarm.
+ *
+ *     summary          one-line string summary of the alarm.  We prefer
+ *                      information provided in the associated knowledge
+ *                      article, if there is one.  Otherwise, we use the probe
+ *                      group name if we have one.  Otherwise, we generate a
+ *                      summary from a fault associated with the alarm.
+ */
+maAdm.prototype.alarmDetails = function (alarm)
+{
+	var self = this;
+	var rv, pgid, pgname, eventName;
+	var deployed, metadata, svcnames;
+
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+	deployed = this.ma_amon_deployed;
+	metadata = this.ma_alarm_metadata;
+	pgid = alarm.a_groupid;
+	rv = {
+	    'badgroup': false,
+	    'nogroup': false,
+	    'affects': null,
+	    'summary': null,
+	    'ka': null
+	};
+
+	/*
+	 * Figure out the most specific summary message we can provide given the
+	 * local metadata and probe group information.
+	 */
+	if (pgid !== null) {
+		pgname = deployed.probeGroupNameForUuid(pgid);
+		if (pgname !== null) {
+			eventName = metadata.probeGroupEventName(
+			    pgname);
+			if (rv.eventName !== null) {
+				rv.ka = metadata.eventKa(eventName);
+				if (rv.ka !== null) {
+					rv.summary = rv.ka.ka_title;
+				} else {
+					rv.summary = eventName;
+				}
+			} else {
+				rv.summary = pgname;
+			}
+		} else {
+			rv.badgroup = true;
+		}
+	} else {
+		rv.nogroup = true;
+	}
+
+	if (rv.summary === null) {
+		/*
+		 * Open alarms should have at least one fault, and closed alarms
+		 * should have none.  This is verified on the way in from Amon.
+		 */
+		if (alarm.a_faults.length > 0) {
+			rv.summary = alarm.a_faults[0].aflt_summary;
+		} else {
+			assertplus.ok(alarm.a_closed);
+			rv.summary = '(closed alarm has no faults)';
+		}
+	}
+
+	/*
+	 * Determine the affected services by looking at all of the faults.
+	 */
+	svcnames = {};
+	alarm.a_faults.forEach(function (f) {
+		svcnames[
+		    self.ma_instance_svcname.hasOwnProperty(f.aflt_agent) ?
+		    self.ma_instance_svcname[f.aflt_agent] :
+		    'unknown'] = true;
+	});
+
+	if (alarm.a_faults.length === 0) {
+		svcnames['none (alarm is closed)'] = true;
+	}
+
+	rv.affects = Object.keys(svcnames);
+
+	return (rv);
+};
+
+/*
+ * Returns a structure summarizing a specific fault.  The returned object has
+ * properties:
+ *
+ *    kind	      one of "cmd", "log-scan", "bunyan-log-scan", or "unknown"
+ *                    describing the kind of probe that generated this fault
+ *                    (see below)
+ *
+ *    messageSummary  for the log-scan types, this is the shortest reasonable
+ *                    summary of the log message that generated the fault
+ *
+ *    messageWhole    for one of the log-scan types, this is the entire contents
+ *                    of the message that generated the fault
+ *
+ * Manta uses four different types of probes:
+ *
+ *   - "bunyan-log-scan" (scans a file for messages at a specified level)
+ *   - "cmd" (runs a command periodically)
+ *   - "disk-usage (checks disk space used)
+ *   - "log-scan" (scans a file for a pattern)
+ *
+ * We can encounter faults for any of these types of probe, and we want to print
+ * each one differently.  We could reliably tell which type we're looking at by
+ * looking up the probe, but it's expensive to fetch information about all
+ * probes, so we don't typically do it just to show alarm details.  Instead, we
+ * use heuristics about the information provided in the fault to guess what kind
+ * we're looking at.  This function abstracts that behavior.
+ */
+maAdm.prototype.faultSummary = function (fault)
+{
+	var fltdetail, rv;
+
+	rv = {
+	    'kind': 'unknown',
+	    'messageSummary': null,
+	    'messageWhole': null
+	};
+
+	fltdetail = fault.aflt_data.details;
+	if (!fltdetail) {
+		return (rv);
+	}
+
+	if (typeof (fltdetail.cmd) == 'string' &&
+	    fltdetail.hasOwnProperty('stdout') &&
+	    fltdetail.hasOwnProperty('stderr')) {
+		/* This is a "cmd" probe. */
+		rv.kind = 'cmd';
+	} else if (Array.isArray(fltdetail.matches) &&
+	    fltdetail.matches.length > 0) {
+		if (typeof (fltdetail.matches[0].context) == 'string') {
+			/*
+			 * This is a "log-scan" probe, and the "context" field
+			 * indicates the line that matched.
+			 */
+			rv.kind = 'log-scan';
+			rv.messageWhole = fltdetail.matches[0].context;
+			rv.messageSummary = rv.messageWhole;
+		} else if (typeof (fltdetail.matches[0].match) == 'object') {
+			/*
+			 * This is a "bunyan-log-scan" probe, and the "match"
+			 * field indicates the entire bunyan record that
+			 * matched.  Note that "log-scan" probes also have a
+			 * "match" field, and it means something else, so it's
+			 * important that we checked for this after checking for
+			 * "context" above.
+			 */
+			rv.kind = 'bunyan-log-scan';
+			rv.messageSummary = fltdetail.matches[0].match.msg;
+			rv.messageWhole = JSON.stringify(
+			    fltdetail.matches[0].match, null, '    ');
+		}
+	}
+
+	return (rv);
+};
+
+/*
+ * Prints detailed information about a specific alarm that has already been
+ * loaded, identified by id.  If the alarm has not been loaded, an error is
+ * returned.
+ */
+maAdm.prototype.alarmPrint = function alarmPrint(args)
+{
+	var alarm, out, i, nmax;
+	var details, fault, fltdetail, fltsum, formatted;
+	var now = Date.now();
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.id, 'args.id');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.optionalNumber(args.nmaxfaults, 'args.nmaxfaults');
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+
+	out = args.stream;
+	alarm = this.ma_alarms.alarmForId(args.id);
+	if (alarm === null) {
+		return (new VError('no such alarm: "%s"', args.id));
+	}
+
+	details = this.alarmDetails(alarm);
+	if (details.ka !== null) {
+		this.doKaPrint({
+		    'header': 'ALARM ' + args.id,
+		    'stream': out,
+		    'ka': details.ka
+		});
+		fprintf(out, '\n');
+	} else {
+		fprintf(out, 'ALARM %s\n', alarm.a_id);
+	}
+
+	fprintf(out, 'summary:         %s\n', details.summary);
+	fprintf(out, 'state:           %s\n', alarm.a_closed ?
+	    'closed': 'open');
+	fprintf(out, 'opened:          %s (%s ago)\n',
+	    alarm.a_time_opened.toISOString(),
+	    fmtDuration(now - alarm.a_time_opened.getTime()));
+	fprintf(out, 'last event:      %s (%s ago)\n',
+	    alarm.a_time_last.toISOString(),
+	    fmtDuration(now - alarm.a_time_last.getTime()));
+	if (alarm.a_time_closed === null) {
+		fprintf(out, 'closed:          never\n');
+	} else {
+		fprintf(out, 'closed:          %s (%s ago)\n',
+		    alarm.a_time_closed.toISOString(),
+		    fmtDuration(now - alarm.a_time_closed.getTime()));
+	}
+	fprintf(out, 'notifications:   %s\n', alarm.a_suppressed ?
+	    'disabled' : 'enabled');
+	fprintf(out, 'total faults:    %s\n', alarm.a_faults.length);
+	fprintf(out, 'total events:    %s\n', alarm.a_nevents);
+	fprintf(out, 'affects zones:   %s\n', details.affects.join(', '));
+
+	if (alarm.a_faults.length === 0) {
+		return (null);
+	}
+
+	if (typeof (args.nmaxfaults) == 'number') {
+		nmax = Math.min(alarm.a_faults.length, args.nmaxfaults);
+	} else {
+		nmax = alarm.a_faults.length;
+	}
+
+	for (i = 0; i < nmax; i++) {
+		fprintf(out, '\n    FAULT %d of %d FOR ALARM %d\n',
+		    i + 1, alarm.a_faults.length, alarm.a_id);
+		fault = alarm.a_faults[i];
+		fprintf(out, '    reason:          %s\n', fault.aflt_summary);
+		fprintf(out, '    time:            %s (%s ago)\n',
+		    fault.aflt_time.toISOString(),
+		    fmtDuration(now - fault.aflt_time.getTime()));
+		fprintf(out, '    machine:         %s\n', fault.aflt_machine);
+		fprintf(out, '    agent:           %s\n', fault.aflt_agent);
+		fprintf(out, '    agent alias:     %s\n',
+		    fault.aflt_agent_alias);
+
+		/*
+		 * It's not expected that we would ever see a fault with "clear"
+		 * set to true.  If Amon received that, it would have closed the
+		 * fault and removed it from the list of faults.
+		 */
+		if (fault.aflt_clear) {
+			fprintf(out, '    warn: fault event has "clear" set\n');
+		}
+
+		fltsum = this.faultSummary(fault);
+		if (fltsum.kind != 'cmd' &&
+		    fltsum.kind != 'log-scan' &&
+		    fltsum.kind != 'bunyan-log-scan') {
+			continue;
+		}
+
+		fltdetail = fault.aflt_data.details;
+		if (fltsum.kind == 'cmd') {
+			/* This is a "cmd" probe. */
+			fprintf(out, '    cmd exit status: %s\n',
+			    (fltdetail.exitStatus ||
+			    fltdetail.exitStatus === 0) ?
+			    fltdetail.exitStatus : 'none');
+			fprintf(out, '    cmd signal:      %s\n',
+			    fltdetail.signal ? fltdetail.signal : 'none');
+			fprintf(out, '    probe cmd:       %s\n',
+			    JSON.stringify(fltdetail.cmd));
+
+			fprintf(out, '%s', formatCmdOutput(
+			    '    ', 'stdout', fltdetail.stdout));
+			fprintf(out, '%s', formatCmdOutput(
+			    '    ', 'stderr', fltdetail.stderr));
+		} else if (fltsum.kind == 'log-scan') {
+			/* This is a "log-scan" probe. */
+			fprintf(out, '    first matching message:\n');
+			fprintf(out, '    ------------\n');
+			fprintf(out, '    %s\n',
+			    JSON.stringify(fltsum.messageWhole));
+			fprintf(out, '    ------------\n');
+		} else if (fltsum.kind == 'bunyan-log-scan') {
+			/* This is a "bunyan-log-scan" probe. */
+			formatted = prependLines(fltsum.messageWhole, '    ');
+			fprintf(out, '    first matching message:\n');
+			fprintf(out, '    ------------\n');
+			fprintf(out, '%s\n', formatted);
+			fprintf(out, '    ------------\n');
+		}
+
+		/*
+		 * The only other type of probe currently in use is the
+		 * disk-usage probe, and it has no additional information than
+		 * what's in the message that we already printed out.
+		 */
+	}
+
+	return (null);
+};
+
+/*
+ * Returns an array of all known event names (based on alarm metadata).  Each of
+ * these identifies a specific failure mode for which we create probes.
+ */
+maAdm.prototype.alarmEventNames = function alarmEventNames()
+{
+	assertplus.notStrictEqual(this.ma_alarm_metadata, null,
+	    'must call alarmsInit() first');
+	var rv = [];
+	this.ma_alarm_metadata.eachEvent(function (eventName) {
+		rv.push(eventName);
+	});
+	return (rv);
+};
+
+/*
+ * Prints the contents of a specific knowledge article, identified by its event
+ * name.
+ */
+maAdm.prototype.alarmKaPrint = function alarmKaPrint(args)
+{
+	var ka, eventName;
+
+	assertplus.notStrictEqual(this.ma_alarm_metadata, null,
+	    'must call alarmsInit() first');
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.string(args.eventName, 'args.eventName');
+
+	eventName = args.eventName;
+	ka = this.ma_alarm_metadata.eventKa(eventName);
+	if (ka === null) {
+		return (new VError('no such event: "%s"', eventName));
+	}
+
+	this.doKaPrint({
+	    'stream': args.stream,
+	    'ka': ka
+	});
+};
+
+maAdm.prototype.doKaPrint = function doKaPrint(args)
+{
+	var out, ka, header;
+	var wrapper = wordwrap(4, 80);
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.ka, 'args.ka');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.optionalString(args.header, 'args.header');
+
+	ka = args.ka;
+	out = args.stream;
+	header = args.header ? args.header : 'TITLE';
+	fprintf(out, '%s: %s\n', header, ka.ka_title);
+	fprintf(out, 'SEVERITY: %s\n', ka.ka_severity);
+	fprintf(out, 'DESC:\n%s\n', wrapper(ka.ka_description));
+	fprintf(out, 'IMPACT:\n%s\n', wrapper(ka.ka_impact));
+	fprintf(out, 'AUTOMATED RESPONSE:\n%s\n', wrapper(ka.ka_response));
+	fprintf(out, 'SUGGESTED ACTION:\n%s\n', wrapper(ka.ka_action));
+};
+
+/*
+ * General-purpose function for printing tabular output.
+ */
+maAdm.prototype.doList = function doList(args)
+{
+	var colnames, columns, taboptions, tabstream;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.optionalArrayOfString(
+	    args.columnsSelected, 'args.columnsSelected');
+	assertplus.arrayOfString(args.columnsDefault, 'args.columnsDefault');
+	assertplus.object(args.columnMetadata, 'args.columnMetadata');
+	assertplus.arrayOfObject(args.rows, 'args.rows');
+	assertplus.optionalBool(args.omitHeader, 'args.omitHeader');
+
+	colnames = args.columnsSelected || args.columnsDefault;
+	columns = colnames.map(function (colname) {
+		colname = colname.toLowerCase();
+		assertplus.ok(args.columnMetadata.hasOwnProperty(colname),
+		    'no property "' + colname + '"');
+		return (args.columnMetadata[colname]);
+	});
+	taboptions = {
+	    'stream': args.stream,
+	    'omitHeader': args.omitHeader,
+	    'columns': columns
+	};
+	tabstream = new tab.TableOutputStream(taboptions);
+	args.rows.forEach(function (row) {
+		tabstream.writeRow(row);
+	});
+};
+
+/*
+ * Print a summary about the currently configured probe groups and probes.
+ */
+maAdm.prototype.alarmConfigShow = function (args)
+{
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configBasic" source first');
+	alarms.amonConfigSummarize({
+	    'config': this.ma_amon_deployed,
+	    'metadata': this.ma_alarm_metadata,
+	    'instanceSvcname': this.ma_instance_svcname,
+	    'stream': args.stream
+	});
+};
+
+/*
+ * Create a plan for updating the Amon configuration.
+ */
+maAdm.prototype.amonUpdatePlanCreate = function amonUpdatePlanCreate(options)
+{
+	assertplus.notStrictEqual(this.ma_amon_deployed, null,
+	    'must call alarmsInit() with "configFull" source first');
+	assertplus.object(options, 'args');
+	assertplus.bool(options.unconfigure, 'options.unconfigure');
+
+	return (alarms.amonUpdatePlanCreate({
+	    'account': this.ma_app.owner_uuid,
+	    'contactsBySeverity': this.ma_alarm_levels,
+	    'metadata': this.ma_alarm_metadata,
+	    'instances': this.ma_instance_info,
+	    'instancesBySvc': this.ma_instances_local_bysvcname,
+	    'deployed': this.ma_amon_deployed,
+	    'unconfigure': options.unconfigure
+	}));
+};
+
+/*
+ * Summarize a plan for updating the Amon configuration.
+ */
+maAdm.prototype.amonUpdatePlanDump = function amonUpdatePlanDump(args)
+{
+	assertplus.object(args, 'args');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.bool(args.verbose, 'args.verbose');
+
+	alarms.amonUpdatePlanSummarize({
+	    'stream': args.stream,
+	    'plan': args.plan,
+	    'instances': this.ma_instance_info,
+	    'cns': this.ma_cns,
+	    'metadata': this.ma_alarm_metadata,
+	    'verbose': args.verbose,
+	    'vmsDestroyed': this.ma_vms_destroyed,
+	    'cnsAbandoned': this.ma_cns_abandoned
+	});
+};
+
+/*
+ * Execute a plan for updating the Amon configuration.
+ */
+maAdm.prototype.amonUpdatePlanApply =
+    function amonUpdatePlanApply(args, callback)
+{
+	assertplus.object(args, 'args');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.number(args.concurrency, 'args.concurrency');
+
+	alarms.amonUpdatePlanApply({
+	    'account': this.ma_app.owner_uuid,
+	    'amon': this.ma_sdc.AMON,
+	    'concurrency': args.concurrency,
+	    'stream': args.stream,
+	    'plan': args.plan
+	}, callback);
+};
+
 /*
  * The dumpConfig.* functions dump sample configurations based on common
  * deployments in development and test.
@@ -1254,7 +2498,7 @@ maAdm.prototype.dumpCns = function (sout, conf)
 		    'ADMIN IP': gz['admin_ip'],
 		    'COMPUTE ID': gz['compute_id'] || '-',
 		    'STORAGE IDS': kind == 'storage' ?
-		        gz['storage_ids'].sort().join(',') : '-',
+			gz['storage_ids'].sort().join(',') : '-',
 		    'KIND': kind
 		});
 	});
@@ -1301,7 +2545,7 @@ maAdm.prototype.dumpZkServers = function (sout, conf)
 		    'ZONENAME': instance ? instance.uuid : '-',
 		    'ZONEABBR': instance ? instance.uuid.substr(0, 8) : '-',
 		    'DATACENTER': instance ?
-		        instance.metadata['DATACENTER'] : '-'
+			instance.metadata['DATACENTER'] : '-'
 		});
 	});
 
@@ -1361,6 +2605,8 @@ maAdm.prototype.loadInstances = function ()
 	rv = [];
 	this.ma_config_bycn = {};
 	this.ma_config_bycfg = {};
+	this.ma_instance_info = {};
+	this.ma_instances_local_bysvcname = {};
 
 	for (svcid in this.ma_instances) {
 		svcname = services[svcid]['name'];
@@ -1369,6 +2615,7 @@ maAdm.prototype.loadInstances = function ()
 		this.ma_config_bycfg[svcid] =
 		    new svcs.ServiceConfiguration(svckey);
 		this.ma_config_bycn[svcid] = {};
+		this.ma_instances_local_bysvcname[svcname] = [];
 
 		for (i = 0; i < this.ma_instances[svcid].length; i++) {
 			instance = this.ma_instances[svcid][i];
@@ -1377,6 +2624,10 @@ maAdm.prototype.loadInstances = function ()
 				server = this.ma_vms[instance['uuid']]
 				    ['server_uuid'];
 				gz = this.ma_gzinfo[server];
+				assertplus.ok(!this.ma_instance_svcname.
+				    hasOwnProperty(instance['uuid']));
+				this.ma_instance_svcname[
+				    instance['uuid']] = svcname;
 			} else {
 				server = '-';
 				gz = null;
@@ -1402,7 +2653,7 @@ maAdm.prototype.loadInstances = function ()
 			row = {
 			    'SERVICE': svcname,
 			    'SH': instance['metadata']['SHARD'] ?
-			        instance['metadata']['SHARD'].toString() : '-',
+				instance['metadata']['SHARD'].toString() : '-',
 			    'DATACENTER': metadata['DATACENTER'] || '-',
 			    'ZONENAME': instance['uuid'],
 			    'GZ HOST': gz ? gz['hostname'] : '-',
@@ -1416,6 +2667,21 @@ maAdm.prototype.loadInstances = function ()
 			};
 			rv.push(row);
 
+			this.ma_instance_info[instance['uuid']] =
+			    new instance_info.InstanceInfo({
+				'uuid': instance['uuid'],
+				'svcname': svcname,
+				'metadata': instance['metadata'],
+				'local': gz !== null,
+				'server_uuid': gz !== null ?
+				    server : null
+			    });
+
+			if (gz !== null) {
+				this.ma_instances_local_bysvcname[
+				    svcname].push(instance['uuid']);
+			}
+
 			if (image === '-')
 				continue;
 
@@ -1467,6 +2733,9 @@ maAdm.prototype.loadCns = function ()
 
 			gzinfo[cnid]['admin_ip'] = iface['ip4addr'];
 		}
+
+		assertplus.ok(!this.ma_instance_svcname.hasOwnProperty(cnid));
+		this.ma_instance_svcname[cnid] = 'global zone';
 	}
 
 	if (this.ma_app['metadata']) {
@@ -1940,7 +3209,7 @@ maAdm.prototype.dumpPlan = function ()
 				    'zonename': p['zonename'],
 				    'image': p['IMAGE'] || p['new_image'],
 				    'shard': p['SH'] || p['shard']
-			        });
+				});
 			    }));
 	});
 
@@ -2185,15 +3454,15 @@ maAdm.prototype.close = function ()
  * Each element in the ZK_SERVERS array has these properties:
  *
  *     "num"	Ordinal number of this ZooKeeper instance.  These are
- *      	allocated starting from 1 when an instance is deployed.
- *      	This value is used by _all_ ZooKeeper instances when
- *      	writing out their ZK configuration files.  It must be
- *      	unique within the cluster.  It's unclear from the ZooKeeper
- *      	documentation if it must also be consecutive and start at 1.
+ *		allocated starting from 1 when an instance is deployed.
+ *		This value is used by _all_ ZooKeeper instances when
+ *		writing out their ZK configuration files.  It must be
+ *		unique within the cluster.  It's unclear from the ZooKeeper
+ *		documentation if it must also be consecutive and start at 1.
  *
- *      	This value MUST match the ZK_ID metadata property on the
- *      	corresponding SAPI instance, which is also used in ZK
- *      	configuration.
+ *		This value MUST match the ZK_ID metadata property on the
+ *		corresponding SAPI instance, which is also used in ZK
+ *		configuration.
  *
  *     "host"	IP address of this ZooKeeper instance.
  *
@@ -2203,8 +3472,8 @@ maAdm.prototype.close = function ()
  * other elements must not have this property):
  *
  *     "last"	Indicates that this is the last entry in the list.  This is used
- *     		in templates for JSON configuration files to avoid including a
- *     		trailing comma.
+ *		in templates for JSON configuration files to avoid including a
+ *		trailing comma.
  *
  * Because ZK_SERVERS is used so directly to write out ZooKeeper configuration
  * files, this property value inherits constraints associated with ZooKeeper
@@ -2300,14 +3569,14 @@ maAdm.prototype.fixupZkServers = function (callback)
  * The return value is an object with:
  *
  *     validationErrors		List of Error objects describing serious
- *     				validation errors like those described above.
- *     				There is no support for fixing these
- *     				automatically.
+ *				validation errors like those described above.
+ *				There is no support for fixing these
+ *				automatically.
  *
  *     configuredInstances	List of objects describing the entries in
- *     				ZK_SERVERS, each having:
+ *				ZK_SERVERS, each having:
  *
- *     		instance		SAPI instance metadata
+ *		instance		SAPI instance metadata
  *
  *		zkid			ZK_ID metadata
  *
@@ -2316,12 +3585,12 @@ maAdm.prototype.fixupZkServers = function (callback)
  *		port			PORT (from ZK_SERVERS)
  *
  *     missingInstances		List of indexes into ZK_SERVERS identifying
- *     				elements with no matching SAPI instance.
+ *				elements with no matching SAPI instance.
  *
  *     nforeign			Number of ZK_SERVERS instances for which we have
- *     				no metadata about the corresponding compute
- *     				node.  This usually means that the instance is
- *     				deployed inside another datacenter.
+ *				no metadata about the corresponding compute
+ *				node.  This usually means that the instance is
+ *				deployed inside another datacenter.
  */
 maAdm.prototype.auditZkServers = function ()
 {
@@ -2334,7 +3603,7 @@ maAdm.prototype.auditZkServers = function ()
 	if (!this.ma_app.metadata.hasOwnProperty(maZkConfigProp)) {
 		return ({
 		    'validationErrors': [
-		        new VError('%s not found in metadata', maZkConfigProp)
+			new VError('%s not found in metadata', maZkConfigProp)
 		    ],
 		    'configuredInstances': [],
 		    'missingInstances': [],
@@ -2487,3 +3756,101 @@ maAdm.prototype.auditZkServers = function ()
 
 	return (rv);
 };
+
+function fmtListDateTime(ts)
+{
+	if (ts === null) {
+		return ('-');
+	}
+
+	return (new Date(ts).toISOString());
+}
+
+function fmtDateOnly(ts)
+{
+	if (ts === null) {
+		return ('-');
+	}
+
+	return (new Date(ts).toISOString().substr(0, '2017-02-06'.length));
+}
+
+/*
+ * TODO This implementation is copied from manta-marlin.  It should be moved to
+ * node-jsprim.
+ */
+function fmtDuration(ms)
+{
+	var hour, min, sec, rv;
+
+	/* compute totals in each unit */
+	assertplus.number(ms, 'ms');
+	sec = Math.floor(ms / 1000);
+	min = Math.floor(sec / 60);
+	hour = Math.floor(min / 60);
+
+	/* compute offsets for each unit */
+	ms %= 1000;
+	sec %= 60;
+	min %= 60;
+
+	rv = '';
+	if (hour > 0)
+		rv += hour + 'h';
+
+	if (hour > 0 || min > 0) {
+		if (hour > 0 && min < 10)
+			rv += '0' + min + 'm';
+		else
+			rv += min + 'm';
+	}
+
+	if ((hour > 0 || min > 0) && sec < 10)
+		rv += '0' + sec;
+	else
+		rv += sec;
+
+	rv += 's';
+	return (rv);
+}
+
+function formatCmdOutput(prefix, streamname, str)
+{
+	var trimmed;
+
+	/*
+	 * Don't bother printing empty outputs.
+	 */
+	trimmed = str.trim();
+	if (trimmed.length === 0) {
+		return ('');
+	}
+
+	if (trimmed.indexOf('\n') == -1) {
+		return (extsprintf.sprintf('%s%6s:           %s\n',
+		    prefix, streamname, JSON.stringify(str)));
+	}
+
+	return (extsprintf.sprintf('%s%6s:\n%s\n',
+	    prefix, streamname, prependLines(str, '        | ')));
+}
+
+function prependLines(str, prefix)
+{
+	var lines, i;
+
+	/*
+	 * A simple "map" would be concise and elegant, but wouldn't handle the
+	 * trailing newline case very well.
+	 */
+	lines = str.split('\n');
+	for (i = 0; i < lines.length - 1; i++) {
+		lines[i] = prefix + lines[i];
+	}
+
+	if (lines.length > 0 && lines[lines.length - 1].length > 0) {
+		lines[lines.length - 1] = prefix + lines[lines.length - 1];
+	}
+
+	return (lines.join('\n'));
+}
diff --git a/lib/alarms/alarms.js b/lib/alarms/alarms.js
new file mode 100644
index 0000000..50723a5
--- /dev/null
+++ b/lib/alarms/alarms.js
@@ -0,0 +1,397 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/alarms/alarms.js: facilities for working with amon alarms.
+ */
+
+var assertplus = require('assert-plus');
+var jsprim = require('jsprim');
+var vasync = require('vasync');
+
+var sprintf = require('extsprintf').sprintf;
+var VError = require('verror');
+
+var amon_objects = require('./amon_objects');
+
+/* Exported interface */
+exports.amonLoadAlarmsForState = amonLoadAlarmsForState;
+exports.amonLoadAlarmsForIds = amonLoadAlarmsForIds;
+exports.amonCloseAlarms = amonCloseAlarms;
+exports.amonUpdateAlarmsNotification = amonUpdateAlarmsNotification;
+
+
+/*
+ * Load information about Amon alarms in the specified state.
+ *
+ * Named arguments:
+ *
+ *     account         Triton account uuid whose open alarms to load
+ *
+ *     amon            Amon client (from sdc-clients)
+ *
+ *     state           one of "open", "closed", "all", or "recent"
+ *
+ * The callback is invoked as callback(err, alarmset).  "alarmset" is a
+ * MantaAlarmSet that is provided if any alarms could be loaded.  It may not be
+ * provided if no alarms could be loaded.  "err" describes any issues loading
+ * alarms.  You can have any combination of "err" and "alarmset".
+ */
+function amonLoadAlarmsForState(args, callback)
+{
+	var amon, account, rv, options;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.string(args.state, 'args.state');
+
+	amon = args.amon;
+	account = args.account;
+	rv = new MantaAlarmSet();
+	options = { 'state': args.state };
+
+	amon.listAlarms(account, options, function (err, rawalarms) {
+		var errors;
+
+		if (err) {
+			err = new VError(err, 'listing open alarms');
+			callback(err);
+			return;
+		}
+
+		errors = [];
+		rawalarms.forEach(function (rawalarm) {
+			var alarm;
+
+			alarm = amon_objects.loadAlarmObject(rawalarm);
+			if (alarm instanceof Error) {
+				errors.push(new VError(alarm,
+				    'bad alarm from server'));
+				return;
+			}
+
+			if (rv.hasAlarmWithId(alarm.a_id)) {
+				errors.push(new VError('server reported ' +
+				    'more than one alarm with id %d',
+				    alarm.a_id));
+				return;
+			}
+
+			rv.addAlarm(alarm);
+		});
+
+		err = VError.errorFromList(errors);
+		rv.finalize();
+		callback(err, rv);
+	});
+}
+
+/*
+ * Iterate the specified "alarmIds" and invoke "func" for each one.
+ *
+ * External to this file, we avoid assuming that alarm ids are positive
+ * integers.  That's an amon-ism.  But the Amon client library does assume that,
+ * so here's where we have to validate it.  This function also manages a queue
+ * of the requested concurrency.
+ */
+function amonAlarmForEach(args, callback)
+{
+	var errors, queue, func;
+
+	assertplus.object(args, 'args');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.func(args.func, 'args.func');
+
+	errors = [];
+	func = args.func;
+	queue = vasync.queuev({
+	    'concurrency': args.concurrency,
+	    'worker': function iterAlarm(alarmid, qcallback) {
+		var num;
+
+		num = jsprim.parseInteger(alarmid);
+		if (typeof (num) == 'number' && num < 1) {
+			num = VError('not a positive integer');
+		}
+
+		if (num instanceof Error) {
+			errors.push(new VError(num, 'alarm "%s"', alarmid));
+			qcallback();
+			return;
+		}
+
+		func(num, function onFuncDone(err) {
+			if (err) {
+				errors.push(err);
+			}
+
+			qcallback();
+		});
+	    }
+	});
+
+	args.alarmIds.forEach(function (a) { queue.push(a); });
+	queue.on('end', function () {
+		callback(VError.errorFromList(errors));
+	});
+
+	queue.close();
+}
+
+/*
+ * Closes the specified open alarms.
+ *
+ * Named arguments:
+ *
+ *     account         Triton account uuid whose open alarms to load
+ *
+ *     amon            Amon client (from sdc-clients)
+ *
+ *     alarmIds	       array of alarm ids to close
+ *
+ *     concurrency     maximum request concurrency
+ *
+ * This is an array-based interface in order to better support parallelizing
+ * operations.  This could also expose an object-mode stream interface.
+ */
+function amonCloseAlarms(args, callback)
+{
+	var account, amon;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+
+	account = args.account;
+	amon = args.amon;
+	amonAlarmForEach({
+	    'alarmIds': args.alarmIds,
+	    'concurrency': args.concurrency,
+	    'func': function amonCloseOne(alarmid, subcallback) {
+		assertplus.number(alarmid);
+		amon.closeAlarm(account, alarmid, function onAmonClose(err) {
+			if (err) {
+				err = new VError(err,
+				    'close alarm "%d"', alarmid);
+			}
+
+			subcallback(err);
+		});
+	    }
+	}, callback);
+}
+
+
+/*
+ * Updates the "suppressed" property on the specified alarms.
+ *
+ * Named arguments:
+ *
+ *     account         Triton account uuid whose open alarms to load
+ *
+ *     amonRaw         a restify JSON client for the AMON master API.
+ *                     This is different from most other consumers, which use an
+ *                     actual Amon client.
+ *
+ *     alarmIds        array of alarm ids to close
+ *
+ *     concurrency     maximum request concurrency
+ *
+ *     suppressed      new value for the "suppressed" property
+ *
+ * This is an array-based interface in order to better support parallelizing
+ * operations.  This could also expose an object-mode stream interface.
+ */
+function amonUpdateAlarmsNotification(args, callback)
+{
+	var account, amon, suppressed;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.amonRaw, 'args.amonRaw');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.bool(args.suppressed, 'args.suppressed');
+
+	account = args.account;
+	amon = args.amonRaw;
+	suppressed = args.suppressed;
+
+	amonAlarmForEach({
+	    'alarmIds': args.alarmIds,
+	    'concurrency': args.concurrency,
+	    'func': function amonUpdateOne(alarmid, subcallback) {
+		/*
+		 * Unfortunately, sdc-client's Amon client does not support this
+		 * operation, so we need to hit the API directly.
+		 *
+		 * The server also doesn't recognize POST parameters specified
+		 * in the body, so we have to put them into the query string.
+		 */
+		var action, resource;
+		action = suppressed ? 'suppress' : 'unsuppress';
+		resource = sprintf('/pub/%s/alarms/%d?action=%s',
+		    encodeURIComponent(account), alarmid, action);
+		amon.post(resource, function (err) {
+			if (err) {
+				err = new VError(err,
+				    '%s notifications for alarm %d',
+				    suppressed ? 'disable' : 'enable',
+				    alarmid);
+			}
+			subcallback(err);
+		});
+	    }
+	}, callback);
+}
+
+/*
+ * Fetches details about the specified alarms.  Named arguments:
+ *
+ *     account         Triton account uuid whose open alarms to load
+ *
+ *     amon            Amon client (from sdc-clients)
+ *
+ *     alarmIds	       array of alarm ids to close
+ *
+ *     concurrency     maximum request concurrency
+ *
+ * The callback is invoked as callback(err, alarmset).  "alarmset" is a
+ * MantaAlarmSet that is always provided and contains any alarms that were
+ * successfully loaded.  "err" describes any errors loading alarms, and you can
+ * have it whether or not "alarmset" has any alarms.
+ */
+function amonLoadAlarmsForIds(args, callback)
+{
+	var account, amon, fetching, rv;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.arrayOfString(args.alarmIds, 'args.alarmIds');
+	assertplus.number(args.concurrency, 'args.concurrency');
+
+	account = args.account;
+	amon = args.amon;
+	fetching = {};
+	rv = new MantaAlarmSet();
+	amonAlarmForEach({
+	    'alarmIds': args.alarmIds,
+	    'concurrency': args.concurrency,
+	    'func': function amonLoadOne(alarmid, subcallback) {
+		/*
+		 * Ignore duplicates.
+		 */
+		if (fetching[alarmid]) {
+			setImmediate(subcallback);
+			return;
+		}
+
+		fetching[alarmid] = true;
+		amon.getAlarm(account, alarmid, function (err, rawalarm) {
+			var alarm;
+
+			if (err) {
+				subcallback(new VError(
+				    err, 'fetch alarm "%d"', alarmid));
+				return;
+			}
+
+			alarm = amon_objects.loadAlarmObject(rawalarm);
+			if (alarm instanceof Error) {
+				subcallback(new VError(alarm,
+				    'bad alarm from server'));
+				return;
+			}
+
+			/*
+			 * We checked for duplicates before we made the request.
+			 */
+			rv.addAlarm(alarm);
+			subcallback();
+		});
+	    }
+	}, function (err) {
+		rv.finalize();
+		callback(err, rv);
+	});
+}
+
+/*
+ * Represents a set of open amon alarms.
+ */
+function MantaAlarmSet()
+{
+	/* list of open alarms */
+	this.mas_alarms = [];
+
+	/* alarms indexed by id */
+	this.mas_alarms_byid = {};
+
+	/*
+	 * The set goes through two phases: the first phase is where consumers
+	 * (within this file) insert alarms, and the second phase is where
+	 * consumers (in other subsystems) iterate the alarms.  finalize() must
+	 * be called by the first consumer to change phases.  This is currently
+	 * used just to ensure that we sort the alarms exactly once, but it also
+	 * ensures a clean separation of the two parts of this interface.  (We
+	 * could instead create a write-only MantaAlarmSetBuilder and make this
+	 * read-only.)
+	 */
+	this.mas_finalized = false;
+}
+
+MantaAlarmSet.prototype.hasAlarmWithId = function (alarmId)
+{
+	assertplus.number(alarmId, 'alarmId');
+	return (this.mas_alarms_byid.hasOwnProperty(alarmId));
+};
+
+MantaAlarmSet.prototype.addAlarm = function (alarm)
+{
+	assertplus.object(alarm, 'alarm');
+	assertplus.number(alarm.a_id, 'alarm id');
+	assertplus.ok(!this.mas_finalized, 'alarm set is already finalized');
+	assertplus.ok(!this.mas_alarms_byid.hasOwnProperty(alarm.a_id));
+	this.mas_alarms.push(alarm);
+	this.mas_alarms_byid[alarm.a_id] = alarm;
+};
+
+MantaAlarmSet.prototype.finalize = function ()
+{
+	assertplus.ok(!this.mas_finalized, 'alarm set already finalized');
+	this.mas_finalized = true;
+	this.mas_alarms = this.mas_alarms.sort(function (a1, a2) {
+		assertplus.number(a1.a_id);
+		assertplus.number(a2.a_id);
+		return (a1.a_id - a2.a_id);
+	});
+};
+
+MantaAlarmSet.prototype.eachAlarm = function (func)
+{
+	assertplus.ok(this.mas_finalized,
+	    'cannot iterate until set is finalized');
+	this.mas_alarms.forEach(function (aa) {
+		func(aa.a_id, aa);
+	});
+};
+
+MantaAlarmSet.prototype.alarmForId = function (id)
+{
+	assertplus.ok(this.mas_finalized,
+	    'cannot iterate until set is finalized');
+	return (this.mas_alarms_byid.hasOwnProperty(id) ?
+	    this.mas_alarms_byid[id] : null);
+};
diff --git a/lib/alarms/amon_objects.js b/lib/alarms/amon_objects.js
new file mode 100644
index 0000000..784d452
--- /dev/null
+++ b/lib/alarms/amon_objects.js
@@ -0,0 +1,411 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/alarms/amon_objects.js: low-level Amon objects and their schemas.
+ * The classes in this file are used as simple structs, mostly with details
+ * private to this subsystem.  Each class's fields mirror those in the Amon API.
+ */
+
+var assertplus = require('assert-plus');
+var jsprim = require('jsprim');
+
+var sprintf = require('extsprintf').sprintf;
+var VError = require('verror');
+
+var common = require('../common');
+
+exports.loadAlarmObject = loadAlarmObject;
+exports.loadProbeObject = loadProbeObject;
+exports.loadProbeGroupObject = loadProbeGroupObject;
+
+/*
+ * This class is used as a struct, with details exposed to the next-level
+ * subsystem (lib/adm.js).  The fields here mirror those in the Amon API for
+ * Alarms.
+ */
+function AmonAlarm(alarmdef)
+{
+	var self = this;
+
+	assertplus.object(alarmdef, 'alarmdef');
+	assertplus.number(alarmdef.id, 'alarmdef.id');
+	assertplus.string(alarmdef.user, 'alarmdef.user');
+	assertplus.optionalString(alarmdef.probeGroup, 'alarmdef.probeGroup');
+	assertplus.bool(alarmdef.closed, 'alarmdef.closed');
+	assertplus.bool(alarmdef.suppressed, 'alarmdef.suppressed');
+	assertplus.number(alarmdef.timeOpened, 'alarmdef.timeOpened');
+	assertplus.optionalNumber(alarmdef.timeClosed, 'alarmdef.timeClosed');
+	assertplus.number(alarmdef.timeLastEvent, 'alarmdef.timeLastEvent');
+	assertplus.number(alarmdef.numEvents, 'alarmdef.numEvents');
+	assertplus.arrayOfObject(alarmdef.faults, 'alarmdef.faults');
+
+	this.a_id = alarmdef.id;
+	this.a_user = alarmdef.user;
+	this.a_groupid = alarmdef.probeGroup || null;
+	this.a_closed = alarmdef.closed;
+	this.a_suppressed = alarmdef.suppressed;
+	this.a_time_opened = new Date(alarmdef.timeOpened);
+	this.a_time_closed = alarmdef.timeClosed ?
+	    new Date(alarmdef.timeClosed) : null;
+	this.a_time_last = new Date(alarmdef.timeLastEvent);
+	this.a_nevents = alarmdef.numEvents;
+	this.a_faults = alarmdef.faults.map(function (f) {
+		return (new AmonFault(self, f));
+	});
+}
+
+/*
+ * This class is used as a struct, with details exposed to the next-level
+ * subsystem (lib/adm.js).  The fields here mirror those in the Amon API for
+ * Alarms.
+ */
+function AmonFault(alarm, faultdef)
+{
+	assertplus.object(alarm, 'alarm');
+	assertplus.ok(alarm instanceof AmonAlarm);
+	assertplus.object(faultdef, 'faultdef');
+	assertplus.string(faultdef.type, 'faultdef.type');
+	assertplus.equal(faultdef.type, 'probe');
+	assertplus.string(faultdef.probe, 'faultdef.probe');
+	assertplus.object(faultdef.event, 'faultdef.event');
+	assertplus.equal(faultdef.event.v, '1');
+	assertplus.string(faultdef.event.type, 'faultdef.event.type');
+	assertplus.equal(faultdef.event.type, 'probe');
+	assertplus.bool(faultdef.event.clear, 'faultdef.event.clear');
+	assertplus.string(faultdef.event.machine, 'faultdef.event.machine');
+	assertplus.string(faultdef.event.uuid, 'faultdef.event.uuid');
+	assertplus.string(faultdef.event.agent, 'faultdef.event.agent');
+	assertplus.string(faultdef.event.agentAlias,
+	    'faultdef.event.agentAlias');
+	assertplus.number(faultdef.event.time, 'faultdef.event.time');
+	assertplus.object(faultdef.event.data, 'faultdef.event.data');
+	assertplus.string(faultdef.event.data.message,
+	    'faultdef.event.data.message');
+
+	this.aflt_alarm = alarm;
+	this.aflt_probeid = faultdef.probe;
+	this.aflt_clear = faultdef.event.clear;
+	this.aflt_uuid = faultdef.event.uuid;
+	this.aflt_machine = faultdef.event.machine;
+	this.aflt_agent = faultdef.event.agent;
+	this.aflt_agent_alias = faultdef.event.agentAlias;
+	this.aflt_time = new Date(faultdef.event.time);
+	this.aflt_summary = faultdef.event.data.message;
+	this.aflt_data = faultdef.event.data;
+}
+
+/*
+ * This class is used as a struct, with details private to this subsystem.
+ * The fields here mirror those in the Amon API for Probes.  Because this can
+ * represent probes that have not yet been created, "uuid" is not required.
+ * Most optional fields are "null" when not present, though "contacts" may
+ * actually be not present.
+ */
+function AmonProbe(probedef)
+{
+	assertplus.object(probedef, 'probedef');
+	assertplus.optionalString(probedef.uuid, 'probedef.uuid');
+	assertplus.optionalString(probedef.name, 'probedef.name');
+	assertplus.string(probedef.type, 'probedef.type');
+	assertplus.object(probedef.config, 'probedef.config');
+	assertplus.string(probedef.agent, 'probedef.agent');
+	assertplus.optionalString(probedef.machine, 'probedef.machine');
+	assertplus.optionalString(probedef.group, 'probedef.group');
+	assertplus.optionalArrayOfString(probedef.contacts,
+	    'probedef.contacts');
+	assertplus.optionalBool(probedef.groupEvents, 'probedef.groupEvents');
+
+	this.p_uuid = probedef.hasOwnProperty('uuid') ? probedef.uuid : null;
+	this.p_name = probedef.hasOwnProperty('name') ? probedef.name : null;
+	this.p_type = probedef.type;
+	this.p_config = jsprim.deepCopy(probedef.config);
+	this.p_agent = probedef.agent;
+	this.p_machine = probedef.machine || null;
+	this.p_groupid = probedef.group || null;
+	this.p_contacts = probedef.contacts || null;
+	this.p_group_events = probedef.groupEvents || false;
+}
+
+/*
+ * This class is used as a struct, with details private to this subsystem.
+ * The fields here mirror those in the Amon API for Probe Groups.
+ */
+function AmonProbeGroup(groupdef)
+{
+	assertplus.object(groupdef, 'groupdef');
+	assertplus.string(groupdef.user, 'groupdef.user');
+	assertplus.string(groupdef.uuid, 'groupdef.uuid');
+	assertplus.string(groupdef.name, 'groupdef.name');
+	assertplus.bool(groupdef.disabled, 'groupdef.disabled');
+	assertplus.optionalArrayOfString(
+	    groupdef.contacts, 'groupdef.contacts');
+
+	this.pg_name = groupdef.name;
+	this.pg_user = groupdef.user;
+	this.pg_uuid = groupdef.uuid;
+	this.pg_contacts = groupdef.hasOwnProperty('contacts') ?
+	    groupdef.contacts.slice(0) : [];
+	this.pg_enabled = groupdef.disabled ? false : true;
+}
+
+
+/*
+ * Schema helper functions
+ *
+ * A note on optional properties: in some cases, when a value is unspecified
+ * (e.g., a probe with no probe group), the property is just missing.  The
+ * schema handles this by making the corresponding property not required.  In
+ * other cases (e.g., the timeClosed for an alarm that has not yet been closed),
+ * Amon includes the property with value "null".  The schema handles this by
+ * explicitly allowing "null" as one of the allowed types.
+ *
+ * By convention, schema types that we define in order to be able to reuse them
+ * are always named with a suffix of either "Required" (if the schema represents
+ * a required property) or "Optional" (if not).  We use the Optional version of
+ * a type when Amon might leave the property out entirely.  On the other hand,
+ * we use the schemaAllowNull() function to take any Required schema type and
+ * return one that can be null.
+ */
+
+/*
+ * Given a JSON schema, return a schema that is exactly equivalent, but also
+ * allows "null" values.
+ */
+function schemaAllowNull(schemaType) {
+	var rv;
+
+	assertplus.object(schemaType, 'schemaType');
+	assertplus.string(schemaType.type, 'schemaType.type');
+	assertplus.strictEqual(schemaType.required, true,
+	    'can only allow "required" properties to be null');
+	rv = jsprim.deepCopy(schemaType);
+	rv.type = [ 'null', rv.type ];
+	return (rv);
+}
+
+/*
+ * Schemas
+ */
+
+var schemaTypeNonNegativeIntegerRequired = {
+    'type': 'integer',
+    'required': true,
+    'minimum': 0
+};
+
+var schemaTypeUuidOptional = {
+    'type': 'string',
+    'maxLength': 36
+};
+
+var schemaTypeUuidRequired = {
+    'type': 'string',
+    'required': true,
+    'maxLength': 36
+};
+
+var schemaTypeTimestampAsNumberRequired = {
+    'type': 'number',
+    'required': true,
+    'minimum': 0
+};
+
+/*
+ * It's important that these Amon schemas be strict enough that we don't pass
+ * through objects that will cause us to crash when we go to dereference fields
+ * that are missing or have the wrong type.  They should generally not be
+ * stricter than Amon itself allows unless consumers can handle the possibility
+ * that objects that don't conform to our stricter schema may be ignored from
+ * their model of the world.  We use this behavior when we encounter probe
+ * groups with no name, for example.
+ *
+ * It's important that we not reject valid objects from Amon in a way that would
+ * cause entire operations to fail.  For example, we currently bail out any
+ * "verify"/"update" operation if we encounter any invalid probes.  We don't
+ * want that to happen in a real deployment, since it renders the tool useless.
+ * But we also want to err on the side of caution and not plow ahead with probes
+ * we don't know what to do with.
+ *
+ * The point of all this is that we need to be very careful about situations
+ * where this schema is stricter than Amon's.  The known cases are documented
+ * below.
+ */
+
+var schemaTypeAmonFault = {
+    'type': 'object',
+    'properties': {
+	'type': { 'type': 'string', 'required': true, 'enum': [ 'probe' ] },
+	'probe': schemaTypeUuidRequired,
+	'event': {
+	    'type': 'object',
+	    'required': true,
+	    'properties': {
+		'v': { 'type': 'integer', 'required': true, 'enum': [ 1 ] },
+		'type': {
+		    'type': 'string',
+		    'required': true,
+		    'enum': [ 'probe' ]
+		},
+		'clear': { 'type': 'boolean', 'required': true },
+		'machine': schemaTypeUuidRequired,
+		'uuid': schemaTypeUuidRequired,
+		'agent': schemaTypeUuidRequired,
+		'agentAlias': { 'type': 'string', 'required': true },
+		'time': schemaTypeTimestampAsNumberRequired,
+		'data': {
+		    'type': 'object',
+		    'required': true,
+		    'properties': {
+			'message': {
+			    'type': 'string',
+			    'required': true
+			}
+		    }
+		}
+	    }
+	}
+    }
+};
+
+var schemaTypeAmonAlarm = {
+    'type': 'object',
+    'properties': {
+	'id': schemaTypeNonNegativeIntegerRequired,
+	'user': schemaTypeUuidRequired,
+	'probeGroup': schemaTypeUuidOptional,
+	'closed': { 'type': 'boolean', 'required': true },
+	'suppressed': { 'type': 'boolean', 'required': true },
+	'timeOpened': schemaTypeTimestampAsNumberRequired,
+	'timeClosed': schemaAllowNull(schemaTypeTimestampAsNumberRequired),
+	'timeLastEvent': schemaTypeTimestampAsNumberRequired,
+	'numEvents': schemaTypeNonNegativeIntegerRequired,
+	'faults': {
+	    'type': 'array',
+	    'required': true,
+	    'items': schemaTypeAmonFault
+	}
+    }
+};
+
+var schemaTypeAmonContacts = {
+    'type': 'array',
+    'items': {
+	'type': 'string'
+    }
+};
+
+var schemaTypeAmonProbe = {
+    'type': 'object',
+    'properties': {
+	/*
+	 * See the comment on the AmonProbe class definition.  We allow "uuid"
+	 * to be omitted for probes that have not yet been created.
+	 *
+	 * We also allow it to have unbounded length (unlike a normal uuid
+	 * field) because the implementation uses the probe's name in this
+	 * field, and that can be larger than a uuid (but still within reason).
+	 */
+	'uuid': { 'type': 'string' },
+	'name': { 'type': 'string' },
+	'type': { 'type': 'string', 'required': true },
+	'config': { 'type': 'object', 'required': true },
+	'agent': schemaTypeUuidRequired,
+	'groupEvents': schemaAllowNull({ 'type': 'boolean', 'required': true }),
+	'machine': schemaAllowNull(schemaTypeUuidRequired),
+
+	/*
+	 * "group" is not explicitly a uuid in the case of uncreated probes.
+	 */
+	'group': schemaAllowNull({ 'type': 'string', 'required': true }),
+	'contacts': schemaTypeAmonContacts
+    }
+};
+
+var schemaTypeAmonProbeGroup = {
+    'type': 'object',
+    'properties': {
+	/*
+	 * As with probes, the structure is a little looser to accommodate
+	 * uncreated probe groups.  We allow strings instead of requiring them
+	 * to be uuids.  However, we do require both of these properties to be
+	 * present.  It's technically allowed for users to create probe groups
+	 * with no names.  These will fail validation, and we will ignore them.
+	 * (That's generally fine, because we also handle alarms for probe
+	 * groups that we don't know about.)
+	 */
+	'uuid': { 'type': 'string', 'required': true },
+	'name': { 'type': 'string', 'required': true },
+	'user': schemaTypeUuidRequired,
+	'contacts': schemaTypeAmonContacts,
+	'disabled': { 'type': 'boolean', 'required': true }
+    }
+};
+
+function loadAlarmObject(alarmdef)
+{
+	var error;
+
+	error = jsprim.validateJsonObject(schemaTypeAmonAlarm, alarmdef);
+	if (error === null &&
+	    !alarmdef.closed && alarmdef.faults.length === 0) {
+		error = new VError('alarm open with no faults');
+	}
+
+	if (error === null &&
+	    ((alarmdef.closed && alarmdef.timeClosed === null) ||
+	    (!alarmdef.closed && alarmdef.timeClosed !== null))) {
+		error = new VError('alarm\'s "closed" is not consistent ' +
+		    'with "timeClosed"');
+	}
+
+	if (error !== null) {
+		if (typeof (alarmdef.id) == 'number') {
+			error = new VError(error, 'alarm %d', alarmdef.id);
+		}
+
+		return (error);
+	}
+
+	return (new AmonAlarm(alarmdef));
+}
+
+function loadProbeObject(probedef)
+{
+	var error;
+
+	error = jsprim.validateJsonObject(schemaTypeAmonProbe, probedef);
+	if (error !== null) {
+		if (typeof (probedef.uuid) == 'string') {
+			error = new VError(error, 'probe "%s"', probedef.uuid);
+		}
+
+		return (error);
+	}
+
+	return (new AmonProbe(probedef));
+}
+
+function loadProbeGroupObject(groupdef)
+{
+	var error;
+
+	error = jsprim.validateJsonObject(schemaTypeAmonProbeGroup, groupdef);
+	if (error !== null) {
+		if (typeof (groupdef.uuid) == 'string') {
+			error = new VError(error, 'probe group "%s"',
+			    groupdef.uuid);
+		}
+
+		return (error);
+	}
+
+	return (new AmonProbeGroup(groupdef));
+}
diff --git a/lib/alarms/config.js b/lib/alarms/config.js
new file mode 100644
index 0000000..3226364
--- /dev/null
+++ b/lib/alarms/config.js
@@ -0,0 +1,544 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/alarms/config.js: facilities for representing a set of amon
+ * configuration, which essentially means a set of probes and probe groups.
+ */
+
+var assertplus = require('assert-plus');
+var jsprim = require('jsprim');
+var progbar = require('progbar');
+var vasync = require('vasync');
+var VError = require('verror');
+var fprintf = require('extsprintf').fprintf;
+
+var amon_objects = require('./amon_objects');
+var services = require('../services');
+
+/* Exported interface */
+exports.amonLoadProbeGroups = amonLoadProbeGroups;
+exports.amonLoadComponentProbes = amonLoadComponentProbes;
+exports.amonConfigSummarize = amonConfigSummarize;
+exports.MantaAmonConfig = MantaAmonConfig;
+
+/*
+ * Fetches Amon probe groups.
+ *
+ *     amon             an Amon client
+ *
+ *     account		Triton account uuid whose probes to fetch
+ *
+ * callback is invoked as "callback(err, amonconfig)", where on success
+ * "amonconfig" is an instance of MantaAmonConfig.  Note that "err" and
+ * "amonconfig" can both be non-null, in which case "err" represents non-fatal
+ * (warning-level) issues encountered.
+ */
+function amonLoadProbeGroups(args, callback)
+{
+	var account, amon;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.func(callback, 'callback');
+
+	account = args.account;
+	amon = args.amon;
+	amon.listProbeGroups(account, function (err, rawgroups) {
+		var amoncfg, errors;
+
+		if (err) {
+			err = new VError(err, 'listing probegroups');
+			callback(err);
+			return;
+		}
+
+		amoncfg = new MantaAmonConfig();
+		errors = [];
+		rawgroups.forEach(function (rawgroup) {
+			var error = amoncfg.addProbeGroup(rawgroup);
+			if (error instanceof Error) {
+				errors.push(
+				    new VError(error, 'ignoring group'));
+			}
+		});
+
+		err = VError.errorFromList(errors);
+		callback(err, amoncfg);
+	});
+}
+
+/*
+ * Fetches Amon probe objects for all probes for the specified components.
+ * Named arguments:
+ *
+ *     amonRaw          a restify JSON client for the AMON master API.
+ *     			This is different from most other consumers, which use
+ *     			an actual Amon client.
+ *
+ *     amoncfg          an instance of MantaAmonConfig with probe groups
+ *                      configured already.  This configuration will be updated
+ *                      with probe details.
+ *
+ *     components	an array of objects describing the components.  Each
+ *     			component should have properties:
+ *
+ *     		"type"	either "cn" (for compute nodes) or "vm" (for containers)
+ *
+ *     		"uuid"  the server_uuid (for type "cn") or VM uuid (for
+ *     			containers)
+ *
+ *     concurrency	an integer number for the maximum concurrent requests
+ *
+ * "callback" is invoked as "callback(err)".
+ *
+ * Amon has an API for listing probes, but it's limited to 1000 probes, which is
+ * too small for large Manta deployments.  Additionally, that API has no support
+ * for pagination.  Instead, we use the private Amon agent API to fetch the list
+ * of probes for each agent.  That number is generally much smaller.  This
+ * results in a lot more requests, but we don't have a better option.
+ */
+function amonLoadComponentProbes(args, callback)
+{
+	var amoncfg, client, queue, errors, warnings, progress, ndone;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.amonRaw, 'args.amonRaw');
+	assertplus.object(args.amoncfg, 'args.amoncfg');
+	assertplus.ok(args.amoncfg instanceof MantaAmonConfig);
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.arrayOfObject(args.components, 'args.components');
+	assertplus.func(callback, 'callback');
+
+	amoncfg = args.amoncfg;
+	client = args.amonRaw;
+	errors = [];
+	warnings = [];
+	ndone = 0;
+	if (process.stderr.isTTY) {
+		progress = new progbar.ProgressBar({
+		    'filename': 'fetching probes for each agent',
+		    'bytes': false,
+		    'size': args.components.length
+		});
+	}
+
+	queue = vasync.queuev({
+	    'concurrency': args.concurrency,
+	    'worker': function fetchProbeQueueWorker(component, qcallback) {
+		assertplus.object(component, 'component');
+		assertplus.string(component.type, 'component.type');
+		assertplus.string(component.uuid, 'component.uuid');
+
+		amonFetchAgentProbes({
+		    'amon': client,
+		    'agentUuid': component.uuid
+		}, function (err, probes) {
+			if (err) {
+				err = new VError(err, 'fetching probes for ' +
+				    'agent on %s "%s"', component.type,
+				    component.uuid);
+				errors.push(err);
+				qcallback();
+				return;
+			}
+
+			probes.forEach(function (p) {
+				var error = amoncfg.addProbe(p);
+				if (error !== null) {
+					warnings.push(new VError(error,
+					    'ignoring probe'));
+				}
+			});
+
+			ndone++;
+			if (progress !== undefined) {
+				progress.advance(ndone);
+			}
+
+			qcallback();
+		});
+	    }
+	});
+
+	args.components.forEach(function (c, i) {
+		var label = 'args.components[' + i + ']';
+		assertplus.string(c.type, label + '.type');
+		assertplus.string(c.uuid, label + '.uuid');
+		queue.push({ 'type': c.type, 'uuid': c.uuid });
+	});
+
+	queue.on('end', function () {
+		if (progress !== undefined) {
+			progress.end();
+		}
+
+		callback(VError.errorFromList(errors),
+		    VError.errorFromList(warnings));
+	});
+
+	queue.close();
+}
+
+/*
+ * Uses the amon (private) relay API to list the probes associated with the
+ * given agent.
+ *
+ * Named arguments:
+ *
+ *     amon             a restify JSON client for the AMON master API
+ *
+ *     agentUuid        uuid of the agent whose probes should be fetched
+ */
+function amonFetchAgentProbes(args, callback)
+{
+	var client, uripath;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.string(args.agentUuid, 'args.agentUuid');
+	assertplus.func(callback, 'callback');
+
+	client = args.amon;
+	uripath = '/agentprobes?agent=' + encodeURIComponent(args.agentUuid);
+	client.get(uripath, function (err, req, res, result) {
+		/*
+		 * This API has the same problem as most Amon API "list"
+		 * operations, which is that they implicitly have a limit on the
+		 * number of results, there's no way to override that, and
+		 * there's no way to paginate the list.  As a result, we can
+		 * never see more than that many results.  Today, this number is
+		 * 1000.  We attempt to at least detect that this might have
+		 * happened.
+		 */
+		var limit = 1000;
+		if (!err && result.length == limit) {
+			err = new VError('got %d results, ' +
+			    'assuming truncation', limit);
+		}
+
+		if (err) {
+			err = new VError(err, 'amon: get "%s"', uripath);
+			callback(err);
+			return;
+		}
+
+		callback(null, result);
+	});
+}
+
+
+/*
+ * Print a human-readable summary of configured probes and probe groups.
+ */
+function amonConfigSummarize(args, callback)
+{
+	var out, config, metadata, instanceSvcname;
+	var ngroups, nagents, nprobes, norphans;
+	var svcs, rows;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.config, 'args.config');
+	assertplus.ok(args.config instanceof MantaAmonConfig);
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.object(args.metadata, 'args.metadata');
+	assertplus.object(args.instanceSvcname, 'args.instanceSvcname');
+
+	out = args.stream;
+	config = args.config;
+	metadata = args.metadata;
+	instanceSvcname = args.instanceSvcname;
+
+	ngroups = 0;
+	nprobes = 0;
+	nagents = 0;
+	norphans = 0;
+	svcs = {};
+	svcs['unknown'] = {
+	    'svc_groups': {},
+	    'svc_nprobes': 0,
+	    'svc_ninstances': 0,
+	    'svc_norphans': 0,
+	    'svc_agents': {}
+	};
+	svcs['global zone'] = jsprim.deepCopy(svcs['unknown']);
+	services.mSvcNamesProbes.forEach(function (svcname) {
+		svcs[svcname] = jsprim.deepCopy(svcs['unknown']);
+	});
+
+	/*
+	 * Print a count of probes and agents affected for each probe group.
+	 */
+	rows = [];
+	config.eachProbeGroup(function (pg) {
+		var eventName, ka, name;
+		var ngroupprobes, agents, ngroupagents;
+
+		agents = {};
+		ngroupprobes = 0;
+		config.eachProbeGroupProbe(pg.pg_name, function iterProbe(p) {
+			var svcname, svc;
+
+			agents[p.p_agent] = true;
+			ngroupprobes++;
+			svcname = instanceSvcname.hasOwnProperty(p.p_agent) &&
+			    svcs.hasOwnProperty(instanceSvcname[p.p_agent]) ?
+			    instanceSvcname[p.p_agent] : 'unknown';
+			svc = svcs[svcname];
+			svc.svc_nprobes++;
+			svc.svc_groups[pg.pg_uuid] = true;
+			svc.svc_agents[p.p_agent] = true;
+		});
+
+		ngroupagents = Object.keys(agents).length;
+		nprobes += ngroupprobes;
+		ngroups++;
+
+		eventName = metadata.probeGroupEventName(pg.pg_name);
+		if (eventName !== null) {
+			ka = metadata.eventKa(eventName);
+			if (ka !== null) {
+				name = ka.ka_title;
+			} else {
+				name = eventName;
+			}
+		} else {
+			name = pg.pg_name;
+		}
+
+		rows.push({
+		    'nprobes': ngroupprobes,
+		    'nagents': ngroupagents,
+		    'name': name
+		});
+	});
+
+	config.eachOrphanProbe(function (p) {
+		var svcname, svc;
+
+		nprobes++;
+		norphans++;
+		svcname = instanceSvcname.hasOwnProperty(p.p_agent) &&
+		    svcs.hasOwnProperty(instanceSvcname[p.p_agent]) ?
+		    instanceSvcname[p.p_agent] : 'unknown';
+		svc = svcs[svcname];
+		svc.svc_nprobes++;
+		svc.svc_norphans++;
+	});
+
+	fprintf(out, 'Configuration by probe group:\n\n');
+	fprintf(out, '    %7s  %7s  %s\n', 'NPROBES', 'NAGENTS', 'PROBE GROUP');
+	rows.sort(function (r1, r2) {
+		return (r1.name.localeCompare(r2.name));
+	}).forEach(function (row) {
+		fprintf(out, '    %7d  %7d  %s\n',
+		    row.nprobes, row.nagents, row.name);
+	});
+
+	/*
+	 * Now print a summary of probes by service name.
+	 */
+	fprintf(out, '\nConfiguration by service:\n\n');
+	fprintf(out, '    %-16s  %7s  %7s  %7s  %8s\n',
+	    'SERVICE', 'NGROUPS', 'NAGENTS', 'NPROBES', 'NORPHANS');
+	Object.keys(svcs).sort(function (a1, a2) {
+		if (a1 == 'unknown') {
+			return (1);
+		} else if (a2 == 'unknown') {
+			return (-1);
+		}
+		return (a1.localeCompare(a2));
+	}).forEach(function (svcname) {
+		var svc, nsvcagents;
+
+		svc = svcs[svcname];
+		nsvcagents = Object.keys(svc.svc_agents).length;
+		fprintf(out, '    %-16s  %7d  %7d  %7d  %8d\n', svcname,
+		    Object.keys(svc.svc_groups).length, nsvcagents,
+		    svc.svc_nprobes, svc.svc_norphans);
+		nagents += nsvcagents;
+	});
+
+	fprintf(out, '    %-16s  %7d  %7d  %7d  %8d\n\n', 'TOTAL',
+	    ngroups, nagents, nprobes, norphans);
+}
+
+
+/*
+ * Amon configuration
+ *
+ * The MantaAmonConfig class represents a set of probes and probe groups.  See
+ * the block comment in lib/alarms/index.js for more information.
+ *
+ * This implementation requires that probe group names be unique, and that probe
+ * groups be added before probes.  The name uniqueness constraint is important
+ * because the only way to compare what we expect to be deployed against what's
+ * really deployed is based on the probe group names.  If we have more than one
+ * probe group with the same name, then it would be much harder to tell whether
+ * the right probes were deployed.
+ */
+function MantaAmonConfig()
+{
+	/*
+	 * mapping of probe group name -> probe group object
+	 * This is the canonical set of probe groups represented by this object.
+	 */
+	this.mac_probegroups_by_name = {};
+
+	/*
+	 * mapping of probe group uuid -> probe group name
+	 * This set is updated as callers add probe groups, but it's primarily
+	 * used as callers subsequently add probes in order to map those probes
+	 * to corresponding probe groups.  It's also used for deployed probe
+	 * groups to allow consumers to map group uuids to group names.
+	 */
+	this.mac_probegroups_by_uuid = {};
+
+	/*
+	 * mapping of probe group name -> list of probes
+	 * Along with mac_probes_orphan below, this is the canonical set of
+	 * probes represented by this object.
+	 */
+	this.mac_probes_by_probegroup = {};
+
+	/* List of probes having no group */
+	this.mac_probes_orphan = [];
+}
+
+/*
+ * Adds a probe.  The "probedef" object must match the Amon schema for a probe.
+ */
+MantaAmonConfig.prototype.addProbe = function (probedef)
+{
+	var probe, pgname;
+
+	probe = new amon_objects.loadProbeObject(probedef);
+	if (probe instanceof Error) {
+		return (probe);
+	}
+
+	if (probe.p_groupid === null) {
+		this.mac_probes_orphan.push(probe);
+		return (null);
+	}
+
+	if (!this.mac_probegroups_by_uuid.hasOwnProperty(probe.p_groupid)) {
+		return (new VError('probe "%s": unknown probe group "%s"',
+		    probe.p_uuid, probe.p_groupid));
+	}
+
+	pgname = this.mac_probegroups_by_uuid[probe.p_groupid];
+	assertplus.ok(this.mac_probes_by_probegroup.hasOwnProperty(pgname));
+	this.mac_probes_by_probegroup[pgname].push(probe);
+	return (null);
+};
+
+/*
+ * Adds a probe group.  The "groupdef" object must match the Amon schema for a
+ * probe group.
+ */
+MantaAmonConfig.prototype.addProbeGroup = function (groupdef)
+{
+	var probegroup;
+
+	probegroup = amon_objects.loadProbeGroupObject(groupdef);
+	if (probegroup instanceof Error) {
+		return (probegroup);
+	}
+
+	if (this.mac_probegroups_by_name.hasOwnProperty(probegroup.pg_name)) {
+		return (new VError('duplicate probe group name: "%s"',
+		    probegroup.pg_name));
+	}
+
+	if (this.mac_probegroups_by_uuid.hasOwnProperty(probegroup.pg_uuid)) {
+		return (new VError('duplicate probe group uuid: "%s"',
+		    probegroup.pg_uuid));
+	}
+
+	assertplus.ok(!this.mac_probes_by_probegroup.hasOwnProperty(
+	    probegroup.pg_name));
+	this.mac_probegroups_by_name[probegroup.pg_name] = probegroup;
+	this.mac_probegroups_by_uuid[probegroup.pg_uuid] = probegroup.pg_name;
+	this.mac_probes_by_probegroup[probegroup.pg_name] = [];
+	return (null);
+};
+
+/*
+ * Returns the specified probe group, if it exists.  Otherwise, returns null.
+ */
+MantaAmonConfig.prototype.probeGroupForName = function (pgname)
+{
+	assertplus.string(pgname, 'pgname');
+	if (!this.mac_probegroups_by_name.hasOwnProperty(pgname)) {
+		return (null);
+	}
+
+	return (this.mac_probegroups_by_name[pgname]);
+};
+
+/*
+ * Returns the probe group name for the given probe group id.
+ */
+MantaAmonConfig.prototype.probeGroupNameForUuid = function (pgid)
+{
+	if (!this.mac_probegroups_by_uuid.hasOwnProperty(pgid)) {
+		return (null);
+	}
+
+	return (this.mac_probegroups_by_uuid[pgid]);
+};
+
+MantaAmonConfig.prototype.hasProbeGroup = function (pgname)
+{
+	assertplus.string(pgname);
+	return (this.mac_probes_by_probegroup.hasOwnProperty(pgname));
+};
+
+/*
+ * Iterates all of the probe groups in this configuration and invokes
+ * "func(probegroup)".
+ */
+MantaAmonConfig.prototype.eachProbeGroup = function (func)
+{
+	var probesbypg;
+
+	assertplus.func(func, 'func');
+	probesbypg = this.mac_probes_by_probegroup;
+	jsprim.forEachKey(this.mac_probegroups_by_name, function (name, pg) {
+		assertplus.ok(probesbypg.hasOwnProperty(name));
+		func(pg);
+	});
+};
+
+/*
+ * Iterates all probes in this configuration that are associated with probe
+ * group "pgname" and invokes "func(probe)" for each one.
+ */
+MantaAmonConfig.prototype.eachProbeGroupProbe = function (pgname, func)
+{
+	var probes;
+	assertplus.string(pgname, 'pgname');
+	assertplus.func(func, 'func');
+	assertplus.ok(this.mac_probes_by_probegroup.hasOwnProperty(pgname),
+	    'unknown probe group name: "' + pgname + '"');
+	probes = this.mac_probes_by_probegroup[pgname];
+	probes.forEach(function (p) { func(p); });
+};
+
+/*
+ * Iterates all probes in this configuration that have no associated probe
+ * group and invokes "func(probe)" for each one.
+ */
+MantaAmonConfig.prototype.eachOrphanProbe = function (func)
+{
+	assertplus.func(func, 'func');
+	this.mac_probes_orphan.forEach(function (p) { func(p); });
+};
diff --git a/lib/alarms/index.js b/lib/alarms/index.js
new file mode 100644
index 0000000..a215109
--- /dev/null
+++ b/lib/alarms/index.js
@@ -0,0 +1,245 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * Manta Alarm Management
+ *
+ *
+ * INTRODUCTION
+ *
+ * Manta uses Triton's Amon facilities to define checks and other conditions
+ * that will raise alarms and notify operators when problems arise.  Operators
+ * are expected to run "manta-adm" during deployment to configure Amon with all
+ * of the expected checks.  (Other than running the command itself, this process
+ * is fully automatic.)  Later, when alarms are opened in response to failures,
+ * operators also use "manta-adm" to list alarms, fetch details about them,
+ * suspend notifications in cases of known issues, and ultimately close alarms
+ * for which the underlying issue is believed to be resolved.
+ *
+ * Amon is configured in terms of probes.  Most probes are either commands that
+ * run periodically or log file watchers that continuously monitor the contents
+ * of log files.  Each probe is attached to a specific instance, which is either
+ * a Triton VM or a Triton CN.  Of course, the set of VMs and CNs used for Manta
+ * is not static, and certainly not known at build time, so probes must be
+ * dynamically generated based on metadata (which is stored in this repository)
+ * and the set of components actually deployed at any given time.  This process
+ * is described in more detail below.
+ *
+ * Within Amon's configuration, probes are gathered into probe groups, which are
+ * mainly useful because they define how the corresponding alarms get organized.
+ * When multiple probes in the same group fail, those failures are generally
+ * collected into a single alarm.  That's useful to group multiple instances of
+ * the same problem (e.g., multiple "webapi" components reporting the same
+ * error).  Unlike previous versions of this software, distinct failure modes
+ * generally result in different alarms.  This makes it possible to silence
+ * individual alarms corresponding to known issues without squelching
+ * notifications about new issues as well.
+ *
+ *
+ * LOCAL METADATA AND KNOWN FAILURE MODES
+ *
+ * The metadata contained in this repository enumerates all of the known Manta
+ * failure modes, defines checks for identifying them, and provides useful
+ * information for an operator about each one.  Inspired by the illumos Fault
+ * Management Architecture ("FMA"), the metadata describes one or more _event
+ * classes_, each having a unique name in a hierarchical, dot-delimited
+ * namespace.  Each of these corresponds to a distinct failure mode.  For
+ * example, the event:
+ *
+ *     upset.manta.loadbalancer.no_backends
+ *
+ * indicates that a loadbalancer has no available backends.  ("upset" is an
+ * existing top-level FMA event class that covers soft errors.  Since we expect
+ * future events to fall into the same bucket of Manta-related soft errors, we
+ * currently validate that all event names start with "upset.manta".  There's no
+ * intrinsic reason that new events must start with this prefix, and this
+ * subsystem should not assume that they do except for validation purposes.  If
+ * you're looking to add events in different top-level classes, make sure you
+ * understand how they fit into the broader FMA event schema.)
+ *
+ * In our model, these event classes correspond one-to-one with Amon probe
+ * groups.
+ *
+ * For operator-visible events like these, FMA supports the idea of _knowledge
+ * articles_, which provide content written for operators that describes a
+ * problem's severity, impact, any automated response (if any), and suggested
+ * action.
+ *
+ * Putting all this together: each piece of metadata defined in this repository
+ * is called a _probe template_.  Each template describes a known Manta failure
+ * mode, a list of checks for identifying it, and knowledge article content.
+ * Specifically, each template has:
+ *
+ *     - an FMA event class name unique to this failure mode.  This is used as a
+ *       primary key to refer to this particular failure mode.
+ *
+ *     - a scope, which describes what kinds of components this template applies
+ *       to (e.g., "loadbalancer" zones)
+ *
+ *     - a list of checks for identifying this failure mode.  These are used to
+ *       create Amon probes to detect this failure.
+ *
+ *     - knowledge article content
+ *
+ * The specific format is described in lib/alarms/metadata.js.
+ *
+ * As an example, the aforementioned event has FMA event class
+ * "upset.manta.loadbalancer.no_backends".  Its scope would be "loadbalancer",
+ * and it would define a check script to run in each loadbalancer zone to count
+ * the backends and fail if the count is zero.  To implement this, the
+ * deployment tooling creates one probe group for the failure mode itself and
+ * a probe to run the check _for each_ loadbalancer instance.
+ *
+ * More sophisticated configurations are also possible.  See the comments in
+ * config.js for details.
+ *
+ * FMA supports a sophisticated system of telemetry, diagnosis, reporting, and
+ * retirement of faulty components.  We only use the concepts of events, the
+ * event hierarchy, and knowledge articles, and this implementation shares no
+ * code with FMA itself.
+ *
+ *
+ * IMPLEMENTATION OVERVIEW
+ *
+ * Putting this together, there are basically three sources of information
+ * related to probes and alarms:
+ *
+ *    (1) The list of instances of each component that are currently deployed.
+ *        This includes the lists of SAPI instances, VMs, and CNs, and the
+ *        information comes from SAPI, VMAPI, and CNAPI.
+ *
+ *    (2) Local metadata that describes the probe groups and probes that should
+ *        exist in a Manta deployment.  This metadata also includes knowledge
+ *        articles that provide additional information for the operator for each
+ *        failure mode (like instructions about how to respond to various types
+ *        of alarms).
+ *
+ *    (3) The list of probes and probe groups that are actually deployed, and
+ *        the list of open alarms and the events associated with each alarm.
+ *        This comes from Amon, but Amon only knows about its own agents, which
+ *        have uuids corresponding to VM and CN uuids.  To make sense of this
+ *        information, it has to be at least joined with the list of components
+ *        deployed, but likely also the local metadata associated with probe
+ *        groups.
+ *
+ *        This source can be split further into the list of alarms and probe
+ *        groups and (separately) the list of probes.  The list of probes is
+ *        much more expensive to gather, and is only necessary when
+ *        verifying or updating the Amon configuration.
+ *
+ * Using this information, we want to support a few different stories:
+ *
+ *    (1) List open alarms or detailed information about specific alarms.
+ *        ("manta-adm alarm show" and related commands)
+ *
+ *        We want to present the list of known, active problems.  This is the
+ *        list of open alarms, which we can fetch from Amon.  We want to
+ *        associate each problem with the affected components using their
+ *        service names.  That requires joining the "machine" that's provided
+ *        in each fault with the information we fetched separately about
+ *        deployed VMs and CNs.  We also want to provide knowledge article
+ *        content about each alarm by joining with the local configuration,
+ *        based on the alarm's probe group name.
+ *
+ *    (2) List configured probes and probe groups.
+ *        ("manta-adm alarm config show" and related commands)
+ *
+ *        It's useful for operators to see what probes have been configured.
+ *        This involves fetching probes and probe groups from Amon and combining
+ *        that information with the local knowledge articles for each one and
+ *        possibly the list of VMs and CNs deployed.
+ *
+ *    (3) Update the probe and probe group configuration.
+ *        ("manta-adm alarm config verify", "manta-adm alarm config update")
+ *
+ *        For both initial deployment and subsequent updates, it's important to
+ *        have an idempotent operation that compares what probes and probe
+ *        groups are supposed to be configured with what's actually deployed and
+ *        then updates the deployment to match what's expected.  This also
+ *        involves joining all three sources of information.
+ *
+ * Adding to the complexity, there are several other types of probes or probe
+ * groups that we may encounter:
+ *
+ *     - Probes and probe groups added by operators for their own custom
+ *       monitoring.  This is fully supported, though it cannot be configured
+ *       using the Manta tools.  We present these as best we can -- using
+ *       whatever metadata is in the probe groups rather than knowledge article
+ *       information.
+ *
+ *     - Probes and probe groups added by previous versions of this software
+ *       before any of the local metadata was provided.  These groups are
+ *       explicitly deprecated: we want operators to move away from them because
+ *       they're very hard to use.  For display, we treat these like probes and
+ *       probe groups that operators added, where we have no local knowledge
+ *       article information about them.  For update, we'll remove these
+ *       altogether, since they're replaced by other probes and groups that we
+ *       deploy.
+ *
+ *     - Other probes and probe groups added by other versions of this software
+ *       (either older or newer) that had local metadata at the time.  We can
+ *       distinguish these because of the way probe groups are named.  We treat
+ *       older objects similar to probes and probe groups that were added before
+ *       this metadata was available: we'll consider them removable during
+ *       "manta-adm alarm config verify/update".  We'll ignore newer objects.
+ *
+ * The implementation of these facilities is divided into:
+ *
+ *     - lib/alarms/index.js (this file): general documentation and symbols
+ *       exported from this subsystem.
+ *
+ *     - lib/alarms/alarms.js: defines data structures and functions for
+ *       managing alarms themselves.
+ *
+ *     - lib/alarms/amon_objects.js: defines classes and loaders for low-level
+ *       Amon objects, including input validation.
+ *
+ *     - lib/alarms/config.js: defines data structures and functions for
+ *       managing Amon configuration (namely, a set of probes and probe groups).
+ *       This includes functions that fetch probes and probe groups from Amon,
+ *       and classes for walking these structures for the purpose of verifying
+ *       or updating the configuration.
+ *
+ *     - lib/alarms/metadata.js: defines data structures and functions for
+ *       working with the locally provided metadata for known failure modes.
+ *
+ *     - lib/alarms/update.js: defines data structures and functions for
+ *       updating the Amon configuration.  This includes functions for comparing
+ *       two sets of configuration (usually a "deployed" configuration and a
+ *       "desired" configuration), generating a plan to move from one to
+ *       another, and applying that plan.
+ */
+
+var alarm_metadata = require('./metadata');
+var alarm_alarms = require('./alarms');
+var alarm_config = require('./config');
+var alarm_update = require('./update');
+
+/* Exported interfaces */
+
+/* Alarms */
+exports.amonLoadAlarmsForState = alarm_alarms.amonLoadAlarmsForState;
+exports.amonLoadAlarmsForIds = alarm_alarms.amonLoadAlarmsForIds;
+exports.amonCloseAlarms = alarm_alarms.amonCloseAlarms;
+exports.amonUpdateAlarmsNotification =
+    alarm_alarms.amonUpdateAlarmsNotification;
+
+/* Configuration */
+exports.amonLoadProbeGroups = alarm_config.amonLoadProbeGroups;
+exports.amonLoadComponentProbes = alarm_config.amonLoadComponentProbes;
+exports.amonConfigSummarize = alarm_config.amonConfigSummarize;
+
+/* Configuration updates */
+exports.amonUpdatePlanCreate = alarm_update.amonUpdatePlanCreate;
+exports.amonUpdatePlanSummarize = alarm_update.amonUpdatePlanSummarize;
+exports.amonUpdatePlanApply = alarm_update.amonUpdatePlanApply;
+
+/* Local metadata */
+exports.loadMetadata = alarm_metadata.loadMetadata;
diff --git a/lib/alarms/metadata.js b/lib/alarms/metadata.js
new file mode 100644
index 0000000..9cae65e
--- /dev/null
+++ b/lib/alarms/metadata.js
@@ -0,0 +1,951 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/alarms/metadata.js: facilities for working with locally-provided metadata
+ * about probes and probe groups.  See the block comment in lib/alarms/index.js
+ * for details.
+ *
+ *
+ * INTERFACES
+ *
+ * This module exposes the following function publicly:
+ *
+ *     loadMetadata: loads locally-provided metadata from files into a
+ *     MantaAmonMetadata object
+ *
+ * That function implicitly exposes this class:
+ *
+ *     MantaAmonMetadata: a class that provides basic methods for iterating the
+ *     locally-provided metadata.  Instances of this class are immutable once
+ *     constructed.
+ *
+ * This module exposes the following function semi-privately (to other modules
+ * in this directory):
+ *
+ *     probeGroupNameForTemplate: constructs a probe group name based on a probe
+ *     template
+ *
+ * as well as the "MetadataLoader" for tools.
+ *
+ *
+ * PROBE TEMPLATE FILES
+ *
+ * In this repo, the directory "alarm_metadata/probe_templates" contains a
+ * number of probe template files written in YAML.  Each file describes an array
+ * of probe templates.  The probe templates from all of these files are combined
+ * into a single configuration; the organization into separate files is purely
+ * for readers.  Each probe template describes a distinct failure mode for a
+ * Manta deployment and implicitly specifies a group of probes to be created at
+ * deployment-time.  These concepts and the broad design are described in much
+ * more detail in lib/alarms/index.js.
+ *
+ * We use YAML because of its reasonable support of strings with embedded
+ * newlines.  These probe template files contain both ordinary configuration
+ * (that could be specified in JSON as well as anything else) and a bunch of
+ * human-readable strings (each containing potentially a few paragraphs) that
+ * are closely associated with that configuration.  These files are not used by
+ * tools outside this repository, so the format can be changed in the future.
+ *
+ * Each probe template MUST contain these top-level properties:
+ *
+ *    "event"                   a unique, FMA-style event class name.  This
+ *    (required string)         ultimately defines a probe group.  All probes
+ *                              created from this template will be part of the
+ *                              same probe group (and there will be no other
+ *                              probes in this probe group).
+ *
+ *    "scope"                   describes the set of components that this
+ *    (required object)         probe template is intended to monitor, as well
+ *                              as how to distribute probes for those components
+ *
+ *        "scope.service"       identifies the SAPI service being monitored.
+ *        (required string)     In most cases, this template will generate an
+ *                              Amon probe for each instance of the specified
+ *                              service.
+ *
+ *        "scope.global"        if true, then instead of creating a probe for
+ *        (optional boolean)    each instance of the SAPI service indicated by
+ *                              "scope.service" (which would all be non-global
+ *                              zones), the system creates probes for every
+ *                              global zone that hosts those instance.
+ *
+ *        "scope.checkFrom"     if specified, this field identifies the SAPI
+ *        (optional string)     service for which probes will be created.  That
+ *                              would normally be the same as "scope.service",
+ *                              but in some cases, we monitor one service using
+ *                              probes associated with another.  For example, we
+ *                              monitor each storage zone with probes associated
+ *                              with nameservice zones.
+ *
+ *                              Specifying this causes a probe to be generated
+ *                              for each instance of "scope.service" for each
+ *                              instance of "scope.checkFrom".  That is, it's
+ *                              O(m * n) probes, where "m" and "n" are the
+ *                              numbers of instances of the two services.
+ *                              Generally, one or both of these services should
+ *                              have a fixed, small number of instances (like
+ *                              "nameservice" or "ops"), rather than both being
+ *                              services that are intended to scale to large
+ *                              numbers (like "webapi").
+ *
+ *    "checks"                  array of objects describing Amon probes to
+ *    (required array)          create.  There will be one Amon probe generated
+ *                              for each "check".  There must be at least one
+ *                              check.
+ *
+ *        "checks[i].type"      See Amon probe's "type" field.
+ *        (required string)
+ *
+ *        "checks[i].config"    See Amon probe's "config" field.
+ *        (required object)
+ *
+ *                              The "type" and "config" properties of each check
+ *                              are the same as for the corresponding properties
+ *                              of Amon probes, except that we only support a
+ *                              limited subset of types, and we support an
+ *                              additional "config" property: probes of type
+ *                              "cmd" may specify the special property:
+ *
+ *        "checks[i].config.autoEnv"    If specified, then this should
+ *        (optional array of strings)   be an array of SAPI metadata variables.
+ *                                      These metadata variables will be made
+ *                                      available in the process environment of
+ *                                      the command that runs as part of the
+ *                                      probe.  That means you can use them in
+ *                                      the probe's script.
+ *
+ *                                      When this property is specified on
+ *                                      supported probes, the "env" property of
+ *                                      the probe is filled in with the current
+ *                                      values of the specified SAPI metadata,
+ *                                      and the "autoEnv" property itself is not
+ *                                      passed through to Amon.
+ *
+ *    "ka"                      Specified knowledge article content.  This is
+ *    (required object)         prose text intended for operators trying to
+ *                              understand an open alarm.
+ *
+ *        "ka.title"            A very short summary of the problem.  This
+ *        (required string)     should fit comfortably in about 30 columns of
+ *                              text.
+ *
+ *        "ka.severity"         The severity of the problem, which must be one
+ *        (required string)     of the following:
+ *
+ *                                  "critical"  the data path or jobs path
+ *                                              may be significantly affected or
+ *                                              may be imminently so.
+ *                                              "Affected" here means increased
+ *                                              error rate or latency for end
+ *                                              user operations.
+ *
+ *                                  "major"     the data path or jobs path may
+ *                                              be affected, but the impact is
+ *                                              likely minor or limited to a
+ *                                              small number of requests.  Even
+ *                                              if not currently affected, these
+ *                                              paths are at risk for a major
+ *                                              disruption.
+ *
+ *                                  "minor"     the data path and jobs path are
+ *                                              likely not currently affected
+ *                                              (not more than a bounded, fixed
+ *                                              number of requests).
+ *
+ *                                  The severity is also used to determine the
+ *                                  Amon contacts applied to the probe group.
+ *                                  The specific contacts for each severity
+ *                                  level are contained in the top-level
+ *                                  configuration file.
+ *
+ *        "ka.description"      A summary of the problem in more detail than
+ *        (required string)     "ka.title".
+ *
+ *        "ka.response"         A description of any automated response taken by
+ *        (required string)     the system in response to this event.
+ *
+ *        "ka.impact"           A description of the impact to the system of
+ *        (required string)     this event.  This is a good place to describe
+ *                              how this event affects the error rate, latency,
+ *                              or anything else that's affected by this event.
+ *
+ *        "ka.action"           A description of actions recommended for the
+ *        (required string)     operator.
+ *
+ * To summarize, an Amon probe is created for each element of "checks" for each
+ * instance of SAPI service "scope.service".   If "scope.checkFrom" is
+ * specified, then all of _those_ probes are created for each instance of
+ * the "checkFrom" service.
+ *
+ * Probe templates MAY also contain these top-level properties
+ *
+ *    "legacyName"              a string describing the legacy mantamon
+ *    (string)                  probe names that correspond to the probes
+ *                              for this template.  This is currently not used
+ *                              by anything, but is potentially useful for
+ *                              readers to understand the history of particular
+ *                              templates.
+ */
+
+var assertplus = require('assert-plus');
+var fs = require('fs');
+var jsprim = require('jsprim');
+var jsyaml = require('js-yaml');
+var path = require('path');
+var vasync = require('vasync');
+var VError = require('verror');
+
+var services = require('../services');
+
+/* Exported interface */
+exports.loadMetadata = loadMetadata;
+exports.probeGroupNameForTemplate = probeGroupNameForTemplate;
+exports.MetadataLoader = MetadataLoader;
+
+/* Exposed for testing only */
+exports.testingParseProbeGroupName = parseProbeGroupName;
+
+/*
+ * Concurrency with which we load probe template files.
+ */
+var PTS_CONCURRENCY_FILES = 10;
+
+/*
+ * Load all of the probe template metadata from the specified directory.
+ *
+ * Named arguments include:
+ *
+ *     directory	path to directory containing all probe template files
+ *     (string)
+ *
+ * "callback" is invoked upon completion as callback(err, metadata).
+ */
+function loadMetadata(args, callback)
+{
+	var mdl;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.directory, 'args.directory');
+
+	mdl = new MetadataLoader();
+	mdl.loadFromDirectory(args.directory, function onLoadDone() {
+		var error = VError.errorFromList(mdl.errors());
+		callback(error, error === null ? mdl.mdl_amoncfg : null);
+	});
+}
+
+/*
+ * An instance of MantaAmonMetadata represents the local metadata associated
+ * with probes and probe groups.  This is the primary exposed interface from
+ * this module, though objects are only exposed through the loading interfaces.
+ * (Outside consumers cannot create instances of this class directly.)
+ */
+function MantaAmonMetadata()
+{
+	/* Probe group information keyed by the configured event name. */
+	this.mam_templates_byevent = {};
+
+	/*
+	 * A single template can be used to define multiple probe groups with
+	 * the service name filled into the event name, which makes it different
+	 * for each service.  For example, the "SMF maintenance" template
+	 * has a scope of "each", which causes us to create one probe group per
+	 * distinct service.  The event name in the template is:
+	 *
+	 *     upset.manta.$service.smf_maintenance
+	 *
+	 * This creates one event per distinct service, which look like:
+	 *
+	 *     upset.manta.postgres.smf_maintenance
+	 *     upset.manta.moray.smf_maintenance
+	 *     ...
+	 *
+	 * To be able to recognize these expanded names, we expand them as we
+	 * process each template and store aliases here.
+	 */
+	this.mam_event_aliases = {};
+}
+
+
+/*
+ * Public interfaces: for all callers
+ */
+
+/*
+ * Public interface to return the knowledge article for an event called
+ * "eventName".  Returns null if there is no knowledge article registered for
+ * this event.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.eventKa = function eventKa(eventName)
+{
+	var resolved = this.resolveEventName(eventName);
+	if (resolved === null) {
+		return (null);
+	}
+
+	return (this.mam_templates_byevent[resolved].pt_ka);
+};
+
+/*
+ * Iterate the probe group events represented in this metadata.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.eachEvent = function (func)
+{
+	jsprim.forEachKey(this.mam_templates_byevent, function (evt, pt) {
+		if (pt.pt_aliases.length === 0) {
+			func(evt);
+		}
+	});
+
+	jsprim.forEachKey(this.mam_event_aliases, function (alias) {
+		func(alias);
+	});
+};
+
+
+/*
+ * Semi-private interfaces: for other files in this directory.
+ */
+
+/*
+ * Iterate all registered probe templates.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.eachTemplate = function (func)
+{
+	jsprim.forEachKey(this.mam_templates_byevent, function (_, pt) {
+		func(pt);
+	});
+};
+
+/*
+ * Given a probe group with name "probeGroupName", return the string name of the
+ * event that is emitted when an alarm for this group fires.  This is primarily
+ * useful for passing to the eventKa() function to get the knowledge article
+ * associated with this probe group.  This function returns null if the event
+ * name is unknown or not applicable (because it's an operator-created probe
+ * group or the like).
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.probeGroupEventName =
+    function probeGroupEventName(probeGroupName)
+{
+	var result;
+
+	result = parseProbeGroupName(probeGroupName);
+	if (result.error !== null || result.isLegacy || result.isOther) {
+		return (null);
+	}
+
+	assertplus.string(result.eventName);
+	return (result.eventName);
+};
+
+/*
+ * Given a probe group with name "probeGroupName", determine whether it should
+ * be removed as part of a configuration update operation.  See the block
+ * comment at the top of this file for an explanation of why we mark different
+ * types of groups for removal.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.probeGroupIsRemovable =
+    function probeGroupIsRemovable(probeGroupName)
+{
+	var result, eventName;
+
+	result = parseProbeGroupName(probeGroupName);
+	if (result.error !== null || result.isOther) {
+		return (false);
+	}
+
+	if (result.isLegacy) {
+		return (true);
+	}
+
+	assertplus.string(result.eventName);
+	eventName = this.resolveEventName(result.eventName);
+	return (eventName === null);
+};
+
+
+/*
+ * Private interfaces: for this file only
+ */
+
+/*
+ * Private interface to load a probe template into this data structure.  This
+ * normally comes from the probe template files checked into this repository,
+ * though the test suite can use this to load specific templates.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.addTemplate = function addTemplate(args)
+{
+	var inp, eventName, pt, error, nsubs;
+	var self = this;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.input, 'args.input');
+	assertplus.string(args.originLabel, 'args.originLabel');
+
+	inp = args.input;
+	eventName = inp.event;
+
+	if (this.mam_templates_byevent.hasOwnProperty(eventName)) {
+		return (new VError('%s: re-uses event name "%s" previously ' +
+		    'used in template "%s"', args.originLabel, eventName,
+		    this.mam_templates_byevent[eventName].pt_origin_label));
+	}
+
+	pt = new ProbeTemplate({
+	    'input': inp,
+	    'originLabel': args.originLabel
+	});
+
+	if (pt.pt_scope.ptsc_service != 'each') {
+		if (/[^a-zA-Z0-9_.]/.test(eventName)) {
+			return (new VError('%s: event name contains ' +
+			    'unsupported characters', args.originLabel));
+		}
+
+		this.mam_templates_byevent[eventName] = pt;
+		return (null);
+	}
+
+	this.mam_templates_byevent[eventName] = pt;
+
+	/*
+	 * Generate per-service aliases for probe groups that generate more than
+	 * one event name.
+	 */
+	nsubs = 0;
+	error = null;
+	services.mSvcNamesProbes.forEach(function (svcname) {
+		var fmasvcname;
+
+		/*
+		 * For FMA event names, we adopt the convention of using
+		 * underscores instead of dashes.  We need to translate service
+		 * names accordingly.
+		 */
+		assertplus.ok(svcname !== 'marlin');
+		fmasvcname = svcname.replace(/-/g, '_');
+
+		/*
+		 * We support certain limited expansions within the FMA event
+		 * name.  Each expansion is an ASCII string beginning with '$',
+		 * followed by an alphabetic character or "_", followed by any
+		 * number of alphanumeric characters or "_".  This is perhaps
+		 * simplistic, but because these fields are otherwise plaintext,
+		 * there's nothing else to confuse the interpretation here
+		 * (e.g., quoted strings or escape characters).  Note that the
+		 * use of '$' or '$3' or the like will work fine, though a
+		 * literal string like $ABC that is not intended to be expanded
+		 * will not work.  This would be a little strange for an FMA
+		 * event name.
+		 */
+		var aliasname = pt.pt_event.replace(
+		    /\$([a-zA-Z_][a-zA-Z0-9_]*)/g,
+		    function onMatch(substr, varname) {
+			assertplus.equal('$' + varname, substr);
+			if (varname == 'service') {
+				nsubs++;
+				return (fmasvcname);
+			}
+
+			if (error === null) {
+				error = new VError('template "%s": unknown ' +
+				    'variable "%s" in event name',
+				    pt.pt_origin_label, substr);
+			}
+
+			return ('INVALID');
+		    });
+
+
+		if (/[^a-zA-Z0-9_.]/.test(aliasname)) {
+			if (error === null) {
+				error = new VError('%s: expanded event name ' +
+				    'contains unsupported characters: "%s"',
+				    args.originLabel, aliasname);
+			}
+		} else {
+			pt.pt_aliases.push({
+			    'pta_event': aliasname,
+			    'pta_service': svcname
+			});
+		}
+	});
+
+	if (error === null && nsubs === 0) {
+		return (new VError('template "%s": templates with scope ' +
+		    '"each" must use "$service" in event name to ensure ' +
+		    'uniqueness', pt.pt_origin_label));
+	}
+
+	if (error !== null) {
+		return (error);
+	}
+
+	pt.pt_aliases.forEach(function (alias) {
+		assertplus.ok(!self.mam_event_aliases.hasOwnProperty(
+		    alias.pta_event), 'duplicate alias: ' + alias.pta_event);
+		self.mam_event_aliases[alias.pta_event] = pt.pt_event;
+	});
+
+	return (null);
+};
+
+/*
+ * Resolve an event name that may be an alias to the underlying event name.
+ * Returns null if this event is not known in this metadata.
+ *
+ * See above for allowed callers.
+ */
+MantaAmonMetadata.prototype.resolveEventName = function (eventName)
+{
+	if (this.mam_event_aliases.hasOwnProperty(eventName)) {
+		assertplus.ok(this.mam_templates_byevent.hasOwnProperty(
+		    this.mam_event_aliases[eventName]));
+		return (this.mam_event_aliases[eventName]);
+	}
+
+	if (this.mam_templates_byevent.hasOwnProperty(eventName)) {
+		return (eventName);
+	}
+
+	return (null);
+};
+
+
+var schemaProbeTemplateFile = {
+    'type': 'array',
+    'required': true,
+    'items': {
+	'type': 'object',
+	'additionalProperties': false,
+	'properties': {
+	    'event': {
+	        'type': 'string',
+		'required': true,
+		'minLength': 'upset.manta.'.length
+	    },
+	    'legacyName': { 'type': 'string' },
+	    'scope': {
+		'type': 'object',
+		'required': true,
+		'additionalProperties': false,
+		'properties': {
+		    'service': {
+		        'type': 'string',
+			'required': true,
+			'enum': [ 'each', 'all' ].concat(
+			    services.mSvcNamesProbes)
+		    },
+		    'global': {
+			'type': 'boolean'
+		    },
+		    'checkFrom': {
+		        'type': 'string',
+			'enum': services.mSvcNamesProbes
+		    }
+		}
+	    },
+	    'checks': {
+		'type': 'array',
+		'required': true,
+		'minItems': 1,
+		'items': {
+		    'type': 'object',
+		    'additionalProperties': false,
+		    'properties': {
+			'type': {
+			    'type': 'string',
+			    'enum': [
+			        'bunyan-log-scan',
+				'cmd',
+				'disk-usage',
+				'log-scan'
+			    ]
+			},
+			'config': {
+			    'type': 'object'
+			}
+		    }
+		}
+	    },
+	    'ka': {
+		'type': 'object',
+		'required': true,
+		'additionalProperties': false,
+		'properties': {
+		    'title': { 'type': 'string', 'required': true },
+		    'description': { 'type': 'string', 'required': true },
+		    'severity': { 'type': 'string', 'required': true },
+		    'response': { 'type': 'string', 'required': true },
+		    'impact': { 'type': 'string', 'required': true },
+		    'action': { 'type': 'string', 'required': true }
+		}
+	    }
+	}
+    }
+};
+
+
+/*
+ * This class is used as a struct, with details private to this subsystem.
+ * The fields here closely mirror those in the probe template schema.  For
+ * details, see the documentation for that.
+ *
+ * The constructor takes arguments in the form as it comes out of the the
+ * YAML-parsed files.  These structures should have already been validated.
+ */
+function ProbeTemplate(args)
+{
+	var self = this;
+	var inp;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.input, 'args.input');
+	assertplus.string(args.originLabel, 'args.originLabel');
+
+	inp = args.input;
+
+	/*
+	 * The origin label is a string describing the source of this template.
+	 * It's generally a filename and potentially an index into the templates
+	 * listed in the file.  This is used in error messages that result from
+	 * building a configuration based on this template.
+	 */
+	this.pt_origin_label = args.originLabel;
+
+	/* FMA-style event class for this probe template. */
+	this.pt_event = inp.event;
+
+	/*
+	 * The scope object describes which components this probe monitors (and
+	 * potentially from which other components, if those are different).
+	 */
+	this.pt_scope = {};
+	this.pt_scope.ptsc_service = inp.scope.service;
+	this.pt_scope.ptsc_global = (inp.scope.global === true);
+	this.pt_scope.ptsc_check_from = inp.scope.checkFrom || null;
+
+	this.pt_checks = [];
+	inp.checks.forEach(function (c) {
+		var cc;
+
+		cc = {};
+		cc.ptc_type = c.type;
+		cc.ptc_config = jsprim.deepCopy(c.config);
+		self.pt_checks.push(cc);
+	});
+
+	this.pt_ka = {};
+	this.pt_ka.ka_title = inp.ka.title;
+	this.pt_ka.ka_description = inp.ka.description;
+	this.pt_ka.ka_severity = inp.ka.severity;
+	this.pt_ka.ka_response = inp.ka.response;
+	this.pt_ka.ka_impact = inp.ka.impact;
+	this.pt_ka.ka_action = inp.ka.action;
+	this.pt_aliases = [];
+}
+
+
+/*
+ * Represents the operation of loading a bunch of probe templates from
+ * configuration files.
+ */
+function MetadataLoader()
+{
+	/* problems encountered during load */
+	this.mdl_load_errors = [];
+
+	/* probe templates found */
+	this.mdl_amoncfg = new MantaAmonMetadata();
+
+	/* for debugging only */
+	this.mdl_load_pipeline = null;
+}
+
+/*
+ * Read YAML files in "directory" and load them.  Invokes "callback" upon
+ * completion.  Errors and warnings are not passed to the callback.  See the
+ * separate public methods for accessing those.
+ */
+MetadataLoader.prototype.loadFromDirectory =
+    function loadFromDirectory(directory, callback)
+{
+	var files;
+	var queue;
+
+	assertplus.string(directory, 'directory');
+	assertplus.func(callback, 'callback');
+
+	this.mdl_load_pipeline = vasync.pipeline({
+	    'arg': this,
+	    'funcs': [
+		function listDirectory(self, subcallback) {
+			fs.readdir(directory,
+			    function onReaddirDone(err, entries) {
+				if (err) {
+					err = new VError(err, 'readdir "%s"',
+					    directory);
+					self.mdl_load_errors.push(err);
+					subcallback();
+					return;
+				}
+
+				files = entries.filter(function (e) {
+					return (jsprim.endsWith(e, '.yaml'));
+				}).map(function (e) {
+					return (path.join(directory, e));
+				});
+
+				subcallback();
+			    });
+		},
+
+		function readFiles(self, subcallback) {
+			if (self.mdl_load_errors.length > 0) {
+				setImmediate(subcallback);
+				return;
+			}
+
+			queue = vasync.queuev({
+			    'concurrency': PTS_CONCURRENCY_FILES,
+			    'worker': function loadQueueCallback(f, qcallback) {
+				self.loadFromFile(f, qcallback);
+			    }
+			});
+
+			files.forEach(function (f) { queue.push(f); });
+			queue.on('end', function () { subcallback(); });
+			queue.close();
+		}
+	    ]
+	}, function (err) {
+		/*
+		 * Errors should be pushed onto mdl_load_errors, not emitted
+		 * here.
+		 */
+		assertplus.ok(!err);
+		callback();
+	});
+};
+
+/*
+ * Read a single YAML file and load it.  Invokes "callback" upon completion.
+ * Like loadFromDirectory(), errors and warnings are not passed to the callback,
+ * but recorded for later.
+ */
+MetadataLoader.prototype.loadFromFile =
+    function loadFromFile(filename, callback)
+{
+	var self = this;
+	var readoptions;
+
+	assertplus.string(filename, 'filename');
+	assertplus.func(callback, 'callback');
+
+	readoptions = { 'encoding': 'utf8' };
+	fs.readFile(filename, readoptions, function (err, contents) {
+		if (err) {
+			err = new VError(err, 'read "%s"', filename);
+			self.mdl_load_errors.push(err);
+		} else {
+			self.loadFromString(contents, filename);
+		}
+
+		callback();
+	});
+};
+
+MetadataLoader.prototype.loadFromString =
+    function loadFromString(contents, inputlabel)
+{
+	var parsed, err;
+	var self = this;
+
+	assertplus.string(contents, 'contents');
+	assertplus.string(inputlabel, 'inputlabel');
+
+	try {
+		parsed = jsyaml.safeLoad(contents, {
+		    'filename': inputlabel
+		});
+	} catch (ex) {
+		err = new VError(ex, 'parse "%s"', inputlabel);
+		self.mdl_load_errors.push(err);
+		return;
+	}
+
+	err = jsprim.validateJsonObject(schemaProbeTemplateFile, parsed);
+	if (err instanceof Error) {
+		err = new VError(err, 'parse "%s"', inputlabel);
+		self.mdl_load_errors.push(err);
+		return;
+	}
+
+	parsed.forEach(function (p, i) {
+		var label, error, k;
+
+		label = inputlabel + ': probe ' + (i + 1);
+
+		/*
+		 * We require event names to begin with "upset.manta."
+		 */
+		if (!jsprim.startsWith(p.event, 'upset.manta.')) {
+			self.mdl_load_errors.push(new VError(
+			    '%s: field "event": must begin with "upset.manta."',
+			    label));
+			return;
+		}
+
+		/*
+		 * In order to format the various messages, it's
+		 * important that they be consistent with respect to
+		 * trailing newlines.  It's easy to get this wrong in
+		 * YAML, so we check for it here.
+		 */
+		for (k in p.ka) {
+			if (jsprim.endsWith(p.ka[k], '\n')) {
+				error = new VError('%s: field ka.%s: ' +
+				    'ends with trailing newline',
+				    label, k);
+				break;
+			}
+		}
+
+		if (!error) {
+			error = self.mdl_amoncfg.addTemplate({
+			    'input': p,
+			    'originLabel': label
+			});
+		}
+
+		if (error) {
+			self.mdl_load_errors.push(error);
+		}
+	});
+};
+
+MetadataLoader.prototype.errors = function ()
+{
+	return (this.mdl_load_errors.slice());
+};
+
+/*
+ * List of unversioned probe group names used by previous versions of this
+ * software.
+ */
+var MAM_LEGACY_PROBEGROUP_NAMES = [
+    'authcache-alert',
+    'compute-alert',
+    'electric-moray-alert',
+    'jobsupervisor-alert',
+    'loadbalancer-alert',
+    'moray-alert',
+    'nameservice-alert',
+    'ops-alert',
+    'ops-info',
+    'postgres-alert',
+    'storage-alert',
+    'webapi-alert'
+];
+
+/*
+ * Probe group names
+ *
+ * Probe templates are defined in the source code configuration.  Each template
+ * is expected to correspond to a distinct failure mode.  There may be more than
+ * one probe group for each template, depending on the scope.  These probe
+ * groups need to have names, and those names link them to the metadata we have
+ * (i.e., the knowledge articles).  To do this, we use FMA-style event names
+ * (e.g., upset.manta.$service.$problem).  Since this information will be
+ * programmatically parsed, we want to include a version number.  Together, we
+ * construct the probe group name for a given template by taking the FMA-style
+ * event name, substituting the service name if requested, and appending a
+ * version suffix.
+ *
+ * Given an arbitrary probe group name, we can classify it into one of a few
+ * buckets:
+ *
+ *    - If it matches one of the well-known probe groups used by previous
+ *      versions of this software, we call that "legacy".  We don't have
+ *      metadata about these groups, and they should be removed if we're making
+ *      updates to the probe configuration.
+ *
+ *    - Otherwise, if we cannot find the ";v=" suffix, then we assume this not a
+ *      probe created by this software.  This is likely something operators
+ *      created.  We'll generally leave these alone.
+ *
+ *    - Otherwise, if we find the suffix, but the version is newer than one we
+ *      recognize, then we'll not touch this probe group.  In the future, if we
+ *      decide to change the encoding (e.g., to include additional information
+ *      in the probe group name), then we can do so as long as we preserve a
+ *      ";v=" suffix with a new version number.
+ *
+ *    - Finally, if we find an acceptable version suffix, then this is a probe
+ *      group that we know how to manage.
+ *
+ * See the block comment at the top of this file for details on these different
+ * kinds of probe groups.
+ */
+
+function probeGroupNameForTemplate(pt, eventname)
+{
+	assertplus.object(pt, 'pt');
+	assertplus.string(eventname, 'eventname');
+	return (eventname + ';v=1');
+}
+
+function parseProbeGroupName(probeGroupName)
+{
+	var result, i, verpart;
+
+	result = {};
+	result.error = null;		/* failure to parse (bad version) */
+	result.isLegacy = null;		/* from "mantamon" era */
+	result.isOther = null;		/* operator-created */
+	result.eventName = null;	/* software-created, versioned era */
+
+	if (MAM_LEGACY_PROBEGROUP_NAMES.indexOf(probeGroupName) != -1) {
+		result.isLegacy = true;
+		result.isOther = false;
+		return (result);
+	}
+
+	result.isLegacy = false;
+	i = probeGroupName.indexOf(';');
+	if (i == -1 || probeGroupName.substr(i + 1, 2) != 'v=') {
+		result.isOther = true;
+		return (result);
+	}
+
+	result.isOther = false;
+	verpart = probeGroupName.substr(i + 3);
+	if (verpart != '1') {
+		result.error = new VError('unrecognized version "%s" in ' +
+		    'probe group with name "%s"', verpart, probeGroupName);
+		return (result);
+	}
+
+	result.eventName = probeGroupName.slice(0, i);
+	return (result);
+}
diff --git a/lib/alarms/update.js b/lib/alarms/update.js
new file mode 100644
index 0000000..7f383b6
--- /dev/null
+++ b/lib/alarms/update.js
@@ -0,0 +1,1338 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/alarms/update.js: facilities for updating a deployed set of Amon probes
+ * and probe groups.  This module builds on the facilities provided by
+ * config.js.
+ */
+
+var assertplus = require('assert-plus');
+var jsprim = require('jsprim');
+var vasync = require('vasync');
+var VError = require('verror');
+var extsprintf = require('extsprintf');
+
+var fprintf = extsprintf.fprintf;
+var sprintf = extsprintf.sprintf;
+
+var services = require('../services');
+
+var alarm_metadata = require('./metadata');
+var alarm_config = require('./config');
+
+/* Exported interface */
+exports.amonUpdatePlanCreate = amonUpdatePlanCreate;
+exports.amonUpdatePlanSummarize = amonUpdatePlanSummarize;
+exports.amonUpdatePlanApply = amonUpdatePlanApply;
+
+/*
+ * Amon update plan
+ *
+ * The MantaAmonUpdatePlan class represents a set of probes and probe groups to
+ * be removed and a set of probes and probe groups to be added in order to
+ * update the Amon configuration for the Manta service.
+ */
+function MantaAmonUpdatePlan()
+{
+	/*
+	 * The actual plan is represented by the lists of probes and groups to
+	 * be added and removed.
+	 */
+
+	this.mup_probes_remove = []; 	/* probes to remove */
+	this.mup_groups_remove = []; 	/* probe groups to remove */
+	this.mup_groups_add = []; 	/* groups to add */
+	this.mup_probes_add = []; 	/* probes to add */
+
+	/*
+	 * Statistics kept about the update
+	 */
+
+	/* count of probe groups that were deployed and wanted */
+	this.mup_ngroupsmatch = 0;
+	/* count of probes that were deployed and wanted */
+	this.mup_nprobesmatch = 0;
+	/* count of probes ignored because they were orphans */
+	this.mup_nprobesorphan = 0;
+	/* count of probe groups that were deployed, unwanted, but kept */
+	this.mup_ngroupsignore = 0;
+
+	/*
+	 * Counts of probes added and removed and agents affected, by group id.
+	 */
+
+	this.mup_nadd_bygroup = {};
+	this.mup_nremove_bygroup = {};
+	this.mup_agents_bygroup = {};
+
+	/* warning messages to display to the operator */
+	this.mup_warnings = [];
+
+	/*
+	 * MantaAmonConfig objects used to generate this plan.
+	 */
+	this.mup_deployed = null;	/* found configuration */
+	this.mup_wanted = null;		/* normal wanted configuration */
+	this.mup_unconfigure = false;	/* unconfigure operation */
+}
+
+/*
+ * This is one of only two methods that may be called from outside of this file.
+ * Returns true if the update plan indicates that any changes need to be made.
+ */
+MantaAmonUpdatePlan.prototype.needsChanges = function ()
+{
+	return (this.mup_groups_remove.length > 0 ||
+	    this.mup_probes_remove.length > 0 ||
+	    this.mup_probes_add.length > 0 ||
+	    this.mup_groups_add.length > 0);
+};
+
+/*
+ * This is one of only two methods that may be called from outside of this file.
+ * Returns a list of Error objects describing problems found constructing the
+ * update plan.  These are generally non-fatal, but should be presented to an
+ * operator.
+ */
+MantaAmonUpdatePlan.prototype.warnings = function ()
+{
+	return (this.mup_warnings.slice(0));
+};
+
+MantaAmonUpdatePlan.prototype.probeUpdate = function (probe, counters, list)
+{
+	var groupid, agent;
+
+	assertplus.string(probe.p_groupid,
+	    'probe has no group id (adding and removing probes ' +
+	    'without groups is not supported');
+	groupid = probe.p_groupid;
+	assertplus.string(probe.p_agent);
+	agent = probe.p_agent;
+
+	if (!counters.hasOwnProperty(groupid)) {
+		counters[groupid] = 0;
+	}
+	counters[groupid]++;
+
+	if (!this.mup_agents_bygroup.hasOwnProperty(groupid)) {
+		this.mup_agents_bygroup[groupid] = {};
+	}
+	this.mup_agents_bygroup[groupid][agent] = true;
+
+	list.push(probe);
+};
+
+MantaAmonUpdatePlan.prototype.groupAdd = function groupAdd(group)
+{
+	this.mup_groups_add.push(group);
+};
+
+MantaAmonUpdatePlan.prototype.groupRemove = function groupRemove(group)
+{
+	this.mup_groups_remove.push(group);
+};
+
+MantaAmonUpdatePlan.prototype.probeAdd = function probeAdd(probe)
+{
+	this.probeUpdate(probe, this.mup_nadd_bygroup, this.mup_probes_add);
+};
+
+MantaAmonUpdatePlan.prototype.probeRemove = function probeRemove(probe)
+{
+	this.probeUpdate(probe, this.mup_nremove_bygroup,
+	    this.mup_probes_remove);
+};
+
+/*
+ * Given information about a current deployment, determine the set of updates to
+ * Amon necessary to update the configuration to what it should be.  See the
+ * block comment in lib/alarms/index.js for a discussion of the goals and
+ * constraints of this operation.
+ *
+ * Named arguments:
+ *
+ *     account            Triton account uuid to use for wanted Amon probes
+ *
+ *     contactsBySeverity object mapping event severity levels to the associated
+ *                        set of amon contacts
+ *
+ *     instances          object mapping instance uuids to InstanceInfo objects
+ *
+ *     instancesBySvc     object mapping SAPI service names to array of instance
+ *                        uuids for instances in this datacenter
+ *
+ *     deployed           MantaAmonConfig object describing the set of probes
+ *                        and probe groups curently deployed
+ *
+ *     metadata           MantaAmonMetadata object describing the set of probes
+ *                        and probe groups that should be deployed
+ *
+ *     unconfigure        if specified, then all probes and probe groups should
+ *                        be removed, rather than updated to what would normally
+ *                        be configured
+ *
+ * This function returns either an Error (on failure) or a MantaAmonUpdatePlan.
+ */
+function amonUpdatePlanCreate(args)
+{
+	var deployed, metadata, wanted, rv;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.contactsBySeverity, 'args.contactsBySeverity');
+	assertplus.object(args.instances, 'args.instances');
+	assertplus.object(args.instancesBySvc, 'args.instancesBySvc');
+	assertplus.object(args.deployed, 'args.deployed');
+	assertplus.ok(args.deployed instanceof alarm_config.MantaAmonConfig);
+	assertplus.object(args.metadata, 'args.metadata');
+	assertplus.bool(args.unconfigure, 'args.unconfigure');
+
+	deployed = args.deployed;
+	metadata = args.metadata;
+	wanted = amonGenerateWanted({
+	    'account': args.account,
+	    'contactsBySeverity': args.contactsBySeverity,
+	    'metadata': metadata,
+	    'instances': args.instances,
+	    'instancesBySvc': args.instancesBySvc
+	});
+
+	if (wanted instanceof Error) {
+		return (new VError(wanted,
+		    'generating wanted amon configuration'));
+	}
+
+	rv = new MantaAmonUpdatePlan();
+	rv.mup_deployed = deployed;
+	rv.mup_wanted = wanted;
+
+	/*
+	 * We don't expect to deploy any probes that don't have probe groups
+	 * associated with them.
+	 */
+	wanted.eachOrphanProbe(function (p) {
+		throw (new VError(
+		    'unexpected orphan probe in "wanted" set'));
+	});
+
+	if (args.unconfigure) {
+		amonUpdatePlanCreateUnconfigure({
+		    'metadata': metadata,
+		    'plan': rv
+		});
+
+		return (rv);
+	}
+
+	/*
+	 * Iterate the "wanted" set and create any probe groups and probes that
+	 * are missing from the "deployed" set.
+	 */
+	wanted.eachProbeGroup(function iterWProbeGroup(wpg) {
+		var pgname, dpg, probesByAgent;
+
+		pgname = wpg.pg_name;
+		dpg = deployed.probeGroupForName(pgname);
+
+		if (dpg !== null) {
+			rv.mup_ngroupsmatch++;
+
+			if (!jsprim.deepEqual(wpg.pg_contacts.slice(0).sort(),
+			    dpg.pg_contacts.slice(0).sort())) {
+				/*
+				 * If the contacts on the probe group differ,
+				 * then notify the user.  We don't have a way to
+				 * update it (see MON-355).  We could remove
+				 * everything, but that would make open alarms
+				 * harder to grok, so we ask the operator to do
+				 * that.
+				 */
+				rv.mup_warnings.push(new VError('probe group ' +
+				    'with name "%s" (deployed with uuid %s): ' +
+				    'contacts do not match expected.',
+				    pgname, dpg.pg_user));
+			}
+
+			if (wpg.pg_user != dpg.pg_user) {
+				/*
+				 * This is theoretically similar to the
+				 * "contacts" case above, but there's no way the
+				 * user account should ever change, even with a
+				 * reconfiguration.  We'll just ignore that
+				 * these are different (but let the operator
+				 * know).
+				 */
+				rv.mup_warnings.push(new VError('probe group ' +
+				    'with name "%s" (deployed with uuid %s): ' +
+				    'user does not match expected',
+				    pgname, dpg.pg_user));
+			}
+		} else {
+			rv.groupAdd(wpg);
+		}
+
+		/*
+		 * In order to tell which probes need to be added and removed,
+		 * we need to be able to match up probes that are deployed with
+		 * probes that are wanted.  For our purposes, we will consider
+		 * a deployed probe and a wanted probe equivalent if they have
+		 * the same value for all of the immutable, configurable fields
+		 * that we expect not to change: the probe group name, "type",
+		 * "config", "agent", and "machine".  We'll warn if "contacts"
+		 * or "groupEvents" don't match what we expect.  If a new
+		 * version of the software changes the configuration (e.g., by
+		 * changing the bash script executed or the frequency of
+		 * execution), the deployed and wanted probes won't match, and
+		 * we'll end up removing the deployed one and adding the wanted
+		 * one.
+		 *
+		 * In order to keep this search relatively efficient, we first
+		 * build a list of probes for each agent for this probe group.
+		 * This should generally correspond to the list of checks
+		 * configured in the local metadata.  That's usually just one
+		 * probe, but might be a handful.
+		 */
+		probesByAgent = {};
+		if (deployed.hasProbeGroup(pgname)) {
+			deployed.eachProbeGroupProbe(pgname,
+			    function iterDProbe(p) {
+				if (!probesByAgent.hasOwnProperty(p.p_agent)) {
+					probesByAgent[p.p_agent] = [];
+				}
+
+				probesByAgent[p.p_agent].push(p);
+			    });
+		}
+
+		wanted.eachProbeGroupProbe(pgname, function iterWProbe(wp) {
+			var agent, dprobes, i, dp;
+
+			/*
+			 * Try to find a match for this wanted probe in the list
+			 * of deployed probes for the same agent.
+			 */
+			agent = wp.p_agent;
+			if (!probesByAgent.hasOwnProperty(agent)) {
+				rv.probeAdd(wp);
+				return;
+			}
+
+			dprobes = probesByAgent[agent];
+			for (i = 0; i < dprobes.length; i++) {
+				dp = dprobes[i];
+				if (dp.p_type == wp.p_type &&
+				    jsprim.deepEqual(dp.p_config,
+				    wp.p_config) &&
+				    dp.p_machine == wp.p_machine) {
+					break;
+				}
+			}
+
+			if (i == dprobes.length) {
+				rv.probeAdd(wp);
+				return;
+			}
+
+			/*
+			 * We've found a match, but if it differs in fields we
+			 * would never expect to change, warn the administrator.
+			 */
+			rv.mup_nprobesmatch++;
+			if (wp.p_group_events != dp.p_group_events ||
+			    (dp.p_contacts === null &&
+			    wp.p_contacts !== null) ||
+			    (dp.p_contacts !== null &&
+			    wp.p_contacts === null) ||
+			    (dp.p_contacts !== null &&
+			    !jsprim.deepEqual(dp.p_contacts.slice(0).sort(),
+			    wp.p_contacts.slice(0).sort()))) {
+				rv.mup_warnings.push(new VError('probe group ' +
+				    '"%s" (deployed with uuid "%s"): probe ' +
+				    'for agent "%s": found match that ' +
+				    'differs in "groupEvents" or "contacts"',
+				    pgname, dpg.pg_uuid, agent));
+			}
+
+
+			/*
+			 * Since we've found a match, there's no action to take
+			 * for this probe.  Remove the entry for the deployed
+			 * probe so that we can identify all of the deployed
+			 * probes that weren't wanted by just iterating what's
+			 * left.  This also prevents us from re-using the same
+			 * deployed probe to match multiple wanted probes, but
+			 * that shouldn't be possible anyway.
+			 */
+			if (dprobes.length == 1) {
+				assertplus.equal(i, 0);
+				delete (probesByAgent[agent]);
+			} else {
+				dprobes.splice(i, 1);
+			}
+		});
+
+		/*
+		 * Remove whatever deployed probes did not match any of the
+		 * wanted probes.  We only create each agent's array when we're
+		 * going to add to it, and we delete the array entirely when we
+		 * would remove its last element, so each array we find here
+		 * should be non-empty.
+		 */
+		jsprim.forEachKey(probesByAgent, function (agent, dprobes) {
+			assertplus.ok(dprobes.length > 0);
+			dprobes.forEach(function (p) {
+				rv.probeRemove(p);
+			});
+		});
+	});
+
+	/*
+	 * Now iterate the "deployed" set and remove probes and probe groups
+	 * that are both unwanted and eligible for removal.
+	 */
+	deployed.eachProbeGroup(function iterDProbeGroup(dpg) {
+		var pgname;
+
+		pgname = dpg.pg_name;
+		if (wanted.probeGroupForName(pgname) !== null) {
+			/*
+			 * This group was handled when we iterated the wanted
+			 * probe groups.
+			 */
+			return;
+		}
+
+		if (!metadata.probeGroupIsRemovable(pgname)) {
+			rv.mup_ngroupsignore++;
+			return;
+		}
+
+		rv.groupRemove(dpg);
+		deployed.eachProbeGroupProbe(pgname, function iterDProbe(p) {
+			rv.probeRemove(p);
+		});
+	});
+
+	deployed.eachOrphanProbe(function (p) {
+		rv.mup_nprobesorphan++;
+	});
+
+	return (rv);
+}
+
+/*
+ * Given information about deployed VMs and CNs and the local metadata about
+ * which probes are to be deployed to which types of components, construct a
+ * MantaAmonConfig that represents the desired set of Amon configuration.
+ */
+function amonGenerateWanted(args)
+{
+	var contactsBySeverity, wanted, errors, error;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.contactsBySeverity, 'args.contactsBySeverity');
+	assertplus.object(args.instances, 'args.instances');
+	assertplus.object(args.instancesBySvc, 'args.instancesBySvc');
+	assertplus.object(args.metadata, 'args.metadata');
+
+	contactsBySeverity = args.contactsBySeverity;
+	wanted = new alarm_config.MantaAmonConfig();
+	errors = [];
+
+	args.metadata.eachTemplate(function iterMetadataEvent(pt) {
+		var sev;
+
+		sev = pt.pt_ka.ka_severity;
+		if (!contactsBySeverity.hasOwnProperty(sev)) {
+			/*
+			 * Since we construct contactsBySeverity in lib/adm.js,
+			 * it's a bug either there or in metadata validation if
+			 * we encounter a probe template with an unknown
+			 * severity level.
+			 */
+			throw (new VError(
+			    'no contacts defined by caller for alarms with ' +
+			    'severity level "%s" (used in %s)', sev,
+			    pt.pt_origin_label));
+		}
+
+		amonGenerateWantedTemplate({
+		    'account': args.account,
+		    'contacts': contactsBySeverity[sev].slice(0),
+		    'instances': args.instances,
+		    'instancesBySvc': args.instancesBySvc,
+		    'wanted': wanted,
+		    'probeTemplate': pt,
+		    'errors': errors
+		});
+	});
+
+	error = VError.errorFromList(errors);
+	return (error !== null ? error : wanted);
+}
+
+function amonGenerateWantedTemplate(args)
+{
+	var events, eventForSvc;
+	var instances, instancesBySvc, pt, wanted, errors;
+
+	assertplus.object(args, 'args');
+	assertplus.string(args.account, 'args.account');
+	assertplus.arrayOfString(args.contacts, 'args.contacts');
+	assertplus.object(args.instances, 'args.instances');
+	assertplus.object(args.instancesBySvc, 'args.instancesBySvc');
+	assertplus.object(args.wanted, 'args.wanted');
+	assertplus.ok(args.wanted instanceof alarm_config.MantaAmonConfig);
+	assertplus.object(args.probeTemplate, 'args.probeTemplate');
+	assertplus.arrayOfObject(args.errors, 'args.errors');
+
+	instances = args.instances;
+	instancesBySvc = args.instancesBySvc;
+	pt = args.probeTemplate;
+	wanted = args.wanted;
+	errors = args.errors;
+
+	eventForSvc = {};
+	if (pt.pt_scope.ptsc_service == 'each') {
+		assertplus.ok(pt.pt_aliases.length > 0);
+		events = [];
+		pt.pt_aliases.forEach(function (alias) {
+			events.push(alias.pta_event);
+			eventForSvc[alias.pta_service] =
+			    alias.pta_event;
+		});
+	} else if (pt.pt_scope.ptsc_service == 'all') {
+		assertplus.ok(pt.pt_aliases.length === 0);
+		events = [ pt.pt_event ];
+		jsprim.forEachKey(instancesBySvc, function (svcname) {
+			if (services.serviceSupportsProbes(svcname)) {
+				eventForSvc[svcname] = pt.pt_event;
+			}
+		});
+	} else if (pt.pt_scope.ptsc_check_from !== null) {
+		assertplus.ok(pt.pt_aliases.length === 0);
+		events = [ pt.pt_event ];
+		eventForSvc[pt.pt_scope.ptsc_check_from] = pt.pt_event;
+	} else {
+		assertplus.ok(pt.pt_aliases.length === 0);
+		events = [ pt.pt_event ];
+		eventForSvc[pt.pt_scope.ptsc_service] = pt.pt_event;
+	}
+
+	events.forEach(function (eventName) {
+		var pgname, error;
+		pgname = alarm_metadata.probeGroupNameForTemplate(
+		    pt, eventName);
+
+		/*
+		 * Undeployed probe groups have no uuid yet.  However, it's
+		 * useful for other code to be able to organize data structures
+		 * by probe group id.  (They could use probe group names, but
+		 * it's not required that probe groups have names, even though
+		 * we do require that for our own groups.  Additionally,
+		 * sometimes it's useful to organize by probe group uuid even
+		 * before a name is known, as when enumerating a bunch of
+		 * probes, some of which may even belong to probe groups that no
+		 * longer exist, and all we have about them is the uuid.)
+		 *
+		 * So it's perhaps dicey, but we just fake up a uuid that
+		 * matches the name.  We guarantee elsewhere that probe group
+		 * names are unique among our own probe groups.
+		 */
+		error = wanted.addProbeGroup({
+		    'uuid': pgname,
+		    'name': pgname,
+		    'user': args.account,
+		    'contacts': args.contacts,
+		    'disabled': false
+		});
+
+		/*
+		 * The only reasons that addProbeGroup can fail are because we
+		 * constructed an invalid probe group or one with a duplicate
+		 * uuid or name.  That would indicate a bug in this code.
+		 */
+		if (error !== null) {
+			assertplus.ok(error instanceof Error);
+			throw (error);
+		}
+	});
+
+	jsprim.forEachKey(eventForSvc, function (svcname, eventName) {
+		var targets, checkers, probeargs, gzs;
+
+		if (!instancesBySvc.hasOwnProperty(svcname)) {
+			/*
+			 * We have no locally deployed zones for whatever
+			 * service we would deploy these probes.  This is likely
+			 * to happen if someone is deploying probes in a
+			 * partially-deployed Manta, or if this is a
+			 * multi-datacenter deployment where some services are
+			 * only in a subset of datacenters.  There's nothing
+			 * wrong with this; we just have no probes to deploy
+			 * here.
+			 */
+			return;
+		}
+
+		checkers = instancesBySvc[svcname];
+
+		if (pt.pt_scope.ptsc_global) {
+			/*
+			 * If "global" was specified on the scope, then this
+			 * probe targets not the zones for the specified
+			 * service, but all global zones where this service
+			 * runs.  There may be more than one instance on each
+			 * CN, so we need to deduplicate this list.
+			 */
+			gzs = {};
+			checkers.forEach(function (c) {
+				assertplus.ok(instances.hasOwnProperty(c));
+				assertplus.ok(instances[c].inst_local);
+				assertplus.string(
+				    instances[c].inst_server_uuid);
+				gzs[instances[c].inst_server_uuid] = true;
+			});
+			checkers = Object.keys(gzs);
+		}
+
+		if (pt.pt_scope.ptsc_check_from !== null) {
+			if (!instancesBySvc.hasOwnProperty(
+			    pt.pt_scope.ptsc_check_from)) {
+				return;
+			}
+
+			targets = instancesBySvc[pt.pt_scope.ptsc_service];
+			probeargs = [];
+			checkers.forEach(function (c) {
+				targets.forEach(function (t) {
+					/*
+					 * We might expect the machine to be the
+					 * "target" here, but amon does not
+					 * allow that for probes of type "cmd",
+					 * and it's not all that meaningful here
+					 * anyway.
+					 */
+					probeargs.push({
+					    'agent': c,
+					    'machine': c,
+					    'target': t
+					});
+				});
+			});
+		} else {
+			probeargs = checkers.map(function (c) {
+				return ({
+				    'agent': c,
+				    'machine': c,
+				    'target': c
+				});
+			});
+		}
+
+		probeargs.forEach(function (p) {
+			pt.pt_checks.forEach(function (check, i) {
+				var conf, probe, label, md, error;
+
+				conf = jsprim.deepCopy(check.ptc_config);
+				probe = {
+				    'name': eventName + i,
+				    'type': check.ptc_type,
+				    'config': conf,
+				    'agent': p.agent,
+				    'machine': p.machine,
+				    'group': alarm_metadata.
+				        probeGroupNameForTemplate(
+				        pt, eventName),
+				    'groupEvents': true
+				};
+
+				/*
+				 * Augment probe configurations with information
+				 * from SAPI metadata.
+				 */
+				label = sprintf('probe for group "%s", ' +
+				    'check %d, machine "%s"', probe.group,
+				    i + 1, p.machine);
+				md = instances.hasOwnProperty(p.target) ?
+				    instances[p.target].inst_metadata : null;
+				amonProbePopulateAutoEnv(label, probe, md,
+				    errors);
+
+				/*
+				 * As with the call to addProbeGroup() above,
+				 * the only reasons this can fail would be
+				 * because of bugs in this code.
+				 */
+				error = wanted.addProbe(probe);
+				if (error !== null) {
+					assertplus.ok(error instanceof Error);
+					throw (error);
+				}
+			});
+		});
+	});
+}
+
+/*
+ * For probes of type "cmd", we support a special configuration property called
+ * "autoEnv".  The value of this property is a list of variable names.  We
+ * populate the probe's shell environment with corresponding values from the
+ * corresponding instance's SAPI metadata.
+ */
+function amonProbePopulateAutoEnv(label, probe, metadata, errors)
+{
+	var vars;
+
+	if (probe.type != 'cmd' || !probe.config.hasOwnProperty('autoEnv')) {
+		return;
+	}
+
+	/*
+	 * Remove the autoEnv property itself since Amon doesn't know anything
+	 * about that.
+	 */
+	vars = probe.config.autoEnv;
+	delete (probe.config.autoEnv);
+	if (vars.length === 0) {
+		return;
+	}
+	if (!probe.config.env) {
+		probe.config.env = {};
+	}
+
+	if (metadata === null) {
+		errors.push(new VError('%s: "autoEnv" specified but no ' +
+		    'metadata found for instance', label));
+		return;
+	}
+
+	vars.forEach(function (v) {
+		if (!metadata.hasOwnProperty(v)) {
+			errors.push(new VError('%s: "autoEnv" variable "%s": ' +
+			    'metadata value not found', label, v));
+			return;
+		}
+
+		if (typeof (metadata[v]) != 'string') {
+			errors.push(new VError('%s: "autoEnv" variable "%s": ' +
+			    'metadata value is not a string', label, v));
+			return;
+		}
+
+		probe.config.env[v] = metadata[v];
+	});
+}
+
+/*
+ * Flesh out an update plan that should unconfigure all of the probes and probe
+ * groups that we would normally create.
+ *
+ * Named arguments:
+ *
+ *    plan	the update plan to flesh out
+ *
+ *    metadata	an instanceof MantaAmonMetadata
+ */
+function amonUpdatePlanCreateUnconfigure(args)
+{
+	var metadata, plan, wanted, deployed;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.metadata, 'args.metadata');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.ok(args.plan instanceof MantaAmonUpdatePlan);
+
+	/*
+	 * Unconfiguring isn't quite as simple as it seems.  We want to remove
+	 * probe groups that we would normally have configured, as well as probe
+	 * groups that we would normally remove (because they were created by
+	 * older versions of the software).  But we want to leave in place any
+	 * probes and probe groups created by an operator.
+	 *
+	 * It would be tempting to just create an empty "wanted" configuration
+	 * and then run through the usual update plan generation process, but
+	 * that process relies on knowing which probe groups are considered
+	 * removable (see probeGroupIsRemovable()), and the definition of that
+	 * differs for this case because our normal probe groups are removable
+	 * when unconfiguring, but not otherwise.
+	 */
+	metadata = args.metadata;
+	plan = args.plan;
+	plan.mup_unconfigure = true;
+	wanted = plan.mup_wanted;
+	deployed = plan.mup_deployed;
+	deployed.eachProbeGroup(function iterDProbeGroup(dpg) {
+		var pgname, wpg;
+
+		pgname = dpg.pg_name;
+		wpg = wanted.probeGroupForName(pgname);
+		if (wpg === null &&
+		    !metadata.probeGroupIsRemovable(pgname)) {
+			plan.mup_ngroupsignore++;
+			return (null);
+		}
+
+		plan.groupRemove(dpg);
+		deployed.eachProbeGroupProbe(pgname, function iterDProbe(p) {
+			plan.probeRemove(p);
+		});
+	});
+}
+
+/*
+ * Print a human-readable summary of an update plan.  Named arguments:
+ *
+ *    plan             The update plan to print
+ *
+ *    stream           Node stream to which to write the summary
+ *
+ *    instances        object mapping instance uuids to InstanceInfo objects
+ *
+ *    cns              set of valid CN uuids in this datacenter
+ *
+ *    vmsDestroyed     set of VMs that are destroyed
+ *
+ *    cnsAbandoned     set of CNs hosting VMs that are destroyed (and no active
+ *                     VMs)
+ *
+ *    metadata         An instance of MantaAmonMetadata, used to translate
+ *                     internal names to more useful titles.
+ *
+ *    verbose          If true, print detailed information about probes changed
+ */
+function amonUpdatePlanSummarize(args)
+{
+	var metadata, out, plan, verbose, instances;
+	var nagents, nprobes, ntotagents, ntotprobes, probes;
+	var ntotbefore, ntotafter, delta;
+	var countsByService = {};
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.stream, 'args.stream');
+	assertplus.object(args.metadata, 'args.metadata');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.ok(args.plan instanceof MantaAmonUpdatePlan);
+	assertplus.object(args.instances, 'args.instances');
+	assertplus.object(args.cns, 'args.cns');
+	assertplus.object(args.vmsDestroyed, 'args.vmsDestroyed');
+	assertplus.object(args.cnsAbandoned, 'args.cnsAbandoned');
+	assertplus.bool(args.verbose, 'args.verbose');
+
+	metadata = args.metadata;
+	out = args.stream;
+	plan = args.plan;
+	verbose = args.verbose;
+	instances = args.instances;
+
+	fprintf(out, 'Probe groups to REMOVE: ');
+	if (plan.mup_groups_remove.length === 0) {
+		fprintf(out, 'none\n\n');
+	} else {
+		fprintf(out, '\n\n');
+		fprintf(out, '%7s %7s %s\n', 'NPROBES', 'NAGENTS', 'GROUP');
+		ntotagents = 0;
+		ntotprobes = 0;
+		plan.mup_groups_remove.forEach(function (pg) {
+			assertplus.ok(plan.mup_nremove_bygroup.hasOwnProperty(
+			    pg.pg_uuid));
+			assertplus.ok(!plan.mup_nadd_bygroup.hasOwnProperty(
+			    pg.pg_uuid));
+			nprobes = plan.mup_nremove_bygroup[pg.pg_uuid];
+
+			assertplus.ok(plan.mup_agents_bygroup.hasOwnProperty(
+			    pg.pg_uuid));
+			nagents = Object.keys(plan.mup_agents_bygroup[
+			    pg.pg_uuid]).length;
+
+			fprintf(out, '%7d %7d %s\n',
+			    nprobes, nagents, pg.pg_name);
+
+			ntotprobes += nprobes;
+			ntotagents += nagents;
+		});
+		fprintf(out, '%7d %7d TOTAL\n\n', ntotprobes, ntotagents);
+	}
+
+	fprintf(out, 'Probe groups to ADD: ');
+	if (plan.mup_groups_add.length === 0) {
+		fprintf(out, 'none\n\n');
+	} else {
+		fprintf(out, '\n\n');
+		fprintf(out, '%7s %7s %s\n', 'NPROBES', 'NAGENTS', 'GROUP');
+		ntotagents = 0;
+		ntotprobes = 0;
+		plan.mup_groups_add.forEach(function (pg) {
+			var evt, ka, name;
+
+			assertplus.ok(!plan.mup_nremove_bygroup.hasOwnProperty(
+			    pg.pg_uuid));
+
+			/*
+			 * It's possible that we would create a probe group that
+			 * has no probes.  This likely means there are no
+			 * instances of the zone that this group is associated
+			 * with.  This would usually happen in a multi-DC
+			 * deployment where there happen to be no instances in
+			 * this datacenter.
+			 */
+			if (plan.mup_nadd_bygroup.hasOwnProperty(pg.pg_uuid)) {
+				nprobes = plan.mup_nadd_bygroup[pg.pg_uuid];
+				assertplus.ok(plan.mup_agents_bygroup.
+				    hasOwnProperty(pg.pg_uuid));
+				nagents = Object.keys(plan.mup_agents_bygroup[
+				    pg.pg_uuid]).length;
+			} else {
+				assertplus.ok(!plan.mup_agents_bygroup.
+				    hasOwnProperty(pg.pg_uuid));
+				nprobes = 0;
+				nagents = 0;
+			}
+
+			name = pg.pg_name;
+			evt = metadata.probeGroupEventName(pg.pg_name);
+			if (evt !== null) {
+				ka = metadata.eventKa(evt);
+				if (ka !== null) {
+					name = ka.ka_title;
+				}
+			}
+
+			fprintf(out, '%7d %7d %s\n', nprobes, nagents, name);
+
+			ntotprobes += nprobes;
+			ntotagents += nagents;
+		});
+		fprintf(out, '%7d %7d TOTAL\n\n', ntotprobes, ntotagents);
+	}
+
+	fprintf(out, 'Count of probes by service:\n\n');
+	fprintf(out, '    %-16s  %6s  %6s  %6s\n', 'SERVICE', 'BEFORE', 'AFTER',
+	    'DELTA');
+	services.mSvcNamesProbes.forEach(function (svcname) {
+		countsByService[svcname] = {
+		    'sc_before': 0,
+		    'sc_after': 0
+		};
+	});
+	countsByService['global zones'] = {
+	    'sc_before': 0,
+	    'sc_after': 0
+	};
+	countsByService['destroyed VMs'] = {
+	    'sc_before': 0,
+	    'sc_after': 0
+	};
+	countsByService['abandoned CNs'] = {
+	    'sc_before': 0,
+	    'sc_after': 0
+	};
+
+	ntotbefore = amonUpdatePlanSummarizeConfig({
+	    'config': plan.mup_deployed,
+	    'cns': args.cns,
+	    'countsByService': countsByService,
+	    'instances': instances,
+	    'out': out,
+	    'propname': 'sc_before',
+	    'vmsDestroyed': args.vmsDestroyed,
+	    'cnsAbandoned': args.cnsAbandoned
+	});
+
+	ntotafter = 0;
+	if (!plan.mup_unconfigure) {
+		ntotafter = amonUpdatePlanSummarizeConfig({
+		    'config': plan.mup_wanted,
+		    'cns': args.cns,
+		    'countsByService': countsByService,
+		    'instances': instances,
+		    'out': out,
+		    'propname': 'sc_after',
+		    'vmsDestroyed': args.vmsDestroyed,
+		    'cnsAbandoned': args.cnsAbandoned
+		});
+	}
+
+	jsprim.forEachKey(countsByService, function (svcname, counts) {
+		delta = counts.sc_after - counts.sc_before;
+		fprintf(out, '    %-16s  %6d  %6d  %6s\n', svcname,
+		    counts.sc_before, counts.sc_after,
+		    delta > 0 ? '+' + delta : delta);
+	});
+	delta = ntotafter - ntotbefore;
+	fprintf(out, '    %-16s  %6d  %6d  %6s\n', 'TOTAL',
+	    ntotbefore, ntotafter,
+	    delta > 0 ? '+' + delta : delta);
+	fprintf(out, '\n');
+
+	if (verbose) {
+		fprintf(out, 'Probes to ADD:\n');
+		probes = plan.mup_probes_add.slice(0).sort(function (p1, p2) {
+			var s1, s2, rv;
+
+			s1 = instances[p1.p_agent].inst_svcname;
+			s2 = instances[p2.p_agent].inst_svcname;
+			rv = s1.localeCompare(s2);
+			if (rv !== 0) {
+				return (rv);
+			}
+
+			rv = p1.p_agent.localeCompare(p2.p_agent);
+			if (rv !== 0) {
+				return (rv);
+			}
+
+			/*
+			 * We do not allow our own probes to be nameless.
+			 */
+			assertplus.string(p1.p_name);
+			assertplus.string(p2.p_name);
+			return (p1.p_name.localeCompare(p2.p_name));
+		});
+
+		probes.forEach(function (p) {
+			fprintf(out, '    %s %-16s %s\n', p.p_agent,
+			    instances[p.p_agent].inst_svcname, p.p_name);
+		});
+		fprintf(out, '\n');
+	}
+
+	fprintf(out, 'Summary:\n\n');
+	fprintf(out, '%6d wanted probe groups matched existing groups\n',
+	    plan.mup_ngroupsmatch);
+	fprintf(out, '%6d wanted probes matched existing probes\n',
+	    plan.mup_nprobesmatch);
+	fprintf(out, '%6d probes ignored because they were in no probe group\n',
+	    plan.mup_nprobesorphan);
+	fprintf(out, '%6d probe groups ignored (operator-added)\n',
+	    plan.mup_ngroupsignore);
+	fprintf(out, '%6d total probe groups to remove\n',
+	    plan.mup_groups_remove.length);
+	fprintf(out, '%6d total probes to remove\n',
+	    plan.mup_probes_remove.length);
+	fprintf(out, '%6d total probe groups to add\n',
+	    plan.mup_groups_add.length);
+	fprintf(out, '%6d total probes to add\n', plan.mup_probes_add.length);
+	fprintf(out, '%6d warnings\n\n', plan.mup_warnings.length);
+
+	plan.mup_warnings.forEach(function (w) {
+		fprintf(out, 'warn: %s\n', w.message);
+	});
+}
+
+function amonUpdatePlanSummarizeConfig(args)
+{
+	var config, countsByService, cns, instances, out, propname;
+	var vmsDestroyed, cnsAbandoned;
+	var total = 0;
+
+	assertplus.object(args.config, 'args.config');
+	assertplus.object(args.cns, 'args.cns');
+	assertplus.object(args.instances, 'args.instances');
+	assertplus.object(args.countsByService, 'args.countsByService');
+	assertplus.object(args.vmsDestroyed, 'args.vmsDestroyed');
+	assertplus.object(args.cnsAbandoned, 'args.cnsAbandoned');
+	assertplus.object(args.out, 'args.out');
+	assertplus.string(args.propname, 'args.propname');
+
+	config = args.config;
+	countsByService = args.countsByService;
+	cns = args.cns;
+	cnsAbandoned = args.cnsAbandoned;
+	instances = args.instances;
+	vmsDestroyed = args.vmsDestroyed;
+	out = args.out;
+	propname = args.propname;
+
+	config.eachProbeGroup(function (pg) {
+		config.eachProbeGroupProbe(pg.pg_name, function (p) {
+			var agent, svcname;
+
+			assertplus.string(p.p_agent);
+			agent = p.p_agent;
+			if (instances.hasOwnProperty(agent)) {
+				svcname = instances[agent].inst_svcname;
+			} else if (cns.hasOwnProperty(agent)) {
+				svcname = 'global zones';
+			} else if (vmsDestroyed.hasOwnProperty(agent)) {
+				svcname = 'destroyed VMs';
+			} else if (cnsAbandoned.hasOwnProperty(agent)) {
+				svcname = 'abandoned CNs';
+			} else {
+				fprintf(out, 'warning: probe "%s": agent ' +
+				    '"%s" is not a known VM or CN\n',
+				    p.p_uuid, p.p_agent);
+				return;
+			}
+
+			assertplus.ok(countsByService.hasOwnProperty(svcname));
+			countsByService[svcname][propname]++;
+			total++;
+		});
+	});
+
+	return (total);
+}
+
+/*
+ * Apply the changes described by a MantaUpdatePlan.  This removes old probes
+ * and probe groups and creates new ones to replace them.  This operation is not
+ * atomic, and can wind up in basically any intermediate state.  However, the
+ * broader operation (where we construct the update plan and then apply it) is
+ * idempotent.  In the face of only transient errors, this process can be
+ * re-applied to converge to the desired state.
+ */
+function amonUpdatePlanApply(args, callback)
+{
+	var plan, out, au;
+
+	assertplus.object(args, 'args');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.string(args.account, 'args.account');
+	assertplus.object(args.stream, 'args.stream');
+
+	plan = args.plan;
+	out = args.stream;
+	au = new AmonUpdate(args);
+
+	/*
+	 * We always create probes inside probe groups.  In order to represent
+	 * probes before we've created those probe groups, the "p_groupid"
+	 * property for new probes identifies the name (not uuid) of the group
+	 * they will be in.  (We assume that group names are unique, and this is
+	 * validated elsewhere.)  When we create these probes shortly, we'll
+	 * need to look up the real uuid of the group.  There are two cases:
+	 * either the probe group already exists, in which case we have its uuid
+	 * right now, or the probe group will be created by this process, in
+	 * which case we'll need to record that and use it later.
+	 *
+	 * Here, we collect the names and uuids of probe groups that already
+	 * exist and add them to mau_groups_byname.  As we create new probe
+	 * groups, we'll add their names and uuids to the same structure.  We'll
+	 * consult this when we go create new probes.
+	 */
+	jsprim.forEachKey(au.mau_plan.mup_deployed.mac_probegroups_by_name,
+	    function forEachDeployedProbeGroup(name, group) {
+		au.mau_groups_byname[name] = group.pg_uuid;
+	    });
+
+	/*
+	 * Although Amon may tolerate probes whose groups are missing, we avoid
+	 * creating such a state by processing each of these phases separately.
+	 * Strictly speaking, we only need three phases to do this: remove old
+	 * probes, remove and create probe groups, and create new probes.  It's
+	 * simpler (and not much slower) to split this middle phase.
+	 */
+	fprintf(out, 'Applying changes ... ');
+	vasync.pipeline({
+	    'input': null,
+	    'funcs': [
+		function amonUpdateRemoveProbes(_, subcallback) {
+			amonUpdateQueue(au, plan.mup_probes_remove,
+			    amonUpdateProbeRemove, subcallback);
+		},
+		function amonUpdateRemoveProbeGroups(_, subcallback) {
+			amonUpdateQueue(au, plan.mup_groups_remove,
+			    amonUpdateGroupRemove, subcallback);
+		},
+		function amonUpdateAddProbeGroups(_, subcallback) {
+			amonUpdateQueue(au, plan.mup_groups_add,
+			    amonUpdateGroupAdd, subcallback);
+		},
+		function amonUpdateAddProbes(_, subcallback) {
+			amonUpdateQueue(au, plan.mup_probes_add,
+			    amonUpdateProbeAdd, subcallback);
+		}
+	    ]
+	}, function (err) {
+		fprintf(out, 'done.\n');
+		fprintf(out, 'probes removed: %5d\n', au.mau_nprobes_removed);
+		fprintf(out, 'groups removed: %5d\n', au.mau_ngroups_removed);
+		fprintf(out, 'groups added:   %5d\n', au.mau_ngroups_added);
+		fprintf(out, 'probes added:   %5d\n', au.mau_nprobes_added);
+		callback(err);
+	});
+}
+
+/*
+ * Represents the state associated with a single amon update operation.
+ * This class is used as a struct, with details private to this subsystem.
+ */
+function AmonUpdate(args)
+{
+	assertplus.object(args, 'args');
+	assertplus.object(args.amon, 'args.amon');
+	assertplus.object(args.plan, 'args.plan');
+	assertplus.number(args.concurrency, 'args.concurrency');
+	assertplus.string(args.account, 'args.account');
+
+	this.mau_amon = args.amon;
+	this.mau_concurrency = args.concurrency;
+	this.mau_plan = args.plan;
+	this.mau_account = args.account;
+	this.mau_queues = [];
+	this.mau_errors = [];
+	this.mau_groups_byname = {};
+
+	/* for debugging */
+	this.mau_nprobes_removed = 0;
+	this.mau_ngroups_removed = 0;
+	this.mau_ngroups_added = 0;
+	this.mau_nprobes_added = 0;
+}
+
+/*
+ * Given a worker function, pushes all of the specified inputs through a queue.
+ */
+function amonUpdateQueue(au, tasks, worker, callback)
+{
+	var queue;
+
+	queue = vasync.queuev({
+	    'concurrency': au.mau_concurrency,
+	    'worker': function queueWorker(task, qcallback) {
+		worker(au, task, function onWorkDone(err) {
+			if (err) {
+				au.mau_errors.push(err);
+			}
+
+			qcallback();
+		});
+	    }
+	});
+
+	au.mau_queues.push(queue);
+
+	tasks.forEach(function (t) {
+		queue.push(t);
+	});
+
+	queue.on('end', function () {
+		callback(VError.errorFromList(au.mau_errors));
+	});
+	queue.close();
+}
+
+function amonUpdateProbeAdd(au, probe, callback)
+{
+	var newprobe;
+
+	/*
+	 * We must not have assigned a uuid by this point, but we only create
+	 * probes that have names.
+	 */
+	assertplus.strictEqual(probe.p_uuid, null);
+	assertplus.notStrictEqual(probe.p_name, null);
+	newprobe = {
+	    'name': probe.p_name,
+	    'type': probe.p_type,
+	    'config': probe.p_config,
+	    'agent': probe.p_agent,
+	    'machine': probe.p_machine || undefined,
+	    'contacts': probe.p_contacts,
+	    'groupEvents': probe.p_group_events
+	};
+
+	/*
+	 * By this point in the process, we must have a name -> uuid mapping for
+	 * the group associated with this probe.
+	 */
+	assertplus.ok(au.mau_groups_byname.hasOwnProperty(probe.p_groupid));
+	newprobe.group = au.mau_groups_byname[probe.p_groupid];
+
+	au.mau_amon.createProbe(au.mau_account, newprobe,
+	    function onAmonProbeAdd(err) {
+		if (err) {
+			err = new VError(err, 'add probe "%s"', probe.p_name);
+		} else {
+			au.mau_nprobes_added++;
+		}
+
+		callback(err);
+	    });
+}
+
+function amonUpdateProbeRemove(au, probe, callback)
+{
+	assertplus.string(probe.p_uuid);
+	au.mau_amon.deleteProbe(au.mau_account, probe.p_uuid,
+	    function onAmonProbeRemove(err) {
+		if (err) {
+			err = new VError(err, 'remove probe "%s"',
+			    probe.p_uuid);
+		} else {
+			au.mau_nprobes_removed++;
+		}
+
+		callback(err);
+	    });
+}
+
+function amonUpdateGroupAdd(au, group, callback)
+{
+	var newgroup;
+
+	/*
+	 * Prior to this point, the uuid matches the name.
+	 */
+	assertplus.strictEqual(group.pg_uuid, group.pg_name);
+	newgroup = {
+	    'name': group.pg_name,
+	    'user': group.pg_user,
+	    'contacts': group.pg_contacts
+	};
+
+	assertplus.ok(!au.mau_groups_byname.hasOwnProperty(group.pg_name));
+	au.mau_amon.createProbeGroup(au.mau_account, newgroup,
+	    function onAmonGroupAdd(err, amongroup) {
+		if (!err && typeof (amongroup.uuid) != 'string') {
+			err = new VError('amon returned group with bad or ' +
+			    'missing uuid');
+		}
+
+		if (!err && amongroup.name != group.pg_name) {
+			err = new VError('amon returned group with a ' +
+			    'different name (uuid "%s")', amongroup.uuid);
+		}
+
+		if (err) {
+			err = new VError(err, 'add group "%s"', group.pg_uuid);
+			callback(err);
+			return;
+		}
+
+		assertplus.ok(!au.mau_groups_byname.hasOwnProperty(
+		    group.pg_name));
+		au.mau_groups_byname[group.pg_name] = amongroup.uuid;
+		au.mau_ngroups_added++;
+		callback(err);
+	    });
+}
+
+function amonUpdateGroupRemove(au, group, callback)
+{
+	assertplus.string(group.pg_uuid);
+	au.mau_amon.deleteProbeGroup(au.mau_account, group.pg_uuid,
+	    function onAmonGroupRemove(err) {
+		if (err) {
+			err = new VError(err, 'remove group "%s"',
+			    group.pg_uuid);
+		} else {
+			au.mau_ngroups_removed++;
+		}
+
+		callback(err);
+	    });
+}
diff --git a/lib/common.js b/lib/common.js
index 2d81d1b..48fb6da 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright 2017 Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /*
@@ -15,6 +15,7 @@
 var assert = require('assert-plus');
 var fs = require('fs');
 var path = require('path');
+var restifyClients = require('restify-clients');
 var sdc = require('sdc-clients');
 var vasync = require('vasync');
 var VError = require('verror').VError;
@@ -22,8 +23,6 @@ var VError = require('verror').VError;
 var exec = require('child_process').exec;
 var sprintf = require('util').format;
 
-var Logger = require('bunyan');
-
 
 // -- Global variables
 
@@ -45,6 +44,8 @@ exports.INDEX_SHARDS = 'INDEX_MORAY_SHARDS';
 exports.HASH_RING_IMAGE = 'HASH_RING_IMAGE';
 exports.HASH_RING_IMGAPI_SERVICE = 'HASH_RING_IMGAPI_SERVICE';
 
+exports.CONFIG_FILE_DEFAULT = path.join(__dirname, '..', 'etc', 'config.json');
+
 
 // -- Helper functions
 
@@ -84,22 +85,12 @@ function domainToPath(domain) {
 	return ('/' + domain.split('.').reverse().join('/'));
 }
 
-function initLogger(filename) {
-	var __file = path.basename(filename, '.js');
-	var log = new Logger({
-		name: __file,
-		streams: [
-			{
-				level: 'debug',
-				path: path.join(LOG_DIR, __file + '.log')
-			}
-		],
-		serializers: Logger.stdSerializers
-	});
-
-	return (log);
-}
-
+/*
+ * Note that this function instantiates clients configured according to a config
+ * file relative to the root of this repository.  Some commands accept the
+ * configuration file as a command-line option, but those are not respected
+ * here.  This function should be parametrized.
+ */
 function initSdcClients(cb) {
 	var self = this;
 
@@ -153,6 +144,12 @@ function initSdcClients(cb) {
 			agent: false
 		});
 
+		self.AMON_RAW = restifyClients.createJsonClient({
+			log: self.log,
+			url: config.amon.url,
+			agent: false
+		});
+
 		self.UFDS = new sdc.UFDS({
 			log: self.log,
 			url: config.ufds.url,
@@ -196,6 +193,7 @@ function finiSdcClients(cb) {
 	this.NAPI.close();
 	this.SAPI.close();
 	this.AMON.close();
+	this.AMON_RAW.close();
 	this.UFDS.close(cb);
 }
 
@@ -662,7 +660,6 @@ function sortObjectsByProps(rows, comparators)
 
 exports.shuffle = shuffle;
 exports.domainToPath = domainToPath;
-exports.initLogger = initLogger;
 exports.initSdcClients = initSdcClients;
 exports.finiSdcClients = finiSdcClients;
 exports.getMantaApplication = getMantaApplication;
diff --git a/lib/instance_info.js b/lib/instance_info.js
new file mode 100644
index 0000000..36aa528
--- /dev/null
+++ b/lib/instance_info.js
@@ -0,0 +1,64 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * lib/instance_info.js: represents abstract information about a specific
+ * instance (a VMAPI VM).
+ */
+
+var assertplus = require('assert-plus');
+
+/* Exported interface */
+exports.InstanceInfo = InstanceInfo;
+
+/*
+ * InstanceInfo represents information about a specific instance.  This should
+ * eventually include SAPI and VMAPI information.  This is the abstract object
+ * we should pass around between different subsystems, rather than raw VMAPI and
+ * SAPI objects.  For now, this is only used for the alarms subsystem.
+ */
+function InstanceInfo(args)
+{
+	assertplus.object(args, 'args');
+	assertplus.string(args.uuid, 'args.uuid');
+	assertplus.string(args.svcname, 'args.svcname');
+	assertplus.object(args.metadata, 'args.metadata');
+	assertplus.bool(args.local, 'args.local');
+	assertplus.optionalString(args.server_uuid, 'args.server_uuid');
+
+	if (args.local) {
+		assertplus.string(args.server_uuid, 'args.server_uuid');
+	} else {
+		/*
+		 * There's no way for us to authoritatively know the server_uuid
+		 * for remote instances.  There's a server uuid in the SAPI
+		 * information, but it may be out of date if the VM has been
+		 * migrated or the server's chassis has been swapped or the
+		 * like.  The only authoritative place for this information is
+		 * in the VMAPI data, which we don't have for remote instances.
+		 */
+		assertplus.strictEqual(args.server_uuid, null);
+	}
+
+	/* VM uuid */
+	this.inst_uuid = args.uuid;
+
+	/* SAPI service name to which this instance belongs */
+	this.inst_svcname = args.svcname;
+
+	/* SAPI metadata for this instance */
+	this.inst_metadata = args.metadata;
+
+	/* Boolean indicating whether this instance is in this datacenter. */
+	this.inst_local = args.local;
+
+	/* Server uuid where this VM lives, or "null" for non-local instances */
+	this.inst_server_uuid = args.server_uuid;
+}
diff --git a/lib/services.js b/lib/services.js
index 06cd613..64bf761 100644
--- a/lib/services.js
+++ b/lib/services.js
@@ -27,12 +27,13 @@ exports.ServiceConfiguration = ServiceConfiguration;
 exports.serviceNameIsValid = serviceNameIsValid;
 exports.serviceIsSharded = serviceIsSharded;
 exports.serviceSupportsOneach = serviceSupportsOneach;
+exports.serviceSupportsProbes = serviceSupportsProbes;
 exports.serviceConfigProperties = serviceConfigProperties;
 
 /*
  * Service names deployed by default, in the order they get deployed.  This must
  * be kept in sync with mSvcConfigs below and the various parameters in
- * lib/layout.js
+ * lib/layout.js.
  */
 var mSvcNames = [
     'nameservice',
@@ -57,25 +58,26 @@ var mSvcNames = [
  * manta-oneach to be used with "marlin" zones.
  */
 var mSvcConfigs = {
-    'nameservice':	{ 'oneach': true,  'sharded': false },
-    'postgres':		{ 'oneach': true,  'sharded': true  },
-    'moray':		{ 'oneach': true,  'sharded': true  },
-    'electric-moray':	{ 'oneach': true,  'sharded': false },
-    'storage':		{ 'oneach': true,  'sharded': false },
-    'authcache':	{ 'oneach': true,  'sharded': false },
-    'webapi':		{ 'oneach': true,  'sharded': false },
-    'loadbalancer':	{ 'oneach': true,  'sharded': false },
-    'jobsupervisor':	{ 'oneach': true,  'sharded': false },
-    'jobpuller':	{ 'oneach': true,  'sharded': false },
-    'medusa':		{ 'oneach': true,  'sharded': false },
-    'ops':		{ 'oneach': true,  'sharded': false },
-    'madtom':		{ 'oneach': true,  'sharded': false },
-    'marlin-dashboard':	{ 'oneach': true,  'sharded': false },
-    'marlin':		{ 'oneach': false, 'sharded': false },
-    'propeller':	{ 'oneach': true,  'sharded': false }
+    'nameservice':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'postgres':		{ 'oneach': true,  'probes': true,  'sharded': true  },
+    'moray':		{ 'oneach': true,  'probes': true,  'sharded': true  },
+    'electric-moray':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'storage':		{ 'oneach': true,  'probes': true,  'sharded': false },
+    'authcache':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'webapi':		{ 'oneach': true,  'probes': true,  'sharded': false },
+    'loadbalancer':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'jobsupervisor':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'jobpuller':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'medusa':		{ 'oneach': true,  'probes': true,  'sharded': false },
+    'ops':		{ 'oneach': true,  'probes': true,  'sharded': false },
+    'madtom':		{ 'oneach': true,  'probes': true,  'sharded': false },
+    'marlin-dashboard':	{ 'oneach': true,  'probes': true,  'sharded': false },
+    'marlin':		{ 'oneach': false, 'probes': false, 'sharded': false },
+    'propeller':	{ 'oneach': true,  'probes': false, 'sharded': false }
 };
 
 exports.mSvcNames = mSvcNames;
+exports.mSvcNamesProbes = mSvcNames.filter(serviceSupportsProbes);
 
 /*
  * This is exposed for testing only!  There are functional interfaces for
@@ -281,3 +283,12 @@ function serviceSupportsOneach(svcname)
 	assertplus.ok(serviceNameIsValid(svcname));
 	return (mSvcConfigs[svcname].oneach);
 }
+
+/*
+ * Returns true if the given service can support Amon probes.
+ */
+function serviceSupportsProbes(svcname)
+{
+	assertplus.ok(serviceNameIsValid(svcname));
+	return (mSvcConfigs[svcname].probes);
+}
diff --git a/man/man1/manta-adm.1 b/man/man1/manta-adm.1
index 41a1375..4c464aa 100644
--- a/man/man1/manta-adm.1
+++ b/man/man1/manta-adm.1
@@ -1,9 +1,11 @@
-.TH MANTA\-ADM 1 "2016" Manta "Manta Operator Commands"
+.TH MANTA\-ADM 1 "2017" Manta "Manta Operator Commands"
 .SH NAME
 .PP
 manta\-adm \- administer a Manta deployment
 .SH SYNOPSIS
 .PP
+\fB\fCmanta\-adm alarm SUBCOMMAND... [OPTIONS...]\fR
+.PP
 \fB\fCmanta\-adm cn [\-l LOG_FILE] [\-H] [\-o FIELD...] [\-n] [\-s] CN_FILTER\fR
 .PP
 \fB\fCmanta\-adm genconfig "lab" | "coal"\fR
@@ -26,6 +28,9 @@ deployment.  This command only operates on zones within the same datacenter.
 The command may need to be repeated in other datacenters in order to execute it
 across an entire Manta deployment.
 .TP
+\fB\fCmanta\-adm alarm\fR
+List and configure amon\-based alarms for Manta.
+.TP
 \fB\fCmanta\-adm cn\fR
 Show information about Manta servers in this DC.
 .TP
@@ -121,6 +126,14 @@ Many commands also accept:
 Emit verbose log to LOGFILE.  The special string "stdout" causes output to be
 emitted to the program's stdout.
 .PP
+Commands that make changes support:
+.TP
+\fB\fC\-n, \-\-dryrun\fR
+Print what changes would be made without actually making them.
+.TP
+\fB\fC\-y, \-\-confirm\fR
+Bypass all confirmation prompts.
+.PP
 \fBImportant note for programmatic users:\fP Except as noted below, the output
 format for this command is subject to change at any time. The only subcommands
 whose output is considered committed are:
@@ -133,10 +146,190 @@ whose output is considered committed are:
 \fB\fCmanta\-adm zk list\fR, only when used with the "\-o" option
 .RE
 .PP
-The output for any other commands may change at any time. Documented
+The output for any other commands may change at any time.  The \fB\fCmanta\-adm alarm\fR
+subcommand is still considered an experimental interface.  All other documented
 subcommands, options, and arguments are committed, and you can use the exit
-status of the program to determine success of failure.
+status of the program to determine success or failure.
 .SH SUBCOMMANDS
+.SS "alarm" subcommand
+.PP
+\fB\fCmanta\-adm alarm close ALARM_ID...\fR
+.PP
+\fB\fCmanta\-adm alarm config probegroup list [\-H] [\-o FIELD...]\fR
+.PP
+\fB\fCmanta\-adm alarm config show\fR
+.PP
+\fB\fCmanta\-adm alarm config update [\-n] [\-y] [\-\-unconfigure]\fR
+.PP
+\fB\fCmanta\-adm alarm config verify [\-\-unconfigure]\fR
+.PP
+\fB\fCmanta\-adm alarm details ALARM_ID...\fR
+.PP
+\fB\fCmanta\-adm alarm faults ALARM_ID...\fR
+.PP
+\fB\fCmanta\-adm alarm list [\-H] [\-o FIELD...] [\-\-state=STATE]\fR
+.PP
+\fB\fCmanta\-adm alarm metadata events\fR
+.PP
+\fB\fCmanta\-adm alarm metadata ka [EVENT_NAME...]\fR
+.PP
+\fB\fCmanta\-adm alarm notify on|off ALARM_ID...\fR
+.PP
+\fB\fCmanta\-adm alarm show\fR
+.PP
+The \fB\fCmanta\-adm alarm\fR subcommand provides several tools that allow operators to:
+.RS
+.IP \(bu 2
+view and configure amon probes and probe groups (\fB\fCconfig\fR subcommand)
+.IP \(bu 2
+view open alarms (\fB\fCshow\fR, \fB\fClist\fR, \fB\fCdetails\fR, and \fB\fCfaults\fR subcommands)
+.IP \(bu 2
+configure notifications for open alarms (\fB\fCnotify\fR subcommand)
+.IP \(bu 2
+view local metadata about alarms and probes (\fB\fCmetadata\fR subcommand)
+.RE
+.PP
+The primary commands for working with alarms are:
+.RS
+.IP \(bu 2
+\fB\fCmanta\-adm alarm config update\fR: typically used during initial deployment and
+after other deployment operations to ensure that the right set of probes and
+probe groups are configured for the deployed components
+.IP \(bu 2
+\fB\fCmanta\-adm alarm show\fR: summarize open alarms
+.IP \(bu 2
+\fB\fCmanta\-adm alarm details ALARM_ID...\fR: report detailed information (including
+suggested actions) for the specified alarms
+.IP \(bu 2
+\fB\fCmanta\-adm alarm close ALARM_ID...\fR: close open alarms, indicating that they
+no longer represent issues
+.RE
+.PP
+For background about Amon itself, probes, probegroups, and alarms, see the
+Triton Amon reference documentation.
+.PP
+As with other subcommands, this command only operates on the current Triton
+datacenter.  In multi\-datacenter deployments, alarms are managed separately in
+each datacenter.
+.PP
+Some of the following subcommands can operate on many alarms.  These subcommands
+exit failure if they fail for any of the specified alarms, but the operation may
+have completed successfully for other alarms.  For example, closing 3 alarms is
+not atomic.  If the operation fails, then 1, 2, or 3 alarms may still be open.
+.PP
+\fB\fCmanta\-adm alarm close ALARM_ID...\fR
+.PP
+Close the specified alarms.  These alarms will no longer show up in the
+\fB\fCmanta\-adm alarm list\fR or \fB\fCmanta\-adm alarm show\fR output.  Amon purges closed
+alarms completely after some period of time.
+.PP
+If the underlying issue that caused an alarm is not actually resolved, then a
+new alarm may be opened for the same issue.  In some cases, that can happen
+almost immediately.  In other cases, it may take many hours for the problem to
+resurface.  In the case of transient issues, a new alarm may not open again
+until the issue occurs again, which could be days, weeks, or months later.  That
+does not mean the underlying issue was actually resolved.
+.PP
+\fB\fCmanta\-adm alarm config probegroup list [\-H] [\-o FIELD...]\fR
+.PP
+List configured probe groups in tabular form.  This is primarily useful in
+debugging unexpected behavior from the alarms themselves.  The \fB\fCmanta\-adm alarm
+config show\fR command provides a more useful summary of the probe groups that are
+configured.
+.PP
+\fB\fCmanta\-adm alarm config show\fR
+.PP
+Shows summary information about the probes and probe groups that are configured.
+This is not generally necessary but it can be useful to verify that probes are
+configured as expected.
+.PP
+\fB\fCmanta\-adm alarm config update [\-n] [\-y] [\-\-unconfigure]\fR
+.PP
+Examines the Manta components that are deployed and the alarm configuration
+(specifically, the probes and probe groups deployed to monitor those components)
+and compares them with the expected configuration.  If these do not match,
+prints out a summary of proposed changes to the configuration and optionally
+applies those changes.
+.PP
+If \fB\fC\-\-unconfigure\fR is specified, then the tool removes all probes and probe
+groups.
+.PP
+This is the primary tool for updating the set of deployed probes and probe
+groups.  Operators would typically use this command:
+.RS
+.IP \(bu 2
+during initial deployment to deploy probes and probe groups
+.IP \(bu 2
+after deploying (or undeploying) any Manta components to deploy (or remove)
+probes related to the affected components
+.IP \(bu 2
+after updating the \fB\fCmanta\-adm\fR tool itself, which bundles the probe
+definitions, to deploy any new or updated probes
+.IP \(bu 2
+at any time to verify that the configuration matches what's expected
+.RE
+.PP
+This operation is idempotent.
+.PP
+This command supports the \fB\fC\-n/\-\-dryrun\fR and \fB\fC\-y/\-\-confirm\fR options described
+above.
+.PP
+\fB\fCmanta\-adm alarm config verify [\-\-unconfigure]\fR
+.PP
+Behaves exactly like \fB\fCmanta\-adm alarm config update \-\-dryrun\fR\&.
+.PP
+\fB\fCmanta\-adm alarm details ALARM_ID...\fR
+.PP
+Prints detailed information about any number of alarms.  The detailed
+information includes the time the alarm was opened, the last time an event was
+associated with this alarm, the total number of events associated with the
+alarm, the affected components, and information about the severity, automated
+response, and suggested actions for this issue.
+.PP
+\fB\fCmanta\-adm alarm faults ALARM_ID...\fR
+.PP
+Prints detailed information about the faults associated with any number of
+alarms.  Each fault represents a particular probe failure.  The specific
+information provided depends on the alarm.  If the alarm related to a failed
+health check command, then the exit status, terminating signal, stdout, and
+stderr of the command are provided.  If the alarm relates to an error log entry,
+the contents of the log entry are provided.  There can be many faults associated
+with a single alarm.
+.PP
+\fB\fCmanta\-adm alarm list [\-H] [\-o FIELD...] [\-\-state=STATE]\fR
+.PP
+Lists alarms in tabular form.  \fB\fCSTATE\fR controls which alarms are listed, which
+may be any of "open", "closed", "all", or "recent".  The default is "open".
+.PP
+See also the \fB\fCmanta\-adm alarm show\fR command.
+.PP
+\fB\fCmanta\-adm alarm metadata events\fR
+.PP
+List the names for all of the events known to this version of \fB\fCmanta\-adm\fR\&.  Each
+event corresponds to a distinct kind of problem.  For details about each one,
+see \fB\fCmanta\-adm alarm metadata ka\fR\&.  The list of events comes from metadata
+bundled with the \fB\fCmanta\-adm\fR tool.
+.PP
+\fB\fCmanta\-adm alarm metadata ka [EVENT_NAME...]\fR
+.PP
+Print out knowledge articles about each of the specified events.  This
+information comes from metadata bundled with the \fB\fCmanta\-adm\fR tool.  If no events
+are specified, prints out knowledge articles about all events.
+.PP
+Knowledge articles include information about the severity of the problem, the
+impact, the automated response, and the suggested action.
+.PP
+\fB\fCmanta\-adm alarm notify on|off ALARM_ID...\fR
+.PP
+Enable or disable notifications for the specified alarms.  Notifications are
+generally configured through Amon, which supports both email and XMPP
+notification for new alarms and new events on existing, open alarms.  This
+command controls whether notifications are enabled for the specified alarms.
+.PP
+\fB\fCmanta\-adm alarm show\fR
+.PP
+Summarize open alarms.  For each alarm, use the \fB\fCmanta\-adm alarm details\fR
+subcommand to view more information about it.
 .SS "cn" subcommand
 .PP
 \fB\fCmanta\-adm cn [\-l LOG_FILE] [\-H] [\-o FIELD...] [\-n] [\-s] [CN_FILTER]\fR
@@ -419,20 +612,13 @@ care should be taken when using it with stateful services like "postgres" or
 "storage".  See the Manta Operator's Guide for the appropriate procedures for
 upgrading all components.\fP
 .PP
-Options:
-.TP
-\fB\fC\-n, \-\-dryrun\fR
-Print what changes would be made without actually making them.
-.TP
-\fB\fC\-y, \-\-confirm\fR
-Bypass all confirmation prompts.
+This command supports the \fB\fC\-l/\-\-log_file\fR, \fB\fC\-n/\-\-dryrun\fR, and \fB\fC\-y/\-\-confirm\fR
+options described above, plus:
 .TP
 \fB\fC\-\-no\-reprovision\fR
 When upgrading a zone, always provision a new zone and deprovision the
 previous one, rather than reprovisioning the existing one.
 .PP
-See above for information about the \fB\fC\-l/\-\-log_file\fR option.
-.PP
 If \fB\fCSERVICE\fR is specified, then only instances of the named service are
 changed.
 .PP
@@ -550,15 +736,8 @@ See above for information about the \fB\fC\-l\fR, \fB\fC\-H\fR, and \fB\fC\-o\fR
 ordinal number of each server), "datacenter", "zoneabbr", "zonename", "ip", and
 "port".
 .PP
-The \fB\fCmanta\-adm zk fixup\fR command supports options:
-.TP
-\fB\fC\-n, \-\-dryrun\fR
-Print what changes would be made without actually making them.
-.TP
-\fB\fC\-y, \-\-confirm\fR
-Bypass all confirmation prompts.
-.PP
-It also supports the \fB\fC\-l/\-\-log_file\fR option described above.
+The \fB\fCmanta\-adm zk fixup\fR command supports the \fB\fC\-l/\-\-log_file\fR, \fB\fC\-n/\-\-dryrun\fR,
+and \fB\fC\-y/\-\-confirm\fR options described above.
 .SH EXIT STATUS
 .TP
 \fB\fC0\fR
@@ -571,7 +750,7 @@ Generic failure.
 The command\-line options were not valid.
 .SH COPYRIGHT
 .PP
-Copyright (c) 2016 Joyent Inc.
+Copyright (c) 2017 Joyent Inc.
 .SH SEE ALSO
 .PP
 .BR json (1), 
diff --git a/package.json b/package.json
index 9a7e894..212aa89 100644
--- a/package.json
+++ b/package.json
@@ -16,19 +16,22 @@
         "forkexec": "0.1.0",
         "hogan.js": "2.0.0",
         "imgapi-cli": "git+https://github.com/joyent/sdc-imgapi-cli.git#65bba66818",
-        "jsprim": "0.5.1",
-        "mantamon": "git+https://github.com/joyent/mantamon.git#master",
+        "jsprim": "^1.4.0",
+        "js-yaml": "3.8.2",
         "node-uuid": "1.4.0",
         "optimist": "0.3.5",
         "once": "1.3.0",
         "posix-getopt": "1.2.0",
+        "progbar": "1.1.1",
         "readable-stream": "1.0.26",
+        "restify-clients": "1.5.0",
         "sdc-clients": "git+https://github.com/joyent/node-sdc-clients.git#42ea07d3ca",
         "sprintf-js": "0.0.7",
         "tab": "0.1.0",
         "urclient": "1.0.0",
         "vasync": "1.6.3",
-        "verror": "1.3.7",
+        "verror": "1.10.0",
+        "wordwrap": "1.0.0",
         "zonename": "1.1.0"
     }
 }
diff --git a/test/alarms/mock_amon.js b/test/alarms/mock_amon.js
new file mode 100644
index 0000000..9bbd358
--- /dev/null
+++ b/test/alarms/mock_amon.js
@@ -0,0 +1,195 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * mock_amon.js: implements a mock Amon server
+ */
+
+var assertplus = require('assert-plus');
+var http = require('http');
+var querystring = require('querystring');
+var restifyClients = require('restify-clients');
+var sdc = require('sdc-clients');
+var url = require('url');
+var VError = require('verror');
+
+var account = 'mock-account-uuid';
+var mockAmonPortBase = 20175;
+
+/* Exported interface */
+exports.createMockAmon = createMockAmon;
+exports.account = account;
+
+function createMockAmon(log, callback)
+{
+	var port, mock;
+
+	assertplus.object(log, 'log');
+	assertplus.func(callback, 'callback');
+
+	port = mockAmonPortBase++;
+
+	mock = { 'config': null };
+	mock.log = log;
+	mock.url = 'http://127.0.0.1:' + port;
+	mock.client = new sdc.Amon({
+	    'log': log,
+	    'url': mock.url,
+	    'agent': false
+	});
+
+	mock.clientRaw = restifyClients.createJsonClient({
+	    'log': log,
+	    'url': mock.url,
+	    'agent': false
+	});
+
+	mock.server = http.createServer(
+	    function handleRequest(request, response) {
+		mockAmonHandleRequest(mock.log, mock.config, request, response);
+	    });
+
+	mock.server.listen(port, '127.0.0.1', function () {
+		callback(mock);
+	});
+}
+
+/*
+ * HTTP request handler that implements our mock Amon server.  This only
+ * supports the few requests that we need to implement, and it serves data based
+ * on the contents of the "config" parameter, which comes from the "mock" object
+ * that we gave back to the consumer.  In other words, the consumer controls
+ * exactly what this server serves, and it can change it over time.  Supported
+ * URLs are:
+ *
+ *     GET /agentprobes?agent=AGENT
+ *
+ *          The contents of the response are the JSON-encoded object at
+ *          config.agentprobes[AGENT] (where AGENT comes from the querystring).
+ *          If this value is the special string 'error', then a 500 error is
+ *          returned instead.
+ *
+ *     GET /pub/<account>/alarms?state=STATE
+ *
+ *          The contents of the response are the JSON-encoded object at
+ *          config.alarms[state].  If this value is the special string 'error',
+ *          then a 500 error is returned instead.
+ *
+ *     GET /pub/<account>/alarms/ALARM_ID.
+ *
+ *          The contents of the response are the JSON-encoded object at
+ *          config.alarms.by_id[ALARM_ID].  If this value is the special string
+ *          'error', then a 500 error is returned instead.  If this value is
+ *          missing, a 404 is returned.
+ *
+ *     POST /pub/<account>/alarms/ALARM_ID?action=ACTION
+ *
+ *          Uses the data in config.alarms.by_id[ALARM_ID] to determine whether
+ *          the request should fail with a 500 or 404, just like the similar GET
+ *          on the same path.  Successful requests complete with a 204 and
+ *          record that they happened in "config.alarms_$ACTION".
+ *
+ *     GET /pub/<account>/probegroups
+ *
+ *          The contents of the response are the JSON-encoded object at
+ *          config.groups.  If this value is the special string 'error', then a
+ *          500 error is returned instead.
+ *
+ * Receiving any unsupported request or a request with bad arguments results in
+ * an assertion failure.
+ */
+function mockAmonHandleRequest(log, config, request, response)
+{
+	var parsedurl, params, urlparts, value, code;
+
+	assertplus.object(config, 'config');
+
+	log.debug({
+	    'method': request.method,
+	    'url': request.url
+	}, 'mock amon: handling request');
+
+	code = 200;
+	parsedurl = url.parse(request.url);
+	urlparts = parsedurl.pathname.split('/');
+	if (request.method == 'GET' && urlparts.length == 4 &&
+	    urlparts[0] === '' && urlparts[1] == 'pub' &&
+	    urlparts[2] == account && urlparts[3] == 'probegroups') {
+		value = config.groups;
+	} else if (request.method == 'GET' &&
+	    urlparts.length == 2 && urlparts[0] === '' &&
+	    urlparts[1] == 'agentprobes') {
+		assertplus.object(config.agentprobes);
+		params = querystring.parse(parsedurl.query);
+		assertplus.string(params.agent,
+		    'missing expected amon request parameter: agent');
+		value = config.agentprobes[params.agent];
+		if (value === undefined) {
+			value = [];
+		}
+	} else if (request.method == 'GET' &&
+	    urlparts.length == 4 && urlparts[0] === '' &&
+	    urlparts[1] == 'pub' && urlparts[2] == account &&
+	    urlparts[3] == 'alarms') {
+		assertplus.object(config.alarms);
+		params = querystring.parse(parsedurl.query);
+		assertplus.string(params.state,
+		    'missing expected amon request parameter: state');
+		assertplus.ok(config.alarms[params.state],
+		    'requested alarms for unhandled state: ' + params.state);
+		value = config.alarms[params.state];
+	} else if ((request.method == 'GET' || request.method == 'POST') &&
+	    urlparts.length == 5 && urlparts[0] === '' &&
+	    urlparts[1] == 'pub' && urlparts[2] == account &&
+	    urlparts[3] == 'alarms') {
+		assertplus.object(config.alarms);
+		assertplus.object(config.alarms.by_id);
+
+		if (!config.alarms.by_id[urlparts[4]]) {
+			code = 404;
+		} else if (request.method == 'GET' ||
+		    config.alarms.by_id[urlparts[4]] == 'error') {
+			value = config.alarms.by_id[urlparts[4]];
+		} else {
+			code = 204;
+			assertplus.equal(request.method, 'POST');
+			params = querystring.parse(parsedurl.query);
+			assertplus.string(params.action);
+			config['alarms_' + params.action].push(urlparts[4]);
+		}
+	} else {
+		throw (new VError('unimplemented URL: %s %s',
+		    request.method, request.url));
+	}
+
+	if (code == 404) {
+		response.writeHead(404, {
+		    'content-type': 'application/json'
+		});
+		response.end(JSON.stringify({
+		    'code': 'NotFoundError',
+		    'message': 'alarm not found'
+		}));
+	} else if (code == 204) {
+		response.writeHead(204);
+		response.end();
+	} else if (value == 'error') {
+		response.writeHead(500, {
+		    'content-type': 'application/json'
+		});
+		response.end(JSON.stringify({
+		    'code': 'InjectedError',
+		    'message': 'injected error'
+		}));
+	} else {
+		response.writeHead(code);
+		response.end(JSON.stringify(value));
+	}
+}
diff --git a/test/alarms/tst.alarms.js b/test/alarms/tst.alarms.js
new file mode 100644
index 0000000..3dc0177
--- /dev/null
+++ b/test/alarms/tst.alarms.js
@@ -0,0 +1,539 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.alarms.js: tests interfaces for iterating and updating Amon alarms.
+ * Like the config tests, these use a mock Amon server.  These tests only
+ * exercise the code in lib/alarms/alarms.js that fetch, represent, and modify
+ * alarms.  These interfaces don't use any probe group or probe information, nor
+ * local metadata.
+ */
+
+var assertplus = require('assert-plus');
+var bunyan = require('bunyan');
+var vasync = require('vasync');
+var VError = require('verror');
+
+var alarms = require('../../lib/alarms');
+var mock_amon = require('./mock_amon');
+
+var account = mock_amon.account;
+var alarmsById = {};
+var timestamp = Date.parse('2017-05-03T00:00:00Z');
+var tsiso = new Date(timestamp).toISOString();
+var mockAmon;
+
+function main()
+{
+	var log;
+
+	log = new bunyan({
+	    'name': 'tst.alarms.js',
+	    'level': process.env['LOG_LEVEL'] || 'fatal',
+	    'stream': process.stderr
+	});
+
+	vasync.waterfall([
+		function init(callback) {
+			mock_amon.createMockAmon(log, function (mock) {
+				mockAmon = mock;
+				callback();
+			});
+		},
+
+		function loadFail(callback) {
+			mockAmon.config = { 'alarms': { 'all': 'error' } };
+			alarms.amonLoadAlarmsForState({
+			    'account': account,
+			    'amon': mockAmon.client,
+			    'state': 'all'
+			}, function (err, alarmlist) {
+				assertplus.ok(err);
+				assertplus.ok(err instanceof Error);
+				assertplus.ok(
+				    /listing open alarms: injected error/.test(
+				    err.message));
+				assertplus.ok(!alarmlist);
+				callback();
+			});
+		},
+
+		function loadAlarmsOpen(callback) {
+			mockAmon.config = {
+			    'alarms': { 'open': [
+				alarmsById['35'],
+				alarmsById['40'],
+				/* invalid alarm having no id */
+				{},
+				alarmsById['45'],
+				alarmsById['50'],
+				alarmsById['55']
+			    ] }
+			};
+
+			alarms.amonLoadAlarmsForState({
+			    'account': account,
+			    'amon': mockAmon.client,
+			    'state': 'open'
+			}, function (err, alarmset) {
+				var warnings, list, a, f;
+
+				/*
+				 * As long as "alarmset" is present, then "err"
+				 * only indicates warning-level issues.
+				 */
+				assertplus.ok(err);
+				assertplus.ok(alarmset);
+
+				/*
+				 * Check the warnings.
+				 */
+				warnings = [];
+				VError.errorForEach(err, function (e) {
+					warnings.push(e.message);
+				});
+				warnings.sort();
+
+				assertplus.deepEqual(warnings, [
+				    'bad alarm from server: alarm 45: ' +
+				    'alarm\'s "closed" is not consistent ' +
+				    'with "timeClosed"',
+
+				    'bad alarm from server: property "id": ' +
+				    'is missing and it is required'
+				]);
+
+				/*
+				 * Check the list of alarms itself.
+				 */
+				list = [];
+				alarmset.eachAlarm(function (id, aa) {
+					list.push({ 'id': id, 'alarm': aa });
+				});
+
+				list = list.sort(function (a1, a2) {
+					return (a1.id - a2.id);
+				});
+
+				list.forEach(function (l) {
+					assertplus.ok(l.alarm ==
+					    alarmset.alarmForId(l.id));
+				});
+
+				/*
+				 * Examine the first alarm in detail.
+				 */
+				a = list[0].alarm;
+				assertplus.equal(a.a_id, 35);
+				assertplus.equal(a.a_user, account);
+				assertplus.equal(a.a_groupid, 'group-35');
+				assertplus.strictEqual(a.a_closed, false);
+				assertplus.strictEqual(a.a_suppressed, false);
+				assertplus.equal(a.a_time_opened.toISOString(),
+				    tsiso);
+				assertplus.strictEqual(a.a_time_closed, null);
+				assertplus.equal(a.a_time_last.toISOString(),
+				    tsiso);
+				assertplus.equal(a.a_nevents, 3);
+				assertplus.equal(a.a_faults.length, 1);
+
+				f = a.a_faults[0];
+				assertplus.equal(f.aflt_alarm, a);
+				assertplus.equal(f.aflt_probeid,
+				    'probe-uuid-35');
+				assertplus.strictEqual(f.aflt_clear, false);
+				assertplus.equal(f.aflt_uuid, 'event-uuid-35');
+				assertplus.equal(f.aflt_machine, 'machine-35');
+				assertplus.equal(f.aflt_agent,
+				    'agent-uuid-35');
+				assertplus.equal(f.aflt_agent_alias,
+				    'agent-name-35');
+				assertplus.equal(f.aflt_time.toISOString(),
+				    tsiso);
+				assertplus.equal(f.aflt_summary, 'boom (35)');
+
+				/*
+				 * The second one is largely the same, but has
+				 * no group.
+				 */
+				a = list[1].alarm;
+				assertplus.equal(a.a_id, 40);
+				assertplus.strictEqual(a.a_groupid, null);
+
+				callback();
+			});
+		},
+
+		function loadAlarmsById(callback) {
+			mockAmon.config = {
+			    'alarms': { 'by_id': {
+				'35': alarmsById['35'],
+				'40': alarmsById['40'],
+				'42': 'error',
+				'45': alarmsById['45']
+			    } }
+			};
+
+			/*
+			 * This request exercises several cases, including
+			 * non-integer alarms, duplicate alarm requests, invalid
+			 * alarms from the server, requests that we've
+			 * configured the mock amon to fail with a 500, and
+			 * alarms that don't exist.
+			 */
+			alarms.amonLoadAlarmsForIds({
+			    'account': account,
+			    'amon': mockAmon.client,
+			    'alarmIds': [
+			        '35', '45', '37', 'bogus', '40', '35', '42' ],
+			    'concurrency': 3
+			}, function (err, alarmset) {
+				var warnings, list;
+
+				/*
+				 * As before, there should be an error, but also
+				 * some alarms
+				 */
+				assertplus.ok(err);
+				assertplus.ok(alarmset);
+
+				warnings = [];
+				VError.errorForEach(err, function (e) {
+					warnings.push(e.message);
+				});
+				warnings.sort();
+
+				assertplus.deepEqual(warnings, [
+				    'alarm "bogus": invalid number: "bogus"',
+				    'bad alarm from server: alarm 45: ' +
+					'alarm\'s "closed" is not consistent ' +
+					'with "timeClosed"',
+				    'fetch alarm "37": alarm not found',
+				    'fetch alarm "42": injected error'
+				]);
+
+				list = [];
+				alarmset.eachAlarm(function (id) {
+					list.push(id);
+				});
+				list = list.sort();
+				assertplus.deepEqual(list, [ 35, 40 ]);
+
+				callback();
+			});
+		},
+
+		/*
+		 * Exercise alarm "close".
+		 */
+		function closeAlarms(callback) {
+			mockAmon.config = {
+			    'alarms_close': [],
+			    'alarms': { 'by_id': {
+				'35': alarmsById['35'],
+				'40': alarmsById['40'],
+				'42': 'error'
+			    } }
+			};
+
+			/*
+			 * As above, this request exercises several cases,
+			 * including non-integer alarms, duplicate alarm
+			 * requests, requests that we've configured the mock
+			 * amon to fail with a 500, and alarms that don't exist.
+			 */
+			alarms.amonCloseAlarms({
+			    'account': account,
+			    'amon': mockAmon.client,
+			    'alarmIds': [
+			        '35', '37', 'bogus', '40', '42' ],
+			    'concurrency': 3
+			}, function (err) {
+				var errors;
+
+				assertplus.ok(err);
+				errors = [];
+				VError.errorForEach(err, function (e) {
+					errors.push(e.message);
+				});
+				errors.sort();
+
+				assertplus.deepEqual(errors, [
+				    'alarm "bogus": invalid number: "bogus"',
+				    'close alarm "37": alarm not found',
+				    'close alarm "42": injected error'
+				]);
+
+				assertplus.deepEqual(
+				    mockAmon.config.alarms_close.sort(),
+				    [ '35', '40' ]);
+				callback();
+			});
+		},
+
+		/*
+		 * Exercise alarm notification disable.
+		 */
+		function disableNotifications(callback) {
+			mockAmon.config = {
+			    'alarms_suppress': [],
+			    'alarms': { 'by_id': {
+				'35': alarmsById['35'],
+				'40': alarmsById['40'],
+				'42': 'error'
+			    } }
+			};
+
+			/*
+			 * As above, this request exercises several cases,
+			 * including non-integer alarms, duplicate alarm
+			 * requests, requests that we've configured the mock
+			 * amon to fail with a 500, and alarms that don't exist.
+			 */
+			alarms.amonUpdateAlarmsNotification({
+			    'account': account,
+			    'amonRaw': mockAmon.clientRaw,
+			    'suppressed': true,
+			    'alarmIds': [
+			        '35', '37', 'bogus', '40', '42' ],
+			    'concurrency': 3
+			}, function (err) {
+				var errors;
+
+				assertplus.ok(err);
+				errors = [];
+				VError.errorForEach(err, function (e) {
+					errors.push(e.message);
+				});
+				errors.sort();
+
+				assertplus.deepEqual(errors, [
+				    'alarm "bogus": invalid number: "bogus"',
+				    'disable notifications for alarm 37: ' +
+				        'alarm not found',
+				    'disable notifications for alarm 42: ' +
+				        'injected error'
+				]);
+
+				assertplus.deepEqual(
+				    mockAmon.config.alarms_suppress.sort(),
+				    [ '35', '40' ]);
+				callback();
+			});
+		},
+
+		/*
+		 * Exercise alarm notification enable.
+		 */
+		function enableNotifications(callback) {
+			mockAmon.config = {
+			    'alarms_unsuppress': [],
+			    'alarms': { 'by_id': {
+				'35': alarmsById['35'],
+				'40': alarmsById['40'],
+				'42': 'error'
+			    } }
+			};
+
+			/*
+			 * As above, this request exercises several cases,
+			 * including non-integer alarms, duplicate alarm
+			 * requests, requests that we've configured the mock
+			 * amon to fail with a 500, and alarms that don't exist.
+			 */
+			alarms.amonUpdateAlarmsNotification({
+			    'account': account,
+			    'amonRaw': mockAmon.clientRaw,
+			    'suppressed': false,
+			    'alarmIds': [
+			        '35', '37', 'bogus', '40', '42' ],
+			    'concurrency': 3
+			}, function (err) {
+				var errors;
+
+				assertplus.ok(err);
+				errors = [];
+				VError.errorForEach(err, function (e) {
+					errors.push(e.message);
+				});
+				errors.sort();
+
+				assertplus.deepEqual(errors, [
+				    'alarm "bogus": invalid number: "bogus"',
+				    'enable notifications for alarm 37: ' +
+				        'alarm not found',
+				    'enable notifications for alarm 42: ' +
+				        'injected error'
+				]);
+
+				assertplus.deepEqual(
+				    mockAmon.config.alarms_unsuppress.sort(),
+				    [ '35', '40' ]);
+				callback();
+			});
+		}
+	], function (err) {
+		if (err) {
+			throw (err);
+		}
+
+		mockAmon.server.close();
+		console.log('%s okay', __filename);
+	});
+}
+
+/* normal, complete alarm */
+alarmsById['35'] = {
+    'id': 35,
+    'user': account,
+    'probeGroup': 'group-35',
+    'closed': false,
+    'suppressed': false,
+    'timeOpened': timestamp,
+    'timeClosed': null,
+    'timeLastEvent': timestamp,
+    'numEvents': 3,
+    'faults': [ {
+	    'type': 'probe',
+	    'probe': 'probe-uuid-35',
+	    'event': {
+	    'v': 1,
+	    'type': 'probe',
+	    'clear': false,
+	    'machine': 'machine-35',
+	    'uuid': 'event-uuid-35',
+	    'agent': 'agent-uuid-35',
+	    'agentAlias': 'agent-name-35',
+	    'time': timestamp,
+	    'data': {
+		'message': 'boom (35)'
+	    }
+	}
+    } ]
+};
+
+/* normal alarm having no group */
+alarmsById['40'] = {
+    'id': 40,
+    'user': account,
+    'closed': false,
+    'suppressed': false,
+    'timeOpened': timestamp,
+    'timeClosed': null,
+    'timeLastEvent': timestamp,
+    'numEvents': 3,
+    'faults': [ {
+	'type': 'probe',
+	'probe': 'probe-uuid-40',
+	'event': {
+	    'v': 1,
+	    'type': 'probe',
+	    'clear': false,
+	    'machine': 'machine-40',
+	    'uuid': 'event-uuid-40',
+	    'agent': 'agent-uuid-40',
+	    'agentAlias': 'agent-name-40',
+	    'time': timestamp,
+	    'data': {
+		'message': 'boom (40)'
+	    }
+	}
+    } ]
+};
+
+/* invalid alarm: closed/timeClosed */
+alarmsById['45'] = {
+    'id': 45,
+    'user': account,
+    'closed': true,
+    'suppressed': false,
+    'timeOpened': timestamp,
+    'timeClosed': null,
+    'timeLastEvent': timestamp,
+    'numEvents': 3,
+    'faults': [ {
+	'type': 'probe',
+	'probe': 'probe-uuid-nonexistent',
+	'event': {
+	    'v': 1,
+	    'type': 'probe',
+	    'clear': false,
+	    'machine': 'machine-45',
+	    'uuid': 'event-uuid-45',
+	    'agent': 'agent-uuid-45',
+	    'agentAlias': 'agent-name-45',
+	    'time': timestamp,
+	    'data': {
+		'message': 'boom (45)'
+	    }
+	}
+    } ]
+};
+
+/* alarm with non-existent probe group */
+alarmsById['50'] = {
+    'id': 50,
+    'user': account,
+    'probeGroup': 'unknown-group',
+    'closed': false,
+    'suppressed': false,
+    'timeOpened': timestamp,
+    'timeClosed': null,
+    'timeLastEvent': timestamp,
+    'numEvents': 3,
+    'faults': [ {
+	'type': 'probe',
+	'probe': 'probe-uuid-nonexistent',
+	'event': {
+	    'v': 1,
+	    'type': 'probe',
+	    'clear': false,
+	    'machine': 'machine-50',
+	    'uuid': 'event-uuid-50',
+	    'agent': 'agent-uuid-50',
+	    'agentAlias': 'agent-name-50',
+	    'time': timestamp,
+	    'data': {
+		'message': 'boom (50)'
+	    }
+	}
+    } ]
+};
+
+/* alarm with non-existent probe */
+alarmsById['55'] = {
+    'id': 55,
+    'user': account,
+    'closed': false,
+    'suppressed': false,
+    'timeOpened': timestamp,
+    'timeClosed': null,
+    'timeLastEvent': timestamp,
+    'numEvents': 3,
+    'faults': [ {
+	'type': 'probe',
+	'probe': 'probe-uuid-nonexistent',
+	    'event': {
+	    'v': 1,
+	    'type': 'probe',
+	    'clear': false,
+	    'machine': 'machine-55',
+	    'uuid': 'event-uuid-55',
+	    'agent': 'agent-uuid-55',
+	    'agentAlias': 'agent-name-55',
+	    'time': timestamp,
+	    'data': {
+		'message': 'boom (55)'
+	    }
+	}
+    } ]
+};
+
+main();
diff --git a/test/alarms/tst.amon_objects.js b/test/alarms/tst.amon_objects.js
new file mode 100644
index 0000000..bb3686c
--- /dev/null
+++ b/test/alarms/tst.amon_objects.js
@@ -0,0 +1,678 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.amon_objects.js: tests for Amon object schema and representations
+ */
+
+var assertplus = require('assert-plus');
+var jsprim = require('jsprim');
+var VError = require('verror');
+
+var amon_objects = require('../../lib/alarms/amon_objects');
+
+var testCases;
+
+function main()
+{
+	generateTestCases();
+	testCases.forEach(runTestCase);
+	console.error('%s okay', __filename);
+}
+
+/*
+ * Each test case must have properties:
+ *
+ *    name (string)	name of the test case
+ *
+ *    objtype (string)	one of "probe", "probe group", or "alarm"
+ *
+ *    input (object)	an object as it might be returned from Amon
+ *
+ * plus exactly one of these properties:
+ *
+ *    errmsg (regexp)	a regular expression to be checked against an error
+ *    			resulting from loading the given input object
+ *
+ *    verify (func)	a check function to verify the loaded object
+ */
+function runTestCase(tc)
+{
+	var result, load, errpattern;
+
+	assertplus.object(tc, 'tc');
+	assertplus.string(tc.name, 'tc.name');
+	process.stderr.write('test case: ' + tc.name + ': ');
+	if (tc.input !== null) {
+		assertplus.object(tc.input, 'tc.input');
+	}
+
+	if (tc.hasOwnProperty('errmsg')) {
+		assertplus.ok(!tc.hasOwnProperty('verify'));
+		errpattern = tc.errmsg;
+	} else {
+		assertplus.func(tc.verify, 'tc.verify');
+		errpattern = null;
+	}
+
+	switch (tc.objtype) {
+	case 'alarm':
+		load = amon_objects.loadAlarmObject;
+		break;
+
+	case 'probe':
+		load = amon_objects.loadProbeObject;
+		break;
+
+	case 'probegroup':
+		load = amon_objects.loadProbeGroupObject;
+		break;
+
+	default:
+		throw (new VError('unsupported object type: "%s"', tc.objtype));
+	}
+
+	result = load(tc.input);
+	if (result instanceof Error) {
+		if (errpattern === null) {
+			throw (new VError(result,
+			    'expected no error, but found one'));
+		}
+
+		if (!errpattern.test(result.message)) {
+			throw (new VError(result,
+			    'expected error %s, but found',
+			    JSON.stringify(errpattern.source)));
+		}
+
+		console.error('okay (found expected error)');
+	} else {
+		tc.verify(result);
+		console.error('okay (verified result)');
+	}
+}
+
+function generateTestCases()
+{
+	var validAlarm, validProbeGroup, validProbe, input;
+
+	testCases = [];
+
+	/*
+	 * We'll start with this basic alarm and verify that it gets loaded
+	 * correctly.  Then we'll transform it in various ways to make it
+	 * invalid and make sure that we get the appropriate error message.
+	 */
+	validAlarm = {
+	    'id': 791,
+	    'user': 'martin',
+	    'closed': false,
+	    'suppressed': false,
+	    'timeOpened': Date.parse('2017-04-25T01:23:45.678Z'),
+	    'timeClosed': null,
+	    'timeLastEvent': Date.parse('2017-04-26T09:54:32.876Z'),
+	    'numEvents': 14,
+	    'faults': [ {
+		'type': 'probe',
+		'probe': 'probe-uuid-1',
+		'event': {
+		    'v': 1,
+		    'type': 'probe',
+		    'clear': false,
+		    'machine': 'machine-uuid-1',
+		    'uuid': 'event-uuid-1',
+		    'agent': 'agent-uuid-1',
+		    'agentAlias': 'anAgent1',
+		    'time': Date.parse('2017-04-26T09:54:32.876Z'),
+		    'data': {
+			'message': 'some summary message'
+		    }
+		}
+	    }, {
+		'type': 'probe',
+		'probe': 'probe-uuid-2',
+		'event': {
+		    'v': 1,
+		    'type': 'probe',
+		    'clear': true,
+		    'machine': 'machine-uuid-2',
+		    'uuid': 'event-uuid-2',
+		    'agent': 'agent-uuid-2',
+		    'agentAlias': 'anAgent2',
+		    'time': Date.parse('2017-04-26T08:54:32.876Z'),
+		    'data': {
+			'message': 'a different summary message'
+		    }
+		}
+	    } ]
+	};
+
+	testCases = [ {
+	    'name': 'alarm: basic case',
+	    'objtype': 'alarm',
+	    'input': validAlarm,
+	    'verify': function verifyBasicAlarm(result) {
+		var fault, extras;
+
+		assertplus.strictEqual(result.a_id, 791);
+		assertplus.strictEqual(result.a_user, 'martin');
+		assertplus.strictEqual(result.a_groupid, null);
+		assertplus.strictEqual(result.a_closed, false);
+		assertplus.strictEqual(result.a_suppressed, false);
+		assertplus.strictEqual(result.a_time_opened.toISOString(),
+		    '2017-04-25T01:23:45.678Z');
+		assertplus.strictEqual(result.a_time_closed, null);
+		assertplus.strictEqual(result.a_time_last.toISOString(),
+		    '2017-04-26T09:54:32.876Z');
+		assertplus.strictEqual(result.a_nevents, 14);
+		assertplus.arrayOfObject(result.a_faults);
+		assertplus.strictEqual(result.a_faults.length, 2);
+
+		/*
+		 * If new properties are added to alarm objects, they should be
+		 * tested above and added to the list below.
+		 */
+		extras = jsprim.extraProperties(result, [
+		    'a_id',
+		    'a_user',
+		    'a_groupid',
+		    'a_closed',
+		    'a_suppressed',
+		    'a_time_opened',
+		    'a_time_closed',
+		    'a_time_last',
+		    'a_nevents',
+		    'a_faults'
+		]);
+		assertplus.deepEqual([], extras,
+		    'alarm object has untested properties: ' +
+		    extras.join(','));
+
+		fault = result.a_faults[0];
+		assertplus.ok(fault.aflt_alarm == result);
+		assertplus.strictEqual(fault.aflt_probeid, 'probe-uuid-1');
+		assertplus.strictEqual(fault.aflt_clear, false);
+		assertplus.strictEqual(fault.aflt_uuid, 'event-uuid-1');
+		assertplus.strictEqual(fault.aflt_machine, 'machine-uuid-1');
+		assertplus.strictEqual(fault.aflt_agent, 'agent-uuid-1');
+		assertplus.strictEqual(fault.aflt_agent_alias, 'anAgent1');
+		assertplus.strictEqual(fault.aflt_time.toISOString(),
+		    '2017-04-26T09:54:32.876Z');
+		assertplus.strictEqual(fault.aflt_summary,
+		    'some summary message');
+		assertplus.object(fault.aflt_data);
+
+		/*
+		 * Similarly, if new properties are added to fault objects,
+		 * they should be tested above and added to the list below.
+		 */
+		extras = jsprim.extraProperties(fault, [
+		    'aflt_alarm',
+		    'aflt_probeid',
+		    'aflt_clear',
+		    'aflt_uuid',
+		    'aflt_machine',
+		    'aflt_agent',
+		    'aflt_agent_alias',
+		    'aflt_time',
+		    'aflt_summary',
+		    'aflt_data'
+		]);
+		assertplus.deepEqual([], extras,
+		    'fault object has untested properties: ' +
+		    extras.join(','));
+
+		fault = result.a_faults[1];
+		assertplus.ok(fault.aflt_alarm == result);
+		assertplus.strictEqual(fault.aflt_probeid, 'probe-uuid-2');
+		assertplus.strictEqual(fault.aflt_clear, true);
+		assertplus.strictEqual(fault.aflt_uuid, 'event-uuid-2');
+		assertplus.strictEqual(fault.aflt_machine, 'machine-uuid-2');
+		assertplus.strictEqual(fault.aflt_agent, 'agent-uuid-2');
+		assertplus.strictEqual(fault.aflt_agent_alias, 'anAgent2');
+		assertplus.strictEqual(fault.aflt_time.toISOString(),
+		    '2017-04-26T08:54:32.876Z');
+		assertplus.strictEqual(fault.aflt_summary,
+		    'a different summary message');
+	    }
+	} ];
+
+	/*
+	 * Exercise different values for a valid alarm.
+	 */
+	input = jsprim.deepCopy(validAlarm);
+	input.id = 0;
+	input.suppressed = true;
+	input.closed = true;
+	input.timeClosed = Date.parse('2017-04-27T00:00:00.123Z');
+	testCases.push({
+	    'name': 'alarm: closed and suppressed',
+	    'objtype': 'alarm',
+	    'input': input,
+	    'verify': function (result) {
+		assertplus.strictEqual(result.a_id, 0);
+		assertplus.strictEqual(result.a_suppressed, true);
+		assertplus.strictEqual(result.a_closed, true);
+		assertplus.strictEqual(result.a_time_closed.toISOString(),
+		    '2017-04-27T00:00:00.123Z');
+	    }
+	});
+
+	/*
+	 * For each required property, create a test case that exercises what
+	 * happens when that property is missing.
+	 */
+	[ 'id', 'user', 'closed', 'suppressed', 'timeOpened', 'timeClosed',
+	    'timeLastEvent', 'numEvents', 'faults' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validAlarm);
+		delete (input[prop]);
+		testCases.push({
+		    'name': 'alarm: missing "' + prop + '"',
+		    'objtype': 'alarm',
+		    'input': input,
+		    'errmsg': new RegExp(
+		        'property "' + prop + '": .* missing and.*required')
+		});
+	});
+
+	/*
+	 * "Bad type" test cases.
+	 */
+
+	input = jsprim.deepCopy(validAlarm);
+	input.id = 'one-two-three';
+	testCases.push({
+	    'name': 'alarm: bad "id"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /^property "id": string value found.*integer.*required$/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.user = 47;
+	testCases.push({
+	    'name': 'alarm: bad "user"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "user":.*number.*found.*string.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.user = 47;
+	testCases.push({
+	    'name': 'alarm: bad "user"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "user":.*number.*found.*string.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.probeGroup = {};
+	testCases.push({
+	    'name': 'alarm: bad "probeGroup"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "probeGroup":.*object.*found.*string.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.closed = {};
+	testCases.push({
+	    'name': 'alarm: bad "closed"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "closed":.*object.*found.*bool.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.suppressed = {};
+	testCases.push({
+	    'name': 'alarm: bad "suppressed"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "suppressed":.*object.*found.*bool.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.timeOpened = '2017-04-25T01:23:45.678Z';
+	testCases.push({
+	    'name': 'alarm: bad "timeOpened"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "timeOpened":.*string.*found.*number.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.timeClosed = '2017-04-25T01:23:45.678Z';
+	testCases.push({
+	    'name': 'alarm: bad "timeClosed"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "timeClosed":.*string.*found.*number.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.timeLastEvent = '2017-04-25T01:23:45.678Z';
+	testCases.push({
+	    'name': 'alarm: bad "timeLastEvent"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /"timeLastEvent":.*string.*found.*number.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.numEvents = 'forty-seven';
+	testCases.push({
+	    'name': 'alarm: bad "numEvents"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "numEvents":.*string.*found.*integer.*required/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.faults = 'boom!';
+	testCases.push({
+	    'name': 'alarm: bad "faults"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "faults":.*string.*found.*array.*required/
+	});
+
+	/*
+	 * Bad fault objects: missing required properties.
+	 */
+
+	[ 'type', 'probe', 'event' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validAlarm);
+		delete (input.faults[0][prop]);
+		testCases.push({
+		    'name': 'fault: missing property "' + prop + '"',
+		    'objtype': 'alarm',
+		    'input': input,
+		    'errmsg': new RegExp('property "faults\\[0\\].' + prop +
+		        '".*missing.*required')
+		});
+	});
+
+	[ 'v', 'type', 'clear', 'machine', 'uuid', 'agent', 'agentAlias',
+	    'time', 'data' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validAlarm);
+		delete (input.faults[0].event[prop]);
+		testCases.push({
+		    'name': 'fault: missing property "event.' + prop + '"',
+		    'objtype': 'alarm',
+		    'input': input,
+		    'errmsg': new RegExp('property "faults\\[0\\].event.' +
+		        prop + '".*missing.*required')
+		});
+	});
+
+	/*
+	 * Bad fault objects: bad types for various properties.
+	 */
+
+	[ 'type', 'probe', 'event' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validAlarm);
+		input.faults[0][prop] = 17;
+		testCases.push({
+		    'name': 'fault: bad "' + prop + '"',
+		    'objtype': 'alarm',
+		    'input': input,
+		    'errmsg': new RegExp('property "faults\\[0\\].' + prop +
+		        '": number value found.*required')
+		});
+	});
+
+	[ 'v', 'type', 'clear', 'machine', 'uuid', 'agent', 'agentAlias',
+	    'time' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validAlarm);
+		input.faults[0].event[prop] = {};
+		testCases.push({
+		    'name': 'fault: bad "event.' + prop + '"',
+		    'objtype': 'alarm',
+		    'input': input,
+		    'errmsg': new RegExp('property "faults\\[0\\].event.' +
+		        prop + '": object value found, but .* required')
+		});
+	});
+
+	/*
+	 * Semantically bad alarm objects
+	 */
+
+	input = jsprim.deepCopy(validAlarm);
+	input.faults[0].type = 'other';
+	testCases.push({
+	    'name': 'fault: unsupported "type"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "faults\[0\].type":.*enumeration/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.faults[0].event.type = 'other';
+	testCases.push({
+	    'name': 'fault: unsupported "type"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "faults\[0\].event.type":.*enumeration/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.faults[0].event.v = 2;
+	testCases.push({
+	    'name': 'fault: unsupported version"',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /property "faults\[0\].event.v":.*enumeration/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.faults = [];
+	testCases.push({
+	    'name': 'alarm: open with no faults',
+	    'objtype': 'alarm',
+	    'input': input,
+	    'errmsg': /alarm open with no faults/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.closed = true;
+	testCases.push({
+	    'name': 'alarm: inconsistent close state (1)',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /alarm's "closed" is not consistent with "timeClosed"/
+	});
+
+	input = jsprim.deepCopy(validAlarm);
+	input.timeClosed = input.timeLastEvent;
+	testCases.push({
+	    'name': 'alarm: inconsistent close state (2)',
+	    'objtype': 'alarm',
+	    'input': input,
+	    /* JSSTYLED */
+	    'errmsg': /alarm's "closed" is not consistent with "timeClosed"/
+	});
+
+
+	/*
+	 * Probe group objects
+	 */
+
+	validProbeGroup = {
+	    'uuid': 'uuid-1',
+	    'name': 'honor roller',
+	    'user': 'user-uuid-1',
+	    'disabled': false,
+	    'contacts': [ 'contact1', 'contact2' ]
+	};
+
+	testCases.push({
+	    'name': 'probe group: basic case',
+	    'objtype': 'probegroup',
+	    'input': validProbeGroup,
+	    'verify': function verifyBasicProbeGroup(pg) {
+		assertplus.strictEqual(pg.pg_name, 'honor roller');
+		assertplus.strictEqual(pg.pg_user, 'user-uuid-1');
+		assertplus.strictEqual(pg.pg_uuid, 'uuid-1');
+		assertplus.strictEqual(pg.pg_enabled, true);
+		assertplus.deepEqual(
+		    pg.pg_contacts, [ 'contact1', 'contact2' ]);
+	    }
+	});
+
+	input = jsprim.deepCopy(validProbeGroup);
+	input.disabled = true;
+	delete (input.contacts);
+	testCases.push({
+	    'name': 'probe group: disabled, no contacts',
+	    'objtype': 'probegroup',
+	    'input': input,
+	    'verify': function verifyDisabledProbeGroup(pg) {
+		assertplus.strictEqual(pg.pg_name, 'honor roller');
+		assertplus.strictEqual(pg.pg_user, 'user-uuid-1');
+		assertplus.strictEqual(pg.pg_uuid, 'uuid-1');
+		assertplus.strictEqual(pg.pg_enabled, false);
+		assertplus.deepEqual(pg.pg_contacts, []);
+	    }
+	});
+
+	[ 'uuid', 'name', 'user', 'disabled' ].forEach(
+	    function (prop) {
+		input = jsprim.deepCopy(validProbeGroup);
+		delete (input[prop]);
+		testCases.push({
+		    'name': 'probe group: missing "' + prop + '"',
+		    'objtype': 'probegroup',
+		    'input': input,
+		    'errmsg': new RegExp('property "' + prop + '":.*missing')
+		});
+
+		input = jsprim.deepCopy(validProbeGroup);
+		input[prop] = 37;
+		testCases.push({
+		    'name': 'probe group: bad type for "' + prop + '"',
+		    'objtype': 'probegroup',
+		    'input': input,
+		    'errmsg': new RegExp('property "' + prop +
+		        '": number value found, but.* is required')
+		});
+	    });
+
+	/*
+	 * Probe objects
+	 */
+
+	validProbe = {
+	    'uuid': 'uuid-1',
+	    'name': 'probe-1',
+	    'type': 'cmd',
+	    'config': {},
+	    'agent': 'agent-uuid-1',
+	    'groupEvents': false,
+	    'machine': null,
+	    'group': null,
+	    'contacts': [ 'contact1', 'contact2' ]
+	};
+
+	input = jsprim.deepCopy(validProbe);
+	testCases.push({
+	    'name': 'probe: basic case (1)',
+	    'objtype': 'probe',
+	    'input': input,
+	    'verify': function verifyBasicProbe(p) {
+		assertplus.strictEqual(p.p_uuid, 'uuid-1');
+		assertplus.strictEqual(p.p_name, 'probe-1');
+		assertplus.strictEqual(p.p_type, 'cmd');
+		assertplus.deepEqual(p.p_config, {});
+		assertplus.strictEqual(p.p_agent, 'agent-uuid-1');
+		assertplus.strictEqual(p.p_groupid, null);
+		assertplus.strictEqual(p.p_machine, null);
+		assertplus.deepEqual(p.p_contacts, [ 'contact1', 'contact2' ]);
+		assertplus.strictEqual(p.p_group_events, false);
+	    }
+	});
+
+	/*
+	 * Alternate valid probe: for the remaining tests, we'll use a probe
+	 * representation that more closely matches what we usually see in
+	 * practice: "groupEvents" is true; "machine" and "group" are specified;
+	 * and "contacts" is not.
+	 */
+	validProbe.groupEvents = true;
+	validProbe.machine = 'machine-uuid-1';
+	validProbe.group = 'group-uuid-1';
+	delete (validProbe.contacts);
+
+	input = jsprim.deepCopy(validProbe);
+	testCases.push({
+	    'name': 'probe: basic case (2)',
+	    'objtype': 'probe',
+	    'input': input,
+	    'verify': function verifyAltProbe(p) {
+		assertplus.strictEqual(p.p_uuid, 'uuid-1');
+		assertplus.strictEqual(p.p_name, 'probe-1');
+		assertplus.strictEqual(p.p_type, 'cmd');
+		assertplus.deepEqual(p.p_config, {});
+		assertplus.strictEqual(p.p_agent, 'agent-uuid-1');
+		assertplus.strictEqual(p.p_groupid, 'group-uuid-1');
+		assertplus.strictEqual(p.p_machine, 'machine-uuid-1');
+		assertplus.deepEqual(p.p_contacts, null);
+		assertplus.strictEqual(p.p_group_events, true);
+	    }
+	});
+
+	/*
+	 * Test missing required fields.  Many of the fields that may be "null"
+	 * are still required.
+	 */
+	[ 'type', 'config', 'agent', 'groupEvents', 'machine',
+	    'group' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validProbe);
+		delete (input[prop]);
+		testCases.push({
+		    'name': 'probe: missing prop "' + prop + '"',
+		    'objtype': 'probe',
+		    'input': input,
+		    'errmsg': new RegExp('property "' + prop + '":.*missing')
+		});
+	    });
+
+	[ 'uuid', 'name', 'type', 'config', 'agent', 'groupEvents',
+	    'machine', 'group', 'contacts' ].forEach(function (prop) {
+		input = jsprim.deepCopy(validProbe);
+		input[prop] = 37;
+		testCases.push({
+		    'name': 'probe: bad "' + prop + '"',
+		    'objtype': 'probe',
+		    'input': input,
+		    'errmsg': new RegExp('property "' + prop +
+		        '": number.*found.*required')
+		});
+	    });
+}
+
+main();
diff --git a/test/alarms/tst.config.js b/test/alarms/tst.config.js
new file mode 100644
index 0000000..7262858
--- /dev/null
+++ b/test/alarms/tst.config.js
@@ -0,0 +1,540 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.config.js: tests interfaces for iterating Amon probes and probe groups.
+ * The test cases here do not make use of local metadata -- these just test the
+ * basic interfaces for loading and iterating the objects stored in Amon.
+ * These test cases work by implementing a mock Amon server, serving data that
+ * comes from the test case specification, and then checking what we managed to
+ * load from that server.
+ */
+
+var assertplus = require('assert-plus');
+var bunyan = require('bunyan');
+var vasync = require('vasync');
+var VError = require('verror');
+
+var alarms = require('../../lib/alarms');
+var mock_amon = require('./mock_amon');
+
+var account = mock_amon.account;
+var testCases = [];
+var mockAmon;
+
+function main()
+{
+	var log;
+
+	log = new bunyan({
+	    'name': 'tst.config.js',
+	    'level': process.env['LOG_LEVEL'] || 'fatal',
+	    'stream': process.stderr
+	});
+
+	mock_amon.createMockAmon(log, function (mock) {
+		mockAmon = mock;
+
+		/*
+		 * Run the actual test cases.
+		 */
+		vasync.forEachPipeline({
+		    'inputs': testCases,
+		    'func': runTestCase
+		}, function (err) {
+			if (err) {
+				throw (err);
+			}
+
+			mockAmon.server.close();
+			console.log('%s okay', __filename);
+		});
+	});
+}
+
+/*
+ * Execute a single test case.  Each test case specifies the set of Amon probe
+ * groups and probes that should be returned.  This test runner uses the
+ * interfaces that we're testing to load this data from a mock Amon server and
+ * then calls onLoaded() to verify the results.  Unexpected failures (including
+ * failures of test assertions) result in thrown exceptions.
+ *
+ * The test case object itself contains properties:
+ *
+ *     name		human-readable name of the test
+ *
+ *     components	names and types of each component whose probes should
+ *     			be loaded from Amon.  See amonLoadComponentProbes().
+ *
+ *     amon		used to fill in the mock Amon server's current
+ *     			configuration, which is used by the mock Amon server's
+ *     			request handler.  This is how test cases specify which
+ *     			probe groups and probes should be returned by the mock
+ *     			Amon server.  See mockAmonHandleRequest() for details.
+ *
+ *     onLoaded		function to invoke after all this is done.  This accepts
+ *     			arguments as onLoaded(pgerror, perror, pwarnings,
+ *     			config), where:
+ *
+ *     		pgerror		an optional Error that's present if there
+ *     				were any issues (either warnings or errors)
+ *     				loading probe group information.  If these
+ *     				issues were errors, then the "config" argument
+ *     				will be null.
+ *
+ *     		perror		an optional Error that's present if there were
+ *     				any errors loading probe information.  As long
+ *     				as probe groups were loaded, "config" may still
+ *     				be non-null, but may be missing some probe
+ *     				information.
+ *
+ *     		pwarn		an optional Error that's present if there were
+ *     				any warnings loading probe information.
+ *
+ *     		config		object that represents the loaded probe groups
+ *     				and probes.  See amonLoadProbeGroups().  If this
+ *     				object is present, then we successfully loaded
+ *     				at least some probe groups.  If any of the other
+ *     				arguments is present, then this configuration
+ *     				may be incomplete because of the problems
+ *     				described there.  As long as neither "pgerror"
+ *     				nor "perror" is present, one can expect that
+ *     				this configuration is complete enough to operate
+ *     				on programmatically.
+ */
+function runTestCase(testcase, callback)
+{
+	console.log('test case: %s', testcase.name);
+	assertplus.strictEqual(mockAmon.config, null);
+	mockAmon.config = testcase.amon;
+
+	alarms.amonLoadProbeGroups({
+	    'amon': mockAmon.client,
+	    'account': account
+	}, function (lpgError, lpgConfig) {
+		assertplus.equal(mockAmon.config, testcase.amon);
+
+		if (!lpgConfig) {
+			mockAmon.config = null;
+			testcase.onLoaded(lpgError, null, null, null);
+			callback();
+			return;
+		}
+
+		alarms.amonLoadComponentProbes({
+		    'amonRaw': mockAmon.clientRaw,
+		    'amoncfg': lpgConfig,
+		    'components': testcase.components,
+		    'concurrency': 10
+		}, function (lcpError, lcpWarnings) {
+			assertplus.equal(mockAmon.config, testcase.amon);
+			mockAmon.config = null;
+			testcase.onLoaded(lpgError, lcpError,
+			    lcpWarnings, lpgConfig);
+			callback();
+		});
+	});
+}
+
+/*
+ * Finally, define the actual test cases.
+ */
+
+testCases.push({
+    'name': 'amon 500 error (listing probe groups)',
+    'components': [],
+    'amon': {
+	'groups': 'error',
+	'agentprobes': {}
+    },
+    'onLoaded': function (pgerr, perr, pwarn, config) {
+	assertplus.ok(!perr);
+	assertplus.ok(!pwarn);
+	assertplus.ok(!config);
+	assertplus.ok(pgerr);
+	assertplus.ok(pgerr instanceof Error);
+	assertplus.ok(/listing probegroups:.*injected error/.test(
+	    pgerr.message));
+    }
+});
+
+testCases.push({
+    'name': 'amon 500 error (listing agent probes)',
+    'components': [ { 'type': 'cn', 'uuid': 'c1' } ],
+    'amon': {
+	'groups': [],
+	'agentprobes': { 'c1': 'error', 'c2': [] }
+    },
+    'onLoaded': function (pgerr, perr, pwarn, config) {
+	assertplus.ok(!pgerr);
+	assertplus.ok(!pwarn);
+	assertplus.ok(config);
+	assertplus.ok(perr);
+	assertplus.ok(perr instanceof Error);
+	assertplus.ok(
+	    /* JSSTYLED */
+	    /fetching probes for agent on cn "c1":.*injected error/.test(
+	    perr.message));
+    }
+});
+
+testCases.push({
+    'name': 'empty configuration',
+    'components': [ { 'type': 'cn', 'uuid': 'c1' } ],
+    'amon': {
+	'groups': [],
+	'agentprobes': { 'c1': [] }
+    },
+    'onLoaded': function (pgerr, perr, pwarn, config) {
+	assertplus.ok(!pgerr);
+	assertplus.ok(!perr);
+	assertplus.ok(!pwarn);
+	assertplus.ok(config);
+	assertplus.ok(!config.hasProbeGroup('foobar'));
+	assertplus.strictEqual(config.probeGroupNameForUuid('foobar'), null);
+	assertplus.strictEqual(config.probeGroupForName('foobar'), null);
+
+	config.eachProbeGroup(function () {
+		throw (new Error('unexpected probe group found'));
+	});
+
+	config.eachOrphanProbe(function () {
+		throw (new Error('unexpected orphan probe found'));
+	});
+
+	assertplus.throws(function () {
+	    config.eachProbeGroupProbe('foo', function () {});
+	}, /unknown probe group name/);
+    }
+});
+
+/*
+ * This test case exercises the works: probes on both VMs and CNs, probes with
+ * no probe groups, invalid probes and probe groups, probe groups with duplicate
+ * names, and more.
+ */
+testCases.push({
+    'name': 'complex configuration',
+    'components': [
+	{ 'type': 'cn', 'uuid': 'cn1' },
+	{ 'type': 'vm', 'uuid': 'vm1' }
+    ],
+    'amon': {
+	'groups': [ {
+	    'uuid': 'probe-group-1',
+	    'name': 'group1',
+	    'user': account,
+	    'disabled': false,
+	    'contacts': [ 'contact1' ]
+	}, {
+	    'uuid': 'probe-group-2',
+	    'name': 'group2',
+	    'user': account,
+	    'disabled': false,
+	    'contacts': [ 'contact2' ]
+	}, {
+	    /* exercise warning case: duplicate probe group uuid */
+	    'uuid': 'probe-group-2',
+	    'name': 'group3',
+	    'user': account,
+	    'disabled': false,
+	    'contacts': [ 'contact2' ]
+	}, {
+	    /* exercise warning case: totally invalid probe group */
+	}, {
+	    /* exercise warning case: invalid probe group having a uuid */
+	    'uuid': 'probe-group-bogus'
+	}, {
+	    /* exercise warning case: duplicate probe group name */
+	    'uuid': 'probe-group-3',
+	    'name': 'group2',
+	    'user': account,
+	    'disabled': false,
+	    'contacts': []
+	} ],
+
+	'agentprobes': {
+	    'cn1': [ {
+		'uuid': 'probe-uuid-1',
+		'name': 'cn1-group1-probe1',
+		'group': 'probe-group-1',
+		'user': account,
+		'type': 'cmd',
+		'config': {},
+		'agent': 'cn1',
+		'machine': 'cn1',
+		'groupEvents': true
+	    }, {
+		'uuid': 'probe-uuid-2',
+		'name': 'cn1-group2-probe1',
+		'group': 'probe-group-2',
+		'user': account,
+		'type': 'cmd',
+		'config': {},
+		'agent': 'cn1',
+		'machine': 'cn1',
+		'groupEvents': true
+	    }, {
+		/* exercise warning case: probe for unknown probe group */
+		'uuid': 'probe-uuid-3',
+		'name': 'cn1-group-unknown-probe1',
+		'group': 'probe-group-unknown',
+		'user': account,
+		'type': 'cmd',
+		'config': {},
+		'agent': 'cn1',
+		'machine': 'cn1',
+		'groupEvents': true
+	    }, {
+		/* exercise warning case: totally invalid probe */
+	    } ],
+	    'vm1': [ {
+		'uuid': 'probe-uuid-4',
+		'name': 'vm1-group2-probe1',
+		'group': 'probe-group-2',
+		'user': account,
+		'type': 'cmd',
+		'config': {},
+		'agent': 'vm1',
+		'machine': 'vm1',
+		'groupEvents': true
+	    }, {
+		/* exercise case of probe with no probe group */
+		'uuid': 'probe-uuid-5',
+		'name': 'vm1-nogroup-probe1',
+		'user': account,
+		'type': 'cmd',
+		'config': {},
+		'agent': 'vm1',
+		'machine': 'vm1',
+		'group': null,
+		'groupEvents': true
+	    } ]
+	}
+    },
+
+    'onLoaded': function (pgerr, perr, pwarn, config) {
+	var warnings, pg, found;
+
+	/*
+	 * We'll have a bunch of warnings, but we should end up with a valid
+	 * configuration.  Group all the warnings, sort them by message, and
+	 * check each of the messages.
+	 */
+	assertplus.ok(config);
+	assertplus.ok(!perr);
+
+	warnings = [];
+	VError.errorForEach(pgerr, function (e) { warnings.push(e.message); });
+	VError.errorForEach(pwarn, function (e) { warnings.push(e.message); });
+	warnings = warnings.sort();
+	assertplus.deepEqual(warnings, [
+	    'ignoring group: duplicate probe group name: "group2"',
+	    'ignoring group: duplicate probe group uuid: "probe-group-2"',
+	    'ignoring group: probe group "probe-group-bogus": ' +
+		'property "name": is missing and it is required',
+	    'ignoring group: property "uuid": is missing and it is required',
+	    'ignoring probe: probe "probe-uuid-3": unknown probe group ' +
+	        '"probe-group-unknown"',
+	    'ignoring probe: property "type": is missing and it is required'
+	]);
+
+	/*
+	 * Test hasProbeGroup().
+	 */
+	assertplus.ok(config.hasProbeGroup('group1'));
+	assertplus.ok(config.hasProbeGroup('group2'));
+	assertplus.ok(!config.hasProbeGroup('group3'));
+
+	/*
+	 * Test probeGroupNameForUuid() and probeGroupForName().
+	 */
+	assertplus.strictEqual(
+	    config.probeGroupNameForUuid('probe-group-1'), 'group1');
+	pg = config.probeGroupForName('group1');
+	assertplus.notStrictEqual(pg, null);
+	assertplus.equal(pg.pg_name, 'group1');
+	assertplus.equal(pg.pg_uuid, 'probe-group-1');
+
+	/* The group with a duplicate name should not be present. */
+	assertplus.strictEqual(
+	    config.probeGroupNameForUuid('probe-group-3'), null);
+
+	/*
+	 * Test eachProbeGroup().
+	 */
+	found = [];
+	config.eachProbeGroup(function (fpg) {
+		found.push(fpg);
+	});
+
+	found = found.sort(function (pg1, pg2) {
+		return (pg1.pg_uuid.localeCompare(pg2.pg_uuid));
+	});
+
+	assertplus.equal(found.length, 2);
+	assertplus.ok(pg == found[0]);
+	assertplus.equal(found[1].pg_uuid, 'probe-group-2');
+
+	/*
+	 * Test eachProbeGroupProbe().
+	 */
+	found = [];
+	config.eachProbeGroupProbe('group2', function (p) {
+		assertplus.equal(p.p_groupid, 'probe-group-2');
+		found.push(p.p_uuid);
+	});
+	found = found.sort();
+	assertplus.deepEqual(found, [ 'probe-uuid-2', 'probe-uuid-4' ]);
+
+	/*
+	 * Test eachOrphanProbe().
+	 */
+	found = [];
+	config.eachOrphanProbe(function (p) {
+		found.push(p.p_uuid);
+	});
+	assertplus.deepEqual(found, [ 'probe-uuid-5' ]);
+    }
+});
+
+testCases.push(makeBigTestCase());
+
+/*
+ * Creates a test case that exercises a fairly large configuration.  In
+ * practice, we expect the number of probe groups to remain reasonably bounded
+ * (on the order of 100), but the number of other objects might scale a bunch
+ * higher: CNs (order of 1000) and VMs (order of 1000 per box).  We're not near
+ * these numbers yet, and we'll likely need better interfaces for working with
+ * these objects at that scale.  For now, we set these to be a bit higher than
+ * we expect to see in production.
+ */
+function makeBigTestCase()
+{
+	var ncns = 150;
+	var nvmspercn = 15;
+	var ngroups = 50;
+	var scaleTestCase = {
+	    'name': 'very large config',
+	    'components': [],
+	    'amon': {
+		'groups': [],
+		'agentprobes': {}
+	    },
+	    'onLoaded': function (pgerr, perr, pwarn, config) {
+		var nfound;
+
+		assertplus.ok(!pgerr);
+		assertplus.ok(!perr);
+		assertplus.ok(!pwarn);
+
+		/*
+		 * Sanity-check the configuration.
+		 */
+		assertplus.ok(config.hasProbeGroup('group-0-name'));
+		assertplus.ok(!config.hasProbeGroup(
+		    'group-' + ngroups + '-name'));
+
+		/*
+		 * Iterate and count the probe groups.
+		 */
+		nfound = 0;
+		config.eachProbeGroup(function (pg) { nfound++; });
+		assertplus.equal(nfound, ngroups);
+
+		/*
+		 * Iterate and count the probes.
+		 */
+		nfound = 0;
+		config.eachProbeGroup(function (pg) {
+			config.eachProbeGroupProbe(pg.pg_name, function (p) {
+				nfound++;
+			});
+		});
+		assertplus.equal(nfound, ngroups * ncns * (nvmspercn + 1));
+	    }
+	};
+
+	var cni, vmi, groupi;
+	var cnname, vmname, gname, name, probes, nprobes;
+
+	nprobes = 0;
+	process.stdout.write('generating test case ... ');
+
+	for (groupi = 0; groupi < ngroups; groupi++) {
+		scaleTestCase.amon.groups.push({
+		    'uuid': 'group-' + groupi + '-uuid',
+		    'name': 'group-' + groupi + '-name',
+		    'user': account,
+		    'disabled': false,
+		    'contacts': [ 'contact1' ]
+		});
+	}
+
+	for (cni = 0; cni < ncns; cni++) {
+		cnname = 'cn' + cni;
+		scaleTestCase.components.push({
+		    'type': 'cn',
+		    'uuid': cnname
+		});
+
+		for (vmi = 0; vmi < nvmspercn; vmi++) {
+			vmname = cnname + '-vm-' + vmi;
+			scaleTestCase.components.push({
+			    'type': 'vm',
+			    'uuid': vmname
+			});
+		}
+
+		probes = scaleTestCase.amon.agentprobes[cnname] = [];
+		for (groupi = 0; groupi < ngroups; groupi++) {
+			gname = 'group-' + groupi;
+			name = cnname + '-group-' + groupi + '-probe';
+			probes.push({
+			    'uuid': name + '-uuid',
+			    'name': name + '-name',
+			    'group': gname + '-uuid',
+			    'user': account,
+			    'type': 'cmd',
+			    'config': {},
+			    'agent': cnname,
+			    'machine': vmname,
+			    'groupEvents': true
+			});
+			nprobes++;
+		}
+
+		for (vmi = 0; vmi < nvmspercn; vmi++) {
+			vmname = cnname + '-vm-' + vmi;
+			probes = scaleTestCase.amon.agentprobes[vmname] = [];
+			for (groupi = 0; groupi < ngroups; groupi++) {
+				gname = 'group-' + groupi;
+				name = vmname + '-group-' + groupi + '-probe';
+				probes.push({
+				    'uuid': name + '-uuid',
+				    'name': name + '-name',
+				    'group': gname + '-uuid',
+				    'user': account,
+				    'type': 'cmd',
+				    'config': {},
+				    'agent': vmname,
+				    'machine': vmname,
+				    'groupEvents': true
+				});
+				nprobes++;
+			}
+		}
+	}
+
+	console.log('%d probes', nprobes);
+	return (scaleTestCase);
+}
+
+main();
diff --git a/test/alarms/tst.metadata_basic.js b/test/alarms/tst.metadata_basic.js
new file mode 100644
index 0000000..17068f6
--- /dev/null
+++ b/test/alarms/tst.metadata_basic.js
@@ -0,0 +1,706 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.metadata_basic.js: tests probe template metadata subsystem
+ */
+
+var assertplus = require('assert-plus');
+var extsprintf = require('extsprintf');
+var jsprim = require('jsprim');
+var VError = require('verror');
+
+var sprintf = extsprintf.sprintf;
+
+var alarm_metadata = require('../../lib/alarms/metadata');
+var services = require('../../lib/services');
+
+var testCases = [];
+var sampleEvent = 'upset.manta.test_event';
+var sampleLegacyName = 'my sample probe';
+var sampleScope = { 'service': 'madtom' };
+var sampleChecks = [ { 'type': 'cmd', 'config': { 'test': 'prop' } } ];
+var sampleKa = {
+    'title': 'sample title',
+    'description': 'sample description',
+    'severity': 'sample severity',
+    'response': 'sample response',
+    'impact': 'sample impact',
+    'action': 'sample action'
+};
+
+var sampleTemplate = {
+    'event': sampleEvent,
+    'legacyName': sampleLegacyName,
+    'scope': sampleScope,
+    'checks': sampleChecks,
+    'ka': sampleKa
+};
+
+function main()
+{
+	generateTestCases();
+	testCases.forEach(runTestCase);
+	console.error('%s okay', __filename);
+}
+
+function generateTestCases()
+{
+	/*
+	 * Test a case that loads 0 templates.
+	 */
+	testCases.push({
+	    'name': 'basic, valid input with 0 templates',
+	    'input': JSON.stringify([]),
+	    'verify': function verifyEmpty(md) {
+		md.eachEvent(function (eventName) {
+			throw (new VError('empty metadata found an event: "%s"',
+			    eventName));
+		});
+
+		md.eachTemplate(function (tpl) {
+			throw (new VError('empty metadata found a template'));
+		});
+	    }
+	});
+
+	/*
+	 * Test basic results of the success path, including all of the
+	 * interfaces that allow consumers to interact with the parsed metadata.
+	 */
+	testCases.push({
+	    'name': 'basic, valid input (exhaustive)',
+	    'input': JSON.stringify([ sampleTemplate ]),
+	    'verify': function verifyValid(md) {
+		var list, ka, pt, pgname, evtname, parsed;
+
+		/*
+		 * Test eachEvent().  This interface is exported at-large to
+		 * consumers in sdc-manta.
+		 */
+		list = [];
+		md.eachEvent(function (eventName) { list.push(eventName); });
+		assertplus.deepEqual(list, [ sampleEvent ]);
+
+		/*
+		 * Test eventKa().  This interface is exported at-large to
+		 * consumers in sdc-manta.
+		 */
+		ka = md.eventKa(sampleEvent + '.junk');
+		assertplus.strictEqual(ka, null);
+		ka = md.eventKa(sampleEvent);
+		assertplus.notStrictEqual(ka, null);
+		assertplus.equal(ka.ka_title, sampleKa.title);
+		assertplus.equal(ka.ka_description, sampleKa.description);
+		assertplus.equal(ka.ka_severity, sampleKa.severity);
+		assertplus.equal(ka.ka_response, sampleKa.response);
+		assertplus.equal(ka.ka_impact, sampleKa.impact);
+		assertplus.equal(ka.ka_action, sampleKa.action);
+
+		/*
+		 * Test eachTemplate() and the ProbeTemplate class fields.  This
+		 * interface is exported only within the alarms configuration
+		 * subsystem of sdc-manta.
+		 */
+		list = [];
+		md.eachTemplate(function (tpl) { list.push(tpl); });
+		assertplus.equal(list.length, 1);
+		pt = list[0];
+		assertplus.equal(pt.pt_event, sampleEvent);
+		assertplus.string(pt.pt_origin_label);
+		assertplus.equal(pt.pt_scope.ptsc_service, sampleScope.service);
+		assertplus.strictEqual(pt.pt_scope.ptsc_global, false);
+		assertplus.strictEqual(pt.pt_scope.ptsc_check_from, null);
+		assertplus.deepEqual(pt.pt_ka, ka);
+		assertplus.arrayOfObject(pt.pt_checks);
+		assertplus.equal(pt.pt_checks.length, 1);
+		assertplus.equal(pt.pt_checks[0].ptc_type,
+		    sampleChecks[0].type);
+		assertplus.deepEqual(pt.pt_checks[0].ptc_config,
+		    sampleChecks[0].config);
+		assertplus.deepEqual(pt.pt_aliases, []);
+
+		/*
+		 * Tests constructing and parsing probe group names.  These
+		 * interfaces are exported only within the alarms configuration
+		 * subsystem of sdc-manta.
+		 */
+		pgname = alarm_metadata.probeGroupNameForTemplate(
+		    pt, sampleEvent);
+		assertplus.equal(pgname, sampleEvent + ';v=1');
+		/* a valid probe group name */
+		parsed = alarm_metadata.testingParseProbeGroupName(pgname);
+		assertplus.strictEqual(parsed.error, null);
+		assertplus.strictEqual(parsed.isLegacy, false);
+		assertplus.strictEqual(parsed.isOther, false);
+		assertplus.strictEqual(parsed.eventName, sampleEvent);
+
+		/* a legacy probe group name */
+		parsed = alarm_metadata.testingParseProbeGroupName('ops-alert');
+		assertplus.strictEqual(parsed.error, null);
+		assertplus.strictEqual(parsed.isLegacy, true);
+		assertplus.strictEqual(parsed.isOther, false);
+		assertplus.strictEqual(parsed.eventName, null);
+
+		/* an operator-created probe group name */
+		parsed = alarm_metadata.testingParseProbeGroupName('mygroup');
+		assertplus.strictEqual(parsed.error, null);
+		assertplus.strictEqual(parsed.isLegacy, false);
+		assertplus.strictEqual(parsed.isOther, true);
+		assertplus.strictEqual(parsed.eventName, null);
+
+		/* a probe group name that fails to parse */
+		parsed = alarm_metadata.testingParseProbeGroupName(
+		    'mygroup;v=2');
+		assertplus.object(parsed.error, 'error');
+		assertplus.ok(parsed.error instanceof Error);
+		/* JSSTYLED */
+		assertplus.ok(/unrecognized version "2" in probe group/.test(
+		    parsed.error.message));
+		assertplus.strictEqual(parsed.isLegacy, false);
+		assertplus.strictEqual(parsed.isOther, false);
+		assertplus.strictEqual(parsed.eventName, null);
+
+		/*
+		 * Test probeGroupEventName() and probeGroupIsRemovable().
+		 * These interfaces are exported only within the alarms
+		 * configuration subsystem of sdc-manta.
+		 */
+		assertplus.strictEqual(null, md.probeGroupEventName('foobar'));
+		assertplus.strictEqual(false,
+		    md.probeGroupIsRemovable('foobar'));
+		/* a legacy probe group name */
+		assertplus.strictEqual(null,
+		    md.probeGroupEventName('ops-alert'));
+		assertplus.strictEqual(true,
+		    md.probeGroupIsRemovable('ops-alert'));
+		/* an operator-created probe group name */
+		assertplus.strictEqual(null,
+		    md.probeGroupEventName('my-custom-group'));
+		assertplus.strictEqual(false,
+		    md.probeGroupIsRemovable('my-custom-group'));
+		assertplus.strictEqual(null,
+		    md.probeGroupEventName('my-custom-group; with semicolon'));
+		assertplus.strictEqual(false,
+		    md.probeGroupIsRemovable('my-custom-group; with semi'));
+		/* a malformed probe group name */
+		assertplus.strictEqual(null,
+		    md.probeGroupEventName(sampleEvent + ';v=2'));
+		assertplus.strictEqual(false,
+		    md.probeGroupIsRemovable(sampleEvent + ';v=2'));
+		/* a configured probe group name */
+		evtname = md.probeGroupEventName(pgname);
+		assertplus.strictEqual(evtname, sampleEvent);
+		assertplus.strictEqual(false, md.probeGroupIsRemovable(pgname));
+	    }
+	});
+
+	/* Test case that creates two simple templates. */
+	testCases.push({
+	    'name': 'basic, valid input with 2 templates',
+	    'input': JSON.stringify([ {
+	        'event': sampleEvent + '.1',
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    }, {
+	        'event': sampleEvent + '.2',
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'verify': function verifyTwo(md) {
+		var events, pts, pgname, evtname;
+
+		events = [];
+		md.eachEvent(function (eventName) {
+			events.push(eventName);
+		});
+		events = events.sort();
+		assertplus.deepEqual(events, [
+		    sampleEvent + '.1', sampleEvent + '.2' ]);
+
+		pts = [];
+		md.eachTemplate(function (pt) {
+			pts.push(pt);
+		});
+		pts.sort(function (pt1, pt2) {
+			assertplus.string(pt1.pt_event);
+			assertplus.string(pt2.pt_event);
+			return (pt1.pt_event.localeCompare(pt2.pt_event));
+		});
+
+		assertplus.equal(pts[0].pt_event, events[0]);
+		assertplus.equal(pts[1].pt_event, events[1]);
+		pgname = alarm_metadata.probeGroupNameForTemplate(
+		    pts[0], events[0]);
+		evtname = md.probeGroupEventName(pgname);
+		assertplus.equal(evtname, events[0]);
+		assertplus.ok(!md.probeGroupIsRemovable(pgname));
+	    }
+	});
+
+	/*
+	 * Test cases with invalid input.
+	 */
+
+	testCases.push({
+	    'name': 'invalid YAML',
+	    'input': '{',
+	    /* JSSTYLED */
+	    'errmsg': /parse "input": unexpected end/
+	});
+
+	testCases.push({
+	    'name':  'schema mismatch: not an array',
+	    'input': JSON.stringify({}),
+	    /* JSSTYLED */
+	    'errmsg': /parse "input":.*object.*found.*array.*required/
+	});
+
+	/*
+	 * For each required field, produce a test case that attempts to parse
+	 * otherwise valid input that's missing that field.
+	 */
+	[ 'event', 'scope', 'checks', 'ka' ].forEach(function (field) {
+		var input = jsprim.deepCopy(sampleTemplate);
+		delete (input[field]);
+
+		testCases.push({
+		    'name': sprintf(
+		        'schema mismatch: missing required field: "%s"', field),
+		    'input': JSON.stringify([ input ]),
+		    'errmsg': new RegExp('^parse "input": property ' +
+		        '"0.' + field + '":.*missing')
+		});
+	});
+
+	/* Bad type for "event" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "event"',
+	    'input': JSON.stringify([ {
+		'event': {},
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.event": ' +
+	        'object.*found,.*string.*required')
+	});
+
+	/* Bad type for "legacyName" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "legacyName"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'legacyName': {},
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': 'busted'
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.legacyName": ' +
+	        'object.*found,.*string.*required')
+	});
+
+	/* Bad type for "scope" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "scope"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': 'bad scope',
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.scope": ' +
+	        'string.*found,.*object.*required')
+	});
+
+	/* Bad type for "checks" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "checks"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': {},
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.checks": ' +
+	        'object.*found,.*array.*required')
+	});
+
+	/* Bad type for "ka" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "ka"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': 'busted'
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.ka": ' +
+	        'string.*found,.*object.*required')
+	});
+
+	/* Extra top-level properties */
+	testCases.push({
+	    'name': 'schema mismatch: extra top-level property',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa,
+		'something': 'anotherValue'
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.something": ' +
+	        'unsupported property')
+	});
+
+	/* "scope": bad service name */
+	testCases.push({
+	    'name': 'schema mismatch: bad "scope.service"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': { 'service': 'bogus' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.scope.service":' +
+	        ' does not have a value in the enumeration')
+	});
+
+	/* "scope": extra properties */
+	testCases.push({
+	    'name': 'schema mismatch: bad "scope" (extra properties)',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': { 'service': 'madtom', 'extraProp': 17 },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property ' +
+	        '"0.scope.extraprop": unsupported property')
+	});
+
+	/* "scope": bad "global" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "scope.global"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': { 'service': 'madtom', 'global': 'false' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.scope.global": ' +
+	        'string.*found,.*boolean.*required')
+	});
+
+	/* "scope": bad "checkFrom" */
+	testCases.push({
+	    'name': 'schema mismatch: bad "scope.checkFrom"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': { 'service': 'madtom', 'checkFrom': 'each' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property ' +
+	        '"0.scope.checkFrom": does not have a value in the enumeration')
+	});
+
+	/* "checks": none */
+	testCases.push({
+	    'name': 'schema mismatch: no checks',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': [],
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property "0.checks": ' +
+	        '.*minimum of 1.*')
+	});
+
+	/* "checks": bad type */
+	testCases.push({
+	    'name': 'schema mismatch: check has bad type',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': [ {
+		    'type': 'unsupported'
+		} ],
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property ' +
+	        '"0.checks\\[0\\].type": does not have a value ' +
+		'in the enumeration')
+	});
+
+	/* "ka": string field has bad type */
+	testCases.push({
+	    'name': 'schema mismatch: ka has non-string field',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': {
+		    'title': {}
+		}
+	    } ]),
+	    'errmsg': new RegExp('^parse "input": property ' +
+	        '"0.ka.title": object.*found.*string.*required')
+	});
+
+	/* "ka": string field has trailing newline */
+	testCases.push({
+	    'name': 'bad input: ka has non-string field',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': {
+		    'title': 'my title',
+		    'description': 'my description',
+		    'response': 'my response\n',
+		    'action': 'an action\nokay\n\nokay here too',
+		    'severity': 'major',
+		    'impact': 'none'
+		}
+	    } ]),
+	    'errmsg': new RegExp('^input: probe 1: field ka.response: ' +
+	        'ends with trailing newline')
+	});
+
+	/* duplicate event name */
+	testCases.push({
+	    'name': 'bad input: duplicate event name',
+	    'input': JSON.stringify([ sampleTemplate, sampleTemplate ]),
+	    'errmsg': new RegExp('^input: probe 2: re-uses event name ' +
+	        '"upset.manta.test_event" previously used in template ' +
+		'"input: probe 1"$')
+	});
+
+	/* event name with invalid characters */
+	testCases.push({
+	    'name': 'bad input: unsupported event name',
+	    'input': JSON.stringify([ {
+	        'event': sampleEvent + '-1',
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^input: probe 1: event name contains ' +
+	        'unsupported characters')
+	});
+
+	/* variables not allowed when scope is not "each" */
+	testCases.push({
+	    'name': 'bad input: attempted use of variables without "each"',
+	    'input': JSON.stringify([ {
+	        'event': sampleEvent + '.$foo',
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^input: probe 1: event name contains ' +
+	        'unsupported characters')
+	});
+
+	/* event name doesn't start with "upset.manta. */
+	testCases.push({
+	    'name': 'bad input: unsupported event name',
+	    'input': JSON.stringify([ {
+	        'event': 'upset.manta_stuff.another_event',
+		'scope': sampleScope,
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^input: probe 1: field "event": must begin ' +
+	        'with "upset.manta."$')
+	});
+
+	/*
+	 * Test cases making use of the "each" scope.  These generate multiple
+	 * aliases and they require the use of the $service variable.
+	 */
+
+	/* missing using '$service' */
+	testCases.push({
+	    'name': 'bad input: use of "each" without "$service"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent,
+		'scope': { 'service': 'each' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^template "input: probe 1": templates ' +
+	        'with scope "each" must use "\\$service" in event name to ' +
+		'ensure uniqueness$')
+	});
+
+	/* use of unsupported variables */
+	testCases.push({
+	    'name': 'bad input: use of "each" with unsupported variable',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent + '.$service.$other',
+		'scope': { 'service': 'each' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^template "input: probe 1": unknown ' +
+	        'variable "\\$other" in event name$')
+	});
+
+	/* unsupported characters after expansion */
+	testCases.push({
+	    'name': 'bad input: use of "each" without "$service"',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent + '.$service.other-junk',
+		'scope': { 'service': 'each' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'errmsg': new RegExp('^input: probe 1: expanded ' +
+	        'event name contains unsupported characters')
+	});
+
+	/* valid input using "each" */
+	testCases.push({
+	    'name': 'valid input using "each" scope',
+	    'input': JSON.stringify([ {
+		'event': sampleEvent + '.$service',
+		'scope': { 'service': 'each' },
+		'checks': sampleChecks,
+		'ka': sampleKa
+	    } ]),
+	    'verify': function verifyValidEach(md) {
+		var expectedServices, expectedEvents, list, ka, pt;
+		var pgname, evtname;
+
+		/*
+		 * See the other valid test case above for the structure of this
+		 * verifier.
+		 *
+		 * We should see events for each service that supports probes.
+		 * This excludes "marlin".
+		 */
+		expectedServices = services.mSvcNamesProbes.slice(0).sort();
+		expectedEvents = expectedServices.map(function (svcname) {
+			return (sampleEvent + '.' + svcname.replace(/-/g, '_'));
+		});
+
+		list = [];
+		md.eachEvent(function (eventName) { list.push(eventName); });
+		assertplus.deepEqual(list.sort(), expectedEvents);
+
+		ka = md.eventKa('upset.manta.test_event.authcache');
+		assertplus.equal(ka.ka_title, sampleKa.title);
+
+		list = [];
+		md.eachTemplate(function (tpl) { list.push(tpl); });
+		assertplus.equal(list.length, 1);
+		pt = list[0];
+		assertplus.equal(pt.pt_event, sampleEvent + '.$service');
+		assertplus.deepEqual(pt.pt_ka, ka);
+		assertplus.equal(pt.pt_scope.ptsc_service, 'each');
+
+		/*
+		 * Check the aliases.
+		 */
+		pt.pt_aliases.slice(0).sort(function (a1, a2) {
+			assertplus.string(a1.pta_service);
+			assertplus.string(a2.pta_service);
+			return (a1.pta_service.localeCompare(a2.pta_service));
+		}).forEach(function (a, i) {
+			assertplus.equal(a.pta_event, expectedEvents[i]);
+			assertplus.equal(a.pta_service, expectedServices[i]);
+		});
+
+		/*
+		 * Check the event name <-> probe group translations.
+		 */
+		pgname = alarm_metadata.probeGroupNameForTemplate(pt,
+		    expectedEvents[0]);
+		evtname = md.probeGroupEventName(pgname);
+		assertplus.equal(evtname, expectedEvents[0]);
+
+		pgname = alarm_metadata.probeGroupNameForTemplate(pt,
+		    expectedEvents[1]);
+		evtname = md.probeGroupEventName(pgname);
+		assertplus.equal(evtname, expectedEvents[1]);
+		assertplus.strictEqual(false, md.probeGroupIsRemovable(pgname));
+	    }
+	});
+}
+
+/*
+ * Each test case must have:
+ *
+ *     name (string)		human-readable name for the test case
+ *
+ *     input (string)		string input to parse as a probe template
+ *
+ * and ONE of the following:
+ *
+ *     errmsg (regexp)		Parsing the input must produce a single error
+ *     				matching this regular expression.
+ *
+ *     verify (function)	Parsing the input must produce no errors.
+ *     				The resulting metadata will be passed to this
+ *     				function for additional verification.  The
+ *     				function should throw an exception for failures.
+ */
+function runTestCase(testcase)
+{
+	var mdl, errors;
+
+	assertplus.object(testcase, 'testcase');
+	assertplus.string(testcase.name, 'testcase.name');
+	assertplus.string(testcase.input, 'testcase.input');
+
+	console.error('test case: %s', testcase.name);
+	mdl = new alarm_metadata.MetadataLoader();
+	mdl.loadFromString(testcase.input, 'input');
+	errors = mdl.errors();
+	assertplus.ok(errors.length < 2,
+	    'test suite did not expect multiple parse errors');
+
+	if (testcase.hasOwnProperty('errmsg')) {
+		assertplus.ok(testcase.errmsg instanceof RegExp,
+		    'expected error message must be a regular expression');
+
+		if (errors.length === 0) {
+			throw (new VError(
+			    'expected error ("%s"), but found none',
+			    testcase.errmsg.source));
+		}
+
+		if (!testcase.errmsg.test(errors[0].message)) {
+			throw (new VError('error message mismatch: found ' +
+			    '"%s", expected "%s"', errors[0].message,
+			    testcase.errmsg.source));
+		}
+
+		console.error('found matching error message');
+	} else {
+		assertplus.func(testcase.verify, 'testcase.verify');
+
+		if (errors.length > 0) {
+			throw (new VError('expected no error, but found: "%s"',
+			    errors[0].message));
+		}
+
+		testcase.verify(mdl.mdl_amoncfg);
+	}
+
+	console.error('');
+}
+
+main();
diff --git a/test/alarms/tst.metadata_files.js b/test/alarms/tst.metadata_files.js
new file mode 100644
index 0000000..9bb8bad
--- /dev/null
+++ b/test/alarms/tst.metadata_files.js
@@ -0,0 +1,270 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.metadata_files.j: tests file-related interfaces in metadata subsystem.
+ * This includes the functions for loading from a directory tree and the check
+ * tool.
+ */
+
+var assertplus = require('assert-plus');
+var extsprintf = require('extsprintf');
+var forkexec = require('forkexec');
+var fs = require('fs');
+var path = require('path');
+var vasync = require('vasync');
+var VError = require('verror');
+
+var sprintf = extsprintf.sprintf;
+
+var alarm_metadata = require('../../lib/alarms/metadata');
+
+var testCases = [];
+var sampleEvent = 'upset.manta.test_event';
+var sampleLegacyName = 'my sample probe';
+var sampleScope = { 'service': 'madtom' };
+var sampleChecks = [ { 'type': 'cmd', 'config': { 'test': 'prop' } } ];
+var sampleKa = {
+    'title': 'sample title',
+    'description': 'sample description',
+    'severity': 'sample severity',
+    'response': 'sample response',
+    'impact': 'sample impact',
+    'action': 'sample action'
+};
+var sampleTemplate = {
+    'event': sampleEvent,
+    'legacyName': sampleLegacyName,
+    'scope': sampleScope,
+    'checks': sampleChecks,
+    'ka': sampleKa
+};
+var done = false;
+var tounlink = [];
+
+/*
+ * We create our test directory in the current directory.  Under catest, this is
+ * always an appropriate working directory.  Outside of that, the user may have
+ * to clean it up if we fail.
+ */
+var testDirectory = path.join('.', 'testdir-' + path.basename(__filename));
+
+function main()
+{
+	process.on('exit', function (code) {
+		if (code === 0 && !done) {
+			throw (new Error('exited prematurely!'));
+		}
+	});
+
+	vasync.waterfall([
+	    function setupTestDirectory(callback) {
+		fs.mkdir(testDirectory, function (err) {
+			if (err && err.code == 'EEXIST') {
+				console.error('using existing directory %s',
+				    testDirectory);
+				err = null;
+			} else {
+				console.error('creating %s', testDirectory);
+			}
+
+			callback(err);
+		});
+	    },
+
+	    function setupTestFile1(callback) {
+		var file, contents;
+		file = path.join(testDirectory, 'file1.yaml');
+		contents = JSON.stringify([ {
+		    'event': sampleEvent + '.1',
+		    'scope': sampleScope,
+		    'checks': sampleChecks,
+		    'ka': sampleKa
+		}, {
+		    'event': sampleEvent + '.3',
+		    'scope': sampleScope,
+		    'checks': sampleChecks,
+		    'ka': sampleKa
+		} ]);
+
+		tounlink.push(file);
+		writeFile(file, contents, callback);
+	    },
+
+	    function setupTestFile2(callback) {
+		var file, contents;
+		file = path.join(testDirectory, 'file2.yaml');
+		contents = JSON.stringify([ {
+		    'event': sampleEvent + '.2',
+		    'scope': sampleScope,
+		    'checks': sampleChecks,
+		    'ka': sampleKa
+		} ]);
+
+		tounlink.push(file);
+		writeFile(file, contents, callback);
+	    },
+
+	    function setupTestFileSkip(callback) {
+		var file;
+		file = path.join(testDirectory, 'file3');
+		tounlink.push(file);
+		writeFile(file, '{', callback);
+	    },
+
+	    function loadDirectory(callback) {
+		console.error('loading data from %s', testDirectory);
+		alarm_metadata.loadMetadata({
+		    'directory': testDirectory
+		}, callback);
+	    },
+
+	    function verifyMetadata(metadata, callback) {
+		var pts;
+
+		pts = [];
+		metadata.eachTemplate(function (pt) {
+			pts.push({
+			    'event': pt.pt_event,
+			    'origin': pt.pt_origin_label
+			});
+		});
+		pts.sort(function (p1, p2) {
+			return (p1.event.localeCompare(p2.event));
+		});
+
+		/*
+		 * Importantly, we have all three probes, and it doesn't matter
+		 * where each one came from.  We also skipped the file that
+		 * didn't end in ".yaml".
+		 */
+		assertplus.deepEqual(pts, [ {
+		    'event': sampleEvent + '.1',
+		    'origin': sprintf('%s/file1.yaml: probe 1', testDirectory)
+		}, {
+		    'event': sampleEvent + '.2',
+		    'origin': sprintf('%s/file2.yaml: probe 1', testDirectory)
+		}, {
+		    'event': sampleEvent + '.3',
+		    'origin': sprintf('%s/file1.yaml: probe 2', testDirectory)
+		} ]);
+
+		callback();
+	    },
+
+	    function loadDirectoryFail(callback) {
+		console.error('loading data from non-existent directory');
+		alarm_metadata.loadMetadata({
+		    'directory': 'junkDirectory'
+		}, function (err, metadata) {
+			assertplus.ok(err !== null);
+			assertplus.ok(err instanceof Error);
+			assertplus.ok(!metadata);
+			/* JSSTYLED */
+			assertplus.ok(/readdir "junkDirectory".*ENOENT/.test(
+			    err.message));
+			callback();
+		});
+	    },
+
+	    function checkFileOkay(callback) {
+		var file = path.join(testDirectory, 'file1.yaml');
+		checkFile(file, function (err, info) {
+			assertplus.ok(!err);
+			assertplus.ok(info.status === 0);
+			callback();
+		});
+	    },
+
+	    function checkFileNonexistent(callback) {
+		var file = path.join(testDirectory, 'ENOENT.yaml');
+		checkFile(file, function (err, info) {
+			assertplus.ok(err !== null);
+			assertplus.ok(err instanceof Error);
+			assertplus.equal(info.status, 1);
+			/* JSSTYLED */
+			assertplus.ok(/read ".*ENOENT.yaml": ENOENT/.test(
+			    info.stderr));
+			callback();
+		});
+	    },
+
+	    function checkFileInvalid(callback) {
+		var file = path.join(testDirectory, 'file3');
+		checkFile(file, function (err, info) {
+			assertplus.ok(err !== null);
+			assertplus.ok(err instanceof Error);
+			assertplus.equal(info.status, 1);
+			assertplus.ok(
+			    /* JSSTYLED */
+			    /parse ".*file3": unexpected end of the stream/.
+			    test(info.stderr));
+			callback();
+		});
+	    },
+
+	    function cleanupFiles(callback) {
+		console.error('removing files: %s', tounlink.join(', '));
+		vasync.forEachPipeline({
+		    'inputs': tounlink,
+		    'func': fs.unlink
+		}, function (err) {
+			callback(err);
+		});
+	    },
+
+	    function cleanupDirectory(callback) {
+		console.error('removing directory: %s', testDirectory);
+		fs.rmdir(testDirectory, callback);
+	    }
+	], function (err) {
+		if (err) {
+			throw (err);
+		}
+
+		done = true;
+		console.error('%s okay', __filename);
+	});
+}
+
+/*
+ * Wrapper around fs.writeFile() that provides a more useful Error on failure.
+ */
+function writeFile(filename, contents, callback)
+{
+	console.error('writing %s', filename);
+	fs.writeFile(filename, contents, function (err) {
+		if (err) {
+			err = new VError('write "%s"', filename);
+		}
+
+		callback(err);
+	});
+}
+
+/*
+ * Runs the checker tool on the specified file.
+ */
+function checkFile(filename, callback)
+{
+	var argv = [
+	    path.join(__dirname, '..', '..', 'tools', 'probecfgchk.js'),
+	    filename
+	];
+
+	console.error('checking %s', filename);
+	forkexec.forkExecWait({
+	    'argv': argv
+	}, function (err, info) {
+		callback(err, info);
+	});
+}
+
+main();
diff --git a/test/alarms/tst.update.js b/test/alarms/tst.update.js
new file mode 100644
index 0000000..70365de
--- /dev/null
+++ b/test/alarms/tst.update.js
@@ -0,0 +1,1123 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * tst.update.js: tests facilities used to update a the deployed probes and
+ * probe groups.
+ */
+
+var assertplus = require('assert-plus');
+var bunyan = require('bunyan');
+var jsprim = require('jsprim');
+var sprintf = require('extsprintf').sprintf;
+var vasync = require('vasync');
+
+var alarms = require('../../lib/alarms');
+var alarm_metadata = require('../../lib/alarms/metadata');
+var instance_info = require('../../lib/instance_info');
+var mock_amon = require('./mock_amon');
+var services = require('../../lib/services');
+
+/*
+ * These test cases are somewhat tedious because in order to verify that the
+ * software is doing what we expect, we need to enumerate the expected probes
+ * and probe groups for various cases.  But there are also a lot of different
+ * cases to test:
+ *
+ *   - configuring and unconfiguring
+ *   - scopes that are per-service, for each service, or for all services
+ *   - global scopes
+ *   - cases where there are no instances of a service in this datacenter
+ *   - groups and probes that were operator-added
+ *   - groups and probes added by previous versions of the software
+ *   - cases where no changes need to be made
+ *   - cases where partial changes need to be made
+ *
+ * The goal is to exercise a set of test cases, each of which describes:
+ *
+ *   - a set of CNs and VMs in a datacenter
+ *   - a set of probe metadata (like the one shipped with this repository, but
+ *     much simpler)
+ *   - a set of probes and probe groups that are deployed already
+ *   - whether the test operation is a "configure" or "unconfigure" operation
+ *
+ * For each test case, we will generate an Amon update plan according to the
+ * parameters of the test case and verify its basic parameters (mostly: the
+ * numbers of groups and probes added and removed).
+ *
+ * We do this in a few stages:
+ *
+ *   (1) generateTestDatacenters() generates descriptions of a handful of
+ *       datacenters that we'll use for testing:
+ *
+ *       - "empty": a single, empty datacenter (degenerate case)
+ *       - "single": a single-datacenter case that we use to exercise most of
+ *         the cases
+ *       - "multi": a multi-datacenter case that we use only to sanity-test that
+ *         case
+ *
+ *   (2) generateTestMetadata() uses hardcoded metadata descriptions to load
+ *       probe metadata that exercises the various cases that we care about
+ *
+ *   (3) generateMockAmonObjects() uses the mock Amon server in this directory
+ *       to load sample hardcoded "deployed" probes and probe groups
+ *
+ *   (4) generateTestCases() generates the actual test cases, which are
+ *       expressed in terms of the above (a description of the datacenter we're
+ *       testing, the probe metadata to use, the set of groups and probes to
+ *       pretend are deployed, etc.)
+ *
+ * Finally, we run through all the test cases, invoking the verifier function to
+ * assert whatever the test case needs about the resulting plan.
+ */
+var testCases;
+
+/*
+ * Datacenter configurations
+ *
+ * See above.  This structure is filled in by generateTestDatacenters().
+ */
+var dcconfigs = {
+    'cfg_empty': new DatacenterConfig(),
+    'cfg_basic': new DatacenterConfig(),
+    'cfg_multi': new DatacenterConfig()
+};
+
+/*
+ * nInstancesBySvc is used to by generateTestDatacenters() to generate a list of
+ * fake VMs and CNs for a datacenter.  The only reason that the code we're
+ * testing isn't completely agnostic to service names is because the
+ * implementation of the "all" scope requires knowing all of the service names.
+ * We don't actually need to exercise every service differently, and doing so
+ * would be pretty tedious because we'll need to manually list out all of the
+ * expected probes for every instance.  So we only define a few instances and
+ * test out those.
+ */
+var nInstancesBySvc = {
+    'nameservice': 3,
+    'jobsupervisor': 2
+};
+
+/*
+ * Parameters used for all of the tests.
+ */
+var account = mock_amon.account;
+var contactsBySeverity = {
+    'minor': [ 'minor_contact1', 'minor_contact2', 'minor_contact3' ],
+    'major': [ 'major_contact' ],
+    'critical': [ 'critical_contact1', 'critical_contact2' ]
+};
+
+/*
+ * Probe metadata
+ *
+ * The raw objects below are processed using the normal metadata loading code to
+ * generate loaded versions.  We test a couple of different metadata
+ * configurations: one with no metadata (as a degenerate case) and another one
+ * that covers a bunch of the cases described above.
+ */
+
+/* loaded versions */
+var metadataEmpty, metadataBasic;
+
+/* raw versions (JSON representations of the metadata) */
+var rawMetadataEmpty = [];
+var rawMetadataBasic = [ {
+    /* scope: basic service scope */
+    'event': 'upset.manta.test.nameservice_broken',
+    'scope': { 'service': 'nameservice' },
+    'checks': [ {
+	'type': 'cmd',
+	'config': {
+	    'env': { 'complex': 'snpp' },
+	    'autoEnv': [ 'sector' ]
+	}
+    } ],
+    'ka': {
+	'title': 'test ka: basic "service" scope',
+	'description': 'exercises a basic "service" scope template',
+	'severity': 'minor',
+	'response': 'none',
+	'impact': 'none',
+	'action': 'none'
+    }
+}, {
+    /* scope: "global" */
+    'event': 'upset.manta.test.global',
+    'scope': { 'service': 'nameservice', 'global': true },
+    'checks': [ { 'type': 'cmd', 'config': {} } ],
+    'ka': {
+	'title': 'test ka: global "service" scope',
+	'description': 'exercises a global "service" scope template',
+	'severity': 'major',
+	'response': 'none',
+	'impact': 'none',
+	'action': 'none'
+    }
+}, {
+    /* scope: "each" */
+    'event': 'upset.manta.test.$service',
+    'scope': { 'service': 'each' },
+    'checks': [ { 'type': 'cmd', 'config': {} } ],
+    'ka': {
+	'title': 'test ka: each "service" scope',
+	'description': 'exercises an "each" "service" scope template',
+	'severity': 'critical',
+	'response': 'none',
+	'impact': 'none',
+	'action': 'none'
+    }
+}, {
+    /* scope: "all" */
+    'event': 'upset.manta.test.all',
+    'scope': { 'service': 'all' },
+    'checks': [ { 'type': 'cmd', 'config': {} } ],
+    'ka': {
+	'title': 'test ka: all "service" scope',
+	'description': 'exercises an "all" "service" scope template',
+	'severity': 'minor',
+	'response': 'none',
+	'impact': 'none',
+	'action': 'none'
+    }
+} ];
+
+/*
+ * List of probe groups that should be deployed by the above metadata,
+ * regardless of the datacenter configuration.
+ */
+var deployedGroups = [ {
+    'uuid': 'deployed-group-uuid-1',
+    'name': 'upset.manta.test.nameservice_broken;v=1',
+    'user': account,
+    'disabled': false,
+    'contacts': contactsBySeverity.minor
+}, {
+    'uuid': 'deployed-group-uuid-2',
+    'name': 'upset.manta.test.global;v=1',
+    'user': account,
+    'disabled': false,
+    'contacts': contactsBySeverity.major
+}, {
+    'uuid': 'deployed-group-uuid-3',
+    'name': 'upset.manta.test.all;v=1',
+    'user': account,
+    'disabled': false,
+    'contacts': contactsBySeverity.minor
+} ];
+
+function main()
+{
+	var log;
+
+	log = new bunyan({
+	    'name': 'tst.update.js',
+	    'level': process.env['LOG_LEVEL'] || 'fatal',
+	    'stream': process.stderr
+	});
+
+	generateTestDatacenters();
+	generateTestMetadata();
+	mock_amon.createMockAmon(log, function (mock) {
+		generateMockAmonObjects(mock, function () {
+			mock.server.close();
+			generateTestCases();
+			testCases.forEach(runTestCase);
+			console.log('%s okay', __filename);
+		});
+	});
+}
+
+/*
+ * Populates "dcconfigs" with a reasonable set of CNs and VMs for each of the
+ * three configurations we intend to test.
+ */
+function generateTestDatacenters()
+{
+	var instances, instancesBySvc, servernames;
+
+	/*
+	 * The empty DC is easy: just set up the data structure.
+	 */
+	jsprim.forEachKey(nInstancesBySvc, function (svcname, n) {
+		dcconfigs.cfg_empty.ctp_instances_by_svcname[
+		    svcname] = [];
+	});
+
+	/*
+	 * For the basic single datacenter case, fake up instances in numbers
+	 * described by nInstancesBySvc.
+	 */
+	instances = dcconfigs.cfg_basic.ctp_instances;
+	instancesBySvc = dcconfigs.cfg_basic.ctp_instances_by_svcname;
+	servernames = {};
+	jsprim.forEachKey(nInstancesBySvc, function (svcname, n) {
+		var i, instid, cnname;
+		instancesBySvc[svcname] = [];
+		for (i = 0; i < n; i++) {
+			instid = sprintf('svc-%s-%d', svcname, i);
+			/*
+			 * We use only two different CN uuids to make sure that
+			 * we re-use CNs for a given service.  That's in order
+			 * to make sure that "global" scoped templates do not
+			 * generate multiple probes for the same CN just because
+			 * there are two instances of a service on that CN.
+			 */
+			cnname = sprintf('server-uuid-%d', i % 2);
+			instancesBySvc[svcname].push(instid);
+			instances[instid] = new instance_info.InstanceInfo({
+			    'uuid': instid,
+			    'svcname': svcname,
+			    'server_uuid': cnname,
+			    'local': true,
+			    'metadata': {
+				'sector': '7G'
+			    }
+			});
+
+			servernames[cnname] = true;
+		}
+	});
+	dcconfigs.cfg_basic.ctp_servers = Object.keys(servernames);
+	dcconfigs.cfg_basic.ctp_vms_destroyed = [ 'destroyed-nameservice' ];
+	dcconfigs.cfg_basic.ctp_servers_abandoned = [ 'abandoned-cn' ];
+
+	/*
+	 * For the multi-datacenter case, we need to fake up information about
+	 * instances in all three DCs.
+	 */
+	instances = dcconfigs.cfg_multi.ctp_instances;
+	instancesBySvc = dcconfigs.cfg_multi.
+	    ctp_instances_by_svcname;
+	servernames = {};
+	jsprim.forEachKey(nInstancesBySvc, function (svcname, n) {
+		var i, instid, cnname, iiargs;
+
+		instancesBySvc[svcname] = [];
+
+		/*
+		 * This is a quick way of spreading instances across the
+		 * datacenter.  It's not exactly how we'd really do it, but it
+		 * should be close enough for our purposes.
+		 */
+		for (i = 0; i < n; i++) {
+			instid = sprintf('dc%d-%s-inst%d',
+			    i % 3, svcname, i);
+			iiargs = {
+			    'uuid': instid,
+			    'svcname': svcname,
+			    'metadata': {
+				'sector': '7G'
+			    }
+			};
+
+			/*
+			 * Since we're already ignoring most services for the
+			 * purpose of this test case, we know that there will be
+			 * many services with no instances in the local
+			 * datacenter.
+			 */
+			if (i % 3 === 0) {
+				cnname = sprintf('server-uuid-%d', i);
+				instancesBySvc[svcname].push(instid);
+				iiargs['local'] = true;
+				iiargs['server_uuid'] = cnname;
+				servernames[cnname] = true;
+			} else {
+				iiargs['local'] = false;
+				iiargs['server_uuid'] = null;
+			}
+
+			instances[instid] = new instance_info.InstanceInfo(
+			    iiargs);
+		}
+	});
+	dcconfigs.cfg_multi.ctp_servers = Object.keys(servernames);
+}
+
+/*
+ * Load the raw metadata (hardcoded above).
+ */
+function generateTestMetadata()
+{
+	var mdl, errors;
+
+	mdl = new alarm_metadata.MetadataLoader();
+	mdl.loadFromString(JSON.stringify(rawMetadataEmpty), 'input');
+	errors = mdl.errors();
+	assertplus.strictEqual(errors.length, 0);
+	metadataEmpty = mdl.mdl_amoncfg;
+
+	mdl = new alarm_metadata.MetadataLoader();
+	mdl.loadFromString(JSON.stringify(rawMetadataBasic), 'input');
+	errors = mdl.errors();
+	assertplus.strictEqual(errors.length, 0);
+	metadataBasic = mdl.mdl_amoncfg;
+}
+
+/*
+ * Use the mock Amon server to load various combinations of probes and probe
+ * groups.  Unfortunately, these are extremely datacenter-specific and
+ * metadata-specific, so there's not a great way to avoid hardcoding a bunch of
+ * different combinations of deployed groups and probes.
+ */
+function generateMockAmonObjects(mock, callback)
+{
+	mock.config = {};
+	mock.config.groups = [];
+	mock.config.agentprobes = {};
+
+	vasync.waterfall([
+		/*
+		 * Generate a config representing no probes deployed to the
+		 * empty DC configuration.
+		 */
+		function emptyDcNoProbes(subcallback) {
+			var dc = dcconfigs.cfg_empty;
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_none = cfg;
+				subcallback();
+			});
+		},
+
+		/*
+		 * Generate a config representing no probes deployed to the
+		 * basic single-DC configuration.
+		 */
+		function basicDcNoProbes(subcallback) {
+			var dc = dcconfigs.cfg_basic;
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_none = cfg;
+				subcallback();
+			});
+		},
+
+		/*
+		 * Generate a config representing no probes deployed to the
+		 * multi-DC configuration.
+		 */
+		function multiDcNoProbes(subcallback) {
+			var dc = dcconfigs.cfg_multi;
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_none = cfg;
+				subcallback();
+			});
+		},
+
+		/*
+		 * Generate a config representing all of the expected probes
+		 * deployed to the basic single-DC configuration.
+		 */
+		function basicDcFullProbes(subcallback) {
+			var dc = dcconfigs.cfg_basic;
+
+			/*
+			 * Start with the hardcoded groups and add a group for
+			 * each service that supports probes to reflect the
+			 * "each" probe template.
+			 */
+			mock.config.groups = jsprim.deepCopy(deployedGroups);
+			services.mSvcNamesProbes.forEach(function (svcname, i) {
+				svcname = svcname.replace(/-/g, '_');
+				mock.config.groups.push({
+				    'uuid': 'deployed-group-uuid-svc-' +
+				        svcname,
+				    'name': 'upset.manta.test.' + svcname +
+				        ';v=1',
+				    'user': account,
+				    'disabled': false,
+				    'contacts': contactsBySeverity.critical
+				});
+			});
+
+			/*
+			 * Define probes for each of the local instances for
+			 * each of the groups above.
+			 *
+			 * Specifying the environment here implicitly tests the
+			 * behavior of the "autoEnv" property, since if it
+			 * didn't work, the software would make additional
+			 * changes to the deployed probes.
+			 */
+			mock.config.agentprobes = {};
+			mock.config.agentprobes['svc-nameservice-0'] = [
+			    makeProbe({
+			        'group': 'deployed-group-uuid-1',
+				'name': 'upset.manta.test.nameservice_broken0',
+				'agent': 'svc-nameservice-0',
+				'config': {
+				    'env': {
+					'complex': 'snpp',
+					'sector': '7G'
+				    }
+				}
+			    }),
+			    makeProbe({
+				'group': 'deployed-group-uuid-3',
+				'name': 'upset.manta.test.all0',
+				'agent': 'svc-nameservice-0'
+			    }),
+			    makeProbe({
+			        'group': 'deployed-group-uuid-svc-nameservice',
+				'name': 'upset.manta.test.nameservice0',
+				'agent': 'svc-nameservice-0'
+			    })
+			];
+			mock.config.agentprobes['svc-nameservice-1'] = [
+			    makeProbe({
+			        'group': 'deployed-group-uuid-1',
+				'name': 'upset.manta.test.nameservice_broken0',
+				'agent': 'svc-nameservice-1',
+				'config': {
+				    'env': {
+					'complex': 'snpp',
+					'sector': '7G'
+				    }
+				}
+			    }),
+			    makeProbe({
+				'group': 'deployed-group-uuid-3',
+				'name': 'upset.manta.test.all0',
+				'agent': 'svc-nameservice-1'
+			    }),
+			    makeProbe({
+			        'group': 'deployed-group-uuid-svc-nameservice',
+				'name': 'upset.manta.test.nameservice0',
+				'agent': 'svc-nameservice-1'
+			    })
+			];
+			mock.config.agentprobes['svc-nameservice-2'] = [
+			    makeProbe({
+			        'group': 'deployed-group-uuid-1',
+				'name': 'upset.manta.test.nameservice_broken0',
+				'agent': 'svc-nameservice-2',
+				'config': {
+				    'env': {
+					'complex': 'snpp',
+					'sector': '7G'
+				    }
+				}
+			    }),
+			    makeProbe({
+				'group': 'deployed-group-uuid-3',
+				'name': 'upset.manta.test.all0',
+				'agent': 'svc-nameservice-2'
+			    }),
+			    makeProbe({
+			        'group': 'deployed-group-uuid-svc-nameservice',
+				'name': 'upset.manta.test.nameservice0',
+				'agent': 'svc-nameservice-2'
+			    })
+			];
+
+			mock.config.agentprobes['svc-jobsupervisor-0'] = [
+			    makeProbe({
+				'group': 'deployed-group-uuid-3',
+				'name': 'upset.manta.test.all0',
+				'agent': 'svc-jobsupervisor-0'
+			    }),
+			    makeProbe({
+				'group': 'deployed-group-uuid-svc-' +
+				    'jobsupervisor',
+				'name': 'upset.manta.test.jobsupervisor0',
+				'agent': 'svc-jobsupervisor-0'
+			    })
+			];
+			mock.config.agentprobes['svc-jobsupervisor-1'] = [
+			    makeProbe({
+				'group': 'deployed-group-uuid-3',
+				'name': 'upset.manta.test.all0',
+				'agent': 'svc-jobsupervisor-1'
+			    }),
+			    makeProbe({
+				'group': 'deployed-group-uuid-svc-' +
+				     'jobsupervisor',
+				'name': 'upset.manta.test.jobsupervisor0',
+				'agent': 'svc-jobsupervisor-1'
+			    })
+			];
+
+			mock.config.agentprobes['server-uuid-0'] = [
+			    makeProbe({
+				'group': 'deployed-group-uuid-2',
+				'name': 'upset.manta.test.global0',
+				'agent': 'server-uuid-0'
+			    })
+			];
+			mock.config.agentprobes['server-uuid-1'] = [
+			    makeProbe({
+				'group': 'deployed-group-uuid-2',
+				'name': 'upset.manta.test.global0',
+				'agent': 'server-uuid-1'
+			    })
+			];
+
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_full = cfg;
+				subcallback();
+			});
+		},
+
+		/*
+		 * To the previous configuration, add the legacy probe group,
+		 * the operator-created probe group, the probe group from a
+		 * future version, the probes for these, the probe that has no
+		 * probe group, and the probe that has a group that doesn't
+		 * exist.
+		 */
+		function basicDcExtraProbes(subcallback) {
+			var dc = dcconfigs.cfg_basic;
+			var nsagent = dc.ctp_instances_by_svcname[
+			    'nameservice'][0];
+
+			mock.config.groups.push({
+			    'uuid': 'operator-group-1',
+			    'name': 'operator-created group 1',
+			    'user': account,
+			    'disabled': false,
+			    'contacts': [ 'operator-contact-1' ]
+			});
+			mock.config.groups.push({
+			    'uuid': 'future-group-1',
+			    'name': 'upset.manta.future;v=2',
+			    'user': account,
+			    'disabled': false,
+			    'contacts': [ 'operator-contact-2' ]
+			});
+			mock.config.groups.push({
+			    'uuid': 'nameservice-alert-uuid',
+			    'name': 'nameservice-alert',
+			    'user': account,
+			    'disabled': false,
+			    'contacts': [ 'major_contact' ]
+			});
+
+			/* probe for the operator's custom group */
+			mock.config.agentprobes['server-uuid-0'].push(
+			    makeProbe({
+			        'name': 'operator-1',
+			        'group': 'operator-group-1'
+			    }));
+			/* probe from the future */
+			mock.config.agentprobes['server-uuid-0'].push(
+			    makeProbe({
+			        'name': 'future-1',
+				'group': 'future-group-1'
+			    }));
+			/* probe having no group at all */
+			mock.config.agentprobes['server-uuid-0'].push(
+			    makeProbe({
+				'name': 'rogue'
+			    }));
+			/* probe for group that's missing */
+			mock.config.agentprobes['server-uuid-0'].push(
+			    makeProbe({
+				'name': 'badgroup',
+				'group': 'no-such-group'
+			    }));
+			/* probe for the nameservice's legacy group */
+			mock.config.agentprobes[nsagent].push(makeProbe({
+			    'name': 'nameservice-legacy',
+			    'group': 'nameservice-alert-uuid',
+			    'agent': nsagent
+			}));
+
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_extra = cfg;
+				subcallback();
+			});
+		},
+
+		/*
+		 * From the previous configuration, remove some of the probes
+		 * that we would normally deploy automatically.  This represents
+		 * a partially deployed configuration and tests that the
+		 * software does the right thing for smaller, incremental
+		 * updates.
+		 *
+		 * We also add a probe for an existing, automatically-managed
+		 * probe group and a zone that no longer exists to test that we
+		 * clean these up.
+		 */
+		function basicDcPartialProbes(subcallback) {
+			var dc = dcconfigs.cfg_basic;
+			var groupToRm = 'deployed-group-uuid-svc-nameservice';
+			var nsagent = dc.ctp_instances_by_svcname[
+			    'nameservice'][0];
+
+			/*
+			 * Remove one of the deployed probe groups and its
+			 * probes.
+			 */
+			mock.config.groups = mock.config.groups.filter(
+			    function (g) {
+				return (g.uuid != groupToRm);
+			    });
+			jsprim.forEachKey(mock.config.agentprobes,
+			    function (agentuuid, agentprobes) {
+				if (dc.ctp_instances_by_svcname[
+				    'nameservice'].indexOf(agentuuid) == -1) {
+					return;
+				}
+
+				mock.config.agentprobes[agentuuid] =
+				    agentprobes.filter(function (p) {
+					return (p.group != groupToRm);
+				    });
+			    });
+
+			/*
+			 * Remove one of the deployed probes for another probe
+			 * group.
+			 */
+			mock.config.agentprobes[nsagent] =
+			    mock.config.agentprobes[nsagent].filter(
+			    function (p) {
+				return (p.group != 'deployed-group-uuid-1');
+			    });
+
+			/*
+			 * Create probes for destroyed VMs and for a CN
+			 * associated with a destroyed VM.
+			 */
+			mock.config.agentprobes['destroyed-nameservice'] = [
+			    makeProbe({
+			        'group': 'deployed-group-uuid-1',
+				'name': 'upset.manta.test.nameservice_broken0',
+				'agent': 'destroyed-nameservice'
+			    })
+			];
+
+			mock.config.agentprobes['abandoned-cn'] = [
+			    makeProbe({
+				'group': 'deployed-group-uuid-2',
+				'name': 'upset.manta.test.global0',
+				'agent': 'abandoned-cn'
+			    })
+			];
+
+			loadDeployedForConfig(mock, dc, function (cfg) {
+				dc.ctp_deployed_partial = cfg;
+				subcallback();
+			});
+		}
+	], function (err) {
+		assertplus.ok(!err);
+		callback();
+	});
+}
+
+/*
+ * Given the mock Amon configuration and the specified datacenter configuraiton,
+ * load the set of deployed probe groups and probes.
+ */
+function loadDeployedForConfig(mock, dcconfig, callback)
+{
+	var components;
+
+	/*
+	 * We use the datacenter description to assemble a list of components
+	 * for which to fetch probes and then defer to the usual code path to
+	 * actually load the objects.
+	 */
+	assertplus.object(dcconfig.ctp_servers);
+	components = [];
+	dcconfig.ctp_servers.forEach(function (s) {
+		components.push({ 'type': 'cn', 'uuid': s });
+	});
+	jsprim.forEachKey(dcconfig.ctp_instances, function (_, instance) {
+		if (!instance.inst_local) {
+			return;
+		}
+
+		components.push({ 'type': 'vm', 'uuid': instance.inst_uuid });
+	});
+	dcconfig.ctp_vms_destroyed.forEach(function (uuid) {
+		components.push({ 'type': 'vm', 'uuid': uuid });
+	});
+	dcconfig.ctp_servers_abandoned.forEach(function (s) {
+		components.push({ 'type': 'cn', 'uuid': s });
+	});
+
+	alarms.amonLoadProbeGroups({
+	    'amon': mock.client,
+	    'account': account
+	}, function (err, config) {
+		assertplus.ok(!err);
+		assertplus.ok(config);
+		alarms.amonLoadComponentProbes({
+		    'amonRaw': mock.clientRaw,
+		    'amoncfg': config,
+		    'components': components,
+		    'concurrency': 3
+		}, function (probeError) {
+			assertplus.ok(!probeError);
+			callback(config);
+		});
+	});
+}
+
+function generateTestCases()
+{
+	var ngroupsfull, nprobesfull, nprobesmulti;
+
+	testCases = [];
+
+	/*
+	 * There are three non-"each" templates, plus an "each" template
+	 * that generates a group for each service that supports probes.
+	 */
+	ngroupsfull = deployedGroups.length + services.mSvcNamesProbes.length;
+
+	/*
+	 * For the single-DC case, we've got:
+	 *
+	 *   - 3 "nameservice" probes for the "nameservice" template
+	 *   - 2 "global" probes for the "global" template
+	 *   - 3 "nameservice" probes for the "each" template
+	 *   - 2 "jobsupervisor" probes for the "each" template
+	 *   - 5 probes for the "all" template
+	 *
+	 * totalling 15 probes.
+	 */
+	nprobesfull = 15;
+
+	/*
+	 * For the multi-DC case, we've got:
+	 *
+	 *   - 1 "nameservice" probe for the "nameservice" template
+	 *     (because other instances are in other DCs)
+	 *   - 1 "global" probe for the "global" template
+	 *     (again, because other nameservice instances are in other DCs)
+	 *   - 1 "nameservice" probe for the "each" template
+	 *   - 1 "jobsupevisor" probe for the "each" template
+	 *   - 2 probes for the "all" template
+	 */
+	nprobesmulti = 6;
+
+	testCases.push({
+	    'name': 'empty DC, undeployed, configure with no metadata',
+	    'metadata': metadataEmpty,
+	    'dcConfig': dcconfigs.cfg_empty,
+	    'deployed': 'none',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(!plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'empty DC, undeployed, configure (add groups only)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_empty,
+	    'deployed': 'none',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, ngroupsfull);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'empty DC, undeployed, unconfigure (no changes)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_empty,
+	    'deployed': 'none',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(!plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, undeployed, configure with no metadata',
+	    'metadata': metadataEmpty,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'none',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(!plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, undeployed, configure (many changes)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'none',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, ngroupsfull);
+		assertplus.strictEqual(plan.mup_probes_add.length, nprobesfull);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, undeployed, unconfigure (no changes)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'none',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(!plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, deployed, configure with no metadata',
+	    'metadata': metadataEmpty,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'full',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length,
+		    nprobesfull);
+		assertplus.strictEqual(plan.mup_groups_remove.length,
+		    ngroupsfull);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, deployed, configure (no changes)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'full',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(!plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, deployed, unconfigure (many changes)',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'full',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		assertplus.strictEqual(plan.mup_probes_remove.length,
+		    nprobesfull);
+		assertplus.strictEqual(plan.mup_groups_remove.length,
+		    ngroupsfull);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, deployed with extra, configure',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'extra',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		/* We expect to remove only the legacy group and probe. */
+		assertplus.strictEqual(plan.mup_probes_remove.length, 1);
+		assertplus.strictEqual(plan.mup_groups_remove.length, 1);
+		/* We don't expect to add anything. */
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, deployed with extra, unconfigure',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'extra',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		/*
+		 * We expect to remove the legacy group and probe, plus the
+		 * usual ones.
+		 */
+		assertplus.strictEqual(plan.mup_probes_remove.length,
+		    1 + nprobesfull);
+		assertplus.strictEqual(plan.mup_groups_remove.length,
+		    1 + ngroupsfull);
+		/* We don't expect to add anything. */
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, partially deployed, configure',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'partial',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+
+		/*
+		 * We expect to remove the legacy probe group, its probe,
+		 * and the VM-level and CN-level probes for the VM that no
+		 * longer exists and the CN that no longer hosts any VMs.
+		 */
+		assertplus.strictEqual(plan.mup_groups_remove.length, 1);
+		assertplus.strictEqual(plan.mup_probes_remove.length, 3);
+
+		/*
+		 * We expect to add one group that was missing, plus one probe
+		 * for each nameservice for the group that was missing, plus
+		 * one additional probe for the probe that was missing.
+		 */
+		assertplus.strictEqual(plan.mup_groups_add.length, 1);
+		assertplus.strictEqual(plan.mup_probes_add.length, 4);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'basic DC, partially deployed, unconfigure',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_basic,
+	    'deployed': 'partial',
+	    'unconfigure': true,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+
+		/*
+		 * We expect to remove all of the usual groups except for the
+		 * one that was already missing (because this was a partial
+		 * deployment to begin with), plus the legacy one.
+		 */
+		assertplus.strictEqual(plan.mup_groups_remove.length,
+		    ngroupsfull);
+
+		/*
+		 * Similarly, we expect to remove all of the usual probes except
+		 * for the four that were already missing (because this was a
+		 * partial deployment), plus the legacy one, plus the one each
+		 * for the VM and CN that no longer exist.
+		 */
+		assertplus.strictEqual(plan.mup_probes_remove.length,
+		    nprobesfull - 1);
+		assertplus.strictEqual(plan.mup_groups_add.length, 0);
+		assertplus.strictEqual(plan.mup_probes_add.length, 0);
+	    }
+	});
+
+	testCases.push({
+	    'name': 'multi DC, undeployed, configure',
+	    'metadata': metadataBasic,
+	    'dcConfig': dcconfigs.cfg_multi,
+	    'deployed': 'none',
+	    'unconfigure': false,
+	    'verify': function (plan) {
+		assertplus.ok(plan.needsChanges());
+		assertplus.strictEqual(plan.mup_groups_remove.length, 0);
+		assertplus.strictEqual(plan.mup_probes_remove.length, 0);
+		assertplus.strictEqual(plan.mup_groups_add.length, ngroupsfull);
+		assertplus.strictEqual(plan.mup_probes_add.length,
+		    nprobesmulti);
+	    }
+	});
+}
+
+function runTestCase(tc)
+{
+	var dc, plan;
+
+	console.error(tc.name);
+
+	dc = tc.dcConfig;
+	assertplus.ok(tc.deployed == 'none' || tc.deployed == 'full' ||
+	    tc.deployed == 'extra' || tc.deployed == 'partial');
+	plan = alarms.amonUpdatePlanCreate({
+	    'account': account,
+	    'contactsBySeverity': contactsBySeverity,
+	    'instances': dc.ctp_instances,
+	    'instancesBySvc': dc.ctp_instances_by_svcname,
+	    'deployed': tc.deployed == 'none' ?  dc.ctp_deployed_none :
+		tc.deployed == 'extra' ? dc.ctp_deployed_extra :
+		tc.deployed == 'partial' ? dc.ctp_deployed_partial :
+		dc.ctp_deployed_full,
+	    'metadata': tc.metadata,
+	    'unconfigure': tc.unconfigure
+	});
+	assertplus.ok(!(plan instanceof Error));
+	tc.verify(plan);
+}
+
+function makeProbe(params)
+{
+	var agent, machine;
+
+	agent = params.agent || 'server-uuid-0';
+	machine = params.machine || agent;
+
+	return ({
+	    'uuid': 'probe-uuid-' + params.name,
+	    'name': 'probe-name-' + params.name,
+	    'group': params.group || null,
+	    'user': account,
+	    'type': 'cmd',
+	    'config': params.config || {},
+	    'agent': agent,
+	    'machine': machine,
+	    'groupEvents': true
+	});
+}
+
+function DatacenterConfig()
+{
+	/* CN uuids for local servers */
+	this.ctp_servers = [];
+	/* all instances in all DCs (mapping instance uuid -> InstanceInfo) */
+	this.ctp_instances = {};
+	/* local instances (mapping svcname -> array of instance uuids) */
+	this.ctp_instances_by_svcname = {};
+
+	/* destroyed VMs (list of uuids) */
+	this.ctp_vms_destroyed = [];
+
+	/* abandoned CNs (list of uuids) */
+	this.ctp_servers_abandoned = [];
+
+	/* Deployed Amon objects */
+	this.ctp_deployed_full = null;	/* when full */
+	this.ctp_deployed_none = null;	/* when empty */
+	this.ctp_deployed_extra = null;	/* when full, plus a few other cases */
+}
+
+main();
diff --git a/test/tst.services.js b/test/tst.services.js
index 217613f..bf2cf11 100644
--- a/test/tst.services.js
+++ b/test/tst.services.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2016, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /*
@@ -87,6 +87,16 @@ function main()
 		}
 	});
 
+	/*
+	 * Test serviceSupportsProbes().
+	 */
+	assertplus.deepEqual([ 'marlin', 'propeller' ], knownServices.filter(
+	    function (svcname) {
+		return (!services.serviceSupportsProbes(svcname));
+	    }));
+	assertplus.deepEqual(services.mSvcNamesProbes,
+	    services.mSvcNames.filter(services.serviceSupportsProbes));
+
 	console.error('%s tests passed', __filename);
 }
 
diff --git a/tools/probecfgchk.js b/tools/probecfgchk.js
new file mode 100755
index 0000000..4aefe7f
--- /dev/null
+++ b/tools/probecfgchk.js
@@ -0,0 +1,63 @@
+#!/usr/bin/env node
+
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * probecfgchk: validates a given probe configuration file
+ */
+
+var cmdutil = require('cmdutil');
+var vasync = require('vasync');
+
+var alarm_metadata = require('../lib/alarms/metadata');
+var nerrors = 0;
+
+function main()
+{
+	cmdutil.configure({
+	    'synopses': [ 'FILENAME...' ],
+	    'usageMessage': 'validates one or more probe template files'
+	});
+
+	if (process.argv.length < 3) {
+		cmdutil.usage();
+	}
+
+	vasync.forEachPipeline({
+	    'func': validateOneFile,
+	    'inputs': process.argv.slice(2)
+	}, function () {
+		process.exit(nerrors === 0 ? 0 : 1);
+	});
+}
+
+function validateOneFile(filename, callback)
+{
+	var pts;
+
+	pts = new alarm_metadata.MetadataLoader();
+	pts.loadFromFile(filename, function onLoaded() {
+		var errors;
+
+		errors = pts.errors();
+		nerrors += errors.length;
+
+		if (errors.length === 0) {
+			console.error('%s okay', filename);
+		} else {
+			errors.forEach(function (e) { cmdutil.warn(e); });
+		}
+
+		callback();
+	});
+}
+
+main();
-- 
2.21.0

