commit 1d42635ed7e1002cbd2d6e8c4774f418fcdba5ff
Author: Trent Mick <trentm@gmail.com>
Date:   2018-11-01T15:05:23-07:00 (11 months ago)
    
    MANTA-3552 create Manta Prometheus image

diff --git a/.gitignore b/.gitignore
index f089238..6ddcf39 100644
--- a/.gitignore
+++ b/.gitignore
@@ -2,4 +2,5 @@
 /node_modules
 /make_stamps
 /npm-debug.log
-/build
+/cache
+/prometheus-pkg-*.tar.bz2
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..abeb971
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,6 @@
+[submodule "deps/prometheus"]
+	path = deps/prometheus
+	url = https://github.com/joyent/prometheus.git
+[submodule "deps/sdc-scripts"]
+	path = deps/sdc-scripts
+	url = https://github.com/joyent/sdc-scripts.git
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..c677124
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,98 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+GO_PREBUILT_VERSION = 1.10.3
+
+include ./tools/mk/Makefile.defs
+include ./tools/mk/Makefile.smf.defs
+ifeq ($(shell uname -s),SunOS)
+    include ./tools/mk/Makefile.go_prebuilt.defs
+endif
+
+SERVICE_NAME = prometheus
+RELEASE_TARBALL := $(SERVICE_NAME)-pkg-$(STAMP).tar.bz2
+RELSTAGEDIR := /tmp/$(STAMP)
+SMF_MANIFESTS = smf/manifests/prometheus.xml
+
+PROMETHEUS_IMPORT = github.com/prometheus/prometheus
+PROMETHEUS_GO_DIR = $(GO_GOPATH)/src/$(PROMETHEUS_IMPORT)
+PROMETHEUS_EXEC = $(PROMETHEUS_GO_DIR)/prometheus
+
+#
+# Repo-specific targets
+#
+.PHONY: all
+all: $(PROMETHEUS_EXEC)
+
+#
+# Link the "pg_prefaulter" submodule into the correct place within our
+# project-local GOPATH, then build the binary.
+#
+$(PROMETHEUS_EXEC): deps/prometheus/.git $(STAMP_GO_TOOLCHAIN)
+	$(GO) version
+	mkdir -p $(dir $(PROMETHEUS_GO_DIR))
+	rm -f $(PROMETHEUS_GO_DIR)
+	ln -s $(TOP)/deps/prometheus $(PROMETHEUS_GO_DIR)
+	(cd $(PROMETHEUS_GO_DIR) && env -i $(GO_ENV) make build)
+
+.PHONY: release
+release: all deps docs $(SMF_MANIFESTS)
+	@echo "Building $(RELEASE_TARBALL)"
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)
+	cp -r \
+		$(TOP)/bin \
+		$(TOP)/package.json \
+		$(TOP)/smf \
+		$(TOP)/sapi_manifests \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/
+	# our prometheus build
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/prometheus
+	cp -r \
+		$(PROMETHEUS_GO_DIR)/prometheus \
+		$(PROMETHEUS_GO_DIR)/promtool \
+		$(PROMETHEUS_GO_DIR)/consoles \
+		$(PROMETHEUS_GO_DIR)/console_libraries \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/prometheus/
+	# zone boot
+	mkdir -p $(RELSTAGEDIR)/root/opt/smartdc/boot
+	cp -r $(TOP)/deps/sdc-scripts/{etc,lib,sbin,smf} \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	cp -r $(TOP)/boot/* \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	# tar it up
+	(cd $(RELSTAGEDIR) && $(TAR) -jcf $(TOP)/$(RELEASE_TARBALL) root)
+	@rm -rf $(RELSTAGEDIR)
+
+
+.PHONY: publish
+publish: release
+	@if [[ -z "$(BITS_DIR)" ]]; then \
+		echo "error: 'BITS_DIR' must be set for 'publish' target"; \
+		exit 1; \
+	fi
+	mkdir -p $(BITS_DIR)/$(SERVICE_NAME)
+	cp $(TOP)/$(RELEASE_TARBALL) $(BITS_DIR)/$(SERVICE_NAME)/$(RELEASE_TARBALL)
+
+.PHONY: dumpvar
+dumpvar:
+	@if [[ -z "$(VAR)" ]]; then \
+		echo "error: set 'VAR' to dump a var"; \
+		exit 1; \
+	fi
+	@echo "$(VAR) is '$($(VAR))'"
+
+mytarget:
+	echo my command
+
+ifeq ($(shell uname -s),SunOS)
+    include ./tools/mk/Makefile.go_prebuilt.targ
+endif
+include ./tools/mk/Makefile.smf.targ
+include ./tools/mk/Makefile.targ
diff --git a/README.md b/README.md
index 1103c15..7e1c97f 100644
--- a/README.md
+++ b/README.md
@@ -1,32 +1,160 @@
 # triton-prometheus
 
-A repo with tooling to setup Prometheus and Grafana in a TritonDC for metrics
-and monitoring of Triton itself. The goal is to make it easy (and somewhat
-standardized, to simplify collaboration) to work with and monitor TritonDC
-metrics.
+The Triton core prometheus service. Triton is moving to using prometheus
+and [grafana](https://github.com/joyent/triton-grafana) to track its own
+metrics and to provide an option for monitoring Triton itself. All Triton
+metrics are gathered via [CMON](https://github.com/joyent/triton-cmon).
+
 
 ## Status
 
-For now this just houses lowly bash scripts for setting up prometheus0
-and grafana0 zones on a Triton headnode. Eventually this might turn into a core
-TritonDC "prometheus" and "grafana" services.
+The Triton core prometheus and grafana services are currently being actively
+developed. [RFD 150](https://github.com/joyent/rfd/tree/master/rfd/0150)
+describes the current plan and status.
+
+
+## Setup
+
+First ensure that [CMON](https://github.com/joyent/triton-cmon) and
+[CNS](https://github.com/joyent/triton-cns) are setup in your TritonDC,
+typically via:
+
+    sdcadm post-setup cns [OPTIONS]
+    sdcadm post-setup cmon [OPTIONS]
+
+Then run the following from your TritonDC's headnode global zone:
+
+    sdcadm post-setup prometheus [OPTIONS]
+
+
+## Configuration
+
+Primarily this VM runs a Prometheus server (as the "prometheus" SMF service).
+The config files for that service are as follows. Note that "/data/..." is a
+delegate dataset to persist through reprovisions.
+
+    /data/prometheus/etc/prometheus.yml
+    /data/prometheus/keys/*             # data with which to auth to CMON
+
+Like most Triton core VM services, a config-agent is used to gather some
+config data. Unlike many Triton core services, this VM uses an additional
+config processing step to create the final prometheus config. At the
+time of writing this is to allow handling an optional "cmon_domain" config var
+for which the fallback default requires some processing (querying CNS for
+the appropriate DNS zone). The basic process is:
+
+1. config-agent runs to fill out "/data/prometheus/etc/sapi-inst-data.json"
+2. The config-agent `post_cmd` runs
+   `/opt/triton/prometheus/bin/prometheus-configure` to create the final
+   `/data/prometheus/etc/prometheus.yml` and enable/restart/clear prometheus,
+   if changed. In addition, on *reprovision*, "sapi-inst-data.json" might
+   already exist because it is on a delegate dataset. Therefore, "boot/setup.sh"
+   will also call `prometheus-configure`.
+
+
+## SAPI Configuration
+
+There are some Triton Prometheus service configuration options that can be
+set in SAPI.
+
+| Key                              | Type   | Description |
+| -------------------------------- | ------ | ----------- |
+| **cmon\_domain**                 | String | Optional. The domain at which Prometheus should talk to this DC's CMON, e.g. "cmon.us-east-1.triton.zone". The actual endpoint is assumed to be https and port 9163. See notes below. |
+| **cmon\_insecure\_skip\_verify** | Bool   | Optional. If `cmon_domain` is provided, this can be set to `true` to have Prometheus ignore TLS cert errors from a self-signed cert. |
+
+Prometheus gets its metrics from the DC's local CMON, typically over the
+external network. To auth with CMON properly in a production environment, it
+needs to know the appropriate CMON URL advertized to public DNS and for which
+it has a signed TLS certificate. This is what `cmon_domain` is for. If this is
+not specified, then this image will attempt to infer an appropriate URL
+via querying the DC's local CNS. See `bin/prometheus-configure` for details.
+
+
+An example setting these values:
+
+    promSvc=$(sdc-sapi /services?name=prometheus | json -Ha uuid)
+    sdc-sapi /services/$promSvc -X PUT \
+        -d '{"metadata": {"cmon_domain": "mycmon.example.com", "cmon_insecure_skip_verify": true}}'
+
+
+## CMON Auth
+
+Prometheus needs to auth with the local CMON. To do this its zone setup creates
+a key and appropriate client certificate in "/data/prometheus/keys/". The
+created public key *must be added to the 'admin' account*. Typically this is
+handled automatically by `sdcadm post-setup prometheus` (VM setup adds its
+public key to its `instPubKey` metadata key, from which sdcadm grabs it).
+
+
+## Security
+
+Prometheus listens on the admin and external networks. The firewall with the
+[standard Triton rules](https://github.com/joyent/sdc-headnode/blob/34dbd8acd65523c844385a81239ea0a872750326/scripts/headnode.sh#L188-L228)
+is enabled to disallow incoming requests on the external network.
+
+Prometheus is on the external network so it can access CMON and work with CNS --
+at least until CNS support split horizon DNS to provide separate records on the
+admin network. This is because CMON's Triton service discovery returns the CNS
+domain names for Triton's core VMs.
+
+Prometheus is on the admin network because Triton's Grafana accesses prometheus
+on the admin.
+
+
+## Troubleshooting
+
+### Prometheus doesn't have Triton data
+
+Triton's Prometheus gets its data from CMON. Here are some things to check
+if this appears to be failing:
+
+- Does the following Prometheus query have any data?
+
+        cpucap_cur_usage_percentage{alias=~"cnapi.+"}
+
+- Does the Prometheus config (/data/prometheus/etc/prometheus.yml) look correct?
+
+- Is Prometheus running? `svcs prometheus`
 
-## How to deploy Prometheus and Grafana for monitoring Triton
+- Does the Prometheus log show errors? E.g. (newlines added for readability):
 
-Run the following from your computer/laptop. Assuming you have something like
-this in your "~/.ssh/config":
+    ```
+    $ tail `svcs -L prometheus`
+    ...
+    level=error ts=2018-09-28T18:42:33.715136969Z caller=triton.go:170
+        component="discovery manager scrape"
+        discovery=trition
+        msg="Refreshing targets failed"
+        err="an error occurred when requesting targets from the discovery endpoint.
+            Get https://mycmon.example.com:9163/v1/discover: dial tcp:
+            lookup mycmon.example.com on 8.8.8.8:53: no such host"
+    ```
 
-	Host coal
-		User root
-		Hostname 10.99.99.7
-		StrictHostKeyChecking no
-		UserKnownHostsFile /dev/null
+- Is Prometheus' Triton service discovery authenticating properly to CMON? If
+  not, the CMON log will show something like this:
 
-Run this:
+    ```
+    [2018-10-04T22:27:37.632Z]  INFO: cmon/17801 on 2539de9f-43d0-49c4-af79-4f02d53dcdde: handled: 401 (req_id=495dcfb9-054a-48fd-85b4-ed0a1500b9bc, route=getcontainers, audit=true, remoteAddress=10.128.0.10, remotePort=58600, latency=2, _audit=true, req.query="", req.version=*)
+        GET /v1/discover HTTP/1.1
+        host: cmon.coal.cns.joyent.us:9163
+        user-agent: Go-http-client/1.1
+        accept-encoding: gzip
+        --
+        HTTP/1.1 401 Unauthorized
+        content-type: application/json
+        content-length: 41
+        date: Thu, 04 Oct 2018 22:28:37 GMT
+        server: cmon
+        x-request-id: 0a1f7159-39f7-45a6-b724-f9ec68831899
+        x-response-time: 18
+        x-server-name: 2539de9f-43d0-49c4-af79-4f02d53dcdde
 
-    ./setup-prometheus.sh coal      # create a prometheus0 zone
-    ./setup-grafana.sh coal         # create a grafana0 zone
+        {
+          "code": "UnauthorizedError",
+          "message": ""
+        }
+    ```
 
-Then wait about 5 minutes for metrics to start coming in (I don't know what
-the exact delay is) and visit the grafana URL (it is printed at the end of
-`setup-grafana.sh ...`).
+    One reason for failures might be that the Prometheus public key
+    (at "/data/prometheus/etc/prometheus.id_rsa.pub") has not been added to
+    the admin user. See `sdc-useradm keys admin`.
diff --git a/bin/prometheus-configure b/bin/prometheus-configure
new file mode 100755
index 0000000..ab6d35d
--- /dev/null
+++ b/bin/prometheus-configure
@@ -0,0 +1,296 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Updates configation files for Prometheus and enables/restarts/clears
+# the SMF prometheus service as necessary.
+#
+# It is expected that this is run via the config-agent "prometheus" manifest
+# `post_cmd` (see "/opt/triton/prometheus/sapi_manifests/prometheus").
+# However, running it directly is supported as well.
+#
+
+#
+# Dev Notes:
+# - Do we need retries on requests to CNS? Probably yes. Currently determining
+#   the default CMON URL and resolv.conf update for the dev config is brittle
+#   by being dependent on the CNS service being up.
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+set -o errexit
+set -o pipefail
+
+PATH=/opt/local/bin:/opt/local/sbin:/usr/bin:/usr/sbin
+
+DATACENTER_NAME=
+DNS_DOMAIN=
+SAPI_INST_DATA_JSON=/data/prometheus/etc/sapi-inst-data.json
+PROMETHEUS_YML=/data/prometheus/etc/prometheus.yml
+
+# A space-separated list of names of things updated. This is used to determine
+# if the prometheus SMF service needs to be restarted.
+UPDATES_MADE=
+
+# Key file paths. Keep in sync with "boot/setup.sh".
+# - PEM format private key
+PRIV_KEY_FILE=/data/prometheus/keys/prometheus.id_rsa
+# - Public client cert file derived from the key.
+CLIENT_CERT_FILE=/data/prometheus/keys/prometheus.cert.pem
+
+
+# ---- support routines
+
+function fatal {
+    printf '%s: ERROR: %s\n' "$(basename $0)" "$*" >&2
+    exit 1
+}
+
+# Attempt to guess an appropriate CMON URL. This setup is appropriate for
+# a development setup.
+function prometheus_configure_get_default_cmon_domain() {
+    local cnsUrl
+    local ownerUuid
+    local externalNet
+    local suffixesForVm
+    local cnsStatusCode
+    local suffix
+    local cmonDomain
+
+    # Ask CNS for the DNS suffixes in use for the external (non-admin)
+    # network.
+    #
+    #    e.g.:
+    #    {
+    #      "suffixes": [
+    #        "svc.930896af-bf8c-48d4-885c-6573a94b1853.coal.cns.joyent.us",
+    #        "inst.930896af-bf8c-48d4-885c-6573a94b1853.coal.cns.joyent.us"
+    #      ]
+    #    }
+    cnsUrl=http://cns.$DATACENTER_NAME.$DNS_DOMAIN
+    ownerUuid=$(mdata-get sdc:owner_uuid)
+    exteralNet=$(mdata-get sdc:nics | json -c 'this.nic_tag !== "admin"' 0.network_uuid)
+    [[ -n "$exteralNet" ]] || fatal "could not determine non-admin NIC for this VM"
+    suffixesForVm="$(curl -i -X POST -H "Content-Type: application/json" -s $cnsUrl/suffixes-for-vm -d@/dev/stdin <<PAYLOAD | json
+    {
+        "owner_uuid": "$ownerUuid",
+        "networks": [
+            "$exteralNet"
+        ]
+    }
+PAYLOAD
+)"
+    cnsStatusCode=$(echo "$suffixesForVm" | head -1 | awk '{print $2}')
+    [[ $cnsStatusCode == "200" ]] \
+        || fatal "error retrieving suffixes-for-vm from CNS: status $cnsStatusCode"
+
+    # Then use suffix -- everything after the account UUID -- on the first
+    # "suffixes" entry.
+    suffix=$(echo "$suffixesForVm" | json -H suffixes.0 | cut -d. -f3-)
+
+    cmonDomain="cmon.$suffix"
+    echo "$cmonDomain"
+}
+
+
+# Update /etc/resolv.conf as necessary.
+#
+# Side-effect: Updates "UPDATES_MADE" global.
+function prometheus_configure_update_resolv_conf() {
+    local requireCnsResolver=$1
+    local resolvers
+    local binderIp
+    local cnsIp
+
+    resolvers=$(mdata-get sdc:resolvers | json -a)
+
+    echo "search $DNS_DOMAIN" > /etc/resolv.conf.new
+
+    if [[ "$requireCnsResolver" == "yes" ]]; then
+        # Ensure that the CNS IP (any will do, we'll use its admin IP because
+        # that is easy for us to lookup in binder) is first in this zone's
+        # resolv.conf.
+        # Limitation: This just uses the first CNS in DNS if there are many.
+        #
+        # We have to specify the binder IP because (a) `dig` only looks at the
+        # first nameserver in /etc/resolv.conf and (b) we might have the CNS
+        # IP as the first resolver.
+        binderIp=$(echo "$resolvers" | head -1)
+        cnsIp=$(dig @$binderIp +short cns.$DATACENTER_NAME.$DNS_DOMAIN | head -1)
+        [[ -n "$cnsIp" ]] || fatal "could not determine IP for CNS"
+
+        # We need this to be the first nameserver line because, e.g., 8.8.8.8
+        # will error out on these internal DNS names.
+        echo "nameserver $cnsIp" >> /etc/resolv.conf.new
+    fi
+
+    echo "$resolvers" | while read ip; do
+        echo "nameserver $ip" >> /etc/resolv.conf.new
+    done
+
+
+    if ! diff /etc/resolv.conf /etc/resolv.conf.new >/dev/null; then
+        echo "Updating /etc/resolve.conf (requireCnsResolver=$requireCnsResolver)"
+        cp /etc/resolv.conf /etc/resolv.conf.bak
+        mv /etc/resolv.conf.new /etc/resolv.conf
+        UPDATES_MADE="$UPDATES_MADE resolv.conf"
+    fi
+
+    return 0
+}
+
+# Update the prometheus config as required. Note this may involve updating
+# resolv.conf as well.
+#
+# Side-effect: Updates "UPDATES_MADE" global.
+function prometheus_configure_update_config() {
+    local cmonDomain
+    local cmonInsecure
+    local requireCnsResolver
+
+    # The appropriate CMON URL is either from the service config, or fallback
+    # to guessing from CNS suffix for admin VMs.
+    cmonDomain=$(json -f $SAPI_INST_DATA_JSON cmon_domain)
+    if [[ -z "$cmonDomain" ]]; then
+        cmonDomain=$(prometheus_configure_get_default_cmon_domain)
+        cmonInsecure=true
+        if [[ -z "$cmonDomain" ]]; then
+            fatal "'cmon_domain' service config is not set and could not determine a default CMON URL"
+        fi
+
+        # The "default" CMON URL here is the code path for development
+        # convenience. We only assume that CNS is minimally setup per
+        #     https://github.com/joyent/triton-cns/blob/master/docs/operator-guide.md#small-developmenttesting-setup
+        # To resolve CNS names for CMON we then need CNS' IP in this zone's
+        # resolv.conf (public DNS, e.g. 8.8.8.8, won't know anything about
+        # these domain names).
+        #
+        # Dev Note: An alternative to consider would be to put the CNS IP
+        # in the set of resolvers for the "admin" network. That's an impactful
+        # change, however.
+        requireCnsResolver=yes
+    else
+        cmonInsecure=$(json -f $SAPI_INST_DATA_JSON cmon_insecure_skip_verify)
+        if [[ -z "$cmonInsecure" ]]; then
+            cmonInsecure=false
+        fi
+        requireCnsResolver=no
+    fi
+
+    # Update /etc/resolv.conf as appropriate.
+    prometheus_configure_update_resolv_conf $requireCnsResolver
+
+    # Generate the config.
+    cat >${PROMETHEUS_YML}.new <<CONFIG
+global:
+  scrape_interval:     15s # Default is 1 minute.
+  evaluation_interval: 15s # Default is 1 minute.
+  # scrape_timeout is set to the global default (10s).
+
+scrape_configs:
+  # The job name is added as a label 'job=<job_name>' to any timeseries scraped
+  # from this config.
+  - job_name: 'admin_${DATACENTER_NAME}'
+    scheme: https
+    tls_config:
+      cert_file: $CLIENT_CERT_FILE
+      key_file: $PRIV_KEY_FILE
+      insecure_skip_verify: $cmonInsecure
+    relabel_configs:
+      - source_labels: [__meta_triton_machine_alias]
+        target_label: alias
+      - source_labels: [__meta_triton_machine_id]
+        target_label: instance
+    triton_sd_configs:
+      - account: 'admin'
+        dns_suffix: '$cmonDomain'
+        endpoint: '$cmonDomain'
+        version: 1
+        tls_config:
+          cert_file: $CLIENT_CERT_FILE
+          key_file: $PRIV_KEY_FILE
+          insecure_skip_verify: $cmonInsecure
+CONFIG
+
+    # Update the config, if changed.
+    if [[ ! -f ${PROMETHEUS_YML} ]]; then
+        # First time config.
+        echo "Writing first time prometheus config ($PROMETHEUS_YML)"
+        mv ${PROMETHEUS_YML}.new ${PROMETHEUS_YML}
+        UPDATES_MADE="$UPDATES_MADE prometheus.yml"
+    elif ! diff ${PROMETHEUS_YML} ${PROMETHEUS_YML}.new >/dev/null; then
+        # The config differs.
+        echo "Updating prometheus config ($PROMETHEUS_YML)"
+        cp ${PROMETHEUS_YML} ${PROMETHEUS_YML}.bak
+        mv ${PROMETHEUS_YML}.new ${PROMETHEUS_YML}
+        UPDATES_MADE="$UPDATES_MADE prometheus.yml"
+    fi
+
+    return 0
+}
+
+# The prometheus SMF service runs as the 'nobody' user, so the files it
+# accesses must be owned by nobody.
+function prometheus_configure_ensure_nobody_owner() {
+    local output
+
+    output=$(chown -c nobody:nobody \
+        $PROMETHEUS_YML \
+        $PRIV_KEY_FILE \
+        $CLIENT_CERT_FILE \
+        /data/prometheus/data)
+    if [[ -n "$output" ]]; then
+        UPDATES_MADE="$UPDATES_MADE chown"
+        echo "$output"
+    fi
+
+    return 0
+}
+
+# Enable/restart/clear prometheus, if necessary. Note: This uses the global
+# "UPDATES_MADE" to determine if config file changes have been made.
+function prometheus_configure_restart_prom() {
+    local currState
+
+    currState=$(svcs -Ho state prometheus)
+    if [[ "$currState" == "disabled" ]]; then
+        # Zone setup starts with prometheus in disabled state. We enable it
+        # after the config is generated for the first time.
+        echo "Enabling prometheus SMF service"
+        svcadm enable prometheus
+    elif [[ "$currState" == "online" ]]; then
+        if [[ -n "$UPDATES_MADE" ]]; then
+            echo "Restarting prometheus SMF service"
+            svcadm restart prometheus
+        fi
+    elif [[ "$currState" == "maintenance" ]]; then
+        echo "Clearing prometheus SMF service"
+        svcadm clear prometheus
+    else
+        fatal "unexpected prometheus service state: '$currState'"
+    fi
+
+    return 0
+}
+
+
+
+# ---- mainline
+
+DATACENTER_NAME=$(mdata-get sdc:datacenter_name)
+DNS_DOMAIN=$(mdata-get sdc:dns_domain)
+
+prometheus_configure_update_config
+prometheus_configure_ensure_nobody_owner
+prometheus_configure_restart_prom
+
+exit 0
diff --git a/boot/configure.sh b/boot/configure.sh
new file mode 100755
index 0000000..92bf518
--- /dev/null
+++ b/boot/configure.sh
@@ -0,0 +1,17 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+# Nothing to do on each boot.
+
+exit 0
diff --git a/boot/setup.sh b/boot/setup.sh
new file mode 100755
index 0000000..2faa634
--- /dev/null
+++ b/boot/setup.sh
@@ -0,0 +1,162 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# One-time setup of a Triton prometheus core zone.
+#
+# It is expected that this is run via the standard Triton user-script,
+# i.e. as part of the "mdata:execute" SMF service. That user-script ensures
+# this setup.sh is run once for each (re)provision of the image. However this
+# script should also be idempotent.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+PATH=/opt/local/bin:/opt/local/sbin:/usr/bin:/usr/sbin
+
+# Prometheus data is stored on its delegate dataset:
+#
+#   /data/prometheus/
+#       data/    # TSDB database
+#       etc/     # config file(s)
+#       keys/    # keys with which to auth with CMON
+#
+PERSIST_DIR=/data/prometheus
+DATA_DIR=$PERSIST_DIR/data
+ETC_DIR=$PERSIST_DIR/etc
+KEY_DIR=$PERSIST_DIR/keys
+
+SAPI_INST_DATA_JSON=$ETC_DIR/sapi-inst-data.json
+
+# Key file paths. Keep in sync with "bin/prometheus-configure".
+# - PEM format private key
+PRIV_KEY_FILE=$KEY_DIR/prometheus.id_rsa
+# - SSH public key (to be added to admin)
+PUB_KEY_FILE=$KEY_DIR/prometheus.id_rsa.pub
+# - Public client cert file derived from the key.
+CLIENT_CERT_FILE=$KEY_DIR/prometheus.cert.pem
+
+
+# ---- internal routines
+
+function fatal {
+    printf '%s: ERROR: %s\n' "$(basename $0)" "$*" >&2
+    exit 1
+}
+
+
+# Mount our delegated dataset at /data.
+function prometheus_setup_delegate_dataset() {
+    local data
+    local mountpoint
+
+    dataset=zones/$(zonename)/data
+    mountpoint=$(zfs get -Hp mountpoint $dataset | awk '{print $3}')
+    if [[ $mountpoint != "/data" ]]; then
+        zfs set mountpoint=/data $dataset
+    fi
+}
+
+
+# Setup key and client certificate used to auth with this DC's CMON.
+function prometheus_setup_key() {
+    local key_name
+
+    if [[ -f "$CLIENT_CERT_FILE" && -f "$PRIV_KEY_FILE" && -f "$PUB_KEY_FILE" ]]; then
+        echo "Key files already exist: $CLIENT_CERT_FILE, $PRIV_KEY_FILE, $PUB_KEY_FILE"
+    else
+        echo "Generating key and client cert for CMON auth"
+        mkdir -p $KEY_DIR
+        key_name=prometheus-$(zonename | cut -d- -f1)-$(date -u '+%Y%m%dT%H%M%S')
+        # Creating auth keys and cert per CMON docs:
+        # https://github.com/joyent/triton-cmon/blob/master/docs/INSTALLING.md#create-a-certificate-from-your-private-key
+        ssh-keygen -t rsa -b 2048 -f $PRIV_KEY_FILE -N "" -C "$key_name"
+        openssl req -new -key $PRIV_KEY_FILE -out /tmp/prometheus.csr.pem \
+            -subj "/CN=admin"
+        openssl x509 -req -days 365 -in /tmp/prometheus.csr.pem \
+            -signkey $PRIV_KEY_FILE -out $CLIENT_CERT_FILE
+
+        # We write our public key to metadata so external tooling (typically
+        # `sdcadm post-setup prometheus`) can add this key to the 'admin'
+        # account for auth to CMON.
+        mdata-put instPubKey < $PUB_KEY_FILE
+    fi
+
+    return 0
+}
+
+
+function prometheus_setup_env {
+    if ! grep prometheus /root/.profile >/dev/null; then
+        echo "" >>/root/.profile
+        echo "export PATH=/opt/triton/prometheus/bin:/opt/triton/prometheus/prometheus:\$PATH" >>/root/.profile
+    fi
+}
+
+
+function prometheus_setup_prometheus {
+    local config_file
+    local dc_name
+    local dns_domain
+
+    config_file=$ETC_DIR/prometheus.yml
+    dc_name=$(mdata-get sdc:datacenter_name)
+    dns_domain=$(mdata-get sdc:dns_domain)
+    if [[ -z "$dns_domain" ]]; then
+        # As of TRITON-92, we expect sdcadm to set this for all core Triton
+        # zones.
+        fatal "could not determine 'dns_domain'"
+    fi
+
+    mkdir -p $ETC_DIR
+    mkdir -p $DATA_DIR
+
+    # This is disabled by default. It is up to 'prometheus-configure' to
+    # enable it.
+    /usr/sbin/svccfg import /opt/triton/prometheus/smf/manifests/prometheus.xml
+
+    # 'prometheus-configure' is typically run by config-agent via the template
+    # 'post_cmd' (for first-time zone setup and for config changes). However,
+    # this file is on the delegate dataset, so for reprovisions config-agent
+    # might not have a change to make.
+    if [[ -f $SAPI_INST_DATA_JSON ]]; then
+        TRACE=1 /opt/triton/prometheus/bin/prometheus-configure
+    fi
+
+    return 0
+}
+
+
+# ---- mainline
+
+prometheus_setup_delegate_dataset
+prometheus_setup_key
+prometheus_setup_env
+
+# Before 'sdc_common_setup' so the prometheus SMF service is imported before
+# config-agent is first setup.
+prometheus_setup_prometheus
+
+
+CONFIG_AGENT_LOCAL_MANIFESTS_DIRS=/opt/triton/prometheus
+source /opt/smartdc/boot/lib/util.sh
+sdc_common_setup
+
+# Log rotation.
+sdc_log_rotation_add config-agent /var/svc/log/*config-agent*.log 1g
+sdc_log_rotation_add registrar /var/svc/log/*registrar*.log 1g
+sdc_log_rotation_add prometheus /var/svc/log/*prometheus*.log 1g
+sdc_log_rotation_setup_end
+
+sdc_setup_complete
+
+exit 0
diff --git a/deps/prometheus b/deps/prometheus
new file mode 160000
index 0000000..4267e06
--- /dev/null
+++ b/deps/prometheus
@@ -0,0 +1 @@
+Subproject commit 4267e0677d33aff01c19d4bb4107f0dee482bbb9
diff --git a/deps/sdc-scripts b/deps/sdc-scripts
new file mode 160000
index 0000000..deefaef
--- /dev/null
+++ b/deps/sdc-scripts
@@ -0,0 +1 @@
+Subproject commit deefaef587ed3bee2706cb6e53ee3468e682932e
diff --git a/sapi_manifests/prometheus/manifest.json b/sapi_manifests/prometheus/manifest.json
new file mode 100644
index 0000000..83b4982
--- /dev/null
+++ b/sapi_manifests/prometheus/manifest.json
@@ -0,0 +1,5 @@
+{
+	"name": "prometheus",
+	"path": "/data/prometheus/etc/sapi-inst-data.json",
+	"post_cmd": "/opt/triton/prometheus/bin/prometheus-configure"
+}
diff --git a/sapi_manifests/prometheus/template b/sapi_manifests/prometheus/template
new file mode 100644
index 0000000..e3bb2fd
--- /dev/null
+++ b/sapi_manifests/prometheus/template
@@ -0,0 +1,11 @@
+{
+{{#cmon_domain}}
+    "cmon_domain": "{{{cmon_domain}}}",
+{{/cmon_domain}}
+{{#cmon_insecure_skip_verify}}
+    "cmon_insecure_skip_verify": {{{cmon_insecure_skip_verify}}},
+{{/cmon_insecure_skip_verify}}
+
+    {{! "_eof" is an unused key for convenience handling the trailing comma }}
+    "_eof": null
+}
diff --git a/setup-grafana.sh b/setup-grafana.sh
deleted file mode 100755
index 3fc09df..0000000
--- a/setup-grafana.sh
+++ /dev/null
@@ -1,201 +0,0 @@
-#!/bin/bash
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-# Copyright (c) 2018 Joyent, Inc.
-#
-
-#
-# Run this on your laptop to setup a Triton "grafana0" zone on the given Triton
-# headnode. Typicallly you would have previously run `setup-prometheus.sh`
-# to have created a prometheus0 zone.
-#
-# On a new coal, run `trentops/bin/coal-post-setup.sh`, then:
-#
-#       ./tools/setup-grafana.sh coal
-#
-# Afterwords, it will print the URL to the Grafana. It is provisioned with the
-# latest dashboards defined in https://github.com/joyent/triton-grafana
-# It takes a few minutes though for the discovery process to complete before
-# you'll see any metrics.
-#
-
-IMAGE_UUID="7b5981c4-1889-11e7-b4c5-3f3bdfc9b88b" # LX Ubuntu 16.04
-MIN_MEMORY=1024
-GRAFANA_VERSION="5.2.2"
-ALIAS=grafana0
-
-HOST=$1
-if [[ -z "$HOST" ]]; then
-    echo "error: missing HEADNODE-GZ argument" >&2
-    echo "usage: ./setup-prometheus.sh HEADNODE-GZ" >&2
-    exit 1
-fi
-
-if [[ -z ${SSH_OPTS} ]]; then
-    SSH_OPTS=""
-fi
-
-# Code in this block runs on the remote system
-ssh ${SSH_OPTS} ${HOST} <<EOF
-
-set -o errexit
-if [[ -n "${TRACE}" ]]; then
-    set -o xtrace
-fi
-
-function fatal() {
-    echo "FATAL: \$*" >&2
-    exit 1
-}
-
-. ~/.bash_profile
-
-
-#
-# grafana0 zone creation
-#
-
-vm_uuid=\$(vmadm lookup alias=$ALIAS)
-[[ -z "\$vm_uuid" ]] || fatal "VM $ALIAS already exists"
-
-if ! sdc-imgadm get ${IMAGE_UUID} >/dev/null 2>&1; then
-    sdc-imgadm import -S https://images.joyent.com ${IMAGE_UUID} </dev/null
-fi
-
-headnode_uuid=\$(sysinfo | json UUID)
-admin_uuid=\$(sdc-useradm get admin | json uuid)
-admin_network_uuid=\$(sdc-napi /networks?name=admin | json -H 0.uuid)
-external_network_uuid=\$(sdc-napi /networks?name=external | json -H 0.uuid)
-package=\$(sdc-papi /packages | json -Ha uuid max_physical_memory | sort -n -k 2 \
-    | while read uuid mem; do
-
-    # Find the first one with at least ${MIN_MEMORY}
-    if [[ -z \${pkg} && \${mem} -ge ${MIN_MEMORY} ]]; then
-        pkg=\${uuid}
-        echo \${uuid}
-    fi
-done)
-
-prometheus_ip=\$(vmadm lookup -1 alias=prometheus0 -j \
-    | json 0.nics | json -c 'this.nic_tag === "admin"' 0.ip)
-[[ -n "\$prometheus_ip" ]] \
-    || fatal "could not find prometheus0 zone admin IP: have you setup a prometheus0 zone?"
-
-echo "Admin account: \${admin_uuid}"
-echo "Admin network: \${admin_network_uuid}"
-echo "External network: \${external_network_uuid}"
-echo "Headnode: \${headnode_uuid}"
-echo "Package: \${package}"
-echo "Alias: ${ALIAS}"
-
-[[ -n "\${admin_uuid}" ]] || fatal "missing admin UUID"
-[[ -n "\${headnode_uuid}" ]] || fatal "missing headnode UUID"
-[[ -n "\${admin_network_uuid}" ]] || fatal "missing admin network UUID"
-[[ -n "\${package}" ]] || fatal "missing package"
-
-# - networks: Need the 'admin' to access the prometheus0 zone. Need 'external'
-#   so, in general, an operator can reach it. WARNING: Need an auth story here.
-# - tags.smartdc_role: So 'sdc-login -l graf' works.
-echo "Creating VM ${ALIAS} ..."
-vm_uuid=\$((sdc-vmapi /vms?sync=true -X POST -d@/dev/stdin | json -H vm_uuid) <<PAYLOAD
-{
-    "alias": "${ALIAS}",
-    "billing_id": "\${package}",
-    "brand": "lx",
-    "image_uuid": "${IMAGE_UUID}",
-    "networks": [{"uuid": "\${admin_network_uuid}"}, {"uuid": "\${external_network_uuid}", "primary": true}],
-    "owner_uuid": "\${admin_uuid}",
-    "server_uuid": "\${headnode_uuid}",
-    "tags": {
-        "smartdc_role": "grafana"
-    }
-}
-PAYLOAD
-)
-
-
-#
-# Grafana setup.
-#
-
-grafana_ip=\$(vmadm get \${vm_uuid} | json nics | json -c 'this.primary' 0.ip)
-
-# Get the latest https://github.com/joyent/triton-grafana
-cd /zones/\${vm_uuid}/root/root
-curl -Lk -o triton-grafana-master.tgz https://github.com/joyent/triton-grafana/archive/master.tar.gz
-gtar -zxvf triton-grafana-master.tgz
-mv triton-grafana-master triton-grafana
-
-# Setup grafana.
-cd /zones/\${vm_uuid}/root/root
-curl -L -kO https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-${GRAFANA_VERSION}.linux-amd64.tar.gz
-gtar -zxvf grafana-${GRAFANA_VERSION}.linux-amd64.tar.gz
-ln -s grafana-${GRAFANA_VERSION} grafana
-cd grafana
-
-cat >./conf/provisioning/datasources/triton.yaml <<DATAYML
-# config file version
-apiVersion: 1
-
-datasources:
-    - name: Triton
-      type: prometheus
-      access: proxy
-      orgId: 1
-      url: http://\${prometheus_ip}:9090
-      isDefault: true
-      editable: true
-DATAYML
-
-cat >./conf/provisioning/dashboards/triton.yaml <<DASHYML
-# config file version
-apiVersion: 1
-
-providers:
-    - name: Triton
-      orgId: 1
-      folder: ''
-      type: file
-      options:
-        path: /root/triton-grafana/dashboards
-DASHYML
-
-# Generate grafana systemd manifest
-cat >/zones/\${vm_uuid}/root/etc/systemd/system/grafana.service <<SYSTEMD
-[Unit]
-	Description=Grafana server
-	After=network.target
-
-[Service]
-	WorkingDirectory=/root/grafana
-	StandardOutput=syslog
-	ExecStart=/root/grafana/bin/grafana-server
-	User=root
-
-[Install]
-	WantedBy=multi-user.target
-SYSTEMD
-
-zlogin \${vm_uuid} "systemctl daemon-reload && systemctl enable grafana && systemctl start grafana && systemctl status grafana" </dev/null
-
-# Lame method to allow grafana to start and provision the dashboards.
-# Would be better to poll the curl attempts below.
-sleep 5
-
-# Set the CNAPI dashboard (for now) as the default org dashboard.
-alias json="/native/usr/node/bin/node /native/usr/bin/json"
-dashId=\$(curl -sSf -u admin:admin "\${grafana_ip}:3000/api/search?type=dash-db&query=cnapi" | json 0.id)
-curl -sSf -u admin:admin \${grafana_ip}:3000/api/org/preferences -H content-type:application/json \
-    -d '{"theme":"","homeDashboardId":'\$dashId',"timezone":"utc"}' -X PUT
-echo ""
-
-
-echo ""
-echo "* * * Successfully setup * * *"
-echo "Prometheus: http://\${prometheus_ip}:9090/"
-echo "Grafana: http://\${grafana_ip}:3000/ (admin:admin)"
-
-EOF
diff --git a/setup-prometheus.sh b/setup-prometheus.sh
deleted file mode 100755
index a9f1ad8..0000000
--- a/setup-prometheus.sh
+++ /dev/null
@@ -1,233 +0,0 @@
-#!/bin/bash
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-# Copyright (c) 2018 Joyent, Inc.
-#
-
-#
-# This tool works to setup prometheus (and required cmon/cns bits) on a test
-# machine which has been setup with trentops:bin/coal-post-setup.sh or another
-# similar mechanism (e.g. globe-theatre nightly setup).
-#
-# On a new coal, run coal-post-setup.sh, then:
-#
-#  ./tools/setup-prom.sh coal
-#
-# and you should be able to then go to the prometheus page that gets spit out at
-# the end. It takes a few minutes though for the discovery process to complete
-# before you'll see any metrics.
-#
-
-IMAGE_UUID="7b5981c4-1889-11e7-b4c5-3f3bdfc9b88b" # LX Ubuntu 16.04
-MIN_MEMORY=1024
-PROMETHEUS_VERSION="2.3.2"
-ALIAS=prometheus0
-
-HOST=$1
-if [[ -z "$HOST" ]]; then
-    echo "error: missing HEADNODE-GZ argument" >&2
-    echo "usage: ./setup-prometheus.sh HEADNODE-GZ" >&2
-    exit 1
-fi
-
-if [[ -z ${SSH_OPTS} ]]; then
-    SSH_OPTS=""
-fi
-
-# Code in this block runs on the remote system
-ssh ${SSH_OPTS} ${HOST} <<EOF
-
-set -o errexit
-if [[ -n "${TRACE}" ]]; then
-    set -o xtrace
-fi
-
-function fatal() {
-    echo "FATAL: \$*" >&2
-    exit 1
-}
-
-. ~/.bash_profile
-
-
-#
-# prometheus0 zone creation
-#
-
-vm_uuid=\$(vmadm lookup alias=$ALIAS)
-[[ -z "\$vm_uuid" ]] || fatal "VM $ALIAS already exists"
-
-if ! sdc-imgadm get ${IMAGE_UUID} >/dev/null 2>&1; then
-    sdc-imgadm import -S https://images.joyent.com ${IMAGE_UUID} </dev/null
-fi
-
-# Setup for CNS to actually work
-sdc-useradm replace-attr admin approved_for_provisioning true </dev/null
-sdc-useradm replace-attr admin triton_cns_enabled true </dev/null
-sdc-login -l cns "svcadm restart cns-updater" </dev/null
-sdc-login -l cns "cnsadm vm \$(vmadm lookup alias=vmapi0)" </dev/null
-
-set -o errexit
-
-# need to provision to headnode so we can zlogin
-headnode_uuid=\$(sysinfo | json UUID)
-
-# Find admin uuid
-admin_uuid=\$(sdc-useradm get admin | json uuid)
-
-# Find network (we want to be on same one as cmon)
-network_uuid=\$(vmadm get \$(vmadm lookup alias=~^cmon | head -1) | json nics.1.network_uuid)
-admin_network_uuid=\$(sdc-napi /networks?name=admin | json -H 0.uuid)
-
-# Find package
-package=\$(sdc-papi /packages | json -Ha uuid max_physical_memory | sort -n -k 2 \
-    | while read uuid mem; do
-
-    # Find the first one with at least ${MIN_MEMORY}
-    if [[ -z \${pkg} && \${mem} -ge ${MIN_MEMORY} ]]; then
-        pkg=\${uuid}
-        echo \${uuid}
-    fi
-done)
-
-# Find CNS resolver(s)
-prometheus_dc=\$(bash /lib/sdc/config.sh -json | json datacenter_name)
-prometheus_domain=\$(bash /lib/sdc/config.sh -json | json dns_domain)
-
-binder_resolvers=\$(dig +short binder.\${prometheus_dc}.\${prometheus_domain} | tr '\n' ',' | sed -e "s/,$//")
-cns_resolvers=\$(dig +noall +answer +short @binder.\${prometheus_dc}.\${prometheus_domain} cns.\${prometheus_dc}.\${prometheus_domain} | tr '\n' ',' | sed -e "s/,$//")
-
-echo "Admin account: \${admin_uuid}"
-echo "Admin network: \${admin_network_uuid}"
-echo "Headnode: \${headnode_uuid}"
-echo "Network: \${network_uuid}"
-echo "Package: \${package}"
-echo "Alias: ${ALIAS}"
-echo "CNS Resolvers: \${cns_resolvers}"
-echo "Binder Resolvers: \${binder_resolvers}"
-
-[[ -n "\${admin_uuid}" ]] || fatal "missing admin UUID"
-[[ -n "\${headnode_uuid}" ]] || fatal "missing headnode UUID"
-[[ -n "\${network_uuid}" ]] || fatal "missing CMON network UUID"
-[[ -n "\${admin_network_uuid}" ]] || fatal "missing admin network UUID"
-[[ -n "\${package}" ]] || fatal "missing package"
-[[ -n "\${cns_resolvers}" ]] || fatal "missing CNS resolver"
-[[ -n "\${binder_resolvers}" ]] || fatal "missing binder resolver"
-
-# - user-script: Note that until TRITON-605 is resolved, net-agent will likely
-#   be undoing our explicit "resolvers" below. As a workaround we'll have a
-#   user-script that sorts it out on boot (see ./boot/configure.sh for a future
-#   alternative to this user-script).
-# - tags.smartdc_role: So 'sdc-login -l prom' works.
-echo "Creating VM ${ALIAS} ..."
-vm_uuid=\$((sdc-vmapi /vms?sync=true -X POST -d@/dev/stdin | json -H vm_uuid) <<PAYLOAD
-{
-    "alias": "${ALIAS}",
-    "billing_id": "\${package}",
-    "brand": "lx",
-    "image_uuid": "${IMAGE_UUID}",
-    "networks": [{"uuid": "\${admin_network_uuid}"}, {"uuid": "\${network_uuid}", "primary": true}],
-    "owner_uuid": "\${admin_uuid}",
-    "server_uuid": "\${headnode_uuid}",
-    "resolvers": ["\$(echo "\${cns_resolvers},\${binder_resolvers},8.8.8.8" | sed -e 's/,/","/g')"],
-    "customer_metadata": {
-        "cnsResolvers": "\${cns_resolvers}",
-        "user-script": "#!/bin/bash\n\nset -o errexit\nset -o pipefail\nset -o xtrace\n\nmdata-get cnsResolvers | tr , '\n' | while read ip; do\n        grep \"^nameserver \\\$ip$\" /etc/resolvconf/resolv.conf.d/head >/dev/null 2>&1 || echo \"nameserver \\\$ip\" >> /etc/resolvconf/resolv.conf.d/head;\n    done\nresolvconf -u\n\nexit 0\n"
-    },
-    "tags": {
-        "smartdc_role": "prometheus"
-    }
-}
-PAYLOAD
-)
-
-# Download the bits (since external resolvers not setup in zone)
-cd /zones/\${vm_uuid}/root/root
-curl -L -kO https://github.com/prometheus/prometheus/releases/download/v${PROMETHEUS_VERSION}/prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
-tar -zxvf prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
-ln -s prometheus-${PROMETHEUS_VERSION}.linux-amd64 prometheus
-cd prometheus
-
-# Generate/Register Cert/Key
-ssh-keygen -t rsa -f prometheus_key -N ''
-openssl rsa -in prometheus_key -outform pem >prometheus_key.priv.pem
-openssl req -new -key prometheus_key.priv.pem -out prometheus_key.csr.pem -subj "/CN=admin"
-openssl x509 -req -days 365 -in prometheus_key.csr.pem -signkey prometheus_key.priv.pem -out prometheus_key.pub.pem
-/opt/smartdc/bin/sdc-useradm add-key -f admin prometheus_key.pub
-
-# Generate Config
-prometheus_ip=\$(vmadm get \${vm_uuid} | json nics.1.ip)
-cns_zone="\${prometheus_dc}.cns.\${prometheus_domain}"
-
-cp prometheus.yml prometheus.yml.bak
-cat >prometheus.yml <<PROMYML
-# my global config
-global:
-  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
-  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
-  # scrape_timeout is set to the global default (10s).
-
-# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
-rule_files:
-  # - "first.rules"
-  # - "second.rules"
-
-# A scrape configuration containing exactly one endpoint to scrape:
-# Here it's Prometheus itself.
-scrape_configs:
-  # The job name is added as a label 'job=<job_name>' to any timeseries scraped from this config.
-  - job_name: 'admin_\${prometheus_dc}'
-    scheme: https
-    tls_config:
-      cert_file: /root/prometheus/prometheus_key.pub.pem
-      key_file: /root/prometheus/prometheus_key.priv.pem
-      insecure_skip_verify: true
-    relabel_configs:
-      - source_labels: [__meta_triton_machine_alias]
-        target_label: alias
-      - source_labels: [__meta_triton_machine_id]
-        target_label: instance
-    triton_sd_configs:
-      - account: 'admin'
-        dns_suffix: 'cmon.\${cns_zone}'
-        endpoint: 'cmon.\${cns_zone}'
-        version: 1
-        tls_config:
-          cert_file: /root/prometheus/prometheus_key.pub.pem
-          key_file: /root/prometheus/prometheus_key.priv.pem
-          insecure_skip_verify: true
-PROMYML
-
-# Generate systemd manifest
-cat >/zones/\${vm_uuid}/root/etc/systemd/system/prometheus.service <<SYSTEMD
-[Unit]
-    Description=Prometheus server
-    After=network.target
-
-[Service]
-    WorkingDirectory=/root/prometheus
-    StandardOutput=syslog
-    ExecStart=/root/prometheus/prometheus \\
-        --storage.tsdb.path=/root/prometheus/data \\
-        --config.file=/root/prometheus/prometheus.yml \\
-        --web.external-url=http://\${prometheus_ip}:9090/
-    User=root
-
-[Install]
-    WantedBy=multi-user.target
-SYSTEMD
-
-
-zlogin \${vm_uuid} "systemctl daemon-reload && systemctl enable prometheus && systemctl start prometheus && systemctl status prometheus" </dev/null
-
-echo ""
-echo "* * * Successfully setup * * *"
-echo "Prometheus: http://\${prometheus_ip}:9090/"
-echo ""
-echo "You can setup a grafana0 zone next via:"
-echo "    ./setup-grafana.sh $HOST"
-
-EOF
diff --git a/smf/manifests/prometheus.xml b/smf/manifests/prometheus.xml
new file mode 100644
index 0000000..5f73752
--- /dev/null
+++ b/smf/manifests/prometheus.xml
@@ -0,0 +1,67 @@
+<?xml version="1.0"?>
+<!DOCTYPE service_bundle SYSTEM "/usr/share/lib/xml/dtd/service_bundle.dtd.1">
+<!--
+    This Source Code Form is subject to the terms of the Mozilla Public
+    License, v. 2.0. If a copy of the MPL was not distributed with this
+    file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+    Copyright (c) 2018, Joyent, Inc.
+-->
+
+<service_bundle type="manifest" name="prometheus">
+  <service name="triton/site/prometheus" type="service" version="1.0.0">
+
+    <create_default_instance enabled="false"/>
+    <single_instance/>
+
+    <dependency name="network" grouping="require_all" restart_on="error" type="service">
+      <service_fmri value="svc:/milestone/network:default"/>
+    </dependency>
+
+    <dependency name="filesystem" grouping="require_all" restart_on="error" type="service">
+      <service_fmri value="svc:/system/filesystem/local"/>
+    </dependency>
+
+    <exec_method
+      type="method"
+      name="start"
+      exec="/opt/triton/prometheus/prometheus/prometheus --storage.tsdb.path=/data/prometheus/data --config.file=/data/prometheus/etc/prometheus.yml &amp;"
+      timeout_seconds="30">
+      <method_context working_directory="/opt/triton/prometheus">
+        <method_credential user="nobody" group="nobody" privileges="basic,net_privaddr"/>
+        <method_environment>
+          <envvar name="PATH" value="/opt/local/bin:/usr/bin:/usr/sbin:/bin"/>
+          <envvar name="LD_PRELOAD_32" value="/usr/lib/extendedFILE.so.1" />
+        </method_environment>
+      </method_context>
+    </exec_method>
+
+    <exec_method type="method" name="restart" exec=":kill" timeout_seconds="60">
+      <method_context working_directory="/opt/triton/prometheus" />
+    </exec_method>
+
+    <exec_method type="method" name="stop" exec=":kill" timeout_seconds="60">
+      <method_context working_directory="/opt/triton/prometheus" />
+    </exec_method>
+
+    <property_group name="startd" type="framework">
+      <propval name="ignore_error" type="astring" value="core,signal"/>
+    </property_group>
+
+    <property_group name="application" type="application">
+
+    </property_group>
+
+    <stability value="Stable"/>
+
+    <template>
+      <common_name>
+        <loctext xml:lang="C">Triton Prometheus</loctext>
+      </common_name>
+    </template>
+
+  </service>
+
+</service_bundle>
diff --git a/tools/download_go b/tools/download_go
new file mode 100755
index 0000000..69e9a3e
--- /dev/null
+++ b/tools/download_go
@@ -0,0 +1,126 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# This program will download a Go toolchain for a particular system.  It
+# currently expects to find illumos builds of the toolchain on the Joyent
+# download server, where we will be placing them alongside sdcnode, etc.
+# The program is designed specifically to be used as part of a make target.
+#
+# We may revisit this once the Go project makes official builds for illumos
+# systems available in the future.
+#
+# NOTE: This program comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This program accepts four arguments, in the following order:
+#
+#	GOVERSION	The version of the Go toolchain to use; e.g., "1.9.2"
+#	GOOS		The build machine operating system; e.g., "solaris"
+#	GOARCH		The build machine CPU architecture; e.g., "amd64"
+#	OUTDIR		The local directory into which the downloaded tar
+#			file will be placed.
+#
+# The program will use the provided arguments to find and download an archive
+# of the Go toolchain for use on the build machine.  The archive will be named
+# for a combination of the provided arguments; e.g.,
+# "go1.9.2.solaris-amd64.tar.bz2".  A target symbolic link will also be
+# created, with just the version number in the name; e.g., "go-1.9.2.tar.bz2".
+# If the archive could not be downloaded, an error message will be printed and
+# the output file and target link will be unaffected.
+#
+
+BASEURL='https://download.joyent.com/pub/build/go/adhoc/'
+GOVERSION=$1
+GOOS=$2
+GOARCH=$3
+OUTDIR=$4
+
+if [[ -z $GOVERSION || -z $GOOS || -z $GOARCH || -z $OUTDIR ]]; then
+	printf 'ERROR: usage: download_go GOVERSION GOOS GOARCH OUTDIR\n' 2>&1
+	exit 1
+fi
+
+if [[ ! -d $OUTDIR ]]; then
+	printf 'ERROR: output directory "%s" does not exist\n' "$OUTDIR" 2>&1
+	exit 1
+fi
+
+TARGET="go-$GOVERSION.tar.bz2"
+
+#
+# Download the index page which lists the current set of available go
+# builds:
+#
+if ! list=$(curl -sSfL "$BASEURL") || [[ -z "$list" ]]; then
+	printf 'ERROR: could not download index page\n' >&2
+	exit 1
+fi
+
+#
+# Using only commonly found household items, extract the full name of the
+# go tar archive we need.  This program needs to be able to operate in a
+# minimally populated build zone, so we avoid using anything beyond basic
+# UNIX tools like "awk".
+#
+# One word to describe this process might be "brittle".
+#
+if ! name=$(/usr/bin/awk -v "v=$GOVERSION" -v "o=$GOOS" -v "a=$GOARCH" -F\" '
+    BEGIN { pattern = "^go"v"."o"-"a".tar.bz2$"; }
+    $1 == "<a href=" && $2 ~ pattern { print $2 }' <<< "$list") ||
+    [[ -z "$name" ]]; then
+	printf 'ERROR: could not locate file name in index page\n' >&2
+	printf '\t(Does Go version %s (%s-%s) exist?)\n' \
+	    "$GOVERSION" "$GOOS" "$GOARCH" >&2
+	exit 1
+fi
+
+
+#
+# If the full file name of the latest go build does not exist, download it now
+# to a temporary file.  If it succeeds, move it into place.
+#
+output_file="$OUTDIR/$name"
+if [[ ! -f $output_file ]]; then
+	printf 'Downloading Go: %s\n' "$BASEURL$name"
+
+	temp_file="$OUTDIR/.tmp.$name.$$"
+	rm -f "$temp_file"
+
+	if ! curl -sSf -o "$temp_file" "$BASEURL$name"; then
+		printf 'ERROR: could not download go\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+
+	if ! mv "$temp_file" "$output_file"; then
+		printf 'ERROR: could not move tar file into place\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+fi
+
+#
+# Make sure the target link points at the correct file:
+#
+rm -f "$OUTDIR/$TARGET"
+if ! ln -s "$name" "$OUTDIR/$TARGET"; then
+	printf 'ERROR: could not create target link\n' >&2
+	exit 1
+fi
+
+exit 0
+
+# vim: set ts=8 sts=8 sw=8 noet:
diff --git a/tools/obliterate-prometheus-service.sh b/tools/obliterate-prometheus-service.sh
new file mode 100755
index 0000000..e8e8c33
--- /dev/null
+++ b/tools/obliterate-prometheus-service.sh
@@ -0,0 +1,68 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018 Joyent, Inc.
+#
+
+#
+# Obliterate a Triton prometheus service and instances. This is just for
+# development.
+#
+# Usage:
+#       scp tools/obliterate-prometheus-service.sh coal:/var/tmp
+#       ssh coal
+#       /var/tmp/obliterate-prometheus-service.sh
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+set -o errexit
+set -o pipefail
+
+function fatal() {
+    echo "$0: fatal: \$*" >&2
+    exit 1
+}
+
+function obliterate_prometheus_service {
+    local promSvc
+
+    promSvc=$(sdc-sapi /services?name=prometheus | json -H 0.uuid)
+    if [[ -z $promSvc ]]; then
+        return
+    fi
+
+    sdc-sapi /instances?service_uuid=$promSvc \
+        | json -Ha uuid params.alias \
+        | while read uuid alias; do
+            echo "Delete prometheus instance $uuid ($alias)"
+            sdc-sapi /instances/$uuid -X DELETE
+        done
+
+    echo "Delete prometheus service ($promSvc)"
+    sdc-sapi /services/$promSvc -X DELETE
+}
+
+
+# ---- mainline
+
+# Guard from running this in production. This is the same guard file we use
+# for running many of the Triton test suites.
+if [[ ! -f "/lib/sdc/.sdc-test-no-production-data" ]]; then
+    cat <<EOF
+To run this you must create the following file:
+
+    /lib/sdc/.sdc-test-no-production-data
+
+after ensuring you have no production data in this TritonDC.
+EOF
+    exit 2
+fi
+
+
+obliterate_prometheus_service
\ No newline at end of file
diff --git a/tools/service_bundle.dtd.1 b/tools/service_bundle.dtd.1
new file mode 100644
index 0000000..e5c2380
--- /dev/null
+++ b/tools/service_bundle.dtd.1
@@ -0,0 +1,1091 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+ Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.
+
+ CDDL HEADER START
+
+ The contents of this file are subject to the terms of the
+ Common Development and Distribution License (the "License").
+ You may not use this file except in compliance with the License.
+
+ You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
+ or http://www.opensolaris.org/os/licensing.
+ See the License for the specific language governing permissions
+ and limitations under the License.
+
+ When distributing Covered Code, include this CDDL HEADER in each
+ file and include the License file at usr/src/OPENSOLARIS.LICENSE.
+ If applicable, add the following below this CDDL HEADER, with the
+ fields enclosed by brackets "[]" replaced with your own identifying
+ information: Portions Copyright [yyyy] [name of copyright owner]
+
+ CDDL HEADER END
+-->
+
+<!--
+  Service description DTD
+
+    Most attributes are string values (or an individual string from a
+    restricted set), but attributes with a specific type requirement are
+    noted in the comment describing the element.
+-->
+
+<!--
+  XInclude support
+
+    A series of service bundles may be composed via the xi:include tag.
+    smf(5) tools enforce that all bundles be of the same type.
+-->
+
+<!--
+     These entities are used for the property, propval and property_group
+     elements, that require type attributes for manifest, while for profiles
+     the type attributes are only implied.
+-->
+
+<!ENTITY % profile "IGNORE">
+<!ENTITY % manifest "INCLUDE">
+
+<!ELEMENT xi:include
+  (xi:fallback)
+  >
+<!ATTLIST xi:include
+  href CDATA #REQUIRED
+  parse (xml|text) "xml"
+  encoding CDATA #IMPLIED
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!ELEMENT xi:fallback
+  ANY
+  >
+<!ATTLIST xi:fallback
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!--
+  stability
+
+    This element associates an SMI stability level with the parent
+    element.  See attributes(5) for an explanation of interface
+    stability levels.
+
+    Its attribute is
+
+	value	The stability level of the parent element.
+-->
+
+<!ELEMENT stability EMPTY>
+
+<!ATTLIST stability
+	value		( Standard | Stable | Evolving | Unstable |
+			External | Obsolete ) #REQUIRED >
+
+<!-- Property value lists -->
+
+<!--
+  value_node
+
+    This element represents a single value within any of the typed
+    property value lists.
+
+    Its attribute is
+
+	value	The value for this node in the list.
+-->
+
+<!ELEMENT value_node EMPTY>
+
+<!ATTLIST value_node
+	value CDATA #REQUIRED>
+
+<!--
+  count_list
+  integer_list
+  opaque_list
+  host_list
+  hostname_list
+  net_address_list
+  net_address_v4_list
+  net_address_v6_list
+  time_list
+  astring_list
+  ustring_list
+  boolean_list
+  fmri_list
+  uri_list
+
+    These elements represent the typed lists of values for a property.
+    Each contains one or more value_node elements representing each
+    value on the list.
+
+    None of these elements has attributes.
+-->
+
+<!ELEMENT count_list
+	( value_node+ )>
+
+<!ATTLIST count_list>
+
+<!ELEMENT integer_list
+	( value_node+ )>
+
+<!ATTLIST integer_list>
+
+<!ELEMENT opaque_list
+	( value_node+ )>
+
+<!ATTLIST opaque_list>
+
+<!ELEMENT host_list
+	( value_node+ )>
+
+<!ATTLIST host_list>
+
+<!ELEMENT hostname_list
+	( value_node+ )>
+
+<!ATTLIST hostname_list>
+
+<!ELEMENT net_address_list
+	( value_node+ )>
+
+<!ATTLIST net_address_list>
+
+<!ELEMENT net_address_v4_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v4_list>
+
+<!ELEMENT net_address_v6_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v6_list>
+
+<!ELEMENT time_list
+	( value_node+ )>
+
+<!ATTLIST time_list>
+
+<!ELEMENT astring_list
+	( value_node+ )>
+
+<!ATTLIST astring_list>
+
+<!ELEMENT ustring_list
+	( value_node+ )>
+
+<!ATTLIST ustring_list>
+
+<!ELEMENT boolean_list
+	( value_node+ )>
+
+<!ATTLIST boolean_list>
+
+<!ELEMENT fmri_list
+	( value_node+ )>
+
+<!ATTLIST fmri_list>
+
+<!ELEMENT uri_list
+	( value_node+ )>
+
+<!ATTLIST uri_list>
+
+<!-- Properties and property groups -->
+
+<!--
+   property
+
+     This element is for a singly or multiply valued property within a
+     property group.  It contains an appropriate value list element,
+     which is expected to be consistent with the type attribute.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	override These values should replace values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	override	( true | false ) "false" >
+]]>
+	
+<![%manifest;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+   propval
+
+     This element is for a singly valued property within a property
+     group.  List-valued properties must use the property element above.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	value	The value for this property.  Must match type
+		restriction of type attribute.
+
+	override This value should replace any values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+  property_group
+
+    This element is for a set of related properties on a service or
+    instance.  It contains an optional stability element, as well as
+    zero or more property-containing elements.
+
+    Its attributes are
+
+	name	The name of this property group.
+
+	type	A category for this property group.  Groups of type
+		"framework", "implementation" or "template" are primarily
+		of interest to the service management facility, while
+		groups of type "application" are expected to be only of
+		interest to the service to which this group is attached.
+		Other types may be introduced using the service symbol
+		namespace conventions.
+
+	delete	If in the repository, this property group should be removed.
+-->
+
+<![%profile;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #IMPLIED
+	delete		( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+]]>
+
+<!--
+  service_fmri
+
+    This element defines a reference to a service FMRI (for either a
+    service or an instance).
+
+    Its attribute is
+
+	value	The FMRI.
+-->
+
+<!ELEMENT service_fmri EMPTY>
+
+<!ATTLIST service_fmri
+	value		CDATA #REQUIRED>
+
+<!-- Dependencies -->
+
+<!--
+  dependency
+
+    This element identifies a group of FMRIs upon which the service is
+    in some sense dependent.  Its interpretation is left to the
+    restarter to which a particular service instance is delegated.  It
+    contains a group of service FMRIs, as well as a block of properties.
+
+    Its attributes are
+
+	name	The name of this dependency.
+
+	grouping The relationship between the various FMRIs grouped
+		here; "require_all" of the FMRIs to be online, "require_any"
+		of the FMRIs to be online, or "exclude_all" of the FMRIs
+		from being online or in maintenance for the dependency to
+		be satisfied.  "optional_all" dependencies are satisfied
+		when all of the FMRIs are either online or unable to come
+		online (because they are disabled, misconfigured, or one
+		of their dependencies is unable to come online).
+
+	restart_on The type of events from the FMRIs that the service should
+		be restarted for.  "error" restarts the service if the
+		dependency is restarted due to hardware fault.  "restart"
+		restarts the service if the dependency is restarted for
+		any reason, including hardware fault.  "refresh" restarts
+		the service if the dependency is refreshed or restarted for
+		any reason.  "none" will never restart the service due to
+		dependency state changes.
+
+	type	The type of dependency: on another service ('service'), on
+		a filesystem path ('path'), or another dependency type.
+
+	delete	This dependency should be deleted.
+-->
+
+<!ELEMENT dependency
+	( service_fmri*, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependency
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all ) #REQUIRED
+	restart_on	( error | restart | refresh | none ) #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!-- Dependents -->
+
+<!--
+  dependent
+
+    This element identifies a service which should depend on this service.  It
+    corresponds to a dependency in the named service.  The grouping and type
+    attributes of that dependency are implied to be "require_all" and
+    "service", respectively.
+
+    Its attributes are
+
+	name	The name of the dependency property group to create in the
+		dependent entity.
+
+	grouping The grouping relationship of the dependency property
+		group to create in the dependent entity.  See "grouping"
+		attribute on the dependency element.
+
+	restart_on The type of events from this service that the named service
+		should be restarted for.
+
+	delete	True if this dependent should be deleted.
+
+	override Whether to replace an existing dependent of the same name.
+
+-->
+
+<!ELEMENT dependent
+	( service_fmri, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependent
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all) #REQUIRED
+	restart_on	( error | restart | refresh | none) #REQUIRED
+	delete		( true | false ) "false"
+	override	( true | false ) "false" >
+
+<!-- Method execution context, security profile, and credential definitions -->
+
+<!--
+  envvar
+
+    An environment variable. It has two attributes:
+
+	name	The name of the environment variable.
+	value	The value of the environment variable.
+-->
+
+<!ELEMENT envvar EMPTY>
+
+<!ATTLIST envvar
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED >
+
+<!--
+  method_environment
+
+    This element defines the environment for a method. It has no
+    attributes, and one or more envvar child elements.
+-->
+
+<!ELEMENT method_environment (envvar+) >
+
+<!ATTLIST method_environment>
+
+<!--
+  method_profile
+
+    This element indicates which exec_attr(5) profile applies to the
+    method context being defined.
+
+    Its attribute is
+
+	name	The name of the profile.
+-->
+
+<!ELEMENT method_profile EMPTY>
+
+<!ATTLIST method_profile
+	name		CDATA #REQUIRED >
+
+<!--
+  method_credential
+
+    This element specifies credential attributes for the execution
+    method to use.
+
+    Its attributes are
+
+	user	The user ID, in numeric or text form.
+
+	group	The group ID, in numeric or text form.  If absent or
+		":default", the group associated with the user in the
+		passwd database.
+
+	supp_groups Supplementary group IDs to be associated with the
+		method, separated by commas or spaces.  If absent or
+		":default", initgroups(3C) will be used.
+
+	privileges An optional string specifying the privilege set.
+
+	limit_privileges An optional string specifying the limit
+		privilege set.
+-->
+
+<!ELEMENT method_credential EMPTY>
+
+<!ATTLIST method_credential
+	user		CDATA #REQUIRED
+	group		CDATA #IMPLIED
+	supp_groups	CDATA #IMPLIED
+	privileges	CDATA #IMPLIED
+	limit_privileges CDATA #IMPLIED >
+
+<!--
+  method_context
+
+    This element combines credential and resource management attributes
+    for execution methods.  It may contain a method_environment, or
+    a method_profile or method_credential element.
+
+    Its attributes are
+
+	working_directory The home directory to launch the method from.
+		":default" can be used as a token to indicate use of the
+		user specified by the credential or profile specified.
+
+	project	The project ID, in numeric or text form.  ":default" can
+		be used as a token to indicate use of the project
+		identified by getdefaultproj(3PROJECT) for the non-root
+		user specified by the credential or profile specified.
+		If the user is root, ":default" designates the project
+		the restarter is running in.
+
+	resource_pool The resource pool name to launch the method on.
+		":default" can be used as a token to indicate use of the
+		pool specified in the project(4) entry given in the
+		"project" attribute above.
+-->
+<!ELEMENT method_context
+	( (method_profile | method_credential)?, method_environment? ) >
+
+<!ATTLIST method_context
+	working_directory	CDATA #IMPLIED
+	project			CDATA #IMPLIED
+	resource_pool		CDATA #IMPLIED >
+
+<!-- Restarter delegation, methods, and monitors -->
+
+<!--
+  exec_method
+
+    This element describes one of the methods used by the designated
+    restarter to act on the service instance.  Its interpretation is
+    left to the restarter to which a particular service instance is
+    delegated.  It contains a set of attributes, an optional method
+    context, and an optional stability element for the optional
+    properties that can be included.
+
+    Its attributes are
+
+	type	The type of method, either "method" or "monitor".
+
+	name	Name of this execution method.  The method names are
+		usually a defined interface of the restarter to which an
+		instance of this service is delegated.
+
+	exec	The string identifying the action to take.  For
+		svc.startd(1M), this is a string suitable to pass to
+		exec(2).
+
+	timeout_seconds [integer] Duration, in seconds, to wait for this
+		method to complete.  A '0' or '-1' denotes an infinite
+		timeout.
+
+	delete	If in the repository, the property group for this method
+		should be removed.
+-->
+
+<!ELEMENT exec_method
+	( method_context?, stability?, ( propval | property )* ) >
+
+<!ATTLIST exec_method
+	type		( method | monitor ) #REQUIRED
+	name		CDATA #REQUIRED
+	exec		CDATA #REQUIRED
+	timeout_seconds	CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!--
+  restarter
+
+    A flag element identifying the restarter to which this service or
+    service instance is delegated.  Contains the FMRI naming the
+    delegated restarter.
+
+    This element has no attributes.
+-->
+
+<!ELEMENT restarter
+	( service_fmri ) >
+
+<!ATTLIST restarter>
+
+<!--
+  Templates
+-->
+
+<!--
+  doc_link
+
+    The doc_link relates a resource described by the given URI to the
+    service described by the containing template.  The resource is
+    expected to be a documentation or elucidatory reference of some
+    kind.
+
+    Its attributes are
+
+      name      A label for this resource.
+
+      uri       A URI to the resource.
+-->
+
+<!ELEMENT doc_link EMPTY>
+
+<!ATTLIST doc_link
+	name		CDATA #REQUIRED
+	uri		CDATA #REQUIRED >
+
+<!--
+  manpage
+
+    The manpage element connects the reference manual page to the
+    template's service.
+
+    Its attributes are
+
+      title     The manual page title.
+
+      section   The manual page's section.
+
+      manpath   The MANPATH environment variable, as described in man(1)
+                that is required to reach the named manual page
+-->
+
+<!ELEMENT manpage EMPTY>
+
+<!ATTLIST manpage
+	title		CDATA #REQUIRED
+	section		CDATA #REQUIRED
+	manpath		CDATA ":default" >
+
+<!--
+  documentation
+
+    The documentation element groups an arbitrary number of doc_link
+    and manpage references.
+
+    It has no attributes.
+-->
+
+<!ELEMENT documentation
+	( doc_link | manpage )* >
+
+<!ATTLIST documentation>
+
+<!--
+  loctext
+
+    The loctext element is a container for localized text.
+
+    Its sole attribute is
+
+	xml:lang The name of the locale, in the form accepted by LC_ALL,
+		etc.  See locale(5).
+-->
+<!ELEMENT loctext
+        (#PCDATA) >
+
+<!ATTLIST loctext
+        xml:lang	CDATA #REQUIRED >
+
+<!--
+  description
+
+    The description holds a set of potentially longer, localized strings that
+    consist of a short description of the service.
+
+    The description has no attributes.
+-->
+<!ELEMENT description
+        ( loctext+ ) >
+
+<!ATTLIST description>
+
+<!--
+  common_name
+
+    The common_name holds a set of short, localized strings that
+    represent a well-known name for the service in the given locale.
+
+    The common_name has no attributes.
+-->
+<!ELEMENT common_name
+        ( loctext+ ) >
+
+<!ATTLIST common_name>
+
+<!--
+  units
+
+    The units a numerical property is expressed in.
+-->
+
+<!ELEMENT units
+	( loctext+ ) >
+
+<!ATTLIST units>
+
+<!--
+  visibility
+
+    Expresses how a property is typically accessed.  This isn't
+    intended as access control, but as an indicator as to how a
+    property is used.
+
+    Its attributes are:
+
+      value     'hidden', 'readonly', or 'readwrite' indicating that
+		the property should be hidden from the user, shown but
+		read-only, or modifiable.
+-->
+
+<!ELEMENT visibility EMPTY>
+
+<!ATTLIST visibility
+	value	( hidden | readonly | readwrite ) #REQUIRED >
+
+<!--
+  value
+
+    Describes a legal value for a property value, and optionally contains a
+    human-readable name and description for the specified property
+    value.
+
+    Its attributes are:
+
+      name	A string representation of the value.
+-->
+
+<!ELEMENT value
+	( common_name?, description? ) >
+
+<!ATTLIST value
+	name	CDATA #REQUIRED >
+
+<!--
+  values
+
+    Human-readable names and descriptions for valid values of a property.
+-->
+
+<!ELEMENT values
+	(value+) >
+
+<!ATTLIST values>
+
+<!--
+  cardinality
+
+    Places a constraint on the number of values the property can take
+    on.
+
+    Its attributes are:
+	min	minimum number of values
+	max	maximum number of values
+
+    Both attributes are optional.  If min is not specified, it defaults to
+    0.  If max is not specified it indicates an unlimited number of values.
+    If neither is specified this indicates 0 or more values.
+-->
+
+<!ELEMENT cardinality EMPTY>
+
+<!ATTLIST cardinality
+	min	CDATA "0"
+	max	CDATA "18446744073709551615">
+
+<!--
+  internal_separators
+
+    Indicates the separators used within a property's value used to
+    separate the actual values.  Used in situations where multiple
+    values are packed into a single property value instead of using a
+    multi-valued property.
+-->
+
+<!ELEMENT internal_separators
+	(#PCDATA) >
+
+<!ATTLIST internal_separators>
+
+<!--
+  range
+
+    Indicates a range of possible integer values.
+
+    Its attributes are:
+
+      min	The minimum value of the range (inclusive).
+      max	The maximum value of the range (inclusive).
+-->
+
+<!ELEMENT range EMPTY>
+
+<!ATTLIST range
+	min	CDATA #REQUIRED
+	max	CDATA #REQUIRED >
+
+<!--
+  constraints
+
+    Provides a set of constraints on the values a property can take on.
+-->
+
+<!ELEMENT constraints
+	( value*, range* ) >
+<!ATTLIST constraints>
+
+<!--
+  include_values
+
+    Includes an entire set of values in the choices block.
+
+    Its attributes are:
+
+	type    Either "constraints" or "values", indicating an
+		inclusion of all values allowed by the property's
+		constraints or all values for which there are
+		human-readable names and descriptions, respectively.
+-->
+
+<!ELEMENT include_values EMPTY>
+
+<!ATTLIST include_values
+	type	( constraints | values ) #REQUIRED >
+
+<!--
+  choices
+
+    Provides a set of common choices for the values a property can take
+    on.  Useful in those cases where the possibilities are unenumerable
+    or merely inconveniently legion, and a manageable subset is desired
+    for presentation in a user interface.
+-->
+
+<!ELEMENT choices
+	( value*, range*, include_values* ) >
+
+<!ATTLIST choices>
+
+<!--
+  prop_pattern
+
+
+    The prop_pattern describes one property of the enclosing property group
+    pattern.
+
+    Its attributes are:
+
+	name    The property's name.
+	type    The property's type.
+	required
+		If the property group is present, this property is required.
+
+	type can be omitted if required is false.
+-->
+
+<!ELEMENT prop_pattern
+	( common_name?, description?, units?, visibility?, cardinality?,
+	  internal_separators?, values?, constraints?, choices? ) >
+
+<!ATTLIST prop_pattern
+	name		CDATA	#REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	required	( true | false )	"false" >
+
+<!--
+  pg_pattern
+
+    The pg_pattern describes one property group.
+    Depending on the element's attributes, these descriptions may apply
+    to just the enclosing service/instance, instances of the enclosing
+    service, delegates of the service (assuming it is a restarter), or
+    all services.
+
+    Its attributes are:
+
+	name    The property group's name.  If not specified, it
+		matches all property groups with the specified type.
+	type    The property group's type.  If not specified, it
+		matches all property groups with the specified name.
+	required
+		If the property group is required.
+	target	The scope of the pattern, which may be all, delegate,
+		instance, or this.  'all' is reserved for framework use
+		and applies the template to all services on the system.
+		'delegate' is reserved for restarters, and means the
+		template applies to all services which use the restarter.
+		'this' would refer to the defining service or instance.
+		'instance' can only be used in a service's template block,
+		and means the definition applies to all instances of this
+		service.
+
+-->
+
+<!ELEMENT pg_pattern
+	( common_name?, description?, prop_pattern* ) >
+
+<!ATTLIST pg_pattern
+	name		CDATA	""
+	type		CDATA	""
+	required	( true | false )	"false"
+	target		( this | instance | delegate | all )	"this" >
+
+<!--
+  template
+
+    The template contains a collection of metadata about the service.
+    It contains a localizable string that serves as a common,
+    human-readable name for the service.  (This name should be less than
+    60 characters in a single byte locale.)  The template may optionally
+    contain a longer localizable description of the service, a
+    collection of links to documentation, either in the form of manual
+    pages or in the form of URI specifications to external documentation
+    sources (such as docs.sun.com).
+
+    The template has no attributes.
+-->
+<!ELEMENT template
+        ( common_name, description?, documentation?, pg_pattern* ) >
+
+<!ATTLIST template>
+
+<!-- Notification Parameters -->
+
+<!ELEMENT paramval EMPTY>
+
+<!ATTLIST paramval
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED>
+
+<!ELEMENT parameter
+	( value_node* )>
+
+<!ATTLIST parameter
+	name		CDATA #REQUIRED>
+
+<!ELEMENT event EMPTY>
+
+<!ATTLIST event
+	value		CDATA #REQUIRED>
+
+<!ELEMENT type
+	( ( parameter | paramval )* )>
+
+<!ATTLIST type
+	name		CDATA #REQUIRED
+	active		( true | false ) "true" >
+
+<!--
+  notification parameters
+
+    This element sets the notification parameters for Software Events and
+    Fault Management problem lifecycle events.
+-->
+
+<!ELEMENT notification_parameters
+	( event, type+ )>
+
+<!ATTLIST notification_parameters>
+
+<!-- Services and instances -->
+
+<!--
+  create_default_instance
+
+    A flag element indicating that an otherwise empty default instance
+    of this service (named "default") should be created at install, with
+    its enabled property set as given.
+
+    Its attribute is
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT create_default_instance EMPTY >
+
+<!ATTLIST create_default_instance
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  single_instance
+
+    A flag element stating that this service can only have a single
+    instance on a particular system.
+-->
+
+<!ELEMENT single_instance EMPTY>
+
+<!ATTLIST single_instance>
+
+<!--
+  instance
+
+    The service instance is the object representing a software component
+    that will run on the system if enabled.  It contains an enabled
+    element, a set of dependencies on other services, potentially
+    customized methods or configuration data, an optional method
+    context, and a pointer to its restarter.  (If no restarter is
+    specified, the master restarter, svc.startd(1M), is assumed to be
+    responsible for the service.)
+
+    Its attributes are
+
+	name	The canonical name for this instance of the service.
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT instance
+	( restarter?, dependency*, dependent*, method_context?,
+	exec_method*, notification_parameters*, property_group*,
+	template? ) >
+
+<!ATTLIST instance
+	name		CDATA #REQUIRED
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  service
+
+    The service contains the set of instances defined by default for
+    this service, an optional method execution context, any default
+    methods, the template, and various restrictions or advice applicable
+    at installation.  The method execution context and template elements
+    are required for service_bundle documents with type "manifest", but
+    are optional for "profile" or "archive" documents.
+
+    Its attributes are
+
+	name	The canonical name for the service.
+
+	version	[integer] The integer version for this service.
+
+	type	Whether this service is a simple service, a delegated
+		restarter, or a milestone (a synthetic service that
+		collects a group of dependencies).
+-->
+
+<!ELEMENT service
+	( create_default_instance?, single_instance?, restarter?,
+	dependency*, dependent*, method_context?, exec_method*,
+	notification_parameters*, property_group*, instance*,
+	stability?, template? ) >
+
+<!ATTLIST service
+	name		CDATA #REQUIRED
+	version		CDATA #REQUIRED
+	type		( service | restarter | milestone ) #REQUIRED >
+
+<!--
+  service_bundle
+
+    The bundle possesses two attributes:
+
+	type	How this file is to be understood by the framework (or
+		used in a non-framework compliant way). Standard types
+		are 'archive', 'manifest', and 'profile'.
+	
+	name	A name for the bundle.  Manifests should be named after
+		the package which delivered them; profiles should be
+		named after the "feature set nickname" they intend to
+		enable.
+-->
+
+<!ELEMENT service_bundle
+	( service_bundle* | service* | xi:include* )>
+
+<!ATTLIST service_bundle
+	type		CDATA #REQUIRED
+	name		CDATA #REQUIRED>
