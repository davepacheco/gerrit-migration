commit 098fb505db405ebdeebf3de0df78110844425f1c (refs/changes/92/1292/8)
Author: Jordan Hendricks <jordan.hendricks@joyent.com>
Date:   2017-04-10T21:45:59+00:00 (2 years, 6 months ago)
    
    MANTA-2169 Support multipart upload of a single file to Manta

diff --git a/Makefile b/Makefile
index 64b5393..b337435 100644
--- a/Makefile
+++ b/Makefile
@@ -5,7 +5,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2017, Joyent, Inc.
 #
 
 #
@@ -91,7 +91,7 @@ CLEAN_FILES += $(NODEUNIT) ./node_modules/.bin/nodeunit cover_html .coverage_dat
 
 .PHONY: test
 test: all
-	$(NODEUNIT) test/*.test.js
+	$(NODEUNIT) test/*.test.js test/mpu/*.test.js
 
 .PHONY: cover
 cover: $(NODECOVER)
diff --git a/etc/config.coal.json b/etc/config.coal.json
index 76947d7..7e3a8c4 100644
--- a/etc/config.coal.json
+++ b/etc/config.coal.json
@@ -9,6 +9,7 @@
     },
     "maxObjectCopies": 6,
     "maxRequestAge": 600,
+    "enableMPU": true,
     "numWorkers": 4,
     "port": 8080,
     "auth": {
diff --git a/lib/audit.js b/lib/audit.js
index 93b380b..d352464 100644
--- a/lib/audit.js
+++ b/lib/audit.js
@@ -234,6 +234,10 @@ function auditLogger(options) {
         obj.entryShard = req.entryShard;
         obj.parentShard = req.parentShard;
 
+        if (req.route) {
+            obj.route = req.route.name;
+        }
+
         if (req._timeToLastByte !== undefined &&
             req._totalBytes !== undefined) {
             obj._auditData = true;
diff --git a/lib/auth.js b/lib/auth.js
index c368e28..68fe898 100644
--- a/lib/auth.js
+++ b/lib/auth.js
@@ -689,13 +689,24 @@ function parseHttpAuthToken(req, res, next) {
 
 
 function loadOwner(req, res, next) {
+    var p = req.path();
+    loadOwnerFromPath(req, p, next);
+}
+
+
+/*
+ * Extract the owner of a resource based on the input path, verify that
+ * the account exists, and set the `owner` field on the request object
+ * to the object returned from Mahi.
+ */
+function loadOwnerFromPath(req, p, next) {
     req.log.debug('loadOwner: entered');
 
     var account;
     try {
-        account = decodeURIComponent(req.path().split('/', 2).pop());
+        account = decodeURIComponent(p.split('/', 2).pop());
     } catch (e) {
-        next(new InvalidPathError(req.path()));
+        next(new InvalidPathError(p));
         return;
     }
 
@@ -718,7 +729,7 @@ function loadOwner(req, res, next) {
         req.owner = owner;
 
         if (req.caller.anonymous && !owner.user) {
-            next(new AuthorizationError(common.ANONYMOUS_USER, req.path(),
+            next(new AuthorizationError(common.ANONYMOUS_USER, p,
                 'owner ' + account + ' has no anonymous user'));
             return;
         } else if (req.caller.anonymous) {
@@ -841,6 +852,12 @@ function gatherContext(req, res, next) {
 }
 
 
+/*
+ * Based on the metadata fetched for the request, this handler determines
+ * the appropriate authorization context to set at req.authContext. This
+ * is later passed to mahi by the authorization code to authorize a given
+ * action.
+ */
 function storageContext(req, res, next) {
     var resource = {};
     var metadata;
@@ -872,14 +889,16 @@ function storageContext(req, res, next) {
      * authorization checks and return the correct error.
      */
     if (!req.metadata.type && !req.parentMetadata.type) {
-        next(new DirectoryDoesNotExistError(req));
+        next(new DirectoryDoesNotExistError(req.path()));
         return;
     }
 
-    if (!req.metadata.type && req.parentMetadata.type) { // PUT new obj or dir
+    if (!req.metadata.type && req.parentMetadata.type) {
+        // PUT new obj or dir
         metadata = req.parentMetadata;
         req.authContext.conditions.overwrite = false;
-    } else { // PUT on existing obj or dir
+    } else {
+        // PUT on existing obj or dir
         metadata = req.metadata;
         req.authContext.conditions.overwrite = true;
     }
@@ -1009,6 +1028,8 @@ module.exports = {
         ]);
     },
 
+    loadOwnerFromPath: loadOwnerFromPath,
+
     gatherContext: gatherContext,
     storageContext: storageContext,
     createAuthToken: createAuthToken,
diff --git a/lib/common.js b/lib/common.js
index e9dbc00..8f36dd6 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var EventEmitter = require('events').EventEmitter;
@@ -44,6 +44,8 @@ var JOBS_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/([a-f0-9]{8}-[a-f0-9]{4}-
 /* JSSTYLED */
 var JOBS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/?.*/;
 /* JSSTYLED */
+var UPLOADS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/uploads\/?.*/;
+/* JSSTYLED */
 var JOBS_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/jobs\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/stor/;
 var PUBLIC_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/public(\/(.*)|$)/;
 var REPORTS_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/reports(\/(.*)|$)/;
@@ -57,6 +59,7 @@ var ROOT_REGEXPS = [
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/public\\/?$'), // public
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/stor\\/?$'), // storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/?$'), // jobs (list)
+    new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/uploads\\/?$'), // uploads (list)
 
     // jobs storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/[\\w-]+\\/stor\\/?$'),
@@ -159,6 +162,7 @@ HttpRequest.isRestrictedWrite = function isRestrictedWrite() {
 
 ///--- API
 
+//TODO: comment this.
 function createMetadata(req, type, cb) {
     var prev = req.metadata || {};
     // Override the UpdateMetadata type, as this flows in via PUT Object
@@ -338,13 +342,13 @@ function ensureNotRoot(req, res, next) {
     if (req.method === 'PUT') {
         if (req.headers['content-type'] && req.headers['content-type'] !==
             'application/x-json-stream; type=directory') {
-            next(new RootDirectoryError(req));
+            next(new RootDirectoryError(req.method, req.path()));
             return;
         }
     }
 
     if (req.method === 'DELETE' && !JOBS_PATH.test(req.path())) {
-        next(new RootDirectoryError(req));
+        next(new RootDirectoryError(req.method, req.path()));
         return;
     }
 
@@ -362,7 +366,7 @@ function ensureParent(req, res, next) {
         req.log.debug('ensureParent: done');
         next();
     } else if (!req.parentMetadata || req.parentMetadata.type === null) {
-        next(new DirectoryDoesNotExistError(req));
+        next(new DirectoryDoesNotExistError(req.path()));
     } else if (req.parentMetadata.type !== 'directory') {
         next(new ParentNotDirectoryError(req));
     } else {
@@ -377,8 +381,9 @@ function ensureParent(req, res, next) {
  * metadata, if necessary.
  */
 function getMetadata(req, res, next) {
-    var log = req.log;
+    assert.ok(req.key);
 
+    var log = req.log;
     log.debug('getMetadata: entered');
     vasync.parallel({
         funcs: [
@@ -457,6 +462,7 @@ function getMetadata(req, res, next) {
                 req.metadata._etag = r.etag || null;
                 req.metadata.headers =
                     req.metadata.headers || {};
+                // TODO: comment this for conditional requests
                 if (r.metadata.etag)
                     res.set('Etag', r.metadata.etag);
                 if (r.metadata.mtime) {
@@ -718,23 +724,36 @@ module.exports = {
 
     PATH_LOGIN_RE: PATH_LOGIN_RE,
 
-    StoragePaths: {
-        'public': {
-            'name': 'Public',
-            'regex': PUBLIC_STOR_PATH
-        },
-        'stor': {
-            'name': 'Storage',
-            'regex': STOR_PATH
-        },
-        'jobs': {
-            'name': 'Jobs',
-            'regex': JOBS_ROOT_PATH
-        },
-        'reports': {
-            'name': 'Reports',
-            'regex': REPORTS_STOR_PATH
+    UPLOADS_ROOT_PATH: UPLOADS_ROOT_PATH,
+
+    storagePaths: function storagePaths(cfg) {
+        var StoragePaths = {
+            'public': {
+                'name': 'Public',
+                'regex': PUBLIC_STOR_PATH
+            },
+            'stor': {
+                'name': 'Storage',
+                'regex': STOR_PATH
+            },
+            'jobs': {
+                'name': 'Jobs',
+                'regex': JOBS_ROOT_PATH
+            },
+            'reports': {
+                'name': 'Reports',
+                'regex': REPORTS_STOR_PATH
+            }
+        };
+
+        if (cfg.enableMPU) {
+            StoragePaths.uploads = {
+                'name': 'Uploads',
+                'regex': UPLOADS_ROOT_PATH
+            };
         }
+
+        return (StoragePaths);
     },
 
     createMetadata: createMetadata,
@@ -921,23 +940,6 @@ module.exports = {
         }
 
         return (setup);
-    },
-
-    // Not used anymore
-    debugRequestHandler: function () {
-        function _debugLogRequest(req, res, next) {
-            var log = req.log;
-            var str = req.method + ' ' +
-                req.url + ' ' +
-                req.httpVersion + '\n';
-            Object.keys(req.headers).sort().forEach(function (k) {
-                str += k + ': ' + req.headers[k] + '\n';
-            });
-            log.debug('handling request:\n%s\n', str);
-            return (next());
-        }
-
-        return (_debugLogRequest);
     }
 
 };
diff --git a/lib/dir.js b/lib/dir.js
index d2d3bba..01f2fd0 100644
--- a/lib/dir.js
+++ b/lib/dir.js
@@ -172,9 +172,9 @@ function getDirectory(req, res, next) {
 
 function getRootDirectory(req, res, next) {
     if (req.method !== 'HEAD' && req.method !== 'GET')
-        return (next(new RootDirectoryError(req)));
+        return (next(new RootDirectoryError(req.method, req.path())));
 
-    var storagePaths = Object.keys(common.StoragePaths).sort();
+    var storagePaths = Object.keys(common.storagePaths(req.config)).sort();
     // Pagination is useless, but things like mfind rely on it.
     if (req.params.marker) {
         while (storagePaths.length > 0 &&
@@ -265,7 +265,6 @@ module.exports = {
 
     putDirectoryHandler: function putDirectoryHandler() {
         var chain = [
-            // common.ensureNotRootHandler(),
             common.ensureParentHandler(),
             mkdir
         ];
diff --git a/lib/errors.js b/lib/errors.js
index bd5c156..8e1e22d 100644
--- a/lib/errors.js
+++ b/lib/errors.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var assert = require('assert');
@@ -16,6 +16,14 @@ var util = require('util');
 var restify = require('restify');
 var VError = require('verror');
 
+/*
+ * This file exports errors into the global namespace, for both restify
+ * and new errors. In order to add a new error to muskie, you should
+ * add it to this file, and edit the javascript lint config file in this
+ * repo to include the new error identifier (see jsl.node.conf for
+ * examples). This will define the error for the linter so your code
+ * is `make check` clean.
+ */
 
 
 ///--- Globals
@@ -24,7 +32,6 @@ var sprintf = util.format;
 var RestError = restify.RestError;
 
 
-
 ///--- Errors
 
 function MuskieError(obj) {
@@ -115,11 +122,11 @@ function ContentLengthError() {
 util.inherits(ContentLengthError, MuskieError);
 
 
-function DirectoryDoesNotExistError(req) {
+function DirectoryDoesNotExistError(p) {
     MuskieError.call(this, {
         restCode: 'DirectoryDoesNotExist',
         statusCode: 404,
-        message: sprintf('%s does not exist', path.dirname(req.path()))
+        message: sprintf('%s does not exist', path.dirname(p))
     });
 }
 util.inherits(DirectoryDoesNotExistError, MuskieError);
@@ -439,6 +446,36 @@ function MissingPermissionError(perm) {
 util.inherits(MissingPermissionError, MuskieError);
 
 
+function MultipartUploadCreateError(msg) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadInvalidArgument',
+        statusCode: 409,
+        message: sprintf('cannot create upload: %s', msg)
+    });
+}
+util.inherits(MultipartUploadCreateError, MuskieError);
+
+
+function MultipartUploadStateError(id, msg) {
+    MuskieError.call(this, {
+        restCode: 'InvalidMultipartUploadState',
+        statusCode: 409,
+        message: sprintf('upload %s: %s', id, msg)
+    });
+}
+util.inherits(MultipartUploadStateError, MuskieError);
+
+
+function MultipartUploadInvalidArgumentError(id, msg) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadInvalidArgument',
+        statusCode: 409,
+        message: sprintf('upload %s: %s', id, msg)
+    });
+}
+util.inherits(MultipartUploadInvalidArgumentError, MuskieError);
+
+
 function NotAcceptableError(req, type) {
     MuskieError.call(this, {
         restCode: 'NotAcceptable',
@@ -516,12 +553,12 @@ function RequestedRangeNotSatisfiableError(req, err) {
 util.inherits(RequestedRangeNotSatisfiableError, MuskieError);
 
 
-function RootDirectoryError(req) {
+function RootDirectoryError(method, p) {
     MuskieError.call(this, {
         restCode: 'OperationNotAllowedOnRootDirectory',
         statusCode: 400,
         message: sprintf('%s is not allowed on %s',
-                         req.method, req.path())
+                         method, p)
     });
 }
 util.inherits(RootDirectoryError, MuskieError);
@@ -631,13 +668,6 @@ function translateError(err, req) {
 
 ///--- Exports
 
-// Make it easy to access all Errors by injecting into the global
-// namespace (both restify and $self errors).
-// Object.keys(restify).forEach(function (k) {
-//         if (/\w+Error$/.test(k))
-//                 global[k] = restify[k];
-// });
-
 // Auto export all Errors defined in this file
 fs.readFileSync(__filename, 'utf8').split('\n').forEach(function (l) {
     /* JSSTYLED */
diff --git a/lib/obj.js b/lib/obj.js
index 6686ece..febe095 100644
--- a/lib/obj.js
+++ b/lib/obj.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 //
@@ -78,9 +78,30 @@ var httpDate = restify.httpDate;
 var sprintf = util.format;
 
 var DATA_TIMEOUT = parseInt(process.env.MUSKIE_DATA_TIMEOUT || 45000, 10);
+
+// Upper bound of 1 million entries in a directory.
+var MAX_DIRENTS = 1000000;
+
+// The default content-length value we use if we don't know the object size up
+// front, including streaming PUTs and some multipart uploads.
 var DEF_MAX_LEN = 53687091200;
 
+/*
+ * Default minimum and maximum number of copies of an object we will store,
+ * as specified in the {x-}durability-level header.
+ *
+ * The max number of copies is configurable in the config file; the minimum
+ * is not.
+ */
+var DEF_MIN_COPIES = 1;
+var DEF_MAX_COPIES = 9;
 
+// Default number of object copies to store.
+var DEF_NUM_COPIES = 2;
+
+
+// The MD5 sum string for a zero-byte object.
+var ZERO_BYTE_MD5 = '1B2M2Y8AsgTpgAmY7PhCfg==';
 
 ///--- Helpers
 
@@ -206,7 +227,7 @@ function parseArguments(req, res, next) {
     } else {
         var copies;
         var len;
-        var maxObjectCopies = req.config.maxObjectCopies;
+        var maxObjectCopies = req.config.maxObjectCopies || DEF_MAX_COPIES;
 
         // First determine object size
         if (req.isChunked()) {
@@ -222,7 +243,7 @@ function parseArguments(req, res, next) {
             next(new ContentLengthError());
             return;
         } else if ((req.getContentLength() || 0) === 0) {
-            req._contentMD5 = '1B2M2Y8AsgTpgAmY7PhCfg==';
+            req._contentMD5 = ZERO_BYTE_MD5;
             req.sharks = [];
             req._zero = true;
             len = 0;
@@ -231,9 +252,10 @@ function parseArguments(req, res, next) {
         // Next determine the number of copies
         copies = parseInt((req.header('durability-level') ||
                            req.header('x-durability-level') ||
-                           2), 10);
-        if (copies < 1 || copies > (maxObjectCopies || 9)) {
-            next(new InvalidDurabilityLevelError(1, maxObjectCopies));
+                           DEF_NUM_COPIES), 10);
+        if (copies < DEF_MIN_COPIES || copies > maxObjectCopies) {
+            next(new InvalidDurabilityLevelError(DEF_MIN_COPIES,
+                maxObjectCopies));
             return;
         }
 
@@ -308,12 +330,14 @@ function findSharks(req, res, next) {
 }
 
 
+// Ensures that directories do not exceed a set number of entries.
 function enforceDirectoryCount(req, res, next) {
     if (req.query.metadata) {
         next();
         return;
     }
 
+    assert.ok(req.parentKey);
     var opts = {
         directory: req.parentKey,
         requestId: req.id()
@@ -326,8 +350,7 @@ function enforceDirectoryCount(req, res, next) {
         } else {
             count = count || 0;
 
-            // Enforce a 1M directory limit
-            if (count > 1000000) {
+            if (count > MAX_DIRENTS) {
                 next(new DirectoryLimitError(req.parentKey));
             } else {
                 next();
@@ -337,14 +360,20 @@ function enforceDirectoryCount(req, res, next) {
 }
 
 
+/*
+ * This handler attempts to connect to one of the pre-selected, cross-DC sharks.
+ * If a connection to any shark in the set fails, we try a different set of
+ * sharks.
+ */
 function startSharkStreams(req, res, next) {
     if (req._zero || req.query.metadata) {
         next();
         return;
     }
 
-    var log = req.log;
+    assert.ok(req._sharks);
 
+    var log = req.log;
     log.debug({
         objectId: req.objectId,
         sharks: req._sharks
@@ -410,6 +439,13 @@ function startSharkStreams(req, res, next) {
 }
 
 
+/*
+ * Here we stream the data from the object to each connected shark, using a
+ * check stream to compute the md5 sum of the data as it passes through muskie
+ * to mako.
+ *
+ * This handler is blocking.
+ */
 function sharkStreams(req, res, next) {
     if (req._zero || req.query.metadata) {
         next();
@@ -575,6 +611,9 @@ function sharkStreams(req, res, next) {
 }
 
 
+/*
+ * Here we save a new object record to Moray.
+ */
 function saveMetadata(req, res, next) {
     var log = req.log;
     common.createMetadata(req, 'object', function (err, opts) {
@@ -888,6 +927,11 @@ function deletePointer(req, res, next) {
 
 module.exports = {
 
+    DEF_MAX_LEN: DEF_MAX_LEN,
+    DEF_MIN_COPIES: DEF_MIN_COPIES,
+    DEF_MAX_COPIES: DEF_MAX_COPIES,
+    DEF_NUM_COPIES: DEF_NUM_COPIES,
+    ZERO_BYTE_MD5: ZERO_BYTE_MD5,
 
     putObjectHandler: function _putObject() {
         var chain = [
@@ -923,5 +967,24 @@ module.exports = {
             deletePointer
         ];
         return (chain);
+    },
+
+     // Handlers used for uploading parts to multipart uploads are exposed here.
+    putPartHandler: function _putPart() {
+        var chain = [
+            parseArguments,
+            enforceDirectoryCount,
+            startSharkStreams,
+            sharkStreams,
+            saveMetadata
+        ];
+        return (chain);
+    },
+
+    enforceDirectoryCountHandler: function _enforceDirectoryCount() {
+        var chain = [
+            enforceDirectoryCount
+        ];
+        return (chain);
     }
 };
diff --git a/lib/other.js b/lib/other.js
index 5a91a42..c53333f 100644
--- a/lib/other.js
+++ b/lib/other.js
@@ -376,7 +376,6 @@ module.exports = {
             common.ensureParentHandler(),
             preflightPUTRequest,
             common.ensureEntryExistsHandler(),
-            // common.assertMetadataHandler(),
             preflightRequest
         ];
 
diff --git a/lib/server.js b/lib/server.js
index 1bf8b7e..8f0cfb4 100644
--- a/lib/server.js
+++ b/lib/server.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var crypto = require('crypto');
@@ -24,10 +24,11 @@ var common = require('./common');
 var dir = require('./dir');
 var jobs = require('./jobs');
 var link = require('./link');
+var medusa = require('./medusa');
 var obj = require('./obj');
 var other = require('./other');
 var picker = require('./picker');
-var medusa = require('./medusa');
+var uploads = require('./uploads');
 
 // injects into the global namespace
 require('./errors');
@@ -284,6 +285,12 @@ function createServer(options, clearProxy) {
         authAction: 'mlogin'
     }, medusa.getMedusaAttachHandler());
 
+
+    // Multipart Upload API
+    if (options.enableMPU) {
+        addMultipartUploadRoutes(server);
+    }
+
     server.use(common.getMetadataHandler());
     server.use(auth.storageContext);
     server.use(auth.authorizationHandler());
@@ -303,6 +310,10 @@ function createServer(options, clearProxy) {
                common.assertMetadataHandler(),
                dir.getDirectoryHandler());
 
+    if (options.enableMPU) {
+        addMultipartUploadDataPlaneRoutes(server);
+    }
+
     // Root dir
 
     server.get({
@@ -334,10 +345,18 @@ function createServer(options, clearProxy) {
         authAction: 'deletedirectory'
     }, dir.rootDirHandler());
 
-    Object.keys(common.StoragePaths).forEach(function (k) {
 
-        var _p = common.StoragePaths[k].regex;
-        var _n = common.StoragePaths[k].name;
+    /*
+     * Here we generate routes for GET, PUT, HEAD, DELETE and OPTIONS requests
+     * for all directory trees that are considered "storagePaths", which use
+     * generic Muskie handlers (for example, PUT to a directory, GET an object,
+     * and so on).
+     */
+    var storagePaths = common.storagePaths(options);
+    Object.keys(storagePaths).forEach(function (k) {
+
+        var _p = storagePaths[k].regex;
+        var _n = storagePaths[k].name;
 
         // Otherwise in audit/dtrace we'll see GetStorageStorage
         if (_n === 'Storage')
@@ -410,7 +429,233 @@ function createServer(options, clearProxy) {
     return (server);
 }
 
+function forbiddenHandler(req, res, next) {
+        req.log.info('Method ' + req.method + ' disallowed for ' + req.url);
+        res.send(403);
+        next(false);
+}
+
+
+/*
+ * This adds the routes for the majority of multipart upload API endpoints,
+ * including:
+ *   - create
+ *   - get
+ *   - abort
+ *   - commit
+ *
+ * As well as handlers that redirect the client to the correct upload path if
+ * they perform a request of the form:
+ *    {HEAD,GET,PUT,POST,DELETE} /:account/uploads/:id.
+ */
+function addMultipartUploadRoutes(server) {
+
+    /*
+     * Path: /:account/uploads
+     *
+     * Allowed: POST (create-mpu), GET (list-mpu), HEAD
+     * Disallowed: PUT, DELETE
+     */
+    server.post({
+        path: '/:account/uploads',
+        name: 'CreateUpload',
+        contentType: 'application/json'
+    }, uploads.createHandler());
+
+    server.put({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+
+    // Redirects
+    /* JSSTYLED */
+    var uploadsRedirectPath = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}';
+    /* JSSTYLED */
+    var uploadsRedirectPathPart = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}/:partNum';
+    server.get({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.get({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    /*
+     * Path: /:account/uploads/[0-f]/:id
+     *
+     * Allowed: GET (list-parts), HEAD
+     * Disallowed: PUT, POST, DELETE
+     */
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    /*
+     * Path: /:account/uploads/[0-f]/:id/state
+     *
+     * Allowed: GET (get-mpu)
+     * Disallowed: HEAD, PUT, POST, DELETE
+     */
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/state',
+        name: 'GetUpload'
+    }, uploads.getHandler());
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    /*
+     * Path: /:account/uploads/[0-f]/:id/abort
+     *
+     * Allowed: POST (abort-mpu)
+     * Disallowed: GET, HEAD, PUT, DELETE
+     */
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/abort',
+        name: 'AbortUpload'
+    }, uploads.abortHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    /*
+     * Path: /:account/uploads/[0-f]/:id/commit
+     *
+     * Allowed: POST (commit-mpu)
+     * Disallowed: GET, HEAD, PUT, DELETE
+     */
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/commit',
+        name: 'CommitUpload',
+        contentType: 'application/json'
+    }, uploads.commitHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+}
+
 
+/*
+ * This adds the routes for the "data plane" portions of the multipart upload
+ * API -- that is, the uploading of parts.
+ */
+function addMultipartUploadDataPlaneRoutes(server) {
+    /*
+     * Path: /:account/uploads/[0-f]/:id/:partNum
+     *
+     * Allowed: PUT (upload-part), HEAD
+     * Disallowed: GET, POST, DELETE
+     */
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/:partNum',
+        name: 'UploadPart',
+        contentType: '*/*'
+    }, uploads.uploadPartHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+}
 
 ///--- Exports
 
diff --git a/lib/shark_client.js b/lib/shark_client.js
index 98db362..b9c223d 100644
--- a/lib/shark_client.js
+++ b/lib/shark_client.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var EventEmitter = require('events').EventEmitter;
@@ -55,8 +55,11 @@ util.inherits(SharkResponseError, Error);
 
 function _request(opts, cb) {
     cb = once(cb);
-
     var req = http.request(opts);
+
+    if (opts.body) {
+        req.write(JSON.stringify(opts.body));
+    }
     /*
      * This timer represents the timeout for connecting to the shark
      * for this request, so it is important that it is cleared only once
@@ -85,6 +88,10 @@ function _request(opts, cb) {
         cb(new ConnectTimeoutError(opts.hostname, opts.connectTimeout));
     }, opts.connectTimeout);
 
+    if (opts.method === 'POST') {
+        clearTimeout(connectionTimer);
+    }
+
     req.once('error', function onRequestError(err) {
         clearTimeout(connectionTimer);
         cb(err);
@@ -117,8 +124,9 @@ function _request(opts, cb) {
     });
 
     req.once('response', onResponse);
-    if (opts.method !== 'PUT')
+    if (opts.method !== 'PUT') {
         req.end();
+    }
 }
 
 
@@ -135,11 +143,19 @@ function request(thisp, method, opts, cb) {
         },
         hostname: thisp.hostname,
         method: method,
-        path: '/' + (opts.creator || opts.owner) + '/' + opts.objectId,
-        port: thisp.port,
-        requestId: opts.requestId
+        port: thisp.port
     };
 
+    if (!opts.path) {
+        _opts.path = '/' + (opts.creator || opts.owner) + '/' + opts.objectId;
+    } else {
+        _opts.path = opts.path;
+    }
+
+    if (opts.body) {
+        _opts.body = opts.body;
+    }
+
     log.debug(_opts, 'request: entered');
 
     // don't log this
@@ -227,7 +243,7 @@ util.inherits(SharkClient, EventEmitter);
 
 
 /**
- * Wraps up the restify http_client.get request.
+ * Wraps node's http request.
  *
  * Options needs:
  *   - objectId
@@ -251,7 +267,7 @@ SharkClient.prototype.get = function get(opts, cb) {
 
 
 /**
- * Wraps up the restify http_client.head request.
+ * Wraps node's http request.
  *
  * Options needs:
  *   - objectId
@@ -274,8 +290,8 @@ SharkClient.prototype.head = function head(opts, cb) {
 };
 
 
-/**
- * Wraps up the restify http_client.put request.
+/*
+ * Wraps up node's http request.
  *
  * Options needs:
  *   - contentLength
@@ -321,12 +337,39 @@ SharkClient.prototype.put = function put(opts, cb) {
 };
 
 
+/*
+ * Wraps up node's http request.
+ *
+ * Options needs:
+ *   - objectId
+ *   - contentType
+ *   - objectId
+ *   - owner
+ *   - requestId
+ *
+ * @param {object} options see above
+ * @param {body} JSON blob to send in POST request
+ * @param {function} callback => f(err, req)
+ */
+SharkClient.prototype.post = function post(opts, body, cb) {
+    assert.object(opts, 'options');
+    assert.object(body, 'body');
+    assert.string(opts.objectId, 'options.objectId');
+    assert.string(opts.owner, 'options.owner');
+    assert.string(opts.requestId, 'options.requestId');
+    assert.func(cb, 'callback');
+
+    opts.body = body;
+
+    request(this, 'POST', opts, cb);
+};
+
+
 SharkClient.prototype.toString = function toString() {
     return ('[object SharkClient<' + this.hostname + '>]');
 };
 
 
-
 ///--- Exports
 
 module.exports = {
diff --git a/lib/uploads/abort.js b/lib/uploads/abort.js
new file mode 100644
index 0000000..82296fa
--- /dev/null
+++ b/lib/uploads/abort.js
@@ -0,0 +1,101 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var restify = require('restify');
+
+var auth = require('../auth');
+var uploadsCommon = require('./common');
+require('../errors');
+
+
+///--- API
+
+
+
+/*
+ * Ensures that the upload is in the correct state: either created or aborted,
+ * and updates the upload record's metadata if needed to reflect this state.
+ */
+function finalizingState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+    var id = upload.id;
+
+    var state = req.upload.get(uploadsCommon.mdKeys.STATE);
+    var type = req.upload.get(uploadsCommon.mdKeys.TYPE);
+
+    log.debug({
+        uploadId: id,
+        uploadState: state,
+        finalizingType: type ? type : 'N/A'
+    }, 'abort: requested');
+
+    if (state === uploadsCommon.MPU_S_CREATED) {
+        assert.ok(!type);
+        upload.finalizeUploadRecord(uploadsCommon.MPU_FT_ABORT, null,
+        function (err2) {
+            if (err2) {
+                next(err2);
+            } else {
+                next();
+            }
+        });
+    } else if ((state === uploadsCommon.MPU_S_FINALIZING) &&
+        (type === uploadsCommon.MPU_FT_ABORT)) {
+
+        log.debug('abort already in progress for upload ' + id);
+        next();
+
+    } else if ((state === uploadsCommon.MPU_S_FINALIZING) &&
+        (type === uploadsCommon.MPU_FT_COMMIT)) {
+
+        next(new MultipartUploadStateError(id, 'already committed'));
+
+    } else {
+        assert.fail('Invalid state/type combination for upload: '
+            + state + '/' + type);
+     }
+}
+
+
+function abort(req, res, next) {
+    var log = req.log;
+
+    req.upload.abortUpload(function (err) {
+        if (err) {
+            next(err);
+        } else {
+            log.info({
+                uploadId: req.upload.id
+            }, 'abort: completed');
+
+            res.setHeader('Content-Length', '0');
+            res.send(204);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    abortHandler: function abortHandler() {
+        var chain = [
+            uploadsCommon.loadUpload,
+            uploadsCommon.uploadContext,
+            auth.authorizationHandler(),
+            finalizingState,
+            abort
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/commit.js b/lib/uploads/commit.js
new file mode 100644
index 0000000..39d685b
--- /dev/null
+++ b/lib/uploads/commit.js
@@ -0,0 +1,542 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var crypto = require('crypto');
+var restify = require('restify');
+var path = require('path');
+var util = require('util');
+var vasync = require('vasync');
+var verror = require('verror');
+
+var auth = require('../auth');
+var common = require('../common');
+var obj = require('../obj');
+var sharkClient = require('../shark_client');
+var uploadsCommon = require('./common');
+var utils = require('../utils');
+require('../errors');
+
+
+///--- Globals
+
+var shallowCopy = utils.shallowCopy;
+var sprintf = util.format;
+
+/*
+ * We enforce a minimum part size because each part requires additional space
+ * and load on the metadata tier throughout the life of the upload: uploading
+ * parts, contacting Moray to validate etags on commit, and performing garbage
+ * collection of the parts and their metadata after the upload is finalized.
+ *
+ * Thus, we discourage excessive use of parts by requiring all parts (except
+ * the last part) to be at least 5 MB.
+ */
+var MIN_PART_SIZE = 5242880;
+
+
+///--- Helpers
+
+/*
+ * Invokes the mako-finalize operation on a single shark.
+ *
+ * Parameters:
+ * - req the current request
+ * - body: body to POST to the shark
+ * - opts: an options blob to pass to the shark client
+ * - shark: a shark object
+ */
+function invokeMakoFinalize(req, body, opts, shark, cb) {
+    var client = sharkClient.getClient({
+        connectTimeout: req.sharkConfig.connectTimeout,
+        log: req.log,
+        retry: req.sharkConfig.retry,
+        shark: shark,
+        agent: req.sharkAgent
+    });
+    assert.ok(client, 'sharkClient returned null');
+
+    var start = Date.now();
+    var hostname = shark.manta_storage_id;
+
+    client.post(opts, body, function (err, _, res) {
+        /*
+         * Similar to PUTs, log information about sharks we contacted over
+         * the course of the commit request.
+         */
+        var sharkInfo = {
+            shark: hostname,
+            timeTotal: Date.now() - start,
+            result: 'fail',
+            _startTime: start
+        };
+        req.sharksContacted.push(sharkInfo);
+
+        var s = {
+            shark: hostname,
+            md5: null
+        };
+        if (err) {
+            cb(err, s);
+        } else {
+            s.md5 = res.headers['x-joyent-computed-content-md5'];
+            if (!s.md5) {
+                cb(new InternalError('mako failed to return an MD5 sum'), s);
+            } else {
+                sharkInfo.result = 'ok';
+                cb(null, s);
+            }
+        }
+    });
+}
+
+
+// Given an array of etags, computes the md5 sum of all etags concatenated.
+function computePartsMD5(parts) {
+    var hash = crypto.createHash('md5');
+    parts.forEach(function (p) {
+        hash.update(p);
+    });
+
+    return (hash.digest('base64'));
+}
+
+
+///--- API
+
+
+// Get the owner of the resource of the input object path.
+function loadOwner(req, res, next) {
+    var p = req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH);
+    auth.loadOwnerFromPath(req, p, next);
+}
+
+
+/*
+ * For authorizing the use of the object path on commit, we rely on
+ * existing handlers for other muskie endpoints: in particular,
+ * getMetadata, which loads the metadata for the parent directory, if
+ * needed, and the metadata for the object at the path stored at req.key; and
+ * storageContext, with sets up the authContext used by mahi to authorize
+ * the caller to perform the given action. In order to use these handlers,
+ * we need to set some state on the request object, specifically:
+ *      - req.key: the key of the object path (for this commit)
+ *      - req.parentKey: the key of the object path's parent directory
+ */
+function setupMetadataState(req, res, next) {
+    var log = req.log;
+
+    req._path = req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH);
+
+    req.key = req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH_KEY);
+    if (!req.isRootDirectory(req.key)) {
+        req.parentKey = path.dirname(req.key);
+    }
+
+    log.debug({
+        objectPathKey: req.key,
+        parentKey: req.parentKey
+    }, 'passing keys to getMetadata');
+
+    next();
+}
+
+
+/*
+ * Ensures that the upload is in a proper state before proceeding: either
+ * CREATED or COMMIT. It it is in state COMMIT, the request must specify the
+ * same set of parts as is recorded in the upload record.
+ */
+function validateUploadState(req, res, next) {
+    var log = req.log;
+    var parts = req.body.parts || [];
+    var id = req.upload.id;
+
+    var state = req.upload.get(uploadsCommon.mdKeys.STATE);
+    var type = req.upload.get(uploadsCommon.mdKeys.TYPE);
+    var computedPartsMD5 = computePartsMD5(parts);
+
+    req.upload.mpuPartsMD5 = computedPartsMD5;
+
+    log.debug({
+        uploadId: id,
+        parts: parts,
+        uploadState: state,
+        finalizingType: type ? type : 'N/A',
+        parts: parts,
+        computedPartsMD5: computedPartsMD5
+    }, 'commit: requested');
+
+    if (state === uploadsCommon.MPU_S_FINALIZING) {
+        if (type === uploadsCommon.MPU_FT_ABORT) {
+            // Abort already in progress
+            next(new MultipartUploadStateError(id, 'already aborted'));
+
+        } else if (type === uploadsCommon.MPU_FT_COMMIT) {
+            // Not an error, but we need to verify the parts are the
+            // same as the input ones before proceeding
+            var p = req.upload.get(uploadsCommon.mdKeys.PARTS_MD5);
+            if (computedPartsMD5 !== p) {
+                log.info({
+                    userSpecified: computedPartsMD5,
+                    expected: p
+                }, 'mismatch of parts md5');
+
+                next(new MultipartUploadStateError(id,
+                    'already has a commit in progress'));
+            } else {
+                next();
+            }
+
+        } else {
+            assert.fail('Invalid type: ' + type);
+        }
+    } else if (state === uploadsCommon.MPU_S_CREATED) {
+        next();
+    } else {
+        assert.fail('Invalid state: ' + state);
+    }
+}
+
+
+/*
+ * Ensures that the input parts set for the commit has the etags of the parts
+ * as they exist now. This step also checks that all parts have a size that
+ * exceeds the minimum part size (excluding the last part).
+ */
+function validateParts(req, res, next) {
+    var log = req.log;
+    var id = req.upload.id;
+    var parts = req.body.parts;
+    log.debug('validating parts for upload');
+
+    if (!parts) {
+        req.body.parts = [];
+        log.debug('empty parts array');
+        next();
+        return;
+    } else if (parts.length > uploadsCommon.MAX_NUM_PARTS) {
+        next(new MultipartUploadInvalidArgumentError(id,
+            sprintf('too many parts provided (%d provided; max is %d)',
+                parts.length, uploadsCommon.MAX_NUM_PARTS)));
+        return;
+    }
+
+    var errors = [];
+    var sum = 0;
+
+    /*
+     * This function verifies that:
+     * - the etag exists
+     * - the etag matches the current etag for the part
+     * - the size of the part is at least the minimum size, unless
+     *   it's the last part
+     */
+    function validateEtag(part, cb) {
+        var index = part.index;
+        var etag = part.etag;
+
+        var record = req.upload.uploadMd;
+        var key = record.key + '/' + index;
+
+        if (etag === '') {
+            errors.push(new MultipartUploadInvalidArgumentError(id,
+                sprintf('[part %d] invalid etag (%s)', index, etag)));
+            cb();
+            return;
+        }
+
+        var opts = {
+            key: key,
+            requestId: req.getId()
+        };
+
+        req.moray.getMetadata(opts, function (err, md) {
+            log.debug('part index: ' + index + ', etag: ' + etag);
+            if (err) {
+                if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                    //  No part with that part number has been uploaded.
+                    errors.push(new MultipartUploadInvalidArgumentError(id,
+                        sprintf('[part %d] part does not exist', index)));
+                } else {
+                    errors.push(new InternalError(err));
+                }
+            } else {
+                var size = parseInt(md.contentLength, 10);
+                var isFinalPart = index === (parts.length - 1);
+
+                if (md.etag !== etag) {
+                    // Uploaded part has a different etag than the input one.
+                    errors.push(new MultipartUploadInvalidArgumentError(id,
+                        sprintf('[part %d] invalid etag "%s"', index, etag)));
+                } else if (!isFinalPart && (size < MIN_PART_SIZE)) {
+                    errors.push(new MultipartUploadInvalidArgumentError(id,
+                        sprintf('[part %d] part is too small (size %d)',
+                            index, size)));
+                }
+
+                sum += size;
+            }
+
+            cb();
+        });
+    }
+
+    var queue = vasync.queue(validateEtag, 10);
+    parts.forEach(function (val, i) {
+        queue.push({
+            index: i,
+            etag: val
+        });
+    });
+    queue.close();
+
+    queue.on('end', function () {
+        log.debug('part validation completed');
+        if (errors.length > 0) {
+
+            // Even if there's an internal error, we still send any user
+            // errors we encountered, so they can be corrected and retried.
+            for (var i = 0; i < errors.length; i++) {
+                var e = errors[i];
+                assert.number(e.statusCode);
+                if (e.statusCode >= 500) {
+                    log.error('internal error: ' + e);
+                } else if (e.statusCode >= 400) {
+                    next(e);
+                    return;
+                } else {
+                    assert.fail('invalid error: ' + e);
+                }
+            }
+
+            next(new InternalError('commit error'));
+
+        } else {
+            req.upload.checkSize(sum, function (valid, expected) {
+                if (!valid) {
+                    next(new MultipartUploadInvalidArgumentError(id,
+                        sprintf('expected content-length %s, but object' +
+                            'was %s', expected, sum)));
+                } else {
+                    req.upload.mpuSize = sum;
+                    next();
+                }
+            });
+        }
+    });
+}
+
+
+/*
+ * Saves the upload record with its state set to FINALIZING.
+ */
+function finalizingState(req, res, next) {
+    assert.ok(req.upload.mpuPartsMD5);
+
+    req.upload.finalizeUploadRecord(
+        uploadsCommon.MPU_FT_COMMIT,
+        req.upload.mpuPartsMD5,
+        function (err) {
+            if (err) {
+                next(err);
+            } else {
+                next();
+            }
+    });
+}
+
+
+/*
+ * Invokes the mako-finalize operation on each shark selected at the beginning
+ * of the upload. If there is a problem with any of the sharks, this operation
+ * will fail.
+ *
+ * The mako node expects a JSON blob of the form:
+ * {
+ *      version,        // the version of multipart upload this is
+ *      owner,          // string uuid of the owner of the upload object
+ *      nbytes,         // expected size of the object
+ *      objectId,       // string uuid of object
+ *      parts,          // array of string uuids for each part
+ * }
+ *
+ * This handler is also expected to set the following on the uploads object:
+ *  - contentMD5
+ *  - objectId (if it does not exist yet)
+ */
+function finalizeUpload(req, res, next) {
+    var log = req.log;
+
+    var objectId = req.upload.get(uploadsCommon.mdKeys.OBJECT_ID);
+    var sharks = req.upload.get(uploadsCommon.mdKeys.SHARKS);
+    var nbytes = req.upload.mpuSize;
+
+    // Skip mako-finalize for zero-byte uploads.
+    if (nbytes === 0) {
+        log.debug('zero-byte object; skipping mako-finalize');
+        req.upload.mpuContentMD5 = obj.ZERO_BYTE_MD5;
+        req.upload.mpuSize = 0;
+        next();
+        return;
+    }
+
+    var body = {
+        version: 1,
+        nbytes: nbytes,
+        account: req.owner.account.uuid,
+        objectId: objectId,
+        parts: req.body.parts
+    };
+
+    var opts = {
+        objectId: objectId,
+        owner: req.owner.account.uuid,
+        requestId: req.getId(),
+        path: '/mpu/v1/commit' + '/' + req.upload.id
+    };
+
+    req.sharksContacted = [];
+
+    vasync.forEachParallel({
+        func: function finalize(shark, cb) {
+            var _opts = shallowCopy(opts);
+            var _body = shallowCopy(body);
+            invokeMakoFinalize(req, _body, _opts, shark, cb);
+        },
+        inputs: sharks
+    },  function (err, results) {
+            log.debug('mako-finalize: all sharks contacted');
+
+            if (err) {
+                results.operations.forEach(function (r) {
+                    log.error('error with shark ' + r.result.shark +
+                        ': ' + r.err);
+                });
+                // TODO: this should probably be a new type of error.
+                next(new SharksExhaustedError());
+            } else {
+                var md5 = null;
+
+                // Validate that all makos returned the same md5 sum.
+                var mismatch = false;
+                results.operations.forEach(function (r) {
+                    assert.ok(r.status === 'ok');
+                    assert.ok(r.result);
+
+                    if (md5 && (md5 !== r.result.md5)) {
+                        mismatch = true;
+                    } else {
+                        md5 = r.result.md5;
+                    }
+                });
+
+                if (mismatch) {
+                    log.error('mako nodes returned different md5 sums for ' +
+                        'the same object');
+
+                    results.operations.forEach(function (r) {
+                        log.error(sprintf('shark \"%s\", md5: %s',
+                            r.result.shark, r.result.md5));
+                    });
+
+                    next(new InternalError());
+                } else {
+                    // Validate user-provided md5 sums.
+                    req.upload.checkMD5(md5, function (valid, expected) {
+                        if (!valid) {
+                            next(new ChecksumError(expected, md5));
+                        } else {
+                            req.upload.mpuContentMD5 = md5;
+                            next();
+                        }
+                    });
+                }
+            }
+    });
+}
+
+
+/*
+ * This step makes the committed upload visible from Manta by atomically
+ * inserting a commit record and object record on the shard associated
+ * with the object. Most of the heavy lifting is done by the req.uploads
+ * object here.
+ */
+function commit(req, res, next) {
+    var log = req.log;
+
+    var size = req.upload.mpuSize;
+    var md5 = req.upload.mpuContentMD5;
+    var partsMD5 = req.upload.mpuPartsMD5;
+
+    assert.number(size);
+    assert.string(md5);
+
+    req.upload.commitUpload(partsMD5, size, md5, function (err) {
+        if (err) {
+            next(err);
+        } else {
+            var p = req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH);
+
+            log.info({
+                uploadId: req.upload.id,
+                objectPath: p
+            }, 'commit: completed');
+
+            res.setHeader('Location', p);
+            res.send(201);
+            next();
+        }
+    });
+}
+
+function ensureNotRoot(req, res, next) {
+    var p = req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH);
+
+    if (!req.isRootDirectory(p)) {
+        next();
+        return;
+    } else {
+        next(new RootDirectoryError(req.method, p));
+    }
+}
+
+
+///--- Exports
+
+module.exports = {
+    commitHandler: function commitHandler() {
+        var chain = [
+            uploadsCommon.loadUpload,
+            uploadsCommon.uploadContext,
+            auth.authorizationHandler(),
+            loadOwner,
+            setupMetadataState,
+            common.getMetadataHandler(),
+            auth.storageContext,
+            auth.authorizationHandler(),
+            common.ensureNotDirectoryHandler(),
+            common.ensureParentHandler(),
+            ensureNotRoot,
+            obj.enforceDirectoryCountHandler(),
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 500000
+            }),
+            validateUploadState,
+            validateParts,
+            finalizingState,
+            finalizeUpload,
+            commit
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/common.js b/lib/uploads/common.js
new file mode 100644
index 0000000..dbc9e92
--- /dev/null
+++ b/lib/uploads/common.js
@@ -0,0 +1,1133 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var util = require('util');
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libmanta = require('libmanta');
+var libuuid = require('libuuid');
+var path = require('path');
+var verror = require('verror');
+
+var common = require('../common');
+var obj = require('../obj');
+require('../errors');
+
+
+/*
+ *  This file contains the majority of the logic for handling multipart uploads.
+ *
+ *  API OVERVIEW:
+ *
+ *  The Manta multipart upload API allows clients to upload a Manta object
+ *  by splitting it into parts and uploading the parts individually. When all
+ *  parts are uploaded, the client signifies that the upload is completed by
+ *  "committing" the upload through the API, which creates a Manta object
+ *  that is the concatenation of the uploaded parts and is indistiguishable from
+ *  an object created through a normal Manta PUT. If a client decides not to
+ *  finish the upload, it may also abort the upload process.
+ *
+ *  The possible operations in the mulitpart upload API are:
+ *      - create: establish a multipart upload
+ *      - upload-part: upload a part of the object
+ *      - abort: cancel the upload
+ *      - commit: complete the upload
+ *      - get: get information about an ongoing upload
+ *
+ *  There is an additional API endpoint designed for client usability purposes
+ *  that redirects all requests sent to the path /:account/upload/:id to the
+ *  correct upload path.
+ *
+ *
+ *  TERMINOLOGY:
+ *
+ *  There is some terminology that is used consistently throughout the
+ *  multipart upload implementation that is useful to know:
+ *
+ *   - Upload ID: a uuid representing a multipart upload request, selected
+ *     when the upload is created.
+ *
+ *   - Upload Path: The path where parts of an upload are uploaded to and
+ *     stored in Manta. This is different from the target object path.
+ *
+ *   - Upload Record: The Manta directory record for the upload path. This
+ *     record contains state about the upload recording in an additional
+ *     "upload" blob tacked onto the record. The upload record gives us a
+ *     mechanism of passing state about an upload across muskie requests.
+ *
+ *   - Tarlet Object: The object that is intended to be created when the upload
+ *     is committed.
+ *
+ *   - Target Object Path: An input to creating an upload, this refers to the
+ *     path in Manta where the target object will be stored once the upload is
+ *     committed.
+ *
+ *   - Target Object Record: The Manta object record for the target object.
+ *
+ *   - Finalizing Record: A Manta record, stored in a special multipart uploads
+ *     bucket (namely, the "manta_uploads" bucket), that is guaranteed to exist
+ *     on the same shard as the target object record. The key of this record is
+ *     constructed using both the target object path and the upload ID. (By
+ *     constructing the key this way, we allow for different multipart uploads
+ *     for the same target object path, whether they are simulataneous or not.)
+ *     The presence of a finalizing record for a given target object path and
+ *     upload ID pair indicates that an upload has been "finalized" -- either
+ *     committed or aborted.
+ *
+ *  METADATA STRUCTURE:
+ *
+ *  Because most of the state about an upload is stored in metadata records in
+ *  Moray, it is important to have a well-defined structure for what this
+ *  information looks like.
+ *
+ *   - Upload Record: This record has the same structure as a typical Manta
+ *     directory record, with an additional object called "upload" that has
+ *     the following structure:
+ *
+ *      upload {
+ *          id,             // upload id
+ *          state,          // state of the upload: CREATED or FINALIZING
+ *          type,           // if state is FINALIZING, then ABORT or COMMIT
+ *          objectPath,     // target object path
+ *          objectPathKey,  // the Moray key for the target object path
+ *          uploadPath,     // upload path
+ *          headers,        // headers to store on object record
+ *          sharks,         // mako sharks the object is stored on
+ *          partsMD5,       // for a commit, the MD5 sum of the parts etags
+ *          objectId        // object ID for the target object
+ *      }
+ *
+ *    - Finalizing Record: This record has the same structure as a typical Manta
+ *     directory record, with an additional object called "upload" that includes
+ *     the following fields:
+ *      upload {
+ *          uploadId,           // upload id
+ *          finalizingType,     // ABORT or COMMIT
+ *          objectPath          // target object path
+ *          objectId            // target object id
+ *          md5                 // MD5 sum of the object (returned from mako)
+ *      }
+ *
+ *    - Object Record: The object record is a normal Manta object record, but
+ *      there are a few fields on the object that are set explicitly by the
+ *      multipart upload code, instead of the common metadata code.
+ *
+ *      In particular, the following fields are set explicitly:
+ *        - objectId: This is generated when the object is created and is
+ *          needed for mako-finalize.
+ *        - contentLength: This is set either by the user when creating the
+ *          upload (and validated by the commit endpoint), or it is
+ *          calculated on commit.
+ *        - contentMD5: This is set either by the user when creating the
+ *          upload (and validated by the commit endpoint), or it is
+ *          calculated on commit.
+ *        - headers: This is set by the user when creating the upload.
+ *        - sharks: These are selected when the upload is created.
+ *
+ *
+ *  AUTHORIZATION:
+ *
+ *  Generally, MPU actions are authorized against the resource /:account/uploads
+ *  (for MPU creation) or /:account/uploads/[0-f]/:id (other MPU actions).
+ *  Subusers are not allowed to perform multipart uploads.
+ *
+ *
+ *  IMPLEMENTATION DETAILS:
+ *
+ *  The logic of this API is implemented as methods on the MultipartUpload
+ *  object defined in this file. When a multipart upload related request comes
+ *  in to muskie, a new MultipartUpload request is constructed, and sets up
+ *  some state the various handlers will need.
+ *
+ *  After an upload's creation, most of the state about the upload is stored in
+ *  the upload record. After validating inputs to a request, the first thing a
+ *  multipart upload API endpoint should do is call the method uploadState(),
+ *  which will load the upload record from Moray and allow the handlers to
+ *  fetch state from the record using the get() method, and modify the record
+ *  using the set() method.
+ *
+ *  Once the API handlers have completed the relevant logic based on the
+ *  upload's state, they each call a relevant method on the upload object
+ *  ({create,abort,commit,get}Upload()). These methods take care of saving
+ *  the upload record back to Moray, and perform any additional metadata
+ *  transformations as needed.
+ */
+
+
+///--- Globals
+
+var sprintf = util.format;
+var hasKey = jsprim.hasKey;
+
+// Regex of an upload id (which is just a uuid).
+var ID_REGEX = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
+var PART_NUM_REGEX = /^([0-9]|[1-9][0-9]{0,3})$/;
+
+/*
+ * Multipart upload parts are stored in the directory:
+ *   /:account/uploads/<prefix directory>/:id.
+ *
+ * The purpose of the prefix directory is to prevent us from hitting the
+ * max number of directory entries within the "uploads" folder. As such,
+ * we want to divide uploads roughly evenly into subdirectories.
+ * Because uuids are randomly generated, we expect that they would be uniformly
+ * distributed based on the first PREFIX_LENGTH characters of the upload id.
+ *
+ * For now, we use a PREFIX_LENGTH of 1, so /:account/uploads has a maximum
+ * of 16 directories, which allows for 16 million ongoing multipart uploads.
+ * If needed, we can bump this prefix length to allow for more.
+ */
+var PREFIX_LENGTH = 1;
+
+// Range of allowed part numbers is [0, 10000).
+var MIN_PART_NUM = 0;
+var MAX_PART_NUM = 9999;
+var MAX_NUM_PARTS = MAX_PART_NUM - MIN_PART_NUM + 1;
+
+// Upload states
+var MPU_S_CREATED = 'created';
+var MPU_S_FINALIZING = 'finalizing';
+var MPU_S_DONE = 'done';
+
+// Finalizing types
+var MPU_FT_COMMIT = 'commit';
+var MPU_FT_ABORT = 'abort';
+
+// These are the keys used to look up values in the MPU upload record.
+// (See MultipartUpload.get() and MultipartUpload.set()).
+var mdKeys = {
+    // the state of the upload
+    STATE: 'state',
+
+    // if state is FINALIZING, the finalizing type
+    TYPE: 'type',
+
+    // target object path
+    OBJECT_PATH: 'objectPath',
+
+    // the normalized target object path for Manta, which includes the owner
+    // uuid instead of the account name. It is the key used to insert/look up
+    // the target object path in Moray.
+    OBJECT_PATH_KEY: 'objectPathKey',
+
+    // path to the the upload directory (where parts are logically stored)
+    UPLOAD_PATH: 'uploadPath',
+
+    // headers specified for the target object when the MPU was created
+    HEADERS: 'headers',
+
+    // sharks selected for the target object; where parts are uploaded
+    SHARKS: 'sharks',
+
+    // for a committed object, the md5 sum of all part etags concatenated,
+    // in order (with no characters between them)
+    PARTS_MD5: 'partsMD5',
+
+    // the target object ID
+    OBJECT_ID: 'objectId'
+};
+
+function isValidUploadMdKey(key) {
+    var consts = Object.keys(mdKeys);
+
+    for (var i = 0; i < consts.length; i++) {
+        if (mdKeys[consts[i]] === key) {
+            return (true);
+        }
+    }
+
+    return (false);
+}
+
+
+
+///--- Helpers
+
+/*
+ * Creates an upload record in memory for the upload path.
+ * (e.g., /jhendricks/uploads/c/c46ac2b1-fcc3-4e12-8c46-c935808ed59f)
+ *
+ * To save the record in Moray, use MultipartUpload.persistUploadRecord().
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - opts: options blob that must have the following items:
+ *      - objectPath
+ *      - sharks
+ *      - headers
+ *  - cb: function that is passed an error and the metadata blob
+ */
+function createUploadRecord(upload, opts, cb) {
+    assert.object(opts);
+    assert.string(opts.objectPath);
+    assert.string(opts.objectPathKey);
+    assert.object(opts.sharks);
+    assert.object(opts.headers);
+    assert.string(upload.uploadPath);
+    assert.string(upload.id);
+    assert.func(cb);
+
+    var req = upload.req;
+
+    /*
+     * createMetadata assumes that the key for the metadata it should create
+     * is saved in req.key, which is true for most requests. In this case,
+     * we save the key stored in req.key (which corresponds to the path
+     * /:account/uploads, instead of the upload record key) and restore it
+     * after the metadata is created. This is a bit janky, but allows us to
+     * reuse existing code to create metadata for directories much more
+     * easily.
+     */
+    var savedKey = req.key;
+    assert.ok(upload.uploadMd.key);
+    req.key = upload.uploadMd.key;
+
+    common.createMetadata(req, 'directory', function (err, md) {
+        req.key = savedKey;
+
+        if (err) {
+            cb(err);
+        } else {
+            md._etag = null;
+            md.upload = {
+                id: upload.id,
+                state: MPU_S_CREATED,
+                type: null,  // used only for finalizing uploads
+                objectPath: opts.objectPath,
+                objectPathKey: opts.objectPathKey,
+                uploadPath: upload.uploadPath,
+                headers: opts.headers,
+                sharks: opts.sharks,
+                partsMD5: null, // used only for commits
+                objectId: libuuid.create()
+            };
+
+            cb(null, md);
+        }
+    });
+}
+
+/*
+ * Creates the metadata object in memory for an MPU finalizing record, for both
+ * commit and aborts.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - type: finalizing type
+ *  - md5: if a commit, the md5 sum of the object
+ */
+function createFinalizingRecord(upload, type, md5) {
+    assert.ok(type === MPU_FT_COMMIT || type === MPU_FT_ABORT);
+    if (type === MPU_FT_COMMIT) {
+        assert.string(md5);
+    }
+
+    var req = upload.req;
+
+    var md = {
+        uploadId: upload.id,
+        finalizingType: type,
+        owner: req.owner.account.uuid,
+        requestId: req.getId(),
+        objectPath: upload.get(mdKeys.OBJECT_PATH),
+        objectId: upload.get(mdKeys.OBJECT_ID),
+        md5: md5,
+
+        // This is critical for finalizing records, as it tells Moray we only
+        // want to insert the record if none already exists for the same key.
+        // If we didn't do this, we might clobber another running finalizing
+        // record update instead of failing.
+        _etag: null
+    };
+
+    return (md);
+}
+
+
+/*
+ * Creates the metdata for the target object record in memory.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - size: size of the object
+ *  - md5: md5 sum (calculated in mako-finalize)
+ *  - cb: function that is passed an error and the metadata blob
+ */
+
+function createTargetObjectRecord(upload, size, md5, cb) {
+    var req = upload.req;
+    var objPath = upload.get(mdKeys.OBJECT_PATH);
+
+    normalize(upload.req, objPath, function (err, objKey) {
+        if (err) {
+            cb(err);
+        } else {
+            //TODO: comment
+            var savedKey = req.key;
+            var savedHeaders = req.headers;
+
+            req.key = objKey;
+            req.headers = upload.get(mdKeys.HEADERS);
+            req.query.metadata = null;
+
+            common.createMetadata(req, 'object', function (err2, md) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    req.key = savedKey;
+                    req.headers = savedHeaders;
+
+                    // createMetadata does most of the work for us here, but
+                    // a few values need to be overwritten.
+                    md.objectId = upload.get(mdKeys.OBJECT_ID);
+                    md.contentLength = size;
+                    md.contentMD5 = md5;
+
+                    var ct = upload.get(mdKeys.HEADERS)['content-type'];
+                    if (ct) {
+                        md.contentType = ct;
+                    } else {
+                        md.contentType = 'application/octet-stream';
+                    }
+
+                    md.sharks = upload.get(mdKeys.SHARKS);
+
+                    cb(null, md);
+                }
+            });
+        }
+    });
+}
+
+
+/*
+ * Saves the upload record to moray with the given state and type.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - state: upload state
+ *  - type: if applicable, finalizing type
+ *  - cb: function
+ */
+function persistUploadRecord(upload, state, type, cb) {
+    assert.ok(state === MPU_S_CREATED || state === MPU_S_FINALIZING);
+    assert.func(cb);
+    if (state === MPU_S_CREATED) {
+        assert.ok(!type);
+        assert.ok(upload.uploadMd.toSave._etag === null);
+    } else {
+        assert.ok(type === MPU_FT_COMMIT || type === MPU_FT_ABORT);
+        assert.ok(upload.uploadMd.toSave._etag);
+    }
+    assert.ok(upload.uploadMd.toSave, 'no upload record to save');
+
+    var log = upload.req.log;
+
+    upload.set(mdKeys.STATE, state);
+    upload.set(mdKeys.TYPE, type);
+
+    upload.uploadMd.toSave.requestId = upload.req.getId();
+    upload.req.moray.putMetadata(upload.uploadMd.toSave, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+            log.debug({
+                uploadId: upload.id,
+                record: md
+            }, 'persistUploadRecord: done');
+            cb();
+        }
+    });
+}
+
+
+/*
+ * Loads the upload record, saves a copy of it, and creates a new
+ * copy that can be modified throughout the request.
+ */
+function loadUploadRecord(upload, cb) {
+    var record = upload.uploadMd;
+
+    var options = {
+        key: record.key,
+        requestId: upload.req.getId()
+    };
+
+    upload.req.moray.getMetadata(options, function (err, md, wrap) {
+        if (err) {
+            cb(err);
+        } else {
+            assert.ok(md);
+            assert.ok(md.upload, '\"upload\" not present in upload record md');
+
+            record.loaded = md;
+            record.toSave = jsprim.deepCopy(record.loaded);
+
+            assert.ok(wrap._etag);
+            record.toSave._etag = wrap._etag;
+
+            cb(null, record.loaded.upload);
+        }
+    });
+}
+
+/*
+ * Loads the finalizing record.
+ */
+function loadFinalizingMetadata(upload, cb) {
+    var record = upload.finalizingMd;
+
+    record.key = upload.constructKey();
+    var options = {
+        key: record.key,
+        requestId: upload.req.getId()
+    };
+
+    upload.req.moray.getFinalizingMetadata(options, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+            assert.ok(md);
+            record.loaded = md;
+            cb(null, record.loaded);
+        }
+    });
+}
+
+
+// Normalizes a path in Manta.
+function normalize(req, mPath, cb) {
+    var opts = {
+        account: req.owner.account,
+        path: mPath
+    };
+
+    libmanta.normalizeMantaPath(opts, function (err, p) {
+        if (err) {
+            req.log.debug({
+                url: path,
+                err: err
+            }, 'failed to normalize URL');
+            cb(err);
+        } else {
+            cb(null, p);
+        }
+    });
+}
+
+
+/*
+ * Given an upload ID, returns the prefix to use for the parent directory
+ * of the upload directory. For now, this is the just the first character of
+ * the upload uuid, but we may want to use more characters later to allow for
+ * more simulataneous uploads.
+ *
+ * For example, for the input id '0bb83e47-32df-4833-a6fd-94d77e8c7dd3' and a
+ * prefix length of 1, this function will return '0'.
+ */
+function idToPrefix(id) {
+    assert.string(id);
+    assert.ok(id.match(ID_REGEX), 'upload ID does not match uuid regex');
+
+    return (id.substring(0, PREFIX_LENGTH));
+}
+
+
+///--- Routes
+
+/*
+ * Common handler used by all API calls on an existing multipart upload
+ * that loads the upload record, which is used in subsequent handlers,
+ * and stores information about the upload at req.upload.
+ */
+function loadUpload(req, res, next) {
+    var log = req.log;
+
+    /*
+     * Multipart upload is not supported for subusers. For now, if the
+     * caller of this operation is a subuser of an account, we disallow
+     * any use of the multipart upload API.
+     */
+    if (req.caller.user) {
+        next(new AuthorizationError(req.caller.user.login, req.url));
+        return;
+    }
+
+    var id = req.params.id;
+    if (!id.match(ID_REGEX)) {
+        next(new ResourceNotFoundError('upload ID ' + id));
+        return;
+    }
+
+    req.upload = new MultipartUpload(req, id);
+    loadUploadRecord(req.upload, function (err, upload) {
+        if (err) {
+            next(err);
+        } else {
+            log.debug(sprintf('loaded upload record for %s: state %s',
+                req.upload.id, upload.state));
+            next();
+        }
+    });
+}
+
+
+/*
+ * This handler sets up the authContext that is eventually passed to mahi to
+ * authorize the user to perform an action on an existing multipart upload.
+ * It is the analog to "storageContext" for storage-based actions, or
+ * "jobContext" in the jobs API.
+ */
+function uploadContext(req, res, next) {
+    var log = req.log;
+    log.debug('uploadContext: started');
+
+    var opts = {
+        // keys like /<account uuid>/uploads/[0-f]/<upload id>
+        key: req.key.split('/').slice(0, 4).join('/'),
+        requestId: req.getId()
+    };
+
+    common.loadMetadata(req, opts, function (md_err, md) {
+        if (md_err) {
+            next(md_err);
+            return;
+        }
+        var o = req.upload.uploadOwner();
+        req.mahi.getAccountById(o, function (auth_err, owner) {
+            if (auth_err) {
+                next(auth_err);
+                return;
+            }
+
+            if (owner.account.uuid !== req.owner.account.uuid) {
+                next(new ResourceNotFoundError(req.path()));
+                return;
+            }
+
+            req.authContext.resource = {
+                owner: owner,
+                key: md.key || req.key,
+                roles: md.roles || []
+            };
+
+            log.debug('uploadContext: completed');
+            next();
+        });
+    });
+}
+
+
+///--- API
+
+/*
+ * Constructor for the MultipartUpload object, which is instantiated at
+ * the beginning of each multipart upload related request and attached to the
+ * request object at `req.upload`.
+ *
+ * The inputs to the constructor are:
+ *      - id, the upload uuid
+ *      - req, the request object for this multipart upload related request
+ *
+ *
+ * The structure of this object is as follows:
+ *
+ * {
+ *    id,                     // upload uuid
+ *    req,                    // pointer to the request this upload is for
+ *    uploadPath,             // upload path
+ *
+ *
+ *    // Private fields used to share state across a specific upload request.
+ *    // They aren't always used or set.
+ *    _headers,
+ *    _size,
+ *    _copies,
+ *    _md5,
+ *
+ *
+ *    // These objects represent some of the relevant metadata for the upload.
+ *
+ *    // When an upload or finalizing record is first loaded during a request,
+ *    // it is saved on the MultipartUpload object at
+ *    // `{upload,finalizing}Md.loaded`. Changes to metadata are made in a copy
+ *    // of the metadata that is saved at {upload,finalizing}Md.toSave.
+ *
+ *    // Additionally, each object contains the moray bucket and the key
+ *    // for the metadata record it represents.
+ *
+ *    uploadMd {          // upload record metadata object
+ *        key,            // normalized uploadPath
+ *        bucket,         // bucket for upload records (normal manta records)
+ *        loaded {        // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    },
+ *
+ *    finalizingMd {      // finalizing record metadata object
+ *        key,            // normalized objectPath
+ *        bucket,         // bucket for finalizing records
+ *        loaded,         // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    }
+ * }
+ *
+ */
+function MultipartUpload(req, id) {
+    var self = this;
+    self.id = id;
+    self.req = req;
+    self.uploadPath = '/' + req.owner.account.login + '/uploads/' +
+        idToPrefix(id) + '/' + id;
+
+    self.mpuHeaders = null;
+    self.mpuSize = null;
+    self.mpuCopies = null;
+    self.mpuContentMD5 = null;
+    self.mpuPartsMD5 = null;
+    self.mpuObjectPathKey = null;
+
+    self.uploadMd = {
+        key: null,
+        bucket: 'manta',
+        loaded: null,
+        toSave: null
+    };
+
+    normalize(req, self.uploadPath, function (err, p) {
+        if (err) {
+            throw (new InvalidPathError(self.uploadPath));
+        } else {
+            self.uploadMd.key = p;
+        }
+    });
+
+    self.finalizingMd = {
+        key: null,
+        bucket: 'manta_uploads',
+        loaded: null,
+        toSave: null
+    };
+
+    return (self);
+}
+
+
+///--- Create
+
+/*
+ * Creates the multipart upload by creating the upload record and inserting
+ * it into Moray.
+ *
+ * Parameters:
+ *  - opts: options blob that expects:
+ *      - objectPath
+ *      - sharks: array of shark objects returned from the picker
+ *      - headers: user-specified headers object (or an empty object)
+ */
+MultipartUpload.prototype.createUpload = function createUpload(opts, cb) {
+    assert.func(cb);
+    assert.string(opts.objectPath);
+    assert.string(opts.objectPathKey);
+    assert.ok(opts.sharks);
+    assert.object(opts.headers);
+
+    var self = this;
+
+    createUploadRecord(self, opts, function (err, uploadMd) {
+        if (err) {
+            cb(err);
+        } else {
+            self.uploadMd.toSave = uploadMd;
+            persistUploadRecord(self, MPU_S_CREATED, null, function (err2) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    cb(null, self.uploadPath);
+                }
+            });
+        }
+    });
+};
+
+
+
+
+/*
+ * Aborts an upload.
+ *
+ * First validates that no commit record exists for the upload, then inserts
+ * an abort record for the upload on the object shard.
+ */
+MultipartUpload.prototype.abortUpload = function abortUpload(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    self.finalizingRecordExists(function (err, exists, upload) {
+        if (err) {
+            cb(err);
+        } else if (exists) {
+            // This is only an error if the record isn't an abort record.
+            var type = self.finalizingMd.loaded.finalizingType;
+            if (type === MPU_FT_ABORT) {
+                log.debug('abort record exists for upload ' + self.id);
+                cb();
+            } else {
+                cb(new MultipartUploadInvalidArgumentError(upload.id,
+                    'already aborted'));
+            }
+
+        } else {
+            var md = createFinalizingRecord(self, MPU_FT_ABORT, null);
+            var record = self.finalizingMd;
+            record.toSave = md;
+
+            self.req.moray.putFinalizingMetadata({
+                key: record.key,
+                md: record.toSave
+            },
+            function (err2) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    cb();
+                }
+            });
+        }
+    });
+};
+
+
+/*
+ * Commits an upload.
+ *
+ * First checks for the existence of a finalizing record, then saves the
+ * upload record as finalizing, and atomically inserts a commit record
+ * and object record on the object's shard.
+ */
+MultipartUpload.prototype.commitUpload =
+function commitUpload(partsMD5, size, md5, cb) {
+    assert.string(partsMD5);
+    assert.number(size);
+    assert.string(md5);
+    assert.func(cb);
+
+    var log = this.req.log;
+    var self = this;
+
+    self.finalizingRecordExists(function (err, exists, upload) {
+        if (err) {
+            cb(err);
+        } else if (exists) {
+            // This is valid only for a commit record with matching parts.
+            var type = self.finalizingMd.loaded.finalizingType;
+            if (type === MPU_FT_ABORT) {
+                cb(new MultipartUploadStateError(upload.id, 'already aborted'));
+            } else {
+                if (self.get(mdKeys.PARTS_MD5) !== partsMD5) {
+                    cb(new MultipartUploadStateError(self.id,
+                        'already committed with a different part set'));
+                } else {
+                    log.debug('valid commit record already exists for upload ' +
+                        self.id);
+                    cb();
+                }
+            }
+        } else {
+            createTargetObjectRecord(self, size, md5,
+            function (err2, objectMd) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    var finalizingMd = createFinalizingRecord(self,
+                        MPU_FT_COMMIT, md5);
+                    var batch = [ {
+                        bucket: self.finalizingMd.bucket,
+                        key: self.finalizingMd.key,
+                        value: finalizingMd,
+                        operation: 'put',
+                        opts: {
+                            req_id: self.req.getId(),
+                            etag: null
+                        }
+                    }, {
+                        bucket: self.uploadMd.bucket,
+                        key: self.get(mdKeys.OBJECT_PATH_KEY),
+                        value: objectMd,
+                        operation: 'put'
+                    } ];
+                    var opts = {
+                        requestId: self.req.getId(),
+                        requests: batch
+                    };
+
+                    self.req.moray.commitMPU(opts, function (err3, meta) {
+                        if (err3) {
+                            log.error('error batching data: ' + err3);
+                            cb(err3);
+                        } else {
+                            log.debug('batch successful');
+                            cb();
+                        }
+                    });
+                }
+            });
+        }
+    });
+};
+
+//--- Get
+/*
+ * Returns a object representation of the upload that can be serialized as JSON
+ * and sent to the client.
+ */
+MultipartUpload.prototype.getUpload = function getUpload(cb) {
+    var self = this;
+
+    var upload = {
+        id: self.id,
+        state: self.get(mdKeys.STATE),
+        uploadPath: self.get(mdKeys.UPLOAD_PATH),
+        targetObject: self.get(mdKeys.OBJECT_PATH),
+        headers: self.get(mdKeys.HEADERS),
+        numCopies: self.numSharks()
+    };
+
+    if (upload.state === MPU_S_CREATED) {
+        setImmediate(cb, null, upload);
+    } else {
+        assert.ok(upload.state === MPU_S_FINALIZING);
+        self.finalizingRecordExists(function (err, exists, fr) {
+            if (err) {
+                cb(err, null);
+            } else {
+                if (exists) {
+                    upload.state = MPU_S_DONE;
+                    delete upload.uploadPath;
+
+                    if (fr.finalizingType === MPU_FT_COMMIT) {
+                        upload.partsMD5Summary = self.get(mdKeys.PARTS_MD5);
+                        upload.result = 'committed';
+                    } else {
+                        upload.result = 'aborted';
+                    }
+                } else {
+                    // This means the upload has started to be finalized, but
+                    // the finalizing record hasn't made it into Moray yet,
+                    // either because another request to finalize the upload is
+                    // processing, or a previous one failed.
+                    upload.type = self.get(mdKeys.TYPE);
+                }
+
+                cb(null, upload);
+            }
+        });
+    }
+};
+
+
+///--- Common methods for API endpoints
+
+/*
+ * Attempts to load the upload's finalizing record, and if it exists,
+ * passes the callback the record. This is useful for both committing
+ * and aborting uploads.
+ */
+MultipartUpload.prototype.finalizingRecordExists =
+function finalizingRecordExists(cb) {
+    loadFinalizingMetadata(this, function (err, upload) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                cb(null, false);
+            } else {
+                cb(err);
+            }
+        } else {
+            cb(null, true, upload);
+        }
+    });
+};
+
+
+/*
+ * Saves the upload record with state set to FINALIZING.
+ *
+ * Parameters:
+ *  - type: finalizing type
+ *  - parts: if a commit, array of etags representing the parts
+ *  - cb: function
+ */
+MultipartUpload.prototype.finalizeUploadRecord =
+function finalizeUploadRecord(type, md5, cb) {
+    assert.ok(type === MPU_FT_COMMIT || type === MPU_FT_ABORT);
+    assert.ok(this.uploadMd.loaded, 'upload record not loaded');
+    assert.ok(this.uploadMd.toSave._etag, 'no etag on upload record');
+
+    this.set(mdKeys.PARTS_MD5, md5);
+    persistUploadRecord(this, MPU_S_FINALIZING, type, cb);
+};
+
+
+/*
+ * Used by API handlers to set an item in the upload record.
+ * The input key should be one of the keys specifeid in mdKeys.
+ */
+MultipartUpload.prototype.set = function set(k, v) {
+    assert.ok(this.uploadMd.toSave);
+    assert.ok(isValidUploadMdKey(k));
+
+    this.uploadMd.toSave.upload[k] = v;
+};
+
+
+/*
+ * Looks up a value in the loaded upload record.
+ */
+MultipartUpload.prototype.get = function get(k) {
+    assert.ok(this.uploadMd.loaded);
+    assert.ok(isValidUploadMdKey(k));
+
+    return (this.uploadMd.loaded.upload[k]);
+};
+
+
+/*
+ * Returns the size of the object if specifed on create, or a default value.
+ */
+MultipartUpload.prototype.uploadSize = function uploadSize() {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    var size;
+    if (hasKey(u.headers, 'content-length')) {
+        size = u.headers['content-length'];
+    } else {
+        size = obj.DEF_MAX_LEN;
+    }
+    assert.number(size);
+    assert.ok(size >= 0);
+
+    return (size);
+};
+
+
+/*
+ * Verifies that if a size was specified on create, the input expected value
+ * matches this size.
+ */
+MultipartUpload.prototype.checkSize = function checkSize(expected, cb) {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    if (!u.headers['content-length']) {
+        cb(true);
+    } else {
+        var size = parseInt(u.headers['content-length'], 10);
+        assert.ok(size >= 0);
+        if (size !== expected) {
+            cb(false, size);
+        } else {
+            cb(true);
+        }
+    }
+};
+
+/*
+ * Verifies that if an md5 was specified on create, the input expected value
+ * matches this md5.
+ */
+MultipartUpload.prototype.checkMD5 = function checkMD5(expected, cb) {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    var md5 = u.headers['content-md5'];
+
+    if (!md5) {
+        cb(true);
+    } else {
+        if (md5 !== expected) {
+            cb(false, md5);
+        } else {
+            cb(true);
+        }
+    }
+};
+
+
+/*
+ * Returns the number of sharks selected for this upload on create.
+ */
+MultipartUpload.prototype.numSharks = function numSharks() {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+    assert.arrayOfObject(u.sharks);
+
+    return (u.sharks.length);
+};
+
+
+/*
+ * Used to create the key for the batch request to moray on commit.
+ * The key is of the form: <upload id>:<object path>
+ */
+MultipartUpload.prototype.constructKey = function constructKey() {
+    var o = this.get(mdKeys.OBJECT_PATH_KEY);
+    assert.ok(o, 'objectPathKey not saved in upload');
+
+    var key = this.id + ':' + o;
+    return (key);
+};
+
+
+// Returns the key for the upload path (for use in Moray).
+MultipartUpload.prototype.uploadPathKey = function uploadPathKey() {
+    assert.ok(this.uploadMd);
+    var k = this.uploadMd.key;
+    assert.ok(k);
+    return (k);
+};
+
+
+// Returns the owner of the upload.
+MultipartUpload.prototype.uploadOwner = function uploadOwner() {
+    assert.ok(this.uploadMd.loaded, 'upload record not loaded');
+    assert.ok(this.uploadMd.loaded.owner, 'no owner found in upload record');
+    assert.string(this.uploadMd.loaded.owner, 'owner is not a string');
+
+    return (this.uploadMd.loaded.owner);
+};
+
+
+///--- Exports
+
+module.exports = {
+
+    ID_REGEX: ID_REGEX,
+    PART_NUM_REGEX: PART_NUM_REGEX,
+    MIN_PART_NUM: MIN_PART_NUM,
+    MAX_PART_NUM: MAX_PART_NUM,
+    MAX_NUM_PARTS: MAX_NUM_PARTS,
+    MPU_S_CREATED: MPU_S_CREATED,
+    MPU_S_FINALIZING: MPU_S_FINALIZING,
+    MPU_FT_ABORT: MPU_FT_ABORT,
+    MPU_FT_COMMIT: MPU_FT_COMMIT,
+
+    mdKeys: mdKeys,
+
+    MultipartUpload: MultipartUpload,
+
+    // Common handlers for API endpoints
+    loadUpload: loadUpload,
+    uploadContext: uploadContext
+};
diff --git a/lib/uploads/create.js b/lib/uploads/create.js
new file mode 100644
index 0000000..25c1467
--- /dev/null
+++ b/lib/uploads/create.js
@@ -0,0 +1,349 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libmanta = require('libmanta');
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+var verror = require('verror');
+
+var auth = require('../auth');
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+require('../errors');
+
+
+///--- Globals
+
+var hasKey = jsprim.hasKey;
+var sprintf = util.format;
+
+
+///--- Helpers
+
+/*
+ * Selects the sharks for the upload through the picker.choose interface.
+ *
+ * The number of sharks needed and the size of the sharks are specified by
+ * the durability-level and the content-length headers, respectively, or
+ * set to a default value.
+ */
+function chooseSharks(req, size, copies, cb) {
+    assert.object(req, 'req');
+    assert.number(size, 'size');
+    assert.number(copies, 'copies');
+    assert.func(cb, 'callback');
+
+    var log = req.log;
+
+    if (size === 0) {
+        setImmediate(cb, null, {});
+    } else {
+        var opts = {
+            requestId: req.getId(),
+            replicas: copies,
+            size: size
+        };
+        req.picker.choose(opts, function (err, sharks) {
+            if (err) {
+                cb(err);
+            } else {
+                log.info('upload: sharks chosen');
+                cb(null, sharks[0]);
+            }
+        });
+    }
+}
+
+
+// Given the key for the request,
+function uploadRoot(key) {
+
+}
+
+///--- API
+
+
+/*
+ * This sets up the req.authContext object, which the authorization code
+ * will use to authorize the user. The resource the caller is trying to
+ * access for upload creation is the top-level uploads directory.
+ *
+ * We also check at this point if the caller is a subuser, which is not
+ * allowed for MPU at this time.
+ */
+function uploadContextRoot(req, res, next) {
+    // Disallow subusers from creating uploads
+    if (req.caller.user) {
+        next(new AuthorizationError(req.caller.user.login, req.url));
+        return;
+    }
+
+    var opts = {
+        // Derive the top-level uploads directory (/<account uuid>/uploads).
+        key: req.key.split('/').slice(0, 3).join('/'),
+        requestId: req.getId()
+    };
+
+    common.loadMetadata(req, opts, function (err, md) {
+        if (err) {
+            next(err);
+            return;
+        }
+
+        var id = libuuid.create();
+        req.upload = new uploadsCommon.MultipartUpload(req, id);
+
+        req.authContext.resource = {
+            owner: req.owner,
+            key: md.key || req.key,
+            roles: md.roles || []
+        };
+
+        next();
+    });
+}
+
+
+// Instantiates the uploads object.
+function setupUpload(req, res, next) {
+    var id = libuuid.create();
+    req.upload = new uploadsCommon.MultipartUpload(req, id);
+
+    next();
+}
+
+/*
+ * Validates that all parameters needed for creating an upload exist, including:
+ *   - objectPath (the final path the uploaded object resides)
+ *
+ * Also validates optional headers, if they exist:
+ *   - durability-level
+ *   - content-length
+ *   - content-md5
+ *
+ * This handler is expected to set the following state on the upload object:
+ * - objectPath
+ * - size
+ * - copies
+ * - headers
+ * - contentMD5
+ * - contentType
+ */
+function validateParams(req, res, next) {
+    var log = req.log;
+
+    if (!req.body.objectPath || (typeof (req.body.objectPath) !== 'string')) {
+        next(new MultipartUploadInvalidArgumentError('a valid "objectPath" ' +
+            'is required'));
+    } else {
+        var opts = {
+            account: req.owner.account,
+            path: req.body.objectPath
+        };
+        libmanta.normalizeMantaPath(opts, function (err, p) {
+            if (err) {
+                log.debug({
+                    url: path,
+                    err: err
+                }, 'failed to normalize URL');
+
+                next(err);
+            } else {
+                var inputHeaders, headers, size, copies;
+
+                inputHeaders = req.body.headers || {};
+                var maxObjectCopies = req.config.maxObjectCopies ||
+                    obj.DEF_MAX_COPIES;
+
+                headers = {};
+                // TODO check size of headers here?
+                Object.keys(inputHeaders).forEach(function (k) {
+                    headers[k.toLowerCase()] = inputHeaders[k];
+                });
+
+                // Reject conditional headers.
+                if (hasKey(headers, 'if-match') ||
+                    hasKey(headers, 'if-none-match') ||
+                    hasKey(headers, 'if-modified-since') ||
+                    hasKey(headers, 'if-unmodified-since')) {
+                    next(new MultipartUploadCreateError('conditional headers ' +
+                        'are not supported for multipart upload objects'));
+                    return;
+                }
+
+                // Supported headers are: content-length, {x-}durability-level,
+                // and content-md5. We set these values to defaults otherwise.
+                if (hasKey(headers, 'content-length')) {
+                    size = headers['content-length'];
+                    if (typeof (size) === 'number') {
+                        if (size < 0) {
+                            var msg = '"content-length" must be >= 0';
+                            next(new MultipartUploadCreateError(msg));
+                            return;
+                        }
+                    } else {
+                        next(new MultipartUploadCreateError('"content-length"' +
+                        ' must be a number'));
+                        return;
+                    }
+                } else {
+                    size = obj.DEF_MAX_LEN;
+                }
+
+                if (hasKey(headers, 'durability-level')) {
+                    copies = headers['durability-level'];
+                } else if (hasKey(headers, 'x-durability-level')) {
+                    copies = headers['x-durability-level'];
+                } else {
+                    copies = obj.DEF_NUM_COPIES;
+                }
+
+                if (typeof (copies) !== 'number' ||
+                    copies < obj.DEF_MIN_COPIES || copies > maxObjectCopies) {
+                    next(new InvalidDurabilityLevelError(obj.DEF_MIN_COPIES,
+                        maxObjectCopies));
+                    return;
+                }
+
+                assert.string(p);
+                assert.object(headers);
+                assert.number(size);
+                assert.number(copies);
+
+                req.upload.mpuObjectPathKey = p;
+                req.upload.mpuHeaders = headers;
+                req.upload.mpuSize = size;
+                req.upload.mpuCopies = copies;
+
+                log.debug({
+                    objectPath: req.body.objectPath,
+                    headers: headers,
+                    size: size,
+                    copies: copies
+                }, 'create-mpu: requested');
+
+                next();
+            }
+        });
+    }
+}
+
+
+/*
+ * Checks if the parent of the upload directory exists, and if it doesn't,
+ * creates the directory.
+ *
+ * For example,if the prefix length for an upload ID is 1, and the id is abcdef,
+ * the prefix directory is of the form: /account/uploads/a.
+ */
+function ensurePrefixDir(req, res, next) {
+    var log = req.log;
+    var requestId = req.getId();
+
+    var parentOpts = {
+        key: path.dirname(req.upload.uploadPathKey()),
+        requestId: requestId
+    };
+
+    req.moray.getMetadata(parentOpts, function (err, md, _) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                // If the directory doesn't exist yet, create it.
+                parentOpts.dirname = path.dirname(parentOpts.key);
+                parentOpts.mtime = Date.now();
+                parentOpts.owner = req.owner.account.uuid;
+                parentOpts.requestId = req.getId();
+                parentOpts.type = 'directory';
+
+                req.moray.putMetadata(parentOpts, function (err2) {
+                    if (err2) {
+                        next(err2);
+                    } else {
+                        log.debug('prefix directory \"' + parentOpts.key +
+                            '\" created');
+                        next();
+                    }
+                });
+            } else {
+                next(err);
+            }
+        } else {
+            next();
+        }
+    });
+}
+
+
+/*
+ * Actually create the upload in the sense that the upload record exists.
+ * To do so, we must first choose the sharks that the final object will
+ * live on and save the metadata for the upload record.
+ */
+function createUpload(req, res, next) {
+    var log = req.log;
+
+    var s = req.upload.mpuSize;
+    var c = req.upload.mpuCopies;
+
+    chooseSharks(req, s, c, function (err, sharks) {
+        if (err) {
+            next(err);
+        } else {
+            var opts = {
+                objectPath: req.body.objectPath,
+                objectPathKey: req.upload.mpuObjectPathKey,
+                sharks: sharks,
+                headers: req.upload.mpuHeaders
+            };
+            req.upload.createUpload(opts, function (err2, partsDirectory) {
+                    if (err2) {
+                        next(err2);
+                    } else {
+                        log.debug({
+                            id: req.upload.id,
+                            sharks: sharks
+                        }, 'create-mpu: competed');
+
+                        res.send(201, {
+                            id: req.upload.id,
+                            partsDirectory: partsDirectory
+                        });
+                        next();
+                    }
+            });
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    createHandler: function createHandler() {
+        var chain = [
+            uploadContextRoot,
+            auth.authorizationHandler(),
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 100000
+            }),
+            validateParams,
+            ensurePrefixDir,
+            createUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/get.js b/lib/uploads/get.js
new file mode 100644
index 0000000..5f01b4f
--- /dev/null
+++ b/lib/uploads/get.js
@@ -0,0 +1,51 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+
+///--- API
+
+
+function getUpload(req, res, next) {
+    var log = req.log;
+
+    log.debug({
+        id: req.upload.id
+    }, 'get-mpu: requested');
+
+    req.upload.getUpload(function (err, upload) {
+        if (err) {
+            next(err);
+        } else {
+            log.debug({
+                id: req.upload.id,
+                upload: upload
+            }, 'get-mpu: completed');
+
+            res.send(200, upload);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+
+    getHandler: function getHandler() {
+        var chain = [
+            uploadsCommon.loadUpload,
+            getUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/index.js b/lib/uploads/index.js
new file mode 100644
index 0000000..da67ab5
--- /dev/null
+++ b/lib/uploads/index.js
@@ -0,0 +1,29 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+///--- Helpers
+
+function reExport(obj) {
+    Object.keys(obj || {}).forEach(function (k) {
+        module.exports[k] = obj[k];
+    });
+}
+
+
+
+///--- Exports
+
+module.exports = {};
+reExport(require('./create'));
+reExport(require('./upload'));
+reExport(require('./commit'));
+reExport(require('./abort'));
+reExport(require('./get'));
+reExport(require('./redirect'));
diff --git a/lib/uploads/redirect.js b/lib/uploads/redirect.js
new file mode 100644
index 0000000..b36b290
--- /dev/null
+++ b/lib/uploads/redirect.js
@@ -0,0 +1,106 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+var assert = require('assert-plus');
+var path = require('path');
+var restify = require('restify');
+
+
+///--- Helpers
+
+
+// Verfies the part num (as an integer) is within the range allowed.
+function partNumInRange(pn) {
+    assert.number(pn);
+    return ((pn >= uploadsCommon.MIN_PART_NUM) &&
+            (pn <= uploadsCommon.MAX_PART_NUM));
+}
+
+function partNumDefined(pn) {
+    return (pn !== undefined && pn !== null);
+}
+
+///--- API
+
+/*
+ * Gets the ID from the request URL, which is either of the form:
+ *      /<account>/uploads/<id>
+ * or
+ *      /<account>/uploads/<id>/<partNum>
+ */
+function parseId(req, res, next) {
+    var log = req.log;
+
+    log.debug({
+        id: req.params.id,
+        url: req.url,
+        method: req.method
+    }, 'redirect: requested');
+
+    var pn = req.params.partNum;
+
+    if (!partNumDefined(pn)) {
+        // Path of the form /:account/uploads/:id.
+        req.params.id = path.basename(req.url);
+    } else if (uploadsCommon.PART_NUM_REGEX.test(pn)) {
+        // Path of the form /:account/uploads/:id/:partNum
+        req.params.id = path.basename(path.dirname(req.url));
+    } else {
+        next(new ResourceNotFoundError('part num ' + pn));
+        return;
+    }
+
+    next();
+}
+
+
+/*
+ * Redirects the request by looking up the upload path using the upload ID.
+ */
+function redirect(req, res, next) {
+    var log = req.log;
+
+    // We want to get the upload path from the loaded metadata of the upload,
+    // as opposed to what's on the object itself.
+    var url = req.upload.get(uploadsCommon.mdKeys.UPLOAD_PATH);
+
+    var pn = req.params.partNum;
+    if (partNumDefined(pn)) {
+        url += '/' + pn;
+    }
+
+    log.debug({
+        id: req.params.id,
+        url: req.url,
+        method: req.method,
+        redirectLocation: url
+    }, 'redirect: completed');
+
+    res.setHeader('Location', url);
+    res.send(301);
+    next();
+}
+
+
+///--- Exports
+
+module.exports = {
+    redirectHandler: function redirectHandler() {
+        var chain = [
+            parseId,
+            uploadsCommon.loadUpload,
+            redirect
+        ];
+        return (chain);
+    }
+
+};
diff --git a/lib/uploads/upload.js b/lib/uploads/upload.js
new file mode 100644
index 0000000..edc9e87
--- /dev/null
+++ b/lib/uploads/upload.js
@@ -0,0 +1,107 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var vasync = require('vasync');
+
+var auth = require('../auth');
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+require('../errors');
+
+//TODO: enforce max individual part size based on object size
+
+///--- API
+
+/*
+ * Does some basic validation on the part before proceeding to the normal PUT
+ * path, including:
+ *   - ensuring the partNum is valid
+ *   - ensuring the upload hasn't been finalized yet
+ *   - ensuring client isn't trying to change the number of copies of the object
+ */
+function validate(req, res, next) {
+    var log = req.log;
+    var id = req.upload.id;
+
+    var partNum = req.params.partNum;
+    var valid = uploadsCommon.PART_NUM_REGEX.test(partNum);
+
+    if (!valid) {
+        next(new MultipartUploadInvalidArgumentError(id,
+            partNum + ' is not valid'));
+    } else {
+        var state = req.upload.get(uploadsCommon.mdKeys.STATE);
+
+        if (state !== uploadsCommon.MPU_S_CREATED) {
+            next(new MultipartUploadStateError(id, 'already finalized'));
+        } else {
+            log.debug({
+                uploadId: id,
+                partNum: partNum,
+                headers: req.headers
+            }, 'upload-part: requested');
+
+            next();
+        }
+    }
+}
+
+
+/*
+ * The PUT handling code relies on some state being set up on the request
+ * object that is done by handlers not used for uploading parts.
+ *
+ * This handler ensures that the state needed for the PUT handling code
+ * is available so that the PUT handling code we do use for uploading
+ * parts works seamlessly.
+ */
+function setupPutState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+
+    // Ensure zero-byte objects aren't streamed to mako.
+    if (req.upload.uploadSize() === 0) {
+        log.debug('zero-byte part');
+        req._zero = true;
+    }
+
+    // Ensure that the PUT handling code can find the correct sharks to use.
+    req._sharks = [upload.get(uploadsCommon.mdKeys.SHARKS)];
+
+    // Fake a durability-level header that matches the header
+    // specified on upload creation.
+    req.headers['durability-level'] = req.upload.numSharks();
+
+    next();
+}
+
+
+///--- Exports
+
+module.exports = {
+    uploadPartHandler: function uploadPartHandler() {
+        var chain = [
+            uploadsCommon.loadUpload,
+            uploadsCommon.uploadContext,
+            auth.authorizationHandler(),
+            validate,
+            setupPutState,
+
+            // Piggybacking on existing PUT code.
+            obj.putPartHandler()
+        ];
+
+        return (chain);
+    }
+};
diff --git a/package.json b/package.json
index a743a67..bb9eb6b 100644
--- a/package.json
+++ b/package.json
@@ -19,7 +19,7 @@
         "deep-equal": "0.0.0",
         "dtrace-provider": "0.2.8",
         "http-signature": "1.1.0",
-	"jsprim": "^1.3.1",
+        "jsprim": "^1.3.1",
         "kang": "1.1.0",
         "keep-alive-agent": "0.0.1",
         "keyapi": "git+ssh://git@github.com:joyent/keyapi.git#c30dd2710ad2175095dc0e96479686fa774b8063",
@@ -34,13 +34,13 @@
         "once": "1.3.0",
         "restify": "2.6.3",
         "vasync": "1.4.3",
-        "verror": "^1.7.0",
+        "verror": "^1.9.0",
         "watershed": "0.3.0",
         "xtend": "2.1.1"
     },
     "devDependencies": {
         "smartdc": "git+ssh://git@github.com:joyent/node-smartdc.git#v7.3",
-        "manta": "1.4.5",
+        "manta": "4.3.0",
         "nodeunit": "0.8.6",
         "node-uuid": "1.4.1"
     },
diff --git a/sapi_manifests/muskie/template b/sapi_manifests/muskie/template
index f40f604..fb155f5 100644
--- a/sapi_manifests/muskie/template
+++ b/sapi_manifests/muskie/template
@@ -152,6 +152,10 @@
     "maximum": 2000
   },
 
+  {{#MPU_ENABLE}}
+  "enableMPU": true,
+  {{/MPU_ENABLE}}
+
   "medusa": {
     "moray": {
       "srvDomain": "{{ELECTRIC_MORAY}}",
@@ -195,4 +199,5 @@
       },
       "clientTimeout": 120000
   }
+
 }
diff --git a/test/dir.test.js b/test/dir.test.js
index 6e50190..6bb5455 100644
--- a/test/dir.test.js
+++ b/test/dir.test.js
@@ -199,11 +199,11 @@ test('ls top', function (t) {
             t.ok(http_res);
             t.checkResponse(http_res, 200);
             t.equal(0, objs.length);
-            t.equal(4, dirs.length);
+            t.equal(5, dirs.length);
             var names = dirs.map(function (d) {
                 return (d.name);
             }).sort();
-            t.deepEqual(['jobs', 'public', 'reports', 'stor'],
+            t.deepEqual(['jobs', 'public', 'reports', 'stor', 'uploads'],
                         names);
             t.end();
         });
@@ -238,11 +238,11 @@ test('ls top with marker', function (t) {
             t.ok(http_res);
             t.checkResponse(http_res, 200);
             t.equal(0, objs.length);
-            t.equal(2, dirs.length);
+            t.equal(3, dirs.length);
             var names = dirs.map(function (d) {
                 return (d.name);
             }).sort();
-            t.deepEqual(['reports', 'stor'], names);
+            t.deepEqual(['reports', 'stor', 'uploads'], names);
             t.end();
         });
     });
diff --git a/test/helper.js b/test/helper.js
index 1a5f8a9..f843843 100644
--- a/test/helper.js
+++ b/test/helper.js
@@ -68,6 +68,7 @@ function createClient() {
             user: process.env.MANTA_USER || 'admin'
         }),
         rejectUnauthorized: false,
+        subuser: process.env.MANTA_SUBUSER,
         url: process.env.MANTA_URL || 'http://localhost:8080',
         user: process.env.MANTA_USER || 'admin'
     });
diff --git a/test/mpu/abort.test.js b/test/mpu/abort.test.js
new file mode 100644
index 0000000..e4d0f41
--- /dev/null
+++ b/test/mpu/abort.test.js
@@ -0,0 +1,230 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uuid = require('node-uuid');
+var path = require('path');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var computePartsMD5 = helper.computePartsMD5;
+var createPartOptions = helper.createPartOptions;
+var createUpload = helper.createUpload;
+var sanityCheckUpload = helper.sanityCheckUpload;
+var writeObject = helper.writeObject;
+
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+    self.path = self.dir + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+
+test('abort upload', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.abortUpload(o.id, opts, function (err2) {
+            if (ifErr(t, err2, 'aborted upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.getUpload(o.id, opts, function (err3, upload) {
+                if (ifErr(t, err3, 'got upload')) {
+                    t.end();
+                    return;
+                }
+
+                sanityCheckUpload(t, o, upload);
+                t.deepEqual(upload.headers, {});
+                t.equal(upload.state, 'done');
+                t.equal(upload.result, 'aborted');
+                t.end();
+            });
+        });
+    });
+});
+
+test('abort upload: upload already aborted', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+        checkCreateResponse(t, o);
+
+        var opts = {
+            account: a
+        };
+
+        self.client.abortUpload(o.id, opts, function (err2) {
+            if (ifErr(t, err2, 'aborted upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.abortUpload(o.id, opts, function (err3) {
+                if (ifErr(t, err, 'aborted upload')) {
+                    t.end();
+                    return;
+                }
+
+                self.client.getUpload(o.id, opts, function (err4, upload) {
+                    if (ifErr(t, err, 'got upload')) {
+                        t.end();
+                        return;
+                    }
+
+                    sanityCheckUpload(t, o, upload);
+                    t.deepEqual(upload.headers, {});
+                    t.equal(upload.state, 'done');
+                    t.equal(upload.result, 'aborted');
+                    t.end();
+                });
+            });
+        });
+    });
+});
+
+
+// Abort: bad input
+
+test('abort upload: upload already committed', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.commitUpload(o.id, [], opts, function (err2) {
+            if (ifErr(t, err2, 'commited upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.abortUpload(o.id, opts, function (err3) {
+                t.ok(err3);
+                if (!err3) {
+                    return (t.end());
+                }
+                t.ok(verror.hasCauseWithName(err3,
+                    'InvalidMultipartUploadStateError'), err);
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('abort upload: non-uuid id', function (t) {
+    var self = this;
+    var bogus = 'foobar';
+    var action = 'abort';
+
+    var options = {
+        headers: {
+            'content-type': 'application/json',
+            'expect': 'application/json'
+        },
+        path: '/' + this.client.user + '/uploads/0/' + bogus + '/' + action
+    };
+
+    self.client.signRequest({
+        headers: options.headers
+    },
+    function (err) {
+        if (ifErr(t, err, 'sign request')) {
+            t.end();
+            return;
+        }
+
+        self.client.jsonClient.post(options, {}, function (err2, _, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+
+            t.checkResponse(res, 404);
+            t.ok(verror.hasCauseWithName(err2, 'ResourceNotFoundError'));
+            t.end();
+        });
+    });
+});
+
+
+test('abort upload: non-existent id', function (t) {
+    var self = this;
+    var opts = {
+         account: this.client.user
+    };
+
+    var bogus = uuid.v4();
+
+    self.client.getUpload(bogus, opts, function (err, upload) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err, 'ResourceNotFoundError'), err);
+        t.end();
+    });
+});
diff --git a/test/mpu/auth.test.js b/test/mpu/auth.test.js
new file mode 100644
index 0000000..c0e6ade
--- /dev/null
+++ b/test/mpu/auth.test.js
@@ -0,0 +1,269 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uuid = require('node-uuid');
+var path = require('path');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var computePartsMD5 = helper.computePartsMD5;
+var createPartOptions = helper.createPartOptions;
+var createUpload = helper.createUpload;
+var createUploadSubuser = helper.createUploadSubuser;
+var redirectPath = helper.redirectPath;
+var sanityCheckUpload = helper.sanityCheckUpload;
+var writeObject = helper.writeObject;
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.userClient = testHelper.createUserClient('muskie_test_user');
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    var self = this;
+    self.client.close();
+    self.userClient.close();
+    cb();
+});
+
+
+
+// Subusers (not supported for MPU API)
+
+// Create
+test('subusers disallowed: create', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUploadSubuser(self, a, p, h, function (err) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'AuthorizationFailedError'), err);
+        t.end();
+    });
+});
+
+// Get
+test('subusers disallowed: get upload under same account', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.userClient.getUpload(o.id, opts, function (err2, upload) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'AuthorizationFailedError'),
+                err2);
+            t.end();
+        });
+    });
+});
+
+
+// Upload
+test('subusers disallowed: upload part', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.randomPartNum();
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.userClient, o.id, pn, opts, function (err2, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'NoMatchingRoleTagError'),
+                err2);
+            t.end();
+        });
+    });
+});
+
+
+// Abort
+test('subusers disallowed: abort', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.userClient.abortUpload(o.id, opts, function (err2) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'AuthorizationFailedError'),
+                err2);
+            t.end();
+        });
+    });
+});
+
+
+// Commit
+test('subusers disallowed: commit', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.userClient.commitUpload(o.id, [], opts, function (err2) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'AuthorizationFailedError'),
+                err2);
+            t.end();
+        });
+    });
+});
+
+
+// Redirect
+test('subusers disallowed: redirect (GET /:account/uploads/id)', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.userClient.get(redirectPath(a, o.id), opts, function (err2) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'AuthorizationFailedError'),
+                err2);
+            t.end();
+        });
+    });
+});
+
+
+test('subusers disallowed: redirect (GET /:account/uploads/id)', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var pn = 0;
+
+        self.userClient.get(redirectPath(a, o.id, pn), opts, function (err2) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2, 'AuthorizationFailedError'),
+                err2);
+            t.end();
+        });
+    });
+});
diff --git a/test/mpu/commit.test.js b/test/mpu/commit.test.js
new file mode 100644
index 0000000..a5d13d2
--- /dev/null
+++ b/test/mpu/commit.test.js
@@ -0,0 +1,799 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uuid = require('node-uuid');
+var path = require('path');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var computePartsMD5 = helper.computePartsMD5;
+var createPartOptions = helper.createPartOptions;
+var createUpload = helper.createUpload;
+var sanityCheckUpload = helper.sanityCheckUpload;
+var writeObject = helper.writeObject;
+
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+    self.path = self.dir + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+// Commit
+
+// TODO: commit > 1 part
+// TODO: already committed > 1 part
+// TODO: max upload size exceeded
+// TODO: different md5 than specified on create
+
+
+test('commit upload: zero parts', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err3) {
+            if (ifErr(t, err3, 'committed upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.getUpload(o.id, opts, function (err4, upload) {
+                if (ifErr(t, err4, 'created upload')) {
+                    t.end();
+                    return;
+                }
+
+                sanityCheckUpload(t, o, upload);
+                t.deepEqual(upload.headers, {});
+                t.equal(upload.state, 'done');
+                t.equal(upload.result, 'committed');
+                t.equal(upload.partsMD5Summary, computePartsMD5([]));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: one part', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = createPartOptions(a, helper.TEXT);
+
+        var pn = 0;
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            var etag = res.headers.etag;
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, [etag], opts, function (err3) {
+                if (ifErr(t, err3, 'committed upload')) {
+                    t.end();
+                    return;
+                }
+
+                self.client.getUpload(o.id, opts, function (err4, upload) {
+                    if (ifErr(t, err4, 'created upload')) {
+                        t.end();
+                        return;
+                    }
+
+                    sanityCheckUpload(t, o, upload);
+                    t.deepEqual(upload.headers, {});
+                    t.equal(upload.state, 'done');
+                    t.equal(upload.result, 'committed');
+                    t.equal(upload.partsMD5Summary, computePartsMD5([etag]));
+                    t.end();
+                });
+            });
+        });
+    });
+});
+
+
+test('commit upload: already commited, same set of parts', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            var etag = res.headers.etag;
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, [etag], opts, function (err3) {
+                if (ifErr(t, err3, 'committed upload')) {
+                    t.end();
+                    return;
+                }
+
+                self.client.commitUpload(o.id, [etag], opts, function (err4) {
+                    if (ifErr(t, err4, 'committed upload')) {
+                        t.end();
+                        return;
+                    }
+
+                    self.client.getUpload(o.id, opts, function (err5, upload) {
+                        if (ifErr(t, err5, 'got upload')) {
+                            t.end();
+                            return;
+                        }
+
+                        sanityCheckUpload(t, o, upload);
+                        t.deepEqual(upload.headers, {});
+                        t.equal(upload.state, 'done');
+                        t.equal(upload.result, 'committed');
+                        t.equal(upload.partsMD5Summary,
+                            computePartsMD5([etag]));
+                        t.end();
+                    });
+                });
+            });
+        });
+    });
+});
+
+
+// Commit: invalid upload (not related to the JSON API inputs)
+
+test('commit upload: already aborted', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.abortUpload(o.id, opts, function (err2) {
+            if (ifErr(t, err2, 'created upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.commitUpload(o.id, [], opts, function (err3) {
+                if (!err3) {
+                    t.fail('upload already aborted');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err3,
+                    'InvalidMultipartUploadStateError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: already committed, different set of parts', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            var etag = res.headers.etag;
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, [etag, etag], opts, function (err3) {
+                if (!err3) {
+                    t.fail('upload already committed with different part set');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err3,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: object size does not match create header (0 parts)',
+function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    var h = {
+        'content-length': helper.TEXT.length
+    };
+
+    createUpload(self, a, self.path, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = {
+           account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err2) {
+            if (!err2) {
+                t.fail('object size mismatch');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err2,
+                'MultipartUploadInvalidArgumentError'));
+            t.end();
+        });
+    });
+
+});
+
+
+test('commit upload: object size does not match create header (1 part)',
+function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    var h = {
+        'content-length': helper.TEXT.length + 1
+    };
+
+    createUpload(self, a, self.path, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            var etag = res.headers.etag;
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, [etag], opts, function (err3) {
+                if (!err3) {
+                    t.fail('object size mismatch');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err3,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: non-final part less than min part size', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = createPartOptions(a, helper.TEXT);
+        var etags = [];
+
+        vasync.forEachParallel({
+            func: function uploadText(pn, cb) {
+                writeObject(self.client, o.id, pn, opts, function (errw, res) {
+                    if (!errw) {
+                        etags[pn] = res.headers.etag;
+                    }
+                    cb();
+                });
+            },
+            inputs: [0, 1, 2]
+        }, function (errp, results) {
+            if (ifErr(t, errp, 'uploading parts')) {
+                t.end();
+                return;
+            }
+
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, etags, opts, function (err2) {
+                if (!err2) {
+                    t.fail('non-final part has less than minimum size');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err2,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+// Commit: invalid object path specifed on create
+
+test('commit upload: path is top-level directory', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = '/' + a + '/stor';
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = {
+           account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err3) {
+            if (!err3) {
+                t.fail('invalid object path (top-level directory)');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err3,
+                'OperationNotAllowedOnDirectoryError'));
+             t.end();
+        });
+    });
+});
+
+
+test('commit upload: parent dir does not exist (parent is top-level dir)',
+function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = '/' + a + '/' + uuid.v4() + '/foo.txt';
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = {
+           account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err3) {
+            if (!err3) {
+                t.fail('invalid object path (parent is top-level directory)');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err3, 'DirectoryDoesNotExistError'));
+             t.end();
+        });
+    });
+});
+
+
+test('commit upload: parent dir does not exist (parent is not a top-level dir)',
+function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir + '/foobar/foo.txt';
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var opts = {
+           account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err3) {
+            if (!err3) {
+                t.fail('invalid object path (parent does not exist)');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err3,
+                'DirectoryDoesNotExistError'));
+             t.end();
+        });
+    });
+});
+
+
+test('commit upload: object path under another account', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = '/poseidon/stor/foo.txt';
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err2) {
+            if (!err2) {
+                t.fail('upload created under a different account');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err2,
+                'AuthorizationFailedError'));
+            t.end();
+        });
+    });
+});
+
+
+test('commit upload: object path under a nonexistent account', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var bogus = uuid.v4();
+    var p = '/' + bogus + '/foo.txt';
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.commitUpload(o.id, [], opts, function (err2) {
+            if (!err2) {
+                t.fail('upload created under a different account');
+                t.end();
+                return;
+            }
+
+            t.ok(verror.hasCauseWithName(err2,
+                'AccountDoesNotExistError'));
+            t.end();
+        });
+    });
+});
+
+
+
+
+// Commit: bad inputs to API
+
+test('commit upload: empty part etag', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, [''], opts, function (err3) {
+                if (!err3) {
+                    t.fail('commit part 0 has an empty etag');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err3,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: incorrect part etag', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            opts = {
+                account: a
+            };
+
+            self.client.commitUpload(o.id, ['foobar'], opts, function (err3) {
+                if (!err3) {
+                    t.fail('commit part 0 has incorrect etag');
+                    t.end();
+                    return;
+                }
+
+                t.ok(verror.hasCauseWithName(err3,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: more than 10000 parts specified', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, self.path, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = 0;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+
+            var etag = res.headers.etag;
+            opts = {
+                account: a
+            };
+
+            var parts = [];
+            for (var i = 0; i <= (helper.MAX_PART_NUM + 1); i++) {
+                parts[i] = etag;
+            }
+
+            self.client.commitUpload(o.id, parts, opts, function (err3) {
+                if (!err3) {
+                    t.fail('commit specified > 10000 parts');
+                    t.end();
+                    return;
+                }
+                t.ok(verror.hasCauseWithName(err3,
+                    'MultipartUploadInvalidArgumentError'));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('commit upload: non-uuid id', function (t) {
+    var self = this;
+    var bogus = 'foobar';
+    var action = 'commit';
+
+    var options = {
+        headers: {
+            'content-type': 'application/json',
+            'expect': 'application/json'
+        },
+        path: '/' + this.client.user + '/uploads/0/' + bogus + '/' + action
+    };
+
+    self.client.signRequest({
+        headers: options.headers
+    },
+    function (err) {
+        if (ifErr(t, err, 'sign request')) {
+            t.end();
+            return;
+        }
+
+        self.client.jsonClient.post(options, {}, function (err2, _, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+
+            t.checkResponse(res, 404);
+            t.ok(verror.hasCauseWithName(err2, 'ResourceNotFoundError'));
+            t.end();
+        });
+    });
+});
+
+
+test('commit upload: non-existent id', function (t) {
+    var self = this;
+    var opts = {
+         account: this.client.user
+    };
+
+    var bogus = uuid.v4();
+    self.client.commitUpload(bogus, [], opts, function (err, upload) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err, 'ResourceNotFoundError'));
+        t.end();
+    });
+});
diff --git a/test/mpu/create.test.js b/test/mpu/create.test.js
new file mode 100644
index 0000000..fc4c186
--- /dev/null
+++ b/test/mpu/create.test.js
@@ -0,0 +1,547 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uuid = require('node-uuid');
+var path = require('path');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var obj = require('../../lib/obj.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var computePartsMD5 = helper.computePartsMD5;
+var createPartOptions = helper.createPartOptions;
+var createUpload = helper.createUpload;
+var sanityCheckUpload = helper.sanityCheckUpload;
+var writeObject = helper.writeObject;
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+
+// Create: happy cases
+
+test('create upload', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {};
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// content-length
+test('create upload: content-length header', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var size = helper.randomUploadSize();
+    var h = {
+        'content-length': size
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// durability-level
+test('create upload: durability-level header', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var copies = helper.randomNumCopies();
+
+    var h = {
+        'durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// x-durability-level
+test('create upload: x-durability-level header', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.randomNumCopies();
+
+    var h = {
+        'x-durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'got upload')) {
+            t.end();
+            return;
+        }
+        checkCreateResponse(t, o);
+
+        var opts = {
+            account: a
+        };
+
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// content-md5
+test('create upload: content-md5 header', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var h = {
+        'content-md5': 'JdMoQCNCYOHEGq1fgaYyng=='
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            t.ifError(err2);
+            if (ifErr(t, err, 'created upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// mix of headers, supported and unsupported
+test('create upload: various headers', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.randomNumCopies();
+    var size = helper.randomUploadSize();
+
+    var h = {
+        'content-length': size,
+        'durability-level': copies,
+        'content-md5': 'JdMoQCNCYOHEGq1fgaYyng==',
+        'm-my-custom-header': 'my-custom-value'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, h);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// make sure headers are case-insensitive
+test('create upload: mixed case headers', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.randomNumCopies();
+    var size = helper.randomUploadSize();
+
+    var h = {
+        'Content-Length': size,
+        'DURABILITY-LEVEL': copies,
+        'cOntEnt-Md5': 'JdMoQCNCYOHEGq1fgaYyng==',
+        'm-my-CuStoM-header': 'my-custom-value'
+    };
+
+    // only headers should be case-insensitive (values shouldn't change)
+    var lowerCase = {
+        'content-length': size,
+        'durability-level': copies,
+        'content-md5': 'JdMoQCNCYOHEGq1fgaYyng==',
+        'm-my-custom-header': 'my-custom-value'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+        self.client.getUpload(o.id, opts, function (err2, upload) {
+            if (ifErr(t, err2, 'got upload')) {
+                t.end();
+                return;
+            }
+
+            sanityCheckUpload(t, o, upload);
+            t.deepEqual(upload.headers, lowerCase);
+            t.ok(upload.state, 'created');
+            t.end();
+        });
+    });
+});
+
+
+// Create: bad input
+
+test('create upload: no input object path', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, null, null, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: object path not a string', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    createUpload(self, a, [], null, function (err, o) {
+        t.ok(err); //TODO error message name
+        if (!err) {
+            return (t.end());
+        }
+        t.end();
+    });
+});
+
+
+test('create upload: if-match header disalowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {
+        'if-match': 'foo'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: if-none-match header disalowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {
+        'if-none-match': 'foo'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: if-modified-since header disalowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {
+        'if-modified-since': 'foo'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+test('create upload: if-unmodified-since header disalowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+    var h = {
+        'if-unmodified-since': 'foo'
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: content-length less than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var size = helper.MIN_UPLOAD_SIZE - 1;
+    var h = {
+        'content-length': size
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'MultipartUploadInvalidArgumentError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: durability-level greater than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.MAX_NUM_COPIES + 1;
+    var h = {
+        'durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'InvalidDurabilityLevelError'), err);
+        t.end();
+    });
+});
+
+test('create upload: x-durability-level greater than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.MAX_NUM_COPIES + 1;
+    var h = {
+        'x-durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'InvalidDurabilityLevelError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: durability-level less than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.MIN_NUM_COPIES - 1;
+    var h = {
+        'durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'InvalidDurabilityLevelError'), err);
+        t.end();
+    });
+});
+
+
+test('create upload: x-durability-level less than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    var copies = helper.MIN_NUM_COPIES - 1;
+    var h = {
+        'x-durability-level': copies
+    };
+
+    createUpload(self, a, p, h, function (err, o) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err,
+            'InvalidDurabilityLevelError'), err);
+        t.end();
+    });
+});
diff --git a/test/mpu/get.test.js b/test/mpu/get.test.js
new file mode 100644
index 0000000..5cd8e76
--- /dev/null
+++ b/test/mpu/get.test.js
@@ -0,0 +1,107 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var path = require('path');
+var uuid = require('node-uuid');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+
+// Get: bad input (happy path tested in create)
+
+test('get upload: non-uuid id', function (t) {
+    var self = this;
+    var bogus = 'foobar';
+    var action = 'state';
+
+    var options = {
+        headers: {
+            'content-type': 'application/json',
+            'expect': 'application/json'
+        },
+        path: '/' + this.client.user + '/uploads/0/' + bogus + '/' + action
+    };
+
+    self.client.signRequest({
+        headers: options.headers
+    },
+    function (err) {
+        if (ifErr(t, err, 'sign request')) {
+            t.end();
+            return;
+        }
+
+        self.client.get(options, {}, function (err2, _, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+
+            t.checkResponse(res, 404);
+            t.ok(verror.hasCauseWithName(err2, 'ResourceNotFoundError'));
+            t.end();
+        });
+    });
+});
+
+
+test('get upload: non-existent id', function (t) {
+    var self = this;
+    var opts = {
+         account: this.client.user
+    };
+
+    var bogus = uuid.v4();
+
+    self.client.getUpload(bogus, opts, function (err, upload) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err, 'ResourceNotFoundError'), err);
+        t.end();
+    });
+});
diff --git a/test/mpu/helper.js b/test/mpu/helper.js
new file mode 100644
index 0000000..5097546
--- /dev/null
+++ b/test/mpu/helper.js
@@ -0,0 +1,260 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var crypto = require('crypto');
+var manta = require('manta');
+var MemoryStream = require('stream').PassThrough;
+var path = require('path');
+
+var obj = require('../../lib/obj.js');
+
+
+///--- Globals
+
+var MIN_UPLOAD_SIZE = 0;
+var MAX_TEST_UPLOAD_SIZE = 1000;
+
+var MIN_NUM_COPIES = 1;
+// TODO: not sure if there's a way to get this value from the config.
+var MAX_NUM_COPIES = 6;
+
+var MIN_PART_NUM = 0;
+var MAX_PART_NUM = 9999;
+
+var TEXT = 'The lazy brown fox \nsomething \nsomething foo';
+
+
+///--- Helpers
+
+function ifErr(t, err, desc) {
+    t.ifError(err, desc);
+    if (err) {
+        t.deepEqual(err.body, {}, desc + ': error body');
+        return (true);
+    }
+
+    return (false);
+}
+
+
+function between(min, max) {
+    return (Math.floor(Math.random() * (max - min + 1) + min));
+}
+
+
+function randomPartNum() {
+    return (between(MIN_PART_NUM, MAX_PART_NUM));
+}
+
+
+function randomUploadSize() {
+    return (between(MIN_UPLOAD_SIZE, MAX_TEST_UPLOAD_SIZE));
+}
+
+
+function randomNumCopies() {
+    return (between(MIN_NUM_COPIES, MAX_NUM_COPIES));
+}
+
+
+// Given an account, id and (optionally) part number, returns a path that should
+// be redirected
+// (e.g. /jhendricks/uploads/d/d32e43e8-358f-42c0-aa8b-647a3d0f32f7)
+function uploadPath(account, id, partNum) {
+    var url = '/' + account + '/uploads/' + id.charAt(0) + '/' + id;
+
+    if (!isNaN(partNum)) {
+        url += '/' + partNum;
+    }
+
+    return (url);
+}
+
+
+// Given an account, id and (optionally) part number, returns a path that should
+// be redirected (e.g. /jhendricks/uploads/d32e43e8-358f-42c0-aa8b-647a3d0f32f7)
+function redirectPath(a, id, pn) {
+    var p = '/' + a + '/uploads/' + id;
+    if (!(pn === null || pn === undefined)) {
+        p += '/' + pn;
+    }
+
+    return (p);
+}
+
+
+// Creates the options needed to upload string with account.
+function createPartOptions(account, string) {
+    var opts = {
+        account: account,
+        md5: crypto.createHash('md5').update(string).digest('base64'),
+        size: Buffer.byteLength(string),
+        type: 'text/plain'
+    };
+
+    return (opts);
+}
+
+
+function writeObject(client, id, partNum, opts, cb) {
+    var stream = new MemoryStream();
+    client.put(uploadPath(opts.account, id, partNum), stream, opts, cb);
+    process.nextTick(stream.end.bind(stream, TEXT));
+}
+
+
+function computePartsMD5(parts) {
+    var hash = crypto.createHash('md5');
+    parts.forEach(function (p) {
+        hash.update(p);
+    });
+
+    return (hash.digest('base64'));
+}
+
+
+function checkCreateResponse(t, o) {
+    t.ok(o);
+
+    // verify everything we expect to be in the response from create is there
+    if (o) {
+        t.ok(o.id);
+        t.ok(o.partsDirectory);
+        t.equal(o.id, path.basename(o.partsDirectory));
+    }
+}
+
+
+function sanityCheckUpload(t, o, u) {
+    t.ok(o);
+    t.ok(u);
+
+    // verify everything we expect to be in the response from get-mpu is there
+    if (u) {
+        t.ok(u.id);
+        t.ok(u.state);
+        t.ok(u.targetObject);
+        t.ok(u.headers);
+        t.ok(u.numCopies);
+
+        if (u.state === 'created') {
+            t.ok(u.uploadPath);
+        } else if (u.state === 'finalizing') {
+            t.ok(u.type);
+            t.ok(u.type === 'commit' || u.type === 'abort');
+        } else {
+            t.ok(u.state === 'done');
+            t.ok(u.result === 'committed' || u.result === 'aborted');
+            if (u.result === 'committed') {
+                t.ok(u.partsMD5Summary);
+            }
+        }
+    }
+
+    // verify that the response from create matches with what get-mpu said
+    if (o && u) {
+        t.equal(o.id, u.id);
+
+        if (u.state === 'created') {
+            t.equal(o.partsDirectory, u.uploadPath);
+        }
+    }
+}
+
+/*
+ * Helper that creates an upload and passes the object returned from `create`
+ * to the callback.
+ *
+ * Parameters:
+ *  - s: the tester (TODO not sure if this is right)
+ *  - account: account for the upload
+ *  - subuser: boolean whether to use a subuser in the request
+ *  - p: the target object path to pass to `create`
+ *  - h: a headers object to pass to `create`
+ *  - cb: callback of the form cb(err, object)
+ */
+function createUploadHelper(s, account, subuser, p, h, cb) {
+    var opts = {
+        headers: {
+            'content-type': 'application/json',
+            'expect': 'application/json'
+        },
+        path: '/' + account + '/uploads'
+    };
+
+    var client = s.client;
+    if (subuser) {
+        client = s.userClient;
+    }
+
+    client.signRequest({
+        headers: opts.headers
+    }, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            var body = {};
+            if (p) {
+                body.objectPath = p;
+            }
+            if (h) {
+                body.headers = h;
+            }
+
+            s.client.jsonClient.post(opts, body,
+            function (err2, req, res, o) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    cb(null, o);
+                }
+            });
+        }
+    });
+}
+
+
+// Creates a multipart upload using the subuser on the test account.
+function createUploadSubuser(s, account, p, h, cb) {
+    createUploadHelper(s, account, true, p, h, cb);
+}
+
+// Creates a multipart upload using the test account.
+function createUpload(s, account, p, h, cb) {
+    createUploadHelper(s, account, false, p, h, cb);
+}
+
+
+///--- Exports
+
+module.exports = {
+    MIN_UPLOAD_SIZE: MIN_UPLOAD_SIZE,
+    MAX_TEST_UPLOAD_SIZE: MAX_TEST_UPLOAD_SIZE,
+    MIN_NUM_COPIES: MIN_NUM_COPIES,
+    MAX_NUM_COPIES: MAX_NUM_COPIES,
+    MIN_PART_NUM: MIN_PART_NUM,
+    MAX_PART_NUM: MAX_PART_NUM,
+    TEXT: TEXT,
+
+    ifErr: ifErr,
+    between: between,
+    randomPartNum: randomPartNum,
+    randomUploadSize: randomUploadSize,
+    randomNumCopies: randomNumCopies,
+    uploadPath: uploadPath,
+    redirectPath: redirectPath,
+    createPartOptions: createPartOptions,
+    createUpload: createUpload,
+    createUploadSubuser: createUploadSubuser,
+    computePartsMD5: computePartsMD5,
+    sanityCheckUpload: sanityCheckUpload,
+    checkCreateResponse: checkCreateResponse,
+    writeObject: writeObject
+};
diff --git a/test/mpu/redirect.test.js b/test/mpu/redirect.test.js
new file mode 100644
index 0000000..9df5da3
--- /dev/null
+++ b/test/mpu/redirect.test.js
@@ -0,0 +1,423 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var manta = require('manta');
+var path = require('path');
+var MemoryStream = require('stream').PassThrough;
+var uuid = require('node-uuid');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var createUpload = helper.createUpload;
+var redirectPath = helper.redirectPath;
+var uploadPath = helper.uploadPath;
+
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+
+// Redirect
+
+test('redirect upload: GET /:account/uploads/:id', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.get(redirectPath(a, o.id), opts,
+        function (err2, stream, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: PUT /:account/uploads/:id', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var s = new MemoryStream();
+        self.client.put(redirectPath(a, o.id), s, opts, function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: HEAD /:account/uploads/:id', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.info(redirectPath(a, o.id), opts, function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            // info() doesn't return a status code, but if the location is in
+            // location header, the redirect was successful.
+            t.equal(res.headers.location, uploadPath(a, o.id));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: POST /:account/uploads/:id', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var options = {
+            headers: {
+                'content-type': 'application/json',
+                'expect': 'application/json'
+            },
+            path: redirectPath(a, o.id)
+        };
+
+        self.client.signRequest({
+            headers: options.headers
+        },
+        function (err2) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.jsonClient.post(options, {}, function (err3, _, res) {
+                if (ifErr(t, err3, 'redirect upload')) {
+                    t.end();
+                    return;
+                }
+
+                t.checkResponse(res, 301);
+                t.equal(res.headers.location, uploadPath(a, o.id));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('redirect upload: DELETE /:account/uploads/:id', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        self.client.unlink(redirectPath(a, o.id), opts, function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: GET /:account/uploads/:id/:partNum', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var pn = 0;
+        self.client.get(redirectPath(a, o.id, pn), opts,
+        function (err2, stream, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id, pn));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: PUT /:account/uploads/:id/:partNum', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var s = new MemoryStream();
+        var pn = 0;
+        self.client.put(redirectPath(a, o.id, pn), s, opts,
+        function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id, pn));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: HEAD /:account/uploads/:id/:partNum', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var pn = 0;
+        self.client.info(redirectPath(a, o.id, pn), opts, function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            // info() doesn't return a status code, but if the location is in
+            // location header, the redirect was successful.
+            t.equal(res.headers.location, uploadPath(a, o.id, pn));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: POST /:account/uploads/:id/:partNum', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var pn = 0;
+        var options = {
+            headers: {
+                'content-type': 'application/json',
+                'expect': 'application/json'
+            },
+            path: redirectPath(a, o.id, pn)
+        };
+
+        self.client.signRequest({
+            headers: options.headers
+        },
+        function (err2) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            self.client.jsonClient.post(options, {}, function (err3, _, res) {
+                if (ifErr(t, err3, 'redirect upload')) {
+                    t.end();
+                    return;
+                }
+
+                t.checkResponse(res, 301);
+                t.equal(res.headers.location, uploadPath(a, o.id, pn));
+                t.end();
+            });
+        });
+    });
+});
+
+
+test('redirect upload: DELETE /:account/uploads/:id/:partNum', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+        var opts = {
+            account: a
+        };
+
+        var pn = 0;
+        self.client.unlink(redirectPath(a, o.id, pn), opts,
+        function (err2, res) {
+            if (ifErr(t, err2, 'redirect upload')) {
+                t.end();
+                return;
+            }
+
+            t.checkResponse(res, 301);
+            t.equal(res.headers.location, uploadPath(a, o.id, pn));
+            t.end();
+        });
+    });
+});
+
+
+test('redirect upload: non-existent id', function (t) {
+    var self = this;
+    var a = self.client.user;
+
+    var bogus = uuid.v4();
+    var opts = {
+        account: a
+    };
+
+
+    self.client.get(redirectPath(a, bogus), opts, function (err, _, res) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+
+        t.ok(verror.hasCauseWithName(err, 'ResourceNotFoundError'), err);
+        t.checkResponse(res, 404);
+        t.end();
+    });
+});
diff --git a/test/mpu/upload.test.js b/test/mpu/upload.test.js
new file mode 100644
index 0000000..7ff18b4
--- /dev/null
+++ b/test/mpu/upload.test.js
@@ -0,0 +1,276 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var path = require('path');
+var uuid = require('node-uuid');
+var vasync = require('vasync');
+var verror = require('verror');
+
+if (require.cache[path.join(__dirname, '/../helper.js')])
+    delete require.cache[path.join(__dirname, '/../helper.js')];
+if (require.cache[__dirname + '/helper.js'])
+    delete require.cache[__dirname + '/helper.js'];
+var testHelper = require('../helper.js');
+var helper = require('./helper.js');
+
+var after = testHelper.after;
+var before = testHelper.before;
+var test = testHelper.test;
+var ifErr = helper.ifErr;
+var checkCreateResponse = helper.checkCreateResponse;
+var computePartsMD5 = helper.computePartsMD5;
+var createPartOptions = helper.createPartOptions;
+var createUpload = helper.createUpload;
+var sanityCheckUpload = helper.sanityCheckUpload;
+var writeObject = helper.writeObject;
+
+before(function (cb) {
+    var self = this;
+
+    self.client = testHelper.createClient();
+    self.uploads_root = '/' + self.client.user + '/uploads';
+    self.root = '/' + self.client.user + '/stor';
+    self.dir = self.root + '/' + uuid.v4();
+
+    self.client.mkdir(self.dir, function (mkdir_err) {
+        if (mkdir_err) {
+            cb(mkdir_err);
+            return;
+        } else {
+            cb(null);
+        }
+    });
+});
+
+
+after(function (cb) {
+    this.client.rmr(this.dir, cb.bind(null, null));
+});
+
+
+// TODO streaming object
+// TODO size greater than max part size
+
+test('upload part: minimium part number', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.MIN_PART_NUM;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+            t.end();
+        });
+    });
+});
+
+
+test('upload part: maximum part number', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.MAX_PART_NUM;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+            t.end();
+        });
+    });
+});
+
+
+test('upload part: random part number', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.randomPartNum();
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+            t.end();
+        });
+    });
+});
+
+
+test('upload part: zero-byte part', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.randomPartNum();
+        var opts = createPartOptions(a, helper.TEXT);
+        opts.size = 0;
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            if (ifErr(t, err2, 'uploaded part')) {
+                t.end();
+                return;
+            }
+
+            t.ok(res);
+            t.checkResponse(res, 204);
+            t.end();
+        });
+    });
+});
+
+
+// Upload: bad input
+
+test('upload part: part number less than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+
+        checkCreateResponse(t, o);
+
+        var pn = helper.MIN_PART_NUM - 1;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2,
+                'MultipartUploadInvalidArgumentError'));
+            t.end();
+        });
+    });
+});
+
+
+test('upload part: part number greater than allowed', function (t) {
+    var self = this;
+    var a = self.client.user;
+    var p = self.dir;
+
+    createUpload(self, a, p, null, function (err, o) {
+        if (ifErr(t, err, 'created upload')) {
+            t.end();
+            return;
+        }
+        checkCreateResponse(t, o);
+
+        var pn = helper.MAX_PART_NUM + 1;
+        var opts = createPartOptions(a, helper.TEXT);
+
+        writeObject(self.client, o.id, pn, opts, function (err2, res) {
+            t.ok(err2);
+            if (!err2) {
+                return (t.end());
+            }
+            t.ok(verror.hasCauseWithName(err2,
+                'MultipartUploadInvalidArgumentError'));
+            t.end();
+        });
+    });
+});
+
+
+test('upload part: non-uuid id', function (t) {
+    var self = this;
+
+    var bogus = 'foobar';
+    var pn = helper.randomPartNum();
+    var opts = createPartOptions(this.client.user, helper.TEXT);
+
+    writeObject(self.client, bogus, pn, opts, function (err, res) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err, 'DirectoryDoesNotExistError'));
+        t.checkResponse(res, 404);
+        t.end();
+    });
+});
+
+
+test('upload part: non-existent id', function (t) {
+    var self = this;
+
+    var bogus = uuid.v4();
+    var pn = helper.randomPartNum();
+    var opts = createPartOptions(this.client.user, helper.TEXT);
+
+    writeObject(self.client, bogus, pn, opts, function (err, res) {
+        t.ok(err);
+        if (!err) {
+            return (t.end());
+        }
+        t.ok(verror.hasCauseWithName(err, 'DirectoryDoesNotExistError'));
+        t.checkResponse(res, 404);
+        t.end();
+    });
+});
diff --git a/test/obj.test.js b/test/obj.test.js
index e27b553..01b3a5e 100644
--- a/test/obj.test.js
+++ b/test/obj.test.js
@@ -269,12 +269,13 @@ test('put object (3 copies)', function (t) {
 });
 
 
-test('put object (7 copies)', function (t) {
+// Default maximum is 9 copies.
+test('put object (10 copies)', function (t) {
     var stream = new MemoryStream();
     var text = 'The lazy brown fox \nsomething \nsomething foo';
     var size = Buffer.byteLength(text);
     var _opts = {
-        copies: 7,
+        copies: 10,
         size: size
     };
     process.nextTick(stream.end.bind(stream, text));
diff --git a/tools/jsl.node.conf b/tools/jsl.node.conf
index 72d31c3..76a1fc1 100644
--- a/tools/jsl.node.conf
+++ b/tools/jsl.node.conf
@@ -170,6 +170,9 @@
 +define MaxContentLengthError
 +define MaxSizeExceededError
 +define MissingPermissionError
++define MultipartUploadCreateError
++define MultipartUploadInvalidArgumentError
++define MultipartUploadStateError
 +define NoMatchingRoleTagError
 +define NotAcceptableError
 +define NotEnoughSpaceError
