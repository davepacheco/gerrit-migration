commit 2d4b72ebe897c191fa9d91e6e810297f87da499a (refs/changes/92/1292/6)
Author: Jordan Hendricks <jordan.hendricks@joyent.com>
Date:   2017-01-27T18:48:44+00:00 (2 years, 8 months ago)
    
    MANTA-2169 Support multipart upload of a single file to Manta

diff --git a/.gitignore b/.gitignore
index d416fc4..408b0e2 100644
--- a/.gitignore
+++ b/.gitignore
@@ -11,3 +11,4 @@ cscope.out
 smf/manifests/*.xml
 *.tar.bz2
 *.log
+*.swp
diff --git a/lib/audit.js b/lib/audit.js
index 36bfa92..908da68 100644
--- a/lib/audit.js
+++ b/lib/audit.js
@@ -232,6 +232,9 @@ function auditLogger(options) {
         }
         obj.sharksContacted = req.sharksContacted;
         obj.shard = req.shard;
+        if (req.route) {
+            obj.route = req.route.name;
+        }
 
         if (req._timeToLastByte !== undefined &&
             req._totalBytes !== undefined) {
diff --git a/lib/common.js b/lib/common.js
index 8996f9f..858afdc 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -44,6 +44,8 @@ var JOBS_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/([a-f0-9]{8}-[a-f0-9]{4}-
 /* JSSTYLED */
 var JOBS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/?.*/;
 /* JSSTYLED */
+var UPLOADS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/uploads\/?.*/;
+/* JSSTYLED */
 var JOBS_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/jobs\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/stor/;
 var PUBLIC_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/public(\/(.*)|$)/;
 var REPORTS_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/reports(\/(.*)|$)/;
@@ -57,6 +59,7 @@ var ROOT_REGEXPS = [
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/public\\/?$'), // public
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/stor\\/?$'), // storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/?$'), // jobs (list)
+    new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/uploads\\/?$'), // uploads (list)
 
     // jobs storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/[\\w-]+\\/stor\\/?$'),
@@ -146,7 +149,7 @@ HttpRequest.isRootDirectory = function isRootDirectory(d) {
     return (_test(d));
 };
 
-
+//TODO: think uploads should go here
 HttpRequest.isRestrictedWrite = function isRestrictedWrite() {
     if (this.method !== 'PUT')
         return (false);
@@ -159,6 +162,7 @@ HttpRequest.isRestrictedWrite = function isRestrictedWrite() {
 
 ///--- API
 
+//TODO: comment this.
 function createMetadata(req, type, cb) {
     var prev = req.metadata || {};
     // Override the UpdateMetadata type, as this flows in via PUT Object
@@ -371,7 +375,7 @@ function ensureParent(req, res, next) {
     }
 }
 
-
+//TODO: comment this
 function getMetadata(req, res, next) {
     var log = req.log;
 
@@ -468,7 +472,7 @@ function getMetadata(req, res, next) {
     });
 }
 
-
+//TODO: comment this.
 function loadMetadata(req, opts, callback) {
     req.moray.getMetadata(opts, function (err, md, wrap) {
         if (err) {
@@ -700,6 +704,8 @@ module.exports = {
 
     PATH_LOGIN_RE: PATH_LOGIN_RE,
 
+    UPLOADS_ROOT_PATH: UPLOADS_ROOT_PATH,
+
     StoragePaths: {
         'public': {
             'name': 'Public',
@@ -716,6 +722,10 @@ module.exports = {
         'reports': {
             'name': 'Reports',
             'regex': REPORTS_STOR_PATH
+        },
+        'uploads': {
+            'name': 'Uploads',
+            'regex': UPLOADS_ROOT_PATH
         }
     },
 
@@ -903,23 +913,6 @@ module.exports = {
         }
 
         return (setup);
-    },
-
-    // Not used anymore
-    debugRequestHandler: function () {
-        function _debugLogRequest(req, res, next) {
-            var log = req.log;
-            var str = req.method + ' ' +
-                req.url + ' ' +
-                req.httpVersion + '\n';
-            Object.keys(req.headers).sort().forEach(function (k) {
-                str += k + ': ' + req.headers[k] + '\n';
-            });
-            log.debug('handling request:\n%s\n', str);
-            return (next());
-        }
-
-        return (_debugLogRequest);
     }
 
 };
diff --git a/lib/dir.js b/lib/dir.js
index d2d3bba..e2d90bd 100644
--- a/lib/dir.js
+++ b/lib/dir.js
@@ -265,7 +265,6 @@ module.exports = {
 
     putDirectoryHandler: function putDirectoryHandler() {
         var chain = [
-            // common.ensureNotRootHandler(),
             common.ensureParentHandler(),
             mkdir
         ];
diff --git a/lib/errors.js b/lib/errors.js
index bd5c156..955103b 100644
--- a/lib/errors.js
+++ b/lib/errors.js
@@ -5,9 +5,10 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
+//TODO: comment that you have to change the conf for lint to add errors
 var assert = require('assert');
 var fs = require('fs');
 var path = require('path');
@@ -439,6 +440,111 @@ function MissingPermissionError(perm) {
 util.inherits(MissingPermissionError, MuskieError);
 
 
+function MultipartUploadAbortedError(id) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadAborted',
+        statusCode: 409,
+        message: sprintf('upload %s aborted', id)
+    });
+}
+util.inherits(MultipartUploadAbortedError, MuskieError);
+
+
+
+function MultipartUploadCommitInProgessError(id) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadCommitInProgress',
+        statusCode: 409,
+        message: sprintf('upload %s already has a commit in progress', id)
+    });
+}
+util.inherits(MultipartUploadCommitInProgessError, MuskieError);
+
+
+function MultipartUploadContentLengthError(id, expected, actual) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadContentLengthError',
+        statusCode: 400,
+        message: sprintf('expected content-length %d, but object was: %d',
+            id, expected, actual)
+    });
+}
+util.inherits(MultipartUploadContentLengthError, MuskieError);
+
+
+function MultipartUploadFinalizeConflictError(id, action) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadFinalizeConflict',
+        statusCode: 409,
+        message: sprintf('cannot %s upload %s; already finalized', action, id)
+    });
+}
+util.inherits(MultipartUploadFinalizeConflictError, MuskieError);
+
+
+function MultipartUploadMissingObjecPathError() {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadMissingObjecPathError',
+        statusCode: 400,
+        message: 'an objectPath is required'
+    });
+}
+util.inherits(MultipartUploadMissingObjecPathError, MuskieError);
+
+
+function MultipartUploadMissingPartError(id, index) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadMissingPartError',
+        statusCode: 400,
+        message: sprintf('missing etag for part %d, upload %s', index, id)
+    });
+}
+util.inherits(MultipartUploadMissingPartError, MuskieError);
+
+
+function MultipartUploadPartEtagError(id, index, etag) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartEtag',
+        statusCode: 400,
+        message: sprintf('upload %s, part %s has invalid etag: %s',
+            id, index, etag)
+    });
+}
+util.inherits(MultipartUploadPartEtagError, MuskieError);
+
+
+function MultipartUploadPartLimitError(id, numParts) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartLimitError',
+        statusCode: 400,
+        message: sprintf('invalid commit for upload %s: too many parts (%s)',
+            id, numParts)
+    });
+}
+util.inherits(MultipartUploadPartLimitError, MuskieError);
+
+
+function MultipartUploadPartNumError(id, partNum) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartNum',
+        statusCode: 400,
+        message: sprintf('invalid partNum for upload %s: %s', id, partNum)
+    });
+}
+util.inherits(MultipartUploadPartNumError, MuskieError);
+
+
+function MultipartUploadPartSizeError(id, index, size) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartSize',
+        statusCode: 400,
+        message: sprintf('upload %s, part %d is too small (size %d)',
+            id, index, size)
+    });
+}
+util.inherits(MultipartUploadPartSizeError, MuskieError);
+
+
 function NotAcceptableError(req, type) {
     MuskieError.call(this, {
         restCode: 'NotAcceptable',
diff --git a/lib/obj.js b/lib/obj.js
index 31f38cb..075caa5 100644
--- a/lib/obj.js
+++ b/lib/obj.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 //
@@ -192,6 +192,7 @@ function parseArguments(req, res, next) {
             'content-md5',
             'durability-level'
         ].some(function (k) {
+            debugger;
             var bad = req.headers[k];
             if (bad) {
                 setImmediate(function killRequest() {
@@ -912,5 +913,11 @@ module.exports = {
             deletePointer
         ];
         return (chain);
-    }
+    },
+
+    parseArguments: parseArguments,
+    startSharkStreams: startSharkStreams,
+    sharkStreams: sharkStreams,
+    saveMetadata: saveMetadata,
+    DEF_MAX_LEN: DEF_MAX_LEN
 };
diff --git a/lib/other.js b/lib/other.js
index 5a91a42..c53333f 100644
--- a/lib/other.js
+++ b/lib/other.js
@@ -376,7 +376,6 @@ module.exports = {
             common.ensureParentHandler(),
             preflightPUTRequest,
             common.ensureEntryExistsHandler(),
-            // common.assertMetadataHandler(),
             preflightRequest
         ];
 
diff --git a/lib/server.js b/lib/server.js
index 1bf8b7e..808dad0 100644
--- a/lib/server.js
+++ b/lib/server.js
@@ -24,10 +24,11 @@ var common = require('./common');
 var dir = require('./dir');
 var jobs = require('./jobs');
 var link = require('./link');
+var medusa = require('./medusa');
 var obj = require('./obj');
 var other = require('./other');
 var picker = require('./picker');
-var medusa = require('./medusa');
+var uploads = require('./uploads');
 
 // injects into the global namespace
 require('./errors');
@@ -284,6 +285,158 @@ function createServer(options, clearProxy) {
         authAction: 'mlogin'
     }, medusa.getMedusaAttachHandler());
 
+
+    // Multipart Uploads
+    function forbiddenHandler(req, res, next) {
+        req.log.info('Method ' + req.method + ' disallowed for ' + req.url);
+        res.send(403);
+        next(false);
+    }
+    server.post({
+        path: '/:account/uploads',
+        name: 'CreateUpload',
+        contentType: 'application/json'
+    }, uploads.createHandler());
+
+    server.put({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+
+    /* JSSTYLED */
+    var uploadsRedirectPath = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}';
+    /* JSSTYLED */
+    var uploadsRedirectPathPart = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}/:partNum';
+    server.get({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.get({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/state',
+        name: 'GetUpload' //TODO add authaction?
+    }, uploads.getHandler());
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/state'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/abort',
+        name: 'AbortUpload' //TODO add authaction?
+    }, uploads.abortHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/commit',
+        name: 'CommitUpload', //TODO add authaction?
+        contentType: 'application/json'
+    }, uploads.commitHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+
     server.use(common.getMetadataHandler());
     server.use(auth.storageContext);
     server.use(auth.authorizationHandler());
@@ -303,6 +456,30 @@ function createServer(options, clearProxy) {
                common.assertMetadataHandler(),
                dir.getDirectoryHandler());
 
+    // /jhendricks/uploads/:prefix/:id/:partNum
+    //      - PUT
+    //      - HEAD
+    //      - Forbidden: GET/POST/DELETE
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/:partNum',
+        name: 'UploadPart', //TODO add authaction?
+        contentType: '*/*'
+    }, uploads.uploadPartHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+
+
     // Root dir
 
     server.get({
@@ -334,6 +511,14 @@ function createServer(options, clearProxy) {
         authAction: 'deletedirectory'
     }, dir.rootDirHandler());
 
+    // creates routes for everything in StoragePaths array
+    // put___directory
+    // put___link
+    // put___object
+    // options___storage
+    // get___storage
+    // head___storage
+    // delete___storage
     Object.keys(common.StoragePaths).forEach(function (k) {
 
         var _p = common.StoragePaths[k].regex;
diff --git a/lib/shark_client.js b/lib/shark_client.js
index 98db362..d65e320 100644
--- a/lib/shark_client.js
+++ b/lib/shark_client.js
@@ -55,8 +55,11 @@ util.inherits(SharkResponseError, Error);
 
 function _request(opts, cb) {
     cb = once(cb);
-
     var req = http.request(opts);
+
+    if (opts.body) {
+        req.write(JSON.stringify(opts.body));
+    }
     /*
      * This timer represents the timeout for connecting to the shark
      * for this request, so it is important that it is cleared only once
@@ -117,8 +120,9 @@ function _request(opts, cb) {
     });
 
     req.once('response', onResponse);
-    if (opts.method !== 'PUT')
+    if (opts.method !== 'PUT') {
         req.end();
+    }
 }
 
 
@@ -135,11 +139,19 @@ function request(thisp, method, opts, cb) {
         },
         hostname: thisp.hostname,
         method: method,
-        path: '/' + (opts.creator || opts.owner) + '/' + opts.objectId,
-        port: thisp.port,
-        requestId: opts.requestId
+        port: thisp.port
     };
 
+    if (!opts.path) {
+        _opts.path = '/' + (opts.creator || opts.owner) + '/' + opts.objectId;
+    } else {
+        _opts.path = opts.path;
+    }
+
+    if (opts.body) {
+        _opts.body = opts.body;
+    }
+
     log.debug(_opts, 'request: entered');
 
     // don't log this
@@ -227,7 +239,7 @@ util.inherits(SharkClient, EventEmitter);
 
 
 /**
- * Wraps up the restify http_client.get request.
+ * Wraps node's http request.
  *
  * Options needs:
  *   - objectId
@@ -251,7 +263,7 @@ SharkClient.prototype.get = function get(opts, cb) {
 
 
 /**
- * Wraps up the restify http_client.head request.
+ * Wraps node's http request.
  *
  * Options needs:
  *   - objectId
@@ -274,8 +286,8 @@ SharkClient.prototype.head = function head(opts, cb) {
 };
 
 
-/**
- * Wraps up the restify http_client.put request.
+/*
+ * Wraps up node's http request.
  *
  * Options needs:
  *   - contentLength
@@ -321,12 +333,39 @@ SharkClient.prototype.put = function put(opts, cb) {
 };
 
 
+/*
+ * Wraps up node's http request.
+ *
+ * Options needs:
+ *   - objectId
+ *   - contentType
+ *   - objectId
+ *   - owner
+ *   - requestId
+ *
+ * @param {object} options see above
+ * @param {body} JSON blob to send in POST request
+ * @param {function} callback => f(err, req)
+ */
+SharkClient.prototype.post = function post(opts, body, cb) {
+    assert.object(opts, 'options');
+    assert.object(body, 'body');
+    assert.string(opts.objectId, 'options.objectId');
+    assert.string(opts.owner, 'options.owner');
+    assert.string(opts.requestId, 'options.requestId');
+    assert.func(cb, 'callback');
+
+    opts.body = body;
+
+    request(this, 'POST', opts, cb);
+};
+
+
 SharkClient.prototype.toString = function toString() {
     return ('[object SharkClient<' + this.hostname + '>]');
 };
 
 
-
 ///--- Exports
 
 module.exports = {
diff --git a/lib/uploads/abort.js b/lib/uploads/abort.js
new file mode 100644
index 0000000..b7ee058
--- /dev/null
+++ b/lib/uploads/abort.js
@@ -0,0 +1,94 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var restify = require('restify');
+
+var uploadsCommon = require('./common');
+require('../errors');
+
+
+///--- API
+
+
+
+/*
+ * Ensures that the upload is in the correct state: either created or aborted,
+ * and updates the upload record's metadata if needed to reflect this state.
+ *
+ */
+function finalizingState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+
+    req.upload.uploadState(function (err, state, type) {
+        if (err) {
+            next(err);
+        } else {
+            var states = uploadsCommon.uploadStates;
+            var types = uploadsCommon.uploadTypes;
+
+            if (state === states.CREATED) {
+                assert.ok(!type);
+                upload.finalizeUploadRecord(types.ABORT, null, function (err2) {
+                        if (err2) {
+                            next(err2);
+                        } else {
+                            next();
+                        }
+                });
+            } else if ((state === states.FINALIZING) &&
+                (type === types.ABORT)) {
+
+                log.debug('abort already in progress for upload ' + upload.id);
+                next();
+
+            } else if ((state === states.FINALIZING) &&
+                (type === types.COMMIT)) {
+
+                log.debug('commit already in progress for upload ' + upload.id);
+                next(new MultipartUploadFinalizeConflictError(upload.id,
+                    types.COMMIT));
+
+            } else {
+                assert.fail('Invalid state/type combination for upload: '
+                    + state + '/' + type);
+            }
+        }
+    });
+}
+
+
+function abort(req, res, next) {
+    req.upload.abortUpload(function (err) {
+        if (err) {
+            next(err);
+        } else {
+            req.log.info('upload ' + req.upload.id + ' aborted');
+            res.setHeader('Content-Length', '0');
+            res.send(204);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    abortHandler: function abortHandler() {
+        var chain = [
+            uploadsCommon.setupUpload,
+            finalizingState,
+            abort
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/commit.js b/lib/uploads/commit.js
new file mode 100644
index 0000000..d6de480
--- /dev/null
+++ b/lib/uploads/commit.js
@@ -0,0 +1,430 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libuuid = require('libuuid');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+var verror = require('verror');
+
+var obj = require('../obj');
+var sharkClient = require('../shark_client');
+var uploadsCommon = require('./common');
+var utils = require('../utils');
+require('../errors');
+
+
+///--- Globals
+
+var clone = utils.shallowCopy;
+var sprintf = util.format;
+
+// 5 MB
+var MIN_PART_SIZE = 5252880;
+
+
+///--- Helpers
+
+/*
+ * Invokes the mako-finalize operation on a single shark.
+ *
+ * Parameters:
+ * - req the current request
+ * - body: body to POST to the shark
+ * - opts: an options blob to pass to the shark client
+ * - shark: a shark object
+ */
+function invokeMakoFinalize(req, body, opts, shark, cb) {
+    var client = sharkClient.getClient({
+        connectTimeout: req.sharkConfig.connectTimeout,
+        log: req.log,
+        retry: req.sharkConfig.retry,
+        shark: shark,
+        agent: req.sharkAgent
+    });
+    assert.ok(client, 'sharkClient returned null');
+
+    var start = Date.now();
+    var hostname = shark.manta_storage_id;
+
+    client.post(opts, body, function (err, _, res) {
+        /*
+         * Similar to PUTs, log information about sharks we contacted over
+         * the course of the commit request.
+         */
+        var sharkInfo = {
+            shark: hostname,
+            timeTotal: Date.now() - start,
+            result: 'fail',
+            _startTime: start
+        };
+        req.sharksContacted.push(sharkInfo);
+
+        var s = {
+            shark: hostname,
+            md5: null
+        };
+        if (err) {
+            cb(err, s);
+        } else {
+            s.md5 = res.headers['x-joyent-computed-content-md5'];
+            if (!s.md5) {
+                cb(new InternalError('mako failed to return an MD5 sum'), s);
+            } else {
+                sharkInfo.result = 'ok';
+                cb(null, s);
+            }
+        }
+    });
+}
+
+
+///--- API
+
+/*
+ * Ensures that the upload is in a proper state before proceeding: either
+ * CREATED or COMMIT. It it is in state COMMIT, the request must specify the
+ * same set of parts as is recorded in the upload record.
+ */
+function validateUploadState(req, res, next) {
+    var parts = req.body.parts;
+    var id = req.upload.id;
+
+    req.upload.uploadState(function (err, state, type) {
+        if (err) {
+            next(err);
+        } else {
+            var states = uploadsCommon.uploadStates;
+            var types = uploadsCommon.uploadTypes;
+
+            if (state === states.FINALIZING) {
+                if (type === types.ABORT) {
+                    // Abort already in progress
+                    next(new MultipartUploadAbortedError(id));
+
+                } else if (type === types.COMMIT) {
+                    // Not an error, but we need to verify the parts are the
+                    // same as the input ones before proceeding
+                    var p = req.upload.get(uploadsCommon.mdKeys.PARTS) || [];
+                    if (!jsprim.deepEqual(parts, p)) {
+                        next(new MultipartUploadCommitInProgessError(id));
+                    } else {
+                        next();
+                    }
+
+                } else {
+                    assert.fail('Invalid type: ' + type);
+                }
+            } else if (state === states.CREATED) {
+                next();
+            } else {
+                assert.fail('Invalid state: ' + state);
+            }
+        }
+    });
+}
+
+
+/*
+ * Ensures that the input parts set for the commit has the etags of the parts
+ * as they exist now. This step also checks that all parts have a size that
+ * exceeds the minimum part size (excluding the last part).
+ */
+function validateParts(req, res, next) {
+    var log = req.log;
+    var parts = req.body.parts;
+    log.info('validating parts for upload');
+
+    if (!parts) {
+        req.body.parts = [];
+        log.info('empty parts array');
+        next();
+        return;
+    } else if (parts.length > 10000) {
+        next(new MultipartUploadPartLimitError(req.upload.id, parts.length));
+        return;
+    }
+
+    var errors = [];
+    var sum = 0;
+
+    /*
+     * This function verifies that:
+     * - the etag exists
+     * - the etag matches the current etag for the part
+     * - the size of the part is at least the minimum size, unless
+     *   it's the last part
+     */
+    function validateEtag(part, cb) {
+        var index = part.index;
+        var etag = part.etag;
+
+        if (index !== 0) {
+            var record = req.upload.uploadMd;
+            var key = record.key + '/' + index;
+            var id = req.upload.id;
+
+            if (etag === '') {
+                cb(new MultipartUploadMissingPartError(id, index));
+                return;
+            }
+
+            req.moray.client.getObject(record.bucket, key, function (err, md) {
+                log.info('part index: ' + index + ', etag: ' + etag);
+
+                if (err) {
+                    errors.push(err);
+                } else {
+                    var size = parseInt(md.value.contentLength, 10);
+                    var isFinalPart = index === (parts.length - 1);
+
+                    if (md.value.etag !== etag) {
+                        errors.push(new MultipartUploadPartEtagError(id, index,
+                            etag));
+                    } else if (!isFinalPart && (size < MIN_PART_SIZE)) {
+                        errors.push(new MultipartUploadPartSizeError(id, index,
+                            size));
+                    }
+
+                    sum += size;
+                    cb();
+                }
+            });
+        } else {
+            // Skip part 0
+            cb();
+        }
+    }
+
+    var queue = vasync.queue(validateEtag, 10);
+    parts.forEach(function (val, i) {
+        queue.push({
+            index: i,
+            etag: val
+        });
+    });
+    queue.close();
+
+    queue.on('end', function () {
+        log.info('part validation completed');
+        if (errors.length > 0) {
+
+            // Even if there's an internal error, still send the user any uesr
+            // errors, so they can be corrected and retried.
+            for (var i = 0; i < errors.length; i++) {
+                var e = errors[i];
+                if (e.statusCode >= 500) {
+                    log.error('internal error: ' + e);
+                } else if (e.statusCode >= 400) {
+                    next(e);
+                    return;
+                } else {
+                    assert.fail('invalid error: ' + e);
+                }
+            }
+
+            next(new InternalError('commit error'));
+
+        } else {
+            if (sum > obj.DEF_MAX_LEN) {
+                next(new MaxContentLengthError(sum));
+            } else {
+                req.upload.checkSize(sum, function (valid, expected) {
+                    if (!valid) {
+                        next(new MultipartUploadContentLengthError(expected,
+                            sum));
+                    } else {
+                        req.upload._size = sum;
+                        next();
+                    }
+                });
+            }
+        }
+    });
+}
+
+
+/*
+ * Saves the upload record with its state set to FINALIZING.
+ */
+function finalizingState(req, res, next) {
+    req.upload.finalizeUploadRecord(
+        uploadsCommon.uploadTypes.COMMIT,
+        req.body.parts,
+        function (err) {
+            if (err) {
+                next(err);
+            } else {
+                next();
+            }
+    });
+}
+
+
+/*
+ * Invokes the mako-finalize operation on each shark selected at the beginning
+ * of the upload. If there is a problem with any of the sharks, this operation
+ * will fail.
+ *
+ * The mako node expects a JSON blob of the form:
+ * {
+ *      version,        // the version of multipart upload this is
+ *      owner,          // string uuid of the owner of the upload object
+ *      nbytes,         // expected size of the object
+ *      objectId,       // string uuid of object
+ *      parts,          // array of string uuids for each part
+ * }
+ *
+ * This handler is also expected to set the following on the uploads object:
+ *  - contentMD5
+ *  - objectId (if it does not exist yet)
+ */
+function finalizeUpload(req, res, next) {
+    var log = req.log;
+
+    var objectId = req.upload.get(uploadsCommon.mdKeys.OBJECT_ID);
+    var sharks = req.upload.get(uploadsCommon.mdKeys.SHARKS);
+    var nbytes = req.upload._size;
+
+    // Skip mako-finalize for zero-byte uploads.
+    if (nbytes === 0) {
+        log.info('zero-byte object; skipping mako-finalize');
+        req.upload._md5 = '1B2M2Y8AsgTpgAmY7PhCfg==';
+        req.upload._size = 0;
+        next();
+        return;
+    }
+
+
+    req.body.parts.splice(0, 1);
+    var body = {
+        version: 1,
+        nbytes: nbytes,
+        account: req.owner.account.uuid,
+        objectId: objectId,
+        parts: req.body.parts
+    };
+    log.info('mako request body: ' + JSON.stringify(body));
+
+    var opts = {
+        objectId: objectId,
+        owner: req.owner.account.uuid,
+        requestId: req.getId(),
+        path: '/mpu/v1/commit'
+    };
+
+    req.sharksContacted = [];
+
+    vasync.forEachParallel({
+        func: function finalize(shark, cb) {
+            var _opts = clone(opts);
+            var _body = clone(body);
+            invokeMakoFinalize(req, _body, _opts, shark, cb);
+        },
+        inputs: sharks
+    },  function (err, results) {
+            log.info('mako-finalize: completed on all sharks');
+
+            if (err) {
+                results.operations.forEach(function (r) {
+                    log.error('error with shark ' + r.result.shark +
+                        ': ' + r.err);
+                });
+                // TODO: maybe this should be a new type of error.
+                next(new SharksExhaustedError());
+            } else {
+                var md5 = null;
+
+                // Validate that all makos returned the same md5 sum.
+                var mismatch = false;
+                results.operations.forEach(function (r) {
+                    assert.ok(r.status === 'ok');
+                    assert.ok(r.result);
+
+                    if (md5 && (md5 !== r.result.md5)) {
+                        mismatch = true;
+                    } else {
+                        md5 = r.result.md5;
+                    }
+                });
+
+                if (mismatch) {
+                    log.error('mako nodes returned different md5 sums for ' +
+                        'the same object');
+                    results.forEach(function (r) {
+                        log.error(sprintf('shark \"%s\", md5: %s',
+                            r.result.shark, r.result.md5));
+                    });
+
+                    next(new InternalError());
+                } else {
+                    // Validate user-provided md5 sums.
+                    req.upload.checkMD5(md5, function (valid, expected) {
+                        if (!valid) {
+                            next(new ChecksumError(expected, md5));
+                        } else {
+                            req.upload._md5 = md5;
+                            next();
+                        }
+                    });
+                }
+            }
+    });
+}
+
+
+/*
+ * This step makes the committed upload visible from Manta by atomically
+ * inserting a commit record and object record on the shard associated
+ * with the object. Most of the heavy lifting is done by the req.uploads
+ * object here.
+ */
+function commit(req, res, next) {
+    var size = req.upload._size;
+    var md5 = req.upload._md5;
+
+    assert.number(size);
+    assert.string(md5);
+
+    req.upload.commitUpload(req.body.parts, size, md5, function (err) {
+        if (err) {
+            next(err);
+        } else {
+            res.setHeader('Location',
+                req.upload.get(uploadsCommon.mdKeys.OBJECT_PATH));
+            res.send(201);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+//TODO: use something like getMetadata to make sure object path is valid.
+module.exports = {
+    commitHandler: function commitHandler() {
+        var chain = [
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 100000
+            }),
+            uploadsCommon.setupUpload,
+            validateUploadState,
+            validateParts,
+            finalizingState,
+            finalizeUpload,
+            commit
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/common.js b/lib/uploads/common.js
new file mode 100644
index 0000000..9e77984
--- /dev/null
+++ b/lib/uploads/common.js
@@ -0,0 +1,1082 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var util = require('util');
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libmanta = require('libmanta');
+var libuuid = require('libuuid');
+var path = require('path');
+var verror = require('verror');
+
+var common = require('../common');
+var obj = require('../obj');
+require('../errors');
+
+
+/*
+ *  This file contains the majority of the logic for handling multipart uploads.
+ *
+ *
+ *  API OVERVIEW:
+ *
+ *  The Manta multipart upload API allows clients to upload a Manta object
+ *  by splitting it into parts and uploading the parts individually. When all
+ *  parts are uploaded, the client signifies that the upload is completed by
+ *  "committing" the upload through the API, which creates a Manta object
+ *  that is the sum of the uploaded parts and is indistiguisable from an
+ *  object created through a normal Manta PUT. If a client decides not to
+ *  finish the upload, it may also abort the upload process.
+ *
+ *  The possible operations in the mulitpart upload API are:
+ *      - create: establish a multipart upload
+ *      - upload-part: upload a part of the object
+ *      - abort: cancel the upload
+ *      - commit: complete the upload
+ *      - get: get information about an ongoing upload
+ *
+ *  There is an additional API endpoint designed for client usability purposes
+ *  that redirects all requests sent to the path /:account/upload/:id to the
+ *  correct upload path.
+ *
+ *
+ *  TERMS:
+ *
+ *  There is some terminology that is used consistently throughout the
+ *  multipart upload implementation that is useful to know:
+ *
+ *   - Upload ID: a uuid representing a multipart upload request, selected
+ *     when the upload is created.
+ *
+ *   - Upload path: The path where parts of an upload are uploaded to and
+ *     stored in Manta.
+ *
+ *   - Upload record: The Manta directory record for the upload path. This
+ *     record contains state about the upload recording in an additional
+ *     "upload" blob tacked onto the record. The upload record gives us a
+ *     mechanism of passing state about an upload across various upload
+ *     requests.
+ *
+ *   - Object path: An input to creating an upload, this refers to the path
+ *     the object (created from the uploaded parts) will be stored at in
+ *     Manta.
+ *
+ *   - Object record: The Manta object record for the upload's object path.
+ *
+ *   - Finalizing record: A Manta record (stored in a different
+ *     bucket than object and directory metadata -- namely, "manta_uploads")
+ *     and on the same shard as the object record. This upload is identified
+ *     by both the object path and upload ID (both of which are used to
+ *     construct the key used to insert the record into Moray). The presence of
+ *     a finalizing record for a given object path and upload id indicates that
+ *     either a commit or abort has begun for the upload. The finalizing record
+ *     stores which type the record is, the upload ID and the etags for the
+ *     parts.
+ *
+ *
+ *  METADATA STRUCTURE:
+ *
+ *  Because most of the state about an upload is stored in metadata records in
+ *  Moray, it is important to have a well-defined structure for what this
+ *  information looks like.
+ *
+ *   - Upload record: This record has the same structure as a typical Manta
+ *     directory record, with an additional object called "upload" that has
+ *     the following structure:
+ *
+ *          upload {
+ *              id,             // upload id
+ *              state,          // state of the upload: CREATED or FINALIZING
+ *              type,           // if state is FINALIZING, then ABORT or COMMIT
+ *              objectPath,     // object path
+ *              uploadPath,     // upload path
+ *              headers,        // headers to store on object record
+ *              sharks,         // mako sharks the object is stored on
+ *              parts,          // when commit has started, etags of each part
+ *              objectId        // object ID for the uploaded object
+ *          }
+ *
+ *    - Finalizing record: This record has the same structure as a typical Manta
+ *     directory record, with an additional object called "upload" that has
+ *     the following structure:
+ *          upload {
+ *              id,             // upload id
+ *              type,           // ABORT or COMMIT
+ *              parts,          // when type is COMMIT, etags of each part
+ *              objectPath      // object path
+ *          }
+ *
+ *    - Object record: The object record is a normal Manta object record, but
+ *      there are a few fields on the object that are set explitily by the
+ *      multipart upload code, instead of the common metadata code.
+ *
+ *      In particular, the following fields are set explicitly:
+ *        - objectId: This is generated when the object is created and is
+ *          needed for mako-finalize.
+ *        - contentLength: This is set either by the user when creating the
+ *          upload (and validated by the commit endpoint), or it is
+ *          calculated on commit.
+ *        - contentMD5: This is set either by the user when creating the
+ *          upload (and validated by the commit endpoint), or it is
+ *          calculated on commit.
+ *        - contentMD5: This is set either by the user when creating the
+ *          upload, or set to a default value.
+ *        - headers: This is set by the user when creating the upload.
+ *        - sharks: These are selected when the upload is created.
+ *
+ *
+ *  IMPLEMENTATION DETAILS:
+ *
+ *  The logic of this API is implemented as methods on the MultipartUpload
+ *  object defined in this file. When a multipart upload related request comes
+ *  in to muskie, a new MultipartUpload request is constructed, and sets up
+ *  some state the various handlers will need.
+ *
+ *  After an upload's creation, most of the state about the upload is stored in
+ *  the upload record. After validating inputs to a request, the first thing a
+ *  multipart upload API endpoint should do is call the method uploadState(),
+ *  which will load the upload record from Moray and allow the handlers to
+ *  fetch state from the record using the get() method, and modify the record
+ *  using the set() method.
+ *
+ *  Once the API handlers have completed the relevant logic based on the
+ *  upload's state, they each call a relevant method on the upload object
+ *  ({create,abort,commit,get}Upload()). These methods take care of saving
+ *  the upload record back to Moray, and perform any additional metadata
+ *  transformations as needed.
+ *
+ */
+
+
+///--- Globals
+
+var sprintf = util.format;
+
+var ID_REGEX = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
+var PREFIX_LENGTH = 1;
+
+// Upload states
+var states = {
+    CREATED: 'created',
+    FINALIZING: 'finalizing'
+};
+
+// Finalizing types
+var types = {
+    COMMIT: 'commit',
+    ABORT: 'abort'
+};
+
+// Used to lookup values in a loaded upload record
+var mdKeys = {
+    STATE: 'state',
+    TYPE: 'type',
+    OBJECT_PATH: 'objectPath',
+    HEADERS: 'headers',
+    SHARKS: 'sharks',
+    PARTS: 'parts',
+    OBJECT_ID: 'objectId'
+};
+
+
+
+///--- Helpers
+
+/*
+ * Creates the upload record for the upload path.
+ * (e.g., /jhendricks/uploads/c/c46ac2b1-fcc3-4e12-8c46-c935808ed59f)
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - opts: options blob that must have the following items:
+ *      - objectPath
+ *      - sharks
+ *      - headers
+ *  - cb: function that is passed an error and the metadata blob
+ */
+function createUploadRecord(upload, opts, cb) {
+    assert.object(opts);
+    assert.string(opts.objectPath);
+    assert.object(opts.sharks);
+    assert.object(opts.headers);
+    assert.string(upload.uploadPath);
+    assert.string(upload.id);
+    assert.func(cb);
+
+    var req = upload.req;
+
+    /*
+     * createMetadata assumes that the key for the metadata it should create
+     * is saved in req.key, which is true for most requests. In this case,
+     * we save the key stored in req.key (which corresponds to the path
+     * /:account/uploads, instead of the upload record key) and restore it
+     * after the metadata is created. This is a bit janky, but allows us to
+     * reuse existing code to create metadata for directories much more
+     * easily.
+     */
+    var savedKey = req.key;
+    assert.ok(upload.uploadMd.key);
+    req.key = upload.uploadMd.key;
+
+    common.createMetadata(req, 'directory', function (err, md) {
+        req.key = savedKey;
+
+        if (err) {
+            cb(err);
+        } else {
+            //md._etag = null;
+            md.upload = {
+                id: upload.id,
+                state: states.CREATED,
+                type: null,  // used only for finalizing uploads
+                objectPath: opts.objectPath,
+                uploadPath: upload.uploadPath,
+                headers: opts.headers,
+                sharks: opts.sharks,
+                parts: null, // used only for commits
+                objectId: libuuid.create()
+            };
+
+            cb(null, md);
+        }
+    });
+}
+
+/*
+ * Creates the metadata for the finalizing record for the upload, for both
+ * commit and aborts.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - type: finalizing type
+ *  - parts: if a commit, array of etags representing the parts
+ *  - cb: function that is passed the metadata blob
+ */
+function createFinalizingRecord(upload, type, parts, cb) {
+    assert.ok(type === types.COMMIT || type === types.ABORT);
+    assert.func(cb);
+
+    var req = upload.req;
+
+    var md = {
+        key: upload.constructKey(),
+        headers: {},
+        mtime: Date.now(),
+        owner: req.owner.account.uuid,
+        requestId: req.getId(),
+        roles: [],
+        type: 'finalizing',
+        _etag: null,
+
+        upload: {
+            id: upload.id,
+            type: type,
+            parts: parts,
+            objectPath: upload.get(mdKeys.OBJECT_PATH)
+        }
+    };
+
+    if (type === type.COMMIT) {
+        md.upload.parts = parts;
+    }
+
+    cb(md);
+}
+
+
+/*
+ * Creates the object record.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - size: size of the object
+ *  - md5: md5 sum (calculated in mako-finalize)
+ *  - cb: function that is passed an error and the metadata blob
+ */
+
+function createObjectRecord(upload, size, md5, cb) {
+    var req = upload.req;
+    var objPath = upload.get(mdKeys.OBJECT_PATH);
+
+    normalize(upload.req, objPath, function (err, objKey) {
+        if (err) {
+            cb(err);
+        } else {
+            //TODO: comment
+            var savedKey = req.key;
+            var savedHeaders = req.headers;
+
+            req.key = objKey;
+            req.headers = upload.get(mdKeys.HEADERS);
+            req.query.metadata = null;
+
+            common.createMetadata(req, 'object', function (err2, md) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    req.key = savedKey;
+                    req.headers = savedHeaders;
+
+                    // createMetadata does most of the work for us here, but
+                    // a few values need to be overriden.
+                    md.objectId = upload.get(mdKeys.OBJECT_ID);
+                    md.contentLength = size;
+                    md.contentMD5 = md5;
+
+                    var ct = upload.get(mdKeys.HEADERS)['content-type'];
+                    if (ct) {
+                        md.contentType = ct;
+                    } else {
+                        md.contentType = 'application/octet-stream';
+                    }
+
+                    md.sharks = upload.get(mdKeys.SHARKS);
+                    //TODO: _etag.
+
+                    cb(null, md);
+                }
+            });
+        }
+    });
+}
+
+
+/*
+ * Saves the upload record to moray with the given state and type.
+ *
+ * Parameters:
+ *  - upload: MultipartUpload object
+ *  - state: upload state
+ *  - type: if applicable, finalizing type
+ *  - cb: function
+ */
+function persistUploadRecord(upload, state, type, cb) {
+    assert.ok(state === states.CREATED || state === states.FINALIZING);
+    assert.func(cb);
+    if (state === states.CREATED) {
+        assert.ok(!type);
+    } else {
+        assert.ok(type === types.COMMIT || type === types.ABORT);
+    }
+    assert.ok(upload.uploadMd.toSave, 'no upload record to save');
+
+    upload.set(mdKeys.STATE, state);
+    upload.set(mdKeys.TYPE, type);
+    saveMetadata(upload.req, upload.uploadMd, cb);
+}
+
+
+/*
+ * Loads the upload record, saves a copy of it, and creates a new
+ * copy that can be modified throughout the request.
+ */
+function loadUploadRecord(upload, cb) {
+    var record = upload.uploadMd;
+    loadMetadata(upload.req, record, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            assert.ok(record.loaded);
+            assert.ok(record.loaded.upload);
+
+            record.toSave = jsprim.deepCopy(record.loaded);
+
+            cb(null, record.loaded.upload);
+        }
+    });
+}
+
+/*
+ * Loads the finalizing record.
+ */
+function loadFinalizingMetadata(upload, cb) {
+    var record = upload.finalizingMd;
+    function load(u, key, r, lcb) {
+        assert.ok(key, 'key');
+
+        r.key = key;
+        loadMetadata(u.req, record, function (err) {
+            if (err) {
+                lcb(err);
+            } else {
+                assert.ok(record.loaded);
+                assert.ok(record.loaded.upload);
+                assert.ok(record.loaded.upload.type);
+
+                lcb(null, record.loaded.upload);
+            }
+        });
+    }
+
+    var k = upload._objectPathKey;
+    if (!k) {
+        var o = upload.get(mdKeys.OBJECT_PATH);
+        assert.ok(o, 'no object path found');
+        normalize(upload.req, o, function (err, key) {
+            if (err)  {
+                cb(err);
+            } else {
+                upload._objectPathKey = key;
+                load(upload, upload.constructKey(), record, cb);
+            }
+        });
+    } else {
+        load(upload, upload.constructKey(), record, cb);
+    }
+}
+
+
+/*
+ * Saves the metadata located in the input record object at record.toSave.
+ * The record object should be of the form:
+ *      {
+ *          key,        // moray key
+ *          bucket,     // moray bucket
+ *          loaded,     // loaded metadata for this record (not used here)
+ *          toSave      // metadata to save
+ *      }
+ */
+function saveMetadata(req, record, cb) {
+    var log = req.log;
+    var bucket = record.bucket;
+    var md = record.toSave;
+
+
+    var etag = null;
+    if (record.loaded) {
+        etag = record.loaded._etag;
+    }
+
+    var opts = {
+        req_id: req.getId(),
+        etag: etag
+    };
+    log.info('opts: ' + opts);
+
+    req.moray.client.putObject(bucket, md.key, md, opts, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            cb();
+        }
+    });
+}
+
+
+/*
+ * Loads the metadata located in the input record object into record.loaded.
+ * The record object should be of the form:
+ *      {
+ *          key,        // moray key
+ *          bucket,     // moray bucket
+ *          loaded,     // pointer to the loaded metadata once this completes
+ *          toSave      // metadata to save (not used here)
+ *      }
+ */
+function loadMetadata(req, record, cb) {
+    var log = req.log;
+
+    var bucket = record.bucket;
+    var key = record.key;
+
+    req.moray.client.getObject(bucket, key, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+                assert.ok(md.value);
+                // md.value here is the actual metadata
+                assert.ok(md.value.upload);
+
+                log.info('loaded metadata: ' + JSON.stringify(md));
+                record.loaded = md.value;
+                cb();
+        }
+    });
+}
+
+
+// Normalizes a path in Manta.
+function normalize(req, mPath, cb) {
+    var opts = {
+        account: req.owner.account,
+        path: mPath
+    };
+
+    libmanta.normalizeMantaPath(opts, function (err, p) {
+        if (err) {
+            req.log.debug({
+                url: path,
+                err: err
+            }, 'failed to normalize URL');
+            cb(err);
+        } else {
+            cb(null, p);
+        }
+    });
+}
+
+
+/*
+ * Given an upload ID, returns the prefix to use for the parent directory
+ * of the upload directory. For now, this is the just the first character of
+ * the upload uuid, but we may want to use more characters later to allow for
+ * more simulataneous uploads.
+ *
+ * For example, for the input id '0bb83e47-32df-4833-a6fd-94d77e8c7dd3' and a
+ * prefix length of 1, this function will return '0'.
+ */
+function idToPrefix(id) {
+    assert.string(id);
+    assert.ok(id.match(ID_REGEX));
+
+    return (id.substring(0, PREFIX_LENGTH));
+}
+
+
+///--- Routes
+
+function setupUpload(req, res, next) {
+    var id = req.params.id;
+    req.upload = new MultipartUpload(req, id);
+
+    next();
+}
+
+
+///--- API
+
+/*
+ * Constructor for the MultipartUpload object, which is instantiated at
+ * the beginning of each multipart upload related request and attached to the
+ * request object at `req.upload`.
+ *
+ * The inputs to the constructor are:
+ *      - id, the upload uuid
+ *      - req, the request object for this multipart upload related request
+ *
+ *
+ * The structure of this object is as follows:
+ *
+ * {
+ *    id,                     // upload uuid
+ *    req,                    // pointer to the request this upload is for
+ *    uploadPath,             // upload path
+ *
+ *
+ *    // Private fields used to share state across a specific upload request.
+ *    // They aren't always used or set.
+ *    _headers,
+ *    _size,
+ *    _copies,
+ *    _md5,
+ *
+ *
+ *    // These objects represent some of the relevant metadata for the upload.
+ *
+ *    // When an upload or finalizing record is first loaded during a request,
+ *    // it is saved on the MultipartUpload object at
+ *    // `{upload,finalizing}Md.loaded`. Changes to metadata are made in a copy
+ *    // of the metadata that is saved at {upload,finalizing}Md.toSave. The
+ *    // saveMetadata and loadMetadata functions expect this.
+ *
+ *    // Additionally, each object contains the moray bucket and the key
+ *    // for the metadata record it represents.
+ *
+ *    uploadMd {          // upload record metadata object
+ *        key,            // normalized uploadPath
+ *        bucket,         // bucket for upload records (normal manta records)
+ *        loaded {        // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    },
+ *
+ *    finalizingMd {      // finalizing record metadata object
+ *        key,            // normalized objectPath
+ *        bucket,         // bucket for finalizing records
+ *        loaded,         // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    }
+ * }
+ *
+ */
+function MultipartUpload(req, id) {
+    var self = this;
+    self.id = id;
+    self.req = req;
+    self.uploadPath = '/' + req.owner.account.login + '/uploads/' +
+        idToPrefix(id) + '/' + id;
+
+    self._headers = null;
+    self._size = null;
+    self._copies = null;
+    self._md5 = null;
+
+    self.uploadMd = {
+        key: null,
+        bucket: 'manta',
+        records: {
+            loaded: null,
+            toSave: null
+        }
+    };
+
+    normalize(req, self.uploadPath, function (err, p) {
+        if (err) {
+            throw (new InvalidPathError(self.uploadPath));
+        } else {
+            self.uploadMd.key = p;
+            req.log.info('upload path key: ' + self.uploadMd.key);
+        }
+    });
+
+    self.finalizingMd = {
+        key: null,
+        bucket: 'manta_uploads',
+        records: {
+            loaded: null,
+            toSave: null
+        }
+    };
+
+    return (self);
+}
+
+
+///--- Create
+
+/*
+ * Creates the multipart upload by creating the upload record and inserting
+ * it into Moray.
+ *
+ * Parameters:
+ *  - opts: options blob that expects:
+ *      - objectPath
+ *      - sharks: array of shark objects returned from the picker
+ *      - headers: user-specified headers object (or an empty object)
+ */
+MultipartUpload.prototype.createUpload = function createUpload(opts, cb) {
+    assert.func(cb);
+    assert.string(opts.objectPath);
+    assert.ok(opts.sharks);
+    assert.object(opts.headers);
+
+    var self = this;
+
+    self.objectPath = opts.objectPath;
+    createUploadRecord(self, opts, function (err, uploadMd) {
+        if (err) {
+            cb(err);
+        } else {
+                    /* BEGIN JSSTYLED */
+                    /* if (exists) {
+                        uploadMd.etag = upload.etag;
+                    } else {
+                        uploadMd.etag = null;
+                    } */
+                    /* END JSSTYLED */
+
+            self.uploadMd.toSave = uploadMd;
+            persistUploadRecord(self, states.CREATED, null, function (err2) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    cb(null, self.uploadPath);
+                }
+            });
+        }
+    });
+};
+
+
+
+
+/*
+ * Aborts an upload.
+ *
+ * First validates that no commit record exists for the upload, then inserts
+ * an abort record for the upload on the object shard.
+ */
+MultipartUpload.prototype.abortUpload = function abortUpload(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    self.finalizingRecordExists(function (err, exists, upload) {
+        if (err) {
+            cb(err);
+        } else if (exists) {
+            // This is only an error if the record isn't an abort record.
+            var type = self.finalizingMd.loaded.upload.type;
+            if (type === types.ABORT) {
+                log.info('abort record exists for upload ' + self.id);
+                cb();
+            } else {
+                cb(new MultipartUploadFinalizeConflictError(upload.id,
+                    types.ABORT));
+            }
+
+        } else {
+            log.info('upload ' + self.id + ' has no finalizing record yet');
+            createFinalizingRecord(self, types.ABORT, null, function (md) {
+                var record = self.finalizingMd;
+                record.toSave = md;
+
+                var opts = {
+                    req_id: self.req.getId(),
+                    etag: null
+                };
+
+                self.req.log.info('saving finalizing record: ' + md);
+                self.req.moray.client.putObject(record.bucket,
+                    record.key, record.toSave, opts, function (err2) {
+                    if (err2) {
+                        //TODO handle EtagConflictError?
+                        cb(err2);
+                    } else {
+                        cb();
+                    }
+                });
+            });
+        }
+    });
+};
+
+
+/*
+ * Commits an upload.
+ *
+ * First checks for the existence of a finalizing record, then saves the
+ * upload record as finalizing, and atomically inserts a commit record
+ * and object record on the object's shard.
+ */
+MultipartUpload.prototype.commitUpload =
+function commitUpload(partsArr, size, md5, cb) {
+    assert.ok(partsArr);
+    assert.number(size);
+    assert.string(md5);
+    assert.func(cb);
+
+    var log = this.req.log;
+    var self = this;
+
+    self.finalizingRecordExists(function (err, exists, upload) {
+        if (err) {
+            cb(err);
+        } else if (exists) {
+            // This is valid only for a commit record with matching parts.
+            var type = self.finalizingMd.loaded.upload.type;
+            if (type === types.ABORT) {
+                cb(new MultipartUploadFinalizeConflictError(upload.id,
+                    types.ABORT));
+            } else {
+                if (!jsprim.deepEqual(upload.parts, partsArr)) {
+                    cb(new MultipartUploadFinalizeConflictError(self.id,
+                        types.COMMIT));
+                } else {
+                    log.info('valid commit record already exists for upload ' +
+                        self.id);
+                    cb();
+                }
+            }
+        } else {
+            createObjectRecord(self, size, md5, function (err2, objectMd) {
+                if (err2) {
+                    cb(err2);
+                } else {
+                    createFinalizingRecord(self, types.COMMIT, partsArr,
+                    function (finalizingMd) {
+                        var batch = [ {
+                            bucket: self.finalizingMd.bucket,
+                            key: self.finalizingMd.key,
+                            value: finalizingMd,
+                            operation: 'put',
+                            opts: {
+                                req_id: self.req.getId(),
+                                etag: null
+                            }
+                        }, {
+                            bucket: self.uploadMd.bucket,
+                            key: self.constructKey(),
+                            value: objectMd,
+                            operation: 'put'
+                        } ];
+                        var opts = {
+                            req_id: self.req.getId()
+                        };
+
+                        log.info('batch created: '  + JSON.stringify(batch));
+                        self.req.moray.client.batch(batch, opts,
+                        function (err3, meta) {
+                            if (err3) {
+                                log.error('error batching data: ' + err);
+                                cb(err3);
+                            } else {
+                                log.info('batch successful');
+                                 cb();
+                            }
+                        });
+                    });
+                }
+            });
+        }
+    });
+};
+
+//--- Get
+/*
+ * Returns a object representation of the upload that can be serialized as JSON
+ * and sent to the client.
+ */
+MultipartUpload.prototype.getUpload = function getUpload(cb) {
+    var self = this;
+    loadUploadRecord(self, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+            //XXX: Other useful things to include here?
+            var upload = {
+                id: self.id,
+                uploadPath: self.uploadPath,
+                objectPath: md.objectPath,
+                state: md.state,
+                // TODO: this is useful for debugging, but it may be something
+                // we don't want to expose to outside clients.
+                sharks: md.sharks,
+                headers: md.headers,
+                copies: md.copies
+            };
+
+            if (md.type === types.FINALIZING) {
+                upload.type = md.type;
+                upload.parts = md.parts;
+            }
+
+            if (md.contentMD5 !== '') {
+                upload.contentMD5 = md.contentMD5;
+            }
+
+            //cb(null, upload);
+            cb(null, md);
+        }
+    });
+};
+
+
+///--- Common methods for API endpoints
+
+/*
+ * Loads the metadata for the upload and returns its current state
+ * and finalizing type, if applicable.
+ */
+MultipartUpload.prototype.uploadState = function uploadState(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    loadUploadRecord(self, function (err, upload) {
+        if (err) {
+            cb(err);
+        } else {
+            log.info(sprintf('loaded upload record for %s: state %s',
+                self.id, upload.state));
+            cb(null, upload.state, upload.type);
+        }
+    });
+};
+
+
+/*
+ * Attemtps to load the upload's upload record, and if it exists,
+ * passes the callback the record.
+ */
+MultipartUpload.prototype.uploadRecordExists = function uploadRecordExists(cb) {
+    loadUploadRecord(this, function (err, upload) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                cb(null, false);
+            } else {
+                cb(err);
+            }
+        } else {
+            cb(null, true, upload);
+        }
+    });
+};
+
+
+/*
+ * Attemtps to load the upload's finalizing record, and if it exists,
+ * passes the callback the record. This is useful for both committing
+ * and aborting uploads.
+ */
+MultipartUpload.prototype.finalizingRecordExists =
+function finalizingRecordExists(cb) {
+    loadFinalizingMetadata(this, function (err, upload) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                cb(null, false);
+            } else {
+                cb(err);
+            }
+        } else {
+            cb(null, true, upload);
+        }
+    });
+};
+
+
+/*
+ * Saves the upload record with state set to FINALIZING.
+ *
+ * Parameters:
+ *  - type: finalizing type
+ *  - parts: if a commit, array of etags representing the parts
+ *  - cb: function
+ */
+MultipartUpload.prototype.finalizeUploadRecord =
+function finalizeUploadRecord(type, parts, cb) {
+    assert.ok(type === types.COMMIT || type === types.ABORT);
+    assert.ok(this.uploadMd.loaded, 'upload record not loaded');
+
+    this.set(mdKeys.PARTS, parts);
+    persistUploadRecord(this, states.FINALIZING, type, cb);
+};
+
+
+/*
+ * Used by API handlers to set an item in the upload record.
+ * The input key should be one of the keys specifeid in mdKeys.
+ */
+MultipartUpload.prototype.set = function set(k, v) {
+    assert.ok(this.uploadMd.toSave);
+
+    this.uploadMd.toSave.upload[k] = v;
+};
+
+
+/*
+ * Looks up a value in the loaded upload record.
+ */
+MultipartUpload.prototype.get = function get(k) {
+    assert.ok(this.uploadMd.loaded);
+
+    return (this.uploadMd.loaded.upload[k]);
+};
+
+
+/*
+ * Returns the size of the object if specifed on create, or a default value.
+ */
+MultipartUpload.prototype.uploadSize = function uploadSize() {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    var size = parseInt((u.headers['content-length'] || obj.DEF_MAX_LEN), 10);
+    assert.ok(size >= 0);
+
+    return (size);
+};
+
+
+/*
+ * Verifies that if a size was specified on create, the input expected value
+ * matches this size.
+ */
+MultipartUpload.prototype.checkSize = function checkSize(expected, cb) {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    if (!u.headers['content-length']) {
+        cb(true);
+    } else {
+        var size = parseInt(u.headers['content-length'], 10);
+        assert.ok(size >= 0);
+        if (size !== expected) {
+            cb(false, size);
+        } else {
+            cb(true);
+        }
+    }
+};
+
+/*
+ * Verifies that if an md5 was specified on create, the input expected value
+ * matches this md5.
+ */
+MultipartUpload.prototype.checkMD5 = function checkMD5(expected, cb) {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    var md5 = u.headers['content-md5'];
+
+    if (!md5) {
+        cb(true);
+    } else {
+        if (md5 !== expected) {
+            cb(false, md5);
+        } else {
+            cb(true);
+        }
+    }
+};
+
+
+/*
+ * Returns the number of sharks selected for this upload on create.
+ */
+MultipartUpload.prototype.numSharks = function numSharks() {
+    assert.ok(this.uploadMd.loaded);
+    var u = this.uploadMd.loaded.upload;
+    assert.ok(u);
+
+    return (u.sharks.length);
+};
+
+
+/*
+ * Used to create the key for the batch request to moray on commit.
+ * The key is of the form: <upload id>:<object path>
+ */
+MultipartUpload.prototype.constructKey = function constructKey() {
+    var o = this._objectPathKey;
+    assert.ok(o);
+
+    var key = this.id + ':' + o;
+    this.req.log.info('key: ' + key);
+    return (key);
+};
+
+
+// Returns the key for the upload path (for use in Moray).
+MultipartUpload.prototype.uploadPathKey = function uploadPathKey() {
+    var k = null;
+    if (this.uploadMd) {
+        k = this.uploadMd.key;
+    }
+    assert.ok(k);
+    return (k);
+};
+
+
+///--- Exports
+
+module.exports = {
+
+    ID_REGEX: ID_REGEX,
+
+    mdKeys: mdKeys,
+    uploadStates: states,
+    uploadTypes: types,
+
+    MultipartUpload: MultipartUpload,
+
+    setupUpload: setupUpload
+};
diff --git a/lib/uploads/create.js b/lib/uploads/create.js
new file mode 100644
index 0000000..7953ec7
--- /dev/null
+++ b/lib/uploads/create.js
@@ -0,0 +1,225 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var libmanta = require('libmanta');
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+var verror = require('verror');
+
+var sprintf = util.format;
+
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+require('../errors');
+
+
+///--- Helpers
+
+/*
+ * Selects the sharks for the upload through the picker.choose interface.
+ *
+ * The number of sharks needed and the size of the sharks are specified by
+ * the durability-level and the content-length headers, respectively, or
+ * set to a default value.
+ */
+function chooseSharks(req, size, copies, cb) {
+    var log = req.log;
+
+    if (size === 0) {
+        cb(null, {});
+    } else {
+        var opts = {
+            requestId: req.getId(),
+            replicas: copies,
+            size: size
+        };
+        req.picker.choose(opts, function (err, sharks) {
+            if (err) {
+                cb(err);
+            } else {
+                log.info('upload: sharks chosen');
+                cb(null, sharks[0]);
+            }
+        });
+    }
+}
+
+
+///--- API
+
+// Instantiates the uploads object.
+function setupUpload(req, res, next) {
+    var id = libuuid.create();
+    req.upload = new uploadsCommon.MultipartUpload(req, id);
+
+    next();
+}
+
+/*
+ * Validates that all parameters needed for creating an upload exist, including:
+ *   - objectPath (the final path the uploaded object resides)
+ *
+ * Also validates optional headers, if they exist:
+ *   - durability-level
+ *   - content-length
+ *   - content-md5
+ *
+ * This handler is expected to set the following state on the upload object:
+ * - objectPath
+ * - size
+ * - copies
+ * - headers
+ * - contentMD5
+ * - contentType
+ */
+function validateParams(req, res, next) {
+    if (!req.body.objectPath) {
+        next(new MultipartUploadMissingObjecPathError());
+    } else {
+        var headers, size, copies;
+
+        headers = req.body.headers || {};
+        var maxObjectCopies = req.config.maxObjectCopies;
+
+        size = parseInt((headers['content-length'] ||
+            obj.DEF_MAX_LEN), 10);
+        if (size < 0) {
+            next(new MaxContentLengthError(size));
+            return;
+        }
+
+        copies = parseInt((headers['x-durability-level'] || 2), 10);
+        if (copies < 1 || copies > (maxObjectCopies || 9)) {
+            next(new InvalidDurabilityLevelError(1, maxObjectCopies));
+            return;
+        }
+
+        req.upload._headers = headers;
+        req.upload._size = size;
+        req.upload._copies = copies;
+
+        req.log.info('parameters valid');
+
+        next();
+    }
+}
+
+
+/*
+ * Checks if the parent of the upload directory exists, and if it doesn't,
+ * creates the directory.
+ *
+ * For example,if the prefix length for an upload ID is 1, and the id is abcdef,
+ * the prefix directory is of the form: /account/uploads/a.
+ */
+function ensurePrefixDir(req, res, next) {
+    var log = req.log;
+    var requestId = req.getId();
+    var id = req.upload.id;
+    log.info('creating upload ' + id + ' for path: \"' +
+        req.body.objectPath + '\"');
+
+    var parentOpts = {
+        key: path.dirname(req.upload.uploadPathKey()),
+        requestId: requestId
+    };
+    log.info('upload path directory key: ' + parentOpts.key);
+
+    req.moray.getMetadata(parentOpts, function (err, md, _) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                // If the directory doesn't exist yet, create it.
+                parentOpts.dirname = path.dirname(parentOpts.key);
+                parentOpts.mtime = Date.now();
+                parentOpts.owner = req.owner.account.uuid;
+                parentOpts.requestId = req.getId();
+                parentOpts.type = 'directory';
+                //TODO: headers, roles, _etag
+
+                req.moray.putMetadata(parentOpts, function (err2) {
+                    if (err2) {
+                        next(err2);
+                    } else {
+                        //TODO: need to save parent metadata here?
+                        log.info('prefix directory \"' + parentOpts.key +
+                            '\" created');
+                        next();
+                    }
+                });
+            } else {
+                next(err);
+            }
+        } else {
+            log.info('prefix directory \"' + parentOpts.key +
+                '\" already created');
+            next();
+        }
+    });
+}
+
+
+/*
+ * Actually create the upload in the sense that the upload record exists.
+ * To do so, we must first choose the sharks that the final object will
+ * live on and save the metadata for the upload record.
+ */
+function createUpload(req, res, next) {
+    var s = req.upload._size;
+    var c = req.upload._copies;
+
+    chooseSharks(req, s, c, function (err, sharks) {
+        if (err) {
+            next(err);
+        } else {
+            var opts = {
+                objectPath: req.body.objectPath,
+                sharks: sharks,
+                headers: req.body.headers || {}
+            };
+            req.upload.createUpload(opts, function (err2, partsDirectory) {
+                    if (err2) {
+                        next(err2);
+                    } else {
+                        req.log.info('responding OK for upload ' +
+                            req.upload.id);
+                        res.send(201, {
+                            id: req.upload.id,
+                            partsDirectory: partsDirectory
+                        });
+                        next();
+                    }
+            });
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    createHandler: function createHandler() {
+        var chain = [
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 100000
+            }),
+            setupUpload,
+            validateParams,
+            ensurePrefixDir,
+            createUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/get.js b/lib/uploads/get.js
new file mode 100644
index 0000000..f9225e4
--- /dev/null
+++ b/lib/uploads/get.js
@@ -0,0 +1,52 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+
+///--- API
+
+
+function setupUpload(req, res, next) {
+    var id = req.params.id;
+
+    if (!id.match(uploadsCommon.ID_REGEX)) {
+        next(new ResourceNotFoundError(req.url));
+    } else {
+        req.upload = new uploadsCommon.MultipartUpload(req, id);
+        next();
+    }
+}
+
+
+function getUpload(req, res, next) {
+    req.upload.getUpload(function (err, upload) {
+        if (err) {
+            next(err);
+        } else {
+            res.send(200, upload);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+
+    getHandler: function getHandler() {
+        var chain = [
+            setupUpload,
+            getUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/index.js b/lib/uploads/index.js
new file mode 100644
index 0000000..da67ab5
--- /dev/null
+++ b/lib/uploads/index.js
@@ -0,0 +1,29 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+///--- Helpers
+
+function reExport(obj) {
+    Object.keys(obj || {}).forEach(function (k) {
+        module.exports[k] = obj[k];
+    });
+}
+
+
+
+///--- Exports
+
+module.exports = {};
+reExport(require('./create'));
+reExport(require('./upload'));
+reExport(require('./commit'));
+reExport(require('./abort'));
+reExport(require('./get'));
+reExport(require('./redirect'));
diff --git a/lib/uploads/redirect.js b/lib/uploads/redirect.js
new file mode 100644
index 0000000..4d4c4de
--- /dev/null
+++ b/lib/uploads/redirect.js
@@ -0,0 +1,86 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+var assert = require('assert-plus');
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+
+
+
+///--- API
+
+/*
+ * Gets the ID from the request URL, which is either of the form:
+ *      /<account>/uploads/<id>
+ * or
+ *      /<account>/uploads/<id>/<partNum>
+ */
+function parseId(req, res, next) {
+
+    if (req.params && req.params.partNum) {
+        req.params.id = path.basename(path.dirname(req.url));
+    } else {
+        req.params.id = path.basename(req.url);
+    }
+
+    req.log.info('redirect started for id: ' + req.params.id);
+    next();
+}
+
+
+/*
+ * Redirects the request by looking up the upload path using the upload ID.
+ */
+function redirect(req, res, next) {
+    var log = req.log;
+
+    var prefix = req.params.id.charAt(0);
+    var id = req.params.id;
+    var url = '/' + req.params.account + '/uploads/' +  prefix + '/' + id;
+    var key = '/' + req.key.split('/')[1] + '/uploads/' +  prefix + '/' + id;
+
+    // Make sure this ID actually exists before sending a response.
+    var opts = {
+        key: key,
+        requestId: req.getId()
+    };
+    req.moray.getMetadata(opts, function (err, record, wrap) {
+        if (err) {
+            next(err);
+        } else {
+            if (req.params.partNum) {
+                url += '/' + req.params.partNum;
+                key += '/' + req.params.partNum;
+            }
+
+            log.info('Redirecting \"' + req.url + '\"  to \"' + url + '\"');
+            res.setHeader('Location', url);
+            res.send(301);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    redirectHandler: function redirectHandler() {
+        var chain = [
+            parseId,
+            redirect
+        ];
+        return (chain);
+    }
+
+};
diff --git a/lib/uploads/upload.js b/lib/uploads/upload.js
new file mode 100644
index 0000000..961c8fb
--- /dev/null
+++ b/lib/uploads/upload.js
@@ -0,0 +1,125 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var vasync = require('vasync');
+
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+require('../errors');
+
+//TODO: enforce max individual part size based on object size
+
+///--- API
+
+/*
+ * Does some basic validation on the part before proceeding to the normal PUT
+ * path, including:
+ *   - ensuring the partNum is valid
+ *   - ensuring the upload hasn't been finalized yet
+ *   - ensuring client isn't trying to change the number of copies of the object
+ */
+function validate(req, res, next) {
+    var log = req.log;
+    var id = req.upload.id;
+    log.info('validate');
+
+    var regex = /^([1-9][0-9]{0,3}|10000)$/;
+    var partNum = req.params.partNum;
+    var valid = regex.test(partNum);
+
+    if (!valid) {
+        next(new MultipartUploadPartNumError(req.upload.id(), partNum));
+    } else {
+        log.info('validating state');
+        req.upload.uploadState(function (err, state) {
+            if (err) {
+                next(err);
+            } else {
+                if (state !== uploadsCommon.uploadStates.CREATED) {
+                    next(new MultipartUploadFinalizeConflictError(id,
+                        'upload part for'));
+                } else {
+                    var k = 'durability-level';
+                    if (req.headers[k]) {
+                        next(new InvalidUpdateError(k));
+                    } else {
+                        next();
+                    }
+                }
+            }
+        });
+    }
+}
+
+
+/*
+ * The PUT handling code relies on some state being set up on the request
+ * object that is done by handlers not used for uploading parts.
+ *
+ * This handler ensures that the state needed for the PUT handling code
+ * is available so that the PUT handling code we do use for uploading
+ * parts works seamlessly.
+ */
+function setupPutState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+
+    // Ensure zero-byte objects aren't streamed to mako.
+    if (req.upload.uploadSize() === 0) {
+        log.info('zero-byte part');
+        req._zero = true;
+    }
+
+    // Ensure that the PUT handling code can find the correct sharks to use.
+    req._sharks = [upload.get(uploadsCommon.mdKeys.SHARKS)];
+    log.info('sharks for part: ' + JSON.stringify(req._sharks));
+
+    // Fake a durability-level header that matches the header
+    // specified on upload creation.
+    req.headers['x-durability-level'] = req.upload.numSharks();
+
+    next();
+}
+
+
+///--- Exports
+
+//  PUT handlers not included in this chain, in order:
+//      - conditionalRequest()
+//      - ensureNotRootHandler()
+//      [parseArguments]
+//      - ensureNotDirectoryHandler()
+//      - ensureParentHandler()
+//      - enforceDirectoryCount
+//      [other PUT handlers]
+//
+//      TODO: I think I need: conditionalRequest, enforceDirectoryCount
+module.exports = {
+    uploadPartHandler: function uploadPartHandler() {
+        var chain = [
+            uploadsCommon.setupUpload,
+            validate,
+            setupPutState,
+
+            // Piggybacking on existing PUT code.
+            //restify.conditionalRequest,//TODO: this makes request hang
+            obj.parseArguments,
+            obj.startSharkStreams,
+            obj.sharkStreams,
+            obj.saveMetadata
+        ];
+
+        return (chain);
+    }
+};
diff --git a/package.json b/package.json
index cbf77f6..047e50a 100644
--- a/package.json
+++ b/package.json
@@ -19,6 +19,7 @@
         "deep-equal": "0.0.0",
         "dtrace-provider": "0.2.8",
         "http-signature": "1.1.0",
+        "jsprim": "1.3.1",
         "kang": "1.1.0",
         "keep-alive-agent": "0.0.1",
         "keyapi": "git+ssh://git@github.com:joyent/keyapi.git#c30dd2710ad2175095dc0e96479686fa774b8063",
@@ -33,7 +34,7 @@
         "once": "1.3.0",
         "restify": "2.6.3",
         "vasync": "1.4.3",
-        "verror": "^1.7.0",
+        "verror": "1.9.0",
         "watershed": "0.3.0",
         "xtend": "2.1.1"
     },
diff --git a/tools/jsl.node.conf b/tools/jsl.node.conf
index 72d31c3..11c8556 100644
--- a/tools/jsl.node.conf
+++ b/tools/jsl.node.conf
@@ -170,6 +170,16 @@
 +define MaxContentLengthError
 +define MaxSizeExceededError
 +define MissingPermissionError
++define MultipartUploadAbortedError
++define MultipartUploadCommitInProgessError
++define MultipartUploadContentLengthError
++define MultipartUploadFinalizeConflictError
++define MultipartUploadMissingObjecPathError
++define MultipartUploadMissingPartError
++define MultipartUploadPartEtagError
++define MultipartUploadPartLimitError
++define MultipartUploadPartNumError
++define MultipartUploadPartSizeError
 +define NoMatchingRoleTagError
 +define NotAcceptableError
 +define NotEnoughSpaceError
