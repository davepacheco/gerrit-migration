commit aaafb550ed87c38b2a159245fa961ab3aedc9976 (refs/changes/92/1292/1)
Author: Jordan Hendricks <jordan.hendricks@joyent.com>
Date:   2017-01-19T01:50:58+00:00 (2 years, 9 months ago)
    
    MANTA-2169 Support multipart upload of a single file to Manta

diff --git a/.gitignore b/.gitignore
index d416fc4..408b0e2 100644
--- a/.gitignore
+++ b/.gitignore
@@ -11,3 +11,4 @@ cscope.out
 smf/manifests/*.xml
 *.tar.bz2
 *.log
+*.swp
diff --git a/lib/audit.js b/lib/audit.js
index 36bfa92..908da68 100644
--- a/lib/audit.js
+++ b/lib/audit.js
@@ -232,6 +232,9 @@ function auditLogger(options) {
         }
         obj.sharksContacted = req.sharksContacted;
         obj.shard = req.shard;
+        if (req.route) {
+            obj.route = req.route.name;
+        }
 
         if (req._timeToLastByte !== undefined &&
             req._totalBytes !== undefined) {
diff --git a/lib/common.js b/lib/common.js
index 8996f9f..e49a76f 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -43,6 +43,7 @@ var CORS_RES_HDRS = [
 var JOBS_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})/;
 /* JSSTYLED */
 var JOBS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/jobs\/?.*/;
+var UPLOADS_ROOT_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\.@%]+)\/uploads\/?.*/;
 /* JSSTYLED */
 var JOBS_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/jobs\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/stor/;
 var PUBLIC_STOR_PATH = /^\/([a-zA-Z][a-zA-Z0-9_\-\.@%]+)\/public(\/(.*)|$)/;
@@ -57,6 +58,7 @@ var ROOT_REGEXPS = [
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/public\\/?$'), // public
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/stor\\/?$'), // storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/?$'), // jobs (list)
+    new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/uploads\\/?$'), // uploads (list)
 
     // jobs storage
     new RegExp('^\\/[a-zA-Z0-9_\\-\\.@%]+\\/jobs\\/[\\w-]+\\/stor\\/?$'),
@@ -146,7 +148,7 @@ HttpRequest.isRootDirectory = function isRootDirectory(d) {
     return (_test(d));
 };
 
-
+//TODO: think uploads should go here
 HttpRequest.isRestrictedWrite = function isRestrictedWrite() {
     if (this.method !== 'PUT')
         return (false);
@@ -159,6 +161,8 @@ HttpRequest.isRestrictedWrite = function isRestrictedWrite() {
 
 ///--- API
 
+// Creates a metadata object from req.key that can be passed to moray via req.moray.putMetadata
+// TODO why is this used when putMetdata calls its own createMetdata????
 function createMetadata(req, type, cb) {
     var prev = req.metadata || {};
     // Override the UpdateMetadata type, as this flows in via PUT Object
@@ -371,7 +375,7 @@ function ensureParent(req, res, next) {
     }
 }
 
-
+// gets metdata for a given path, resolving dirname metadata and basename metadata
 function getMetadata(req, res, next) {
     var log = req.log;
 
@@ -468,7 +472,7 @@ function getMetadata(req, res, next) {
     });
 }
 
-
+// loads metadata for a given path only (as opposed to resolving its parent)
 function loadMetadata(req, opts, callback) {
     req.moray.getMetadata(opts, function (err, md, wrap) {
         if (err) {
@@ -700,6 +704,8 @@ module.exports = {
 
     PATH_LOGIN_RE: PATH_LOGIN_RE,
 
+    UPLOADS_ROOT_PATH: UPLOADS_ROOT_PATH,
+
     StoragePaths: {
         'public': {
             'name': 'Public',
@@ -716,6 +722,10 @@ module.exports = {
         'reports': {
             'name': 'Reports',
             'regex': REPORTS_STOR_PATH
+        },
+        'uploads': {
+            'name': 'Uploads',
+            'regex': UPLOADS_ROOT_PATH
         }
     },
 
@@ -903,23 +913,6 @@ module.exports = {
         }
 
         return (setup);
-    },
-
-    // Not used anymore
-    debugRequestHandler: function () {
-        function _debugLogRequest(req, res, next) {
-            var log = req.log;
-            var str = req.method + ' ' +
-                req.url + ' ' +
-                req.httpVersion + '\n';
-            Object.keys(req.headers).sort().forEach(function (k) {
-                str += k + ': ' + req.headers[k] + '\n';
-            });
-            log.debug('handling request:\n%s\n', str);
-            return (next());
-        }
-
-        return (_debugLogRequest);
     }
 
 };
diff --git a/lib/dir.js b/lib/dir.js
index d2d3bba..e2d90bd 100644
--- a/lib/dir.js
+++ b/lib/dir.js
@@ -265,7 +265,6 @@ module.exports = {
 
     putDirectoryHandler: function putDirectoryHandler() {
         var chain = [
-            // common.ensureNotRootHandler(),
             common.ensureParentHandler(),
             mkdir
         ];
diff --git a/lib/errors.js b/lib/errors.js
index bd5c156..5bc7941 100644
--- a/lib/errors.js
+++ b/lib/errors.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var assert = require('assert');
@@ -439,6 +439,88 @@ function MissingPermissionError(perm) {
 util.inherits(MissingPermissionError, MuskieError);
 
 
+function MultipartUploadAbortedError(id) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadAborted',
+        statusCode: 409,
+        message: sprintf('upload %s aborted', id)
+    });
+}
+util.inherits(MultipartUploadAbortedError, MuskieError);
+
+
+
+function MultipartUploadCommitInProgessError(id) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadCommitInProgress',
+        statusCode: 409,
+        message: sprintf('upload %s has a commit with a different set of parts in progress', id)
+    });
+}
+util.inherits(MultipartUploadCommitInProgessError, MuskieError);
+
+
+function MultipartUploadContentLengthError(id, expected, actual) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadContentLengthError',
+        statusCode: 409,
+        message: sprintf('expected content-length %d, but object was: %d',
+            id, expected, actual)
+    });
+}
+util.inherits(MultipartUploadContentLengthError, MuskieError);
+
+
+function MultipartUploadFinalizeConflictError(id, action) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadFinalizeConflict',
+        statusCode: 409,
+        message: sprintf('cannot %s upload %s; already finalized', action, id)
+    });
+}
+util.inherits(MultipartUploadFinalizeConflictError, MuskieError);
+
+
+function MultipartUploadMissingObjecPathError() {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadMissingObjecPathError',
+        statusCode: 400,
+        message: 'an objectPath is required'
+    });
+}
+util.inherits(MultipartUploadPartEtagError, MuskieError);
+
+
+function MultipartUploadPartEtagError(id, index, etag) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartEtag',
+        statusCode: 400,
+        message: sprintf('incorrect etag for upload %s, part %d: %s', id, index, etag)
+    });
+}
+util.inherits(MultipartUploadPartEtagError, MuskieError);
+
+
+function MultipartUploadPartNumError(id, partNum) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartNum',
+        statusCode: 400,
+        message: sprintf('invalid partNum for upload %s: %s', id, partNum)
+    });
+}
+util.inherits(MultipartUploadPartNumError, MuskieError);
+
+
+function MultipartUploadPartSizeError(id, index, size) {
+    MuskieError.call(this, {
+        restCode: 'MultipartUploadPartSize',
+        statusCode: 400,
+        message: sprintf('upload %s, part %d is too small (size %d)', id, index, size)
+    });
+}
+util.inherits(MultipartUploadPartSizeError, MuskieError);
+
+
 function NotAcceptableError(req, type) {
     MuskieError.call(this, {
         restCode: 'NotAcceptable',
diff --git a/lib/obj.js b/lib/obj.js
index 31f38cb..075caa5 100644
--- a/lib/obj.js
+++ b/lib/obj.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 //
@@ -192,6 +192,7 @@ function parseArguments(req, res, next) {
             'content-md5',
             'durability-level'
         ].some(function (k) {
+            debugger;
             var bad = req.headers[k];
             if (bad) {
                 setImmediate(function killRequest() {
@@ -912,5 +913,11 @@ module.exports = {
             deletePointer
         ];
         return (chain);
-    }
+    },
+
+    parseArguments: parseArguments,
+    startSharkStreams: startSharkStreams,
+    sharkStreams: sharkStreams,
+    saveMetadata: saveMetadata,
+    DEF_MAX_LEN: DEF_MAX_LEN
 };
diff --git a/lib/other.js b/lib/other.js
index 5a91a42..c53333f 100644
--- a/lib/other.js
+++ b/lib/other.js
@@ -376,7 +376,6 @@ module.exports = {
             common.ensureParentHandler(),
             preflightPUTRequest,
             common.ensureEntryExistsHandler(),
-            // common.assertMetadataHandler(),
             preflightRequest
         ];
 
diff --git a/lib/server.js b/lib/server.js
index 1bf8b7e..043690c 100644
--- a/lib/server.js
+++ b/lib/server.js
@@ -24,10 +24,11 @@ var common = require('./common');
 var dir = require('./dir');
 var jobs = require('./jobs');
 var link = require('./link');
+var medusa = require('./medusa');
 var obj = require('./obj');
 var other = require('./other');
 var picker = require('./picker');
-var medusa = require('./medusa');
+var uploads = require('./uploads');
 
 // injects into the global namespace
 require('./errors');
@@ -284,6 +285,193 @@ function createServer(options, clearProxy) {
         authAction: 'mlogin'
     }, medusa.getMedusaAttachHandler());
 
+
+    // Multipart Uploads
+    //
+    // /jhendricks/uploads
+    //      - GET
+    //      - HEAD 
+    //      - POST: create
+    //      - Forbidden: PUT/DELETE
+    function forbiddenHandler(req, res, next) {
+        req.log.info('Method ' + req.method + ' disallowed for ' + req.url);
+        res.send(403);
+        next(false);
+    }
+    server.post({
+        path: '/:account/uploads',
+        name: 'CreateUpload',
+        contentType: 'application/json'
+    }, uploads.createHandler());
+
+    server.put({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads'
+    }, forbiddenHandler);
+      
+    
+    // /jhendricks/uploads/:id
+    //      - GET/HEAD/PUT/POST/DELETE: redirects to /jhendricks/upload/:prefix/:id
+    //
+    // /jhendricks/uploads/:id/:partNum
+    //      - GET/HEAD/PUT/POST/DELETE: redirects to /jhendricks/upload/:prefix/:id/:partNum
+    //
+    // /jhendricks/uploads/:prefix
+    //      - GET
+    //      - HEAD? (not in RFD)
+    //      - Forbidden: PUT/POST/DELETE
+    var uploadsRedirectPath = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}';
+    var uploadsRedirectPathPart = '/:account/uploads/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}/:partNum';
+    server.get({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPath,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.get({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.put({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*',
+    }, uploads.redirectHandler());
+
+    server.head({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.del({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+
+    server.post({
+        path: uploadsRedirectPathPart,
+        contentType: '*/*'
+    }, uploads.redirectHandler());
+ 
+    
+
+    // /jhendricks/uploads/[0-f]+/:id
+    //      - GET/HEAD: should be implicitly defined by generated routes
+    //      - Forbidden: PUT/POST/DELETE
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler);
+
+    /*server.del({
+        path: '/:account/uploads/[0-f]+/:id'
+    }, forbiddenHandler); */ //TODO: commenting this out for now so I can delete things.
+    
+
+    // /jhendricks/uploads/[0-f]+/:id/state
+    //      - GET
+    //      - Forbidden: HEAD/PUT/POST/DELETE
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/state',
+        name: 'GetUpload' //TODO add authaction?
+    }, uploads.getHandler());
+    
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/state',
+    }, forbiddenHandler);
+
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/state',
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/state',
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/state',
+    }, forbiddenHandler);
+    
+
+    // /jhendricks/uploads/:prefix/:id/abort
+    //      - POST
+    //      - Forbidden: GET/PUT/HEAD/DELETE
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/abort',
+        name: 'AbortUpload' //TODO add authaction?
+    }, uploads.abortHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+    
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+
+debugger;
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/abort'
+    }, forbiddenHandler);
+    
+
+    
+    // /jhendricks/uploads/:prefix/:id/commit
+    //      - POST
+    //      - Forbidden: GET/PUT/HEAD/DELETE
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/commit',
+        name: 'CommitUpload', //TODO add authaction?
+        contentType: 'application/json'
+    }, uploads.commitHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+    
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.head({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/commit'
+    }, forbiddenHandler);
+    
+    
+
     server.use(common.getMetadataHandler());
     server.use(auth.storageContext);
     server.use(auth.authorizationHandler());
@@ -303,6 +491,30 @@ function createServer(options, clearProxy) {
                common.assertMetadataHandler(),
                dir.getDirectoryHandler());
 
+    // /jhendricks/uploads/:prefix/:id/:partNum
+    //      - PUT
+    //      - HEAD
+    //      - Forbidden: GET/POST/DELETE
+    server.put({
+        path: '/:account/uploads/[0-f]+/:id/:partNum',
+        name: 'UploadPart', //TODO add authaction?
+        contentType: '*/*'
+    }, uploads.uploadPartHandler());
+
+    server.get({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.post({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+    server.del({
+        path: '/:account/uploads/[0-f]+/:id/:partNum'
+    }, forbiddenHandler);
+
+
+
     // Root dir
 
     server.get({
@@ -334,6 +546,14 @@ function createServer(options, clearProxy) {
         authAction: 'deletedirectory'
     }, dir.rootDirHandler());
 
+    // creates routes for everything in StoragePaths array
+    // put___directory
+    // put___link
+    // put___object
+    // options___storage
+    // get___storage
+    // head___storage
+    // delete___storage
     Object.keys(common.StoragePaths).forEach(function (k) {
 
         var _p = common.StoragePaths[k].regex;
diff --git a/lib/uploads/abort.js b/lib/uploads/abort.js
new file mode 100644
index 0000000..52fa660
--- /dev/null
+++ b/lib/uploads/abort.js
@@ -0,0 +1,91 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+var assert = require('assert-plus');
+var restify = require('restify');
+
+
+///--- API
+
+/*
+ * Ensures that the upload is in the correct state: either created or aborted,
+ * and updates the upload record's metadata if needed to reflect this state.
+ *
+ */
+function finalizingState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+
+    req.upload.uploadState(function (err, state, type) {
+        if (err) {
+            next(err);
+        } else {
+            var states = uploadsCommon.uploadStates;
+            var types = uploadsCommon.uploadTypes;
+
+            if (state === states.CREATED) {
+                assert.ok(!type);
+                upload.finalizeUploadRecord(types.ABORT, null, function(err) {
+                    if (err) {
+                        next(err);
+                    } else {
+                        next();
+                    }
+                });
+            } else if ((state === states.FINALIZING) &&
+                (type === types.ABORT)) {
+
+                log.debug('abort already in progress for upload ' + upload.id);
+                next();
+
+            } else if ((state === states.FINALIZING) &&
+                (type === types.COMMIT)) {
+
+                log.debug('commit already in progress for upload ' + upload.id);
+                next(new MultipartUploadFinalizeConflictError(upload.id,
+                    types.COMMIT));
+
+            } else {
+                assert.fail('Invalid state/type combination for upload: '
+                    + state + '/' + type);
+            }
+        }
+    });
+}
+
+
+function abort(req, res, next) {
+    req.upload.abortUpload(function (err) {
+        if (err) {
+            next(err);
+        } else {
+            req.log.info('upload ' + req.upload.id + ' aborted');
+            res.setHeader('Content-Length', '0');
+            res.send(202);//TODO: http status code for 'Accepted'. Technically this means that the request may or may not eventually be processed, which is generally true for an abort request.
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    abortHandler: function abortHandler() {
+        var chain = [
+            uploadsCommon.setupUpload,
+            finalizingState,
+            abort
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/commit.js b/lib/uploads/commit.js
new file mode 100644
index 0000000..286831c
--- /dev/null
+++ b/lib/uploads/commit.js
@@ -0,0 +1,266 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var restify = require('restify');
+var vasync = require('vasync');
+var verror = require('verror');
+
+
+///--- Globals
+
+var MIN_PART_SIZE = 5000000;
+
+
+///--- API
+
+/*
+ * Ensures that the upload is in a proper state before proceeding: either
+ * CREATED or COMMIT. It it is in state COMMIT, the request must specify the
+ * same set of parts as is recorded in the upload record.
+ */
+function validateUploadState(req, res, next) {
+    var log = req.log;
+    var parts = req.body.parts;
+
+    req.upload.uploadState(function (err, state, type) {
+        if (err) {
+            next(err);
+        } else {
+            var states = uploadsCommon.uploadStates;
+            var types = uploadsCommon.uploadTypes;
+
+            if (state === states.FINALIZING) {
+                if (type === types.ABORT) {
+                    // Abort already in progress
+                    next(new MultipartUploadAbortedError(req.upload.id));
+
+                } else if (type === types.COMMIT) {
+                    // Not an error, but we need to verify the parts are the
+                    // same as the input ones before proceeding
+                    log.info('commit already in progress for upload');
+
+                    if (!jsprim.deepEqual(parts, req.upload.parts())) {
+                        next(new MultipartUploadCommitInProgessError(req.upload.id));
+                    } else {
+                        next();
+                    }
+
+                } else {
+                    assert.fail('Invalid type: ' + type);
+                }
+            } else if (state === states.CREATED) {
+                next();
+            } else {
+                assert.fail('Invalid state: ' + state);
+            }
+        }
+    });
+}
+
+
+/*
+ * Ensures that the input parts set for the commit has the etags of the parts
+ * as they exist now. This step also checks that all parts have a size that
+ * exceeds the minimum part size (excluding the last part).
+ */
+function validateParts(req, res, next) {
+    var log = req.log;
+    var parts = req.body.parts;
+    log.info('validating parts for upload');
+
+    var errors = [];
+    var sum = 0;
+
+    function validateEtag(obj, cb) {
+        var index = obj.index;
+        var etag = obj.etag;
+
+        if (index !== 0) {
+            var record = req.upload.uploadMd;
+            var key = record.key + '/' + index;
+
+            req.moray.client.getObject(record.bucket, key, function (err, md) {
+                log.info('part index: ' + index + ', etag: ' + etag);
+
+                if (err) {
+                    errors.push(err);
+                } else {
+                    var id = req.upload.id;
+                    var size = parseInt(md.value.contentLength, 10);
+                    var isFinalPart = index === (parts.length - 1);
+
+                    if (md.value.etag !== etag) {
+                        errors.push(new MultipartUploadPartEtagError(id, index, etag));
+                    } else if (!isFinalPart && (size < MIN_PART_SIZE)) {
+                        errors.push(new MultipartUploadPartSizeError(id, index, size));
+                    }
+        
+                    sum += size;
+                    cb();
+                }
+            });
+        } else {
+            // Skip part 0
+            cb();
+        }
+    }
+
+    var queue = vasync.queue(validateEtag, 10);
+    parts.forEach(function (val, i) {
+        queue.push({
+            index: i,
+            etag: val
+        });
+    });
+    queue.close();
+
+    function verifyObjectSize(req, size, cb) {
+        if (size > obj.DEF_MAX_LEN) {
+            cb(new MaxContentLengthError(size));
+        } else {
+            // Verify the content-length header if specified.
+            var expected = req.upload.headers()['content-length'];
+            if (expected && expected !== size) {
+                cb(new MultipartUploadContentLengthError(expected, size));
+            } else {
+                cb();
+            }
+        }
+    }
+
+    queue.on('end', function () {
+        log.info('validation of parts completed');
+        if (errors.length > 0) {
+            log.error('errors with parts: ' + errors);
+            //TODO: Fix this error handling
+            next(new verror.VError(errors));
+        } else {
+            verifyObjectSize(req, sum, function (err) {
+                if (err) {
+                    next(err);
+                } else {
+                    log.info('object size ' + sum + ' valid');
+
+                    req.upload.setSize(sum);
+                    next();
+                }
+            });
+        }
+    });
+}
+
+
+/*
+ * Loads the state of the upload record once more to ensure that it hasn't
+ * changed since it was first validated, and saves the upload record with
+ * a new state.
+ */
+function finalizingState(req, res, next) {
+    var log = req.log;
+    var upload = req.upload;
+    var parts = req.body.parts;
+
+    req.upload.uploadState(function (err, state, type) {
+        if (err) {
+            next(err);
+        } else {
+            var states = uploadsCommon.uploadStates;
+            var types = uploadsCommon.uploadTypes;
+
+            if (state === states.CREATED) {
+                assert.ok(!type);
+                upload.finalizeUploadRecord(types.COMMIT, parts, function(err) {
+                    if (err) {
+                        next(err);
+                    } else {
+                        next();
+                    }
+                });
+            } else if ((state === states.FINALIZING) &&
+                (type === types.ABORT)) {
+
+                log.debug('abort already in progress for upload ' + upload.id);
+                next(new MultipartUploadFinalizeConflictError(upload.id,
+                    types.ABORT));
+
+            } else if ((state === states.FINALIZING) &&
+                (type === types.COMMIT)) {
+
+                log.debug('commit already in progress for upload ' + upload.id);
+                next();
+
+            } else {
+                assert.fail('Invalid state/type combination for upload: '
+                    + state + '/' + type);
+            }
+        }
+    });
+}
+
+
+// Invokes mako-finalize on sharks
+// TODO: better comment once this is written.
+function finalizeUpload(req, res, next) {
+    var log = req.log;
+    //TODO: hook this up with rm's work when ready
+    //TODO: validate md5 from mako with user-provided md5
+    log.info('mako-finalize not yet implemented (id: ' + req.upload.id + ')');
+
+
+    next();
+}
+
+
+/*
+ * This step makes the committed upload visible from Manta by atomically
+ * inserting a commit record and object record on the shard associated
+ * with the object. Most of the heavy lifting is done by the req.uploads
+ * object here.
+ */
+function commit(req, res, next) {
+    var log = req.log;
+
+    req.upload.commitUpload(req.body.parts, function (err) {
+        if (err) {
+            next(err);
+        } else {
+            res.setHeader('Location', req.upload.objectPath());
+            res.send(201);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+//TODO: use something like getMetadata to make sure object path is valid.
+module.exports = {
+    commitHandler: function commitHandler() {
+        var chain = [
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 100000
+            }),
+            uploadsCommon.setupUpload,
+            validateUploadState,
+            validateParts,
+            finalizingState,
+            finalizeUpload,
+            commit
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/common.js b/lib/uploads/common.js
new file mode 100644
index 0000000..56419e8
--- /dev/null
+++ b/lib/uploads/common.js
@@ -0,0 +1,854 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var common = require('../common');
+var obj = require('../obj');
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libmanta = require('libmanta');
+var path = require('path');
+var verror = require('verror');
+
+/*
+ *  This file contains the majority of the logic for handling multipart uploads.
+ *
+ *  The Manta multipart upload API allows clients to upload a Manta object
+ *  by splitting it into parts and uploading the parts individually. When all
+ *  parts are uploaded, the client signifies that the upload is completed by
+ *  "committing" the upload through the API, which creates a Manta object
+ *  that is the sum of the uploaded parts and is indistiguisable from an
+ *  object created through a normal Manta PUT. If a client decides not to
+ *  finish the upload, it may also abort the upload process.
+ *
+ *  The possible operations in the mulitpart upload API are:
+ *      - create: establish a multipart upload
+ *      - upload-part: upload a part of the object
+ *      - abort: cancel the upload
+ *      - commit: complete the upload
+ *      - get: get information about an ongoing upload
+ *
+ *  The logic of this API is mostly implemented as methods on the MultipartUpload
+ *  object defined in this file. When a multipart upload related request comes
+ *  in to muskie, a new MultipartUpload request is constructed, and sets up
+ *  important state the various handlers will need.
+ *
+ * TODO: more to come
+ *
+ *
+ *
+ */
+
+
+///--- Globals
+
+var ID_REGEX = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
+var PREFIX_LENGTH = 1;
+
+// Upload states
+var states = {
+    CREATED: 'created',
+    FINALIZING: 'finalizing'
+};
+
+// Finalizing types
+var types = {
+    COMMIT: 'commit',
+    ABORT: 'abort'
+};
+
+
+///--- Helpers
+
+/*
+ * Creates the metadata for the upload record.
+ * (e.g., /jhendricks/uploads/c/c46ac2b1-fcc3-4e12-8c46-c935808ed59f)
+ */
+function createUploadMetadata(upload, cb) {
+    var req = upload.req;
+
+    /*
+     * createMetadata assumes that the key for the metadata it should create
+     * is saved in req.key, which is true for most requests. In this case,
+     * we save the key stored in req.key (which corresponds to the path
+     * /:account/uploads, instead of the upload record key) and restore it
+     * after the metadata is created. This is a bit janky, but allows us to
+     * reuse existing code to create metadata for directories much more
+     * easily.
+     */
+    var savedKey = req.key;
+    assert.ok(upload.uploadMd.key);
+    req.key = upload.uploadMd.key;
+
+    common.createMetadata(req, 'directory', function (err, md) {
+        req.key = savedKey;
+
+        if (err) {
+            cb(err);
+        } else {
+            md._etag = null;
+            cb(null, md);
+        }
+    });
+}
+
+/*
+ * Creates the metadata for the finalizing record for the upload, for both
+ * commit and aborts.
+ *
+ * The key is the same as the path of the final object, which is specified
+ * when the upload is created.
+ */
+function createFinalizingMetadata(upload, type, cb) {
+    assert.ok(type === types.COMMIT || type === types.ABORT)
+    var req = upload.req;
+    var log = upload.req.log;
+    var key = upload.finalizingMd.key;
+
+    var md = {
+        dirname: path.dirname(key),
+        key: key,
+        headers: {},
+        mtime: Date.now(),
+        owner: req.owner.account.uuid,
+        requestId: req.getId(),
+        roles: [],
+        type: 'finalizing',
+        _etag: null,
+
+        upload {
+            id: upload.id,
+            type: type,
+        }
+    };
+
+    if (type === type.COMMIT) {
+        md.upload.parts = parts;
+    }
+
+    cb(md);
+}
+
+
+/*
+ * Creates the metadata for the object that will be uploaded.
+ */
+
+function createObjectMetadata(upload, cb) {
+    var req = upload.req;
+    var log = upload.req.log;
+
+    var objectPath = upload.objectPath();
+
+    normalize(upload.req, objectPath, function (err, objectPathKey) {
+        if (err) {
+            cb(err);
+        } else {
+            //TODO: comment
+            var savedKey = req.key;
+            var savedHeaders = req.headers;
+
+            req.key = objectPathKey;
+            req.headers = upload.headers();
+            req.query.metadata = null;
+
+            common.createMetadata(req, 'object', function (err, md) {
+                if (err) {
+                    cb(err);
+                } else {
+                    req.key = savedKey;
+                    req.headers = savedHeaders;
+
+                    md.size = upload.size();
+                    md.copies = upload.copies();
+                    md.headers = upload.headers();
+                    md.contentMD5 = upload.contentMD5();
+                    //TODO: _etag.
+
+                    cb(null, md);
+                }
+            });
+        }
+    });
+}
+
+/*
+ * Saves the upload record metadata.
+ */
+function saveUploadMetadata(upload, record, cb) {
+    var md = record.toSave;
+
+    // Some sanity checks.
+    assert.equal(md.key, upload.uploadMd.key);
+    assert.ok(md.upload);
+    assert.ok((md.upload.state === states.CREATED) ||
+        (md.upload.state === states.FINALIZING));
+    assert.ok(md.upload.sharks);
+    if (md.upload.state === states.FINALIZING) {
+        assert.ok(md.type);
+
+        if (md.upload.type === types.COMMIT) {
+            assert.ok(md.upload.parts);
+        }
+    }
+
+    saveMetadata(upload.req, record, cb);
+}
+
+/*
+ * Loads the upload record metadata and populates necessary fields on the
+ * upload object (that are not populated on object creation).
+ */
+function loadUploadMetadata(upload, cb) {
+    var log = upload.req.log;
+
+    var record = upload.uploadMd;
+    loadMetadata(upload.req, record, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            assert.ok(record.loaded);
+            assert.ok(record.loaded.upload);
+
+            upload.setObjectPath(record.loaded.upload.objectPath);
+            upload.setObjectPathKey(record.loaded.upload.objectPathKey);
+            upload.setSize(record.loaded.upload.size);
+            upload.setCopies(record.loaded.upload.copies);
+            upload.setHeaders(record.loaded.upload.headers);
+            upload.setContentMD5(record.loaded.upload.contentMD5);
+
+            cb(null, record.loaded.upload);
+        }
+    });
+}
+
+/*
+ * Loads the finalizing record metadata.
+ */
+function loadFinalizingMetadata(upload, cb) {
+    var record = upload.finalizingMd;
+
+    function load(upload, key, record, cb) {
+        assert.ok(key, 'key');
+
+        record.key = key;
+        loadMetadata(upload.req, record, function (err) {
+            if (err) {
+                cb(err);
+            } else {
+                assert.ok(record.loaded);
+                assert.ok(record.loaded.upload);
+                assert.ok(record.loaded.upload.type);
+
+                cb(null, record.loaded.upload);
+            }
+        });
+    }
+
+    if (!upload.objectPathKey()) {
+        normalize(upload.req, upload.objectPath(), function (err, key) {
+            if (err)  {
+                cb(err);
+            } else {
+                upload.setObjectPathKey(key);
+                load(upload, key, record, cb);
+            }
+        });
+    } else {
+        load(upload, key, record, cb);
+    }
+}
+
+
+/*
+ * Saves the metadata located in the input record object at record.toSave.
+ * The record object should be of the form:
+ *      {
+ *          key,        // moray key
+ *          bucket,     // moray bucket
+ *          loaded,     // loaded metadata for this record (not used here)
+ *          toSave     // metadata to save
+ *      }
+ */
+function saveMetadata(req, record, cb) {
+    var bucket = record.bucket;
+    var md = record.toSave;
+
+    var opts = {
+        req_id: req.getId(),
+        etag: md._etag
+    };
+    req.log.info('opts: ' + opts);
+    req.moray.client.putObject(bucket, md.key, md, opts, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            cb();
+        }
+    });
+}
+
+
+/*
+ * Loads the metadata located in the input record object into record.loaded.
+ * The record object should be of the form:
+ *      {
+ *          key,        // moray key
+ *          bucket,     // moray bucket
+ *          loaded,     // pointer to the loaded metadata once this completes
+ *          toSave      // metadata to save (not used here))
+ *      }
+ */
+function loadMetadata(req, record, cb) {
+    var bucket = record.bucket;
+    var key = record.key;
+
+    req.moray.client.getObject(bucket, key, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+                assert.ok(md.value);
+                // md.value here is the actual metadata
+                assert.ok(md.value.upload);
+
+                record.loaded = md.value;
+                cb();
+        }
+    });
+}
+
+
+// Normalizes a path in Manta.
+function normalize(req, path, cb) {
+    var opts = {
+        account: req.owner.account,
+        path: path
+    }
+
+    libmanta.normalizeMantaPath(opts, function (err, p) {
+        if (err) {
+            req.log.debug({
+                url: path,
+                err: err
+            }, 'failed to normalize URL');
+            cb(err);
+        } else {
+            cb(null, p);
+        }
+    });
+}
+
+
+/*
+ * Given an upload ID, returns the prefix to use for the parent directory
+ * of the upload directory. For now, this is the just the first character of
+ * the upload uuid, but we may want to use more characters later to allow for
+ * more simulataneous uploads.
+ *
+ * For example, the id '0bb83e47-32df-4833-a6fd-94d77e8c7dd3' will return '0'
+ * for a prefix length of 1.
+ */
+function idToPrefix(id) {
+    assert.string(id);
+    assert.ok(id.match(ID_REGEX));
+
+    return (id.substring(0, PREFIX_LENGTH));
+}
+
+
+///--- Routes
+//TODO: it probably makes more sense for this to load the upload md, and have the callers instantiate the object themselves
+//this would also require some rework of upload state and potentially rewrites, so moving on for now
+function setupUpload(req, res, next) {
+    var id = req.params.id;
+    req.upload = new MultipartUpload(req, id);
+
+    next();
+}
+
+
+///--- API
+
+/*
+ * Constructor for the MultipartUpload object, with is instantiated at
+ * the beginning of each multipart upload related request and attached to the
+ * request object at `req.upload`.
+ *
+ * The inputs to the constructor are:
+ *      - id, the upload uuid
+ *      - req, the request object for this multipart upload related request
+ *
+ *
+ * The structure of this object is as follows:
+ *
+ * {
+ *    id,                     // upload uuid
+ *    req,                    // pointer to the request this upload is for
+ *    uploadPath,             // path of the upload dir where parts are stored
+ *                            // (e.g., /jhendricks/uploads/a/abcdef)
+ *
+ *    _objectPath,             // final path the object will be saved on
+ *    _objectPathKey,          // normalized path (used in moray)
+ *    _size,                   // object size
+ *    _copies,                 // num copies of the object that will be stored
+ *    _headers,                // headers set for the object on upload creation
+ *    _contentMD5,             // MD5 sum of the object
+ *
+ *    // These objects represent relevant metadata for the upload. There are
+ *    // two types of metadata we need to save for an upload: the upload record
+ *    // and the finalizing record. The upload record is the Manta directory
+ *    // record for the upload directory, which is the path where parts are
+ *    // uploaded. The finalizing record is either the commit or abort record,
+ *    // which is stored on the same shard the metadata for the uploaded object
+ *    // will reside on.
+ *
+ *    // When metadata is first loaded during a request, it is saved at
+ *    // {upload,finalizing}Md.loaded. Changes to metadata are made in a copy
+ *    // of the metadata that is saved at {upload,finalizing}Md.toSave. The
+ *    // saveMetadata and loadMetadata functions expect this.
+ *
+ *    // Additionally, each object contains the moray bucket and the key
+ *    // for the metadata record it represents.
+ *
+ *    uploadMd {          // upload record metadata object
+ *        key,            // normalized uploadPath
+ *        bucket,         // bucket for upload records (normal manta records)
+ *        loaded {        // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    },
+ *
+ *    finalizingMd {      // finalizing record metadata object
+ *        key,            // normalized objectPath
+ *        bucket,         // bucket for finalizing records
+ *        loaded,         // current metadata for this upload
+ *        toSave          // new metadata for this upload
+ *    }
+ * }
+ *
+ * Additionally, there are two classes of methods on the uploads object:
+ *      - multipart API-specific methods called by relevant handlers for these
+ *        requests
+ *      - getters on important attributes, which allow programming with the
+ *        object without neededing to know details of its internal structure
+ *
+ * These methods are documented below.
+ */
+function MultipartUpload(req, id) {
+    var self = this;
+    self.id = id;
+    self.req = req;
+    self.uploadPath = '/' + req.owner.account.login + '/uploads/' +
+        idToPrefix(id) + '/' + id;
+
+    self._objectPath = null;
+    self._size = null;
+    self._copies = null;
+    self._headers = null;
+    self._contentMD5 = null;
+
+    self.uploadMd = {
+        key: null,
+        bucket: 'manta',
+        records: {
+            loaded: null,
+            toSave: null
+        }
+    };
+
+    normalize(req, self.uploadPath, function (err, p) {
+        if (err) {
+            throw(new InvalidPathError(upload.uploadPath));
+        } else {
+            self.uploadMd.key = p;
+            req.log.info('upload path key: ' + self.uploadMd.key);
+        }
+    });
+
+    self.finalizingMd = {
+        key: null,
+        bucket: 'manta_uploads',
+        records: {
+            loaded: null,
+            toSave: null
+        }
+    };
+
+    Object.seal(self);
+    return (self);
+}
+
+
+///--- Create
+
+/*
+ * Creates the multipart upload by creating the upload record and inserting
+ * it into Moray.
+ *
+ * //TODO explain creating object md here
+ *
+ *
+ * An additional item is tacked onto the normal directory record for the upload
+ * directory: an "uploads" object. This object contains the data we need to
+ * manage the multipart upload. Some of fields in the object are not always
+ * populated nor may ever be populated, depending on what sort of API calls
+ * the client makes.
+ *
+ * Fields that are populated when the upload is created are:
+ *      - state: the current state of the upload (CREATED or FINALIZING)
+ *      - sharks: mako nodes the object will reside on after commit
+ *      - objectPath: the path to the final uploaded object in Manta
+ *
+ * The only field that is populated when the upload is finalized is:
+ *      - type: finalizing type (COMMIT or ABORT)
+ *
+ * Finally, the following field is populated only on commit:
+ *      - parts: an array of etags representing parts to commit
+ */
+MultipartUpload.prototype.createUpload = function createUpload(sharks, cb) {
+    assert.object(sharks);
+
+    var self = this;
+
+    createUploadMetadata(self, function(err, uploadMd) {
+        if (err) {
+            cb(err);
+        } else {
+            uploadMd.upload = {
+                state: states.CREATED,
+                sharks: sharks[0],
+                objectPath: self.objectPath(),
+                size: self.size(),
+                copies: self.copies(),
+                headers: self.headers(),
+
+                type: null,     // used for finalizing uploads only
+                parts: null     // used for committing uploads only
+            };
+            self.uploadMd.toSave = uploadMd;
+
+            saveUploadMetadata(self.req, self.uploadMd, function (err) {
+                if (err) {
+                    cb(err);
+                } else {
+                    cb(null, self.uploadPath);
+                }
+            });
+        }
+    });
+}
+
+
+/*
+ * Loads the metadata for the upload and returns its current state
+ * and finalizing type, if applicable.
+ */
+// Consumers: UploadPart, Abort, Commit
+MultipartUpload.prototype.uploadState = function uploadState(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    loadUploadMetadata(self, function (err, upload) {
+        if (err) {
+            cb(err);
+        } else {
+            cb(null, upload.state, upload.type);
+        }
+    });
+}
+
+// Clones a loaded upload record, and adds 'type' and 'parts' added to the record, then saves it to moray.
+// Consumers: Abort, Commit
+/*
+ */
+MultipartUpload.prototype.finalizeUploadRecord = function finalizeUploadRecord(type, parts, cb) {
+    assert.ok((type === types.ABORT) || (type === types.COMMIT));
+    assert.ok(this.uploadMd.loaded);
+    assert.ok(this.uploadMd.loaded.upload);
+
+    if (type === types.COMMIT) {
+        assert.arrayOfString(parts);
+    }
+
+    var log = this.req.log;
+    var self = this;
+    
+    self.uploadMd.toSave = jsprim.deepCopy(self.uploadMd.loaded);
+    self.uploadMd.toSave.upload.state = states.FINALIZING;
+    self.uploadMd.toSave.upload.type = type;
+    self.uploadMd.toSave.upload.parts = parts;
+
+    saveMetadata(self.req, self.uploadMd, function (err) {
+        if (err) {
+            cb(err);
+        } else {
+            cb();
+        }
+    });
+}
+
+
+// Aborts the upload: atomically checks for existence of a finalizing record and inserts an abort one if none exists.
+// Consumers: Abort
+MultipartUpload.prototype.abortUpload = function abortUpload(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    loadFinalizingMetadata(self, function (err, upload) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                    createFinalizingMetadata(self, types.ABORT, function (md) {
+                        var record = self.finalizingMd;
+                        record.toSave = md;
+
+                        var opts = {
+                            req_id: self.req.getId(),
+                            etag: null
+                        }
+                        self.req.log.info('creating finalizing abort record');
+                        self.req.moray.client.putObject(record.bucket,
+                         record.key, record.toSave, opts, function (err) {
+                            if (err) {
+                                cb(err);//TODO handle EtagConflictError?
+                            } else {
+                                cb();
+                            }
+                        });
+                    });
+            } else {
+                cb(err);
+            }
+        } else {
+            log.info('Finalizing record already exists: type:' + self.finalizingMd.loaded.upload.type);
+            if (self.finalizingMd.loaded.upload.type === types.ABORT) {
+                // Not an error (abort is idemptotent)
+                cb();
+            } else {
+                cb(new MultipartUploadFinalizeConflictError(req.upload.id, types.ABORT));
+            }
+        }
+    });
+}
+
+
+// Commits the upload. Saves upload record with state finalizing type commit, and atomically checks for existence of a finalizing record; if none exists, inserts an commit record and object record for objectPath.
+// Consumers: Commit
+MultipartUpload.prototype.commitUpload = function commitUpload(parts, cb) {
+    assert.object(parts, 'parts');
+    var log = this.req.log;
+    var self = this;
+
+    loadFinalizingMetadata(self, function (err, upload) {
+        if (err) {
+            if (err.name === 'ObjectNotFoundError') {
+                createObjectMetadata(self, function (err, objectMd) {
+                    if (err) {
+                        cb(err);
+                    } else {
+                        createFinalizingMetadata(self, types.COMMIT, function (finalizingMd) {
+                            var batch = [{
+                                bucket: self.finalizingMd.bucket,
+                                key: self.finalizingMd.key,
+                                value: finalizingMd,
+                                operation: 'put',
+                                opts: {
+                                    req_id: self.req.getId(),
+                                    etag: null
+                                }
+                            }, {
+                                bucket: self.uploadMd.bucket,
+                                key: objectMd.key,
+                                value: objectMd,
+                                operation: 'put',
+                            }];
+                            var opts = {
+                                req_id: self.req.getId()
+                            }
+                            log.info('creating finalizing commit record and object record');
+
+                            self.req.moray.client.batch(batch, opts, function (err, meta) {
+                                if (err) {
+                                    log.info('Error batching data');
+                                    cb(err);
+                                } else {
+                                    log.info('Batch successful');
+                                    cb();
+                                }
+                            });
+                        });
+                    }
+                });
+            } else {
+                cb(err);
+            }
+        } else {
+            log.info('Finalizing record already exists: type:' + self.finalizingMd.loaded.upload.type);
+            // I think this is an error regardless of type, because it could've been a commit with a different set of parts. For abort, it's fine to have another abort record, though.
+            cb(new MultipartUploadFinalizeConflictError(self.id, types.COMMIT));
+        }
+    });
+}
+
+//--- Get
+/*
+ * Returns a object representation of the upload that can be serialized as JSON
+ * and sent to the client.
+ */
+MultipartUpload.prototype.getUpload = function getUpload(cb) {
+    var log = this.req.log;
+    var self = this;
+
+    loadUploadMetadata(self, function (err, md) {
+        if (err) {
+            cb(err);
+        } else {
+            //XXX: Other useful things to include here?
+            var upload = {
+                id: self.id,
+                uploadPath: self.uploadPath,
+                objectPath: self.objectPath,
+                state: md.state,
+                sharks: md.sharks,
+                headers: md.headers,
+                numCopies: md.copies
+            }
+
+            if (md.type) {
+                upload.type = md.type;
+            }
+
+            if (md.parts) {
+                upload.parts = md.parts;
+            }
+
+            cb(null, upload);
+        }
+    });
+}
+
+
+///--- API: MultipartUpload getters/setters
+
+MultipartUpload.prototype.sharks = function sharks() {
+    var sharks = null;
+    if (this.uploadMd && this.uploadMd.loaded) {
+        sharks = this.uploadMd.loaded.upload.sharks;
+    }
+
+    return (sharks);
+}
+
+
+MultipartUpload.prototype.parts = function parts() {
+    var parts = null;
+    if (this.uploadMd && this.uploadMd.loaded) {
+        parts = this.uploadMd.loaded.upload.parts;
+    }
+    assert.ok(parts);
+    return (parts);
+}
+
+
+MultipartUpload.prototype.uploadPathKey = function uploadPathKey() {
+    var uploadPathKey = null;
+    if (this.uploadMd) {
+        uploadPathKey = this.uploadMd.key;
+    }
+    assert.ok(uploadPathKey);
+    return (uploadPathKey);
+}
+
+
+MultipartUpload.prototype.headers = function headers() {
+    assert.ok(this._headers);
+    assert.object(this._headers);
+
+    return (this._headers);
+}
+
+
+MultipartUpload.prototype.setHeaders = function setHeaders(headers) {
+    this._headers = headers;
+}
+
+
+MultipartUpload.prototype.size = function size() {
+    assert.ok(this._size);
+    assert.number(this._size);
+    assert.ok(this._size >= 0);
+
+    return (this._size);
+}
+
+
+MultipartUpload.prototype.setSize = function setSize(size) {
+    this._size = size;
+}
+
+
+MultipartUpload.prototype.objectPath = function objectPath() {
+    assert.ok(this._objectPath);
+    assert.string(this._objectPath);
+
+    return (this._objectPath);
+}
+
+
+MultipartUpload.prototype.setObjectPath = function setObjectPath(objectPath) {
+    this._objectPath = objectPath;
+}
+
+
+MultipartUpload.prototype.objectPathKey = function objectPathKey() {
+    return (this._objectPathKey);
+}
+
+
+MultipartUpload.prototype.setObjectPathKey = function setObjectPathKey(objectPathKey) {
+    this._objectPathKey = objectPathKey;
+}
+
+
+MultipartUpload.prototype.copies = function copies() {
+    assert.ok(this._copies);
+    assert.number(this._copies);
+
+    return (this._copies);
+}
+
+
+MultipartUpload.prototype.setCopies = function setCopies(copies) {
+    this._copies = copies;
+}
+
+
+MultipartUpload.prototype.contentMD5 = function contentMD5() {
+    assert.ok(this._contentMD5);
+    assert.string(this._contentMD5);
+
+    return (this._contentMD5);
+}
+
+
+MultipartUpload.prototype.setContentMD5 = function setContentMD5(md5) {
+    this._contentMD5 = md5;
+}
+
+
+///--- Exports
+
+module.exports = {
+    
+    uploadStates: states,
+    uploadTypes: types,
+
+    MultipartUpload: MultipartUpload,
+
+    setupUpload: setupUpload,
+};
diff --git a/lib/uploads/create.js b/lib/uploads/create.js
new file mode 100644
index 0000000..e3a4505
--- /dev/null
+++ b/lib/uploads/create.js
@@ -0,0 +1,205 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+
+var libmanta = require('libmanta');
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+var verror = require('verror');
+
+var sprintf = util.format;
+
+
+///--- Helpers
+
+/*
+ * Selects the sharks for the upload through the picker.choose interface.
+ *
+ * The number of sharks needed and the size of the sharks are specified by
+ * the durability-level and the content-length headers, respectively, or
+ * set to a default value.
+ */
+function chooseSharks(req, cb) {
+    var log = req.log;
+
+    var size = req.upload.size();
+    if (size === 0) {
+        cb(null, {});
+    } else {
+        var opts = {
+            requestId: req.getId(),
+            replicas: req.upload.copies(),
+            size: size
+        };
+        req.picker.choose(opts, function (err, sharks) {
+            if (err) {
+                cb(err);
+            } else {
+                log.info('upload: sharks chosen');
+                // sharks[0].datacenter, sharks[0].manta_storage_id
+                sharks[0].forEach(function (s) { log.info(s.manta_storage_id); });
+                cb(null, sharks);
+            }
+        });
+    }
+}
+
+
+///--- API
+
+// Instantiates the uploads object.
+function setupUpload(req, res, next) {
+    var log = req.log;
+    var id = libuuid.create();
+    req.upload = new uploadsCommon.MultipartUpload(req, id);
+
+    next();
+}
+
+/*
+ * Validates that all parameters needed for creating an upload exist, including:
+ *   - objectPath (the final path the uploaded object resides)
+ *
+ * Also validates optional headers, if they exist:
+ *   - durability-level
+ *   - content-length
+ */
+function validateParams(req, res, next) {
+    if (!req.body.objectPath) {
+        next(new MultipartUploadMissingObjecPathError());
+    } else {
+        var size, copies;
+
+        var headers = req.body.headers || {};
+        var maxObjectCopies = req.config.maxObjectCopies;
+
+        len = parseInt((headers['content-length'] || obj.DEF_MAX_LEN), 10);
+        if (len < 0) {
+            next(new MaxContentLengthError(len));
+            return;
+        }
+
+        copies = parseInt((headers['durability-level'] || 2), 10);
+        if (copies < 1 || copies > (maxObjectCopies || 9)) {
+            next(new InvalidDurabilityLevelError(1, maxObjectCopies));
+            return;
+        }
+
+        req.upload.setObjectPath(req.body.objectPath);
+        req.upload.setHeaders(headers);
+        req.upload.setSize(len);
+        req.upload.setCopies(copies);
+        next();
+    }
+}
+
+
+/*
+ * Checks if the parent of the upload directory exists, and if it doesn't,
+ * creates the directory.
+ *
+ * For example,if the prefix length for an upload ID is 1, and the id is abcdef,
+ * the prefix directory is of the form: /account/uploads/a.
+ */
+function ensurePrefixDir(req, res, next) {
+    var log = req.log;
+    var requestId = req.getId();
+    var id = req.upload.id;
+    log.info('creating upload ' + id + ' for path: \"' + req.body.objectPath + '\"');
+
+    var parentOpts = {
+        key: path.dirname(req.upload.uploadPathKey()),
+        requestId: requestId
+    }
+    log.info('upload path directory key: ' + parentOpts.key);
+
+    req.moray.getMetadata(parentOpts, function (err, md, wrap) {
+        if (err) {
+            if (verror.hasCauseWithName(err, 'ObjectNotFoundError')) {
+                // If the directory doesn't exist yet, create it.
+                parentOpts.dirname = path.dirname(parentOpts.key);
+                parentOpts.mtime = Date.now();
+                parentOpts.owner = req.owner.account.uuid;
+                parentOpts.requestId = req.getId();
+                parentOpts.type = 'directory';
+                //TODO: headers, roles, _etag
+
+                req.moray.putMetadata(parentOpts, function (err, md, wrap) {
+                    if (err) {
+                        next(err);
+                    } else {
+                        //TODO: need to save parent metadata here?
+                        log.info('prefix directory \"' + parentOpts.key + '\" created');
+                        next();
+                    }
+                });
+            } else {
+                next(err);
+            }
+        } else {
+            log.info('prefix directory \"' + parentOpts.key + '\" already created');
+            next();
+        }
+    });
+}
+
+
+/*
+ * Actually create the upload in the sense that the upload record exists.
+ * To do so, we must first choose the sharks that the final object will
+ * live on and save the metadata for the upload record.
+ */
+function createUpload(req, res, next) {
+    var log = req.log;
+
+    chooseSharks(req, function (err, sharks) {
+        if (err) {
+            next(err);
+        } else {
+            req.upload.createUpload(sharks, function (err, partsDirectory) {
+                    if (err) {
+                        next(err);
+                    } else {
+                        req.log.info('responding OK for upload ' + req.upload.id);
+                        res.send(201, {
+                            id: req.upload.id,
+                            partsDirectory: partsDirectory
+                        });
+                        next();
+                    }
+            });
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    createHandler: function createHandler() {
+        var chain = [
+            restify.jsonBodyParser({
+                mapParams: false,
+                maxBodySize: 100000
+            }),
+            setupUpload,
+            validateParams,
+            ensurePrefixDir,
+            createUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/get.js b/lib/uploads/get.js
new file mode 100644
index 0000000..4b9ad16
--- /dev/null
+++ b/lib/uploads/get.js
@@ -0,0 +1,39 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+
+///--- API
+
+function getUpload(req, res, next) {
+    req.upload.getUpload(function (err, upload) {
+        if (err) {
+            next(err);
+        } else {
+            res.send(200, upload);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+
+    getHandler: function getHandler() {
+        var chain = [
+            uploadsCommon.setupUpload,
+            getUpload
+        ];
+        return (chain);
+    }
+};
diff --git a/lib/uploads/index.js b/lib/uploads/index.js
new file mode 100644
index 0000000..da67ab5
--- /dev/null
+++ b/lib/uploads/index.js
@@ -0,0 +1,29 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+///--- Helpers
+
+function reExport(obj) {
+    Object.keys(obj || {}).forEach(function (k) {
+        module.exports[k] = obj[k];
+    });
+}
+
+
+
+///--- Exports
+
+module.exports = {};
+reExport(require('./create'));
+reExport(require('./upload'));
+reExport(require('./commit'));
+reExport(require('./abort'));
+reExport(require('./get'));
+reExport(require('./redirect'));
diff --git a/lib/uploads/redirect.js b/lib/uploads/redirect.js
new file mode 100644
index 0000000..6148d32
--- /dev/null
+++ b/lib/uploads/redirect.js
@@ -0,0 +1,85 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var uploadsCommon = require('./common');
+
+var assert = require('assert-plus');
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+
+
+
+///--- API
+
+/*
+ * Gets the ID from the request URL, which is either of the form:
+ *      /<account>/uploads/<id>
+ * or
+ *      /<account>/uploads/<id>/<partNum>
+ */
+function parseId(req, res, next) {
+
+    if (req.params && req.params.partNum) {
+        req.params.id = path.basename(path.dirname(req.url));
+    } else {
+        req.params.id = path.basename(req.url);
+    }
+
+    req.log.info('redirect started for id: ' + req.params.id);
+    next();
+}
+
+
+/*
+ * Redirects the request by looking up the upload path using the upload ID.
+ */
+function redirect(req, res, next) {
+    var log = req.log;
+    
+    var prefix = req.params.id.charAt(0);
+    var url = '/' + req.params.account + '/uploads/' +  prefix + '/' + req.params.id;
+    var key = '/' + req.key.split('/')[1] + '/uploads/' +  prefix + '/' + req.params.id; //TODO better way to do this?
+
+    // Make sure this ID actually exists before sending a response.
+    var opts = {
+        key: key,
+        requestId: req.getId()
+    };
+    req.moray.getMetadata(opts, function (err, record, wrap) {
+        if (err) {
+            next(err);
+        } else {
+            if (req.params.partNum) {
+                url += '/' + req.params.partNum;
+                key += '/' + req.params.partNum;
+            }
+
+            log.info('Redirecting \"' + req.url + '\"  to \"' + url + '\"');
+            res.setHeader('Location', url);
+            res.send(301);
+            next();
+        }
+    });
+}
+
+
+///--- Exports
+
+module.exports = {
+    redirectHandler: function redirectHandler() {
+        var chain = [
+            parseId,
+            redirect
+        ];
+        return (chain);
+    }
+
+};
diff --git a/lib/uploads/upload.js b/lib/uploads/upload.js
new file mode 100644
index 0000000..d0e0570
--- /dev/null
+++ b/lib/uploads/upload.js
@@ -0,0 +1,120 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var common = require('../common');
+var obj = require('../obj');
+var uploadsCommon = require('./common');
+
+var libuuid = require('libuuid');
+var path = require('path');
+var restify = require('restify');
+var vasync = require('vasync');
+
+
+///--- API
+
+/*
+ * Does some basic validation on the part before proceeding to the normal PUT
+ * path, including:
+ *   - ensuring the partNum is valid
+ *   - ensuring the upload hasn't been finalized yet
+ *   - ensuring client isn't trying to change the number of copies of the object
+ */
+function validate(req, res, next) {
+    var log = req.log;
+    var id = req.upload.id;
+    log.info('validate');
+
+    var regex = /^([1-9][0-9]{0,3}|10000)$/;
+    var partNum = req.params.partNum;
+    var valid = regex.test(partNum);
+
+    if (!valid) {
+        next(new MultipartUploadPartNumError(req.upload.id(), partNum));
+    } else {
+        log.info('validating state');
+        req.upload.uploadState(function (err, state) {
+            if (err) {
+                next(err);
+            } else {
+                if (state !== uploadsCommon.uploadStates.CREATED) {
+                    next(new MultipartUploadFinalizeConflictError(id,
+                        'upload part for'));
+                } else {
+                    var k = 'durability-level';
+                    if (req.headers[k]) {
+                        next(new InvalidUpdateError(k));
+                    } else {
+                        next();
+                    }
+                }
+            }
+        });
+    }
+}
+
+
+/*
+ * The PUT handling code relies on some state being set up on the request
+ * object that is done by handlers not used for uploading parts.
+ *
+ * This handler ensures that the state needed for the PUT handling code
+ * is available so that the PUT handling code we do use for uploading
+ * parts works seamlessly.
+ */
+function setupPutState(req, res, next) {
+    var upload = req.upload;
+
+    // Ensure zero-byte objects aren't streamed to mako.
+    if (req.upload.size() === 0) {
+        req._zero = true;
+    }
+
+    // Ensure that the PUT handling code can find the correct sharks to use.
+    req._sharks = [upload.sharks()];
+
+    // Fake a durability-level header that matches the header
+    // specified on upload creation.
+    req.headers['durability-level'] = req.upload.copies();
+
+    next();
+}
+
+
+///--- Exports
+
+//  PUT handlers not included in this chain, in order:
+//      - conditionalRequest()
+//      - ensureNotRootHandler()
+//      [parseArguments]
+//      - ensureNotDirectoryHandler()
+//      - ensureParentHandler()
+//      - enforceDirectoryCount
+//      [other PUT handlers]
+//
+//      TODO: I think I need: conditionalRequest, enforceDirectoryCount
+module.exports = {
+    uploadPartHandler: function uploadPartHandler() {
+        var chain = [
+            uploadsCommon.setupUpload,
+            validate,
+            setupPutState, //TODO: add mechanism to enforce max individual part size based on object size specified during create()
+
+            // Piggybacking on existing PUT code.
+            //restify.conditionalRequest,//TODO: this makes request hang
+            obj.parseArguments,
+            obj.startSharkStreams,
+            obj.sharkStreams,
+            obj.saveMetadata
+        ];
+
+        return (chain);
+    }
+};
diff --git a/package.json b/package.json
index cbf77f6..047e50a 100644
--- a/package.json
+++ b/package.json
@@ -19,6 +19,7 @@
         "deep-equal": "0.0.0",
         "dtrace-provider": "0.2.8",
         "http-signature": "1.1.0",
+        "jsprim": "1.3.1",
         "kang": "1.1.0",
         "keep-alive-agent": "0.0.1",
         "keyapi": "git+ssh://git@github.com:joyent/keyapi.git#c30dd2710ad2175095dc0e96479686fa774b8063",
@@ -33,7 +34,7 @@
         "once": "1.3.0",
         "restify": "2.6.3",
         "vasync": "1.4.3",
-        "verror": "^1.7.0",
+        "verror": "1.9.0",
         "watershed": "0.3.0",
         "xtend": "2.1.1"
     },
