From f458818b938d1b5a5fc14f256fc85a50be4aff37 Mon Sep 17 00:00:00 2001
From: Jerry Jelinek <jerry.jelinek@joyent.com>
Date: Wed, 10 May 2017 22:04:40 +0000
Subject: [PATCH] OS-6080 xsave area should size dynamically, based on CPU
 features

---
 usr/src/uts/common/os/lwp.c           | 13 ++++
 usr/src/uts/i86pc/os/cpuid.c          | 19 ++++--
 usr/src/uts/i86pc/os/machdep.c        |  9 ++-
 usr/src/uts/intel/ia32/ml/exception.s | 13 +++-
 usr/src/uts/intel/ia32/ml/float.s     | 13 +++-
 usr/src/uts/intel/ia32/os/archdep.c   |  8 +--
 usr/src/uts/intel/ia32/os/fpu.c       | 94 +++++++++++++++++++++------
 usr/src/uts/intel/sys/fp.h            | 16 +++--
 usr/src/uts/intel/sys/x86_archext.h   |  1 +
 9 files changed, 144 insertions(+), 42 deletions(-)

diff --git a/usr/src/uts/common/os/lwp.c b/usr/src/uts/common/os/lwp.c
index cde81f511a..37d32cba76 100644
--- a/usr/src/uts/common/os/lwp.c
+++ b/usr/src/uts/common/os/lwp.c
@@ -746,6 +746,10 @@ grow:
 		BROP(p)->b_initlwp_post(lwp);
 	}
 
+#if defined(__x86)
+	fp_lwp_init(lwp);
+#endif
+
 	if (state == TS_RUN) {
 		/*
 		 * We set the new lwp running immediately.
@@ -1864,6 +1868,9 @@ forklwp(klwp_t *lwp, proc_t *cp, id_t lwpid)
 {
 	klwp_t *clwp;
 	void *tregs, *tfpu;
+#if defined(__x86)
+	struct xsave_state *xsp;
+#endif
 	kthread_t *t = lwptot(lwp);
 	kthread_t *ct;
 	proc_t *p = lwptoproc(lwp);
@@ -1898,6 +1905,9 @@ forklwp(klwp_t *lwp, proc_t *cp, id_t lwpid)
 	tregs = clwp->lwp_regs;
 	tfpu = clwp->lwp_fpu;
 	brand_data = clwp->lwp_brand;
+#if defined(__x86)
+	xsp = clwp->lwp_pcb.pcb_fpu.fpu_regs.kfpu_u.kfpu_xs;
+#endif
 
 	/*
 	 * Copy parent lwp to child lwp.  Hold child's p_lock to prevent
@@ -1925,6 +1935,9 @@ forklwp(klwp_t *lwp, proc_t *cp, id_t lwpid)
 	ct->t_sysnum = t->t_sysnum;
 	clwp->lwp_regs = tregs;
 	clwp->lwp_fpu = tfpu;
+#if defined(__x86)
+	fp_lwp_dup(clwp, xsp);
+#endif
 	clwp->lwp_brand = brand_data;
 	clwp->lwp_ap = clwp->lwp_arg;
 	clwp->lwp_procp = cp;
diff --git a/usr/src/uts/i86pc/os/cpuid.c b/usr/src/uts/i86pc/os/cpuid.c
index e1459a8b12..20eccb4907 100644
--- a/usr/src/uts/i86pc/os/cpuid.c
+++ b/usr/src/uts/i86pc/os/cpuid.c
@@ -282,11 +282,12 @@ struct mwait_info {
 /*
  * xsave/xrestor info.
  *
- * This structure contains HW feature bits and size of the xsave save area.
- * Note: the kernel uses a fixed size (AVX_XSAVE_SIZE) to store supported
- * hardware features. Our xsave area does not handle new features beyond AVX
- * and it does not optimize for potential memory savings if features in the
- * middle or end of the save area are not enabled.
+ * This structure contains HW feature bits and the size of the xsave save area.
+ * Note: the kernel declares a fixed size (AVX_XSAVE_SIZE) structure
+ * (xsave_state) to describe the xsave layout. However, at runtime the
+ * per-lwp xsave area is dynamically allocated based on xsav_max_size. The
+ * xsave_state structure simply represents the legacy layout of the beginning
+ * of the xsave area.
  */
 struct xsave_info {
 	uint32_t	xsav_hw_features_low;   /* Supported HW features */
@@ -3531,6 +3532,14 @@ cpuid_get_addrsize(cpu_t *cpu, uint_t *pabits, uint_t *vabits)
 		*vabits = cpi->cpi_vabits;
 }
 
+size_t
+cpuid_get_xsave_size()
+{
+	return ((cpuid_info0.cpi_xsave.xsav_max_size >=
+	    sizeof (struct xsave_state)) ?
+	    cpuid_info0.cpi_xsave.xsav_max_size : sizeof (struct xsave_state));
+}
+
 /*
  * Returns the number of data TLB entries for a corresponding
  * pagesize.  If it can't be computed, or isn't known, the
diff --git a/usr/src/uts/i86pc/os/machdep.c b/usr/src/uts/i86pc/os/machdep.c
index 674e6e2bbc..74f0ea96bb 100644
--- a/usr/src/uts/i86pc/os/machdep.c
+++ b/usr/src/uts/i86pc/os/machdep.c
@@ -21,6 +21,7 @@
 
 /*
  * Copyright (c) 1992, 2010, Oracle and/or its affiliates. All rights reserved.
+ * Copyright 2017, Joyent, Inc.
  */
 /*
  * Copyright (c) 2010, Intel Corporation.
@@ -889,10 +890,14 @@ lwp_stk_init(klwp_t *lwp, caddr_t stk)
 	return (stk);
 }
 
-/*ARGSUSED*/
+/*
+ * Use this opportunity to free any dynamically allocated fp storage.
+ */
 void
 lwp_stk_fini(klwp_t *lwp)
-{}
+{
+	fp_lwp_cleanup(lwp);
+}
 
 /*
  * If we're not the panic CPU, we wait in panic_idle for reboot.
diff --git a/usr/src/uts/intel/ia32/ml/exception.s b/usr/src/uts/intel/ia32/ml/exception.s
index e7a004efe5..5855ef4b81 100644
--- a/usr/src/uts/intel/ia32/ml/exception.s
+++ b/usr/src/uts/intel/ia32/ml/exception.s
@@ -1,6 +1,7 @@
 /*
  * Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2013, 2014 by Delphix. All rights reserved.
+ * Copyright (c) 2017 Joyent, Inc.
  */
 
 /*
@@ -667,6 +668,9 @@ _emul_done:
 	ALTENTRY(ndptrap_frstor)
 	.globl  _patch_xrstorq_rbx
 _patch_xrstorq_rbx:
+	nop
+	nop
+	nop
 	FXRSTORQ	((%rbx))
 	cmpw	$KCS_SEL, REGOFF_CS(%rsp)
 	je	.return_to_kernel
@@ -742,6 +746,9 @@ _patch_xrstorq_rbx:
 	ALTENTRY(ndptrap_frstor)
 	.globl  _patch_xrstorq_rbx
 _patch_xrstorq_rbx:
+	nop
+	nop
+	nop
 	FXRSTORQ	((%rbx))
 	popq	%rdx
 	popq	%rbx
@@ -808,8 +815,10 @@ _patch_xrstorq_rbx:
 _patch_fxrstor_ebx:
 	.globl  _patch_xrstor_ebx
 _patch_xrstor_ebx:
-	frstor	(%ebx)		/* may be patched to fxrstor */
-	nop			/* (including this byte) */
+	frstor	(%ebx)		/* may be patched to fxrstor or xrstor */
+	nop			/* (including these bytes) */
+	nop
+	nop
 	popl	%gs
 	popl	%ds
 	popl	%edx
diff --git a/usr/src/uts/intel/ia32/ml/float.s b/usr/src/uts/intel/ia32/ml/float.s
index 5a8962c9ff..002b7e6947 100644
--- a/usr/src/uts/intel/ia32/ml/float.s
+++ b/usr/src/uts/intel/ia32/ml/float.s
@@ -21,6 +21,7 @@
 
 /*
  * Copyright (c) 1992, 2010, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /*      Copyright (c) 1990, 1991 UNIX System Laboratories, Inc. */
@@ -203,10 +204,11 @@ _lfence_ret_insn:			/ see membar_consumer()
 	/
 	/	frstor (%ebx); nop	-> xrstor (%ebx)
 	/
-	_HOT_PATCH(_xrstor_ebx_insn, _patch_xrstor_ebx, 3)
+	_HOT_PATCH(_xrstor_ebx_insn, _patch_xrstor_ebx, 5)
 	_HOT_PATCH_EPILOG
 	ret
 _xrstor_ebx_insn:			/ see ndptrap_frstor()
+	movl	(%ebx), %ebx
 	#xrstor (%ebx)
 	.byte	0x0f, 0xae, 0x2b
 	SET_SIZE(patch_xsave)
@@ -232,12 +234,14 @@ patch_xsave(void)
 	pushq	%rbp
 	pushq	%r15
 	/
+	/	nop; nop; nop;		-> movq(%rbx), %rbx
 	/	FXRSTORQ (%rbx);	-> xrstor (%rbx)
-	/ hot_patch(_xrstor_rbx_insn, _patch_xrstorq_rbx, 4)
+	/ loop doing the following for 7 bytes:
+	/     hot_patch_kernel_text(_patch_xrstorq_rbx, _xrstor_rbx_insn, 1)
 	/
 	leaq	_patch_xrstorq_rbx(%rip), %rbx
 	leaq	_xrstor_rbx_insn(%rip), %rbp
-	movq	$4, %r15
+	movq	$7, %r15
 1:
 	movq	%rbx, %rdi			/* patch address */
 	movzbq	(%rbp), %rsi			/* instruction byte */
@@ -254,6 +258,7 @@ patch_xsave(void)
 	ret
 
 _xrstor_rbx_insn:			/ see ndptrap_frstor()
+	movq	(%rbx), %rbx
 	#rex.W=1 (.byte 0x48)
 	#xrstor (%rbx)
 	.byte	0x48, 0x0f, 0xae, 0x2b
@@ -327,6 +332,7 @@ fpnsave_ctxt(void *arg)
 	movl	FPU_CTX_FPU_XSAVE_MASK(%rdi), %eax
 	movl	FPU_CTX_FPU_XSAVE_MASK+4(%rdi), %edx
 	leaq	FPU_CTX_FPU_REGS(%rdi), %rsi
+	movq	(%rsi), %rsi
 	#xsave	(%rsi)
 	.byte	0x0f, 0xae, 0x26
 	
@@ -387,6 +393,7 @@ fpnsave_ctxt(void *arg)
 	movl	FPU_CTX_FPU_XSAVE_MASK(%ecx), %eax
 	movl	FPU_CTX_FPU_XSAVE_MASK+4(%ecx), %edx
 	leal	FPU_CTX_FPU_REGS(%ecx), %ecx
+	movl	(%ecx), %ecx
 	#xsave	(%ecx)
 	.byte	0x0f, 0xae, 0x21
 	
diff --git a/usr/src/uts/intel/ia32/os/archdep.c b/usr/src/uts/intel/ia32/os/archdep.c
index c96aff4a19..d8b4f5d6e8 100644
--- a/usr/src/uts/intel/ia32/os/archdep.c
+++ b/usr/src/uts/intel/ia32/os/archdep.c
@@ -25,7 +25,7 @@
 /*	Copyright (c) 1984, 1986, 1987, 1988, 1989 AT&T	*/
 /*	  All Rights Reserved  	*/
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  * Copyright 2012 Nexenta Systems, Inc.  All rights reserved.
  */
 
@@ -307,10 +307,10 @@ setfpregs(klwp_t *lwp, fpregset_t *fp)
 
 	case FP_XSAVE:
 		fpregset_to_fxsave(fp,
-		    &fpu->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave);
+		    &fpu->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave);
 		fpu->fpu_regs.kfpu_xstatus =
 		    fp->fp_reg_set.fpchip_state.xstatus;
-		fpu->fpu_regs.kfpu_u.kfpu_xs.xs_xstate_bv |=
+		fpu->fpu_regs.kfpu_u.kfpu_xs->xs_xstate_bv |=
 		    (XFEATURE_LEGACY_FP | XFEATURE_SSE);
 		break;
 	default:
@@ -370,7 +370,7 @@ getfpregs(klwp_t *lwp, fpregset_t *fp)
 			break;
 		case FP_XSAVE:
 			fxsave_to_fpregset(
-			    &fpu->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave, fp);
+			    &fpu->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave, fp);
 			fp->fp_reg_set.fpchip_state.xstatus =
 			    fpu->fpu_regs.kfpu_xstatus;
 			break;
diff --git a/usr/src/uts/intel/ia32/os/fpu.c b/usr/src/uts/intel/ia32/os/fpu.c
index dc3e286ad5..c6dbaf92ce 100644
--- a/usr/src/uts/intel/ia32/os/fpu.c
+++ b/usr/src/uts/intel/ia32/os/fpu.c
@@ -219,8 +219,10 @@ fp_new_lwp(kthread_id_t t, kthread_id_t ct)
 	case FP_XSAVE:
 		cfp->fpu_xsave_mask = fp->fpu_xsave_mask;
 
-		fx = &fp->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave;
-		cxs = &cfp->fpu_regs.kfpu_u.kfpu_xs;
+		VERIFY(fp->fpu_regs.kfpu_u.kfpu_xs != NULL);
+
+		fx = &fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave;
+		cxs = cfp->fpu_regs.kfpu_u.kfpu_xs;
 		cfx = &cxs->xs_fxsave;
 
 		bcopy(&avx_initial, cxs, sizeof (*cxs));
@@ -247,12 +249,12 @@ fp_new_lwp(kthread_id_t t, kthread_id_t ct)
 /*
  * Free any state associated with floating point context.
  * Fp_free can be called in three cases:
- * 1) from reaper -> thread_free -> ctxfree -> fp_free
+ * 1) from reaper -> thread_free -> freectx-> fp_free
  *	fp context belongs to a thread on deathrow
  *	nothing to do,  thread will never be resumed
  *	thread calling ctxfree is reaper
  *
- * 2) from exec -> ctxfree -> fp_free
+ * 2) from exec -> freectx -> fp_free
  *	fp context belongs to the current thread
  *	must disable fpu, thread calling ctxfree is curthread
  *
@@ -313,7 +315,7 @@ fp_save(struct fpu_ctx *fp)
 		break;
 
 	case FP_XSAVE:
-		xsave(&fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
+		xsave(fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
 		break;
 	default:
 		panic("Invalid fp_save_mech");
@@ -344,7 +346,7 @@ fp_restore(struct fpu_ctx *fp)
 		break;
 
 	case FP_XSAVE:
-		xrestore(&fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
+		xrestore(fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
 		break;
 	default:
 		panic("Invalid fp_save_mech");
@@ -392,6 +394,57 @@ fp_seed(void)
 	fp->fpu_flags = FPU_EN;
 }
 
+/*
+ * When using xsave/xrstor, these three functions are used by the lwp code to
+ * manage the memory for the xsave area.
+ */
+void
+fp_lwp_init(void *l)
+{
+	if (fp_save_mech == FP_XSAVE) {
+		klwp_t *lwp = (klwp_t *)l;
+		struct fpu_ctx *fp = &lwp->lwp_pcb.pcb_fpu;
+
+		ASSERT(cpuid_get_xsave_size() >= sizeof (struct xsave_state));
+
+		/*
+		 * We use zalloc since the fpinit() code path will only
+		 * partially initialize the xsave area using avx_inital.
+		 */
+		fp->fpu_regs.kfpu_u.kfpu_xs =
+		    kmem_zalloc(cpuid_get_xsave_size(), KM_SLEEP);
+	}
+}
+
+void
+fp_lwp_cleanup(void *l)
+{
+	klwp_t *lwp = (klwp_t *)l;
+	struct fpu_ctx *fp = &lwp->lwp_pcb.pcb_fpu;
+
+	if (fp_save_mech == FP_XSAVE && fp->fpu_regs.kfpu_u.kfpu_xs != NULL) {
+
+		kmem_free(fp->fpu_regs.kfpu_u.kfpu_xs, cpuid_get_xsave_size());
+		fp->fpu_regs.kfpu_u.kfpu_xs = NULL;
+	}
+}
+
+void
+fp_lwp_dup(void *lp, void *xsp)
+{
+	if (fp_save_mech == FP_XSAVE) {
+		klwp_t *l = (klwp_t *)lp;
+		struct xsave_state *xp = (struct xsave_state *)xsp;
+
+		/* copy the parent's values into the new lwp's struct */
+		bcopy(l->lwp_pcb.pcb_fpu.fpu_regs.kfpu_u.kfpu_xs,
+		    xp, sizeof (struct xsave_state));
+		/* now fix the pointer */
+		l->lwp_pcb.pcb_fpu.fpu_regs.kfpu_u.kfpu_xs = xp;
+	}
+}
+
+
 /*
  * This routine is called from trap() when User thread takes No Extension
  * Fault. The possiblities are:
@@ -420,11 +473,6 @@ fpnoextflt(struct regs *rp)
 #endif	/* __i386 */
 #endif	/* !__lint */
 
-	/*
-	 * save area MUST be 16-byte aligned, else will page fault
-	 */
-	ASSERT(((uintptr_t)(&fp->fpu_regs.kfpu_u.kfpu_fx) & 0xf) == 0);
-
 	kpreempt_disable();
 	/*
 	 * Now we can enable the interrupts.
@@ -559,14 +607,14 @@ fpexterrflt(struct regs *rp)
 		break;
 
 	case FP_XSAVE:
-		fpsw = fp->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave.fx_fsw;
-		fpcw = fp->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave.fx_fcw;
-		fp->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave.fx_fsw &= ~FPS_SW_EFLAGS;
+		fpsw = fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave.fx_fsw;
+		fpcw = fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave.fx_fcw;
+		fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave.fx_fsw &= ~FPS_SW_EFLAGS;
 		/*
 		 * Always set LEGACY_FP as it may have been cleared by XSAVE
 		 * instruction
 		 */
-		fp->fpu_regs.kfpu_u.kfpu_xs.xs_xstate_bv |= XFEATURE_LEGACY_FP;
+		fp->fpu_regs.kfpu_u.kfpu_xs->xs_xstate_bv |= XFEATURE_LEGACY_FP;
 		break;
 	default:
 		panic("Invalid fp_save_mech");
@@ -620,10 +668,14 @@ fpsimderrflt(struct regs *rp)
 	 */
 	fp_save(fp); 		/* save the FPU state */
 
-	mxcsr = fp->fpu_regs.kfpu_u.kfpu_fx.fx_mxcsr;
-
-	fp->fpu_regs.kfpu_status = fp->fpu_regs.kfpu_u.kfpu_fx.fx_fsw;
-
+	if (fp_save_mech == FP_XSAVE) {
+		mxcsr = fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave.fx_mxcsr;
+		fp->fpu_regs.kfpu_status =
+		    fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave.fx_fsw;
+	} else {
+		mxcsr = fp->fpu_regs.kfpu_u.kfpu_fx.fx_mxcsr;
+		fp->fpu_regs.kfpu_status = fp->fpu_regs.kfpu_u.kfpu_fx.fx_fsw;
+	}
 	fp->fpu_regs.kfpu_xstatus = mxcsr;
 
 	/*
@@ -741,14 +793,14 @@ fpsetcw(uint16_t fcw, uint32_t mxcsr)
 		break;
 
 	case FP_XSAVE:
-		fx = &fp->fpu_regs.kfpu_u.kfpu_xs.xs_fxsave;
+		fx = &fp->fpu_regs.kfpu_u.kfpu_xs->xs_fxsave;
 		fx->fx_fcw = fcw;
 		fx->fx_mxcsr = sse_mxcsr_mask & mxcsr;
 		/*
 		 * Always set LEGACY_FP as it may have been cleared by XSAVE
 		 * instruction
 		 */
-		fp->fpu_regs.kfpu_u.kfpu_xs.xs_xstate_bv |= XFEATURE_LEGACY_FP;
+		fp->fpu_regs.kfpu_u.kfpu_xs->xs_xstate_bv |= XFEATURE_LEGACY_FP;
 		break;
 	default:
 		panic("Invalid fp_save_mech");
diff --git a/usr/src/uts/intel/sys/fp.h b/usr/src/uts/intel/sys/fp.h
index 1b4cce820f..c0aef56a3a 100644
--- a/usr/src/uts/intel/sys/fp.h
+++ b/usr/src/uts/intel/sys/fp.h
@@ -233,10 +233,13 @@ struct fxsave_state {
  * This structure is written to memory by an 'xsave' instruction.
  * First 512 byte is compatible with the format of an 'fxsave' area.
  *
- * The current size is AVX_XSAVE_SIZE (832 bytes), asserted in fpnoextflt().
- * Enabling MPX and AVX512 requires a total size of 2696 bytes. The locations
- * and size of new, extended components are determined dynamically by
- * querying the CPU. See the xsave_info structure in cpuid.c.
+ * The size is at least AVX_XSAVE_SIZE (832 bytes), asserted in fpnoextflt().
+ * Enabling additional xsave-related CPU features increases the size.
+ * We dynamically allocate the per-lwp xsave area at runtime, based on the
+ * size needed for the CPU-specific features. The xsave_sate structure simply
+ * defines the legacy layout of the beginning of the xsave area. The locations
+ * and size of new, extended components are determined dynamically by querying
+ * the CPU. See the xsave_info structure in cpuid.c.
  */
 struct xsave_state {
 	struct fxsave_state	xs_fxsave;
@@ -255,7 +258,7 @@ typedef struct {
 #if defined(__i386)
 		struct fnsave_state kfpu_fn;
 #endif
-		struct xsave_state kfpu_xs;
+		struct xsave_state *kfpu_xs;
 	} kfpu_u;
 	uint32_t kfpu_status;		/* saved at #mf exception */
 	uint32_t kfpu_xstatus;		/* saved at #xm exception */
@@ -305,6 +308,9 @@ extern int fpextovrflt(struct regs *);
 extern int fpexterrflt(struct regs *);
 extern int fpsimderrflt(struct regs *);
 extern void fpsetcw(uint16_t, uint32_t);
+extern void fp_lwp_init(void *);
+extern void fp_lwp_cleanup(void *);
+extern void fp_lwp_dup(void *, void *);
 
 #endif	/* _KERNEL */
 
diff --git a/usr/src/uts/intel/sys/x86_archext.h b/usr/src/uts/intel/sys/x86_archext.h
index 1055706561..d606947533 100644
--- a/usr/src/uts/intel/sys/x86_archext.h
+++ b/usr/src/uts/intel/sys/x86_archext.h
@@ -787,6 +787,7 @@ extern uint_t cpuid_get_procnodeid(struct cpu *cpu);
 extern uint_t cpuid_get_procnodes_per_pkg(struct cpu *cpu);
 extern uint_t cpuid_get_compunitid(struct cpu *cpu);
 extern uint_t cpuid_get_cores_per_compunit(struct cpu *cpu);
+extern size_t cpuid_get_xsave_size();
 extern int cpuid_is_cmt(struct cpu *);
 extern int cpuid_syscall32_insn(struct cpu *);
 extern int getl2cacheinfo(struct cpu *, int *, int *, int *);
-- 
2.21.0

