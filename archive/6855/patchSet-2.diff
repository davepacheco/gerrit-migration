commit e923235b7379e265e68c645bab3d101ab7d7d3f4
Author: Rui Loura <rui@joyent.com>
Date:   2019-08-30T15:22:10-04:00 (5 weeks ago)
    
    MANTA-4513 add metadata updater threadpool
    MANTA-4470 add thread to rebalancer zone to query agent for completed assignments and process them
    MANTA-4521 rebalancer zone should use batched database updates

diff --git a/Cargo.toml b/Cargo.toml
index aff4b40..a32c238 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -14,6 +14,7 @@ libmanta = { git = "https://github.com/joyent/rust-libmanta", tag = "v0.1.0" }
 clap = "2.33.0"
 sharkspotter = { git = "https://github.com/joyent/rust-sharkspotter", tag = "v0.2.0" }
 crossbeam-channel = "0.3.8"
+crossbeam-deque = "0.7.1"
 serde = { version = "1.0.91", features = ["derive"] }
 serde_derive = "1.0.91"
 serde_json = "1.0.39"
@@ -24,12 +25,8 @@ mime = "0.3.13"
 # TODO: remove in favor of rust-libmanta
 moray = { git = "https://github.com/joyent/rust-moray", tag = "v0.1.0" }
 futures = "0.1.27"
-tokio = "0.1.21"
-tokio-threadpool = "0.1.14"
-tokio-async-await = "0.1.7"
-tokio-core = "0.1"
 trust-dns-resolver = "0.11.1"
-threadpool = "1.0"
+threadpool = "1.7.1"
 reqwest = "0.9.18"
 url = "1.7"
 md-5 = "0.8.0"
@@ -50,6 +47,8 @@ slog-bunyan = { git = "https://github.com/kellymclaughlin/bunyan", branch = "bui
 
 ## TODO: is this needed?
 slog-term = "2.4.1" 
+crc = "1.8.1"
+unescape = "0.1.0"
 
 
 [patch.crates-io]
diff --git a/src/error.rs b/src/error.rs
index d66fc39..b24f086 100644
--- a/src/error.rs
+++ b/src/error.rs
@@ -17,6 +17,7 @@ pub enum Error {
     Hyper(hyper::Error),
     Diesel(diesel::result::Error),
     SerdeJson(serde_json::error::Error),
+    Reqwest(reqwest::Error),
 }
 
 impl std::error::Error for Error {
@@ -27,6 +28,7 @@ impl std::error::Error for Error {
             Error::Hyper(e) => e.description(),
             Error::Diesel(e) => e.description(),
             Error::SerdeJson(e) => e.description(),
+            Error::Reqwest(e) => e.description(),
         }
     }
 }
@@ -61,6 +63,12 @@ impl From<serde_json::error::Error> for Error {
     }
 }
 
+impl From<reqwest::Error> for Error {
+    fn from(error: reqwest::Error) -> Self {
+        Error::Reqwest(error)
+    }
+}
+
 impl fmt::Display for Error {
     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
         match self {
@@ -69,6 +77,7 @@ impl fmt::Display for Error {
             Error::Hyper(e) => write!(f, "{}", e),
             Error::Diesel(e) => write!(f, "{}", e),
             Error::SerdeJson(e) => write!(f, "{}", e),
+            Error::Reqwest(e) => write!(f, "{}", e),
         }
     }
 }
diff --git a/src/jobs/evacuate.rs b/src/jobs/evacuate.rs
index fde0eef..f68c10a 100644
--- a/src/jobs/evacuate.rs
+++ b/src/jobs/evacuate.rs
@@ -16,18 +16,23 @@ use crate::jobs::{
     TaskStatus,
 };
 use crate::picker::{self as mod_picker, SharkSource, StorageNode};
+use crate::util;
 
 use std::collections::HashMap;
 use std::error::Error as _Error;
 use std::io::ErrorKind;
 use std::sync::{Arc, Mutex, RwLock};
 use std::thread;
+use std::time::Duration;
 
-use bytes::Bytes;
 use crossbeam_channel as crossbeam;
+use crossbeam_deque::{Injector, Steal};
 use libmanta::moray::{MantaObject, MantaObjectShark};
+use moray::objects::{Etag, MethodOptions};
+use reqwest;
 use slog::{o, Drain, Logger};
 use std::borrow::Borrow;
+use threadpool::ThreadPool;
 use uuid::Uuid;
 
 // --- Diesel Stuff, TODO This should be refactored --- //
@@ -36,12 +41,13 @@ use diesel::prelude::*;
 
 // TODO: move database stuff somewhere.
 table! {
-    use diesel::sql_types::Text;
+    use diesel::sql_types::{Text, Integer};
     use super::EvacuateObjectStatusMapping;
     evacuateobjects (id) {
         id -> Text,
         object -> Text,
         assignment_id -> Text,
+        shard -> Integer,
         status -> EvacuateObjectStatusMapping,
     }
 }
@@ -54,15 +60,22 @@ struct UpdateEvacuateObject<'a> {
 
 #[derive(Insertable, Queryable, Identifiable, AsChangeset, Debug, PartialEq)]
 #[table_name = "evacuateobjects"]
-pub struct EvacuateObjectInsertable {
+pub struct EvacuateObjectDB {
+    pub assignment_id: AssignmentId,
     pub id: String,
     pub object: String,
-    pub assignment_id: AssignmentId,
+    pub shard: i32,
     pub status: EvacuateObjectStatus,
 }
 
 // --- END Diesel Stuff --- //
 
+#[derive(Debug)]
+pub struct SharkSpotterObject {
+    pub shard: i32,
+    pub object: MantaObject,
+}
+
 #[derive(Debug, Clone, PartialEq, DbEnum)]
 pub enum EvacuateObjectStatus {
     Unprocessed,    // Default state
@@ -85,20 +98,22 @@ impl Default for EvacuateObjectStatus {
 /// progress through the evacuation process.
 #[derive(Debug, Default, Clone)]
 pub struct EvacuateObject {
-    pub id: ObjectId,        // MantaObject ObjectId
-    pub object: MantaObject, // The MantaObject being rebalanced
     pub assignment_id: AssignmentId,
     // UUID of assignment this object was most recently part of.
+    pub id: ObjectId,        // MantaObject ObjectId
+    pub object: MantaObject, // The MantaObject being rebalanced
+    pub shard: i32,         // shard number of metadata object record
     pub status: EvacuateObjectStatus,
     // Status of the object in the evacuation job
 }
 
 impl EvacuateObject {
-    fn new(object: MantaObject) -> Self {
+    fn new(ssobj: SharkSpotterObject) -> Self {
         Self {
-            id: object.object_id.to_owned(),
-            object,
             assignment_id: Uuid::new_v4().to_string(),
+            id: ssobj.object.object_id.to_owned(),
+            object: ssobj.object,
+            shard: ssobj.shard,
             ..Default::default()
         }
     }
@@ -106,11 +121,12 @@ impl EvacuateObject {
 
 impl EvacuateObject {
     // TODO: ToSql for EvacuateObject MANTA-4474
-    fn to_insertable(&self) -> Result<EvacuateObjectInsertable, Error> {
-        Ok(EvacuateObjectInsertable {
-            id: self.id.clone(),
+    fn to_insertable(&self) -> Result<EvacuateObjectDB, Error> {
+        Ok(EvacuateObjectDB {
             assignment_id: self.assignment_id.clone(),
+            id: self.id.clone(),
             object: serde_json::to_string(&self.object)?,
+            shard: self.shard,
             status: self.status.clone(),
         })
     }
@@ -133,16 +149,22 @@ pub struct EvacuateDestShark {
 pub struct EvacuateJob {
     /// Hash of destination sharks that may change during the job execution.
     pub dest_shark_list: RwLock<HashMap<StorageId, EvacuateDestShark>>,
+
     /// Hash of in progress assignments.
-    pub assignments: RwLock<HashMap<String, Assignment>>,
+    pub assignments: RwLock<HashMap<AssignmentId, Assignment>>,
+
     /// The shark to evacuate.
     pub from_shark: MantaObjectShark,
+
     /// The minimum available space for a shark to be considered a destination.
     pub min_avail_mb: Option<u64>,
+
     /// Maximum number of tasks to include in a single assignment.
     pub max_tasks_per_assignment: Option<u32>,
+
     /// SqliteConnection to local database.
     pub conn: Mutex<SqliteConnection>,
+
     /// Accumulator for total time spent on DB inserts. (test/dev)
     pub total_db_time: Mutex<u128>,
 }
@@ -173,7 +195,7 @@ impl EvacuateJob {
         // need to handle this a bit more gracefully in the future for
         // restarting jobs...
 
-        let conn = self.conn.lock().unwrap();
+        let conn = self.conn.lock().expect("DB conn lock");
         conn.execute(r#"DROP TABLE evacuateobjects"#)
             .unwrap_or_else(|e| {
                 debug!("Table doesn't exist: {}", e);
@@ -186,6 +208,7 @@ impl EvacuateJob {
                     id TEXT PRIMARY KEY,
                     object TEXT,
                     assignment_id TEXT,
+                    shard Integer,
                     status TEXT CHECK(status IN ('unprocessed', 'processing',
                     'skipped', 'post_processing', 'complete')) NOT NULL
                 );
@@ -246,24 +269,27 @@ impl EvacuateJob {
         // the assignment_manager thread join.
         assignment_manager
             .join()
-            .unwrap()
-            .expect("Error joining assignment generator thread");
+            .expect("Assignment Manager")
+            .expect("Error joining assignment manager thread");
 
         picker.fini();
 
-        sharkspotter_thread.join().unwrap().unwrap_or_else(|e| {
-            error!("Error joining sharkspotter handle: {}\n", e);
-            std::process::exit(1);
+        sharkspotter_thread
+            .join()
+            .expect("Sharkspotter Thread")
+            .unwrap_or_else(|e| {
+                error!("Error joining sharkspotter handle: {}\n", e);
+                std::process::exit(1);
         });
 
         generator_thread
             .join()
-            .unwrap()
+            .expect("Generator Thread")
             .expect("Error joining assignment generator thread");
 
         post_thread
             .join()
-            .unwrap()
+            .expect("Post Thread")
             .expect("Error joining assignment processor thread");
 
         Ok(())
@@ -273,7 +299,7 @@ impl EvacuateJob {
     fn shark_busy(&self, shark: &StorageNode) -> bool {
         self.dest_shark_list
             .read()
-            .unwrap()
+            .expect("dest_shark_list read lock")
             .get(shark.manta_storage_id.as_str())
             .map_or(false, |eds| {
                 debug!(
@@ -295,7 +321,9 @@ impl EvacuateJob {
 
         debug!("checking assignments");
         let mut updated_shark_count = 0;
-        let mut assignments = self.assignments.write().unwrap();
+        let mut assignments = self.assignments
+            .write()
+            .expect("assignments write lock");
         for assignment in assignments.values_mut() {
             if assignment.state != AssignmentState::Assigned {
                 continue;
@@ -303,7 +331,7 @@ impl EvacuateJob {
 
             let _uri = format!(
                 "http://{}/assignment/{}",
-                assignment.dest_shark, assignment.id
+                assignment.dest_shark.manta_storage_id, assignment.id
             );
             // TODO agent: make request to agent "uri" for assignment status
 
@@ -315,19 +343,19 @@ impl EvacuateJob {
             if let Some(dest_shark) = self
                 .dest_shark_list
                 .write()
-                .unwrap()
-                .get_mut(assignment.dest_shark.as_str())
+                .expect("desk_shark_list write lock")
+                .get_mut(assignment.dest_shark.manta_storage_id.as_str())
             {
                 debug!(
                     "Updating shark '{}' to Ready state",
-                    assignment.dest_shark.as_str()
+                    assignment.dest_shark.manta_storage_id.as_str()
                 );
                 dest_shark.status = DestSharkStatus::Ready;
                 updated_shark_count += 1;
             } else {
                 warn!(
                     "Could not find shark: '{}'",
-                    assignment.dest_shark.as_str()
+                    assignment.dest_shark.manta_storage_id.as_str()
                 );
             }
 
@@ -343,7 +371,9 @@ impl EvacuateJob {
     /// shark list accordingly.  This may need to change so that we update
     /// available_mb more judiciously (i.e. based on timestamp).
     fn update_dest_sharks(&self, new_sharks: &[StorageNode]) {
-        let mut dest_shark_list = self.dest_shark_list.write().unwrap();
+        let mut dest_shark_list = self.dest_shark_list
+            .write()
+            .expect("update dest_shark_list write lock");
         for sn in new_sharks.iter() {
             if let Some(dest_shark) =
                 dest_shark_list.get_mut(sn.manta_storage_id.as_str())
@@ -381,7 +411,7 @@ impl EvacuateJob {
         use self::evacuateobjects::dsl::*;
 
         let insertable = obj.to_insertable()?;
-        let locked_conn = self.conn.lock().unwrap();
+        let locked_conn = self.conn.lock().expect("DB conn lock");
         let now = std::time::Instant::now();
 
         // TODO: Is panic the right thing to do here?
@@ -394,7 +424,7 @@ impl EvacuateJob {
                 panic!(msg);
             });
 
-        let mut total_time = self.total_db_time.lock().unwrap();
+        let mut total_time = self.total_db_time.lock().expect("DB time lock");
         *total_time += now.elapsed().as_millis();
 
         Ok(ret)
@@ -408,11 +438,11 @@ impl EvacuateJob {
         use self::evacuateobjects::dsl::*;
 
         let objs = vec_objs.borrow();
-        let insertable_objs: Vec<EvacuateObjectInsertable> = objs
+        let insertable_objs: Vec<EvacuateObjectDB> = objs
             .iter()
             .map(|o| o.to_insertable())
             .collect::<Result<Vec<_>, _>>()?;
-        let locked_conn = self.conn.lock().unwrap();
+        let locked_conn = self.conn.lock().expect("db conn lock");
 
         let now = std::time::Instant::now();
         let ret = diesel::insert_into(evacuateobjects)
@@ -423,30 +453,65 @@ impl EvacuateJob {
                 error!("{}", msg);
                 panic!(msg);
             });
-        let mut total_time = self.total_db_time.lock().unwrap();
+        let mut total_time = self.total_db_time.lock().expect("DB time lock");
         *total_time += now.elapsed().as_millis();
 
         Ok(ret)
     }
 
-    // TODO: Batched update: MANTA-4464
-    fn mark_object_post_processing(&self, obj_id: &str) -> usize {
-        use self::evacuateobjects::dsl::status;
+    /// Mark all objects with a given assignment ID with the specified
+    /// EvacuateObjectStatus
+    fn mark_assignment_objects(
+        &self,
+        id: &AssignmentId,
+        to_status: EvacuateObjectStatus
+    ) -> usize {
+        use self::evacuateobjects::dsl::{
+            evacuateobjects,
+            assignment_id,
+            status,
+        };
 
-        let insertable = UpdateEvacuateObject { id: obj_id };
+        let locked_conn = self.conn.lock().expect("DB conn lock");
 
-        let locked_conn = self.conn.lock().unwrap();
-        diesel::update(&insertable)
-            .set(status.eq(EvacuateObjectStatus::PostProcessing))
+        diesel::update(evacuateobjects)
+            .filter(assignment_id.eq(id))
+            .set(status.eq(to_status))
             .execute(&*locked_conn)
             .unwrap_or_else(|e| {
-                let msg = format!("Error updating object: {} ({})", obj_id, e);
+                let msg = format!("Error updating assignment: {} ({})",
+                    id, e);
                 error!("{}", msg);
                 panic!(msg);
             })
     }
+
+    // TODO
+    #[allow(dead_code)]
+    fn mark_dest_shark_ready(&self, dest_shark: &StorageNode) {
+        if let Some(shark) = self
+            .dest_shark_list
+            .write()
+            .expect("dest_shark_list write")
+            .get_mut(dest_shark.manta_storage_id.as_str())
+        {
+            debug!(
+                "Updating shark '{}' to Ready state",
+                dest_shark.manta_storage_id.as_str()
+            );
+            shark.status = DestSharkStatus::Ready;
+        } else {
+            warn!(
+                "Could not find shark: '{}'",
+                dest_shark.manta_storage_id.as_str()
+            );
+        }
+    }
 }
 
+/// 1. Set AssignmentState to Assigned.
+/// 2. Insert assignment that has been successfully posted to the Agent into the
+///    EvacauteJob's hash of assignments.
 fn assignment_post_success(
     job_action: &EvacuateJob,
     mut assignment: Assignment,
@@ -477,16 +542,78 @@ impl PostAssignment for EvacuateJob {
     }
 }
 
-impl ProcessAssignment for EvacuateJob {
-    fn process(&self, returned_assignment: Bytes) -> Result<(), Error> {
-        // TODO: dont unwrap throughout
+impl GetAssignment for EvacuateJob {
+   fn get(&self, assignment: &Assignment) -> Result<AgentAssignment, Error> {
+       let uri = format!("http://{}/{}",
+                         assignment.dest_shark.manta_storage_id,
+                         assignment.id);
 
-        let assignment_u8: &[u8] = &returned_assignment;
-        let agent_assignment: AgentAssignment =
-            serde_json::from_slice(assignment_u8)?;
-        let uuid = &agent_assignment.uuid;
+       let mut ret = reqwest::get(&uri)?;
+       ret.json::<AgentAssignment>().map_err(Error::from)
+   }
+}
+
+impl UpdateMetadata for EvacuateJob {
+    fn update_shark(
+        &self,
+        mut object: MantaObject,
+        new_shark: &StorageNode,
+    ) -> Result<MantaObject, Error> {
+        let old_shark = &self.from_shark;
+        let obj = serde_json::to_string(&object)?;
+        let etag = match util::crc_hex_str(&obj) {
+            Some(o) => o,
+            None => return Err(InternalError::new(
+                None,
+                "Error getting etag from Manta Object")
+                .into())
+        };
+
+        // Replace shark value
+        let mut shark_found = false;
+        for shark in object.sharks.iter_mut() {
+            if shark.manta_storage_id == old_shark.manta_storage_id {
+                shark.manta_storage_id = new_shark.manta_storage_id.clone();
+                shark.datacenter = new_shark.datacenter.clone();
+                if !shark_found {
+                    shark_found = true;
+                } else {
+                    error!("Found duplicate shark");
+                }
+            }
+        }
+
+        // Prepare metadata message.
+        let key = object.key.as_str();
+        let value = serde_json::to_value(&object)
+            .expect("Serialize Manta Object");
+        let mut opts = MethodOptions::default();
 
-        let mut assignments = self.assignments.write().unwrap();
+        opts.etag = Etag::Specified(etag);
+
+        debug!("Updating metadata. Key: {}\nValue: {}\nopts: {:?}",
+           key, value, opts);
+
+        // TODO: The EvacuateJob struct should implement a moray client hash
+        // and we can call a "get_moray_client()" method here that will
+        // get an existing client, or create a new client if need be.
+        /*
+        mclient.put_object("manta", key, value, &opts, |o| {
+                debug!("Updated object metadata: {}", &o);
+                Ok(())
+            },
+        ).expect("put_object");
+        */
+        Ok(object)
+    }
+}
+
+impl ProcessAssignment for EvacuateJob {
+    fn process(&self, agent_assignment: AgentAssignment) -> Result<(), Error> {
+        let uuid = &agent_assignment.uuid;
+        let mut assignments = self.assignments
+            .write()
+            .expect("assignments read lock");
 
         // std::option::NoneError is still nightly-only experimental
         let assignment = match assignments.get_mut(uuid) {
@@ -509,6 +636,17 @@ impl ProcessAssignment for EvacuateJob {
             }
         };
 
+        // If for some reason this assignment is in the wrong state don't
+        // update it.
+        match assignment.state {
+            AssignmentState::Assigned => (),
+            _ => {
+                warn!("Assignment in unexpected state '{:?}', skipping",
+                      assignment.state);
+                return Ok(());
+            }
+        }
+
         debug!(
             "Checking agent assignment state: {:#?}",
             &agent_assignment.stats.state
@@ -521,10 +659,27 @@ impl ProcessAssignment for EvacuateJob {
             AgentAssignmentState::Complete(None) => {
                 // mark all EvacuateObjects with this assignment id as
                 // successful
+                assignment.state = AssignmentState::Complete;
+                self.mark_assignment_objects(
+                    &assignment.id,
+                    EvacuateObjectStatus::PostProcessing
+                );
 
-                for id in assignment.tasks.keys() {
-                    self.mark_object_post_processing(id);
-                }
+
+                    // Couple options here.  We could:
+                    // - mark all task's in as Complete (waiting for md
+                    // update) and then pass the entire assignment to the
+                    // metadata update broker
+                    // - pass the assignment uuid to the metadata update
+                    // broker and have it do a DB lookup for all objects
+                    // matching this Assignment Uuid.
+                    // - Build a new structure for metadata updates that
+                    // looks like:
+                    //  struct AssignmentMetadataUpdate {
+                    //      dest_shark: <StorageId>,
+                    //      Objects: <MantaObject>, // this could be updated
+                    // with the dest_shark above
+                    //  }
             }
             AgentAssignmentState::Complete(Some(failed_tasks)) => {
                 dbg!(&failed_tasks);
@@ -544,7 +699,7 @@ impl ProcessAssignment for EvacuateJob {
 /// prematurely the sender.send() method will return a SenderError and that
 /// needs to be handled properly.
 fn start_sharkspotter(
-    sender: crossbeam::Sender<MantaObject>,
+    obj_tx: crossbeam::Sender<SharkSpotterObject>,
     domain: &str,
     job_action: Arc<EvacuateJob>,
     min_shard: u32,
@@ -571,7 +726,7 @@ fn start_sharkspotter(
         .name(String::from("sharkspotter"))
         .spawn(move || {
             let mut count = 0;
-            sharkspotter::run(config, log, move |obj, _shard| {
+            sharkspotter::run(config, log, move |object, shard| {
                 // while testing, limit the number of objects processed for now
                 count += 1;
                 if count > 2000 {
@@ -581,8 +736,8 @@ fn start_sharkspotter(
                     ));
                 }
 
-                // TODO: add shard number?
-                sender.send(obj).map_err(CrossbeamError::from).map_err(|e| {
+                let ssobj = SharkSpotterObject{shard: shard as i32, object};
+                obj_tx.send(ssobj).map_err(CrossbeamError::from).map_err(|e| {
                     std::io::Error::new(ErrorKind::Other, e.description())
                 })
             })
@@ -633,9 +788,11 @@ where
             loop {
                 // TODO: allow for premature cancellation
                 trace!("shark index: {}", shark_index);
-                if valid_sharks.is_empty()
-                    || shark_index
-                        >= job_action.dest_shark_list.read().unwrap().len()
+                if valid_sharks.is_empty() ||
+                    shark_index >= job_action.dest_shark_list
+                        .read()
+                        .expect("desk_shark_list read lock len")
+                        .len()
                 {
                     shark_index = 0;
 
@@ -643,6 +800,7 @@ where
                     job_action.check_assignments()?;
 
                     // Check for a new picker snapshot
+                    // TODO: MANTA-4519
                     valid_sharks = match picker
                         .choose(&mod_picker::PickerAlgorithm::Default(&algo))
                     {
@@ -675,7 +833,7 @@ where
                     shark_list = job_action
                         .dest_shark_list
                         .read()
-                        .unwrap()
+                        .expect("dest_shark_list read lock")
                         .values()
                         .map(|v| v.shark.to_owned())
                         .collect();
@@ -698,7 +856,7 @@ where
                 // Only use half of the available space per shark per assignment
                 let assignment = Assignment {
                     id: Uuid::new_v4().to_string(),
-                    dest_shark: cur_shark.manta_storage_id.clone(),
+                    dest_shark: cur_shark.clone(),
                     max_size: cur_shark.available_mb / 2,
                     total_size: 0,
                     tasks: HashMap::new(),
@@ -732,7 +890,7 @@ fn _continue_adding_tasks(
 /// in the assignment template received.
 /// 4. Send filled out assignment back to assignment manager thread.
 fn start_assignment_generator(
-    obj_rx: crossbeam::Receiver<MantaObject>,
+    obj_rx: crossbeam::Receiver<SharkSpotterObject>,
     empty_assignment_rx: crossbeam::Receiver<Assignment>,
     full_assignment_tx: crossbeam::Sender<Assignment>,
     job_action: Arc<EvacuateJob>,
@@ -796,7 +954,8 @@ fn start_assignment_generator(
                     let obj_not_on_dest = obj
                         .sharks
                         .iter()
-                        .find(|s| s.manta_storage_id == assignment.dest_shark)
+                        .find(|s| s.manta_storage_id == assignment.dest_shark
+                            .manta_storage_id)
                         .is_none();
 
                     // We've found the object on the destination shark.  We will
@@ -925,12 +1084,258 @@ fn start_assignment_post(
         .map_err(Error::from)
 }
 
+/// Structures implementing this trait are able to post assignments to an agent.
 trait PostAssignment: Sync + Send {
     fn post(&self, assignment: Assignment) -> Result<(), Error>;
 }
 
+/// Structures implementing this trait are able to process assignments
+/// received from an agent.
 pub trait ProcessAssignment: Sync + Send {
-    fn process(&self, assignment: Bytes) -> Result<(), Error>;
+    fn process(&self, assignment: AgentAssignment) -> Result<(), Error>;
+}
+
+trait UpdateMetadata: Sync + Send {
+    fn update_shark(
+        &self,
+        object: MantaObject,
+        new_shark: &StorageNode,
+    ) -> Result<MantaObject, Error>;
+}
+
+// XXX: async / surf candidate
+/// Structures implementing this trait are able to get assignments from an
+/// agent.
+trait GetAssignment: Sync + Send {
+    fn get(&self, assignment: &Assignment) -> Result<AgentAssignment, Error>;
+}
+
+// TODO
+#[allow(dead_code)]
+fn assignment_get<T>(
+    job_action: Arc<T>,
+    assignment: &Assignment,
+) -> Result<AgentAssignment, Error>
+where
+    T: GetAssignment
+{
+    job_action.get(assignment)
+}
+
+/// Responsible for:
+/// 1. periodically checking the Evacuate Job's hash of assignments that have
+/// reached the Assigned state and, if so, querying the associated Agent for an
+/// update on an that Assigned Assignment.
+///
+/// 2. Upon receipt of a completed assignment from the agent, the assignment is
+/// passed to the process function of the EvacuateJob (which implements the
+/// ProcessAssignment trait), which in turn updates all state of all the
+/// EvacauteObject's in the local DB.
+///
+/// 3. Finally the assignment is sent to the metadata update broker which will
+/// handle updating the metadata of every object in the assignment in the
+/// Manta Metadata tier.
+// TODO
+#[allow(dead_code)]
+fn start_assignment_checker(
+    job_action: Arc<EvacuateJob>,
+    md_update_tx: crossbeam::Sender<Assignment>
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
+    thread::Builder::new()
+        .name(String::from("Assignment Checker"))
+        .spawn(move || {
+            // while job is running??
+            loop {
+                // There's really no need to hold the read lock here.  If
+                // another thread is created at some point to query other
+                // assignments then we simply make an extra HTTP GET call,
+                // perhaps get an already reported assignment back, and when
+                // we take the write lock later we will realize that this
+                // assignment is already in the PostProcess state and skip it.
+                // Under the current implementation that will never happen,
+                // and if it does happen in the future, no harm, no foul.
+                // One alternative would be to take the write lock for the
+                // duration of this loop and process all the assignments
+                // right here, but the number of assignments could grow
+                // significantly and have a significantly negative impact on
+                // performance.
+                let locked_assignments = job_action.assignments
+                    .read()
+                    .expect("assignments");
+
+                let assignments = locked_assignments.clone();
+                drop(locked_assignments);
+
+                for assignment in assignments.values() {
+                    let ag_assignment = assignment_get(
+                        Arc::clone(&job_action),
+                        &assignment)?;
+
+                    // If agent assignment is complete, process it and pass
+                    // it to the metadata update broker.  Otherwise, continue
+                    // to next assignment.
+                    match ag_assignment.stats.state {
+                        AgentAssignmentState::Complete(_) => {
+                            job_action.process(ag_assignment)?
+                        },
+                        _ => continue
+                    }
+
+                    // Mark the shark associated with this assignment as Ready
+                    job_action.mark_dest_shark_ready(&assignment.dest_shark);
+
+                    // XXX: We only really need the assignment ID and the
+                    // dest_shark, so maybe we should create a new struct to
+                    // send this data.  Also, the assignment state is
+                    // probably out of date since we just ran process above.
+                    // Some alternate approaches would be for the
+                    // job_action.process() to return an updated assignment
+                    // and pass that along, or pass this Crossbeam::Sender to
+                    // job_action.process() and send it from there.  The
+                    // latter approach may make testing a bit more difficult.
+                    match md_update_tx.send(assignment.to_owned()) {
+                        Ok(()) => (),
+                        Err(e) => {
+                            error!("Error sending assignment to the metadata \
+                                broker {}", e);
+                        }
+                    }
+                }
+
+                // TODO: Tunable?
+                thread::sleep(Duration::from_secs(20));
+                break;
+            }
+            Ok(())
+        })
+        .map_err(Error::from)
+}
+
+fn metadata_update_worker(
+    job_action: Arc<EvacuateJob>,
+    queue_front: Arc<Injector<Assignment>>,
+) -> impl Fn()
+{
+    move || {
+        use self::evacuateobjects::dsl::{assignment_id, evacuateobjects};
+        loop {
+            let assignment = match queue_front.steal() {
+                Steal::Success(a) => a,
+                Steal::Retry => continue,
+                Steal::Empty => break,
+            };
+
+            let dest_shark = &assignment.dest_shark;
+
+            let locked_conn = job_action.conn.lock().expect("DB conn");
+            let objects: Vec<EvacuateObjectDB> = evacuateobjects
+                .filter(assignment_id.eq(assignment.id))
+                .load::<EvacuateObjectDB>(&*locked_conn)
+                .expect("getting filtered objects");
+
+            drop(locked_conn);
+
+            let mut updated_objects = vec![];
+            for obj in objects {
+                let mut mobj: MantaObject = match serde_json::from_str(
+                    &obj.object
+                ) {
+                    Ok(o) => o,
+                    Err(e) => {
+                        // TODO: log a persistent error for final job report.
+                        error!("Error decoding object {}: {}", &obj.object, e);
+                        continue;
+                    }
+                };
+
+                // This function updates the sharks in both the local copy
+                // (in memory) and in the Manta Metadata tier.
+                mobj = match job_action.update_shark(mobj, dest_shark) {
+                    Ok(o) => o,
+                    Err(e) => {
+                        // TODO: log a persistent error for final job report.
+                        error!(
+                            "Error updating {}, with dest_shark {:?}: {}",
+                            &obj.object, dest_shark, e);
+                        continue;
+                    }
+                };
+
+                updated_objects.push(mobj.object_id.clone());
+            }
+
+            // TODO: batch update all objects in `updated_objects` with
+            // EvacuateObjectStatus::Complete in the local DB meaning we are
+            // completely done and this object has been rebalanced.
+            // This is the finish line.
+        }
+    }
+}
+
+/// This thread runs until EvacuateJob Completion.
+/// When it receives a completed Assignment it will enqueue it into a work queue
+/// and then possibly starts worker thread to do the work.  The worker thread
+/// comes from a pool with a tunable size.  If the max number of worker threads
+/// are already running the completed Assignment stays in the queue to be picked
+/// up by the next available and running worker thread.  Worker threads will
+/// exit if the queue is empty when they finish their current work and check the
+/// queue for the next Assignment.
+///
+/// The plan is for this thread pool size to be the main tunable
+/// controlling our load on the Manta Metadata tier.  The thread pool size can
+/// be changed while the job is running with `.set_num_threads()`.
+/// How we communicate with a running job to tell it to alter its tunables is
+/// still TBD.
+///
+/// One trade off here is whether or not the messages being sent to this
+/// thread are Assignments or individual EvacuateObjects (or
+/// Vec<EvacauteObject>).  By opting for an Assignment (or Vec<EvacuateObject>)
+/// we provide some "tunability" without providing too much rope.  We also
+/// allow for the possibility of doing batched updates on a per worker thread
+/// basis.
+///
+/// Before enqueuing any work it is imperative that that state of the
+/// EvacauteObjects that are about be updated in the metadata tier are in the
+/// correct state in the local DB.  In the event that this thread and/or its
+/// worker(s) die before the metadata is updated in the Manta Metadata tier
+/// we must be able to restart the job, scan the DB for EvacuatedObjects in
+/// the in the PostProcessing state without having to look them up with
+/// sharkspotter again, and download them onto another shark.
+// TODO
+#[allow(dead_code)]
+fn start_metadata_update_broker (
+    job_action: Arc<EvacuateJob>,
+    md_update_rx: crossbeam::Receiver<Assignment>
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
+    // TODO: tunable
+    let pool = ThreadPool::new(2);
+    let queue = Arc::new(Injector::<Assignment>::new());
+    let queue_back = Arc::clone(&queue);
+
+    thread::Builder::new()
+        .name(String::from("Metadata Update broker"))
+        .spawn(move || {
+            loop {
+                let assignment = match md_update_rx.recv() {
+                    Ok(assignment) => assignment,
+                    Err(_) => break,
+                };
+
+                queue_back.push(assignment);
+
+                // XXX: async/await candidate?
+                let worker_job_action = Arc::clone(&job_action);
+                let queue_front = Arc::clone(&queue);
+
+                let worker = metadata_update_worker(
+                    worker_job_action,
+                    queue_front);
+
+                pool.execute(worker);
+            }
+            Ok(())
+        })
+        .map_err(Error::from)
 }
 
 #[cfg(test)]
@@ -1028,13 +1433,11 @@ mod tests {
         );
         let job_action = Arc::new(job_action);
 
-        let handle = start_assignment_manager(
+        let assignment_manager_handle= match start_assignment_manager(
             empty_assignment_tx,
             Arc::clone(&job_action),
             Arc::clone(&picker),
-        );
-
-        let handle = match handle {
+        ) {
             Ok(h) => h,
             Err(e) => {
                 assert_eq!(
@@ -1046,7 +1449,9 @@ mod tests {
             }
         };
 
-        let ret = handle.join().unwrap();
+        let ret = assignment_manager_handle
+            .join()
+            .expect("assignment manager handle");
 
         assert_eq!(ret.is_err(), true);
 
@@ -1074,7 +1479,6 @@ mod tests {
     fn full_test() {
         pretty_env_logger::init();
         let now = std::time::Instant::now();
-
         let picker = MockPicker::new();
         let picker = Arc::new(picker);
         let (empty_assignment_tx, empty_assignment_rx) = crossbeam::bounded(5);
@@ -1091,7 +1495,7 @@ mod tests {
 
         let job_action =
             EvacuateJob::new(String::from("1.stor.joyent.us"), "full_test.db");
-        let conn = job_action.conn.lock().unwrap();
+        let conn = job_action.conn.lock().expect("db connection lock");
         conn.execute(r#"DROP TABLE evacuateobjects"#)
             .unwrap_or_else(|e| {
                 debug!("Table doesn't exist: {}", e);
@@ -1103,11 +1507,11 @@ mod tests {
                 id TEXT PRIMARY KEY,
                 object TEXT,
                 assignment_id TEXT,
+                shard Integer,
                 status TEXT CHECK(status IN ('unprocessed', 'processing',
                 'skipped', 'post_processing', 'complete')) NOT NULL
             );"#,
-        )
-        .unwrap();
+        ).expect("create table");
 
         drop(conn);
 
@@ -1128,7 +1532,11 @@ mod tests {
             .name(String::from("object_generator_test"))
             .spawn(move || {
                 for o in test_objects_copy.into_iter() {
-                    match obj_tx.send(o) {
+                    let ssobj = SharkSpotterObject {
+                        shard: 1,
+                        object: o.clone()
+                    };
+                    match obj_tx.send(ssobj) {
                         Ok(()) => (),
                         Err(e) => {
                             error!(
@@ -1143,20 +1551,30 @@ mod tests {
             })
             .expect("failed to build object generator thread");
 
+        /*
+        let metadata_update_thread = start_metadata_update_broker(
+            Arc::clone(&job_action),
+            md_update_rx,
+        ).expect("start metadata updater thread");
+
+        let assignment_checker_thread = start_assignment_checker(
+            Arc::clone(&job_action),
+            md_update_tx
+        ).expect("start assignment checker thread");
+        */
+
         let generator_thread = start_assignment_generator(
             obj_rx,
             empty_assignment_rx,
             full_assignment_tx,
             Arc::clone(&job_action),
-        )
-        .unwrap();
+        ).expect("start assignment generator");
 
         let manager_thread = start_assignment_manager(
             empty_assignment_tx,
             Arc::clone(&job_action),
             Arc::clone(&picker),
-        )
-        .unwrap();
+        ).expect("start assignment manager");
 
         // TODO: When we add a thread to process completed assignments this
         // will likely have to be refactored.
@@ -1194,18 +1612,10 @@ mod tests {
                         }
                     };
 
-                    let assign_vec = serde_json::to_vec(&ag_assign)
-                        .unwrap_or_else(|e| {
-                            error!("Error convering assignment to bytes {}", e);
-                            panic!("Error");
-                        });
-                    let assign_u8 = Bytes::from(assign_vec);
-
-                    assert!(proc_job_action.process(assign_u8).is_ok());
+                    assert!(proc_job_action.process(ag_assign).is_ok());
                 }
                 info!("Processor thread complete");
-            })
-            .unwrap();
+            }).expect("processing thread");
 
         struct MockJobAction {
             objects: Vec<MantaObject>,
@@ -1245,6 +1655,9 @@ mod tests {
             }
         }
 
+        // TODO
+        //impl GetAssignment for MockJobAction
+
         let mock_job_action = Arc::clone(&Arc::new(MockJobAction {
             objects: test_objects,
             process_tx: assignment_process_tx,
@@ -1255,9 +1668,9 @@ mod tests {
             Err(_) => info!("Done"),
         };
 
-        obj_generator_th.join().unwrap();
+        obj_generator_th.join().expect("object generator thread");
 
-        match manager_thread.join().unwrap() {
+        match manager_thread.join().expect("test assignment manager thread") {
             Ok(()) => (),
             Err(e) => {
                 if let Error::Internal(err) = e {
@@ -1277,7 +1690,7 @@ mod tests {
 
         generator_thread
             .join()
-            .unwrap()
+            .expect("assignment generator thread")
             .expect("Error joining assignment generator thread");
 
         processing_thread
@@ -1287,7 +1700,7 @@ mod tests {
         debug!("TOTAL TIME: {}ms", now.elapsed().as_millis());
         debug!(
             "TOTAL INSERT DB TIME: {}ms",
-            job_action.total_db_time.lock().unwrap()
+            job_action.total_db_time.lock().expect("db time lock")
         );
     }
 }
diff --git a/src/jobs/mod.rs b/src/jobs/mod.rs
index a56de25..2677afa 100644
--- a/src/jobs/mod.rs
+++ b/src/jobs/mod.rs
@@ -11,6 +11,7 @@
 pub mod evacuate;
 
 use crate::config::Config;
+use crate::picker::StorageNode;
 use crate::error::Error;
 
 use std::collections::HashMap;
@@ -76,17 +77,18 @@ impl fmt::Debug for Job {
 
 #[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
 enum AssignmentState {
-    Init,
-    Assigned,
-    Rejected,
-    Complete,
-    PostProcessed,
+    Init,           // Assignment is in the process of being created.
+    Assigned,       // Assignment has been submitted to the Agent.
+    Rejected,       // Agent has rejected the Assignment.
+    Complete,       // Agent as completed its work, and the JobAction is now
+                    // post processing the Assignment.
+    PostProcessed,  // The Assignment has completed all necessary work.
 }
 
 #[derive(Debug, Clone, Serialize, Deserialize)]
 pub struct Assignment {
     id: String,
-    dest_shark: StorageId,
+    dest_shark: StorageNode,
     tasks: HashMap<ObjectId, Task>,
     max_size: u64,
     total_size: u64,
diff --git a/src/picker.rs b/src/picker.rs
index 58e7b77..b8a9366 100644
--- a/src/picker.rs
+++ b/src/picker.rs
@@ -143,6 +143,8 @@ impl Picker {
     }
 }
 
+
+// TODO: MANTA-4519
 impl SharkSource for Picker {
     /// Choose the sharks based on the specified algorithm
     fn choose(&self, algo: &PickerAlgorithm) -> Option<Vec<StorageNode>> {
diff --git a/src/util.rs b/src/util.rs
index a52ec3f..77516a9 100644
--- a/src/util.rs
+++ b/src/util.rs
@@ -8,16 +8,31 @@
  * Copyright 2019, Joyent, Inc.
  */
 
+use crc::crc32;
+use unescape::unescape;
+
 #[cfg(test)]
-use rand::distributions::Alphanumeric;
-#[cfg(test)]
-use rand::Rng;
+use rand::{Rng, distributions::Alphanumeric};
 
 pub fn shard_host2num(shard_host: &str) -> u32 {
     let shard_split: Vec<&str> = shard_host.split('.').collect();
     shard_split[0].parse().unwrap()
 }
 
+pub fn crc_hex_str(data: &str) -> Option<String> {
+    let str_obj = match unescape(data) {
+        Some(o) => o,
+        None => {
+            return None;
+        }
+    };
+    let crc_input = str_obj.trim_matches('"').as_bytes();
+    let etag = crc32::checksum_ieee(crc_input);
+    Some(format!("{:X}", etag))
+}
+
+
+
 // Used in test
 #[cfg(test)]
 pub fn random_string(len: usize) -> String {
