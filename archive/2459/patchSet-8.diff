From 1a56589343fae34afdbcaac9e0308bae26b6aa5c Mon Sep 17 00:00:00 2001
From: Brittany Wald <brittany.wald@joyent.com>
Date: Thu, 24 Aug 2017 23:22:40 +0000
Subject: [PATCH] MANTA-3394 node-fash linter does not check some files

---
 .gitignore                          |   1 +
 Makefile                            |  58 ++++-
 bin/fash.js                         | 126 +++++------
 lib/backend/in_memory.js            |  73 +++---
 lib/backend/leveldb.js              | 241 ++++++++++----------
 lib/common.js                       |   3 +-
 lib/dtrace.js                       |  56 ++---
 lint.sh                             |  12 -
 package.json                        |   9 +-
 test/leveldb.test.js                |   2 +-
 tools/mk/Makefile.defs              |  97 ++++++++
 tools/mk/Makefile.deps              |  54 +++++
 tools/mk/Makefile.node_modules.defs |  68 ++++++
 tools/mk/Makefile.node_modules.targ |  31 +++
 tools/mk/Makefile.targ              | 334 ++++++++++++++++++++++++++++
 15 files changed, 893 insertions(+), 272 deletions(-)
 delete mode 100755 lint.sh
 create mode 100644 tools/mk/Makefile.defs
 create mode 100644 tools/mk/Makefile.deps
 create mode 100644 tools/mk/Makefile.node_modules.defs
 create mode 100644 tools/mk/Makefile.node_modules.targ
 create mode 100644 tools/mk/Makefile.targ

diff --git a/.gitignore b/.gitignore
index 3c3629e..008fb9f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1 +1,2 @@
 node_modules
+make_stamps
\ No newline at end of file
diff --git a/Makefile b/Makefile
index a9318c5..d3e76be 100644
--- a/Makefile
+++ b/Makefile
@@ -8,15 +8,55 @@
 # Copyright (c) 2017, Joyent, Inc.
 #
 
-.PHONY: all test prepush
+#
+# Makefile.defs defines variables used as part of the build process.
+#
+include ./tools/mk/Makefile.defs
+
+#
+# Makefile.node_modules.defs provides a common target for installing modules
+# with NPM from a dependency specification in a "package.json" file.  By
+# including this Makefile, we can depend on $(STAMP_NODE_MODULES) to drive "npm
+# install" correctly.
+#
+include ./tools/mk/Makefile.node_modules.defs
+
+NODE =					node
+NPM =					npm
 
-all:
-	npm install
+#
+# Configuration used by Makefile.defs and Makefile.targ to generate
+# "check" targets.
+#
+JSON_FILES =				package.json
+JS_FILES :=				$(shell find lib bin -name '*.js')
+JSL_FILES_NODE =			$(JS_FILES)
+JSSTYLE_FILES =				$(JS_FILES) \
+					$(shell find test lib bin -name '*.js')
 
-test:
-	npm test
+JSL_CONF_NODE =				tools/jsl.node.conf
+JSSTYLE_FLAGS =				-f tools/jsstyle.conf
 
-prepush:
-	rm -rf node_modules
-	npm install
-	npm test
\ No newline at end of file
+.PHONY: all test
+
+all: $(STAMP_NODE_MODULES)
+
+#
+# The LevelDB tests support three different hashing algorithms. However,
+# the test suite is not built to run tests for all of them in sequence -- at
+# the time of writing, it is not performant enough to complete. In the past,
+# of the three, sha256 has been the default assigned to new hash rings in the
+# codebase. It is assigned here in the interest of backward compatibility.
+#
+test: export LEVELDB_TEST_ALGORITHM=sha256
+test: $(STAMP_NODE_MODULES)
+	    $(NODE) ./node_modules/.bin/nodeunit \
+	    test/*.test.js
+
+#
+# Target definitions.  This is where we include the target Makefiles for
+# the "defs" Makefiles we included above.
+#
+include ./tools/mk/Makefile.deps
+include ./tools/mk/Makefile.targ
+include ./tools/mk/Makefile.node_modules.targ
diff --git a/bin/fash.js b/bin/fash.js
index 7d0b94d..ea04d9c 100755
--- a/bin/fash.js
+++ b/bin/fash.js
@@ -804,78 +804,78 @@ Fash.prototype.do_get_vnodes.help = (
 
 Fash.prototype.do_get_vnode_pnode_and_data =
     function (subcmd, opts, args, callback) {
-        var self = this;
+    var self = this;
 
-        if (opts.help || !opts.v) {
-            this.do_help('help', {}, [subcmd], function (err) {
-                return callback(err ? err : true);
-            });
-        }
+    if (opts.help || !opts.v) {
+        this.do_help('help', {}, [subcmd], function (err) {
+            return callback(err ? err : true);
+        });
+    }
 
-        var hashOptions = {
-            log: self.log
-        };
-        var hash;
-        var constructor;
+    var hashOptions = {
+        log: self.log
+    };
+    var hash;
+    var constructor;
 
-        vasync.pipeline({funcs: [
-            function prepInput(_, cb) {
-                if (!opts.l) {
-                    console.error('leveldb backend requires a location');
-                    self.do_help('help', {}, [subcmd], function (err) {
-                        return callback(err ? err : true);
-                    });
-                } else {
-                    hashOptions.location = opts.l;
-                    return cb();
-                }
-                return (undefined);
-            },
-            function loadRing(_, cb) {
-                // We choose not to support an IN_MEMORY backend.
-                hashOptions.backend = fash.BACKEND.LEVEL_DB;
-                constructor = fash.load;
-                hash = constructor(hashOptions, cb);
-            },
-            function getVnodeArray(_, cb) {
-                var vnodes = common.parseIntArray(opts.v);
-                _.vnodes = vnodes;
+    vasync.pipeline({funcs: [
+        function prepInput(_, cb) {
+            if (!opts.l) {
+                console.error('leveldb backend requires a location');
+                self.do_help('help', {}, [subcmd], function (err) {
+                    return callback(err ? err : true);
+                });
+            } else {
+                hashOptions.location = opts.l;
                 return cb();
-            },
-            function getVnodePnodeAndData(_, cb) {
-                var dataHash = {};
-                function getResults(input, _cb) {
-                    hash.getVnodePnodeAndData(input,
-                        function (err, pnode, vnodeData) {
-                        if (err) {
-                            return _cb(verror.VError(err,
-                                'unable to get pnode and data for for vnode ',
-                                input));
-                        }
-                        dataHash[input] = {};
-                        dataHash[input]['pnode'] = pnode;
-                        dataHash[input]['vnodeData'] = vnodeData;
-                        return _cb(err, null);
-                    });
-                }
-
-                vasync.forEachPipeline({
-                    'inputs': _.vnodes,
-                    'func': getResults
-                }, function (err) {
+            }
+            return (undefined);
+        },
+        function loadRing(_, cb) {
+            // We choose not to support an IN_MEMORY backend.
+            hashOptions.backend = fash.BACKEND.LEVEL_DB;
+            constructor = fash.load;
+            hash = constructor(hashOptions, cb);
+        },
+        function getVnodeArray(_, cb) {
+            var vnodes = common.parseIntArray(opts.v);
+            _.vnodes = vnodes;
+            return cb();
+        },
+        function getVnodePnodeAndData(_, cb) {
+            var dataHash = {};
+            function getResults(input, _cb) {
+                hash.getVnodePnodeAndData(input,
+                    function (err, pnode, vnodeData) {
                     if (err) {
-                        return console.error(new verror.VError(err,
-                            'unable to construct hash for vnode '));
+                        return _cb(verror.VError(err,
+                            'unable to get pnode and data for for vnode ',
+                            input));
                     }
-                    console.log('vnodes: ', dataHash);
+                    dataHash[input] = {};
+                    dataHash[input]['pnode'] = pnode;
+                    dataHash[input]['vnodeData'] = vnodeData;
+                    return _cb(err, null);
                 });
             }
-        ], arg: {}}, function (err) {
-            if (err)
-                console.error(new verror.VError(err));
-        });
 
-        return (undefined);
+            vasync.forEachPipeline({
+                'inputs': _.vnodes,
+                'func': getResults
+            }, function (err) {
+                if (err) {
+                    return console.error(new verror.VError(err,
+                        'unable to construct hash for vnode '));
+                }
+                console.log('vnodes: ', dataHash);
+            });
+        }
+    ], arg: {}}, function (err) {
+        if (err)
+            console.error(new verror.VError(err));
+    });
+
+    return (undefined);
 };
 Fash.prototype.do_get_vnode_pnode_and_data.options = [ {
     names: [ 'v', 'vnodes' ],
diff --git a/lib/backend/in_memory.js b/lib/backend/in_memory.js
index 6e76bf0..c2f64c7 100644
--- a/lib/backend/in_memory.js
+++ b/lib/backend/in_memory.js
@@ -48,7 +48,7 @@ var DATA_NULL = 1;
  *                 topology.
  */
 function ConsistentHash(options, callback) {
-    dtrace._fash_probes['new-start'].fire(function() { return([]); });
+    dtrace._fash_probes['new-start'].fire(function () { return ([]); });
     assert.object(options, 'options');
 
     this.log = options.log;
@@ -122,10 +122,10 @@ function ConsistentHash(options, callback) {
         self.pnodeToVnodeMap_ = topology.pnodeToVnodeMap;
         var pnodeKeys = Object.keys(self.pnodeToVnodeMap_);
 
-        pnodeKeys.forEach(function(pnode) {
+        pnodeKeys.forEach(function (pnode) {
             self.pnodes_.push(pnode);
             var vnodes = self.pnodeToVnodeMap_[pnode];
-            Object.keys(vnodes).forEach(function(vnode) {
+            Object.keys(vnodes).forEach(function (vnode) {
                 var data = vnodes[vnode];
                 self.vnodeToPnodeMap_[vnode] = {
                     pnode: pnode,
@@ -142,18 +142,18 @@ function ConsistentHash(options, callback) {
         self.pnodes_.sort();
 
         log.info('ConsistentHash.new: finished deserializing');
-        dtrace._fash_probes['new-done'].fire(function() {
+        dtrace._fash_probes['new-done'].fire(function () {
             return ([null, 'deserialize']);
         });
     } else {
         log.info('instantiating new ring from scratch.');
         // instantiate pnodeToVnodeMap_
-        self.pnodes_.forEach(function(pnode, index) {
+        self.pnodes_.forEach(function (pnode, index) {
             // make sure there are no duplicate keys in self.pnodes_
             if (pnodeMap[pnode]) {
                 var err = new verror.VError('Unable to instantiate ring, ' +
                     'duplicate pnodes in input');
-                dtrace._fash_probes['new-done'].fire(function() {
+                dtrace._fash_probes['new-done'].fire(function () {
                     return ([err ? err.message : null, 'createNewRing']);
                 });
                 if (callback) {
@@ -206,7 +206,7 @@ function ConsistentHash(options, callback) {
             }
         }
         allocateVnode();
-        dtrace._fash_probes['new-done'].fire(function() {
+        dtrace._fash_probes['new-done'].fire(function () {
             return ([null, 'createNewRing']);
         });
     }
@@ -237,8 +237,8 @@ module.exports = ConsistentHash;
  * @param {function} cb The optional callback f(err).
  */
 ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
-    dtrace._fash_probes['adddata-start'].fire(function() {
-        return([vnode, data]);
+    dtrace._fash_probes['adddata-start'].fire(function () {
+        return ([vnode, data]);
     });
     var self = this;
     var log = self.log;
@@ -286,8 +286,8 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
         data: data
     }, 'ConsistentHash.addData: exiting');
 
-    dtrace._fash_probes['adddata-done'].fire(function() {
-        return([null, vnode, data]);
+    dtrace._fash_probes['adddata-done'].fire(function () {
+        return ([null, vnode, data]);
     });
 
     if (cb) {
@@ -319,8 +319,9 @@ ConsistentHash.prototype.getDataVnodes = function getDataVnodes(cb) {
  *                                    previous pnode owner.
  * @param {function} cb The optional callback f(err).
  */
-ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb) {
-    dtrace._fash_probes['remapvnode-start'].fire(function() {
+ConsistentHash.prototype.remapVnode =
+    function remapVnode(newPnode, vnodes, cb) {
+    dtrace._fash_probes['remapvnode-start'].fire(function () {
         return ([newPnode, vnodes]);
     });
     var self = this;
@@ -330,7 +331,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
         vnodes: vnodes
     }, 'ConsistentHash.remapVnode: entering');
     assert.string(newPnode, 'newPnode');
-    if (typeof(vnodes) === 'number') {
+    if (typeof (vnodes) === 'number') {
         vnodes = [vnodes];
     }
     assert.optionalArrayOfNumber(vnodes, 'vnodes');
@@ -344,7 +345,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
      */
     var vnodeMap = {};
     if (vnodes) {
-        vnodes.forEach(function(v) {
+        vnodes.forEach(function (v) {
             var err;
             if ((v > self.vnodeCount_) || (v < 0)) {
                 err = new verror.VError('vnode ' + v +
@@ -353,12 +354,15 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
                 err = new verror.VError('vnode ' + v +
                                         ' specified more than once');
             } else if (self.vnodeToPnodeMap_[v].pnode === newPnode) {
-                // check that the vnode doesn't already belong to the newPnode.
+                /*
+                 * check that the vnode doesn't already belong to the
+                 * newPnode.
+                 */
                 err = new verror.VError('vnode ' + v +
                                         ' already belongs to pnode');
             }
             if (err) {
-                dtrace._fash_probes['remapvnode-done'].fire(function() {
+                dtrace._fash_probes['remapvnode-done'].fire(function () {
                     return ([err ? err.message : null, newPnode, oldPnode,
                              vnode]);
                 });
@@ -396,21 +400,25 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
 
         /*
          * add vnode to new pnode
-         * 1) move the vnode object from the old pvmap to the new pvmap. Since
-         * we're just moving the vnode, there's no need to write any new values
+         * 1) move the vnode object from the old pvmap to the new pvmap
+         * since we're just moving the vnode, there's no need to write any
+         * new values.
          */
         self.pnodeToVnodeMap_[newPnode][vnode] =
             self.pnodeToVnodeMap_[oldPnode][vnode];
-        // 2) add a new pnode,data object to the vpmap for the current vnode.
+        /*
+         * 2) add a new pnode,data object to the vpmap for the current
+         * vnode
+         */
         self.vnodeToPnodeMap_[vnode] = {
             pnode: newPnode,
             data: vnodeData
         };
 
         /*
-         * remove vnode from current pnode mapping. but first set the value to
-         * 1 -- otherwise the vnode gets removed from the new pnode mappings
-         * as well.
+         * remove vnode from current pnode mapping. but first set the value
+         * to 1, otherwise the vnode gets removed from the new pnode
+         * mappings as well.
          */
         self.pnodeToVnodeMap_[oldPnode][vnode] = 1;
         delete self.pnodeToVnodeMap_[oldPnode][vnode];
@@ -432,7 +440,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
         vnodes: vnodes
     }, 'ConsistentHash.remapVnode: exiting');
 
-    dtrace._fash_probes['remapvnode-done'].fire(function() {
+    dtrace._fash_probes['remapvnode-done'].fire(function () {
         return ([null, newPnode, oldPnode, vnode]);
     });
     if (cb) {
@@ -455,7 +463,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnodes, cb)
  * have changed.
  */
 ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
-    dtrace._fash_probes['removepnode-start'].fire(function() {
+    dtrace._fash_probes['removepnode-start'].fire(function () {
         return ([pnode]);
     });
     var self = this;
@@ -480,7 +488,7 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
     }
 
     if (err) {
-        dtrace._fash_probes['removepnode-done'].fire(function() {
+        dtrace._fash_probes['removepnode-done'].fire(function () {
             return ([err ? err.message : null, pnode]);
         });
         if (cb) {
@@ -498,7 +506,7 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
         pnode: pnode
     }, 'ConsistentHash.removePnode: exiting');
 
-    dtrace._fash_probes['removepnode-done'].fire(function() {
+    dtrace._fash_probes['removepnode-done'].fire(function () {
         return ([err ? err.message : null, pnode]);
     });
 
@@ -553,7 +561,7 @@ ConsistentHash.prototype.getVnodes = function getVnodes(pnode, cb) {
     }
 
     var vnodeArray = [];
-    Object.keys(vnodes).forEach(function(vnode) {
+    Object.keys(vnodes).forEach(function (vnode) {
         vnodeArray.push(parseInt(vnode, 10));
     });
     log.info({
@@ -575,17 +583,18 @@ ConsistentHash.prototype.getVnodes = function getVnodes(pnode, cb) {
  * @returns {pnode, vnode} node The pnode and vnode that the key maps to.
  */
 ConsistentHash.prototype.getNode = function getNode(key, cb) {
-    dtrace._fash_probes['getnode-start'].fire(function() {
+    dtrace._fash_probes['getnode-start'].fire(function () {
         return ([key]);
     });
     assert.optionalFunc(cb, 'callback');
-    var value = crypto.createHash(this.algorithm_.NAME).update(key).digest('hex');
+    var value = crypto.createHash(this.algorithm_.NAME).
+        update(key).digest('hex');
     // find the node that corresponds to this hash.
     var vnode = this.findVnode(value);
     var pnode = this.vnodeToPnodeMap_[vnode].pnode;
     var data = this.pnodeToVnodeMap_[pnode][vnode];
-    dtrace._fash_probes['getnode-done'].fire(function() {
-        return([null, key, value, pnode, vnode, data]);
+    dtrace._fash_probes['getnode-done'].fire(function () {
+        return ([null, key, value, pnode, vnode, data]);
     });
     if (cb) {
         return cb(null, {pnode: pnode, vnode: vnode, data: data});
diff --git a/lib/backend/leveldb.js b/lib/backend/leveldb.js
index 7758343..5472e19 100644
--- a/lib/backend/leveldb.js
+++ b/lib/backend/leveldb.js
@@ -25,7 +25,7 @@ var verror = require('verror');
 
 
 /*
- * level db keys.
+ * LevelDB keys.
  */
 var LKEY_VNODE_COUNT = 'VNODE_COUNT';
 var LKEY_VNODE_DATA = 'VNODE_DATA';
@@ -38,12 +38,12 @@ var LKEY_VERSION = 'VERSION';
 var LKEY_COMPLETE = 'COMPLETE';
 
 /*
- * leveldb values.
+ * LevelDB values.
  */
 var LVAL_NULL = 1;
 
 /*
- * leveldb default config
+ * LevelDB default configuration.
  */
 var LEVEL_CONFIG = {
     createIfMissing: true,
@@ -79,7 +79,7 @@ var LEVEL_CONFIG = {
  *                 topology.
  */
 function ConsistentHash(options, cb) {
-    dtrace._fash_probes['new-start'].fire(function() { return([]); });
+    dtrace._fash_probes['new-start'].fire(function () { return ([]); });
     assert.object(options, 'options');
     assert.optionalObject(options.leveldbCfg, 'options.leveldbCfg');
     assert.string(options.location, 'options.location');
@@ -166,7 +166,7 @@ function ConsistentHash(options, cb) {
         var tasks = [
             function openDb(_, _cb) {
                 _cb = once(_cb);
-                levelup(options.location, self.leveldbCfg_, function(err, db) {
+                levelup(options.location, self.leveldbCfg_, function (err, db) {
                     if (err) {
                         return _cb(new verror.VError(err));
                     }
@@ -182,7 +182,7 @@ function ConsistentHash(options, cb) {
             // step 1
             function putVnodeCount(_, _cb) {
                 _cb = once(_cb);
-                _.db.put(LKEY_VNODE_COUNT, self.vnodeCount_, function(err) {
+                _.db.put(LKEY_VNODE_COUNT, self.vnodeCount_, function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -307,7 +307,7 @@ function ConsistentHash(options, cb) {
                     }, 'writing vnode list for pnode');
                     _.db.put(sprintf(LKEY_PNODE_P, pnode),
                              _.pnodeToVnodeMap[pnode],
-                            function(err)
+                            function (err)
                     {
                         if (err) {
                             err = new verror.VError(err);
@@ -315,7 +315,7 @@ function ConsistentHash(options, cb) {
                         return _cb(err);
                     });
                 }
-                 _.db.put(LKEY_PNODE, Object.keys(pnodeMap), function(err) {
+                 _.db.put(LKEY_PNODE, Object.keys(pnodeMap), function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -324,7 +324,7 @@ function ConsistentHash(options, cb) {
             },
             function writeVnodeDataArray(_, _cb) {
                 _cb = once(_cb);
-                _.db.put(LKEY_VNODE_DATA, [], function(err) {
+                _.db.put(LKEY_VNODE_DATA, [], function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -345,7 +345,7 @@ function ConsistentHash(options, cb) {
                 return _cb();
             },
             function commit(_, _cb) {
-                _.batch.write(function(err) {
+                _.batch.write(function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -355,14 +355,14 @@ function ConsistentHash(options, cb) {
             }
         ];
 
-        vasync.pipeline({funcs: tasks, arg: {}}, function(err) {
+        vasync.pipeline({funcs: tasks, arg: {}}, function (err) {
             if (err) {
                 err = new verror.VError(err, 'unable to create ring');
             }
             log.info({
                 err: err
             }, 'finished instantiated new ring');
-            dtrace._fash_probes['new-done'].fire(function() {
+            dtrace._fash_probes['new-done'].fire(function () {
                 return ([err ? err.message : null, 'createNewRing']);
             });
             return callback(err, self);
@@ -384,7 +384,7 @@ function ConsistentHash(options, cb) {
                 log.info('ConsistentHash.new.deserialize: opening db');
                 //TODO: check to make sure there's nothing already at this
                 //location
-                levelup(options.location, self.leveldbCfg_, function(err, db) {
+                levelup(options.location, self.leveldbCfg_, function (err, db) {
                     if (err) {
                         return _cb(new verror.VError(err));
                     }
@@ -401,7 +401,7 @@ function ConsistentHash(options, cb) {
             // step 1
             function putVnodeCount(_, _cb) {
                 log.info('ConsistentHash.new.deserialize: put vnodeCount');
-                _.db.put(LKEY_VNODE_COUNT, topology.vnodes, function(err) {
+                _.db.put(LKEY_VNODE_COUNT, topology.vnodes, function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -417,7 +417,7 @@ function ConsistentHash(options, cb) {
 
                 // /PNODE
                 var pnodes = Object.keys(pvMap);
-                _.db.put(LKEY_PNODE, pnodes, function(err) {
+                _.db.put(LKEY_PNODE, pnodes, function (err) {
                     if (err) {
                         err = new verror.VError(err);
                         return _cb(err);
@@ -426,12 +426,12 @@ function ConsistentHash(options, cb) {
 
                 // /VNODE/V, /PNODE/P, /P/P/V
                 var pcount = pnodes.length;
-                pnodes.forEach(function(pnode) {
+                pnodes.forEach(function (pnode) {
                     var vnodes = Object.keys(pvMap[pnode]);
                     var vcount = vnodes.length;
 
                     // write /P/P and /V/V. and /P/P/V
-                    vnodes.forEach(function(vnode, index) {
+                    vnodes.forEach(function (vnode, index) {
 
                         /*
                          * json serializes vnode into a string, we need to
@@ -441,7 +441,7 @@ function ConsistentHash(options, cb) {
 
                         // write /V/V
                         _.db.put(sprintf(LKEY_VNODE_V, vnode), pnode,
-                               function(err)
+                               function (err)
                         {
                             if (err) {
                                 err = new verror.VError(err);
@@ -452,13 +452,12 @@ function ConsistentHash(options, cb) {
                         _.db.put(
                             sprintf(LKEY_PNODE_P_V, pnode, vnode),
                             pvMap[pnode][vnode],
-                            function(err) {
+                            function (err) {
                                 if (err) {
                                     err = new verror.VError(err);
                                     return _cb(err);
                                 }
-                            }
-                        );
+                            });
 
                         /*
                          * put the vnode in the VNODE_DATA array if it contains
@@ -477,23 +476,23 @@ function ConsistentHash(options, cb) {
                             _.db.put(
                                 sprintf(LKEY_PNODE_P, pnode),
                                 vnodes,
-                                function(err) {
+                                function (err) {
                                     if (err) {
                                         err = new verror.VError(err);
                                         return _cb(err);
                                     }
-                                }
-                            );
+                                });
                         }
 
                         // write the VNODE_DATA array.
                         if (vcount === 0 && --pcount === 0) {
-                            _.db.put(LKEY_VNODE_DATA, vnodeData, function(err) {
-                                if (err) {
-                                    err = new verror.VError(err);
-                                }
-                                return _cb(err);
-                            });
+                            _.db.put(LKEY_VNODE_DATA, vnodeData,
+                                function (err) {
+                                    if (err) {
+                                        err = new verror.VError(err);
+                                    }
+                                    return _cb(err);
+                                });
                         }
                     });
                 });
@@ -511,21 +510,21 @@ function ConsistentHash(options, cb) {
                 batch.put(LKEY_ALGORITHM, algorithm).
                     put(LKEY_VERSION, fash.VERSION).
                     put(LKEY_COMPLETE, 1);
-                batch.write(function(err) {
+                batch.write(function (err) {
                     if (err) {
                         err = new verror.VError(err);
                     }
                     return _cb(err);
                 });
             }
-        ], arg: {}}, function(err) {
+        ], arg: {}}, function (err) {
             if (err) {
                 err = new verror.VError(err, 'unable to deserialize ring');
             }
             log.info({
                 err: err
             }, 'finished deserializing ring');
-            dtrace._fash_probes['new-done'].fire(function() {
+            dtrace._fash_probes['new-done'].fire(function () {
                 return ([err ? err.message : null, 'deserialize']);
             });
             return callback(err, self);
@@ -538,7 +537,7 @@ function ConsistentHash(options, cb) {
         self.leveldbCfg_.errorIfExists = false;
         vasync.pipeline({funcs: [
             function openDb(_, _cb) {
-                levelup(options.location, self.leveldbCfg_, function(err, db) {
+                levelup(options.location, self.leveldbCfg_, function (err, db) {
                     if (err) {
                         return _cb(new verror.VError(err));
                     }
@@ -551,7 +550,7 @@ function ConsistentHash(options, cb) {
                 });
             },
             function checkComplete(_, _cb) {
-                self.db_.get(LKEY_COMPLETE, function(err, value) {
+                self.db_.get(LKEY_COMPLETE, function (err, value) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -560,20 +559,20 @@ function ConsistentHash(options, cb) {
             },
             function checkVersion(_, _cb) {
                 _cb = once(_cb);
-                self.db_.get(LKEY_VERSION, function(err, version) {
+                self.db_.get(LKEY_VERSION, function (err, version) {
                     if (err) {
                         return _cb(new verror.VError(err));
                     }
                     try {
                         fash.assertVersion(version);
                         return _cb();
-                    } catch(e) {
+                    } catch (e) {
                         return _cb(new verror.VError(e));
                     }
                 });
             },
             function checkVnodes(_, _cb) {
-                self.db_.get(LKEY_VNODE_COUNT, function(err, vnodeCount) {
+                self.db_.get(LKEY_VNODE_COUNT, function (err, vnodeCount) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -585,7 +584,7 @@ function ConsistentHash(options, cb) {
             function checkSlashVnodeSlashN(_, _cb) {
                 // spot check /vnode/largestVnode
                 self.db_.get(sprintf(LKEY_VNODE_V, _.vnodeCount - 1),
-                             function(err, pnode) {
+                             function (err, pnode) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -593,8 +592,8 @@ function ConsistentHash(options, cb) {
                     return _cb(err);
                 });
             },
-            function getAlgorithm(_, _cb){
-                self.db_.get(LKEY_ALGORITHM, function(err, algorithm) {
+            function getAlgorithm(_, _cb) {
+                self.db_.get(LKEY_ALGORITHM, function (err, algorithm) {
                     if (err) {
                         err = new verror.VError(err);
                     }
@@ -604,11 +603,11 @@ function ConsistentHash(options, cb) {
                     return _cb(err);
                 });
             }
-        ], arg: {}}, function(err) {
+        ], arg: {}}, function (err) {
             if (err) {
                 err = new verror.VError(err, 'unable to load ring from db');
             }
-            dtrace._fash_probes['new-done'].fire(function() {
+            dtrace._fash_probes['new-done'].fire(function () {
                 return ([err ? err.message : null, 'loadFromDb']);
             });
             log.info({
@@ -639,32 +638,33 @@ module.exports = ConsistentHash;
  * @param {function} cb The callback f(err, {pnode, vnode, data}).
  */
 ConsistentHash.prototype.getNode = function getNode(key, callback) {
-    dtrace._fash_probes['getnode-start'].fire(function() {
+    dtrace._fash_probes['getnode-start'].fire(function () {
         return ([key]);
     });
     var self = this;
-    var value = crypto.createHash(this.algorithm_.NAME).update(key).digest('hex');
+    var value = crypto.createHash(this.algorithm_.NAME).update(key).
+        digest('hex');
     // find the node that corresponds to this hash
     var vnode = common.findVnode({
         hash: value, vnodeHashInterval: self.algorithm_.VNODE_HASH_INTERVAL
     });
-    self.db_.get(sprintf(LKEY_VNODE_V, vnode), function(err, pnode) {
+    self.db_.get(sprintf(LKEY_VNODE_V, vnode), function (err, pnode) {
         if (err) {
             err = new verror.VError(err);
-            dtrace._fash_probes['getnode-done'].fire(function() {
-                return([err.message, key, value, null, vnode]);
+            dtrace._fash_probes['getnode-done'].fire(function () {
+                return ([err.message, key, value, null, vnode]);
             });
             return callback(err);
         }
         self.db_.get(sprintf(LKEY_PNODE_P_V, pnode, vnode),
-                     function(_err, data)
+                     function (_err, data)
         {
             if (_err) {
                 _err = new verror.VError(_err);
             }
 
-            dtrace._fash_probes['getnode-done'].fire(function() {
-                return([_err ? _err.message : null,
+            dtrace._fash_probes['getnode-done'].fire(function () {
+                return ([_err ? _err.message : null,
                        key, value, pnode, vnode, data]);
             });
             return callback(_err, {pnode: pnode, vnode: vnode, data: data});
@@ -685,8 +685,8 @@ ConsistentHash.prototype.getNode = function getNode(key, callback) {
  * @param {function} cb The callback f(err).
  */
 ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
-    dtrace._fash_probes['adddata-start'].fire(function() {
-        return([vnode, data]);
+    dtrace._fash_probes['adddata-start'].fire(function () {
+        return ([vnode, data]);
     });
     var self = this;
     var log = self.log;
@@ -706,7 +706,7 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
 
     vasync.pipeline({funcs: [
         function getPnode(_, _cb) {
-            db.get(sprintf(LKEY_VNODE_V, vnode), function(err, pnode) {
+            db.get(sprintf(LKEY_VNODE_V, vnode), function (err, pnode) {
                 if (err) {
                     return _cb(new verror.VError(err, 'unable to add data'));
                 }
@@ -720,7 +720,7 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
             });
         },
         function getVnodeDataArray(_, _cb) {
-            db.get(LKEY_VNODE_DATA, function(err, vnodeData) {
+            db.get(LKEY_VNODE_DATA, function (err, vnodeData) {
                 if (err) {
                     return _cb(new verror.VError(err, 'unable to add data'));
                 }
@@ -756,7 +756,7 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
             return _cb();
         },
         function commit(_, _cb) {
-            _.batch.write(function(err) {
+            _.batch.write(function (err) {
                 if (err) {
                     err = new verror.VError(err, 'addData: unable to commit');
                 }
@@ -765,9 +765,9 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
             });
             console.log('{"%s":"%s"}', vnode, data);
         }
-    ], arg:{}}, function(err) {
-        dtrace._fash_probes['adddata-done'].fire(function() {
-            return([err ? err.message : null, vnode, data]);
+    ], arg: {}}, function (err) {
+        dtrace._fash_probes['adddata-done'].fire(function () {
+            return ([err ? err.message : null, vnode, data]);
         });
         return cb(err);
     });
@@ -779,7 +779,8 @@ ConsistentHash.prototype.addData = function addData(vnode, data, cb) {
  * @param {Number} vnode The vnode whose pnode and data we want to see.
  * @param {function} cb The callback f(err, String, String)
  */
-ConsistentHash.prototype.getVnodePnodeAndData = function getVnodePnodeAndData(vnode, cb) {
+ConsistentHash.prototype.getVnodePnodeAndData =
+    function getVnodePnodeAndData(vnode, cb) {
     var self = this;
 
     var log = self.log;
@@ -787,36 +788,39 @@ ConsistentHash.prototype.getVnodePnodeAndData = function getVnodePnodeAndData(vn
 
     log.info({
         vnode: vnode
-    },'ConsistentHash.getDataVnode: entering');
+    }, 'ConsistentHash.getDataVnode: entering');
 
     assert.number(vnode, 'vnode');
     assert.func(cb, 'callback');
 
     vasync.pipeline({funcs: [
         function getVnodePnode(_, _cb) {
-            db.get(sprintf(LKEY_VNODE_V, vnode), function(err, vnodePnode) {
-                if (err) {
-                    return _cb(new verror.VError('cannot get pnode for vnode ' +
-                        vnode + ', vnode ' + vnode + ' or pnode ' +
-                        vnodePnode + ' may not exist.'));
-                }
-                _.pnode = vnodePnode;
-                return _cb();
-            });
+            db.get(sprintf(LKEY_VNODE_V, vnode),
+                function (err, vnodePnode) {
+                    if (err) {
+                        return _cb(new verror.VError(
+                            'cannot get pnode for vnode ' + vnode +
+                            ', vnode ' + vnode + ' or pnode ' +
+                            vnodePnode + ' may not exist.'));
+                    }
+                    _.pnode = vnodePnode;
+                    return _cb();
+                });
         },
         function getVnodeData(_, _cb) {
-            db.get(sprintf(LKEY_PNODE_P_V, _.pnode, vnode), function(err, data)
-            {
-                if (err) {
-                    return _cb(new verror.VError('cannot get data for vnode ' + vnode +
-                        ' and pnode ' + _.pnode));
-                } else {
-                    _.vnodeData = data;
-                    return _cb(null, _);
-                }
-            });
+            db.get(sprintf(LKEY_PNODE_P_V, _.pnode, vnode),
+                function (err, data) {
+                    if (err) {
+                        return _cb(new verror.VError(
+                            'cannot get data for vnode ' + vnode +
+                            ' and pnode ' + _.pnode));
+                    } else {
+                        _.vnodeData = data;
+                        return _cb(null, _);
+                    }
+                });
         }
-    ], arg: {}}, function(err, results) {
+    ], arg: {}}, function (err, results) {
         log.info({err: err}, 'ConsistentHash.getDataVnode: exiting');
         if (err) {
             console.error(new verror.VError(err));
@@ -824,7 +828,8 @@ ConsistentHash.prototype.getVnodePnodeAndData = function getVnodePnodeAndData(vn
         }
 
         if (results.successes[1]) {
-            return cb(null, results.successes[1].pnode, results.successes[1].vnodeData);
+            return cb(null, results.successes[1].pnode,
+                results.successes[1].vnodeData);
         }
 
         return cb();
@@ -845,7 +850,7 @@ ConsistentHash.prototype.getDataVnodes = function getDataVnodes(cb) {
     log.info('ConsistentHash.getDataVnodes: entering');
     assert.func(cb, 'callback');
 
-    db.get(LKEY_VNODE_DATA, function(err, vnodeArray) {
+    db.get(LKEY_VNODE_DATA, function (err, vnodeArray) {
         if (err) {
             err = new verror.VError(err);
         }
@@ -855,8 +860,8 @@ ConsistentHash.prototype.getDataVnodes = function getDataVnodes(cb) {
 };
 
 /*
- * Remaps a vnode on the hash ring. The node can be on an existing pnode, or a new
- * one.
+ * Remaps a vnode on the hash ring. The node can be on an existing pnode,
+ * or a new one.
  *
  * @param {String} node The name of the node.
  * @param {Number} The vnode to add to this pnode. Implicitly removes the
@@ -864,7 +869,7 @@ ConsistentHash.prototype.getDataVnodes = function getDataVnodes(cb) {
  * @param {function} cb The callback f(err).
  */
 ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
-    dtrace._fash_probes['remapvnode-start'].fire(function() {
+    dtrace._fash_probes['remapvnode-start'].fire(function () {
         return ([newPnode, vnode]);
     });
     var self = this;
@@ -904,7 +909,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             return _cb();
         },
         function checkAndCreateNewPnode(_, _cb) {
-            db.get(sprintf(LKEY_PNODE_P, newPnode), function(err) {
+            db.get(sprintf(LKEY_PNODE_P, newPnode), function (err) {
                 if (err && err.name && err.name === 'NotFoundError') {
                     _.batch = _.batch.put(sprintf(LKEY_PNODE_P, newPnode), []);
                     _.isNew = true;
@@ -920,7 +925,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
         },
         function getOldVnodeMapping(_, _cb) {
             // get the previous vnode to pnode mapping
-            db.get(sprintf(LKEY_VNODE_V, vnode), function(err, pnode) {
+            db.get(sprintf(LKEY_VNODE_V, vnode), function (err, pnode) {
                 if (err) {
                     return _cb(new verror.VError(err));
                 }
@@ -936,7 +941,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             });
         },
         function getVnodeData(_, _cb) {
-            db.get(sprintf(LKEY_PNODE_P_V, _.oldPnode, vnode), function(err, d)
+            db.get(sprintf(LKEY_PNODE_P_V, _.oldPnode, vnode), function (err, d)
             {
                 if (err) {
                     return _cb(err);
@@ -948,11 +953,12 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
         },
         function delOldMapping(_, _cb) {
             _.batch = _.batch.del(sprintf(LKEY_PNODE_P_V, _.oldPnode, vnode));
-            db.get(sprintf(LKEY_PNODE_P, _.oldPnode), function(err, oldVnodes) {
+            db.get(sprintf(LKEY_PNODE_P, _.oldPnode),
+                function (err, oldVnodes) {
                 if (err) {
                     return _cb(new verror.VError(err,
-                                                'couldn\'t get path /pnode/' +
-                                                 _.oldPnode));
+                                                'couldn\'t get path' +
+                                                '/pnode/' + _.oldPnode));
                 }
                 var idx = oldVnodes.indexOf(vnode);
                 if (idx === -1) {
@@ -969,7 +975,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             });
         },
         function addNewMapping(_, _cb) {
-            db.get(sprintf(LKEY_PNODE_P, newPnode), function(err, vnodes) {
+            db.get(sprintf(LKEY_PNODE_P, newPnode), function (err, vnodes) {
                 /*
                  * ignore NotFoundErrors if the pnode is new, since it hasn't
                  * been created yet
@@ -991,7 +997,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             });
         },
         function addPnodeToPnodeArray(_, _cb) {
-            db.get(LKEY_PNODE, function(err, pnodes) {
+            db.get(LKEY_PNODE, function (err, pnodes) {
                 if (err) {
                     return _cb(new verror.VError(err));
                 }
@@ -1005,7 +1011,7 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             });
         },
         function commit(_, _cb) {
-            _.batch.write(function(err) {
+            _.batch.write(function (err) {
                 if (err) {
                     return _cb(new verror.VError(err));
                 } else {
@@ -1014,9 +1020,9 @@ ConsistentHash.prototype.remapVnode = function remapVnode(newPnode, vnode, cb) {
             });
             console.log('{"%s":"%s"}', newPnode, vnode);
         }
-    ], arg: {}}, function(err) {
+    ], arg: {}}, function (err) {
         log.info({err: err}, 'ConsistentHash.remapVnode: exiting');
-        dtrace._fash_probes['remapvnode-done'].fire(function() {
+        dtrace._fash_probes['remapvnode-done'].fire(function () {
             return ([err ? err.message : null, newPnode, oldPnode, vnode]);
         });
         return cb(err);
@@ -1039,7 +1045,7 @@ ConsistentHash.prototype.getVnodes = function getVnodes(pnode, cb) {
     assert.func(cb, 'callback');
 
     // check that the pnode exists
-    db.get(sprintf(LKEY_PNODE_P, pnode), function(err, vnodes) {
+    db.get(sprintf(LKEY_PNODE_P, pnode), function (err, vnodes) {
         if (err) {
             return cb(new verror.VError(err, 'pnode is not in ring'));
         }
@@ -1064,7 +1070,7 @@ ConsistentHash.prototype.getPnodes = function getPnodes(cb) {
     log.info('ConsistentHash.getPnodes: entering');
 
     assert.func(cb, 'callback');
-    db.get(LKEY_PNODE, function(err, pnodes) {
+    db.get(LKEY_PNODE, function (err, pnodes) {
         if (err) {
             err = new verror.VError(err, 'unable to get Pnodes');
         }
@@ -1082,7 +1088,7 @@ ConsistentHash.prototype.getPnodes = function getPnodes(cb) {
  * @param {function} cb The callback f(err).
  */
 ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
-    dtrace._fash_probes['removepnode-start'].fire(function() {
+    dtrace._fash_probes['removepnode-start'].fire(function () {
         return ([pnode]);
     });
     var self = this;
@@ -1097,8 +1103,8 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
     assert.func(cb, 'callback');
     // check that the pnode exists
     vasync.pipeline({funcs: [
-        function checkPnodeExists(_, _cb){
-            db.get(sprintf(LKEY_PNODE_P, pnode), function(err, v) {
+        function checkPnodeExists(_, _cb) {
+            db.get(sprintf(LKEY_PNODE_P, pnode), function (err, v) {
                 if (err) {
                     return _cb(new verror.VError(err, 'pnode does not exist'));
                 }
@@ -1118,7 +1124,7 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
             // remove /pnode/%s
             var batch = db.batch().del(sprintf(LKEY_PNODE_P, pnode));
             // get the pnode array
-            db.get(LKEY_PNODE, function(err, pnodes) {
+            db.get(LKEY_PNODE, function (err, pnodes) {
                 if (err) {
                     return _cb(new verror.VError(err));
                 }
@@ -1129,7 +1135,7 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
                     return _cb(new verror.VError('pnode does not exist'));
                 }
                 pnodes.splice(pnodeIndex, 1);
-                batch.put(LKEY_PNODE, pnodes).write(function(_err) {
+                batch.put(LKEY_PNODE, pnodes).write(function (_err) {
                     if (_err) {
                         _err = new verror.VError(_err);
                     }
@@ -1142,8 +1148,8 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
                 return (undefined);
             });
         }
-    ], arg: {}}, function(err) {
-        dtrace._fash_probes['removepnode-done'].fire(function() {
+    ], arg: {}}, function (err) {
+        dtrace._fash_probes['removepnode-done'].fire(function () {
             return ([err ? err.message : null, pnode]);
         });
         return cb(err);
@@ -1161,7 +1167,7 @@ ConsistentHash.prototype.removePnode = function removePnode(pnode, cb) {
  * @return {String} ring.version The version of the ring.
  */
 ConsistentHash.prototype.serialize = function serialize(callback) {
-    dtrace._fash_probes['serialize-start'].fire(function() {
+    dtrace._fash_probes['serialize-start'].fire(function () {
         return ([]);
     });
     var self = this;
@@ -1179,7 +1185,7 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
 
     var tasks = [
         function getNumberOfVnodes(_, cb) {
-            db.get(LKEY_VNODE_COUNT, function(err, vnodes) {
+            db.get(LKEY_VNODE_COUNT, function (err, vnodes) {
                 serializedHash.vnodes = vnodes;
                 return cb(err);
             });
@@ -1189,14 +1195,14 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
             var count = serializedHash.vnodes;
             for (var vnode = 0; vnode < serializedHash.vnodes; vnode++) {
                 db.get(sprintf(LKEY_VNODE_V, vnode),
-                       (function(v, err, pnode)
+                       (function (v, err, pnode)
                 {
                     if (err) {
                         return cb(new verror.VError(err));
                     }
                     serializedHash.pnodeToVnodeMap[pnode] = {};
                     db.get(sprintf(LKEY_PNODE_P_V, pnode, v),
-                           function(_err, data)
+                           function (_err, data)
                     {
                         if (_err) {
                             return cb(new verror.VError(_err));
@@ -1211,8 +1217,8 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
                 }).bind(this, vnode));
             }
         },
-        function getAlgorithm(_, cb){
-            db.get(LKEY_ALGORITHM, function(err, algorithm) {
+        function getAlgorithm(_, cb) {
+            db.get(LKEY_ALGORITHM, function (err, algorithm) {
                 if (err) {
                     err = new verror.VError(err);
                 }
@@ -1220,8 +1226,8 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
                 return cb(err);
             });
         },
-        function getVersion(_, cb){
-            db.get(LKEY_VERSION, function(err, version) {
+        function getVersion(_, cb) {
+            db.get(LKEY_VERSION, function (err, version) {
                 if (err) {
                     err = new verror.VError(err);
                 }
@@ -1231,7 +1237,7 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
         }
     ];
 
-    vasync.pipeline({funcs: tasks, arg: {}}, function(err) {
+    vasync.pipeline({funcs: tasks, arg: {}}, function (err) {
         if (err) {
             err = new verror.VError(err, 'unable to serialize ring');
         }
@@ -1243,7 +1249,7 @@ ConsistentHash.prototype.serialize = function serialize(callback) {
         }
         log.info({err: err}, 'ConsistentHash.serialize: exiting');
 
-        dtrace._fash_probes['serialize-done'].fire(function() {
+        dtrace._fash_probes['serialize-done'].fire(function () {
             return ([err ? err.message : null]);
         });
         return callback(err, stringifiedHash);
@@ -1259,5 +1265,4 @@ module.exports.LKEY_PNODE_P = LKEY_PNODE_P;
 module.exports.LKEY_PNODE_P_V = LKEY_PNODE_P_V;
 module.exports.LKEY_VERSION = LKEY_VERSION;
 module.exports.LKEY_VNODE_COUNT = LKEY_VNODE_COUNT;
-module.exports.LKEY_VNODE_V = LKEY_VNODE_V;
-
+module.exports.LKEY_VNODE_V = LKEY_VNODE_V;
\ No newline at end of file
diff --git a/lib/common.js b/lib/common.js
index 055c1bb..1ebcd3b 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -64,7 +64,8 @@ function _findVnode(options) {
     assert.object(options, 'options');
     assert.object(options.vnodeHashInterval, 'options.vnodeHashinterval');
     assert.string(options.hash, 'options.hash');
-    return parseInt(bignum(options.hash, 16).div(options.vnodeHashInterval), 10);
+    return parseInt(bignum(options.hash, 16).
+        div(options.vnodeHashInterval), 10);
 }
 
 /*
diff --git a/lib/dtrace.js b/lib/dtrace.js
index e2b79ae..d443659 100644
--- a/lib/dtrace.js
+++ b/lib/dtrace.js
@@ -39,37 +39,37 @@ var PROVIDER;
 ///--- API
 
 module.exports = function exportStaticProvider() {
-  if (!PROVIDER) {
-    try {
-      var dtrace = require('dtrace-provider');
-      PROVIDER = dtrace.createDTraceProvider('node-fash');
-    } catch (e) {
-      PROVIDER = {
-        fire: function () {},
-        enable: function () {},
-        addProbe: function () {
-          var p = {
-            fire: function () {}
-          };
-          return (p);
-        },
-        removeProbe: function () {},
-        disable: function () {}
-      };
-    }
+    if (!PROVIDER) {
+        try {
+            var dtrace = require('dtrace-provider');
+            PROVIDER = dtrace.createDTraceProvider('node-fash');
+        } catch (e) {
+            PROVIDER = {
+                fire: function () {},
+                enable: function () {},
+                addProbe: function () {
+                    var p = {
+                        fire: function () {}
+                    };
+                    return (p);
+                },
+                removeProbe: function () {},
+                disable: function () {}
+            };
+        }
 
-    PROVIDER._fash_probes = {};
+        PROVIDER._fash_probes = {};
 
-    Object.keys(PROBES).forEach(function (p) {
-      var args = PROBES[p].splice(0);
-      args.unshift(p);
+        Object.keys(PROBES).forEach(function (p) {
+            var args = PROBES[p].splice(0);
+            args.unshift(p);
 
-      var probe = PROVIDER.addProbe.apply(PROVIDER, args);
-      PROVIDER._fash_probes[p] = probe;
-    });
+            var probe = PROVIDER.addProbe.apply(PROVIDER, args);
+            PROVIDER._fash_probes[p] = probe;
+        });
 
-    PROVIDER.enable();
-  }
+        PROVIDER.enable();
+    }
 
-  return (PROVIDER);
+    return (PROVIDER);
 }();
diff --git a/lint.sh b/lint.sh
deleted file mode 100755
index 27d550c..0000000
--- a/lint.sh
+++ /dev/null
@@ -1,12 +0,0 @@
-#!/bin/bash
-
-git submodule update --init
-
-cd ./deps/javascriptlint
-make install
-cd ../..
-
-./deps/javascriptlint/build/install/jsl --conf ./tools/jsl.node.conf \
-    ./lib/*.js ./lib/backend/*.js ./bin/*.js
-
-./deps/jsstyle/jsstyle -f ./tools/jsstyle.conf ./*.js ./bin/*.js ./test/*.js
diff --git a/package.json b/package.json
index 50a712b..4f08587 100644
--- a/package.json
+++ b/package.json
@@ -21,7 +21,7 @@
     "dynamo",
     "hash ring"
   ],
-  "version": "2.4.0",
+  "version": "2.4.1",
   "repository": {
     "type": "git",
     "url": "https://github.com/yunong/node-fash.git"
@@ -59,12 +59,5 @@
   },
   "bin": {
     "fash": "bin/fash.js"
-  },
-  "config": {
-    "leveldb_test_algorithm": "sha256"
-  },
-  "scripts": {
-    "pretest": "./lint.sh",
-    "test": "./node_modules/.bin/nodeunit test/*.test.js"
   }
 }
diff --git a/test/leveldb.test.js b/test/leveldb.test.js
index 7cbc809..fded58d 100644
--- a/test/leveldb.test.js
+++ b/test/leveldb.test.js
@@ -35,7 +35,7 @@ var NUMBER_OF_VNODES = parseInt(process.env.NUMBER_OF_VNODES || 100);
 var NUMBER_OF_PNODES = parseInt(process.env.NUMBER_OF_PNODES || 10);
 var PNODES = new Array(NUMBER_OF_PNODES);
 var PNODE_STRING = '\'';
-var ALGORITHM = [process.env.npm_package_config_leveldb_test_algorithm] ||
+var ALGORITHM = [process.env.LEVELDB_TEST_ALGORITHM] ||
     ['sha256', 'sha1', 'md5'];
 
 exports.beforeTest = function (t) {
diff --git a/tools/mk/Makefile.defs b/tools/mk/Makefile.defs
new file mode 100644
index 0000000..cc16d86
--- /dev/null
+++ b/tools/mk/Makefile.defs
@@ -0,0 +1,97 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.defs: common defines.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This makefile defines some useful defines. Include it at the top of
+# your Makefile.
+#
+# Definitions in this Makefile:
+#
+#	TOP 		The absolute path to the project directory. The top dir.
+#	BRANCH 		The current git branch.
+#	TIMESTAMP	The timestamp for the build. This can be set via
+#			the TIMESTAMP envvar (used by MG-based builds).
+#	STAMP		A build stamp to use in built package names.
+#
+#	MAKE_STAMPS_DIR	The directory in which make stamp files are to be
+#			created.  See comments below on expensive targets.
+#
+
+TOP := $(shell pwd)
+
+#
+# Mountain Gorilla-spec'd versioning.
+# See "Package Versioning" in MG's README.md:
+# <https://mo.joyent.com/mountain-gorilla/blob/master/README.md#L139-200>
+#
+# Need GNU awk for multi-char arg to "-F".
+_AWK := $(shell (which gawk >/dev/null && echo gawk) \
+	|| (which nawk >/dev/null && echo nawk) \
+	|| echo awk)
+BRANCH := $(shell git symbolic-ref HEAD | $(_AWK) -F/ '{print $$3}')
+ifeq ($(TIMESTAMP),)
+	TIMESTAMP := $(shell date -u "+%Y%m%dT%H%M%SZ")
+endif
+_GITDESCRIBE := g$(shell git describe --all --long --dirty | $(_AWK) -F'-g' '{print $$NF}')
+STAMP := $(BRANCH)-$(TIMESTAMP)-$(_GITDESCRIBE)
+
+# node-gyp will print build info useful for debugging with V=1
+export V=1
+
+#
+# EXPENSIVE TARGETS AND MAKE STAMP FILES
+#
+# Targets which are expensive to run and lack a single file that marks
+# completion are difficult to track with make; e.g., "npm install".  One
+# solution to this problem is to create "stamp" files with symbolic names which
+# are created as the final step in a complex make rule in order to mark
+# completion.
+#
+# In order to make these more uniform, and easier to target with "make clean",
+# we will attempt to store them under a single directory.  Note that these
+# files are never targets for shipping in build artefacts.
+#
+# Stamp-backed targets come in several parts.  First, a macro should be defined
+# which names a file in the MAKE_STAMPS_DIR directory.  Then, a target which
+# creates this stamp file must be provided.  The recipe for this target should
+# use MAKE_STAMP_REMOVE and MAKE_STAMP_CREATE to perform the appropriate stamp
+# management.
+#
+# For example:
+#
+# --- Makefile.*.defs:
+#
+#	$(STAMP_EXPENSIVE_RESULT) := $(MAKE_STAMPS_DIR)/expensive-result
+#
+# --- Makefile.*.targ:
+#
+#	$(STAMP_EXPENSIVE_RESULT): input/file another/input/file
+#		$(MAKE_STAMP_REMOVE)
+#		rm -rf output_tree/  # <--- ensure a clean slate
+#		expensive_program -o output_tree/ $^
+#		$(MAKE_STAMP_CREATE)
+#
+# NOTE: Every stamp file is exposed as an implicit "stamp-$STAMP_NAME" target.
+# The example above could be built manually by invoking:
+#
+#	make stamp-expensive-result
+#
+MAKE_STAMPS_DIR ?=	make_stamps
+CLEAN_FILES +=		$(MAKE_STAMPS_DIR)
+
+MAKE_STAMP_REMOVE =	mkdir -p $(@D); rm -f $(@)
+MAKE_STAMP_CREATE =	mkdir -p $(@D); touch $(@)
\ No newline at end of file
diff --git a/tools/mk/Makefile.deps b/tools/mk/Makefile.deps
new file mode 100644
index 0000000..664f16b
--- /dev/null
+++ b/tools/mk/Makefile.deps
@@ -0,0 +1,54 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.deps: Makefile for including common tools as dependencies
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This file is separate from Makefile.targ so that teams can choose
+# independently whether to use the common targets in Makefile.targ and the
+# common tools here.
+#
+
+#
+# javascriptlint
+#
+JSL_EXEC	?= deps/javascriptlint/build/install/jsl
+JSL		?= $(JSL_EXEC)
+
+$(JSL_EXEC): | deps/javascriptlint/.git
+	cd deps/javascriptlint && make install
+
+distclean::
+	if [[ -f deps/javascriptlint/Makefile ]]; then \
+		cd deps/javascriptlint && make clean; \
+	fi
+
+#
+# jsstyle
+#
+JSSTYLE_EXEC	?= deps/jsstyle/jsstyle
+JSSTYLE		?= $(JSSTYLE_EXEC)
+
+$(JSSTYLE_EXEC): | deps/jsstyle/.git
+
+#
+# restdown
+#
+RESTDOWN_EXEC	?= deps/restdown/bin/restdown
+RESTDOWN	?= python $(RESTDOWN_EXEC)
+$(RESTDOWN_EXEC): | deps/restdown/.git
+
+EXTRA_DOC_DEPS	?=
\ No newline at end of file
diff --git a/tools/mk/Makefile.node_modules.defs b/tools/mk/Makefile.node_modules.defs
new file mode 100644
index 0000000..048adc2
--- /dev/null
+++ b/tools/mk/Makefile.node_modules.defs
@@ -0,0 +1,68 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node_modules.defs: Makefile for using NPM modules.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile provides a target for building NPM modules from the dependency
+# information in the "package.json" file.  The "npm install" operation is
+# expensive and produces a complex (multi-file) result which is difficult for
+# make to use in dependency analysis.  As such, we use a "stamp" file to track
+# successful completion of module installation.
+#
+# This variable allows the consumer to influence the environment used to run
+# NPM commands.
+#
+#	NPM_ENV			This string should be set to a list of
+#				environment variables in the syntax used
+#				by bash; e.g.,
+#
+#					NPM_ENV =	TESTING=yes V=1
+#
+# Consumers should, for targets which depend on the installation of NPM
+# modules, depend on the stamp file using the $(STAMP_NODE_MODULES) variable,
+# e.g.:
+#
+#	.PHONY: all
+#	all: $(STAMP_NODE_MODULES)
+#
+# A phony target, "make stamp-node-modules", is also provided to allow the
+# engineer to manually perform NPM module installation without invoking other
+# targets.  Note that this target should _not_ be used as a dependency for
+# other targets in consuming Makefiles; using phony targets to represent
+# intermediate build stages can inhibit the ability of make to determine
+# when no additional actions are required.
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+NPM ?= $(error You must include either Makefile.node.defs or \
+    Makefile.node_prebuilt.defs before this makefile)
+
+BUILD ?=		build
+
+#
+# Invoking "npm install" at the top-level will create a "node_modules"
+# directory into which NPM modules will be installed.
+#
+CLEAN_FILES +=		node_modules
+
+#
+# To avoid repeatedly reinstalling from NPM, we create a "stamp" file to track
+# successful runs of "npm install".  Note that MAKE_STAMPS_DIR is included
+# in CLEAN_FILES already.
+#
+STAMP_NODE_MODULES ?=	$(MAKE_STAMPS_DIR)/node-modules
\ No newline at end of file
diff --git a/tools/mk/Makefile.node_modules.targ b/tools/mk/Makefile.node_modules.targ
new file mode 100644
index 0000000..9fd1c11
--- /dev/null
+++ b/tools/mk/Makefile.node_modules.targ
@@ -0,0 +1,31 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node_modules.targ: See comments in Makefile.node_modules.defs.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+STAMP_NODE_MODULES ?= $(error You must include Makefile.node_modules.defs \
+    before this file)
+
+#
+# If the "package.json" file changes, we need to rebuild the contents of
+# the "node_modules" directory.
+#
+$(STAMP_NODE_MODULES): package.json | $(NPM_EXEC)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf node_modules
+	$(NPM_ENV) $(NPM) install
+	$(MAKE_STAMP_CREATE)
\ No newline at end of file
diff --git a/tools/mk/Makefile.targ b/tools/mk/Makefile.targ
new file mode 100644
index 0000000..39656dd
--- /dev/null
+++ b/tools/mk/Makefile.targ
@@ -0,0 +1,334 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.targ: common targets.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This Makefile defines several useful targets and rules. You can use it by
+# including it from a Makefile that specifies some of the variables below.
+#
+# Targets defined in this Makefile:
+#
+#	check	Checks JavaScript files for lint and style
+#		Checks bash scripts for syntax
+#		Checks SMF manifests for validity against the SMF DTD
+#
+#	clean	Removes built files
+#
+#	docs	Builds restdown documentation in docs/
+#
+#	prepush	Depends on "check" and "test"
+#
+#	test	Does nothing (you should override this)
+#
+#	xref	Generates cscope (source cross-reference index)
+#
+# For details on what these targets are supposed to do, see the Joyent
+# Engineering Guide.
+#
+# To make use of these targets, you'll need to set some of these variables. Any
+# variables left unset will simply not be used.
+#
+#	BASH_FILES	Bash scripts to check for syntax
+#			(paths relative to top-level Makefile)
+#
+#	CLEAN_FILES	Files to remove as part of the "clean" target.  Note
+#			that files generated by targets in this Makefile are
+#			automatically included in CLEAN_FILES.  These include
+#			restdown-generated HTML and JSON files.
+#
+#	DOC_FILES	Restdown (documentation source) files. These are
+#			assumed to be contained in "docs/", and must NOT
+#			contain the "docs/" prefix.
+#
+#	JSL_CONF_NODE	Specify JavaScriptLint configuration files
+#	JSL_CONF_WEB	(paths relative to top-level Makefile)
+#
+#			Node.js and Web configuration files are separate
+#			because you'll usually want different global variable
+#			configurations.  If no file is specified, none is given
+#			to jsl, which causes it to use a default configuration,
+#			which probably isn't what you want.
+#
+#	JSL_FILES_NODE	JavaScript files to check with Node config file.
+#	JSL_FILES_WEB	JavaScript files to check with Web config file.
+#
+#	JSON_FILES	JSON files to be validated
+#
+#	JSSTYLE_FILES	JavaScript files to be style-checked
+#
+# You can also override these variables:
+#
+#	BASH		Path to bash (default: "bash")
+#
+#	CSCOPE_DIRS	Directories to search for source files for the cscope
+#			index. (default: ".")
+#
+#	JSL		Path to JavaScriptLint (default: "jsl")
+#
+#	JSL_FLAGS_NODE	Additional flags to pass through to JSL
+#	JSL_FLAGS_WEB
+#	JSL_FLAGS
+#
+#	JSON		Path to json tool (default: "json")
+#
+#	JSSTYLE		Path to jsstyle (default: "jsstyle")
+#
+#	JSSTYLE_FLAGS	Additional flags to pass through to jsstyle
+#
+#	RESTDOWN_EXT	By default '.md' is required for DOC_FILES (see above).
+#			If you want to use, say, '.restdown' instead, then set
+#			'RESTDOWN_EXT=.restdown' in your Makefile.
+#
+
+#
+# Defaults for the various tools we use.
+#
+BASH		?= bash
+BASHSTYLE	?= tools/bashstyle
+CP		?= cp
+CSCOPE		?= cscope
+CSCOPE_DIRS	?= .
+JSL		?= jsl
+JSON		?= json
+JSSTYLE		?= jsstyle
+MKDIR		?= mkdir -p
+MV		?= mv
+RESTDOWN_FLAGS	?=
+RESTDOWN_EXT	?= .md
+RMTREE		?= rm -rf
+JSL_FLAGS  	?= --nologo --nosummary
+
+ifeq ($(shell uname -s),SunOS)
+	TAR	?= gtar
+else
+	TAR	?= tar
+endif
+
+
+#
+# Defaults for other fixed values.
+#
+BUILD		= build
+DISTCLEAN_FILES += $(BUILD)
+DOC_BUILD	= $(BUILD)/docs/public
+
+#
+# Configure JSL_FLAGS_{NODE,WEB} based on JSL_CONF_{NODE,WEB}.
+#
+ifneq ($(origin JSL_CONF_NODE), undefined)
+	JSL_FLAGS_NODE += --conf=$(JSL_CONF_NODE)
+endif
+
+ifneq ($(origin JSL_CONF_WEB), undefined)
+	JSL_FLAGS_WEB += --conf=$(JSL_CONF_WEB)
+endif
+
+#
+# Targets. For descriptions on what these are supposed to do, see the
+# Joyent Engineering Guide.
+#
+
+#
+# Instruct make to keep around temporary files. We have rules below that
+# automatically update git submodules as needed, but they employ a deps/*/.git
+# temporary file. Without this directive, make tries to remove these .git
+# directories after the build has completed.
+#
+.SECONDARY: $($(wildcard deps/*):%=%/.git)
+
+#
+# This rule enables other rules that use files from a git submodule to have
+# those files depend on deps/module/.git and have "make" automatically check
+# out the submodule as needed.
+#
+deps/%/.git:
+	git submodule update --init deps/$*
+
+#
+# These recipes make heavy use of dynamically-created phony targets. The parent
+# Makefile defines a list of input files like BASH_FILES. We then say that each
+# of these files depends on a fake target called filename.bashchk, and then we
+# define a pattern rule for those targets that runs bash in check-syntax-only
+# mode. This mechanism has the nice properties that if you specify zero files,
+# the rule becomes a noop (unlike a single rule to check all bash files, which
+# would invoke bash with zero files), and you can check individual files from
+# the command line with "make filename.bashchk".
+#
+.PHONY: check-bash
+check-bash: $(BASH_FILES:%=%.bashchk) $(BASH_FILES:%=%.bashstyle)
+
+%.bashchk: %
+	$(BASH) -n $^
+
+%.bashstyle: %
+	$(BASHSTYLE) $^
+
+.PHONY: check-json
+check-json: $(JSON_FILES:%=%.jsonchk)
+
+%.jsonchk: %
+	$(JSON) --validate -f $^
+
+#
+# The above approach can be slow when there are many files to check because it
+# requires that "make" invoke the check tool once for each file, rather than
+# passing in several files at once.  For the JavaScript check targets, we define
+# a variable for the target itself *only if* the list of input files is
+# non-empty.  This avoids invoking the tool if there are no files to check.
+#
+JSL_NODE_TARGET = $(if $(JSL_FILES_NODE), check-jsl-node)
+.PHONY: check-jsl-node
+check-jsl-node: $(JSL_EXEC)
+	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_NODE) $(JSL_FILES_NODE)
+
+JSL_WEB_TARGET = $(if $(JSL_FILES_WEB), check-jsl-web)
+.PHONY: check-jsl-web
+check-jsl-web: $(JSL_EXEC)
+	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_WEB) $(JSL_FILES_WEB)
+
+.PHONY: check-jsl
+check-jsl: $(JSL_NODE_TARGET) $(JSL_WEB_TARGET)
+
+JSSTYLE_TARGET = $(if $(JSSTYLE_FILES), check-jsstyle)
+.PHONY: check-jsstyle
+check-jsstyle:  $(JSSTYLE_EXEC)
+	$(JSSTYLE) $(JSSTYLE_FLAGS) $(JSSTYLE_FILES)
+
+.PHONY: check
+check:: check-jsl check-json $(JSSTYLE_TARGET) check-bash
+	@echo check ok
+
+.PHONY: clean
+clean::
+	-$(RMTREE) $(CLEAN_FILES)
+
+.PHONY: distclean
+distclean:: clean
+	-$(RMTREE) $(DISTCLEAN_FILES)
+
+CSCOPE_FILES = cscope.in.out cscope.out cscope.po.out
+CLEAN_FILES += $(CSCOPE_FILES)
+
+.PHONY: xref
+xref: cscope.files
+	$(CSCOPE) -bqR
+
+.PHONY: cscope.files
+cscope.files:
+	find $(CSCOPE_DIRS) -name '*.c' -o -name '*.h' -o -name '*.cc' \
+	    -o -name '*.js' -o -name '*.s' -o -name '*.cpp' > $@
+
+#
+# The "docs" target is complicated because we do several things here:
+#
+#    (1) Use restdown to build HTML and JSON files from each of DOC_FILES.
+#
+#    (2) Copy these files into $(DOC_BUILD) (build/docs/public), which
+#        functions as a complete copy of the documentation that could be
+#        mirrored or served over HTTP.
+#
+#    (3) Then copy any directories and media from docs/media into
+#        $(DOC_BUILD)/media. This allows projects to include their own media,
+#        including files that will override same-named files provided by
+#        restdown.
+#
+# Step (3) is the surprisingly complex part: in order to do this, we need to
+# identify the subdirectories in docs/media, recreate them in
+# $(DOC_BUILD)/media, then do the same with the files.
+#
+DOC_MEDIA_DIRS := $(shell find docs/media -type d 2>/dev/null | grep -v "^docs/media$$")
+DOC_MEDIA_DIRS := $(DOC_MEDIA_DIRS:docs/media/%=%)
+DOC_MEDIA_DIRS_BUILD := $(DOC_MEDIA_DIRS:%=$(DOC_BUILD)/media/%)
+
+DOC_MEDIA_FILES := $(shell find docs/media -type f 2>/dev/null)
+DOC_MEDIA_FILES := $(DOC_MEDIA_FILES:docs/media/%=%)
+DOC_MEDIA_FILES_BUILD := $(DOC_MEDIA_FILES:%=$(DOC_BUILD)/media/%)
+
+#
+# Like the other targets, "docs" just depends on the final files we want to
+# create in $(DOC_BUILD), leveraging other targets and recipes to define how
+# to get there.
+#
+.PHONY: docs
+docs::							\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.json)		\
+	$(DOC_MEDIA_FILES_BUILD)
+
+#
+# We keep the intermediate files so that the next build can see whether the
+# files in DOC_BUILD are up to date.
+#
+.PRECIOUS:					\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%json)
+
+#
+# We do clean those intermediate files, as well as all of DOC_BUILD.
+#
+CLEAN_FILES +=					\
+	$(DOC_BUILD)				\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.json)
+
+#
+# Before installing the files, we must make sure the directories exist. The |
+# syntax tells make that the dependency need only exist, not be up to date.
+# Otherwise, it might try to rebuild spuriously because the directory itself
+# appears out of date.
+#
+$(DOC_MEDIA_FILES_BUILD): | $(DOC_MEDIA_DIRS_BUILD)
+
+$(DOC_BUILD)/%: docs/% | $(DOC_BUILD)
+	$(MKDIR) $(shell dirname $@)
+	$(CP) $< $@
+
+docs/%.json docs/%.html: docs/%$(RESTDOWN_EXT) | $(DOC_BUILD) $(RESTDOWN_EXEC) \
+    $(EXTRA_DOC_DEPS)
+	$(RESTDOWN) $(RESTDOWN_FLAGS) -m $(DOC_BUILD) $<
+
+$(DOC_BUILD):
+	$(MKDIR) $@
+
+$(DOC_MEDIA_DIRS_BUILD):
+	$(MKDIR) $@
+
+#
+# The default "test" target does nothing. This should usually be overridden by
+# the parent Makefile. It's included here so we can define "prepush" without
+# requiring the repo to define "test".
+#
+.PHONY: test
+test:
+
+.PHONY: prepush
+prepush: check test
+
+#
+# This rule automatically exposes every "stamp" file as a target that can be
+# invoked manually as "stamp-$STAMP_NAME".  For example, if a stamp has been
+# defined thus:
+#
+#	STAMP_EXPENSIVE_RESULT := $(MAKE_STAMPS_DIR)/expensive-result
+#
+# ... this can be invoked manually as "make stamp-expensive-result".  Note that
+# these phony targets are essentially just for interactive usage.  Targets
+# should be specified to depend on the macro containing the stamp file name.
+#
+# See also the comments in "Makefile.defs".
+#
+stamp-%: $(MAKE_STAMPS_DIR)/%
+	@:
\ No newline at end of file
-- 
2.21.0

