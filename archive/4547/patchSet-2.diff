commit 28e3a60310dcecc0204e9648972ed3cd484644c0 (refs/changes/47/4547/2)
Author: Jason King <jason.king@joyent.com>
Date:   2018-07-20T15:34:02+00:00 (1 year, 3 months ago)
    
    Goodbye sarc, hello 2Q

diff --git a/usr/src/cmd/mdb/common/modules/genunix/Makefile.files b/usr/src/cmd/mdb/common/modules/genunix/Makefile.files
index 5d9cf9bb8f..3b5933f121 100644
--- a/usr/src/cmd/mdb/common/modules/genunix/Makefile.files
+++ b/usr/src/cmd/mdb/common/modules/genunix/Makefile.files
@@ -21,7 +21,7 @@
 #
 # Copyright 2011 Nexenta Systems, Inc.  All rights reserved.
 # Copyright (c) 1999, 2010, Oracle and/or its affiliates. All rights reserved.
-# Copyright 2016 Joyent, Inc.
+# Copyright 2018 Joyent, Inc.
 # Copyright (c) 2013 by Delphix. All rights reserved.
 #
 
@@ -71,6 +71,7 @@ GENUNIX_SRCS =		\
 	netstack.c	\
 	nvpair.c	\
 	pg.c		\
+	qqcache.c	\
 	rctl.c		\
 	sobj.c		\
 	streams.c	\
diff --git a/usr/src/cmd/mdb/common/modules/genunix/genunix.c b/usr/src/cmd/mdb/common/modules/genunix/genunix.c
index 9da3c5eba0..5a4cdc99c2 100644
--- a/usr/src/cmd/mdb/common/modules/genunix/genunix.c
+++ b/usr/src/cmd/mdb/common/modules/genunix/genunix.c
@@ -21,7 +21,7 @@
 /*
  * Copyright 2011 Nexenta Systems, Inc.  All rights reserved.
  * Copyright (c) 1999, 2010, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  * Copyright (c) 2013 by Delphix. All rights reserved.
  */
 
@@ -96,6 +96,7 @@
 #include "netstack.h"
 #include "nvpair.h"
 #include "pg.h"
+#include "qqcache.h"
 #include "rctl.h"
 #include "sobj.h"
 #include "streams.h"
@@ -4681,6 +4682,12 @@ static const mdb_walker_t walkers[] = {
 	{ NVPAIR_WALKER_NAME, NVPAIR_WALKER_DESCR,
 		nvpair_walk_init, nvpair_walk_step, NULL },
 
+	/* from qqcache.c */
+	{ QQCACHE_WALK_NAME, QQCACHE_WALK_DESC,
+		qqcache_walk_init_cache, qqcache_walk_step, qqcache_walk_fini },
+	{ QQCACHE_HASH_WALK_NAME, QQCACHE_HASH_WALK_DESC,
+		qqcache_walk_init_hash, qqcache_walk_step, qqcache_walk_fini },
+
 	/* from rctl.c */
 	{ "rctl_dict_list", "walk all rctl_dict_entry_t's from rctl_lists",
 		rctl_dict_walk_init, rctl_dict_walk_step, NULL },
diff --git a/usr/src/cmd/mdb/common/modules/genunix/qqcache.c b/usr/src/cmd/mdb/common/modules/genunix/qqcache.c
new file mode 100644
index 0000000000..a2ba1463b9
--- /dev/null
+++ b/usr/src/cmd/mdb/common/modules/genunix/qqcache.c
@@ -0,0 +1,117 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright 2018, Joyent, Inc.
+ */
+
+#include <mdb/mdb_modapi.h>
+#include <mdb/mdb_ctf.h>
+
+#include <sys/qqcache.h>
+#include <sys/qqcache_impl.h>
+
+#include "qqcache.h"
+
+typedef struct qqcache_walk_data {
+	size_t	qwd_link_off;
+} qqcache_walk_data_t;
+
+typedef struct mdb_qqcache {
+	size_t qqc_link_off;
+	size_t qqc_nbuckets;
+} mdb_qqcache_t;
+
+static int
+qqcache_walk_init(mdb_walk_state_t *wsp, boolean_t use_hash)
+{
+	qqcache_walk_data_t *qwd;
+	uintptr_t base;
+	size_t i, n, qqc_list_sz;
+	int cache_off, bucket_off, list_off;
+	mdb_qqcache_t qc;
+
+	/*  mdb_ctf_offsetof_by_name will print any errors */
+	cache_off = mdb_ctf_offsetof_by_name("qqcache_t", "qqc_lists");
+	if (cache_off == -1)
+		return (WALK_ERR);
+
+	bucket_off = mdb_ctf_offsetof_by_name("qqcache_t", "qqc_buckets");
+	if (bucket_off == -1)
+		return (WALK_ERR);
+
+	list_off = mdb_ctf_offsetof_by_name("qqcache_list_t", "qqcl_list");
+	if (list_off == -1)
+		return (WALK_ERR);
+
+	/* mdb_ctf_sizeof_by_name will print any errors */
+	qqc_list_sz = mdb_ctf_sizeof_by_name("qqcache_list_t");
+	if (qqc_list_sz == -1)
+		return (WALK_ERR);
+
+	if (mdb_ctf_vread(&qc, "qqcache_t", "mdb_qqcache_t", wsp->walk_addr,
+	    0) == -1) {
+		mdb_warn("failed to read qqcache_t at %#lx", wsp->walk_addr);
+		return (WALK_ERR);
+	}
+
+	qwd = wsp->walk_data = mdb_zalloc(sizeof (*qwd), UM_SLEEP);
+	qwd->qwd_link_off = qc.qqc_link_off;
+
+	if (use_hash) {
+		base = wsp->walk_addr + bucket_off;
+		n = qc.qqc_nbuckets;
+	} else {
+		base = wsp->walk_addr + cache_off;
+		n = QQCACHE_NUM_LISTS;
+	}
+
+	for (i = 0; i < n; i++) {
+		wsp->walk_addr = base + i * qqc_list_sz + list_off;
+
+		if (mdb_layered_walk("list", wsp) == -1) {
+			mdb_warn("can't walk qqcache_t");
+			mdb_free(qwd, sizeof (*qwd));
+			return (WALK_ERR);
+		}
+	}
+
+	return (WALK_NEXT);
+}
+
+int
+qqcache_walk_init_cache(mdb_walk_state_t *wsp)
+{
+	return (qqcache_walk_init(wsp, B_FALSE));
+}
+
+int
+qqcache_walk_init_hash(mdb_walk_state_t *wsp)
+{
+	return (qqcache_walk_init(wsp, B_TRUE));
+}
+
+int
+qqcache_walk_step(mdb_walk_state_t *wsp)
+{
+	qqcache_walk_data_t *qwd = wsp->walk_data;
+	uintptr_t addr = wsp->walk_addr - qwd->qwd_link_off;
+
+	return (wsp->walk_callback(addr, wsp->walk_layer, wsp->walk_cbdata));
+}
+
+void
+qqcache_walk_fini(mdb_walk_state_t *wsp)
+{
+	qqcache_walk_data_t *qwd = wsp->walk_data;
+
+	mdb_free(qwd, sizeof (*qwd));
+}
diff --git a/usr/src/cmd/mdb/common/modules/genunix/qqcache.h b/usr/src/cmd/mdb/common/modules/genunix/qqcache.h
new file mode 100644
index 0000000000..c0d1d14fe6
--- /dev/null
+++ b/usr/src/cmd/mdb/common/modules/genunix/qqcache.h
@@ -0,0 +1,40 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright 2018, Joyent Inc.
+ */
+
+#ifndef _MDB_QQCACHE_H
+#define	_MDB_QQCACHE_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define	QQCACHE_WALK_NAME "qqcache"
+#define	QQCACHE_WALK_DESC "walk a qqcache (2Q cache)"
+
+#define	QQCACHE_HASH_WALK_NAME "qqhash"
+#define	QQCACHE_HASH_WALK_DESC "walk a qqcache (2Q cache) via the hash buckets"
+
+struct mdb_walk_state;
+
+extern int qqcache_walk_init_cache(struct mdb_walk_state *);
+extern int qqcache_walk_init_hash(struct mdb_walk_state *);
+extern int qqcache_walk_step(struct mdb_walk_state *);
+extern void qqcache_walk_fini(struct mdb_walk_state *);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _MDB_QQCACHE_H */
diff --git a/usr/src/uts/common/Makefile.files b/usr/src/uts/common/Makefile.files
index 2def4f2ff2..1dea5d9ed1 100644
--- a/usr/src/uts/common/Makefile.files
+++ b/usr/src/uts/common/Makefile.files
@@ -292,6 +292,7 @@ GENUNIX_OBJS +=	\
 		resolvepath.o	\
 		retire_store.o	\
 		process.o	\
+		qqcache.o	\
 		rlimit.o	\
 		rmap.o		\
 		rw.o		\
@@ -697,7 +698,7 @@ NET80211_OBJS += net80211.o net80211_proto.o net80211_input.o \
 VNIC_OBJS +=	vnic_ctl.o vnic_dev.o
 
 OVERLAY_OBJS +=	overlay.o overlay_fm.o overlay_mux.o overlay_plugin.o \
-		overlay_prop.o overlay_target.o sarc.o
+		overlay_prop.o overlay_target.o
 
 OVERLAY_VXLAN_OBJS +=	overlay_vxlan.o
 
diff --git a/usr/src/uts/common/Makefile.rules b/usr/src/uts/common/Makefile.rules
index 7c9834f3d3..880b53b45e 100644
--- a/usr/src/uts/common/Makefile.rules
+++ b/usr/src/uts/common/Makefile.rules
@@ -23,7 +23,7 @@
 # Copyright (c) 1991, 2010, Oracle and/or its affiliates. All rights reserved.
 # Copyright 2016 Garrett D'Amore <garrett@damore.org>
 # Copyright 2013 Saso Kiselkov. All rights reserved.
-# Copyright 2017 Joyent, Inc.
+# Copyright 2018 Joyent, Inc.
 # Copyright 2016 Nexenta Systems, Inc.
 # Copyright (c) 2016 by Delphix. All rights reserved.
 #
@@ -1609,6 +1609,10 @@ $(OBJS_DIR)/%.o:		$(UTSBASE)/common/pcmcia/pcs/%.c
 	$(COMPILE.c) -o $@ $<
 	$(CTFCONVERT_O)
 
+$(OBJS_DIR)/%.o:        $(UTSBASE)/common/qqcache/%.c
+	$(COMPILE.c) -o $@ $<
+	$(CTFCONVERT_O)
+
 $(OBJS_DIR)/%.o:		$(UTSBASE)/common/refhash/%.c
 	$(COMPILE.c) -o $@ $<
 	$(CTFCONVERT_O)
@@ -2780,6 +2784,9 @@ $(LINTS_DIR)/%.ln:		$(COMMONBASE)/nvpair/%.c
 $(LINTS_DIR)/%.ln:		$(UTSBASE)/common/os/%.c
 	@($(LHEAD) $(LINT.c) $< $(LTAIL))
 
+$(LINTS_DIR)/%.ln:		$(UTSBASE)/common/qqcache/%.c
+	@($(LHEAD) $(LINT.c) $< $(LTAIL))
+
 $(LINTS_DIR)/%.ln:		$(UTSBASE)/common/rpc/%.c
 	@($(LHEAD) $(LINT.c) $< $(LTAIL))
 
diff --git a/usr/src/uts/common/io/overlay/overlay.c b/usr/src/uts/common/io/overlay/overlay.c
index 6862f764b9..0943e94d4c 100644
--- a/usr/src/uts/common/io/overlay/overlay.c
+++ b/usr/src/uts/common/io/overlay/overlay.c
@@ -499,7 +499,7 @@
  * On the other hand, when we have an instance of OVERLAY_TARGET_DYNAMIC, things
  * are much more interesting and as a result, more complicated. We primarily
  * store lists of overlay_target_entry_t's which are stored in both an avl tree
- * and a sarc_t. The primary look up path uses the sarc_t and the avl tree
+ * and a qqcache_t. The primary look up path uses the qqcache_t and the avl tree
  * is only used for a few of the target ioctls used to dump data such that we
  * can get a consistent iteration order for things like dladm show-overlay -t.
  * The key that we use for the reference hashtable is based on the mac address
diff --git a/usr/src/uts/common/io/overlay/overlay_target.c b/usr/src/uts/common/io/overlay/overlay_target.c
index 07cacf62e3..15019297d5 100644
--- a/usr/src/uts/common/io/overlay/overlay_target.c
+++ b/usr/src/uts/common/io/overlay/overlay_target.c
@@ -63,6 +63,12 @@
  */
 #define	OVERLAY_CACHE_SIZE	512
 
+/*
+ * A somewhat arbitrary value.  The percentage of the target cache dedicated
+ * to MFU entries (i.e. entries that have been looked up more than once).
+ */
+#define	OVERLAY_CACHE_A		60
+
 /*
  * We use this data structure to keep track of what requests have been actively
  * allocated to a given instance so we know what to put back on the pending
@@ -220,7 +226,7 @@ overlay_target_entry_dtor(void *arg)
 }
 
 static void
-overlay_target_entry_l2sarc_dtor(void *arg)
+overlay_target_entry_l2qq_dtor(void *arg)
 {
 	overlay_target_entry_t *ote = arg;
 	overlay_target_t *ott = ote->ote_ott;
@@ -233,7 +239,7 @@ overlay_target_entry_l2sarc_dtor(void *arg)
 }
 
 static void
-overlay_target_entry_l3sarc_dtor(void *arg)
+overlay_target_entry_l3qq_dtor(void *arg)
 {
 	overlay_target_entry_t *ote = arg;
 	overlay_target_t *ott = ote->ote_ott;
@@ -338,13 +344,13 @@ overlay_target_free(overlay_dev_t *odd)
 		mutex_enter(&odd->odd_target->ott_lock);
 		/*
 		 * Our VL3 AVL tree and hashtable contain the same elements.
-		 * Additionally, when an entry is removed from the sarc cache,
+		 * Additionally, when an entry is removed from the 2Q cache,
 		 * the entry is removed from the corresponding AVL tree.
-		 * Deleting the sarc cache will destroy any remaining entries,
-		 * so all we need to do is destroy the sarc caches.
+		 * Deleting the 2Q cache will destroy any remaining entries,
+		 * so all we need to do is destroy the 2Q caches.
 		 */
-		sarc_destroy(odd->odd_target->ott_u.ott_dyn.ott_dhash);
-		sarc_destroy(odd->odd_target->ott_u.ott_dyn.ott_l3dhash);
+		qqcache_destroy(odd->odd_target->ott_u.ott_dyn.ott_dhash);
+		qqcache_destroy(odd->odd_target->ott_u.ott_dyn.ott_l3dhash);
 		ASSERT(avl_is_empty(&odd->odd_target->ott_u.ott_dyn.ott_tree));
 		ASSERT(avl_is_empty(
 		    &odd->odd_target->ott_u.ott_dyn.ott_l3tree));
@@ -398,9 +404,9 @@ overlay_target_queue(overlay_target_entry_t *entry)
 	}
 	ott->ott_ocount++;
 	if (is_vl3)
-		sarc_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	else
-		sarc_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
 
 	mutex_exit(&ott->ott_lock);
 	list_insert_tail(&overlay_target_list, entry);
@@ -761,7 +767,7 @@ overlay_route_lookup(overlay_dev_t *odd, mblk_t *mp, uint16_t vlan,
 	}
 
 	mutex_enter(&ott->ott_lock);
-	entry = sarc_lookup(ott->ott_u.ott_dyn.ott_l3dhash, &vl3);
+	entry = qqcache_lookup(ott->ott_u.ott_dyn.ott_l3dhash, &vl3);
 	if (entry == NULL) {
 		if ((entry = kmem_cache_alloc(overlay_entry_cache,
 		    KM_NOSLEEP | KM_NORMALPRI)) == NULL) {
@@ -780,19 +786,19 @@ overlay_route_lookup(overlay_dev_t *odd, mblk_t *mp, uint16_t vlan,
 		entry->ote_ott = ott;
 		entry->ote_odd = odd;
 
-		sarc_insert(ott->ott_u.ott_dyn.ott_l3dhash, entry);
-		sarc_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_insert(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 		avl_add(&ott->ott_u.ott_dyn.ott_l3tree, entry);
 		mutex_exit(&ott->ott_lock);
 
 		overlay_target_queue(entry);
 
 		mutex_enter(&ott->ott_lock);
-		sarc_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 		mutex_exit(&ott->ott_lock);
 		return (OVERLAY_TARGET_ASYNC);
 	}
-	sarc_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+	qqcache_hold(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	mutex_enter(&entry->ote_lock);
 
 	/*
@@ -802,10 +808,10 @@ overlay_route_lookup(overlay_dev_t *odd, mblk_t *mp, uint16_t vlan,
 	if ((entry->ote_flags &
 	    (OVERLAY_ENTRY_F_DROP|OVERLAY_ENTRY_F_ROUTER|
 	    OVERLAY_ENTRY_F_VALID)) == OVERLAY_ENTRY_F_VALID) {
-		vl2_entry = sarc_lookup(ott->ott_u.ott_dyn.ott_dhash,
+		vl2_entry = qqcache_lookup(ott->ott_u.ott_dyn.ott_dhash,
 		    &entry->ote_u.ote_vl3.otvl3_vl2);
 		if (vl2_entry != NULL)
-			sarc_hold(ott->ott_u.ott_dyn.ott_dhash, vl2_entry);
+			qqcache_hold(ott->ott_u.ott_dyn.ott_dhash, vl2_entry);
 	}
 	mutex_exit(&ott->ott_lock);
 
@@ -833,9 +839,9 @@ overlay_route_lookup(overlay_dev_t *odd, mblk_t *mp, uint16_t vlan,
 	}
 
 	mutex_enter(&ott->ott_lock);
-	sarc_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+	qqcache_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	if (vl2_entry != NULL)
-		sarc_rele(ott->ott_u.ott_dyn.ott_dhash, vl2_entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_dhash, vl2_entry);
 	mutex_exit(&ott->ott_lock);
 	return (ret);
 }
@@ -899,7 +905,7 @@ overlay_target_lookup(overlay_dev_t *odd, mblk_t *mp, struct sockaddr *sock,
 	bcopy(mhi.mhi_daddr, omac.otm_mac, ETHERADDRL);
 
 	mutex_enter(&ott->ott_lock);
-	entry = sarc_lookup(ott->ott_u.ott_dyn.ott_dhash, &omac);
+	entry = qqcache_lookup(ott->ott_u.ott_dyn.ott_dhash, &omac);
 	if (entry == NULL) {
 		overlay_target_vl2_t *vl2p;
 
@@ -924,19 +930,19 @@ overlay_target_lookup(overlay_dev_t *odd, mblk_t *mp, struct sockaddr *sock,
 		entry->ote_ott = ott;
 		entry->ote_odd = odd;
 
-		sarc_insert(ott->ott_u.ott_dyn.ott_dhash, entry);
-		sarc_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_insert(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
 		avl_add(&ott->ott_u.ott_dyn.ott_tree, entry);
 		mutex_exit(&ott->ott_lock);
 
 		overlay_target_queue(entry);
 
 		mutex_enter(&ott->ott_lock);
-		sarc_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
 		mutex_exit(&ott->ott_lock);
 		return (OVERLAY_TARGET_ASYNC);
 	}
-	sarc_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
+	qqcache_hold(ott->ott_u.ott_dyn.ott_dhash, entry);
 	mutex_exit(&ott->ott_lock);
 
 	mutex_enter(&entry->ote_lock);
@@ -972,7 +978,7 @@ overlay_target_lookup(overlay_dev_t *odd, mblk_t *mp, struct sockaddr *sock,
 	}
 
 	mutex_enter(&ott->ott_lock);
-	sarc_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
+	qqcache_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
 	mutex_exit(&ott->ott_lock);
 
 	return (ret);
@@ -1003,22 +1009,6 @@ overlay_target_info(overlay_target_hdl_t *thdl, void *arg)
 	return (0);
 }
 
-static sarc_ops_t overlay_sarc_l2_ops = {
-	.sao_hash = overlay_mac_hash,
-	.sao_cmp = overlay_mac_cmp,
-	.sao_dtor = overlay_target_entry_l2sarc_dtor,
-	.sao_fetch = sarc_nofetch,
-	.sao_evict = sarc_noevict
-};
-
-static sarc_ops_t overlay_sarc_l3_ops = {
-	.sao_hash = overlay_ip_hash,
-	.sao_cmp = overlay_ip_cmp,
-	.sao_dtor = overlay_target_entry_l3sarc_dtor,
-	.sao_fetch = sarc_nofetch,
-	.sao_evict = sarc_noevict
-};
-
 /* ARGSUSED */
 static int
 overlay_target_associate(overlay_target_hdl_t *thdl, void *arg)
@@ -1078,8 +1068,10 @@ overlay_target_associate(overlay_target_hdl_t *thdl, void *arg)
 	} else {
 		int ret;
 
-		ret = sarc_create(&ott->ott_u.ott_dyn.ott_dhash,
-		    OVERLAY_CACHE_SIZE, OVERLAY_HSIZE, &overlay_sarc_l2_ops,
+		ret = qqcache_create(&ott->ott_u.ott_dyn.ott_dhash,
+		    OVERLAY_CACHE_SIZE, OVERLAY_CACHE_A, OVERLAY_HSIZE,
+		    overlay_mac_hash, overlay_mac_cmp,
+		    overlay_target_entry_l2qq_dtor,
 		    sizeof (overlay_target_entry_t),
 		    offsetof(overlay_target_entry_t, ote_reflink),
 		    offsetof(overlay_target_entry_t, ote_u.ote_vl2.otvl2_mac),
@@ -1091,14 +1083,16 @@ overlay_target_associate(overlay_target_hdl_t *thdl, void *arg)
 			return (ret);
 		}
 
-		ret = sarc_create(&ott->ott_u.ott_dyn.ott_l3dhash,
-		    OVERLAY_CACHE_SIZE, OVERLAY_HSIZE, &overlay_sarc_l3_ops,
+		ret = qqcache_create(&ott->ott_u.ott_dyn.ott_l3dhash,
+		    OVERLAY_CACHE_SIZE, OVERLAY_CACHE_A, OVERLAY_HSIZE,
+		    overlay_ip_hash, overlay_ip_cmp,
+		    overlay_target_entry_l3qq_dtor,
 		    sizeof (overlay_target_entry_t),
 		    offsetof(overlay_target_entry_t, ote_reflink),
 		    offsetof(overlay_target_entry_t, ote_u.ote_vl3), KM_SLEEP);
 		if (ret != 0) {
 			mutex_exit(&odd->odd_lock);
-			sarc_destroy(ott->ott_u.ott_dyn.ott_dhash);
+			qqcache_destroy(ott->ott_u.ott_dyn.ott_dhash);
 			kmem_cache_free(overlay_target_cache, ott);
 			overlay_hold_rele(odd);
 			return (ret);
@@ -1283,7 +1277,7 @@ overlay_target_lookup_respond_vl3(const overlay_targ_resp_t *otr,
 	overlay_target_entry_t *shared = NULL;
 	overlay_target_entry_t *vl2_entry;
 	overlay_target_t *ott = entry->ote_ott;
-	sarc_t *mhash = ott->ott_u.ott_dyn.ott_dhash;
+	qqcache_t *mhash = ott->ott_u.ott_dyn.ott_dhash;
 	hrtime_t now = gethrtime();
 
 	ASSERT(MUTEX_HELD(&entry->ote_lock));
@@ -1303,8 +1297,8 @@ overlay_target_lookup_respond_vl3(const overlay_targ_resp_t *otr,
 	   sizeof (overlay_target_mac_t));
 
 	mutex_enter(&ott->ott_lock);
-	if ((shared = sarc_lookup(mhash, &otr->otr_mac)) != NULL)
-		sarc_hold(mhash, shared);
+	if ((shared = qqcache_lookup(mhash, &otr->otr_mac)) != NULL)
+		qqcache_hold(mhash, shared);
 	mutex_exit(&ott->ott_lock);
 
 	/*
@@ -1342,16 +1336,16 @@ overlay_target_lookup_respond_vl3(const overlay_targ_resp_t *otr,
 		vl2_entry->ote_vtime = entry->ote_vtime = now;
 
 		mutex_enter(&ott->ott_lock);
-		if ((shared = sarc_lookup(mhash, &otr->otr_mac)) != NULL) {
+		if ((shared = qqcache_lookup(mhash, &otr->otr_mac)) != NULL) {
 			overlay_target_entry_dtor(vl2_entry);
 			kmem_cache_free(overlay_entry_cache, vl2_entry);
-			sarc_hold(mhash, shared);
+			qqcache_hold(mhash, shared);
 
 			vl2_entry = shared;
 		} else {
-			sarc_insert(mhash, vl2_entry);
+			qqcache_insert(mhash, vl2_entry);
 			avl_add(&ott->ott_u.ott_dyn.ott_tree, vl2_entry);
-			sarc_hold(mhash, vl2_entry);
+			qqcache_hold(mhash, vl2_entry);
 		}
 		mutex_exit(&ott->ott_lock);
 	} else {
@@ -1386,7 +1380,7 @@ overlay_target_lookup_respond_vl3(const overlay_targ_resp_t *otr,
 	mutex_exit(&vl2_entry->ote_lock);
 
 	mutex_enter(&ott->ott_lock);
-	sarc_rele(mhash, vl2_entry);
+	qqcache_rele(mhash, vl2_entry);
 	mutex_exit(&ott->ott_lock);
 }
 
@@ -1458,9 +1452,9 @@ overlay_target_lookup_respond(overlay_target_hdl_t *thdl, void *arg)
 	mutex_enter(&ott->ott_lock);
 	ott->ott_ocount--;
 	if (is_vl3)
-		sarc_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	else
-		sarc_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
 	cv_signal(&ott->ott_cond);
 	mutex_exit(&ott->ott_lock);
 
@@ -1572,13 +1566,13 @@ done:
 	ott->ott_ocount--;
 	if (action == OTLDA_DELETE) {
 		/* overlay_target_entry_dtor() will free the mblk chain */
-		sarc_remove(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_remove(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	}
 
 	if (is_vl3)
-		sarc_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_l3dhash, entry);
 	else
-		sarc_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
+		qqcache_rele(ott->ott_u.ott_dyn.ott_dhash, entry);
 
 	cv_signal(&ott->ott_cond);
 	mutex_exit(&ott->ott_lock);
@@ -1910,7 +1904,7 @@ overlay_target_cache_get(overlay_target_hdl_t *thdl, void *arg)
 	} else {
 		overlay_target_entry_t *ote;
 
-		if ((ote = sarc_lookup(ott->ott_u.ott_dyn.ott_dhash,
+		if ((ote = qqcache_lookup(ott->ott_u.ott_dyn.ott_dhash,
 		    &otc->otc_entry.otce_mac)) == NULL) {
 			ret = ENOENT;
 			goto done;
@@ -1996,7 +1990,7 @@ overlay_target_cache_set(overlay_target_hdl_t *thdl, void *arg)
 	mutex_enter(&ott->ott_lock);
 	mutex_exit(&odd->odd_lock);
 
-	if ((ote = sarc_lookup(ott->ott_u.ott_dyn.ott_dhash,
+	if ((ote = qqcache_lookup(ott->ott_u.ott_dyn.ott_dhash,
 	    &otc->otc_entry.otce_mac)) == NULL)
 		ote = new;
 
@@ -2017,7 +2011,7 @@ overlay_target_cache_set(overlay_target_hdl_t *thdl, void *arg)
 	}
 
 	if (ote == new) {
-		sarc_insert(ott->ott_u.ott_dyn.ott_dhash, ote);
+		qqcache_insert(ott->ott_u.ott_dyn.ott_dhash, ote);
 		avl_add(&ott->ott_u.ott_dyn.ott_tree, ote);
 	}
 	mutex_exit(&ote->ote_lock);
@@ -2068,7 +2062,7 @@ overlay_target_cache_remove(overlay_target_hdl_t *thdl, void *arg)
 	if (otc->otc_entry.otce_mac.otm_dcid == 0)
 		otc->otc_entry.otce_mac.otm_dcid = odd->odd_dcid;
 
-	ote = sarc_lookup(ott->ott_u.ott_dyn.ott_dhash,
+	ote = qqcache_lookup(ott->ott_u.ott_dyn.ott_dhash,
 	    &otc->otc_entry.otce_mac);
 	if (ote != NULL) {
 		mutex_enter(&ote->ote_lock);
@@ -2401,7 +2395,7 @@ overlay_target_cache_remove_net(overlay_target_hdl_t *thdl, void *arg)
 		    &ote->ote_u.ote_vl3.otvl3_dst, otcne->otcne_dst_prefixlen))
 			continue;
 
-		sarc_remove(ott->ott_u.ott_dyn.ott_l3dhash, ote);
+		qqcache_remove(ott->ott_u.ott_dyn.ott_l3dhash, ote);
 	}
 
 	mutex_exit(&ott->ott_lock);
diff --git a/usr/src/uts/common/io/overlay/sarc.c b/usr/src/uts/common/io/overlay/sarc.c
deleted file mode 100644
index ba762dfc3c..0000000000
--- a/usr/src/uts/common/io/overlay/sarc.c
+++ /dev/null
@@ -1,676 +0,0 @@
-/*
- * This file and its contents are supplied under the terms of the
- * Common Development and Distribution License ("CDDL"), version 1.0.
- * You may only use this file in accordance with the terms of version
- * 1.0 of the CDDL.
- *
- * A full copy of the text of the CDDL should have accompanied this
- * source.  A copy of the CDDL is also available via the Internet at
- * http://www.illumos.org/license/CDDL.
- */
-
-/*
- * Copyright 2018, Joyent, Inc.
- */
-
-#include <sys/debug.h>
-#include <sys/errno.h>
-#include <sys/sysmacros.h>
-#ifdef _KERNEL
-#include <sys/types.h>
-#else
-#include <stddef.h>
-#include <stdint.h>
-#endif
-
-/*
- * XXX: Until this code is integrated, it can be useful to be able to
- * build this on it's own for testing, etc. on PIs that predate when
- * the __unused macro was added.  If/once this code is integrated into
- * illumos-joyent, this check can be removed.
- */
-#ifndef __unused
-#define	__unused __attribute__((unused))
-#endif
-
-#ifdef _KERNEL
-#include <sys/kmem.h>
-#define	ZALLOC		kmem_zalloc
-#define	FREE		kmem_free
-#else
-#include <umem.h>
-#define	ZALLOC		umem_zalloc
-#define	FREE		umem_free
-#endif
-
-#include "sarc_impl.h"
-
-/*
- * The *_overflow functions mimic the gcc/clang intrinsic functions.  Once
- * we are using a newer compiler version to that includes these as intrisnics,
- * these can be replaced with those versions.
- */
-static int
-uadd_overflow(const size_t a, const size_t b, size_t *sump)
-{
-	*sump = a + b;
-	if (*sump < a || *sump < b)
-		return (1);
-	return (0);
-}
-
-#define	MUL_NO_OVERFLOW ((size_t)1 << (sizeof (size_t) * 4))
-
-static int
-umul_overflow(const size_t a, const size_t b, size_t *cp)
-{
-	*cp = a * b;
-
-	if ((a >= MUL_NO_OVERFLOW || b >= MUL_NO_OVERFLOW) &&
-	    a != 0 && b != 0 && SIZE_MAX / a < b)
-		return (1);
-
-	return (0);
-}
-
-void
-sarc_noevict(void *entry __unused)
-{
-}
-
-boolean_t
-sarc_nofetch(void *entry __unused)
-{
-	return (B_TRUE);
-}
-
-int
-sarc_create(sarc_t **sp, size_t c, size_t hsize, const sarc_ops_t *ops,
-    size_t obj_size, size_t link_off, size_t tag_off, int kmflags)
-{
-	sarc_t *sarc;
-	sarc_list_t *bucket;
-	size_t len = 0;
-	size_t i;
-
-	if (c < SARC_MIN_C)
-		return (EINVAL);
-
-	/* XXX: Maybe return EOVERFLOW instead? */
-	if (umul_overflow(sizeof (sarc_list_t), hsize, &len))
-		return (EINVAL);
-	if (uadd_overflow(sizeof (*sarc), len, &len))
-		return (EINVAL);
-
-	if ((sarc = ZALLOC(len, kmflags)) == NULL)
-		return (ENOMEM);
-
-	sarc->sarc_ops = *ops;
-	sarc->sarc_c = c;
-	sarc->sarc_p = c / 2;
-	sarc->sarc_nbuckets = hsize;
-	sarc->sarc_link_off = link_off;
-	sarc->sarc_tag_off = tag_off;
-	sarc->sarc_elsize = obj_size;
-
-	for (i = 0, bucket = sarc->sarc_bucket; i < hsize; i++, bucket++) {
-		list_create(&bucket->sal_list, obj_size, offsetof(sarc_link_t,
-		    sal_hash_link));
-	}
-
-	for (i = 0; i < SARC_NUM_LISTS; i++) {
-		list_create(&sarc->sarc_list[i].sal_list, obj_size,
-		    offsetof(sarc_link_t, sal_list_link));
-	}
-
-	*sp = sarc;
-	return (0);
-}
-
-void
-sarc_destroy(sarc_t *s)
-{
-	list_t *l;
-	sarc_link_t *lnk;
-	void *obj;
-	size_t i, len;
-
-	if (s == NULL)
-		return;
-
-	/* If creation succeeded, this calculation cannot overflow */
-	len = sizeof (*s) + s->sarc_nbuckets * sizeof (sarc_list_t);
-
-	for (i = 0; i < SARC_NUM_LISTS; i++) {
-		l = &s->sarc_list[i].sal_list;
-		for (;;) {
-			if ((lnk = list_remove_head(l)) == NULL)
-				break;
-		}
-	}
-
-	for (i = 0; i < s->sarc_nbuckets; i++) {
-		l = &s->sarc_bucket[i].sal_list;
-		for (;;) {
-			if ((lnk = list_remove_head(l)) == NULL)
-				break;
-			ASSERT0(lnk->sal_refcnt);
-			obj = link_to_obj(s, lnk);
-			s->sarc_ops.sao_dtor(obj);
-		}
-	}
-
-	FREE(s, len);
-}
-
-static void
-sarc_delete(sarc_t *s, sarc_link_t *lp)
-{
-	void *op = link_to_obj(s, lp);
-	void *tp = obj_to_tag(s, op);
-	uint_t n = s->sarc_ops.sao_hash(tp) % s->sarc_nbuckets;
-
-	ASSERT3U(s->sarc_bucket[n].sal_len, >, 0);
-	ASSERT(!list_is_empty(&s->sarc_bucket[n].sal_list));
-	ASSERT(!list_link_active(&lp->sal_list_link));
-	ASSERT(list_link_active(&lp->sal_hash_link));
-
-	list_remove(&s->sarc_bucket[n].sal_list, lp);
-	s->sarc_bucket[n].sal_len--;
-	s->sarc_ops.sao_dtor(op);
-}
-
-static sarc_link_t *
-sarc_lru_remove(sarc_t *s, sarc_flag_t list)
-{
-	sarc_link_t *lp;
-
-	ASSERT3S(list, >=, SARC_MRU);
-	ASSERT3S(list, <=, SARC_GMFU);
-
-	if ((lp = list_remove_tail(&s->sarc_list[list].sal_list)) != NULL)
-		s->sarc_list[list].sal_len--;
-
-	return (lp);
-}
-
-static void
-sarc_add(sarc_t *s, sarc_link_t *lp, sarc_flag_t which)
-{
-	sarc_list_t *slst;
-
-	ASSERT3S(which & ~SARC_LIST_MASK, ==, 0);
-	ASSERT(!list_link_active(&lp->sal_list_link));
-
-	slst = &s->sarc_list[which];
-	lp->sal_flags &= ~SARC_LIST_MASK;
-	lp->sal_flags |= which;
-	list_insert_head(&slst->sal_list, lp);
-	slst->sal_len++;
-}
-
-/*
- * Evict an entry from the cache (MRU, MFU) and move it to the respective
- * ghost list (MRU -> ghost MRU or MFU -> ghost MFU) to make room for a new
- * entry.  This is the REPLACE procedure from the ARC paper where
- * from_gmfu == (xt in B2)
- */
-static void
-sarc_evict(sarc_t *s, boolean_t from_gmfu)
-{
-	sarc_link_t *lp;
-	sarc_flag_t dst;
-	size_t mru_len = s->sarc_list[SARC_MRU].sal_len;
-
-	if ((mru_len > 0) && ((mru_len > s->sarc_p) ||
-	    (from_gmfu && mru_len == s->sarc_p))) {
-		lp = sarc_lru_remove(s, SARC_MRU);
-		dst = SARC_GMRU;
-	} else {
-		lp = sarc_lru_remove(s, SARC_MFU);
-		dst = SARC_GMFU;
-	}
-
-	s->sarc_ops.sao_evict(link_to_obj(s, lp));
-	sarc_add(s, lp, dst);
-}
-
-static sarc_link_t *
-sarc_hash_lookup(sarc_t *s, const void *tp, sarc_list_t **lpp)
-{
-	uint_t n = s->sarc_ops.sao_hash(tp) % s->sarc_nbuckets;
-	sarc_link_t *lp;
-	sarc_list_t *bucket = &s->sarc_bucket[n];
-	list_t *l = &bucket->sal_list;
-	void *cmp;
-
-	if (lpp != NULL)
-		*lpp = bucket;
-
-	for (lp = list_head(l); lp != NULL; lp = list_next(l, lp)) {
-		cmp = obj_to_tag(s, link_to_obj(s, lp));
-
-		if (s->sarc_ops.sao_cmp(cmp, tp) == 0 &&
-		    !(lp->sal_flags & SARC_F_DEAD))
-			return (lp);
-	}
-
-	return (NULL);
-}
-
-int
-sarc_insert(sarc_t *s, void *obj)
-{
-	sarc_link_t *lp = obj_to_link(s, obj);
-	sarc_link_t *evict_lp = NULL;
-	sarc_list_t *bucket;
-	size_t mru_total;
-	size_t mfu_total;
-
-	/* Make sure there's no duplicates */
-	if (sarc_hash_lookup(s, obj_to_tag(s, obj), &bucket) != NULL)
-		return (EEXIST);
-
-	list_link_init(&lp->sal_hash_link);
-	list_link_init(&lp->sal_list_link);
-	lp->sal_refcnt = 0;
-	lp->sal_flags = 0;
-
-	list_insert_tail(&bucket->sal_list, lp);
-	bucket->sal_len++;
-
-	/* New entries always get put on the MRU */
-	lp->sal_flags = SARC_MRU;
-
-	mru_total = s->sarc_list[SARC_MRU].sal_len +
-	    s->sarc_list[SARC_GMRU].sal_len;
-	mfu_total = s->sarc_list[SARC_MFU].sal_len +
-	    s->sarc_list[SARC_GMFU].sal_len;
-
-	if (mru_total == s->sarc_c) {
-		if (s->sarc_list[SARC_MRU].sal_len < s->sarc_c) {
-			evict_lp = sarc_lru_remove(s, SARC_GMRU);
-			sarc_evict(s, B_FALSE);
-		} else {
-			evict_lp = sarc_lru_remove(s, SARC_MRU);
-		}
-	} else if ((mru_total < s->sarc_c) &&
-	    (mru_total + mfu_total >= s->sarc_c)) {
-		evict_lp = sarc_lru_remove(s, SARC_GMFU);
-		sarc_evict(s, B_FALSE);
-	}
-
-	if (evict_lp != NULL) {
-		if (evict_lp->sal_refcnt > 0) {
-			evict_lp->sal_flags |= SARC_F_DEAD;
-		} else {
-			sarc_delete(s, evict_lp);
-		}
-	}
-
-	/* New entries always go on the MRU */
-	sarc_add(s, lp, SARC_MRU);
-	return (0);
-}
-
-void *
-sarc_lookup(sarc_t *s, const void *tp)
-{
-	sarc_link_t *lp;
-	sarc_list_t *src;
-	void *obj;
-	size_t gmfu_len, gmru_len, ratio;
-	boolean_t from_ghost = B_FALSE;
-	boolean_t from_gmfu = B_FALSE;
-
-	if ((lp = sarc_hash_lookup(s, tp, NULL)) == NULL)
-		return (NULL);
-
-	obj = link_to_obj(s, lp);
-	src = SARC_LIST(s, lp);
-	gmfu_len = s->sarc_list[SARC_GMFU].sal_len;
-	gmru_len = s->sarc_list[SARC_GMRU].sal_len;
-
-	/*
-	 * If an entry has been found, it means it's been accessed
-	 * at least once, so it gets put at the head of the MFU list
-	 */
-	switch (lp->sal_flags & SARC_LIST_MASK) {
-	case SARC_MFU:
-		/*
-		 * While we'll end up removing the entry from the MFU and
-		 * then readding it back to the MFU, we want it moved to
-		 * the head of the MFU from whereever it's current position
-		 * is, so we cannot return early.
-		 */
-	case SARC_MRU:
-		from_ghost = B_FALSE;
-		break;
-	case SARC_GMRU:
-		/*
-		 * If we have a ghost MRU hit, we want to bias
-		 * towards more MRU, so adjust p accordingly
-		 */
-		if ((ratio = gmfu_len / gmru_len) == 0)
-			ratio = 1;
-		s->sarc_p = MIN(s->sarc_p + ratio, s->sarc_c);
-		from_ghost = B_TRUE;
-		break;
-	case SARC_GMFU:
-		/*
-		 * Simlarly, if there's a ghost MFU hit, we want to
-		 * bias towards more MFU, so adjust p accordingly
-		 */
-		if ((ratio = gmru_len / gmfu_len) == 0)
-			ratio = 1;
-		s->sarc_p = (s->sarc_p >= ratio) ? s->sarc_p - ratio : 0;
-		from_ghost = B_TRUE;
-		from_gmfu = B_TRUE;
-		break;
-	}
-
-	/* Remove from its current list */
-	ASSERT3U(src->sal_len, >, 0);
-	ASSERT(!list_is_empty(&src->sal_list));
-	list_remove(&src->sal_list, lp);
-	src->sal_len--;
-
-	if (from_ghost) {
-		/*
-		 * If we cannot fetch the data for a ghost entry, we don't
-		 * want to put it on the MRU list.  Instead just put it back
-		 * at the front of the list it was on.
-		 */
-		if (!s->sarc_ops.sao_fetch(obj)) {
-			list_insert_head(&src->sal_list, lp);
-			src->sal_len++;
-			return (obj);
-		}
-
-		/*
-		 * We have entries on the ghost list, it means the cache
-		 * (MRU, MFU) is full.  Bump something down to the ghost
-		 * list so we can move entry back into the cache.
-		 */
-		sarc_evict(s, from_gmfu);
-	}
-
-	sarc_add(s, lp, SARC_MFU);
-	return (obj);
-}
-
-/*
- * Move the most recent entry in one of the ghost lists onto the tail of
- * which and fetch.  If which is a ghost list, this is a no-op.  Returns
- * B_TRUE if it was able to successfully resurrect an item, B_FALSE
- * otherwise.
- */
-static boolean_t
-sarc_resurrect(sarc_t *s, sarc_flag_t which)
-{
-	sarc_list_t *ghost_list, *dst;
-	sarc_link_t *exghost;
-
-	ASSERT3U(which & ~SARC_LIST_MASK, ==, 0);
-
-	dst = &s->sarc_list[which];
-	switch (which) {
-	case SARC_MRU:
-		ghost_list = &s->sarc_list[SARC_GMRU];
-		break;
-	case SARC_MFU:
-		ghost_list = &s->sarc_list[SARC_GMFU];
-		break;
-	default:
-		return (B_FALSE);
-	}
-	if (ghost_list->sal_len == 0)
-		return (B_FALSE);
-
-	exghost = list_remove_head(&ghost_list->sal_list);
-	if (!s->sarc_ops.sao_fetch(link_to_obj(s, exghost))) {
-		/* If we cannot fetch for some reason, just put it back */
-		list_insert_head(&ghost_list->sal_list, exghost);
-		return (B_FALSE);
-	}
-	ghost_list->sal_len--;
-
-	exghost->sal_flags &= ~SARC_LIST_MASK;
-	exghost->sal_flags |= which;
-	list_insert_tail(&dst->sal_list, exghost);
-	dst->sal_len++;
-
-	return (B_TRUE);
-}
-
-void
-sarc_remove(sarc_t *s, void *op)
-{
-	sarc_link_t *lp = obj_to_link(s, op);
-	sarc_list_t *lst = SARC_LIST(s, lp);
-
-	ASSERT(!list_is_empty(&lst->sal_list));
-	ASSERT3U(lst->sal_len, >, 0);
-	list_remove(&lst->sal_list, lp);
-	lst->sal_len--;
-
-	/*
-	 * For similar reasons as when we resize, if we're removing something
-	 * from the MRU or MFU list, we want to move an entry from the
-	 * respective ghost list so the ghost MRU:ghost MFU ratio (used to
-	 * determine how aggressively p is adjusted on ghost hits) stays
-	 * correct.  Since we're removing a single item, there's not much
-	 * we can do if we can't fetch the ghost item, so ignore the return
-	 * value.
-	 */
-	(void) sarc_resurrect(s, lp->sal_flags & SARC_LIST_MASK);
-
-	if (lp->sal_refcnt > 0) {
-		lp->sal_flags |= SARC_F_DEAD;
-	} else {
-		sarc_delete(s, lp);
-	}
-}
-
-void
-sarc_hold(sarc_t *s, void *op)
-{
-	sarc_link_t *lp = obj_to_link(s, op);
-
-	++lp->sal_refcnt;
-}
-
-void
-sarc_rele(sarc_t *s, void *op)
-{
-	sarc_link_t *lp = obj_to_link(s, op);
-
-	ASSERT3U(lp->sal_refcnt, >, 0);
-
-	if (--lp->sal_refcnt == 0 && (lp->sal_flags & SARC_F_DEAD))
-		sarc_delete(s, lp);
-}
-
-int
-sarc_adjust_c(sarc_t *s, size_t new_c)
-{
-	sarc_link_t *lp = NULL;
-	size_t new_p = 0;
-	size_t mfu_tgt_len = 0;
-
-	/*
-	 * The original ARC paper doesn't cover this.  The most obvious
-	 * thing seems to scale p by the same ratio of old_c:new_c, and
-	 * if new_c < old_c, evict / delete entries as appropriate
-	 */
-	if (new_c < SARC_MIN_C)
-		return (EINVAL);
-
-	if (new_c == s->sarc_c)
-		return (0);
-
-	/*
-	 * new_p = p * (new_c/old_c).  Since we can't easily
-	 * use floating point if we're in the kernel, we try to
-	 * order the operations to preserve as much accuracy as
-	 * possible.  It does mean if new_c * p > SIZE_MAX, we
-	 * will fail the resize, however since the kernel is
-	 * 64-bit, that means new_c * p would be > 2^64 for
-	 * us to fail, so that seems unlikely to be legitimate.
-	 *
-	 * Since we are using integer math to resize p in proportion to the
-	 * change in c, it is possible the new value could result in a value
-	 * one less than if floating point + rounding was done (due to
-	 * truncation instead of rounding with integer division).  At the
-	 * moment, it doesn't seem like this should be a significant concern
-	 * as the value is p is constantly adjusted based on the access pattern
-	 * (i.e. hit rate) of the ghost caches.  If the value of p is off, it
-	 * should converge to the current 'correct' (best might be a better
-	 * description) value of p.  It should be expected that resizing the
-	 * cache is a somewhat disruptive operation in that it can lead to a
-	 * potentially large amount of cache eviction.
-	 */
-	if (umul_overflow(s->sarc_p, new_c, &new_p))
-		return (EOVERFLOW);
-	new_p /= s->sarc_c;
-	mfu_tgt_len = new_c - new_p;
-
-	if (new_c > s->sarc_c) {
-		/*
-		 * When increasing the size of the cache, we could just
-		 * update c and p, and leave the existing entries as is.
-		 * However, the ARC algorithm (at least as explained by
-		 * Megiddo and Modha) seems to implicitly assume that
-		 * if the ghost lists are populated, then their respective
-		 * real lists are 'full'.  Not having this seems like it
-		 * could distort the ideal value of p.  As such we want to
-		 * move as many entries from the ghost lists back into the
-		 * MFU and MRU caches as we can to keep adjustments to p
-		 * from being overly aggressive.
-		 */
-		while (s->sarc_list[SARC_MRU].sal_len < new_p) {
-			if (!sarc_resurrect(s, SARC_MRU))
-				break;
-		}
-
-		while (s->sarc_list[SARC_MFU].sal_len < mfu_tgt_len) {
-			if (!sarc_resurrect(s, SARC_MFU))
-				break;
-		}
-	} else {
-		/*
-		 * Move enough stuff from the MRU and MFU lists onto their
-		 * respective ghost lists.  Since p is the desired size of
-		 * the MRU list, c - p is the size of the MFU.  However,
-		 * the number of entries for a given list and it's ghost
-		 * counter part should also be <= c.  This means:
-		 *	p	Current maximum size of MRU
-		 *	c - p	Current maximum size of MFU
-		 *	c - p	Current maximum size of ghost MRU
-		 *	p	Current maximum size of ghost MFU
-		 *
-		 * Thus the new size of the ghost MRU is == mfu_tgt_len and
-		 * the new new size of the ghost MFU is p.  As we move entries
-		 * around, these limits might be exceeded (e.g. we may move
-		 * more than new_c - new_p entries from the MRU to the
-		 * ghost MFU, but only for the duration of the resize
-		 * operation -- everything should be within limits once we're
-		 * done.
-		 */
-		while (s->sarc_list[SARC_MRU].sal_len > new_p) {
-			if ((lp = sarc_lru_remove(s, SARC_MRU)) == NULL)
-				break;
-			s->sarc_ops.sao_evict(link_to_obj(s, lp));
-			sarc_add(s, lp, SARC_GMRU);
-		}
-		while (s->sarc_list[SARC_GMRU].sal_len > mfu_tgt_len) {
-			if ((lp = sarc_lru_remove(s, SARC_GMRU)) != NULL) {
-				if (lp->sal_refcnt > 0)
-					lp->sal_flags |= SARC_F_DEAD;
-				else
-					sarc_delete(s, lp);
-			} else {
-				break;
-			}
-		}
-
-		while (s->sarc_list[SARC_MFU].sal_len > mfu_tgt_len) {
-			if ((lp = sarc_lru_remove(s, SARC_MFU)) == NULL)
-				break;
-			s->sarc_ops.sao_evict(link_to_obj(s, lp));
-			sarc_add(s, lp, SARC_GMFU);
-		}
-		while (s->sarc_list[SARC_GMFU].sal_len > new_p) {
-			if ((lp = sarc_lru_remove(s, SARC_GMFU)) != NULL) {
-				if (lp->sal_refcnt > 0)
-					lp->sal_flags |= SARC_F_DEAD;
-				else
-					sarc_delete(s, lp);
-			} else {
-				break;
-			}
-		}
-	}
-
-	s->sarc_c = new_c;
-	s->sarc_p = new_p;
-	return (0);
-}
-
-/*
- * Return the first entry.  Entry is refheld.
- */
-void *
-sarc_first(sarc_t *s)
-{
-	sarc_link_t *lp = NULL;
-
-	for (int i = 0; i < SARC_NUM_LISTS; i++) {
-		sarc_list_t *slp = &s->sarc_list[i];
-
-		if ((lp = list_head(&slp->sal_list)) == NULL)
-			continue;
-
-		while (lp != NULL && ((lp->sal_flags & SARC_F_DEAD) != 0))
-			lp = list_next(&slp->sal_list, lp);
-
-		if (lp != NULL) {
-			++lp->sal_refcnt;
-			return (link_to_obj(s, lp));
-		}
-	}
-
-	return (lp);
-}
-
-/*
- * Find the next entry after op.  Assumes op is already refheld.  Releases
- * reference on op.
- */
-void *
-sarc_next(sarc_t *s, void *op)
-{
-	sarc_link_t *lp;
-	int which;
-
-	lp = obj_to_link(s, op);
-	which = lp->sal_flags & SARC_LIST_MASK;
-
-	while (which < SARC_NUM_LISTS) {
-		sarc_list_t *slp = &s->sarc_list[which++];
-
-		while ((lp = list_next(&slp->sal_list, lp)) != NULL) {
-			if (!(lp->sal_flags & SARC_F_DEAD))
-				goto done;
-		}
-	}
-
-done:
-	sarc_rele(s, op);
-	if (lp == NULL)
-		return (NULL);
-
-	++lp->sal_refcnt;
-
-	return (link_to_obj(s, lp));
-}
diff --git a/usr/src/uts/common/io/overlay/sarc_impl.h b/usr/src/uts/common/io/overlay/sarc_impl.h
deleted file mode 100644
index 236d1b1562..0000000000
--- a/usr/src/uts/common/io/overlay/sarc_impl.h
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * This file and its contents are supplied under the terms of the
- * Common Development and Distribution License ("CDDL"), version 1.0.
- * You may only use this file in accordance with the terms of version
- * 1.0 of the CDDL.
- *
- * A full copy of the text of the CDDL should have accompanied this
- * source.  A copy of the CDDL is also available via the Internet at
- * http://www.illumos.org/license/CDDL.
- */
-
-/*
- * Copyright 2018, Joyent, Inc.
- */
-
-#ifndef _SARC_IMPL_H
-#define	_SARC_IMPL_H
-
-#include <sys/debug.h>
-#include <sys/sarc.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#define	SARC_NUM_LISTS	4	/* MRU, MFU, ghost MRU, ghost MFU */
-#define	SARC_LIST_MASK	0x3
-#define	SARC_MIN_C	10	/* Largely arbitrary minimum size */
-
-typedef struct sarc_list {
-	list_t	sal_list;
-	size_t	sal_len;	/* # of entries in list */
-} sarc_list_t;
-
-struct sarc {
-	sarc_ops_t	sarc_ops;		/* RO */
-	size_t		sarc_link_off;		/* RO */
-	size_t		sarc_tag_off;		/* RO */
-	size_t		sarc_nbuckets;		/* RO */
-	size_t		sarc_c;
-	size_t		sarc_p;
-	size_t		sarc_elsize;
-	sarc_list_t	sarc_list[SARC_NUM_LISTS];	/* MRU, MFU, etc */
-	sarc_list_t	sarc_bucket[];			/* hash buckets */
-};
-
-#define	SARC_LIST(_sarc, _lnk) \
-	(&(_sarc)->sarc_list[(_lnk)->sal_flags & SARC_LIST_MASK])
-
-#ifdef lint
-extern sarc_link_t *obj_to_link(sarc_t *, void *);
-extern void *link_to_obj(sarc_t *, sarc_link_t *);
-extern void *obj_to_tag(sarc_t *, void *);
-#else
-#define	obj_to_link(_s, _o)	\
-	((sarc_link_t *)(((char *)(_o)) + (_s)->sarc_link_off))
-#define	link_to_obj(_s, _l)	\
-	((void *)(((char *)(_l)) - (_s)->sarc_link_off))
-#define	obj_to_tag(_s, _o)	\
-	((void *)(((char *)(_o)) + (_s)->sarc_tag_off))
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* _SARC_IMPL_H */
diff --git a/usr/src/uts/common/qqcache/qqcache.c b/usr/src/uts/common/qqcache/qqcache.c
new file mode 100644
index 0000000000..12647155a9
--- /dev/null
+++ b/usr/src/uts/common/qqcache/qqcache.c
@@ -0,0 +1,430 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright 2018, Joyent, Inc.
+ */
+
+#include <sys/debug.h>
+#include <sys/errno.h>
+#include <sys/null.h>
+#include <sys/types.h>
+#include <sys/qqcache.h>
+#include <sys/qqcache_impl.h>
+#include <sys/stddef.h>
+#include <sys/kmem.h>
+
+/*
+ * The *_overflow functions mimic the gcc/clang intrinsic functions.  Once
+ * we are using a newer compiler version to that includes these as intrisnics,
+ * these can be replaced with those versions.
+ */
+static int
+uadd_overflow(const size_t a, const size_t b, size_t *sump)
+{
+	*sump = a + b;
+	if (*sump < a || *sump < b)
+		return (1);
+	return (0);
+}
+
+#define MUL_NO_OVERFLOW ((size_t)1 << (sizeof (size_t) * 4))
+
+static int
+umul_overflow(const size_t a, const size_t b, size_t *cp)
+{
+	*cp = a * b;
+
+	if ((a >= MUL_NO_OVERFLOW || b >= MUL_NO_OVERFLOW) &&
+	    a != 0 && b != 0 && SIZE_MAX / a < b)
+		return (1);
+
+	return (0);
+}
+
+/* Calculate the capacity of each list based on sz and a */
+static void
+qqcache_size_lists(size_t sz, size_t a, size_t *maxp)
+{
+	VERIFY3U(sz, >=, QQCACHE_NUM_LISTS);
+
+	/*
+	 * The general approach is to start with list 0 being sized as a% of
+	 * sz.  However every other list must be able to hold at least one
+	 * entry unless a == 100 (i.e. 100%).  If the straight percentage
+	 * leaves any of the remaining lists with zero entries, we give them
+	 * a size of 1, and then adjust list0's size according so that the
+	 * sum off all list sizes == sz (this is mostly only a concern where
+	 * sz is small enough such that (100 - a)% of sz < QQCACHE_NUM_LISTS).
+	 */
+	size_t list0sz = sz * a / 100;
+	size_t othersz = (sz - list0sz) / (QQCACHE_NUM_LISTS - 1);
+
+	if (list0sz == 0)
+		list0sz = 1;
+
+	if (othersz == 0 && a != 100)
+		othersz = 1;
+
+	if (list0sz + othersz * (QQCACHE_NUM_LISTS - 1) > sz)
+		list0sz = sz - othersz * (QQCACHE_NUM_LISTS - 1);
+
+	maxp[0] = list0sz;
+	for (size_t i = 1; i < QQCACHE_NUM_LISTS; i++)
+		maxp[i] = othersz;
+}
+
+int
+qqcache_create(qqcache_t **qp, size_t sz, size_t a, size_t buckets,
+    qqcache_hash_fn_t hash_fn, qqcache_cmp_fn_t cmp_fn,
+    qqcache_dtor_fn_t dtor_fn, size_t elsize, size_t link_off, size_t tag_off,
+    int kmflags)
+{
+	qqcache_t *qc;
+	size_t len = 0;
+
+	if (sz < QQCACHE_MIN_SIZE)
+		return (EINVAL);
+	if (a > 100)
+		return (EINVAL);
+
+	if (umul_overflow(sizeof (qqcache_list_t), buckets, &len))
+		return (EINVAL);
+	if (uadd_overflow(sizeof (*qc), len, &len))
+		return (EINVAL);
+
+	if ((qc = kmem_zalloc(len, kmflags)) == NULL)
+		return (ENOMEM);
+
+	qc->qqc_hash_fn = hash_fn;
+	qc->qqc_cmp_fn = cmp_fn;
+	qc->qqc_dtor_fn = dtor_fn;
+	qc->qqc_link_off = link_off;
+	qc->qqc_tag_off = tag_off;
+	qc->qqc_nbuckets = buckets;
+	qc->qqc_size = sz;
+	qc->qqc_a = a;
+
+	qqcache_size_lists(sz, a, qc->qqc_max);
+
+	for (size_t i = 0; i < buckets; i++) {
+		list_create(&qc->qqc_buckets[i].qqcl_list, elsize,
+		    offsetof(qqcache_link_t, qqln_hash_link));
+	}
+
+	for (size_t i = 0; i < QQCACHE_NUM_LISTS; i++) {
+		list_create(&qc->qqc_lists[i].qqcl_list, elsize,
+		    offsetof(qqcache_link_t, qqln_list_link));
+	}
+
+	*qp = qc;
+	return (0);
+}
+
+void
+qqcache_destroy(qqcache_t *qc)
+{
+	size_t len;
+
+	if (qc == NULL)
+		return;
+
+	/* If creation succeeded, this calculation cannot overflow */
+	len = sizeof (*qc) + qc->qqc_nbuckets * sizeof (qqcache_list_t);
+
+	for (size_t i = 0; i < QQCACHE_NUM_LISTS; i++) {
+		list_t *l = &qc->qqc_lists[i].qqcl_list;
+		qqcache_link_t *lnk;
+
+		while ((lnk = list_remove_head(l)) != NULL)
+			;
+	}
+
+	for (size_t i = 0; i < qc->qqc_nbuckets; i++) {
+		list_t *l = &qc->qqc_buckets[i].qqcl_list;
+		qqcache_link_t *lnk;
+
+		while ((lnk = list_remove_head(l)) != NULL) {
+			ASSERT0(lnk->qqln_refcnt);
+			qc->qqc_dtor_fn(link_to_obj(qc, lnk));
+		}
+	}
+
+	kmem_free(qc, len);
+}
+
+/*
+ * Removal of an entry is a two step process.  qqcache_remove() removes the
+ * entry from the cache lists, and if a reference is held, sets the
+ * QQCACHE_F_DEAD flag.  When there are no more references held on an entry,
+ * (either none are held at the time qqcache_remove() is called, or the last
+ * reference is removed via qqcache_rele(), qqcache_delete() is called which
+ * removes the entry from its hash bucket and calls the entry's dtor function.
+ *
+ * The main reason for the two step process is largely simplicity.  If the
+ * entry remains in the cache lists w/ the QQCACHE_F_DEAD flag set, it
+ * complicates keeping each cache within its size limits -- either the
+ * list size must reflect the number of non-dead entries (which could be
+ * confusing during troubleshooting), or as we push things down the list, we
+ * would need to skip/ignore dead entries.  The hash buckets however don't
+ * have any size limits (to impose limits would require the hash function
+ * provided by the consumer to produce perfectly equal distribution of entries
+ * across all the hash buckets at all times).  The only time we care about
+ * the QQCACHE_F_DEAD flag in the hash buckets is when trying to lookup a
+ * 'dead' value, so leaving the entries in there does not present the same
+ * issues as leaving them in the hash buckets (while still providing a way to
+ * find refheld entries).
+ */
+static void
+qqcache_delete(qqcache_t *qc, qqcache_link_t *lp)
+{
+	void *op = link_to_obj(qc, lp);
+	void *tp = obj_to_tag(qc, op);
+	uint_t n = qc->qqc_hash_fn(tp) % qc->qqc_nbuckets;
+
+	ASSERT3U(qc->qqc_buckets[n].qqcl_len, >, 0);
+	ASSERT(!list_is_empty(&qc->qqc_buckets[n].qqcl_list));
+	ASSERT(!list_link_active(&lp->qqln_list_link));
+	ASSERT(list_link_active(&lp->qqln_hash_link));
+
+	list_remove(&qc->qqc_buckets[n].qqcl_list, lp);
+	qc->qqc_buckets[n].qqcl_len--;
+	qc->qqc_dtor_fn(op);
+}
+
+void
+qqcache_remove(qqcache_t *qc, void *op)
+{
+	qqcache_link_t *lp = obj_to_link(qc, op);
+	qqcache_list_t *lst = QQCACHE_LIST(qc, lp);
+
+	ASSERT(!list_is_empty(&lst->qqcl_list));
+	ASSERT3U(lst->qqcl_len, >, 0);
+
+	list_remove(&lst->qqcl_list, lp);
+	lst->qqcl_len--;
+
+	if (lp->qqln_refcnt > 0)
+		lp->qqln_flags |= QQCACHE_F_DEAD;
+	else
+		qqcache_delete(qc, lp);
+}
+
+void
+qqcache_hold(qqcache_t *qc, void *op)
+{
+	qqcache_link_t *lp = obj_to_link(qc, op);
+
+	++lp->qqln_refcnt;
+}
+
+void
+qqcache_rele(qqcache_t *qc, void *op)
+{
+	qqcache_link_t *lp = obj_to_link(qc, op);
+
+	VERIFY3U(lp->qqln_refcnt, >, 0);
+
+	if (--lp->qqln_refcnt == 0 && (lp->qqln_flags & QQCACHE_F_DEAD))
+		qqcache_delete(qc, lp);
+}
+
+static qqcache_link_t *
+qqcache_hash_lookup(qqcache_t *qc, const void *tp, qqcache_list_t **lpp)
+{
+	uint_t n = qc->qqc_hash_fn(tp) % qc->qqc_nbuckets;
+	qqcache_link_t *lp;
+	qqcache_list_t *bucket = &qc->qqc_buckets[n];
+	list_t *l = &bucket->qqcl_list;
+	void *cmp;
+
+	if (lpp != NULL)
+		*lpp = bucket;
+
+	for (lp = list_head(l); lp != NULL; lp = list_next(l, lp)) {
+		cmp = obj_to_tag(qc, link_to_obj(qc, lp));
+
+		if (qc->qqc_cmp_fn(cmp, tp) == 0 &&
+		    !(lp->qqln_flags & QQCACHE_F_DEAD)) {
+			return (lp);
+		}
+	}
+
+	return (NULL);
+}
+
+/*
+ * Starting at listnum, push entries from the tail of cache list 'n' to the
+ * head of * list 'n + 1', keeping each list within their size limits.  Excess
+ * entries on the tail of the last list are deleted.  If 'for_insert' is
+ * B_TRUE, also guarantee after this returns that there are no more than
+ * 'max - 1' entries on listnum (so there is room to insert an entry onto
+ * listnum).
+ */
+static void
+qqcache_ripple(qqcache_t *qc, uint_t listnum, boolean_t for_insert)
+{
+	VERIFY3U(listnum, <, QQCACHE_NUM_LISTS);
+
+	for (uint_t i = listnum; i < QQCACHE_NUM_LISTS; i++) {
+		qqcache_list_t *ql = &qc->qqc_lists[i];
+		size_t max = qc->qqc_max[i];
+
+		ASSERT3U(max, >, 0);
+
+		/*
+		 * If we're planning to insert an entry on list 'listnum',
+		 * we bump the maximum size down by one to guarantee we
+		 * have sufficient room for the entry
+		 */
+		if (for_insert && i == listnum)
+			max--;
+
+		while (ql[0].qqcl_len > max) {
+			qqcache_link_t *lnk = list_tail(&ql[0].qqcl_list);
+
+			if (i + 1 < QQCACHE_NUM_LISTS) {
+				list_remove(&ql[0].qqcl_list, lnk);
+				ql[0].qqcl_len--;
+
+				ASSERT3U(lnk->qqln_listnum, ==, i);
+				lnk->qqln_listnum++;
+
+				list_insert_head(&ql[1].qqcl_list, lnk);
+				ql[1].qqcl_len++;
+			} else {
+				qqcache_remove(qc, link_to_obj(qc, lnk));
+			}
+		}
+	}
+}
+
+int
+qqcache_insert(qqcache_t *qc, void *obj)
+{
+	qqcache_link_t *lp = obj_to_link(qc, obj);
+	qqcache_list_t *bucket, *ql;
+
+	if (qqcache_hash_lookup(qc, obj_to_tag(qc, obj), &bucket) != NULL)
+		return (EEXIST);
+
+	list_link_init(&lp->qqln_hash_link);
+	list_link_init(&lp->qqln_list_link);
+	lp->qqln_refcnt = 0;
+	lp->qqln_flags = 0;
+	lp->qqln_listnum = QQCACHE_INSERT_LIST;
+
+	qqcache_ripple(qc, QQCACHE_INSERT_LIST, B_TRUE);
+
+	list_insert_tail(&bucket->qqcl_list, lp);
+	bucket->qqcl_len++;
+
+	list_insert_head(&qc->qqc_lists[QQCACHE_INSERT_LIST].qqcl_list, lp);
+	qc->qqc_lists[QQCACHE_INSERT_LIST].qqcl_len++;
+
+	return (0);
+}
+
+void *
+qqcache_lookup(qqcache_t *qc, const void *tp)
+{
+	qqcache_link_t *lp;
+	qqcache_list_t *src;
+	uint_t tgtnum;
+
+	if ((lp = qqcache_hash_lookup(qc, tp, NULL)) == NULL)
+		return (NULL);
+
+	src = QQCACHE_LIST(qc, lp);
+	list_remove(&src->qqcl_list, lp);
+	src->qqcl_len--;
+
+	tgtnum = (lp->qqln_listnum > 0) ? lp->qqln_listnum - 1 : 0;
+
+	if (tgtnum != lp->qqln_listnum)
+		qqcache_ripple(qc, tgtnum, B_TRUE);
+
+	lp->qqln_listnum = tgtnum;
+	list_insert_head(&qc->qqc_lists[tgtnum].qqcl_list, lp);
+	qc->qqc_lists[tgtnum].qqcl_len++;
+
+	return (link_to_obj(qc, lp));
+}
+
+int
+qqcache_adjust_size(qqcache_t *qc, size_t sz)
+{
+	if (sz < QQCACHE_MIN_SIZE)
+		return (EINVAL);
+
+	qc->qqc_size = sz;
+	qqcache_size_lists(sz, qc->qqc_a, qc->qqc_max);
+	qqcache_ripple(qc, 0, B_FALSE);
+	return (0);
+}
+
+int
+qqcache_adjust_a(qqcache_t *qc, size_t a)
+{
+	if (a > 100)
+		return (EINVAL);
+
+	qc->qqc_a = a;
+	qqcache_size_lists(qc->qqc_size, a, qc->qqc_max);
+	qqcache_ripple(qc, 0, B_FALSE);
+	return (0);
+}
+
+size_t
+qqcache_size(const qqcache_t *qc)
+{
+	return (qc->qqc_size);
+}
+
+size_t
+qqcache_a(const qqcache_t *qc)
+{
+	return (qc->qqc_a);
+}
+
+void *
+qqcache_first(qqcache_t *qc)
+{
+	for (size_t i = 0; i < QQCACHE_NUM_LISTS; i++) {
+		qqcache_list_t *l = &qc->qqc_lists[i];
+
+		if (l->qqcl_len > 0)
+			return (link_to_obj(qc, list_head(&l->qqcl_list)));
+	}
+
+	return (NULL);
+}
+
+void *
+qqcache_next(qqcache_t *qc, void *obj)
+{
+	qqcache_link_t *lp = obj_to_link(qc, obj);
+	qqcache_link_t *next;
+	qqcache_list_t *l = QQCACHE_LIST(qc, lp);
+
+	ASSERT3U(lp->qqln_listnum, <, QQCACHE_NUM_LISTS);
+
+	if ((next = list_next(&l->qqcl_list, lp)) != NULL)
+		return (link_to_obj(qc, next));
+
+	for (size_t i = lp->qqln_listnum + 1; i < QQCACHE_NUM_LISTS; i++) {
+		l = &qc->qqc_lists[i];
+		if (l->qqcl_len > 0)
+			return (link_to_obj(qc, list_head(&l->qqcl_list)));
+	}
+
+	return (NULL);
+}
diff --git a/usr/src/uts/common/sys/Makefile b/usr/src/uts/common/sys/Makefile
index 0fa800d39e..e30552b6e7 100644
--- a/usr/src/uts/common/sys/Makefile
+++ b/usr/src/uts/common/sys/Makefile
@@ -23,7 +23,7 @@
 # Copyright (c) 1989, 2010, Oracle and/or its affiliates. All rights reserved.
 # Copyright 2014, Joyent, Inc. All rights reserved.
 # Copyright 2013 Garrett D'Amore <garrett@damore.org>
-# Copyright 2015, Joyent, Inc. All rights reserved.
+# Copyright 2018, Joyent, Inc. All rights reserved.
 # Copyright 2013 Saso Kiselkov. All rights reserved.
 # Copyright 2015 Igor Kozhukhov <ikozhukhov@gmail.com>
 # Copyright 2016 Nexenta Systems, Inc.
@@ -489,6 +489,8 @@ CHKHDRS=			\
 	ptem.h			\
 	ptms.h			\
 	ptyvar.h		\
+	qqcache.h		\
+	qqcache_impl.h	\
 	raidioctl.h		\
 	ramdisk.h		\
 	random.h		\
diff --git a/usr/src/uts/common/sys/overlay_impl.h b/usr/src/uts/common/sys/overlay_impl.h
index d132f565d9..557ad6f98c 100644
--- a/usr/src/uts/common/sys/overlay_impl.h
+++ b/usr/src/uts/common/sys/overlay_impl.h
@@ -31,8 +31,7 @@
 #include <sys/socket.h>
 #include <sys/ethernet.h>
 #include <sys/list.h>
-
-#include "sarc.h"
+#include <sys/qqcache.h>
 
 #ifdef __cplusplus
 extern "C" {
@@ -82,8 +81,8 @@ typedef struct overlay_target {
 	union {					/* ott_lock */
 		overlay_target_point_t	ott_point;
 		struct overlay_target_dyn {
-			sarc_t		*ott_dhash;
-			sarc_t		*ott_l3dhash;
+			qqcache_t	*ott_dhash;
+			qqcache_t	*ott_l3dhash;
 			avl_tree_t	ott_tree;
 			avl_tree_t	ott_l3tree;
 		} ott_dyn;
@@ -158,7 +157,7 @@ typedef struct overlay_target_vl2 {
 
 struct overlay_target_entry {
 	kmutex_t		ote_lock;
-	sarc_link_t		ote_reflink;	/* hashtable link */
+	qqcache_link_t		ote_reflink;	/* hashtable link */
 	avl_node_t		ote_avllink;	/* iteration link */
 	list_node_t		ote_qlink;
 	overlay_target_entry_flags_t ote_flags;	/* RW: state flags */
diff --git a/usr/src/uts/common/sys/qqcache.h b/usr/src/uts/common/sys/qqcache.h
new file mode 100644
index 0000000000..a2244338dd
--- /dev/null
+++ b/usr/src/uts/common/sys/qqcache.h
@@ -0,0 +1,176 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright 2018, Joyent, Inc.
+ */
+
+#ifndef _QQCACHE_H
+#define	_QQCACHE_H
+
+#include <sys/list.h>
+#include <sys/types.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*
+ * This implements a fixed-size hash table that uses the 2Q algorithm
+ * from Johnson and Shasha to manage the contents of the entries.
+ *
+ * Briefly, there are two fixed sizes lists (0 and 1).  New entries are
+ * added to the head of list 1, and upon subsequent access (lookup), are
+ * moved to the head of list 0.  Entries that fall off the end of list 0
+ * are pushed onto the head of list 1, and entries that fall off the end
+ * of list 1 are deleted.  The percentage of the total size of the cache
+ * for each list is determined by the parameter 'a', which is a percentage
+ * (0-100) of the cache size that is dedicated to list 0.
+ *
+ * This implementation does generalize this algorithm somewhat to an
+ * arbitrary number of lists (instead of just 2) via the QQCACHE_NUM_LISTS
+ * and QQCACHE_INSERT_LIST preprocessor symbols (defined in
+ * sys/qqcache_impl.h).  New entries are added to list QQCACHE_INSERT_LIST
+ * and as each list gets full, the oldest entry in each list is pushed to
+ * the head of the succeeding list, and the oldest entries are removed
+ * from the cache (so each list never has more entries than their maximum
+ * size).
+ *
+ * The API itself is very similar to that of refhash.  A qqcache_link_t struct
+ * is embedded within the definition of the entries that are being stored in
+ * a given qqcache_t.  Functions are provided to hash/compare the tag (key)
+ * value of an entry, as well as destroying the entry during the creation
+ * of the cache.  Lookups then occur by passing a pointer to the key value
+ * being looked up.
+ *
+ * NOTE: As one can take references to entries in the cache via the
+ * qqcache_hold() function, refheld entries that are marked for deletion are
+ * not counted when tracking the cache size, and their dtor function is not
+ * called until the last reference has been released (by calling the
+ * qqcache_rele() function).
+ */
+
+typedef enum qqcache_flag {
+	QQCACHE_F_DEAD	= 0x01,
+} qqcache_flag_t;
+
+typedef struct qqcache_link {
+	list_node_t	qqln_hash_link;	/* Hash chain bucket */
+	list_node_t	qqln_list_link; /* Cache list link */
+	uint_t		qqln_listnum;
+	uint_t		qqln_refcnt;
+	qqcache_flag_t	qqln_flags;
+} qqcache_link_t;
+
+struct qqcache;
+typedef struct qqcache qqcache_t;
+
+typedef uint64_t (*qqcache_hash_fn_t)(const void *);
+typedef int (*qqcache_cmp_fn_t)(const void *, const void *);
+typedef void (*qqcache_dtor_fn_t)(void *);
+
+/*
+ * qqcache_create(qcp, sz, a, buckets, hash_fn, cmp_fn, dtor_fn,
+ *    elsize, link_off, tag_off, flags);
+ *
+ * Creates a new 2Q cache:
+ *
+ *	qqcache_t **qcp	A pointer to the pointer that will hold the new
+ *			cache.
+ *
+ *	size_t sz	The size of the cache (in entries).
+ *
+ *	size_t a	The percentage (0-100) of the cache dedicated to
+ *			MRU entries (list 0);
+ *
+ *	size_t buckets	The number of hash buckets in the cache.
+ *
+ *	qqcache_hash_fn_t hash_fn	The function used to create a
+ *					hash value for a given entry's tag
+ *					value.
+ *
+ *	qqcache_cmp_fn_t cmp_fn		The function used to compare the two
+ *					tag values of two entries.  The function
+ *					should return '0' if the two entries
+ *					are equal, '1' if they are not equal.
+ *
+ *	qqcache_dtor_fn_t dtor_fn	The function used to destroy/free
+ *					entries.
+ *
+ *	size_t elsize	The size of each entry.
+ *
+ *	size_t link_off	The offset of the qqcache_link_t struct in the entry.
+ *
+ *	size_t tag_off	The offset in the entry of the tag value (used for
+ *			hashing and comparison).
+ *
+ *	int flags	The flags passed to kmem_zalloc/umem_zalloc.
+ *
+ * Returns:
+ *	0	Success
+ *	EINVAL	A parameter was not valid
+ *	ENOMEM	The memory allocation failed (only possible when
+ *		KM_NOSLEEP/UMEM_DEFAULT is passed to flags).
+ */
+extern int qqcache_create(qqcache_t **, size_t, size_t, size_t,
+    qqcache_hash_fn_t, qqcache_cmp_fn_t, qqcache_dtor_fn_t,
+    size_t, size_t, size_t, int);
+
+/* Destroy the given qqcache_t */
+extern void qqcache_destroy(qqcache_t *);
+
+/*
+ * qqcache_insert(qc, obj)
+ *
+ * qqcache_t *qc	The cache to insert the item into.
+ *
+ * void *obj		The object to add.
+ *
+ * Returns:
+ *	0	Success
+ *	EEXIST	The same entry (as determined by the cache cmp function) already
+ *		exists in the cache.
+ */
+extern int qqcache_insert(qqcache_t *, void *);
+
+/* Lookup an entry with the given tag/key, or return NULL if not found */
+extern void *qqcache_lookup(qqcache_t *, const void *);
+
+/* Remove the given entry from the cache */
+extern void qqcache_remove(qqcache_t *, void *);
+
+/* Add a hold on the entry in the cache */
+extern void qqcache_hold(qqcache_t *, void *);
+
+/* Release the hold on the entry in the cache */
+extern void qqcache_rele(qqcache_t *, void *);
+
+/*
+ * Adjust the size and percentage of the cache for list 0.  If new values are
+ * smaller than current values, entries may be evicted as necessary to reduce
+ * the size of the cache to the given size.
+ */
+extern int qqcache_adjust_size(qqcache_t *, size_t);
+extern int qqcache_adjust_a(qqcache_t *, size_t);
+
+/* Return the current values of size or a. */
+extern size_t qqcache_size(const qqcache_t *);
+extern size_t qqcache_a(const qqcache_t *);
+
+/* Iterate through entries. */
+extern void *qqcache_first(qqcache_t *);
+extern void *qqcache_next(qqcache_t *, void *);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _QQCACHE_H */
diff --git a/usr/src/uts/common/sys/qqcache_impl.h b/usr/src/uts/common/sys/qqcache_impl.h
new file mode 100644
index 0000000000..f709b74d6c
--- /dev/null
+++ b/usr/src/uts/common/sys/qqcache_impl.h
@@ -0,0 +1,72 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright 2018, Joyent, Inc.
+ */
+
+#ifndef _QQCACHE_IMPL_H
+#define	_QQCACHE_IMPL_H
+
+#include <sys/debug.h>
+#include <sys/qqcache.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define	QQCACHE_NUM_LISTS 2
+#define	QQCACHE_INSERT_LIST 1
+#define	QQCACHE_MIN_SIZE 10
+
+CTASSERT(QQCACHE_INSERT_LIST < QQCACHE_NUM_LISTS);
+CTASSERT(QQCACHE_NUM_LISTS >= 2);
+
+typedef struct qqcache_list {
+	list_t	qqcl_list;
+	size_t	qqcl_len;
+} qqcache_list_t;
+
+struct qqcache {
+	qqcache_hash_fn_t qqc_hash_fn;
+	qqcache_cmp_fn_t qqc_cmp_fn;
+	qqcache_dtor_fn_t qqc_dtor_fn;
+	size_t		qqc_link_off;
+	size_t		qqc_tag_off;
+	size_t		qqc_nbuckets;
+	size_t		qqc_size;
+	size_t		qqc_a;
+	size_t		qqc_max[QQCACHE_NUM_LISTS];
+	qqcache_list_t	qqc_lists[QQCACHE_NUM_LISTS];
+	qqcache_list_t	qqc_buckets[];
+};
+
+#define	QQCACHE_LIST(qqc, lnk) \
+	(&(qqc)->qqc_lists[(lnk)->qqln_listnum])
+
+#ifdef lint
+extern qqcache_link_t *obj_to_link(qqcache_t *, void *);
+extern void *link_to_obj(qqcache_t *, qqcache_link_t *);
+extern void *obj_to_tag(qqcache_t *, void *);
+#else
+#define	obj_to_link(_q, _o) \
+	((qqcache_link_t *)(((char *)(_o)) + (_q)->qqc_link_off))
+#define	link_to_obj(_q, _l) \
+	((void *)(((char *)(_l)) - (_q)->qqc_link_off))
+#define	obj_to_tag(_q, _o) \
+	((void *)(((char *)(_o)) + (_q)->qqc_tag_off))
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _QQCACHE_IMPL_H */
diff --git a/usr/src/uts/common/sys/sarc.h b/usr/src/uts/common/sys/sarc.h
deleted file mode 100644
index 986bd6a80d..0000000000
--- a/usr/src/uts/common/sys/sarc.h
+++ /dev/null
@@ -1,179 +0,0 @@
-/*
- * This file and its contents are supplied under the terms of the
- * Common Development and Distribution License ("CDDL"), version 1.0.
- * You may only use this file in accordance with the terms of version
- * 1.0 of the CDDL.
- *
- * A full copy of the text of the CDDL should have accompanied this
- * source.  A copy of the CDDL is also available via the Internet at
- * http://www.illumos.org/license/CDDL.
- */
-
-/*
- * Copyright 2018, Joyent, Inc.
- */
-
-#ifndef _SARC_H
-#define	_SARC_H
-
-/*
- * SARC - A simplified implementation of the ARC algorithm for caches.
- *
- * This implements a cache that uses the adaptive replacement cache algorithm
- * to manage the contents of the cache.  Like the original description of the
- * ARC algorithm, it assumes each entry is fixed size.  Unlike the original
- * description of the cache, it allows references to be held to entries,
- * possibly beyond the lifetime of the entry in the cache.  Evicted entries
- * that are still refheld at the time of eviction from the cache do not get
- * counted towards it's size.  While the ZFS ARC merely looks for the next
- * suitable entry when evicting refheld entries, it has mechanisms to also
- * slow down the rate at which new data is added to the ZFS ARC.  Adding
- * such mechanisms to this implementation would add additional complexity
- * for any consumers.  Instead, it is dependent upon the user to only
- * keep refheld entries for short periods of time to prevent the cache
- * size from growing excessively large.  This implementation also does not
- * currently implement any locking, so users must serialize access to any
- * use of a given sarc_t with a mutex -- even lookup routines can cause
- * movement of entries amongst the various lists that are maintined, so
- * something such as rwlock would not work correctly.
- */
-
-#include <sys/list.h>
-#include <sys/types.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-typedef enum sarc_flag {
-	SARC_MRU =	0x00,
-	SARC_MFU =	0x01,
-	SARC_GMRU =	0x02,
-	SARC_GMFU =	0x03,
-
-	SARC_F_DEAD =	0x04,
-} sarc_flag_t;
-
-typedef struct sarc_link {
-	list_node_t	sal_hash_link;	/* Hash chain bucket */
-	list_node_t	sal_list_link;	/* MRU, MFU, etc. list link */
-	uint_t		sal_refcnt;
-	sarc_flag_t	sal_flags;
-} sarc_link_t;
-
-struct sarc;
-typedef struct sarc sarc_t;
-
-typedef struct sarc_ops {
-	uint64_t	(*sao_hash)(const void *);
-	int		(*sao_cmp)(const void *, const void *);
-	void		(*sao_dtor)(void *);
-	boolean_t	(*sao_fetch)(void *);
-	void		(*sao_evict)(void *);
-} sarc_ops_t;
-
-/*
- * The ARC algorithm maintains a cache of at most c items (divided into a
- * MRU and MFU lists). The proportion of MRU:MFU entries can vary over time
- * based on access patterns.  ARC utilizes a ghost cache (also of c items
- * split between MRU and MFU) to detect changes in access patterns and
- * adjust the split between MRU and MFU items.
- *
- * The expectation is that an entry being cached can itself be divided into
- * some small identifying portion (that includes at least the hash tag) and
- * the data being cached.   When a cache item moves to a ghost list, the
- * evict operation is called on the entry to indicate the data portion can be
- * freed while retaining the identifying portion of the entry.  When an entry
- * on the ghost list moves back into the cache, the fetch op is called on the
- * entry to reload the data that was released by the earlier evict operation.
- *
- * If the amount of data in an entry is small relative to the identifying
- * information, there may not be much benefit in releasing any memory during
- * an evict call.  Two conveinence functions (sarc_noevict() and sarc_nofetch())
- * are provided for such instances.  These functions are effectively no-ops.
- * When used, the ghost lists become more corporal and act effectively as a
- * second level cache (also c sized), but does not otherwise effect the
- * operation of the ARC algorithm.  It should be noted in such an instance the
- * actual size of the cache will be 2c instead of c.
- */
-extern void sarc_noevict(void *);
-extern boolean_t sarc_nofetch(void *);
-
-/*
- * int sarc_create(sarcp, c, hsize, ops, objsize, link_off, tag_off, km_flags)
- *
- * sarcp	Contains newly allocated sarc_t instance
- * c		Number of items the cache can hold
- * ops		The functions that operate on entry for hashing, comparison, etc
- * objsize	The size of each entry
- * link_off	The offset of sarc_link_t within each entry
- * tag_off	The offset of the tag field within each entry
- * km_flags	The flags used when allocating the new sarc_t instance
- *
- * On success, sarc_create returns 0.  On failure, sarc_create can return:
- * EINVAL	A parameter was not valid
- * ENOMEM	No memory was available
- */
-extern int sarc_create(sarc_t **, size_t, size_t, const sarc_ops_t *, size_t,
-    size_t, size_t, int);
-
-/* Destroys a sarc_t instance */
-extern void sarc_destroy(sarc_t *);
-
-/*
- * Add an entry into the given cache.
- *
- * Returns:
- *	0	Success
- *	EINVAL	sarc_flag_t contained an invalid value
- *	EEXIST	Entry already exists
- */
-extern int sarc_insert(sarc_t *, void *);
-
-/*
- * Lookup an entry in the cache with the given tag.  If found, the refheld
- * object is returned. sarc_rele() should be called to release the reference.
- * If not found, NULL is retured.
- */
-extern void *sarc_lookup(sarc_t *, const void *);
-
-/*
- * Remove an entry from the cache.  If the reference count is > 0, the dtor
- * function call is deferred until the reference count is 0.  Once
- * sarc_remove() is called on an entry, it is no longer returned in any
- * lookup request, irrespective of its reference count.  Such an entry is also
- * then ignored in any cache sizing calculations (such as when entries are
- * moved between MRU, MFU, etc lists or when an entry is removed to make room
- * for newer entries).
- */
-extern void sarc_remove(sarc_t *, void *);
-
-/*
- * Increment the reference count of an entry in the cache.  As lookups always
- * return a refheld entry (when an entry is found), this is only needed to
- * add additional holds on an entry are needed.
- */
-extern void sarc_hold(sarc_t *, void *);
-
-/*
- * Decrement the reference count of an entry in the cache.  This should be
- * called for anything returned by sarc_lookup() to release the hold added
- * by the lookup function.
- */
-extern void sarc_rele(sarc_t *, void *);
-
-extern void *sarc_first(sarc_t *);
-extern void *sarc_next(sarc_t *, void *);
-
-/*
- * Adjust the size of the cache.   May result in large amounts of entries
- * being evicted at once.  May return EINVAL if the new size is below
- * SARC_MIN_C (10).
- */
-extern int sarc_adjust_c(sarc_t *, size_t);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* _SARC_H */
