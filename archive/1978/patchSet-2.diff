From 01127c295070b8e3a07c33f49f38a8bf340685dc Mon Sep 17 00:00:00 2001
From: Jerry Jelinek <jerry.jelinek@joyent.com>
Date: Fri, 19 May 2017 20:42:02 +0000
Subject: [PATCH] OS-6065 add support for xsaveopt or xsavec for improved
 context switching

---
 usr/src/uts/i86pc/os/fpu_subr.c   | 14 +++++-
 usr/src/uts/i86pc/sys/asm_misc.h  | 20 +--------
 usr/src/uts/intel/ia32/ml/float.s | 73 +++++++++++++++++++++++++++----
 usr/src/uts/intel/ia32/os/fpu.c   |  2 +-
 usr/src/uts/intel/sys/fp.h        | 52 ++++++++++++++++------
 5 files changed, 116 insertions(+), 45 deletions(-)

diff --git a/usr/src/uts/i86pc/os/fpu_subr.c b/usr/src/uts/i86pc/os/fpu_subr.c
index e65c65de92..f82a61f822 100644
--- a/usr/src/uts/i86pc/os/fpu_subr.c
+++ b/usr/src/uts/i86pc/os/fpu_subr.c
@@ -174,7 +174,12 @@ fpu_probe(void)
 
 			if (is_x86_feature(x86_featureset, X86FSET_XSAVE)) {
 				fp_save_mech = FP_XSAVE;
-				fpsave_ctxt = xsave_ctxt;
+				if (is_x86_feature(x86_featureset,
+				    X86FSET_XSAVEOPT)) {
+					fpsave_ctxt = xsaveopt_ctxt;
+				} else {
+					fpsave_ctxt = xsave_ctxt;
+				}
 				patch_xsave();
 				fpsave_cachep = kmem_cache_create("xsave_cache",
 				    cpuid_get_xsave_size(), XSAVE_ALIGN,
@@ -210,7 +215,12 @@ fpu_probe(void)
 
 			if (is_x86_feature(x86_featureset, X86FSET_XSAVE)) {
 				fp_save_mech = FP_XSAVE;
-				fpsave_ctxt = xsave_ctxt;
+				if (is_x86_feature(x86_featureset,
+				    X86FSET_XSAVEOPT)) {
+					fpsave_ctxt = xsaveopt_ctxt;
+				} else {
+					fpsave_ctxt = xsave_ctxt;
+				}
 				patch_xsave();
 				fpsave_cachep = kmem_cache_create("xsave_cache",
 				    cpuid_get_xsave_size(), XSAVE_ALIGN,
diff --git a/usr/src/uts/i86pc/sys/asm_misc.h b/usr/src/uts/i86pc/sys/asm_misc.h
index 57ac6ed0b1..b129ca10af 100644
--- a/usr/src/uts/i86pc/sys/asm_misc.h
+++ b/usr/src/uts/i86pc/sys/asm_misc.h
@@ -21,13 +21,12 @@
 /*
  * Copyright 2008 Sun Microsystems, Inc.  All rights reserved.
  * Use is subject to license terms.
+ * Copyright 2017 Joyent, Inc.
  */
 
 #ifndef _SYS_ASM_MISC_H
 #define	_SYS_ASM_MISC_H
 
-#pragma ident	"%Z%%M%	%I%	%E% SMI"
-
 #ifdef	__cplusplus
 extern "C" {
 #endif
@@ -84,23 +83,6 @@ extern "C" {
 
 #endif	/* __i386 */
 
-#if defined(__amd64)
-
-/*
- * While as doesn't support fxsaveq/fxrstorq (fxsave/fxrstor with REX.W = 1)
- * we will use the FXSAVEQ/FXRSTORQ macro
- */
-
-#define	FXSAVEQ(x)	\
-	.byte	0x48;	\
-	fxsave	x
-
-#define	FXRSTORQ(x)	\
-	.byte	0x48;	\
-	fxrstor	x
-
-#endif	/* __amd64 */
-
 #endif /* _ASM */
 
 #ifdef	__cplusplus
diff --git a/usr/src/uts/intel/ia32/ml/float.s b/usr/src/uts/intel/ia32/ml/float.s
index cfc134b219..96968bc3b4 100644
--- a/usr/src/uts/intel/ia32/ml/float.s
+++ b/usr/src/uts/intel/ia32/ml/float.s
@@ -82,7 +82,7 @@ fxsave_insn(struct fxsave_state *fx)
 #if defined(__amd64)
 
 	ENTRY_NP(fxsave_insn)
-	FXSAVEQ	((%rdi))
+	fxsaveq (%rdi)
 	ret
 	SET_SIZE(fxsave_insn)
 
@@ -232,7 +232,7 @@ patch_xsave(void)
 	pushq	%rbp
 	pushq	%r15
 	/
-	/	FXRSTORQ (%rbx);	-> nop; xrstor (%rbx)
+	/	fxrstorq (%rbx);	-> nop; xrstor (%rbx)
 	/ loop doing the following for 4 bytes:
 	/     hot_patch_kernel_text(_patch_xrstorq_rbx, _xrstor_rbx_insn, 1)
 	/
@@ -255,7 +255,7 @@ patch_xsave(void)
 	ret
 
 _xrstor_rbx_insn:			/ see ndptrap_frstor()
-	# Because the FXRSTORQ macro we're patching is 4 bytes long, due
+	# Because the fxrstorq instruction we're patching is 4 bytes long, due
 	# to the 0x48 prefix (indicating 64-bit operand size), we patch 4 bytes
 	# too.
 	nop
@@ -277,6 +277,10 @@ void
 xsave_ctxt(void *arg)
 {}
 
+void
+xsaveopt_ctxt(void *arg)
+{}
+
 /*ARGSUSED*/
 void
 fpxsave_ctxt(void *arg)
@@ -297,7 +301,7 @@ fpnsave_ctxt(void *arg)
 
 	movl	$_CONST(FPU_VALID|FPU_EN), FPU_CTX_FPU_FLAGS(%rdi)
 	movq	FPU_CTX_FPU_REGS(%rdi), %rdi /* fpu_regs.kfpu_u.kfpu_fn ptr */
-	FXSAVEQ	((%rdi))
+	fxsaveq	(%rdi)
 
 	/*
 	 * On certain AMD processors, the "exception pointers" i.e. the last
@@ -335,7 +339,7 @@ fpnsave_ctxt(void *arg)
 
 	/*
 	 * (see notes above about "exception pointers")
-	 * TODO: does it apply to any machine that uses xsave?
+	 * TODO: rewrite this to explicitly handle AMD Error Zero feature.
 	 */
 	btw	$7, FXSAVE_STATE_FSW(%rdi)	/* Test saved ES bit */
 	jnc	0f				/* jump if ES = 0 */
@@ -347,6 +351,32 @@ fpnsave_ctxt(void *arg)
 1:	ret
 	SET_SIZE(xsave_ctxt)
 
+	ENTRY_NP(xsaveopt_ctxt)
+	cmpl	$FPU_EN, FPU_CTX_FPU_FLAGS(%rdi)
+	jne	1f
+	movl	$_CONST(FPU_VALID|FPU_EN), FPU_CTX_FPU_FLAGS(%rdi)
+	/*
+	 * Setup xsaveopt flags in EDX:EAX
+	 */
+	movl	FPU_CTX_FPU_XSAVE_MASK(%rdi), %eax
+	movl	FPU_CTX_FPU_XSAVE_MASK+4(%rdi), %edx
+	movq	FPU_CTX_FPU_REGS(%rdi), %rsi /* fpu_regs.kfpu_u.kfpu_xs ptr */
+	xsaveopt (%rsi)
+
+	/*
+	 * (see notes above about "exception pointers")
+	 * TODO: rewrite this to explicitly handle AMD Error Zero feature.
+	 */
+	btw	$7, FXSAVE_STATE_FSW(%rdi)	/* Test saved ES bit */
+	jnc	0f				/* jump if ES = 0 */
+	fnclex		/* clear pending x87 exceptions */
+0:	ffree	%st(7)	/* clear tag bit to remove possible stack overflow */
+	fildl	.fpzero_const(%rip)
+			/* dummy load changes all exception pointers */
+	STTS(%rsi)	/* trap on next fpu touch */
+1:	ret
+	SET_SIZE(xsaveopt_ctxt)
+
 #elif defined(__i386)
 
 	ENTRY_NP(fpnsave_ctxt)
@@ -396,7 +426,7 @@ fpnsave_ctxt(void *arg)
 
 	/*
 	 * (see notes above about "exception pointers")
-	 * TODO: does it apply to any machine that uses xsave?
+	 * TODO: rewrite this to explicitly handle AMD Error Zero feature.
 	 */
 	btw	$7, FXSAVE_STATE_FSW(%ecx)	/* Test saved ES bit */
 	jnc	0f				/* jump if ES = 0 */
@@ -408,6 +438,31 @@ fpnsave_ctxt(void *arg)
 1:	ret
 	SET_SIZE(xsave_ctxt)
 
+	ENTRY_NP(xsaveopt_ctxt)
+	movl	4(%esp), %ecx		/* a struct fpu_ctx */
+	cmpl	$FPU_EN, FPU_CTX_FPU_FLAGS(%ecx)
+	jne	1f
+
+	movl	$_CONST(FPU_VALID|FPU_EN), FPU_CTX_FPU_FLAGS(%ecx)
+	movl	FPU_CTX_FPU_XSAVE_MASK(%ecx), %eax
+	movl	FPU_CTX_FPU_XSAVE_MASK+4(%ecx), %edx
+	movl	FPU_CTX_FPU_REGS(%ecx), %ecx /* fpu_regs.kfpu_u.kfpu_xs ptr */
+	xsaveopt (%ecx)
+
+	/*
+	 * (see notes above about "exception pointers")
+	 * TODO: rewrite this to explicitly handle AMD Error Zero feature.
+	 */
+	btw	$7, FXSAVE_STATE_FSW(%ecx)	/* Test saved ES bit */
+	jnc	0f				/* jump if ES = 0 */
+	fnclex		/* clear pending x87 exceptions */
+0:	ffree	%st(7)	/* clear tag bit to remove possible stack overflow */
+	fildl	.fpzero_const
+			/* dummy load changes all exception pointers */
+	STTS(%edx)	/* trap on next fpu touch */
+1:	ret
+	SET_SIZE(xsaveopt_ctxt)
+
 #endif	/* __i386 */
 
 	.align	8
@@ -441,7 +496,7 @@ xsave(struct xsave_state *f, uint64_t m)
 
 	ENTRY_NP(fpxsave)
 	CLTS
-	FXSAVEQ	((%rdi))
+	fxsaveq (%rdi)
 	fninit				/* clear exceptions, init x87 tags */
 	STTS(%rdi)			/* set TS bit in %cr0 (disable FPU) */
 	ret
@@ -516,7 +571,7 @@ xrestore(struct xsave_state *f, uint64_t m)
 
 	ENTRY_NP(fpxrestore)
 	CLTS
-	FXRSTORQ	((%rdi))
+	fxrstorq	(%rdi)
 	ret
 	SET_SIZE(fpxrestore)
 
@@ -607,7 +662,7 @@ fpinit(void)
 
 	/* fxsave */
 	leaq	sse_initial(%rip), %rax
-	FXRSTORQ	((%rax))		/* load clean initial state */
+	fxrstorq	(%rax)			/* load clean initial state */
 	ret
 
 1:	/* xsave */
diff --git a/usr/src/uts/intel/ia32/os/fpu.c b/usr/src/uts/intel/ia32/os/fpu.c
index 33cd6b2e87..140fdfae19 100644
--- a/usr/src/uts/intel/ia32/os/fpu.c
+++ b/usr/src/uts/intel/ia32/os/fpu.c
@@ -127,7 +127,7 @@ const struct xsave_state avx_initial = {
 	 * and CPU should initialize XMM/YMM.
 	 */
 	1,
-	{0, 0}	/* These 2 bytes must be zero */
+	0	/* xs_xcomp_bv */
 	/* rest of structure is zero */
 };
 
diff --git a/usr/src/uts/intel/sys/fp.h b/usr/src/uts/intel/sys/fp.h
index 9e1c3a486e..0ed22c1780 100644
--- a/usr/src/uts/intel/sys/fp.h
+++ b/usr/src/uts/intel/sys/fp.h
@@ -230,23 +230,46 @@ struct fxsave_state {
 };	/* 512 bytes */
 
 /*
- * This structure is written to memory by an 'xsave' instruction.
- * First 512 byte is compatible with the format of an 'fxsave' area.
+ * This structure is written to memory by one of the 'xsave' instruction
+ * variants. The first 512 bytes are compatible with the format of the 'fxsave'
+ * area. The header portion of the xsave layout is documented in section
+ * 13.4.2 of the Intel 64 and IA-32 Architectures Software Developerâ€™s Manual,
+ * Volume 1 (IASDv1). The extended portion is documented in section 13.4.3.
  *
- * The size is at least AVX_XSAVE_SIZE (832 bytes), asserted in fpnoextflt().
- * Enabling additional xsave-related CPU features increases the size.
- * We dynamically allocate the per-lwp xsave area at runtime, based on the
- * size needed for the CPU-specific features. The xsave_state structure simply
- * defines the legacy layout of the beginning of the xsave area. The locations
- * and size of new, extended components are determined dynamically by querying
- * the CPU. See the xsave_info structure in cpuid.c.
+ * Our size is at least AVX_XSAVE_SIZE (832 bytes), asserted in fpnoextflt().
+ * Enabling additional xsave-related CPU features requires an increase in the
+ * size. We dynamically allocate the per-lwp xsave area at runtime, based on
+ * the size needed for the CPU-specific features. This xsave_state structure
+ * simply defines our historical layout for the beginning of the xsave area. The
+ * locations and size of new, extended, components is determined dynamically by
+ * querying the CPU. See the xsave_info structure in cpuid.c.
+ *
+ * xsave component usage is tracked using bits in the xs_xstate_bv field. The
+ * components are documented in section 13.1 of IASDv1. For easy reference,
+ * this is a summary of the currently defined component bit definitions:
+ *	x87			0x0001
+ *	SSE			0x0002
+ *	AVX			0x0004
+ *	bndreg (MPX)		0x0008
+ *	bndcsr (MPX)		0x0010
+ *	opmask (AVX512)		0x0020
+ *	zmm hi256 (AVX512)	0x0040
+ *	zmm hi16 (AVX512)	0x0080
+ *	PT			0x0100
+ *	PKRU			0x0200
+ * When xsaveopt_ctxt is being used to save into the xsave_state area, the
+ * xs_xstate_bv field is updated by the xsaveopt instruction to indicate which
+ * elements of the xsave area are active.
+ *
+ * xs_xcomp_bv should always be 0, since we do not currently use the compressed
+ * form of xsave (xsavec).
  */
 struct xsave_state {
-	struct fxsave_state	xs_fxsave;
-	uint64_t		xs_xstate_bv;	/* 512 */
-	uint64_t		xs_rsv_mbz[2];
-	uint64_t		xs_reserved[5];
-	upad128_t		xs_ymm[16];	/* avx - 576 */
+	struct fxsave_state	xs_fxsave;	/* 0-511 legacy region */
+	uint64_t		xs_xstate_bv;	/* 512-519 start xsave header */
+	uint64_t		xs_xcomp_bv;	/* 520-527 */
+	uint64_t		xs_reserved[6];	/* 528-575 end xsave header */
+	upad128_t		xs_ymm[16];	/* 576 AVX component */
 };
 
 /*
@@ -283,6 +306,7 @@ extern int fpu_probe_pentium_fdivbug(void);
 extern void fpnsave_ctxt(void *);
 extern void fpxsave_ctxt(void *);
 extern void xsave_ctxt(void *);
+extern void xsaveopt_ctxt(void *);
 extern void (*fpsave_ctxt)(void *);
 
 extern void fxsave_insn(struct fxsave_state *);
-- 
2.21.0

