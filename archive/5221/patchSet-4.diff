From 97eade0e564875605db4d33feb142ee75f003252 Mon Sep 17 00:00:00 2001
From: Tim Foster <tim.foster@joyent.com>
Date: Tue, 11 Dec 2018 11:12:33 +0000
Subject: [PATCH] TOOLS-2043 Lullaby 3: Improving the Manta/Triton build
 TOOLS-2062 eng.git should be a git submodule of Triton/Manta repositories
 TOOLS-2063 shared tooling needed to build Manta/Triton agents TOOLS-2064 the
 build should do more pre-build validation TOOLS-2065 Makefile.targ should
 include a print-% target TOOLS-2066 Triton/Manta components should be able to
 build local zfs images TOOLS-2067 Triton/Manta components need a way to
 upload build artifacts

---
 .gitignore                                    |    4 +-
 Makefile                                      |   89 +-
 tools/agent-prebuilt.sh                       |  450 ++
 tools/bits-upload.sh                          |  435 ++
 tools/buildimage-extract-pkg.sh               |   35 +
 tools/buildimage/Makefile                     |   54 +
 tools/buildimage/README.md                    |  122 +
 tools/buildimage/bin/buildimage               |  692 +++
 tools/buildimage/lib/imgadm/README.md         |   28 +
 tools/buildimage/lib/imgadm/imgadm.patch      |  305 ++
 tools/buildimage/lib/imgadm/lib/IMG.js        |   81 +
 tools/buildimage/lib/imgadm/lib/cli.js        | 2148 ++++++++
 tools/buildimage/lib/imgadm/lib/common.js     |  846 ++++
 .../lib/imgadm/lib/configuration.js           |  138 +
 tools/buildimage/lib/imgadm/lib/database.js   |  171 +
 tools/buildimage/lib/imgadm/lib/errors.js     |  827 ++++
 tools/buildimage/lib/imgadm/lib/imgadm.js     | 4329 +++++++++++++++++
 tools/buildimage/lib/imgadm/lib/locker.js     |  177 +
 tools/buildimage/lib/imgadm/lib/magic.js      |  102 +
 .../lib/imgadm/lib/sources/docker.js          |  386 ++
 .../lib/imgadm/lib/sources/dsapi.js           |   92 +
 .../lib/imgadm/lib/sources/imgapi.js          |  264 +
 .../lib/imgadm/lib/sources/index.js           |   82 +
 .../lib/imgadm/lib/sources/source.js          |  205 +
 tools/buildimage/lib/imgadm/lib/upgrade.js    |  342 ++
 tools/buildimage/lib/imgadm/lib/zfs.js        |  549 +++
 tools/buildimage/lib/imgadm/package-lock.json | 3607 ++++++++++++++
 tools/buildimage/lib/imgadm/package.json      |   36 +
 tools/buildimage/lib/imgadm/sbin/imgadm       |   42 +
 tools/buildimage/package-lock.json            |   54 +
 tools/buildimage/package.json                 |   14 +
 tools/mk/Makefile.agent_prebuilt.defs         |  203 +
 tools/mk/Makefile.agent_prebuilt.targ         |  120 +
 tools/mk/Makefile.ctf.defs                    |   17 +-
 tools/mk/Makefile.ctf.targ                    |   19 +-
 tools/mk/Makefile.defs                        |  101 +-
 tools/mk/Makefile.deps                        |   22 +-
 tools/mk/Makefile.go_prebuilt.defs            |   18 +-
 tools/mk/Makefile.go_prebuilt.targ            |   18 +-
 tools/mk/Makefile.manpages.defs               |   20 +-
 tools/mk/Makefile.manpages.targ               |   20 +-
 tools/mk/Makefile.node.defs                   |   20 +-
 tools/mk/Makefile.node.targ                   |   20 +-
 tools/mk/Makefile.node_modules.defs           |   20 +-
 tools/mk/Makefile.node_modules.targ           |   22 +-
 tools/mk/Makefile.node_prebuilt.defs          |   20 +-
 tools/mk/Makefile.node_prebuilt.targ          |   20 +-
 tools/mk/Makefile.smf.defs                    |   22 +-
 tools/mk/Makefile.smf.targ                    |   21 +-
 tools/mk/Makefile.targ                        |  176 +-
 tools/mkrepo                                  |    6 +-
 tools/validate-buildenv.sh                    |  650 +++
 52 files changed, 18144 insertions(+), 117 deletions(-)
 create mode 100755 tools/agent-prebuilt.sh
 create mode 100755 tools/bits-upload.sh
 create mode 100755 tools/buildimage-extract-pkg.sh
 create mode 100644 tools/buildimage/Makefile
 create mode 100644 tools/buildimage/README.md
 create mode 100755 tools/buildimage/bin/buildimage
 create mode 100644 tools/buildimage/lib/imgadm/README.md
 create mode 100644 tools/buildimage/lib/imgadm/imgadm.patch
 create mode 100644 tools/buildimage/lib/imgadm/lib/IMG.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/cli.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/common.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/configuration.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/database.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/errors.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/imgadm.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/locker.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/magic.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/sources/docker.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/sources/dsapi.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/sources/imgapi.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/sources/index.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/sources/source.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/upgrade.js
 create mode 100644 tools/buildimage/lib/imgadm/lib/zfs.js
 create mode 100644 tools/buildimage/lib/imgadm/package-lock.json
 create mode 100644 tools/buildimage/lib/imgadm/package.json
 create mode 100755 tools/buildimage/lib/imgadm/sbin/imgadm
 create mode 100644 tools/buildimage/package-lock.json
 create mode 100644 tools/buildimage/package.json
 create mode 100644 tools/mk/Makefile.agent_prebuilt.defs
 create mode 100644 tools/mk/Makefile.agent_prebuilt.targ
 create mode 100755 tools/validate-buildenv.sh

diff --git a/.gitignore b/.gitignore
index 6489fdb..f95486e 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,6 +1,8 @@
-/node_modules
+**/node_modules
+/make_stamps
 /tmp
 /cache/
+bits
 build
 /make_stamps
 docs/*.json
diff --git a/Makefile b/Makefile
index 0c1d07e..d9aa86f 100644
--- a/Makefile
+++ b/Makefile
@@ -70,15 +70,32 @@
 # that Makefile here.
 #
 
+#
+# If a project produces a SmartOS image for use in Triton or Manta, the name of
+# the image should be specified here. Additional metadata for the image can be
+# set using BUILDIMAGE_* macros.
+#
+NAME = myproject
+
 #
 # Tools
 #
 TAPE :=			./node_modules/.bin/tape
 
+#
+# If we need to use buildimage, make sure we declare that before including
+# Makefile.defs since that conditionally sets macros based on
+# ENGBLD_USE_BUILDIMAGE.
+#
+ENGBLD_USE_BUILDIMAGE   = true
+
 #
 # Makefile.defs defines variables used as part of the build process.
+# Ensure we have the eng submodule before attempting to include it.
 #
-include ./tools/mk/Makefile.defs
+ENGBLD_REQUIRE          := $(shell git submodule update --init deps/eng)
+include ./deps/eng/tools/mk/Makefile.defs
+TOP ?= $(error Unable to access eng.git submodule Makefiles.)
 
 #
 # Configuration used by Makefile.defs and Makefile.targ to generate
@@ -98,7 +115,7 @@ JSSTYLE_FLAGS =		-f tools/jsstyle.conf
 # for SMF manifest files.
 #
 SMF_MANIFESTS_IN =	smf/manifests/bapi.xml.in
-include ./tools/mk/Makefile.smf.defs
+include ./deps/eng/tools/mk/Makefile.smf.defs
 
 #
 # Historically, Node packages that make use of binary add-ons must ship their
@@ -111,11 +128,19 @@ include ./tools/mk/Makefile.smf.defs
 NODE_PREBUILT_VERSION =	v4.9.0
 ifeq ($(shell uname -s),SunOS)
 	NODE_PREBUILT_TAG = zone
-	include ./tools/mk/Makefile.node_prebuilt.defs
+	include ./deps/eng/tools/mk/Makefile.node_prebuilt.defs
 else
-	include ./tools/mk/Makefile.node.defs
+	include ./deps/eng/tools/mk/Makefile.node.defs
 endif
 
+#
+# If a project needs to include Triton/Manta agents as part of its image,
+# include Makefile.agent_prebuilt.defs and define an AGENTS macro to specify
+# which agents are required.
+#
+include ./deps/eng/tools/mk/Makefile.agent_prebuilt.defs
+
+
 #
 # If a project includes some components written in the Go language, the Go
 # toolchain will need to be available on the build machine.  At present, the
@@ -125,7 +150,7 @@ ifeq ($(shell uname -s),SunOS)
 	GO_PREBUILT_VERSION =	1.9.2
 	GO_TARGETS =		$(STAMP_GO_TOOLCHAIN)
 	GO_TEST_TARGETS =	test_go
-	include ./tools/mk/Makefile.go_prebuilt.defs
+	include ./deps/eng/tools/mk/Makefile.go_prebuilt.defs
 endif
 
 ifeq ($(shell uname -s),SunOS)
@@ -140,7 +165,7 @@ endif
 # including this Makefile, we can depend on $(STAMP_NODE_MODULES) to drive "npm
 # install" correctly.
 #
-include ./tools/mk/Makefile.node_modules.defs
+include ./deps/eng/tools/mk/Makefile.node_modules.defs
 
 #
 # Configuration used by Makefile.manpages.defs to generate manual pages.
@@ -153,10 +178,30 @@ MAN_OUTROOT =		man
 CLEAN_FILES +=		$(MAN_OUTROOT)
 
 MAN_SECTION :=		1
-include tools/mk/Makefile.manpages.defs
+include ./deps/eng/tools/mk/Makefile.manpages.defs
 MAN_SECTION :=		3bapi
-include tools/mk/Makefile.manpages.defs
+include ./deps/eng/tools/mk/Makefile.manpages.defs
 
+#
+# If a project produces a SmartOS image for use in Manta/Triton, the build
+# should produce a tarball containing the components built from this workspace,
+# including any node_modules imported along with the build of node itself
+# (either built locally or prebuilt)
+#
+RELEASE_TARBALL = $(TOP)/$(NAME)-pkg-$(STAMP).tar.gz
+
+#
+# To support the 'buildimage' target in Makefile.targ, metadata required for the
+# image should be set here.
+#
+
+# This image is triton-origin-multiarch-15.4.1
+BASE_IMAGE_UUID = 04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f
+BUILDIMAGE_NAME = manta-myproject
+BUILDIMAGE_DESC	= My Project Has A Description
+BUILDIMAGE_PKG	= $(TOP)/$(RELEASE_TARBALL)
+BUILDIMAGE_PKGSRC = foobar-42 ook-1.0.1b cheese-0.4cheddar
+AGENTS		= amon config registrar
 
 #
 # Repo-specific targets
@@ -164,6 +209,13 @@ include tools/mk/Makefile.manpages.defs
 .PHONY: all
 all: $(SMF_MANIFESTS) $(STAMP_NODE_MODULES) $(GO_TARGETS) | $(REPO_DEPS)
 
+#
+# If a project produces a SmartOS image for use in Manta/Triton, a release
+# target should construct the RELEASE_TARBALL file
+#
+.PHONY: release
+release:
+	echo "Do work here"
 #
 # This example Makefile defines a special target for building manual pages.  You
 # may want to make these dependencies part of "all" instead.
@@ -209,21 +261,22 @@ test_ctf: helloctf $(STAMP_CTF_TOOLS)
 # the "defs" Makefiles we included above.
 #
 
-include ./tools/mk/Makefile.deps
+include ./deps/eng/tools/mk/Makefile.deps
 
 ifeq ($(shell uname -s),SunOS)
-	include ./tools/mk/Makefile.node_prebuilt.targ
-	include ./tools/mk/Makefile.go_prebuilt.targ
+	include ./deps/eng/tools/mk/Makefile.node_prebuilt.targ
+	include ./deps/eng/tools/mk/Makefile.go_prebuilt.targ
+	include ./deps/eng/tools/mk/Makefile.agent_prebuilt.targ
 else
-	include ./tools/mk/Makefile.node.targ
+	include ./deps/eng/tools/mk/Makefile.node.targ
 endif
 
 MAN_SECTION :=		1
-include tools/mk/Makefile.manpages.targ
+include ./deps/eng/tools/mk/Makefile.manpages.targ
 MAN_SECTION :=		3bapi
-include tools/mk/Makefile.manpages.targ
+include ./deps/eng/tools/mk/Makefile.manpages.targ
 
-include ./tools/mk/Makefile.smf.targ
-include ./tools/mk/Makefile.node_modules.targ
-include ./tools/mk/Makefile.ctf.targ
-include ./tools/mk/Makefile.targ
+include ./deps/eng/tools/mk/Makefile.smf.targ
+include ./deps/eng/tools/mk/Makefile.node_modules.targ
+include ./deps/eng/tools/mk/Makefile.ctf.targ
+include ./deps/eng/tools/mk/Makefile.targ
diff --git a/tools/agent-prebuilt.sh b/tools/agent-prebuilt.sh
new file mode 100755
index 0000000..a3825ee
--- /dev/null
+++ b/tools/agent-prebuilt.sh
@@ -0,0 +1,450 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Used by Makefile.agent_prebuilt.*, this script deals with managing the
+# cache of prebuilt Triton/Manta agent builds which are consumed by other
+# components. We don't expect developers to ever invoke this shell script
+# by hand. Instead, this script exists because it's easier to write/test
+# operations here than to try to embed lots of shell logic in a Makefile
+# target.
+#
+
+set -o errexit
+trap cleanup EXIT
+
+#
+# The options that this script takes correspond to the following
+# Makefile.agent_prebuilt.defs macros:
+#
+# -b AGENT_PREBUILT_BRANCH          the branch of the agent sources to build
+# -B AGENT_PREBUILT_TRY_BRANCH      the try_branch of the agent sources to build
+# -c AGENT_PREBUILT_DIR             the top level cache where we clone/build
+#                                   agents
+# -d <name>_PREBUILT_ROOTDIR        where in the image the package resides
+# -p <name>_PREBUILT_TARBALL_PATTERN  a glob pattern to match the built or
+#                                     downloaded agent
+# -r <name>_PREBUILT_REPO           the local repository name
+# -t <name>_PREBUILT_AGENT_TARGETS  the make targets in that repository to build
+# -u <name>_PREBUILT_GIT_URL        the git repository containing the agent
+#                                   source
+# -U AGENT_PREBUILT_URL             the url to download prebuilt agent tarballs
+#                                   from
+#
+function usage {
+    echo "Usage: agent-prebuilt <options> <command>"
+    echo "COMMANDS:"
+    echo "  clone               clone the git repository to the given branch"
+    echo "  build               build the supplied -t targets"
+    echo "  clean               clean the git repository"
+    echo "  download            download from a http:// or file:/// "
+    echo "  extract             extract the tarball within an image proto dir"
+    echo "  show_tarball        prints the path of the latest tarball"
+    echo ""
+    echo "OPTIONS:"
+    echo "  -b <branch>         the branch to checkout and build"
+    # a "try branch" is where a developer has pushed their changes to a dev
+    # branch which they want to attempt to build. If we can't checkout a
+    # matching "try branch", we fall back to the -b branch.
+    echo "  -B <try_branch>     the try_branch to checkout and build"
+    echo "  -c <dir>            the location of the agent_cache"
+    echo "  -d <dir>            where in the image the package resides"
+    echo "  -p <pattern>        a glob pattern to match the built agent tarball"
+    echo "  -r <repo name>      the local repository directory name"
+    echo "  -t <target>         the make targets to build"
+    echo "  -u <url>            the git repository to clone"
+    echo "  -U <url>            a http:// URL or file:/// dir containing"
+    echo "                      prebuilt tarballs"
+    exit 2
+}
+
+function do_clone {
+    set +o errexit
+    git_exit=0
+    if [[ -d $agent_cache_dir/$repo_name ]]; then
+        cd $agent_cache_dir/$repo_name
+        if [[ $? -ne 0 ]]; then
+            echo "ERROR: unable to cd to $agent_cache_dir/$repo_name"
+            return 1
+        fi
+        git pull
+        if [[ $? -ne 0 ]]; then
+            echo "WARNING: Pulling from $git_url failed, which might be ok if"
+            echo "the branch the existing repository is checked out to doesn't"
+            echo "exist upstream."
+        fi
+        git checkout $try_branch
+        if [[ $? -ne 0 ]]; then
+            echo "Checking out $try_branch failed, falling back to $branch"
+            git checkout $branch
+        fi
+        if [[ $? -ne 0 ]]; then
+            # at this point, failures are really fatal.
+            set -o errexit
+            echo "Checking out $branch also failed, falling back to master"
+            git checkout master
+            git_exit=$?
+        fi
+    else
+        cd $agent_cache_dir
+        if [[ $? -ne 0 ]]; then
+            echo "ERROR: unable to cd to $agent_cache_dir"
+            return 1
+        fi
+        git clone -b $try_branch $git_url $repo_name
+        if [[ $? -ne 0 ]]; then
+            echo "Cloning branch $try_branch failed, falling back to $branch"
+            git clone -b $branch $git_url $repo_name
+        fi
+        if [[ $? -ne 0 ]]; then
+            set -o errexit
+            echo "Cloning branch $branch also failed, falling back to master"
+            git clone -b master $git_url $repo_name
+            git_exit=$?
+        fi
+    fi
+    set -o errexit
+    return $git_exit
+}
+
+function do_build {
+    if [[ ! -d $agent_cache_dir/$repo_name ]]; then
+        echo "Cannot do a build when $repo_name dir is missing!"
+        return 1
+    fi
+    # this sets $LATEST_TARBALL as a side effect
+    get_tarball allow_empty
+    cd $agent_cache_dir/$repo_name
+    if [[ -n "$LATEST_TARBALL" ]]; then
+        # check it matches our hash
+        git_hash=$(git describe --all --long --dirty | awk -F'-g' '{print $NF}')
+        hash_present=$(echo $LATEST_TARBALL | grep "g${git_hash}" || true)
+        if [[ -n "$hash_present" ]]; then
+            echo "Latest tarball $LATEST_TARBALL seems fresh. Not rebuilding."
+            return 0
+        else
+            echo "Latest tarball is stale"
+            echo "  latest tarball: $LATEST_TARBALL"
+            echo "current git hash: $git_hash ($branch)"
+        fi
+    fi
+
+    #
+    # Our agents should be able to build and run anywhere,
+    # so relax the build checks for them. If any agents ever
+    # create dependencies against /opt/local, that would be
+    # bad.
+    #
+    ENGBLD_SKIP_VALIDATE_BUILDENV=true gmake $agent_targets
+    return $?
+}
+
+function do_clean {
+    rm -rf $agent_cache_dir/$repo_name
+    return 0
+}
+
+
+#
+# Determine the full path of the latest tarball, or the location we downloaded
+# it to if $agent_url is set, export as $LATEST_TARBALL.
+#
+function get_tarball {
+
+    if [[ -n "$1" ]]; then
+        allow_empty=true
+    fi
+
+    # 'basename', but using a bash builtin
+    file_pattern=${tarball_pattern##*/}
+    dir_pattern=$(dirname $tarball_pattern)
+    if [[ -z "$agent_url" ]]; then
+        latest_tarball_dir=$agent_cache_dir/$repo_name/$dir_pattern/
+    else
+        # downloaded tarballs are dumped at the top level of the agent_cache_dir
+        latest_tarball_dir=$agent_cache_dir
+    fi
+
+    # look for the try_branch file
+    if [[ -n "$try_branch" ]]; then
+        latest_tarball_file=$(
+            /usr/bin/ls -1 $latest_tarball_dir | grep $file_pattern \
+            2>/dev/null | grep $try_branch | sort | tail -1)
+    fi
+    if [[ -z "$latest_tarball_file" ]]; then
+        # fall back to the branch file
+        latest_tarball_file=$(
+            /usr/bin/ls -1 $latest_tarball_dir | grep $file_pattern \
+            2>/dev/null | grep $branch | sort | tail -1)
+    fi
+    if [[ -z "$latest_tarball_file" ]]; then
+        # fall back to the master branch
+	latest_tarball_file=$(
+            /usr/bin/ls -1 $latest_tarball_dir | grep $file_pattern \
+            2>/dev/null | grep master | sort | tail -1)
+    fi
+    if [[ -z "$latest_tarball_file" ]]; then
+        if [[ -n "$allow_empty" ]]; then
+            export LATEST_TARBALL=""
+            return
+        fi
+        echo "No (try_branch) $try_branch or (branch) $branch or master \
+            tarball for $tarball_pattern at $latest_tarball_dir"
+        exit 1
+    fi
+
+    export LATEST_TARBALL=$latest_tarball_dir/$latest_tarball_file
+}
+
+#
+# Extract the agent into the image rooted at the current directory.
+#
+function do_extract {
+
+    # This sets $LATEST_TARBALL as a side effect
+    get_tarball
+
+    this_dir=$PWD
+    # if we specified a directory relative to the top of the image, make that
+    # and cd into it so the agent appears in the correct location.
+    if [[ -n "$root_dir" ]]; then
+        mkdir -p $root_dir
+        cd $root_dir
+    fi
+    echo "Extracting agent $LATEST_TARBALL to $PWD"
+    case $LATEST_TARBALL in \
+        *bz2) bunzip2 -c $LATEST_TARBALL | gtar xf - ;
+            ;;
+        *gz) gunzip -c $LATEST_TARBALL | gtar xf - ;
+            ;;
+        *)
+            echo "ERROR: unknown extension trying to extract $LATEST_TARBALL"
+            exit 1
+    esac
+    cd $this_dir
+}
+
+#
+# Download this agent from the agent_url directory, according to the
+# tarball_pattern supplied
+#
+function do_download {
+    file_pattern=$(basename $tarball_pattern)
+    set +o errexit
+    http=$(echo $agent_url | grep ^http)
+    set -o errexit
+
+    if [[ -n "$http" ]]; then
+        # look for a try_branch url
+        agent_file=$(curl -sS --fail --connect-timeout 30 $agent_url |
+            grep 'href=' | cut -d'"' -f2 | grep "^${file_pattern}$" |
+            grep $try_branch | tail -1)
+        if [[ -z "$agent_file" ]]; then
+            # fall back to the branch url
+            agent_file=$(curl -sS --fail --connect-timeout 30 $agent_url |
+                grep 'href=' | cut -d'"' -f2 | grep "^${file_pattern}$" |
+                grep $branch | tail -1)
+        fi
+        if [[ -z "$agent_file" ]]; then
+            echo "Unable to determine url for (try_branch) $try_branch \
+                or (branch) $branch $file_pattern at $agent_url"
+            exit 1
+        fi
+        echo "Downloading $agent_url/$agent_file"
+        curl -sS --connect-timeout 30 -o \
+            $agent_cache_dir/$agent_file $agent_url/$agent_file
+    else
+        # copy it, assuming $agent_url and $agent_cache_dir aren't identical.
+        # We don't have 'realpath' on all build systems, so make do with Python.
+        realpath_agent_url=$(python -c
+            "import os; print os.path.realpath('$agent_url')")
+        realpath_agent_cache_dir=$(python -c
+            "import os; print os.path.realpath('$agent_cache_dir')")
+        if [[ "$realpath_agent_url" == "$realpath_agent_cache_dir" ]]; then
+            echo "Identical paths for $agent_url and $agent_cache_dir. Skipping"
+            return
+        fi
+        file_pattern=$(basename $tarball_pattern)
+        # look for a try_branch file
+        latest_tarball_file=$(
+            /usr/bin/ls -1 $agent_url | grep $file_pattern \
+            2>/dev/null | grep $try_branch | sort | tail -1)
+        if [[ -z "$latest_tarball_file" ]]; then
+            # fall back to the branch file
+            latest_tarball_file=$(
+                /usr/bin/ls -1 $agent_url | grep $file_pattern \
+                2>/dev/null | grep $branch | sort | tail -1)
+        fi
+        if [[ -z "$latest_tarball_file" ]]; then
+            echo "Unable to find local file for (try_branch) $try_branch \
+                or (branch) $branch $agent_pattern at $agent_url"
+            exit 1
+        fi
+        latest_tarball_file=$agent_url/$latest_tarball_file
+        echo "Copying local $latest_tarball_file to $agent_cache_dir"
+        cp $latest_tarball_file $agent_cache_dir
+    fi
+}
+
+function cleanup {
+    if [[ -d $agent_cache_dir/$repo_name.lock ]]; then
+        rmdir $agent_cache_dir/$repo_name.lock
+    fi
+}
+
+#
+# Main
+#
+while getopts "B:b:c:d:hp:r:t:u:U:" opt; do
+    case "${opt}" in
+        b)
+            branch=$OPTARG
+            ;;
+        B)
+            try_branch=$OPTARG
+            ;;
+        c)
+            agent_cache_dir=$OPTARG
+            mkdir -p $agent_cache_dir
+            ;;
+        d)
+            # it's ok for this to be empty, indicating the agent tarball
+            # delivers directories right up to the root of the image. Sanity
+            # check the variable, just to be on the safe side.
+            root_dir=$OPTARG
+            if [[ -n "$root_dir" ]]; then
+                case "$root_dir" in
+                    .* | /*)
+                        echo "Error: -d option should not start with . or /"
+                        exit 1
+                        ;;
+                esac
+            fi
+            ;;
+        h)
+            do_usage=true
+            ;;
+        p)
+            tarball_pattern="$OPTARG"
+            ;;
+        r)
+            repo_name=$OPTARG
+            ;;
+        t)
+            agent_targets="$OPTARG"
+            ;;
+        U)
+            # optional
+            agent_url=$OPTARG
+            ;;
+        u)
+            git_url=$OPTARG
+            ;;
+        *)
+            echo "Error: unknown option ${opt}"
+            usage
+    esac
+done
+shift $((OPTIND - 1))
+
+command=$1
+
+if [[ -z "$try_branch" ]]; then
+    try_branch=$branch
+fi
+
+if [[ -z "$branch" ]]; then
+    branch=master
+fi
+
+if [[ -z "$agent_cache_dir" ]]; then
+    echo "-c agent_cache_dir option must be supplied"
+    usage
+fi
+
+if [[ -z "$tarball_pattern" ]]; then
+    echo "-p tarball_pattern option must be supplied"
+    usage
+fi
+
+if [[ -z "$repo_name" ]]; then
+    echo "-r repo_name option must be supplied"
+    usage
+fi
+
+if [[ -z "$agent_targets" && "$command" == "build" ]]; then
+    echo "-t agent_targets option must be supplied"
+    usage
+fi
+
+if [[ -z "$git_url" && "$command" == "clone" ]]; then
+    echo "-u git_url option must be supplied"
+    usage
+fi
+
+if [[ -n "${do_usage}" ]]; then
+    usage
+fi
+
+if [[ -z "$1" ]]; then
+    echo "No command supplied"
+    usage
+fi
+
+# attempt to prevent two agent-prebuilt.sh scripts from operating on the
+# same repo at the same time. $agent_cache_dir exists at this point.
+unlocked="true"
+count=0
+set +o errexit
+while [[ -n "$unlocked" && $count -lt 600 ]]; do
+    if ! mkdir $agent_cache_dir/$repo_name.lock 2> /dev/null; then
+        echo "$agent_cache_dir/$repo_name.lock already held, sleeping $count..."
+        unlocked="locked"
+        count=$(( $count + 1 ))
+        sleep 1
+    else
+        unlocked=""
+    fi
+done
+set -o errexit
+
+if [[ -n "$unlocked" ]]; then
+    echo "Failed to unlock agent cache for $repo_name. Exiting now."
+    exit 1
+fi
+
+case "$command" in
+    clone)
+        do_clone
+        ;;
+    build)
+        do_build
+        ;;
+    clean)
+        do_clean
+        ;;
+    extract)
+        do_extract
+        ;;
+    show_tarball)
+        get_tarball
+        echo $LATEST_TARBALL
+        ;;
+    download)
+        do_download
+        ;;
+    *)
+        echo "Unrecognised command $1"
+        usage
+        ;;
+esac
+
+cleanup
diff --git a/tools/bits-upload.sh b/tools/bits-upload.sh
new file mode 100755
index 0000000..32dc798
--- /dev/null
+++ b/tools/bits-upload.sh
@@ -0,0 +1,435 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Upload the $BITS_DIR directory to Manta or a "local" directory (likely
+# an NFS-mounted share if we're contributing to bits already stored there
+# by other builds on remote systems)
+# This creates a specific directory structure, consumed by the headnode builds:
+#
+# <remote>/<component>/latest-release -> <latest>
+# <remote>/component>/<component-branch-stamp>/<component>/... (files)
+#
+# which is documented at:
+# https://github.com/joyent/mountain-gorilla/blob/master/docs/index.md
+# (see "Bits directory structure")
+#
+
+#
+# It is unlikely that users will ever need to run this script by hand.
+# Users are more likely to run this as part of the 'bits-upload' or
+# 'bits-upload-latest' targets.
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='${BASH_SOURCE}:${LINENO}: '
+    set -o xtrace
+fi
+set -o errexit
+
+#
+# Uncomment the below to have manta-tools emit bunyan logs to stdout
+#
+# MANTA_VERBOSE=-v
+
+#
+# Whether we should overwrite previous uploads if the content is the same
+#
+BITS_UPLOAD_OVERWRITE=false
+
+#
+# A path to our updates-imgadm command
+#
+UPDATES_IMGADM=/root/opt/imgapi-cli/bin/updates-imgadm
+
+if [[ -z "$BITS_DIR" ]]; then
+	BITS_DIR=bits
+fi
+
+PATH=$PATH:/root/opt/node_modules/manta/bin:/opt/tools/bin
+
+function fatal {
+    echo "$(basename $0): error: $1"
+    exit 1
+}
+
+function errexit {
+    [[ $1 -ne 0 ]] || exit 0
+    fatal "error exit status $1 at line $2"
+}
+
+trap 'errexit $? $LINENO' EXIT
+
+function usage {
+    echo "Usage: bits-upload.sh [options] [subdirs...]"
+    echo "OPTIONS"
+    echo "  -b <branch>         the branch use"
+    echo "  -B <try_branch>     the try_branch use"
+    echo "  -d <upload_base_dir> destination path name in manta or a local path"
+    echo "  -L                  indicate the -d arg is a local path"
+    echo "  -n <name>           the name of component to upload"
+    echo "  -p                  also publish images to updates.joyent.com"
+    echo "  -t <timestamp>      the timestamp (optional, derived otherwise)"
+    echo ""
+    echo "Upload bits to Manta or a local destination from \$BITS_DIR"
+    echo "which (defaults to <component>/bits)"
+    echo ""
+    echo "The upload_base_dir is presumed to be either a subdir of"
+    echo "\${MANTA_USER}/stor or if it starts with '/', a path under"
+    echo "\${MANTA_USER}. If Using -L, the -d argument should be an"
+    echo "absolute path."
+    exit 2
+}
+
+#
+# Maintain a global associative array mapping uploaded file basenames
+# to their corresponding Manta paths. This assumes basenames are unique.
+#
+declare -A STORED_MANTA_PATHS
+
+#
+# A simple wrapper to emit manta command-lines before running them.
+#
+function manta_run {
+    echo $@
+    "$@"
+    return $?
+}
+
+#
+# Upload build artifacts to Manta. There's some duplication in the logic
+# here and local_upload.
+#
+function manta_upload {
+
+    if [[ -z "$MANTA_KEY_ID" ]]; then
+        export MANTA_KEY_ID=$(
+            ssh-keygen -E md5 -l -f ~/.ssh/id_rsa.pub | \
+            awk '{sub("^MD5:", "", $2); print $2}')
+    fi
+    if [[ -z "$MANTA_URL" ]]; then
+        export MANTA_URL=https://us-east.manta.joyent.com
+    fi
+    if [[ -z "$MANTA_USER" ]]; then
+        export MANTA_USER="Joyent_Dev";
+    fi
+
+    if [[ ${UPLOAD_BASE_DIR:0:1} != '/' ]]; then
+        # if it starts with a / we assume it's /stor/<something> or
+        # /public/<something> if not, we prepend /stor
+        UPLOAD_BASE_DIR="/stor/${UPLOAD_BASE_DIR}"
+    fi
+
+    MANTA_DESTDIR=/${MANTA_USER}${UPLOAD_BASE_DIR}/${UPLOAD_SUBDIR}
+    echo "Uploading bits to ${MANTA_DESTDIR} "
+    if [[ -z "$SUBS" ]]; then
+        manta_run mmkdir ${MANTA_VERBOSE} -p ${MANTA_DESTDIR}
+    fi
+
+    for sub in $SUBS; do
+        manta_run mmkdir ${MANTA_VERBOSE} -p ${MANTA_DESTDIR}/${sub#${BITS_DIR}}
+    done
+
+    md5sums=""
+    # now we can upload the files
+    for file in $FILES; do
+        manta_object=${MANTA_DESTDIR}/${file#$BITS_DIR}
+
+        local_md5_line=$(md5sum ${file})
+        local_md5=$(echo "${local_md5_line}" | cut -d ' ' -f1)
+        manta_md5=$(mmd5 ${manta_object} | cut -d ' ' -f1)
+
+        if [[ -n ${manta_md5} && ${manta_md5} != ${local_md5} ]]; then
+            fatal "${manta_object} exists but MD5 does not match ${file}"
+        fi
+
+        if [[ -z ${manta_md5} ]]; then
+            # file doesn't exist, upload it
+            manta_run mput ${MANTA_VERBOSE} -f ${file} ${manta_object}
+            [[ $? == 0 ]] || fatal "Failed to upload ${file} to ${manta_object}"
+        elif [[ "$BITS_UPLOAD_OVERWRITE" == "false" ]]; then
+            echo "${manta_object} already exists and matches local file,"
+            echo "Skipping upload."
+        fi
+        md5sums="${md5sums}${local_md5_line}\n"
+
+        # save the file to our global assoc-array of {filename: manta path}
+        # used later when mapping manifests to image file URLs.
+        STORED_MANTA_PATHS[$(basename $file)]=${manta_object}
+
+        # Store a full URL if it appears to be a public resource, otherwise
+        # just save the manta path.
+        set +o errexit
+        echo $manta_object | grep -q /public/
+        if [[ $? -eq 0 ]]; then
+            echo ${MANTA_URL}${manta_object} >> ${BITS_DIR}/artifacts.txt
+        else
+            echo $manta_object >> ${BITS_DIR}/artifacts.txt
+        fi
+        set -o errexit
+    done
+
+    # upload the md5sums
+    echo -e $md5sums | \
+        manta_run mput ${MANTA_VERBOSE} -H "content-type: text/plain" \
+            ${MANTA_DESTDIR}/md5sums.txt
+        echo ${MANTA_DESTDIR}/md5sums.txt >> ${BITS_DIR}/artifacts.txt
+
+    # now update the branch latest link
+    echo "${MANTA_DESTDIR}" | \
+        manta_run mput ${MANTA_VERBOSE} -H "content-type: text/plain" \
+            /${MANTA_USER}${UPLOAD_BASE_DIR}/${UPLOAD_BRANCH}-latest
+    echo /${MANTA_USER}${UPLOAD_BASE_DIR}/${UPLOAD_BRANCH}-latest >> \
+        ${BITS_DIR}/artifacts.txt
+
+    # If this is a bi-weekly release branch, also update latest-release link
+    if [[ $UPLOAD_BRANCH =~ ^release- ]]; then
+        echo "${MANTA_DESTDIR}" | \
+            manta_run mput ${MANTA_VERBOSE} -H "content-type: text/plain" \
+                /${MANTA_USER}${UPLOAD_BASE_DIR}/latest-release
+        echo /${MANTA_USER}${UPLOAD_BASE_DIR}/latest-release >> \
+            ${BITS_DIR}/artifacts.txt
+    fi
+
+    echo "Uploaded to ${MANTA_DESTDIR}"
+}
+
+#
+# Copy build artifacts to a local or NFS-mounted filesystem.
+# There's some duplication in the logic here and manta_upload. Note that
+# the <branch>-latest object created is now a symlink rather than an
+# object containing the latest path.
+#
+function local_upload {
+
+    LOCAL_DESTDIR=${UPLOAD_BASE_DIR}/${UPLOAD_SUBDIR}
+    for sub in $SUBS; do
+        mkdir -p ${LOCAL_DESTDIR}/${sub#${BITS_DIR}}
+    done
+
+    md5sums=""
+    for file in $FILES; do
+        remote_object=${LOCAL_DESTDIR}/${file#$BITS_DIR}
+
+        local_md5_line=$(md5sum ${file})
+        local_md5=$(echo "${local_md5_line}" | cut -d ' ' -f1)
+        if [[ -f ${remote_object} ]]; then
+            remote_md5=$(md5sum ${remote_object} | cut -d ' ' -f1)
+        else
+            remote_md5=""
+        fi
+
+        if [[ -n ${remote_md5} && ${remote_md5} != ${local_md5} ]]; then
+            fatal "${remote_object} exists but MD5 does not match ${file}"
+        fi
+
+        if [[ -z ${remote_md5} ]]; then
+            # file doesn't exist, upload it
+            cp ${file} ${remote_object}
+            [[ $? == 0 ]] || \
+                fatal "Failed to upload ${file} to ${remote_object}"
+        else
+            echo "${remote_object} already exists and matches local file,"
+            echo "skipping upload."
+        fi
+        md5sums="${md5sums}${local_md5_line}\n"
+        echo $remote_object >> ${BITS_DIR}/artifacts.txt
+    done
+
+    # upload the md5sums
+    echo -e $md5sums > ${LOCAL_DESTDIR}/md5sums.txt
+
+    # now update the branch latest link
+    if [[ -L ${UPLOAD_BASE_DIR}/${UPLOAD_BRANCH}-latest ]]; then
+        unlink ${UPLOAD_BASE_DIR}/${UPLOAD_BRANCH}-latest
+    fi
+    (cd $UPLOAD_BASE_DIR ; ln -s ${UPLOAD_SUBDIR} ${UPLOAD_BRANCH}-latest)
+
+    # If this is a bi-weekly release branch, also update latest-release link
+    if [[ $UPLOAD_BRANCH =~ ^release- ]]; then
+        if [[ -L ${UPLOAD_BASE_DIR}/latest-release ]]; then
+            unlink ${UPLOAD_BASE_DIR}/latest-release
+        fi
+        (cd ${UPLOAD_BASE_DIR} ; ln -s ${UPLOAD_SUBDIR} latest-release)
+    fi
+}
+
+#
+# Look for build artifacts to operate on.
+#
+function find_upload_bits {
+    if [[ -z "$SUBDIRS" ]]; then
+        SUBS=$(find $BITS_DIR -type d)
+        FILES=$(find $BITS_DIR -type f)
+    else
+        for subdir in ${SUBDIRS}; do
+            if [[ -d $BITS_DIR/$subdir ]]; then
+                SUBS="$SUBS $(find $BITS_DIR/$subdir -type d)"
+                FILES="$FILES $(find $BITS_DIR/$subdir -type f)"
+            fi
+        done
+    fi
+}
+
+#
+# Publish build artifacts to updates.joyent.com.
+#
+function publish_to_updates {
+    echo "Publishing updates to updates.joyent.com"
+    for file in ${FILES}; do
+        set +o errexit
+        echo ${file} | grep -q '.*manifest$'
+        if [[ $? -ne 0 ]]; then
+            set -o errexit
+            continue
+        fi
+        set -o errexit
+
+        MF=${file}
+        IMAGEFILE=$(echo ${file} | sed -e 's/\..*manifest$/.zfs.gz/g')
+
+        # some payloads are not zfs-based, look for likely alternatives
+        if [[ "$IMAGEFILE" == "${file}" ]]; then
+            IMAGEFILE=$(echo ${file} | sed -e 's/\..*manifest$/.sh/g')
+        fi
+        if [[ "$IMAGEFILE" == "${file}" ]]; then
+            IMAGEFILE=$(echo ${file} | sed -e 's/\..*manifest$/.tgz/g')
+        fi
+
+        if [[ ! -f ${IMAGEFILE} ]]; then
+            echo "Unable to determine image file for ${MF}."
+            echo "Skipping publishing ${MF} to updates.joyent.com"
+            continue
+        fi
+
+        UUID=$(json -f ${MF} uuid)
+        if [[ -z "${UUID}" ]]; then
+            echo "Unable to determine UUID of ${MF}."
+            echo "Skipping publishing ${MF} to updates.joyent.com"
+            continue
+        fi
+
+        # The default 1hr expiry for msign is sufficient, since we're going
+        # to be accessing this URL almost immediately.
+        MANTA_PATH=${STORED_MANTA_PATHS[$(basename $IMAGEFILE)]}
+        MANTA_URL=$(msign $MANTA_PATH)
+        echo "Using the following environment variables for updates-imgadm:"
+        echo "UPDATES_IMGADM_IDENTITY=$UPDATES_IMGADM_IDENTITY"
+        echo "UPDATES_IMGADM_USER=$UPDATES_IMGADM_USER"
+        echo Running: ${UPDATES_IMGADM} -C experimental import -m $MF -f "${MANTA_URL}"
+        ${UPDATES_IMGADM} -C experimental import -m $MF -f "${MANTA_URL}"
+    done
+}
+
+
+#
+# Main
+#
+while getopts "B:b:d:Ln:pt:" opt; do
+    case "${opt}" in
+        b)
+            BRANCH=$OPTARG
+            ;;
+        B)
+            TRY_BRANCH=$OPTARG
+            ;;
+        d)
+            UPLOAD_BASE_DIR=$OPTARG
+            ;;
+        L)
+            USE_LOCAL=true
+            ;;
+        n)
+            NAME=$OPTARG
+            ;;
+        p)
+            PUBLISH_UPDATES=true
+            ;;
+        t)
+            TIMESTAMP=$OPTARG
+            ;;
+        *)
+            echo "Error: Unknown argument ${opt}"
+            usage
+    esac
+done
+shift $((OPTIND - 1))
+
+if [[ -z "${BRANCH}" ]]; then
+    echo "Missing -b argument for branch"
+    usage
+fi
+
+if [[ -z "$UPLOAD_BASE_DIR" ]]; then
+    echo "Missing -d argument for upload_base_dir"
+    usage
+fi
+
+if [[ ! -d "$BITS_DIR" ]]; then
+    fatal "bits dir $BITS_DIR does not exist!"
+fi
+
+if [[ -z "$NAME" ]]; then
+    fatal "Missing -d argument for name"
+fi
+
+SUBDIRS=$*
+
+UPLOAD_BRANCH=$TRY_BRANCH
+if [[ -z "$UPLOAD_BRANCH" ]]; then
+    UPLOAD_BRANCH=$BRANCH
+fi
+
+start_time=$(date +%s)
+
+# we keep a file containing a list of uploads for this
+# session, useful to include as part of build artifacts.
+if [[ -f $BITS_DIR/artifacts.txt ]]; then
+    rm -f $BITS_DIR/artifacts.txt
+fi
+
+find_upload_bits
+
+if [[ -z "$TIMESTAMP" ]]; then
+    LATEST_BUILD_STAMP=$BITS_DIR/$NAME/latest-build-stamp
+    # Pull the latest timestamp from the bits dir instead.
+    if [[ -f $LATEST_BUILD_STAMP ]]; then
+        TIMESTAMP=$(cat $LATEST_BUILD_STAMP)
+    else
+        echo "Missing timestamp, and no contents in $LATEST_BUILD_STAMP"
+        echo "Did the 'prepublish' Makefile target run?"
+        fatal "Unable to derive latest timestamp from files in $BITS_DIR"
+    fi
+fi
+
+UPLOAD_SUBDIR=$TIMESTAMP
+
+if [[ -n "$USE_LOCAL" ]]; then
+    if [[ -n "$PUBLISH_TO_UPDATES" ]]; then
+        fatal "-p requires uploading to Manta, and is incompatible with -L"
+    fi
+    local_upload
+else
+    manta_upload
+fi
+
+if [[ -n "$PUBLISH_UPDATES" ]]; then
+    publish_to_updates
+fi
+
+end_time=$(date +%s)
+elapsed=$((${end_time} - ${start_time}))
+if [[ -n "$USE_LOCAL" ]]; then
+    desc="(path=${UPLOAD_BASE_DIR}/${UPLOAD_SUBDIR})"
+else
+    desc="(Manta path=/${MANTA_USER}${UPLOAD_BASE_DIR}/${UPLOAD_SUBDIR})."
+fi
+echo "Upload took ${elapsed} seconds $desc"
diff --git a/tools/buildimage-extract-pkg.sh b/tools/buildimage-extract-pkg.sh
new file mode 100755
index 0000000..d4f4eed
--- /dev/null
+++ b/tools/buildimage-extract-pkg.sh
@@ -0,0 +1,35 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# This script simply extracts the .tar.gz or .tar.bz package given as $1 to the
+# current directory.
+#
+
+ARCHIVE=$1
+
+# Uncomment this for debugging.
+# VERBOSE=v
+
+case $ARCHIVE in
+    *tar.bz2|*.tar.bz)
+        TAR_ARGS="jx${VERBOSE}f"
+        ;;
+    *.tar.gz|*.tgz)
+        TAR_ARGS="zx${VERBOSE}f"
+        ;;
+    *)
+        echo "Error: buildimage-extract-pkg: Unknown archive file $ARCHIVE"
+        exit 1
+esac
+
+gtar ${TAR_ARGS} $ARCHIVE
+exit $?
diff --git a/tools/buildimage/Makefile b/tools/buildimage/Makefile
new file mode 100644
index 0000000..75b6eac
--- /dev/null
+++ b/tools/buildimage/Makefile
@@ -0,0 +1,54 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# This Makefile contains targets to npm install the dependencies for
+# buildimage and the private copy of imgadm it requires. We expect
+# that the main eng.git/tools/mk/Makefile.targ 'stamp-buildimage-prep'
+# will invoke these targets.
+#
+
+#
+# This is the expected location of the modern pkgsrc bootstrap,
+# currently bootstrap-2018Q3-tools.tar.gz
+#
+BUILD_TOOLS = /opt/tools
+
+
+IMGADM_CC = CC=$(BUILD_TOOLS)/bin/gcc
+IMGADM_CXX = CXX=$(BUILD_TOOLS)/bin/g++
+IMGADM_CTF = CTFCONVERT=/bin/true CTFMERGE=/bin/true
+
+# This is a little ugly. We're piggy-backing on OPT_FLAGS
+# so that we can pass in a specific include dir since otherwise
+# v8plus (an imgadm dependency) expects to see it in
+# $(BUILD_TOOLS)/include/node.
+IMGADM_INC = OPT_FLAGS=-O2 OPT_FLAGS+=-I$(BUILD_TOOLS)/include
+
+# Similarly, we have no way to pass LDFLAGS to v8plus, so use
+# NODE_LIBDIR instead.
+IMGADM_LIB = NODE_LIBDIR+=-L$(BUILD_TOOLS)/node/lib \
+             NODE_LIBDIR+=-L$(BUILD_TOOLS)/lib NODE_LIBDIR+=-luv
+
+IMGADM_FLAGS = MAKE_OVERRIDES='$(IMGADM_CC) $(IMGADM_CXX) $(IMGADM_CTF) $(IMGADM_INC) $(IMGADM_LIB)'
+
+
+buildimage-prep: imgadm-prep
+	rm -rf node_modules; \
+	PATH=$(BUILD_TOOLS)/bin:$$PATH $(BUILD_TOOLS)/bin/npm \
+	    --unsafe-perm \
+	    --scripts-prepend-node-path=true install
+
+imgadm-prep:
+	rm -rf lib/imgadm/node_modules
+	cd lib/imgadm; \
+	$(IMGADM_FLAGS) $(BUILD_TOOLS)/bin/npm \
+	    --unsafe-perm --scripts-prepend-node-path=true install
+
diff --git a/tools/buildimage/README.md b/tools/buildimage/README.md
new file mode 100644
index 0000000..e4f340c
--- /dev/null
+++ b/tools/buildimage/README.md
@@ -0,0 +1,122 @@
+# buildimage (nee Buildy McBuildface)
+
+## What in the world is this?
+
+This directory contains build tools to speed up Triton service image builds.
+To understand this speed up, one needs to understand how builds work
+without/prior to this.
+
+When building an image the process is (only including steps relevant to speed-up
+here):
+
+ * Select a jenkins agent (running a jenkins-agent image) with the appropriate
+   image (must use the same architecture and pkgsrc as the underlying image that
+   the Triton service will use).
+ * Checkout the appropriate version of the service's code.
+ * Do an `npm install` to non-reproducibly populate the `node_modules` directory
+   with the appropriate modules and binaries (add-ons like dtrace-provider).
+ * Build a proto directory which includes the source code from the repo, the
+   `node_modules` directory and some other bits.
+ * Have MG install the sdcnode build, and some other content (config-agent,
+   registrar, etc.) into the build.
+ * Tar up the proto directory.
+ * Determine a package to use to provision a temporary VM in JPC.
+ * Create a temporary VM in JPC using the target image
+   (e.g. sdc-multiarch-15.4.1) and the package determined above.
+ * Wait (up to 30 minutes) for the VM to be created then;
+ * Unpack the proto tarball into the root directory of the VM.
+ * Install the pkgsrc packages that the service defines.
+ * Cleanup junk left behind from booting the VM.
+ * Use sdc-createimagefrommachine to use cloudapi to create an image out of the
+   temporary JPC VM.
+ * Wait (up to 10 minutes) for the image creation to complete.
+ * Delete the temporary JPC VM.
+ * Download the created image and manifest from Manta.
+ * Modify the manifest of the created manifest.
+ * Push the updated manifest to manta.
+ * Delete the temporary VM image from JPC.
+ * Use the image and manifest (e.g. upload to updates.joyent.com)
+
+With the tools here, the process is intended to change to:
+
+ * Select a jenkins agent (running a jenkins-agent image) with the appropriate
+   image (must use the same architecture and pkgsrc as the underlying image that
+   the Triton service will use). This agent must have a delegated dataset.
+ * Checkout the appropriate version of the service's code.
+ * Do an `npm install` to non-reproducibly populate the `node_modules` directory
+   with the appropriate modules and binaries (add-ons like dtrace-provider).
+ * Build a proto directory which includes the source code from the repo, the
+   `node_modules` directory, the sdcnode build, and all the required bloatware.
+ * Run the bin/buildimage tool to:
+     * Import the target image into the delegated dataset under
+       `zones/<vm_uuid>/data/<image_uuid>`.
+     * Create a "zone analog" dataset by cloning the image.
+     * Use rsync to copy from the proto directory to the zone analog dataset.
+     * Chroot into the zone analog dataset and run pkg_add to install the
+       packages.
+     * Cleanup any cruft left behind by pkgsrc.
+     * Use the imgadm image creation logic to create an image from the zone
+       analog using manifest parameters passed in.
+     * Delete the zone analog dataset.
+ * Use the image and manifest (e.g. upload to manta and update
+   updates.joyent.com with the image)
+
+The reasons this is much faster and more reliable include:
+
+ * We can skip tarring up the proto directory and sending over the network.
+ * All build operations take place within the jenkins agent zone. No VMs need
+   to be provisioned.
+ * We don't need to wait on VM creation.
+ * We don't need to cleanup junk left behind by booting the VM since the VM is
+   never booted.
+ * We don't need to wait on image creation.
+ * We don't need to download the image and manifest, or push the modified
+   manifest. (Since they were built locally).
+ * MG is no longer needed so the total amount of code involved is reduced.
+
+With experiments done so far, this offers drastic improvements in image creation
+times. It also should be more reliable since there are far fewer moving parts
+and fewer external dependencies.
+
+## Where did the name come from?
+
+The previous name, 'buildymcbuildface' was a homage to the great [Boaty
+Mcboatface](https://en.wikipedia.org/wiki/Boaty_McBoatface). At the time the
+name was chosen, "buildymcbuildface" also had no Google results. Being unable
+to explain 'buildymcbuildface' with a straight face, we renamed it "buildimage",
+because that's what it does.
+
+## How do I try to use it?
+
+You will probably never need to - we integrated it into its own 'buildimage'
+target in eng.git/tools/mk/Makefile.targ so it ought to "Just Work", with the
+appropriate Makefile definitions.
+
+See the 'buildimage' target in eng.git/tools/mk/Makefile.targ
+
+## Does it come with a warranty?
+
+No.
+
+## What's going on with lib/imgadm?
+
+This tool uses imgadm but unfortunately it needs to run on ancient platforms. As
+such, it needs to include imgadm. Even more unfortunately, it's tricky to
+get this to work properly with npm because imgadm ships its node modules in
+smartos-live.git.
+
+In turn, imgadm.js requires files in /usr/img/lib and from the platform install
+of node, e.g. /usr/node/node_modules/zfs.js.
+
+Our solution for now, is to pull those from the platform and modify our
+bundled imgadm code to use its private copies. We also need to jump through
+a few hoops during the build to allow use of the /opt/tools toolchain,
+including node v6 and more modern compilers. This results in some ugly
+compiler flags in buildimage's Makefile. Apologies for those.
+
+At some point in the future, it might be nice to pull imgadm out from
+smartos-live and have it be a proper npm module. At that point we could just add
+it to our package.json here and point to a version with these changes,
+freeing us up from this runtime restriction.
+
+See lib/imgadm/README.md for details on the version of imgadm we use.
diff --git a/tools/buildimage/bin/buildimage b/tools/buildimage/bin/buildimage
new file mode 100755
index 0000000..389b1ea
--- /dev/null
+++ b/tools/buildimage/bin/buildimage
@@ -0,0 +1,692 @@
+#!/opt/tools/bin/node
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var child_process = require('child_process');
+var dns = require('dns');
+var fs = require('fs');
+var path = require('path');
+var url = require('url');
+
+var assert = require('assert-plus');
+var dashdash = require('dashdash');
+var uuidv4 = require('uuid/v4');
+var vasync = require('vasync');
+
+var CLI = require('../lib/imgadm/lib/cli');
+var imgadmCommon = require('../lib/imgadm/lib/common');
+var indent = imgadmCommon.indent;
+
+
+var CHROOT_MOUNT_DIRS = ['/dev', '/lib', '/proc', '/sbin', '/usr'];
+var CLI_OPTIONS = [
+    {
+        names: ['dir', 'd'],
+        type: 'string',
+        help: 'Directory containing bits to include in image. [required]',
+        helpArg: 'DIR'
+    },
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Print this help and exit.'
+    },
+    {
+        names: ['image', 'i'],
+        type: 'string',
+        help: 'Base image to use. [required]',
+        helpArg: 'IMAGE_UUID'
+    },
+    {
+        names: ['manifest', 'm'],
+        type: 'string',
+        help: 'A JSON object with manifest data. Must have at least name and version. [required]',
+        helpArg: '{"name": "blah", "version": "1.0.0", ...}'
+    },
+    {
+        names: ['packages', 'p'],
+        type: 'string',
+        help: 'Comma separated list of pkgsrc packages to install in image.',
+        helpArg: 'pkg1,pkg2,...'
+    },
+    {
+        names: ['image_prefix', 'P'],
+        type: 'string',
+        help: 'prefix name for output zfs and imgmanifest files.',
+        helpArg: 'PREFIX'
+    },
+    {
+        names: ['verbose', 'v'],
+        type: 'bool',
+        help: 'Enable extra verbosity.'
+    },
+    {
+        name: 'version',
+        type: 'bool',
+        help: 'Print tool version and exit.'
+    }
+];
+var NS_PER_SEC = 1e9;
+// from https://www.netbsd.org/docs/pkgsrc/components.html#components.Makefile
+// but with ',' added for separator and we're matching the string so we don't
+// care as much about first character.
+var PKGS_REGEX = /^[A-Za-z0-9\-_.+,]*$/;
+var PROGNAME = 'buildimage';
+var START_TIME = process.hrtime();
+
+
+function logLine() {
+    var args = Array.prototype.slice.call(arguments);
+    var delta = process.hrtime(START_TIME);
+    var deltaStr;
+    var pad = '';
+    var secsDelta = delta[0] + (delta[1] / NS_PER_SEC);
+
+    // left pad with spaces if we have less than 3 digit seconds
+    // then truncate the result to 12 characters
+    pad = '   '.substr(0, 3 - delta[0].toString().length);
+    deltaStr = (pad + secsDelta).substr(0, 12);
+
+    // if we didn't have 12 characters, right pad w/ 0 so things line up
+    while (deltaStr.length < 12) {
+        deltaStr = deltaStr + '0';
+    }
+
+    args[0] = '[' + deltaStr + '] ' + args[0];
+
+    console.log.apply(null, args);
+}
+
+function logExecError(err, stdout, stderr) {
+    console.error('FAILED(stdout): ' + stdout);
+    console.error('FAILED(stderr): ' + stderr);
+    console.error('FAILED(err): ' + err.message);
+}
+
+function ensureImage(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.uuid(opts.image, 'opts.image');
+    assert.func(callback, 'callback');
+
+    var cli = new CLI();
+
+    logLine('Calling imgadm to import image');
+
+    opts.cli = cli;
+
+    cli.init({}, {}, function _onInit(err) {
+        if (err) {
+            callback(err);
+            return;
+        }
+        opts.dataroot = cli.tool.DEFAULT_ZPOOL;
+        // TODO: validate opts.dataroot looks reasonable.
+        opts.imagesnapshot = opts.dataroot + '/' + opts.image + '@final';
+        cli.do_import('import', {
+            logCb: logLine,
+            'source': ['https://updates.joyent.com']}, [opts.image], callback);
+    });
+}
+
+function createZoneAnalog(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.dataroot, 'opts.dataroot');
+    assert.string(opts.imagesnapshot, 'opts.imagesnapshot');
+    assert.func(callback, 'callback');
+
+    var mountpoint = '/zoneproto-' + process.pid;
+    var newUuid = uuidv4();
+    var source = opts.imagesnapshot;
+    var target = opts.dataroot + '/' + newUuid;
+
+    logLine('Creating zone analog (' + newUuid + ')');
+    opts.mountpoint = mountpoint;
+    opts.target = target;
+    opts.vmUuid = newUuid;
+
+    child_process.execFile('/usr/sbin/zfs', [
+        'clone',
+        '-o', 'mountpoint=' + mountpoint,
+        source,
+        target
+    ], function _onZfs(err, stdout, stderr) {
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        opts.mountdirExists = true;
+        opts.datasetExists = true;
+
+        logLine('Created ' + target + ', and mounted on ' + mountpoint);
+        callback();
+    });
+}
+
+function doChrootMount(mountObj, callback) {
+    assert.object(mountObj, 'mountObj');
+    assert.string(mountObj.dest, 'mountObj.dest');
+    assert.string(mountObj.source, 'mountObj.source');
+    assert.func(callback, 'callback');
+
+    child_process.execFile('/usr/bin/mkdir', [
+        '-p', mountObj.dest
+    ], function _onMkdir(err, stdout, stderr) {
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        child_process.execFile('/usr/sbin/mount', [
+            '-F', 'lofs',
+            '-r', mountObj.source,
+            mountObj.dest
+        ], function _onMount(_err, _stdout, _stderr) {
+            if (_err) {
+                logExecError(_err, _stdout, _stderr);
+                callback(_err);
+                return;
+            }
+
+            logLine('Mounted ' + mountObj.source + ' on ' + mountObj.dest);
+            callback();
+        });
+    });
+}
+
+function setupChroot(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.func(callback, 'callback');
+
+    var mounts;
+
+    mounts = CHROOT_MOUNT_DIRS.map(function _mapDir(dir) {
+        return {
+            dest: opts.mountpoint + '/root' + dir,
+            source: dir
+        };
+    });
+
+    vasync.forEachParallel({
+        func: doChrootMount,
+        inputs: mounts
+    }, function _onMounted(err) {
+        if (!err) {
+            opts.chrootIsMounted = true;
+        }
+        callback(err);
+    });
+}
+
+//
+// In the chroot environment that we run pkg_add in later, it will use the
+// etc/resolv.conf in the chroot to resolve any http_proxy IP addresses.
+// If there's a local http proxy that's not in the DNS configured in the
+// chroot environment (likely 8.8.8.8) then the pkg_add operation will fail,
+// so resolve that hostname now, and modify process.env.http_proxy accordingly.
+//
+function replaceHttpProxy(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.func(callback, 'callback');
+
+    if (!process.env.http_proxy){
+        callback();
+        return;
+    }
+    var parsed = url.parse(process.env.http_proxy);
+    var hostname = parsed.hostname;
+    vasync.waterfall([
+        function(cb) {
+            dns.lookup(hostname, function(err, addr){
+                if (err) {
+                    logLine('Error: failed DNS lookup of $http_proxy host ' +
+                        hostname + ': ' + err);
+                }
+                cb(err, addr);
+            });
+        },
+        function(addr, cb) {
+            assert.string(addr, 'addr');
+            logLine('replacing ' + hostname + ' in http_proxy with ' + addr);
+            process.env.http_proxy = process.env.http_proxy.replace(
+                hostname, addr);
+            logLine('http_proxy now set to ' + process.env.http_proxy);
+            cb();
+        }
+    ]);
+    callback();
+}
+
+function installPkgsrcPkgs(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.array(opts.packages, 'opts.packages');
+    assert.func(callback, 'callback');
+
+    var child;
+
+    if (opts.packages.length === 0) {
+        logLine('No packages to install, skipping pkgsrc');
+        callback();
+        return;
+    }
+
+    logLine('Installing pkgsrc pkgs: ' + opts.packages.join(', '));
+
+    child = child_process.spawn('/usr/sbin/chroot', [
+        opts.mountpoint + '/root',
+        '/opt/local/sbin/pkg_add', '-U'
+    ].concat(opts.packages), {
+        stdio: ['ignore', process.stdout, process.stderr]
+    });
+
+    child.on('close', function _onRsync(code) {
+        logLine('Child pkgsrc chroot exited with code ' + code);
+        if (code !== 0) {
+            callback(new Error('failed to install packages'));
+            return;
+        }
+        logLine('Installed ' + opts.packages.join(', '));
+        callback();
+    });
+}
+
+function loadPkgsrcPkgs(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.func(callback, 'callback');
+
+    child_process.execFile('/usr/sbin/chroot', [
+        opts.mountpoint + '/root',
+        '/opt/local/sbin/pkg_info', '-a'
+    ], {
+        maxBuffer: 10 * 1024 * 1024
+    }, function _onPkgInfo(err, stdout, stderr) {
+        var pkgLines;
+        var pkgString;
+
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        pkgLines = stdout.trim().split('\n').sort();
+        pkgString = JSON.stringify(pkgLines.map(function _mapPkg(pkg) {
+            return (pkg.split(' ')[0]);
+        }), null, 4);
+
+        logLine('Packages:\n' + indent(pkgString));
+
+        callback();
+    });
+}
+
+function doChrootUmount(mountObj, callback) {
+    assert.object(mountObj, 'mountObj');
+    assert.string(mountObj.dest, 'mountObj.dest');
+    assert.func(callback, 'callback');
+
+    child_process.execFile('/usr/sbin/umount', [
+        mountObj.dest
+    ], function _onUmount(err, stdout, stderr) {
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        logLine('Umounted ' + mountObj.dest);
+        callback();
+    });
+}
+
+function unsetupChroot(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.optionalBool(opts.chrootIsMounted, 'opts.chrootIsMounted');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.func(callback, 'callback');
+
+    var mounts;
+
+    mounts = CHROOT_MOUNT_DIRS.map(function _mapDir(dir) {
+        return {
+            dest: opts.mountpoint + '/root' + dir
+        };
+    });
+
+    vasync.forEachParallel({
+        func: doChrootUmount,
+        inputs: mounts
+    }, function _onUmounted(err) {
+        if (!err) {
+            delete opts.chrootIsMounted;
+        }
+        callback(err);
+    });
+}
+
+function installFiles(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.dir, 'opts.dir');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.optionalBool(opts.verbose, 'opts.verbose');
+    assert.func(callback, 'callback');
+
+    var child;
+    var rsyncArgs = '-a';
+
+    if (opts.verbose) {
+        rsyncArgs = '-vaP';
+    }
+
+    logLine('Copying files from ' + opts.dir + ' to ' + opts.mountpoint);
+
+    child = child_process.spawn('/usr/bin/rsync', [
+        rsyncArgs,
+        opts.dir + '/',
+        opts.mountpoint + '/root/'
+    ], {
+        stdio: ['ignore', process.stdout, process.stderr]
+    });
+
+    child.on('close', function _onRsync(code) {
+        logLine('Child rsync exited with code ' + code);
+        callback();
+    });
+}
+
+function cleanupZoneAnalog(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.func(callback, 'callback');
+
+    // Filling out this function was originally marked as
+    // a todo item, but it's unclear what we had intended to
+    // clean up. We're leaving this code here for now to declare
+    // that open question.
+    callback();
+}
+
+function createImage(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.string(opts.dataroot, 'opts.dataroot');
+    assert.uuid(opts.image, 'opts.image');
+    assert.string(opts.image_prefix, 'opts.image_prefix');
+    assert.object(opts.manifest, 'opts.manifest');
+    assert.string(opts.manifest.name, 'opts.manifest.name');
+    assert.string(opts.manifest.version, 'opts.manifest.version');
+    assert.string(opts.target, 'opts.target');
+    assert.uuid(opts.vmUuid, 'opts.vmUuid');
+    assert.func(callback, 'callback');
+
+    opts.cli.tool.createImage({
+        compression: 'gzip',
+        incremental: true,
+        logCb: logLine,
+        manifest: opts.manifest,
+        savePrefix: '/tmp/' + opts.image_prefix + '-' + opts.manifest.version,
+        vmGet: function _vmGet(vmUuid, _, cb) {
+            cb(null, {
+                image_uuid: opts.image,
+                state: 'stopped',
+                uuid: opts.vmUuid,
+                zfs_filesystem: opts.target,
+                zpool: opts.dataroot
+            });
+        },
+        vmUuid: opts.vmUuid
+    }, callback);
+}
+
+function destroyZoneAnalog(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.optionalBool(opts.datasetExists, 'opts.datasetExists');
+    assert.string(opts.target, 'opts.target');
+    assert.func(callback, 'callback');
+
+    child_process.execFile('/usr/sbin/zfs', [
+        'destroy',
+        opts.target
+    ], function _onZfs(err, stdout, stderr) {
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        delete opts.datasetExists;
+        logLine('Destroyed ' + opts.target);
+        callback();
+    });
+}
+
+function destroyMountdir(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.optionalBool(opts.mountdirExists, 'opts.mountdirExists');
+    assert.string(opts.mountpoint, 'opts.mountpoint');
+    assert.func(callback, 'callback');
+
+    child_process.execFile('/usr/bin/rmdir', [
+        opts.mountpoint
+    ], function _onRmdir(err, stdout, stderr) {
+        if (err) {
+            logExecError(err, stdout, stderr);
+            callback(err);
+            return;
+        }
+
+        delete opts.mountdirExists;
+        logLine('Deleted ' + opts.mountpoint);
+        callback();
+    });
+}
+
+function buildImage(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.object(opts.manifest, 'opts.manifest');
+    assert.string(opts.image_prefix, 'opts.image_prefix');
+    assert.string(opts.manifest.name, 'opts.manifest.name');
+    assert.string(opts.manifest.version, 'opts.manifest.version');
+    assert.func(callback, 'callback');
+
+    if (!opts.manifest.owner) {
+        opts.manifest.owner = '00000000-0000-0000-0000-000000000000';
+    }
+
+    if (!opts.manifest.tags) {
+        opts.manifest.tags = {};
+    }
+    if (!opts.manifest.tags.smartdc_service) {
+        opts.manifest.tags.smartdc_service = true;
+    }
+
+    if (!opts.manifest.requirements) {
+        opts.manifest.requirements = {};
+    }
+    if (!opts.manifest.requirements.min_platform) {
+        opts.manifest.requirements.min_platform = {};
+    }
+    // there is a node uname module, but this is not performance-critical
+    // code, so spawn is fine.
+    if (!opts.manifest.requirements.min_platform['7.0']) {
+        var vers = child_process.spawnSync(
+            '/usr/bin/uname', ['-v']).stdout.toString().trim();
+        // we expect a string like joyent_20180807T230146Z
+        if (vers.lastIndexOf('_') >= 0) {
+            vers = vers.split('_').slice(1).join('_');
+        }
+        opts.manifest.requirements.min_platform['7.0'] = vers;
+    }
+
+    logLine('Starting build for %s (%s)',
+        opts.manifest.name, opts.manifest.version);
+
+    vasync.pipeline({
+        arg: opts,
+        funcs: [
+            ensureImage,
+            createZoneAnalog,
+            replaceHttpProxy,
+            installFiles,
+            setupChroot,
+            installPkgsrcPkgs,
+            loadPkgsrcPkgs,
+            unsetupChroot,
+            cleanupZoneAnalog,
+            createImage,
+            destroyZoneAnalog,
+            destroyMountdir
+        ]
+    }, function _onBuilt(err) {
+        if (!err) {
+            callback();
+            return;
+        }
+        console.error(JSON.stringify(err));
+
+        vasync.pipeline({
+            funcs: [
+                function _cleanupChroot(_, cb) {
+                    if (!opts.chrootIsMounted) {
+                        cb();
+                        return;
+                    }
+                    unsetupChroot(opts, function _onUnsetup(err) {
+                        // ignore errors, this is best effort.
+                        console.error('WARN: failed to unsetup chroot: ' +
+                            err.message);
+                        cb();
+                    });
+                }, function _destroyZoneAnalog(_, cb) {
+                    if (!opts.datasetExists) {
+                        cb();
+                        return;
+                    }
+                    destroyZoneAnalog(opts, function _onDestroy(err) {
+                        // ignore errors, this is best effort.
+                        console.error('WARN: failed to destroy zone analog: ' +
+                            err.message);
+                        cb();
+                    });
+                }, function _destroyMountdir(_, cb) {
+                    if (!opts.mountdirExists) {
+                        cb();
+                        return;
+                    }
+                    destroyMountdir(opts, function _onDestroy(err) {
+                        // ignore errors, this is best effort.
+                        console.error('WARN: failed to destroy mount dir: ' +
+                            err.message);
+                        cb();
+                    });
+                }
+            ]
+        }, function _onCleanup() {
+            // Ignore err, since we did what we could and we're already
+            // returning the original err.
+            callback(err);
+        });
+    });
+}
+
+function usage(help, writer) {
+    assert.string(help, 'help');
+    assert.func(writer, 'writer');
+
+    writer('Usage: %s [OPTIONS]\n' + 'Options:\n' + help, PROGNAME);
+}
+
+function main() {
+    var help;
+    var opts;
+    var packageJson = path.join(path.dirname(__dirname), 'package.json');
+    var packages = [];
+    var parser = dashdash.createParser({ options: CLI_OPTIONS });
+    var manifest;
+    var missingRequired = false;
+    var version;
+
+    help = parser.help({includeEnv: true}).trimRight();
+
+    try {
+        opts = parser.parse(process.argv);
+    } catch (e) {
+        console.error('%s: ERROR: %s', PROGNAME, e.message);
+        process.exit(1);
+    }
+
+    if (opts.help) {
+        usage(help, console.log);
+        process.exit(0);
+    }
+
+    if (opts.version) {
+        version = JSON.parse(fs.readFileSync(packageJson)).version;
+        console.log(version);
+        process.exit(0);
+    }
+
+    ['dir', 'image', 'manifest'].forEach(function _checkRequiredArg(arg) {
+        if (!opts[arg]) {
+            console.error('%s: FATAL: %s is required.', PROGNAME, arg);
+            missingRequired = true;
+        }
+    });
+    if (missingRequired) {
+        usage(help, console.error);
+        process.exit(2);
+    }
+
+    try {
+        manifest = JSON.parse(opts.manifest);
+    } catch (e) {
+        console.error('%s: FATAL: failed to parse manifest: ' + e.message,
+            PROGNAME);
+        process.exit(2);
+    }
+
+    if (!manifest.hasOwnProperty('name') || !manifest.hasOwnProperty('version')) {
+        console.error('%s: FATAL: manifest must include name and version',
+            PROGNAME);
+        process.exit(2);
+    }
+
+    if (opts.packages) {
+        if (!opts.packages.match(PKGS_REGEX)) {
+            console.error('%s: FATAL: invalid packages specification.');
+            process.exit(2);
+        }
+
+        packages = opts.packages.split(',');
+    }
+
+    // TODO check that dir is a dir
+    // TODO check that image is a uuid
+
+    buildImage({
+        dir: opts.dir,
+        image: opts.image,
+        image_prefix: opts.image_prefix,
+        manifest: manifest,
+        packages: packages,
+        verbose: opts.verbose
+    }, function _onBuild(err) {
+        if (err) {
+            logLine('Build failed: ' + err.message);
+        } else {
+            logLine('Build complete');
+        }
+    });
+}
+
+main();
diff --git a/tools/buildimage/lib/imgadm/README.md b/tools/buildimage/lib/imgadm/README.md
new file mode 100644
index 0000000..491da68
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/README.md
@@ -0,0 +1,28 @@
+The initial imgadm import was imgadm from
+smartos-live@c6f5e9955adbc45688074ab1b8cac5d340262c56
+
+The following modifications were made:
+ - we should allow running from a non-global zone
+ - we should not use platform node.js modules
+   (locker.js and zfs.js, mentioned below)
+ - we should allow the caller to set the default zpool name
+ - we should allow the use of 'pigz' if it exists to
+   create .gz files, falling back to 'gzip' otherwise
+ - we should attempt to locate a delegated dataset within
+   this instance.
+
+A recursive diff of the changes are available in imgadm.patch
+
+The files from smartos-live.git duplicated in this directory are:
+
+smartos-live.git:src/img
+smartos-live.git:src/node_modules/locker.js
+smartos-live.git:src/node_modules/zfs.js
+
+package.json for this copy of imgadm differs from the smartos-live.git
+instance in order to pull in modern node-sdc-clients, needed so that
+imgadm (via buildimage) can compile using modern versions of node.
+
+We also need a more modern bunyan and restify to avoid build errors
+in dtrace-provider when compiling with node v6.
+
diff --git a/tools/buildimage/lib/imgadm/imgadm.patch b/tools/buildimage/lib/imgadm/imgadm.patch
new file mode 100644
index 0000000..2e41ba9
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/imgadm.patch
@@ -0,0 +1,305 @@
+Only in imgadm-smartos-live-c6f5e9955adbc4: CHANGES.md
+Only in imgadm-smartos-live-c6f5e9955adbc4: Makefile
+diff -r imgadm-smartos-live-c6f5e9955adbc4/README.md imgadm/README.md
+1c1,9
+< # imgadm -- manage VM images
+---
+> The initial imgadm import was imgadm from
+> smartos-live@c6f5e9955adbc45688074ab1b8cac5d340262c56
+> and is completely unmodified, other than the details below:
+> 
+> lib/locker.js and lib/zfs.js both come from smartos-live.git
+> 
+> package.json for this copy of imgadm differs from the smartos-live.git
+> instance in order to pull in modern node-sdc-clients, needed so that
+> imgadm (via buildimage) can compile using modern versions of node.
+3,7c11,12
+< `imgadm` is a tool for managing images on a local headnode or compute node. It
+< can import and destroy local images, present information about how they're
+< being used.  To find and install new images, imgadm speaks to a server
+< implementing the IMGAPI. The default and canonical IMGAPI server is the Joyent
+< Images repository at <https://images.joyent.com>.
+---
+> We also need a more modern bunyan and restify to avoid build errors
+> in dtrace-provider when compiling with node v6.
+9,70d13
+< 
+< # Test Suite
+< 
+<     /usr/img/test/runtests
+< 
+< This can only be run in the global zone (GZ).
+< 
+< 
+< # Development
+< 
+< The src/img tree has not binary components, so you can get away
+< with faster edit/test cycle than having to do a full smartos platform
+< build and rebooting on it. Here is how:
+< 
+<     # On the target SmartOS GZ (e.g. MY-SMARTOS-BOX), make /usr/img
+<     # and /usr/man/man1m writeable for testing:
+<     ssh root@MY-SMARTOS-BOX
+<     rm -rf /var/tmp/img \
+<         && cp -RP /usr/img /var/tmp/img \
+<         && mount -O -F lofs /var/tmp/img /usr/img \
+<         && rm -rf /var/tmp/man1m \
+<         && cp -RP /usr/man/man1m /var/tmp/man1m \
+<         && mount -O -F lofs /var/tmp/man1m /usr/man/man1m
+< 
+<     # On a dev machine:
+<     # Get a clone of the repo.
+<     git clone git@github.com:joyent/smartos-live.git
+<     cd src/img
+< 
+<     # Make edits, e.g. change the version:
+<     vi package.json
+< 
+<     # Build a dev install image (in /var/tmp/img-install-image)
+<     # and rsync that to the target node.
+<     ./tools/dev-install root@MY-SMARTOS-BOX
+< 
+<     # Test that it worked by checking for the version change:
+<     ssh root@MY-SMARTOS-BOX imgadm --version
+< 
+<     # Or run the test suite:
+<     ssh root@MY-SMARTOS-BOX /var/img/test/runtests
+< 
+< 
+< Before commits, please (a) run the test suite on a test box per the notes
+< above and (b) maintain style by running `make check`.
+< 
+< 
+< # /var/imgadm/imgadm.conf
+< 
+< "/var/imgadm/imgadm.conf" is imgadm's config file. Typically it should not be
+< edited as most configuration is done via `imgadm ...` commands. For example,
+< the list of image repository (IMGAPI) "sources" is controlled via
+< `imgadm sources ...`.
+< 
+<     VAR             DESCRIPTION
+<     sources         Array of image repository (IMGAPI) sources used for
+<                     `imgadm avail`, `imgadm import`, etc. Use `imgadm sources`
+<                     to control this value.
+<     upgradedToVer   Automatically set by `imgadm` as it does any necessary
+<                     internal DB migrations.
+<     userAgentExtra  Optional string that is appended to the User-Agent header
+<                     when talking to an IMGAPI source.
+Only in imgadm-smartos-live-c6f5e9955adbc4: TODO.txt
+Only in imgadm-smartos-live-c6f5e9955adbc4: etc
+diff -r imgadm-smartos-live-c6f5e9955adbc4/lib/cli.js imgadm/lib/cli.js
+1100c1100
+<     var zpool = opts.P || common.DEFAULT_ZPOOL;
+---
+>     var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+1135c1135
+<             + common.DEFAULT_ZPOOL + '".'
+---
+>             + 'zones/<uuid>/data".'
+1163c1163
+<     var zpool = opts.P || common.DEFAULT_ZPOOL;
+---
+>     var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+1247c1247
+<             + common.DEFAULT_ZPOOL + '".'
+---
+>             + 'zones/<uuid>/data".'
+1269c1269
+<     var zpool = opts.P || common.DEFAULT_ZPOOL;
+---
+>     var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+1303c1303
+<             + common.DEFAULT_ZPOOL + '".'
+---
+>             + 'zones/<uuid>/data".'
+1326c1326
+<     var zpool = opts.P || common.DEFAULT_ZPOOL;
+---
+>     var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+1351a1352,1353
+>                 var logCb = opts.logCb || console.log;
+> 
+1362c1364
+<                     console.log('Image %s%s is already installed, skipping',
+---
+>                     logCb('Image %s%s is already installed, skipping',
+1480c1482
+<             + common.DEFAULT_ZPOOL + '".'
+---
+>             + 'zones/<uuid>/data".'
+1519c1521
+<     var zpool = opts.P || common.DEFAULT_ZPOOL;
+---
+>     var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+1621c1623
+<             + common.DEFAULT_ZPOOL + '".'
+---
+>             + 'zones/<uuid>/data".'
+diff -r imgadm-smartos-live-c6f5e9955adbc4/lib/common.js imgadm/lib/common.js
+23c23
+<  * Copyright (c) 2013, Joyent, Inc. All rights reserved.
+---
+>  * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+51d50
+< var DEFAULT_ZPOOL = 'zones';
+816d814
+<     DEFAULT_ZPOOL: DEFAULT_ZPOOL,
+diff -r imgadm-smartos-live-c6f5e9955adbc4/lib/imgadm.js imgadm/lib/imgadm.js
+55c55
+< var lock = require('/usr/img/node_modules/locker').lock;
+---
+> var lock = require('./locker.js').lock;
+65c65
+< var zfs = require('/usr/node/node_modules/zfs.js').zfs;
+---
+> var zfs = require('./zfs.js').zfs;
+86a87
+> var DEFAULT_SDC_VERSION = '7.0';
+91,92c92,95
+< var VMADM_FS_NAME_RE = /^([a-zA-Z][a-zA-Z\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})(-disk\d+)?$/;
+< var VMADM_IMG_NAME_RE = /^([a-zA-Z][a-zA-Z\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})$/;
+---
+> // In zones, we don't have 'SDC Version' in sysinfo, but we know
+> // we're always at least SDC 7.0.
+> var VMADM_FS_NAME_RE = /^([a-zA-Z0-9][a-zA-Z0-9\/\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})(-disk\d+)?$/;
+> var VMADM_IMG_NAME_RE = /^([a-zA-Z0-9][a-zA-Z0-9\/\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})$/;
+141c144
+<     var platVer = opts.sysinfo['SDC Version'] || '6.5';
+---
+>     var platVer = opts.sysinfo['SDC Version'] || DEFAULT_SDC_VERSION;
+409a413,467
+>     var zonename;
+> 
+>     function findZonename(next) {
+>         execFile('/usr/bin/zonename', function _zonename(err, stdout, stderr) {
+>             if (!err) {
+>                 zonename = stdout.trim();
+>                 if (zonename === 'global') {
+>                     cb(new errors.UsageError('this version of imgadm only '
+>                         + 'supports non-global zones'));
+>                     return;
+>                 }
+>             }
+>             next(err);
+>         });
+>     }
+> 
+>     function findZonesPool(next) {
+>         execFile('/usr/sbin/zpool', [
+>             'list',
+>             '-Hpo',
+>             'name'
+>         ], function _onZpoolList(err, stdout, stderr) {
+>             if (!err) {
+>                 if (stdout.trim() !== 'zones') {
+>                     cb(new errors.UsageError('this version of imgadm only '
+>                         + 'supports zpools named "zones"'));
+>                     return;
+>                 }
+>             }
+>             next(err);
+>         });
+>     }
+> 
+>     function findDelegated(next) {
+>         var dsname = 'zones/' + zonename + '/data';
+> 
+>         execFile('/usr/sbin/zfs', [
+>             'list',
+>             '-Hpo',
+>             'name',
+>             dsname
+>         ], function _onZpoolList(err, stdout, stderr) {
+>             if (!err) {
+>                 if (stdout.trim() !== dsname) {
+>                     cb(new errors.UsageError('this version of imgadm only '
+>                         + 'supports zones with delegated datasets named '
+>                         + '"data"'));
+>                     return;
+>                 }
+>                 self.DEFAULT_ZPOOL = common.DEFAULT_ZPOOL = dsname;
+>             }
+>             next(err);
+>         });
+>     }
+> 
+454a513,515
+>         findZonename,
+>         findZonesPool,
+>         findDelegated,
+873a935
+> 
+875a938
+> 
+2652a2716,2719
+>                 if (chunk.toString()
+>                     .match(/SMF Initialization problems..svc:\//)) {
+>                     return;
+>                 }
+2656a2724,2727
+>                 if (chunk.toString()
+>                     .match(/NFS plugin problem with SMF repository:/)) {
+>                     return;
+>                 }
+3304a3376,3377
+>     assert.optionalFunc(options.vmGet, 'options.vmGet');
+> 
+3326c3399,3401
+<             common.vmGet(vmUuid, {log: log}, function (err, vm) {
+---
+>             var vmGet = options.vmGet || common.vmGet;
+> 
+>             vmGet(vmUuid, {log: log}, function (err, vm) {
+3835c3910,3916
+<                 compressor = spawn('/usr/bin/gzip', ['-cfq']);
+---
+>                 if (fs.existsSync('/opt/local/bin/pigz')) {
+>                     logCb('Compressing image with pigz');
+>                     compressor = spawn('/opt/local/bin/pigz', ['-cfq']);
+>                 } else {
+>                     logCb('Compressing image with gzip');
+>                     compressor = spawn('/usr/bin/gzip', ['-cfq']);
+>                 }
+Only in imgadm/lib: locker.js
+Only in imgadm/lib: zfs.js
+Only in imgadm-smartos-live-c6f5e9955adbc4: man
+Only in imgadm-smartos-live-c6f5e9955adbc4: node_modules
+Only in imgadm: package-lock.json
+diff -r imgadm-smartos-live-c6f5e9955adbc4/package.json imgadm/package.json
+11c11
+<     "bunyan": "1.3.5",
+---
+>     "bunyan": "1.8.12",
+17a18
+>     "lockfd": "2.0.1",
+22c23
+<     "restify": "2.8.5",
+---
+>     "restify": "7.2.2",
+24c25
+<     "sdc-clients": "git://github.com/joyent/node-sdc-clients.git#29dea8e",
+---
+>     "sdc-clients": "git://github.com/joyent/node-sdc-clients.git#28209ab",
+Only in imgadm-smartos-live-c6f5e9955adbc4/sbin: chroot-gtar
+Only in imgadm-smartos-live-c6f5e9955adbc4/sbin: gtar-unlink-dir
+diff -r imgadm-smartos-live-c6f5e9955adbc4/sbin/imgadm imgadm/sbin/imgadm
+24c24
+<  * Copyright (c) 2013, Joyent, Inc. All rights reserved.
+---
+>  * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+31d30
+< var onlyif = require('/usr/node/node_modules/onlyif');
+37,44c36,37
+<     onlyif.rootInSmartosGlobal(function (onlyifErr) {
+<         if (onlyifErr) {
+<             console.error('imgadm: error: cannot run: ' + onlyifErr);
+<             process.exit(2);
+<         }
+<         var cli = new CLI();
+<         cmdln.main(cli, {argv: argv, showCode: true});
+<     });
+---
+>     var cli = new CLI();
+>     cmdln.main(cli, {argv: argv, showCode: true});
+Only in imgadm-smartos-live-c6f5e9955adbc4: test
+Only in imgadm-smartos-live-c6f5e9955adbc4: tools
diff --git a/tools/buildimage/lib/imgadm/lib/IMG.js b/tools/buildimage/lib/imgadm/lib/IMG.js
new file mode 100644
index 0000000..1a4ebf6
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/IMG.js
@@ -0,0 +1,81 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ */
+
+/*
+ * The no-binary deps node.js interface to `imgadm`.
+ *
+ * Generally it is preferred that `imgadm` (the CLI) is the promised interface
+ * to imgadm. That saves us from node binary module dependencies, which is
+ * difficult to manage for compatibility. However, sometimes perf concerns
+ * dominate. This IMG.js interface was added for `vmadm` and `vminfod` to
+ * use when perf is a concern. The API here is intentionally small and
+ * limited.
+ */
+
+var p = console.log;
+var assert = require('assert-plus');
+
+var Database = require('./database');
+var errors = require('./errors');
+
+
+// ---- the node.js API (intentionally limited and small)
+
+var IMG = {};
+
+/**
+ * Quickly (but with limitations and potential false positives) get details
+ * (mostly the manifest) on an installed image.
+ *
+ * This is *similar* to `IMGAPI.prototype.getImage` with these diffs:
+ * - It doesn't do `zfs list` which makes it faster.
+ * - It doesn't do `zfs list`, which means there can be false positives. The
+ *   imgadm database of metadata can be out of sync with zfs datasets.
+ *   ZFS is the authority.
+ * - It doesn't support the "children" option that `getImage` does.
+ */
+IMG.quickGetImage = function quickGetImage(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.uuid(opts.uuid, 'opts.uuid');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.optionalObject(opts.log, 'opts.log');
+    assert.func(cb, 'cb');
+
+    var db = new Database({log: opts.log});
+    db.loadImage({zpool: opts.zpool, uuid: opts.uuid}, function (err, img) {
+        if (err) {
+            cb(err);
+        } else if (Object.keys(img.manifest).length === 1) {
+            cb(new errors.ImageNotInstalledError(opts.zpool, opts.uuid));
+        } else {
+            cb(null, img);
+        }
+    });
+};
+
+
+// ---- exports
+
+module.exports = IMG;
diff --git a/tools/buildimage/lib/imgadm/lib/cli.js b/tools/buildimage/lib/imgadm/lib/cli.js
new file mode 100644
index 0000000..c7fc22c
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/cli.js
@@ -0,0 +1,2148 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ *
+ * The main entry point for an the imgadm CLI.
+ *
+ * Usage:
+ *      var cli = new CLI();
+ *      cmdln.main(cli, argv, {showCode: true});
+ */
+
+var p = console.warn;
+
+var assert = require('assert-plus');
+var async = require('async');
+var bunyan = require('bunyan');
+var child_process = require('child_process'),
+    spawn = child_process.spawn,
+    exec = child_process.exec;
+var Cmdln = require('cmdln').Cmdln;
+var fs = require('fs');
+var genUuid = require('node-uuid');
+var os = require('os');
+var path = require('path');
+var restify = require('restify');
+var rimraf = require('rimraf');
+var sprintf = require('extsprintf').sprintf;
+var tabula = require('tabula');
+var util = require('util'),
+    format = util.format;
+var vasync = require('vasync');
+
+var imgadm = require('./imgadm');
+var common = require('./common'),
+    objCopy = common.objCopy,
+    objMerge = common.objMerge,
+    NAME = common.NAME,
+    pathSlugify = common.pathSlugify,
+    assertUuid = common.assertUuid;
+var docker = require('./sources/docker');
+var errors = require('./errors');
+
+
+
+// ---- globals
+
+var pkg = require('../package.json');
+
+
+
+// ---- internal support functions
+
+/**
+ * Take CLI input args of the form FIELD=VALUE (or similar) and transform
+ * to an object of `filters` which can be used with `filterImagesInfo`.
+ */
+function filtersFromArgs(args) {
+    assert.arrayOfString(args, 'args');
+
+    var filters = {};
+    for (var i = 0; i < args.length; i++) {
+        var arg = args[i];
+        var idx = arg.indexOf('=');
+        if (idx === -1) {
+            throw new errors.UsageError(format(
+                'invalid filter: "%s" (must be of the form "field=value")',
+                arg));
+        }
+        var argVal = arg.slice(idx + 1);
+        if (argVal === 'true') {
+            argVal = true;
+        } else if (argVal === 'false') {
+            argVal = false;
+        }
+        filters[arg.slice(0, idx)] = argVal;
+    }
+    return filters;
+}
+
+/**
+ * Return a "row" with the manifest fields and a number of calculate
+ * convenience fields to be used for filtering and listing.
+ *
+ * Dev Note: Update the `do_list.help` docs below when changing row fields.
+ *
+ * Dev Note: this modifies `imageInfo.manifest` in-place.
+ */
+function rowFromImageInfo(imageInfo) {
+    assert.object(imageInfo, 'imageInfo');
+
+    var row = imageInfo.manifest;
+    if (row.published_at) {
+        // Just the date.
+        row.published_date = row.published_at.slice(0, 10);
+        row.pub = row.published_date;
+        // Normalize on no milliseconds.
+        row.published = row.published_at.replace(/\.\d+Z$/, 'Z');
+    }
+    row.source = imageInfo.source;
+    row.clones = imageInfo.clones;
+    row.zpool = imageInfo.zpool;
+    if (row.files && row.files[0]) {
+        row.size = row.files[0].size;
+    }
+
+    if (row.type === 'docker') {
+        row.docker_id = row.tags['docker:id'];
+        row.docker_short_id = row.docker_id.slice(0, 12);
+        row.docker_repo = row.tags['docker:repo'];
+        row.docker_tags = Object.keys(row.tags).filter(function (t) {
+            return t.slice(0, 11) === 'docker:tag:';
+        }).map(function (t) { return t.slice(11); });
+    }
+
+    return row;
+}
+
+/* BEGIN JSSTYLED */
+var rowFieldsHelp = (
+      '    Any of the manifest fields (see `imgadm {{cmd}} -j` output) plus the\n'
+    + '    following computed fields for convenience.\n'
+    + '\n'
+    + '    published_date, pub       just the date part of `published_at`\n'
+    + '    published                 `published_at` with the milliseconds removed\n'
+    + '    source                    the source URL, if available\n'
+    + '    clones                    the number of clones (dependent images and VMs)\n'
+    + '    size                      the size, in bytes, of the image file\n'
+    + '\n'
+    + '    In addition if this is a docker image, then the following:\n'
+    + '\n'
+    + '    docker_id                 the full docker id string\n'
+    + '    docker_short_id           the short 12 character docker id\n'
+    + '    docker_repo               the docker repo from which this image\n'
+    + '                              originates, if available\n'
+    + '    docker_tags               a JSON array of docker repo tags, if available\n');
+/* END JSYSTYLED */
+
+
+function filterImagesInfo(imagesInfo, filters) {
+    assert.arrayOfObject(imagesInfo, 'imagesInfo');
+    assert.object(filters, 'filters');
+
+    var fields = Object.keys(filters);
+    if (fields.length === 0) {
+        return imagesInfo;
+    }
+
+    var filtered = [];
+    for (var j = 0; j < imagesInfo.length; j++) {
+        var row = rowFromImageInfo(imagesInfo[j]);
+        var keep = true;
+        for (var f = 0; f < fields.length; f++) {
+            var field = fields[f];
+            var val = filters[field];
+            var lookups = field.split(/\./g);
+            var actual = row;
+            for (var k = 0; k < lookups.length; k++) {
+                actual = actual[lookups[k]];
+                if (actual === undefined) {
+                    break;
+                }
+            }
+            if (actual === undefined) {
+                keep = false;
+                break;
+            } else if (typeof (val) === 'boolean') {
+                if (val !== actual) {
+                    keep = false;
+                    break;
+                }
+            } else if (val[0] === '~') {
+                if (actual.indexOf(val.slice(1)) === -1) {
+                    keep = false;
+                    break;
+                }
+            } else {
+                if (String(actual) !== val) {
+                    keep = false;
+                    break;
+                }
+            }
+        }
+        if (keep) {
+            filtered.push(imagesInfo[j]);
+        }
+    }
+    return filtered;
+}
+
+
+function listImagesInfo(imagesInfo, opts) {
+    assert.arrayOfObject(imagesInfo, 'imagesInfo');
+    assert.optionalObject(opts, 'opts');
+    if (!opts) {
+        opts = {};
+    }
+    assert.optionalBool(opts.json, 'opts.json');
+    assert.optionalBool(opts.skipHeader, 'opts.skipHeader');
+    assert.optionalBool(opts.docker, 'opts.docker');
+    assert.optionalArrayOfString(opts.columns, 'opts.columns');
+    assert.optionalArrayOfString(opts.sort, 'opts.sort');
+
+    if (opts.json) {
+        console.log(JSON.stringify(imagesInfo, null, 2));
+    } else {
+        var rows = imagesInfo.map(
+            function (imageInfo) { return rowFromImageInfo(imageInfo); });
+
+        /**
+         * `docker images`-like output:
+         * - only docker images
+         * - one row per *tag*
+         * - skip "non-head" images (see docker/graph/list.go)
+         */
+        if (opts.docker) {
+            var i, row;
+            var isOriginFromUuid = {};
+            for (i = 0; i < rows.length; i++) {
+                row = rows[i];
+                if (isOriginFromUuid[row.uuid] === undefined) {
+                    isOriginFromUuid[row.uuid] = false;
+                }
+                if (row.origin) {
+                    isOriginFromUuid[row.origin] = true;
+                }
+            }
+            var dRows = [];
+            for (i = 0; i < rows.length; i++) {
+                row = rows[i];
+                if (row.type !== 'docker') {
+                    continue;
+                }
+                var isHead = !isOriginFromUuid[row.uuid];
+                if (!isHead) {
+                    continue;
+                }
+                (row.docker_tags.length ? row.docker_tags : [null]).forEach(
+                    function (dTag) {
+                        var dRow = objCopy(row);
+                        dRow.docker_tag = dTag;
+                        dRows.push(dRow);
+                    });
+            }
+            rows = dRows;
+
+            // Override display opts.
+            opts.columns = [
+                {name: 'UUID', lookup: 'uuid'},
+                {name: 'REPOSITORY', lookup: 'docker_repo'},
+                {name: 'TAG', lookup: 'docker_tag'},
+                {name: 'IMAGE_ID', lookup: 'docker_short_id'},
+                {name: 'CREATED', lookup: 'published'}
+            ];
+            opts.sort = ['published_at'];
+        }
+
+        tabula(rows, {
+            skipHeader: opts.skipHeader,
+            columns: opts.columns,
+            sort: opts.sort
+        });
+    }
+}
+
+
+
+// ---- CLI object
+
+/**
+ * Create an imgadm CLI instance.
+ */
+function CLI() {
+    Cmdln.call(this, {
+        name: NAME,
+        desc: pkg.description,
+        options: [
+            {names: ['help', 'h'], type: 'bool', help: 'Print help and exit.'},
+            {name: 'version', type: 'bool', help: 'Print version and exit.'},
+            {names: ['verbose', 'v'], type: 'bool',
+                help: 'Verbose output: trace-level logging, stack on error. '
+                    + 'See IMGADM_LOG_LEVEL envvar.'},
+            {name: 'E', type: 'bool',
+                help: 'On error, emit a structured JSON error object as the '
+                    + 'last line of stderr output.'}
+        ],
+        helpOpts: {
+            includeEnv: true,
+            minHelpCol: 30 /* line up with option help */
+        }
+    });
+}
+util.inherits(CLI, Cmdln);
+
+
+CLI.prototype.init = function init(opts, args, cb) {
+    var self = this;
+
+    /*
+     * Logging setup.
+     *
+     * - Log to stderr.
+     *   TODO: see sdcadm/vmadm for logging trace-level to separate files
+     *   for subsequent rollup and rotation.
+     * - By default we log at the 'warn' level. Intentionally that is
+     *   almost no logging.
+     * - use IMGADM_LOG_LEVEL=trace envvar to set to trace level and enable
+     *   source location (src=true) in log records
+     * - '-v|--verbose' or IMGADM_LOG_LEVEL=trace to set to trace-level
+     * - use IMGADM_LOG_LEVEL=<bunyan level> to set to a different level
+     * - '-E' to have a possible error be logged as the last single line
+     *   of stderr as a raw Bunyan log JSON record with an 'err'. I.e. in a
+     *   structured format more useful to automation tooling.
+     * - Include a `req_id` in log output. This is the ID for this imgadm
+     *   run. If `REQ_ID` envvar is set, then use that.
+     *
+     * Logging is in Bunyan (JSON) format so one needs to pipe via
+     * `bunyan` for readable output (at least until bunyan.js supports
+     * doing it inline). Admittedly this is a bit of a pain:
+     *
+     *      imgadm -v ... 2>&1 | bunyan
+     */
+    var req_id;
+    if (process.env.REQ_ID) {
+        req_id = process.env.REQ_ID;
+    } else if (process.env.req_id) {
+        req_id = process.env.req_id;
+    } else {
+        req_id = genUuid();
+    }
+    var log = bunyan.createLogger({
+        name: self.name,
+        streams: [
+            {
+                stream: process.stderr,
+                level: 'warn'
+            }
+        ],
+        // TODO hack serializers until
+        // https://github.com/mcavage/node-restify/pull/501 is fixed
+        // serializers: bunyan.stdSerializers,
+        serializers: restify.bunyan.serializers,
+        req_id: req_id
+    });
+    var IMGADM_LOG_LEVEL;
+    try {
+        if (process.env.IMGADM_LOG_LEVEL
+            && bunyan.resolveLevel(process.env.IMGADM_LOG_LEVEL))
+        {
+            IMGADM_LOG_LEVEL = process.env.IMGADM_LOG_LEVEL;
+        }
+    } catch (e) {
+        log.warn('invalid IMGADM_LOG_LEVEL=%s envvar (ignoring)',
+            process.env.IMGADM_LOG_LEVEL);
+    }
+    if (opts.verbose) {
+        log.level('trace');
+        log.src = true;
+    } else if (IMGADM_LOG_LEVEL) {
+        log.level(IMGADM_LOG_LEVEL);
+        if (IMGADM_LOG_LEVEL === 'trace') {
+            log.src = true;
+        }
+    }
+    self.log = log;
+
+    // Log the invocation args (trim out dashdash meta vars).
+    var trimmedOpts = common.objCopy(opts);
+    delete trimmedOpts._args;
+    delete trimmedOpts._order;
+    this.log.debug({opts: trimmedOpts, args: args, cli: true}, 'cli init');
+
+    // Error printing options.
+    if (log.level() <= bunyan.DEBUG) {
+        self.showErrStack = true;
+    }
+    self.structuredErr = opts.E;
+
+    if (opts.version) {
+        console.log(self.name + ' ' + common.getVersion());
+        cb(false);
+        return;
+    }
+
+    // Cmdln class handles `opts.help`.
+    Cmdln.prototype.init.call(this, opts, args, function (err) {
+        if (err || err === false) {
+            cb(err);
+            return;
+        }
+        imgadm.createTool({log: self.log}, function (createErr, tool) {
+            if (createErr) {
+                cb(createErr);
+                return;
+            }
+            self.tool = tool;
+            cb();
+        });
+    });
+};
+
+
+CLI.prototype.fini = function fini(subcmd, err, cb) {
+    /*
+     * We want to log these `cli:true` entry and exits for CLI usage and
+     * we want to the exitStatus -- which means some duplication (see
+     * `cmdln.main` as well) on pulling it out, unfortunately.
+     */
+    var exitStatus = (err ? err.exitStatus || 1 : 0);
+    this.log.debug({subcmd: subcmd, exitStatus: exitStatus, cli: true},
+        'cli exit');
+
+    /*
+     * Handle `-E`: last line stderr is a structured JSON object
+     * with the error.
+     */
+    if (err && this.structuredErr) {
+        this.log.error(err, err.message);
+        this.showErr = false;
+    }
+
+    cb();
+};
+
+
+/**
+ * Override `Cmdln.printHelp` to have custom output for the commands.
+ * Manual, but much nicer.
+ */
+CLI.prototype.printHelp = function printHelp(cb) {
+    var lines = [];
+    if (this.desc) {
+        lines.push(this.desc);
+    }
+
+    lines = lines.concat([
+        '',
+        'Usage:',
+        '    {{name}} [<options>] <command> [<args>...]',
+        '    {{name}} help <command>',
+        ''
+    ]);
+    if (this.optParser.help) {
+        lines.push('Options:');
+        lines.push(this.optParser.help(this.helpOpts).trimRight());
+    }
+
+    lines = lines.concat([
+        '',
+        'Environment:',
+        '    IMGADM_LOG_LEVEL=<level>  Set log level to one of "trace",',
+        '                              "debug", "info", "warn" (default)',
+        '                              "error", "fatal".'
+    ]);
+
+    /* BEGIN JSSTYLED */
+    lines = lines.concat([
+        '',
+        'Commands:',
+        '    imgadm help [<command>]                help on commands',
+        '',
+        '    imgadm sources [<options>]             list and edit image sources',
+        '',
+        '    imgadm avail [<filters>]               list available images',
+        '    imgadm show <uuid|docker-repo-tag>     show manifest of an available image',
+        '',
+        '    imgadm import [-P <pool>] <image-id>   import image from a source',
+        '    imgadm install [-P <pool>] -m <manifest> -f <file>',
+        '                                           import from local image data',
+        '',
+        '    imgadm list [<filters>]                list installed images',
+        '    imgadm get [-P <pool>] <uuid>          info on an installed image',
+        '    imgadm update [<uuid>...]              update installed images',
+        '    imgadm delete [-P <pool>] <uuid>       remove an installed image',
+        '    imgadm ancestry [-P <pool>] <uuid>     show ancestry of an installed image',
+        '    imgadm vacuum [-n] [-f]                delete unused images',
+        '',
+        '    imgadm create <vm-uuid> [<manifest-field>=<value> ...] ...',
+        '                                           create an image from a VM',
+        '    imgadm publish -m <manifest> -f <file> <imgapi-url>',
+        '                                           publish an image to an image repo',
+        '',
+        'See `imgadm help <command>` or the imgadm(1m) man page for more details.'
+    ]);
+    /* END JSSTYLED */
+
+    console.log(lines.join('\n').replace(/{{name}}/g, this.name));
+    cb();
+};
+
+
+CLI.prototype.do_sources = function do_sources(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length > 0) {
+        cb(new errors.UsageError(
+            'unexpected args: ' + args.join(' ')));
+        return;
+    }
+
+    if (opts.add_docker_hub) {
+        opts.a = 'https://docker.io';
+        opts.type = 'docker';
+    }
+
+    var nActions = 0;
+    if (opts.e) nActions++;
+    if (opts.a) nActions++;
+    if (opts.d) nActions++;
+    if (opts.check) nActions++;
+    if (nActions > 1) {
+        cb(new errors.UsageError(
+            'cannot specify more than one of "-a", "-d", "-e", and "-c"'));
+        return;
+    }
+    var skipPingCheck = opts.force === true;
+
+    if (opts.e) {
+        var before = self.tool.sources.map(function (s) {
+            return s.toJSON();
+        });
+
+        var width = 0;
+        self.tool.sources.forEach(function (s) {
+            width = Math.max(width, s.url.length);
+        });
+        var template = format('%%-%ds  %%-%ds  %%s', Math.min(width, 50), 6);
+        var beforeText = before.map(function (s) {
+                var options = [];
+                if (s.insecure) {
+                    options.push('insecure');
+                }
+                return sprintf(template, s.url, s.type, options.join(','))
+                    .trimRight();
+            }).join('\n')
+            + '\n\n'
+            + '#\n'
+            + '# Enter sources, one per line, as follows:\n'
+            + '#\n'
+            + '#   URL TYPE [OPTIONS]\n'
+            + '#\n'
+            + '# where "TYPE" is one of "imgapi" (the default), "docker", or\n'
+            + '# "dsapi" (deprecated); and where "OPTIONS" is the literal\n'
+            + '# string "insecure" to skip TLS server certificate checking\n'
+            + '# for this source.\n'
+            + '#\n'
+            + '# Comments beginning with "#" are stripped.\n'
+            + '#\n';
+        var tmpPath = path.resolve(os.tmpDir(),
+            format('imgadm-sources-%s.txt', process.pid));
+        fs.writeFileSync(tmpPath, beforeText, 'utf8');
+
+        function sourcesInfoFromText(text) {
+            return text.trim().split(/\n/g)
+                .map(function (line) {
+                    return line.split('#')[0].trim();  // drop comments
+                }).filter(function (line) {
+                    return line.length;  // drop blank lines
+                }).map(function (line) {
+                    var parts = line.split(/\s+/g);
+                    if (!parts[1]) {
+                        parts[1] = 'imgapi'; // default type
+                    }
+                    var s = {url: parts[0], type: parts[1]};
+                    if (parts[2]) {
+                        // JSSTYLED
+                        var options = parts[2].trim().split(/,/g);
+                        for (var i = 0; i < options.length; i++) {
+                            switch (options[i]) {
+                            case 'insecure':
+                                s.insecure = true;
+                                break;
+                            default:
+                                throw new errors.UsageError('unknown source '
+                                    + 'option: ' + options[i]);
+                            }
+                        }
+                    }
+                    return s;
+                });
+        }
+
+        // TODO: re-editing if error adding (e.g. typo in type or whtaever)
+        var vi = spawn('/usr/bin/vi', ['-f', tmpPath], {stdio: 'inherit'});
+        vi.on('exit', function (code) {
+            if (code) {
+                console.warn('Error editing image sources: %s (ignoring)',
+                    code);
+                cb();
+                return;
+            }
+            var afterText = fs.readFileSync(tmpPath, 'utf8');
+            fs.unlinkSync(tmpPath);
+            if (afterText === beforeText) {
+                console.log('Image sources unchanged');
+                cb();
+                return;
+            }
+            try {
+                var after = sourcesInfoFromText(afterText);
+            } catch (ex) {
+                cb(ex);
+                return;
+            }
+            if (JSON.stringify(after) === JSON.stringify(before)) {
+                console.log('Image sources unchanged');
+                cb();
+                return;
+            }
+
+            self.log.info({after: after}, 'update sources');
+            self.tool.updateSources(after, skipPingCheck,
+                    function (err, changes) {
+                if (err) {
+                    cb(err);
+                } else {
+                    changes.forEach(function (change) {
+                        if (change.type === 'reorder') {
+                            console.log('Reordered image sources');
+                        } else if (change.type === 'add') {
+                            console.log('Added %s', change.source);
+                        } else if (change.type === 'del') {
+                            console.log('Deleted %s', change.source);
+                        }
+                    });
+                    cb();
+                }
+            });
+        });
+
+    } else if (opts.a) {
+        var addOpts = {
+            url: opts.a,
+            type: opts.type,
+            insecure: opts.insecure
+        };
+        this.tool.configAddSource(addOpts, skipPingCheck,
+            function (err, changed, source) {
+                if (err) {
+                    cb(err);
+                } else if (changed) {
+                    console.log('Added %s', source);
+                    cb();
+                } else {
+                    console.log('Already have %s, no change', source);
+                    cb();
+                }
+            }
+        );
+
+    } else if (opts.d) {
+        this.tool.configDelSourceUrl(opts.d, function (err, deleted) {
+            if (err) {
+                cb(err);
+            } else if (deleted) {
+                deleted.forEach(function (s) {
+                    console.log('Deleted %s', s);
+                });
+                cb();
+            } else {
+                console.log('Do not have image source "%s", no change',
+                    opts.d);
+                cb();
+            }
+        });
+
+    } else if (opts.check) {
+        var rows = [];
+        vasync.forEachParallel({
+            inputs: this.tool.sources,
+            func: function pingCheck(source, next) {
+                source.ping(function (pingErr) {
+                    var row = {url: source.url, type: source.type};
+                    if (pingErr) {
+                        row.ok = false;
+                        row.error = pingErr.toString();
+                    } else {
+                        row.ok = true;
+                    }
+                    rows.push(row);
+                    next(null);
+                });
+            }
+        }, function donePingChecks(err) {
+            if (err) {
+                cb(err);
+                return;
+            }
+            tabula(rows, {columns: ['url', 'type', 'ok', 'error']});
+            cb();
+        });
+
+    } else {
+        // The default flat list of source *urls*.
+        var sources = this.tool.sources.map(function (s) {
+            return {url: s.url, type: s.type, insecure: s.insecure};
+        });
+        if (opts.json) {
+            console.log(JSON.stringify(sources, null, 2));
+        } else if (opts.verbose) {
+            tabula(sources, {columns: ['url', 'type', 'insecure']});
+        } else {
+            // The default flat list of source *urls*.
+            sources.forEach(function (s) {
+                console.log(s.url);
+            });
+        }
+        cb();
+    }
+};
+CLI.prototype.do_sources.help = (
+    /* BEGIN JSSTYLED */
+    'List and edit image sources.\n'
+    + '\n'
+    + 'An image source is a URL to a server implementing the IMGAPI, or\n'
+    + 'the Docker Registry API. The default IMGAPI is ' + common.DEFAULT_SOURCE.url + '\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} sources [--verbose|-v] [--json|-j]  # list sources\n'
+    + '    {{name}} sources -a <url> [-t <type>]        # add a source\n'
+    + '    {{name}} sources -d <url>                    # delete a source\n'
+    + '    {{name}} sources -e                          # edit sources\n'
+    + '    {{name}} sources -c                          # check current sources\n'
+    + '\n'
+    + '{{options}}'
+    + '\n'
+    + 'Examples:\n'
+    + '    # Joyent\'s primary public image repository (defaults to "imgapi")\n'
+    + '    {{name}} sources -a https://images.joyent.com\n'
+    + '    # Docker Hub\n'
+    + '    {{name}} sources -a https://docker.io -t docker\n'
+    + '    # Legacy SDC 6.5 DSAPI (deprecated)\n'
+    + '    {{name}} sources -a https://datasets.joyent.com/datasets -t dsapi\n'
+    /* END JSSTYLED */
+);
+CLI.prototype.do_sources.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['verbose', 'v'],
+        type: 'bool',
+        help: 'Verbose output. List source URL and TYPE.'
+    },
+    {
+        names: ['json', 'j'],
+        type: 'bool',
+        help: 'List sources as JSON.'
+    },
+    {
+        group: ''
+    },
+    {
+        names: ['a'],
+        type: 'string',
+        helpArg: '<source>',
+        help: 'Add a source. It is appended to the list of sources.'
+    },
+    {
+        names: ['add-docker-hub'],
+        type: 'bool',
+        help: 'A shortcut for "imgadm sources -t docker -a https://docker.io".'
+    },
+    {
+        names: ['d'],
+        type: 'string',
+        helpArg: '<source>',
+        help: 'Delete a source.'
+    },
+    {
+        names: ['e'],
+        type: 'bool',
+        help: 'Edit sources in an editor.'
+    },
+    {
+        names: ['check', 'c'],
+        type: 'bool',
+        help: 'Ping check all sources.'
+    },
+    {
+        group: ''
+    },
+    {
+        names: ['type', 't'],
+        type: 'string',
+        default: 'imgapi',
+        helpArg: '<type>',
+        help: 'The source type for an added source. One of "imgapi" (the '
+            + 'default), "docker", or "dsapi" (deprecated).'
+    },
+    {
+        names: ['insecure', 'k'],
+        type: 'bool',
+        help: 'Allow insecure (no server certificate checking) access '
+            + 'to the added HTTPS source URL.'
+    },
+    {
+        names: ['force', 'f'],
+        type: 'bool',
+        help: 'Force no "ping check" on new source URLs. By default '
+            + 'a ping check is done against new source URLs to '
+            + 'attempt to ensure they are a running IMGAPI server.'
+    }
+];
+
+
+CLI.prototype.do_avail = function do_avail(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+
+    try {
+        var filters = filtersFromArgs(args);
+    } catch (e) {
+        cb(e);
+        return;
+    }
+    self.log.debug({filters: filters}, 'avail filters');
+
+    /* JSSTYLED */
+    var columns = opts.o.trim().split(/\s*,\s*/g);
+    /* JSSTYLED */
+    var sort = opts.s.trim().split(/\s*,\s*/g);
+
+    self.tool.sourcesList(function (err, imagesInfo) {
+        // Even if there was an err, we still attempt to return results
+        // for working sources.
+        try {
+            imagesInfo = filterImagesInfo(imagesInfo, filters);
+
+            listImagesInfo(imagesInfo, {
+                json: opts.json,
+                columns: columns,
+                sort: sort,
+                skipHeader: opts.H
+            });
+        } catch (e) {
+            cb(e);
+            return;
+        }
+        cb(err);
+    });
+};
+CLI.prototype.do_avail.help = (
+    'List available images from all sources.\n'
+    + 'This is not supported for Docker sources.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} avail [<options>...]\n'
+    + '\n'
+    + '{{options}}'
+    + '\n'
+    + 'Fields for "-o" and "-s":\n'
+    + rowFieldsHelp
+);
+CLI.prototype.do_avail.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['json', 'j'],
+        type: 'bool',
+        help: 'JSON output.'
+    },
+    {
+        names: ['H'],
+        type: 'bool',
+        help: 'Do not print table header row.'
+    },
+    {
+        names: ['o'],
+        type: 'string',
+        helpArg: 'FIELD,...',
+        help: 'Specify fields (columns) to output. Default is '
+            + '"uuid,name,version,os,type,pub".',
+        default: 'uuid,name,version,os,type,pub'
+    },
+    {
+        names: ['s'],
+        type: 'string',
+        helpArg: 'FIELD,...',
+        help: 'Sort on the given fields. Default is "published_at,name".',
+        default: 'published_at,name'
+    }
+];
+CLI.prototype.do_avail.aliases = ['available'];
+
+
+CLI.prototype.do_list = function do_list(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    var log = self.log;
+    log.debug({opts: opts}, 'list');
+
+    try {
+        var filters = filtersFromArgs(args);
+    } catch (e) {
+        cb(e);
+        return;
+    }
+    if (opts.docker) {
+        filters['type'] = 'docker';
+    }
+    if (args) {
+        log.debug({filters: filters}, 'list filters');
+    }
+
+    /* JSSTYLED */
+    var columns = opts.o.trim().split(/\s*,\s*/g);
+    /* JSSTYLED */
+    var sort = opts.s.trim().split(/\s*,\s*/g);
+
+    self.tool.listImages(function (err, imagesInfo) {
+        log.debug({err: err, imagesInfo: imagesInfo}, 'listImages');
+        if (err) {
+            cb(err);
+            return;
+        }
+
+        try {
+            imagesInfo = filterImagesInfo(imagesInfo, filters);
+
+            listImagesInfo(imagesInfo, {
+                json: opts.json,
+                columns: columns,
+                sort: sort,
+                skipHeader: opts.H,
+                docker: opts.docker
+            });
+        } catch (e) {
+            cb(e);
+            return;
+        }
+        cb();
+    });
+};
+CLI.prototype.do_list.help = (
+    'List locally installed images.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} list [<options>...] [<filters>]\n'
+    + '\n'
+    + '{{options}}'
+    + '\n'
+    + 'Filters:\n'
+    + '    FIELD=VALUE               exact string match\n'
+    + '    FIELD=true|false          boolean match\n'
+    + '    FIELD=~SUBSTRING          substring match\n'
+    + '\n'
+    + 'Fields for filtering, "-o" and "-s":\n'
+    + rowFieldsHelp
+);
+CLI.prototype.do_list.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['json', 'j'],
+        type: 'bool',
+        help: 'JSON output.'
+    },
+    {
+        names: ['H'],
+        type: 'bool',
+        help: 'Do not print table header row.'
+    },
+    {
+        names: ['o'],
+        type: 'string',
+        helpArg: 'FIELD,...',
+        help: 'Specify fields (columns) to output. Default is '
+            + '"uuid,name,version,os,type,pub".',
+        default: 'uuid,name,version,os,type,pub'
+    },
+    {
+        names: ['s'],
+        type: 'string',
+        helpArg: 'FIELD,...',
+        help: 'Sort on the given fields. Default is "published_at,name".',
+        default: 'published_at,name'
+    },
+    {
+        names: ['docker'],
+        type: 'bool',
+        help: 'Limit and format list similar to `docker images`'
+    }
+];
+
+
+CLI.prototype.do_show = function do_show(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+
+    var getOpts = {
+        arg: args[0],
+        ensureActive: false
+    };
+    self.tool.sourcesGetImportInfo(getOpts, function (err, importInfo) {
+        if (err) {
+            cb(err);
+            return;
+        } else if (!importInfo) {
+            cb(new errors.ImageNotFoundError(getOpts.arg));
+            return;
+        } else if (importInfo.manifest) {
+            // IMGAPI/DSAPI return the manifest with source.getImportInfo().
+            console.log(JSON.stringify(importInfo.manifest, null, 2));
+            cb();
+            return;
+        }
+
+        importInfo.source.getImgMeta(importInfo, function (metaErr, imgMeta) {
+            if (metaErr) {
+                cb(metaErr);
+                return;
+            }
+            console.log(JSON.stringify(imgMeta.manifest, null, 2));
+            cb();
+        });
+    });
+};
+CLI.prototype.do_show.help = (
+    'Show the manifest for an available image.\n'
+    + '\n'
+    + 'This searches each imgadm source for the given image and prints its\n'
+    + 'its manifest.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} show <uuid|docker-repo-tag>\n'
+    + '\n'
+    + '{{options}}'
+);
+CLI.prototype.do_show.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    }
+];
+
+
+CLI.prototype.do_get = function do_get(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    var uuid = args[0];
+    assertUuid(uuid);
+    var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+    var getOpts = {uuid: uuid, zpool: zpool, children: opts.r};
+    self.tool.getImage(getOpts, function (err, imageInfo) {
+        if (err) {
+            cb(err);
+            return;
+        }
+        if (!imageInfo) {
+            cb(new errors.ImageNotInstalledError(zpool, uuid));
+            return;
+        }
+        console.log(JSON.stringify(imageInfo, null, 2));
+        cb();
+    });
+};
+CLI.prototype.do_get.help = (
+    'Get information for an installed image.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} get <uuid>\n'
+    + '\n'
+    + '{{options}}'
+);
+CLI.prototype.do_get.aliases = ['info'];
+CLI.prototype.do_get.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['P'],
+        type: 'string',
+        helpArg: '<pool>',
+        help: 'Name of zpool in which to look for the image. Default is "'
+            + 'zones/<uuid>/data".'
+    },
+    {
+        names: ['r'],
+        type: 'bool',
+        help: 'Recursively gather children (child snapshots and dependent '
+            + 'clones).'
+    }
+];
+
+
+/**
+ * `imgadm ancestry <uuid>`
+ */
+CLI.prototype.do_ancestry = function do_ancestry(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    var uuid = args[0];
+    assert.uuid(uuid, 'uuid');
+    var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+    /* JSSTYLED */
+    var columns = opts.o.trim().split(/\s*,\s*/g);
+    var log = self.log;
+    log.debug({opts: opts, zpool: zpool, uuid: uuid}, 'ancestry');
+
+    var ancestry = [];
+    getNextAncestor(uuid);
+
+
+    function getNextAncestor(aUuid) {
+        var getOpts = {uuid: aUuid, zpool: zpool};
+        self.tool.getImage(getOpts, function (err, imageInfo) {
+            if (err) {
+                cb(err);
+                return;
+            }
+            if (!imageInfo) {
+                cb(new errors.ImageNotInstalledError(zpool, aUuid));
+                return;
+            }
+            ancestry.push(imageInfo);
+            if (imageInfo.manifest.origin) {
+                getNextAncestor(imageInfo.manifest.origin);
+            } else {
+                finish();
+            }
+        });
+    }
+
+    function finish() {
+        try {
+            listImagesInfo(ancestry, {
+                json: opts.json,
+                columns: columns,
+                skipHeader: opts.H
+            });
+        } catch (e) {
+            cb(e);
+            return;
+        }
+        cb();
+    }
+};
+CLI.prototype.do_ancestry.help = (
+    'List the ancestry (the "origin" chain) for the given incremental image.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} ancestry [<options>...] <uuid>\n'
+    + '\n'
+    + '{{options}}'
+    + '\n'
+    + 'Fields for "-o":\n'
+    + rowFieldsHelp
+);
+CLI.prototype.do_ancestry.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['json', 'j'],
+        type: 'bool',
+        help: 'JSON output.'
+    },
+    {
+        names: ['H'],
+        type: 'bool',
+        help: 'Do not print table header row.'
+    },
+    {
+        names: ['o'],
+        type: 'string',
+        helpArg: 'FIELD,...',
+        help: 'Specify fields (columns) to output. Default is '
+            + '"uuid,name,version,published".',
+        default: 'uuid,name,version,published'
+    },
+    {
+        names: ['P'],
+        type: 'string',
+        helpArg: '<pool>',
+        help: 'Name of zpool in which to look for the image. Default is "'
+            + 'zones/<uuid>/data".'
+    }
+];
+
+
+/**
+ * `imgadm delete <uuid>`
+ */
+CLI.prototype.do_delete = function do_delete(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    var uuid = args[0];
+    assertUuid(uuid);
+    var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+
+    self.tool.deleteImage({uuid: uuid, zpool: zpool}, function (err) {
+        if (err) {
+            cb(err);
+            return;
+        }
+        console.log('Deleted image %s', uuid);
+    });
+};
+CLI.prototype.do_delete.help = (
+    /* BEGIN JSSTYLED */
+    'Delete an image from the local zpool.\n'
+    + '\n'
+    + 'The removal can only succeed if the image is not actively in use by a VM.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} delete <uuid>\n'
+    + '\n'
+    + '{{options}}'
+    /* END JSSTYLED */
+);
+CLI.prototype.do_delete.aliases = ['destroy'];
+CLI.prototype.do_delete.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['P'],
+        type: 'string',
+        helpArg: '<pool>',
+        help: 'Name of zpool in which to look for the image. Default is "'
+            + 'zones/<uuid>/data".'
+    }
+];
+
+
+/**
+ * `imgadm import <uuid>` for imgapi/dsapi imports
+ * `imgadm import <repo>[:<tag>]` for docker imports
+ */
+CLI.prototype.do_import = function do_import(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    var arg = args[0];
+    var log = self.log;
+    var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+
+    vasync.pipeline({arg: {}, funcs: [
+        function validateArg(ctx, next) {
+            if (common.UUID_RE.test(arg)) {
+                ctx.uuid = arg;
+            } else if (docker.isDockerPullArg(arg)) {
+                ctx.dockerId = arg;
+            } else {
+                next(new errors.UsageError(format(
+                    'invalid image-id arg: %j', arg)));
+                return;
+            }
+            log.info({uuid: ctx.uuid, dockerId: ctx.dockerId, arg: arg},
+                'image-id validated');
+            next();
+        },
+
+        function checkIfUuidInstalled(ctx, next) {
+            if (!ctx.uuid) {
+                next();
+                return;
+            }
+
+            var getOpts = {uuid: ctx.uuid, zpool: zpool};
+            self.tool.getImage(getOpts, function (getErr, ii) {
+                var logCb = opts.logCb || console.log;
+
+                if (getErr) {
+                    next(getErr);
+                    return;
+                }
+                if (ii) {
+                    var extra = '';
+                    if (ii.manifest.name) {
+                        extra = format(' (%s %s)', ii.manifest.name,
+                            ii.manifest.version);
+                    }
+                    logCb('Image %s%s is already installed, skipping',
+                        ii.manifest.uuid, extra);
+                    next(true);
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function getImportInfo(ctx, next) {
+            var getOpts = { arg: arg };
+            if (opts.source) {
+                getOpts.sources = opts.source.map(function (s) {
+                    return self.tool.sourceFromInfo({
+                        url: s,
+                        type: 'imgapi'
+                    });
+                });
+            }
+            self.tool.sourcesGetImportInfo(getOpts, function (err, info) {
+                if (err) {
+                    next(err);
+                    return;
+                } else if (!info) {
+                    next(new errors.ActiveImageNotFoundError(arg));
+                    return;
+                }
+                self.log.info({importInfo: info, arg: arg},
+                    'found source for import');
+                ctx.importInfo = info;
+                next();
+            });
+        },
+
+        /*
+         * If the `arg` was a uuid, then we were able to check if it was
+         * already installed before consulting the source API. If `arg` *wasn't*
+         * we now have a UUID that we can check.
+         */
+        function checkIfImageInstalled(ctx, next) {
+            if (ctx.uuid) {
+                next();
+                return;
+            }
+            assert.uuid(ctx.importInfo.uuid, 'ctx.importInfo.uuid');
+
+            var getOpts = {
+                uuid: ctx.importInfo.uuid,
+                zpool: zpool
+            };
+            self.tool.getImage(getOpts, function (getErr, ii) {
+                if (getErr) {
+                    next(getErr);
+                    return;
+                } else if (ii) {
+                    var extra1 = '';
+                    if (ii.manifest.name) {
+                        extra1 = format(' (%s@%s)', ii.manifest.name,
+                            ii.manifest.version);
+                    }
+                    var extra2 = '';
+                    if (ii.source) {
+                        extra2 = ' from ' + ii.source;
+                    }
+                    console.log('Image %s%s is already installed%s',
+                        ii.manifest.uuid, extra1, extra2);
+                    next(true); // early abort
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function importIt(ctx, next) {
+            self.tool.importImage({
+                importInfo: ctx.importInfo,
+                zpool: zpool,
+                zstream: opts.zstream,
+                quiet: opts.quiet,
+                logCb: console.log
+            }, next);
+        }
+
+    ]}, function finish(err) {
+        if (err === true) { // Early abort.
+            err = null;
+        }
+        cb(err);
+    });
+};
+CLI.prototype.do_import.help = (
+    'Import an image from a source IMGAPI.\n'
+    + '\n'
+    + 'This finds the image with the given UUID (or repository name and tag,\n'
+    + 'for Docker sources) in the configured sources and imports it into\n'
+    + 'the local system.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} import <uuid|docker repo:tag>\n'
+    + '\n'
+    + '{{options}}'
+);
+CLI.prototype.do_import.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['quiet', 'q'],
+        type: 'bool',
+        help: 'Disable progress bar.'
+    },
+    {
+        names: ['P'],
+        type: 'string',
+        helpArg: '<pool>',
+        help: 'Name of zpool in which to look for the image. Default is "'
+            + 'zones/<uuid>/data".'
+    },
+    {
+        names: ['source', 'S'],
+        type: 'arrayOfString',
+        helpArg: '<source>',
+        help: 'An image source (url) from which to import. If given, then '
+            + 'this source is used instead of the configured sources.'
+    },
+    {
+        names: ['zstream'],
+        type: 'bool',
+        help: 'Indicate that the source will send a raw ZFS dataset stream for '
+            + 'the image file data. Typically this is used in conjunction '
+            + 'with -S, so the source is known, and with a source that '
+            + 'stores images in ZFS (e.g. a SmartOS peer node).'
+    }
+];
+
+
+
+/**
+ * `imgadm install -m <manifest> -f <file>`
+ */
+CLI.prototype.do_install = function do_install(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 0) {
+        cb(new errors.UsageError(format(
+            'unexpected args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    assert.string(opts.m, '-m <manifest>');
+    assert.string(opts.f, '-f <file>');
+    assert.optionalString(opts.P, '-P <zpool>');
+    var zpool = opts.P || self.tool.DEFAULT_ZPOOL;
+
+    // 1. Validate args.
+    //    If `published_at` is not defined in the manifest (e.g. if from
+    //    `imgadm create ...`) then they are generated as part of the
+    //    install.
+    if (!fs.existsSync(opts.m)) {
+        cb(new errors.UsageError(format(
+            'manifest path does not exist: "%s"', opts.m)));
+        return;
+    }
+    if (!fs.existsSync(opts.f)) {
+        cb(new errors.UsageError(format(
+            'file path does not exist: "%s"', opts.f)));
+        return;
+    }
+    try {
+        var manifest = JSON.parse(fs.readFileSync(opts.m, 'utf8'));
+    } catch (err) {
+        cb(new errors.InvalidManifestError(err));
+        return;
+    }
+    var uuid = manifest.uuid;
+    assertUuid(uuid, 'manifest.uuid');
+    if (!manifest.published_at) {
+        manifest.published_at = (new Date()).toISOString();
+    }
+
+    // 2. Ensure we don't already have this UUID installed.
+    self.tool.getImage({uuid: uuid, zpool: zpool}, function (getErr, ii) {
+        if (getErr) {
+            cb(getErr);
+            return;
+        }
+        if (ii) {
+            var extra = '';
+            if (ii.manifest.name) {
+                extra = format(' (%s %s)', ii.manifest.name,
+                    ii.manifest.version);
+            }
+            console.log('Image %s%s is already installed, skipping',
+                ii.manifest.uuid, extra);
+            cb();
+            return;
+        }
+
+        // 3. Install it.
+        console.log('Installing image %s (%s@%s)', uuid, manifest.name,
+            manifest.version);
+        var installOpts = {
+            manifest: manifest,
+            zpool: zpool,
+            file: opts.f,
+            logCb: console.log
+        };
+        self.tool.installImage(installOpts, function (installErr) {
+            if (installErr) {
+                cb(installErr);
+                return;
+            }
+            cb();
+        });
+    });
+};
+CLI.prototype.do_install.help = (
+    /* BEGIN JSSTYLED */
+    'Install an image from local manifest and image data files.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} install [<options>] -m <manifest> -f <file>\n'
+    + '\n'
+    + '{{options}}'
+    /* END JSSTYLED */
+);
+CLI.prototype.do_install.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['m'],
+        type: 'string',
+        helpArg: '<manifest>',
+        help: 'Required. Path to the image manifest file to import.'
+    },
+    {
+        names: ['f'],
+        type: 'string',
+        helpArg: '<file>',
+        help: 'Required. Path to the image file to import.'
+    },
+    {
+        names: ['quiet', 'q'],
+        type: 'bool',
+        help: 'Disable progress bar.'
+    },
+    {
+        names: ['P'],
+        type: 'string',
+        helpArg: '<pool>',
+        help: 'Name of zpool in which to look for the image. Default is "'
+            + 'zones/<uuid>/data".'
+    }
+];
+
+
+/**
+ * `imgadm update`
+ */
+CLI.prototype.do_update = function do_update(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    var options = {
+        dryRun: opts.dry_run
+    };
+    if (args.length) {
+        options.uuids = args;
+    }
+    this.tool.updateImages(options, cb);
+};
+CLI.prototype.do_update.help = (
+    'Update currently installed images, if necessary.\n'
+    + 'This does not yet support images from a "docker" source.\n'
+    + '\n'
+    + 'Images that are installed without "imgadm" (e.g. via "zfs recv")\n'
+    + 'may not have cached image manifest information. Also, images installed\n'
+    + 'prior to imgadm version 2.0.3 will not have a "@final" snapshot\n'
+    + '(preferred for provisioning and require for incremental image\n'
+    + 'creation, via "imgadm create -i ..."). This command will attempt\n'
+    + 'to retrieve manifest information and to ensure images have the correct\n'
+    + '"@final" snapshot, using info from current image sources.\n'
+    + '\n'
+    + 'If no "<uuid>" is given, then update is run for all installed images.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} update [<uuid>...]\n'
+    + '\n'
+    + '{{options}}'
+);
+CLI.prototype.do_update.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['dry-run', 'n'],
+        type: 'bool',
+        help: 'Do a dry-run (do not actually make changes).'
+    }
+];
+
+
+// TODO: option to exclude images with a very recent create/import time
+//      imgadm vacuum -t 2d
+// TODO: option to exclude given uuids:  imgadm vacuum -x uuid,uuid
+CLI.prototype.do_vacuum = function do_vacuum(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    var options = {
+        logCb: console.log,
+        dryRun: opts.dry_run,
+        force: opts.force
+    };
+    if (args.length) {
+        cb(new errors.UsageError('unexpected arguments: ' + args.join(' ')));
+    }
+    this.tool.vacuumImages(options, cb);
+};
+CLI.prototype.do_vacuum.help = (
+    'Remove unused images -- i.e. not used for any VMs or child images.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} vacuum [<options>]\n'
+    + '\n'
+    + '{{options}}'
+);
+CLI.prototype.do_vacuum.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['dry-run', 'n'],
+        type: 'bool',
+        help: 'Do a dry-run (do not actually make changes).'
+    },
+    {
+        names: ['force', 'f'],
+        type: 'bool',
+        help: 'Force deletion without prompting for confirmation.'
+    }
+];
+
+
+
+/**
+ * `imgadm create [<options>] <vm-uuid> [<manifest-field>=<value> ...]`
+ */
+CLI.prototype.do_create = function do_create(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length < 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    var vmUuid = args[0];
+    assertUuid(vmUuid);
+    if (opts.compression
+        && !~common.VALID_COMPRESSIONS.indexOf(opts.compression))
+    {
+        cb(new errors.UsageError(format(
+            'invalid -c,--compression "%s": must be one of "%s"',
+            opts.compression, common.VALID_COMPRESSIONS.join('", "'))));
+        return;
+    }
+    if (opts.output_template && opts.publish) {
+        cb(new errors.UsageError(
+            'cannot specify both -o,--output-template and -p,--publish'));
+        return;
+    }
+    if (opts.max_origin_depth !== undefined
+        && Number(opts.max_origin_depth) < 2) {
+        cb(new errors.UsageError(format(
+            'invalid max-origin-depth "%s": must be greater than 1',
+            opts.max_origin_depth)));
+        return;
+    }
+
+    function gatherManifestData(next) {
+        // Pick up fields from the CLI argv.
+        var argFields = {};
+        for (var i = 1; i < args.length; i++) {
+            var arg = args[i];
+            var idx = arg.indexOf('=');
+            if (idx === -1) {
+                return next(new errors.UsageError(format(
+                    'invalid manifest field arg "%s": must match '
+                    + '"<field>=<value>"', arg)));
+            }
+            var key = arg.slice(0, idx);
+            var value = arg.slice(idx + 1);
+            // TODO: imgmanifest.FIELDS should define those for this a JSON
+            // parse is reasonable. Exclude string fields from this.
+            try {
+                value = JSON.parse(value);
+            } catch (e) {}
+            argFields[key] = value;
+        }
+
+        var manifest;
+        if (!opts.m) {
+            manifest = {};
+            next(null, objMerge(manifest, argFields));
+        } else if (opts.m === '-') {
+            var stdin = '';
+            process.stdin.resume();
+            process.stdin.on('data', function (chunk) {
+                stdin += chunk;
+            });
+            process.stdin.on('end', function () {
+                try {
+                    manifest = JSON.parse(stdin);
+                } catch (ex) {
+                    next(new errors.UsageError(
+                        format('invalid manifest JSON on stdin: %s', ex)));
+                    return;
+                }
+                next(null, objMerge(manifest, argFields));
+            });
+        } else {
+            var input = fs.readFileSync(opts.m);
+            try {
+                manifest = JSON.parse(input);
+            } catch (ex) {
+                next(new errors.UsageError(format(
+                    'invalid manifest JSON in "%s": %s', opts.m, ex)));
+                return;
+            }
+            next(null, objMerge(manifest, argFields));
+        }
+    }
+
+    gatherManifestData(function (manErr, manifest) {
+        if (manErr) {
+            cb(manErr);
+            return;
+        }
+        self.log.debug({manifest: manifest}, 'gathered manifest data');
+
+        // Choose the dir/file-prefix to which to save.
+        var savePrefix = '';
+        if (opts.publish) {
+            savePrefix = format('/var/tmp/.imgadm-create-%s-%s',
+                Date.now(), process.pid);
+        } else if (!opts.output_template) {
+            savePrefix = format('%s-%s', pathSlugify(String(manifest.name)),
+                pathSlugify(String(manifest.version)));
+        } else {
+            var stats;
+            try {
+                stats = fs.statSync(opts.output_template);
+            } catch (e) {}
+            if (stats && stats.isDirectory()) {
+                savePrefix = path.join(opts.output_template,
+                    format('%s-%s', pathSlugify(String(manifest.name)),
+                        pathSlugify(String(manifest.version))));
+            } else {
+                savePrefix = opts.output_template;
+            }
+        }
+
+        var createOpts = {
+            vmUuid: vmUuid,
+            manifest: manifest,
+            compression: opts.compression,
+            incremental: opts.incremental,
+            prepareScript: opts.s && fs.readFileSync(opts.s, 'utf8'),
+            savePrefix: savePrefix,
+            logCb: console.log,
+            quiet: opts.quiet,
+            maxOriginDepth: opts.max_origin_depth
+        };
+        self.tool.createImage(createOpts, function (createErr, imageInfo) {
+            if (createErr) {
+                cb(createErr);
+            } else if (opts.publish) {
+                // If '-p URL' given, publish and delete the temp created
+                // image and manifest files.
+                var pOpts = {
+                    m: imageInfo.manifestPath,
+                    f: imageInfo.filePath,
+                    quiet: opts.quiet
+                };
+                var pArgs = [opts.publish];
+                self.do_publish('publish', pOpts, pArgs, function (pErr) {
+                    async.forEach(
+                        [imageInfo.manifestPath, imageInfo.filePath],
+                        rimraf,
+                        function (rmErr) {
+                            if (rmErr) {
+                                console.warn('Error removing temporary '
+                                    + 'created image file: %s', rmErr);
+                            }
+                            cb(pErr);
+                        }
+                    );
+                });
+            } else {
+                cb();
+            }
+        });
+    });
+};
+CLI.prototype.do_create.help = (
+    /* BEGIN JSSTYLED */
+    'Create an image from the given VM and manifest data.\n'
+    + '\n'
+    + 'There are two basic calling modes: (1) a prepare-image script is\n'
+    + 'provided (via "-s") to have imgadm automatically run the script inside the\n'
+    + 'VM before image creation; or (2) the given VM is already "prepared" and\n'
+    + 'shutdown.\n'
+    + '\n'
+    + 'The former involves snapshotting the VM, running the prepare-image script\n'
+    + '(via the SmartOS mdata operator-script facility), creating the image,\n'
+    + 'rolling back to the pre-prepared state. This is preferred because it is (a)\n'
+    + 'easier (fewer steps to follow for imaging) and (b) safe (gating with\n'
+    + 'snapshot/rollback ensures the VM is unchanged by imaging -- the preparation\n'
+    + 'script is typically destructive.\n'
+    + '\n'
+    + 'With the latter, one first creates a VM from an existing image, customizes\n'
+    + 'it, runs "sm-prepare-image" (or equivalent for KVM guest OSes), shuts it\n'
+    + 'down, runs this "imgadm create" to create the image file and manifest, and\n'
+    + 'finally destroys the "proto" VM.\n'
+    + '\n'
+    + 'With either calling mode, the image can optionally be published directly\n'
+    + 'to a given image repository (IMGAPI) via "-p URL". This can also be\n'
+    + 'done separately via "imgadm publish".\n'
+    + '\n'
+    + 'Note: When creating an image from a VM with brand \'bhyve\', \'lx\', or\n'
+    + '\'kvm\', the resulting manifest will have requirements.brand set to match\n'
+    + 'the brand of the source VM. If this is undesirable, the\n'
+    + 'requirements.brand can be set (optionally empty if the resulting image\n'
+    + 'should not have this value set) in the manifest passed with the \'-m\'\n'
+    + 'option.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} create [<options>] <vm-uuid> [<manifest-field>=<value> ...]\n'
+    + '\n'
+    + '{{options}}'
+    + '\n'
+    + 'Arguments:\n'
+    + '    <uuid>         The UUID of the prepared and shutdown VM\n'
+    + '                   from which to create the image.\n'
+    + '    <manifest-field>=<value>\n'
+    + '                   Zero or more manifest fields to include in\n'
+    + '                   in the created manifest. The "<value>" is\n'
+    + '                   first interpreted as JSON, else as a string.\n'
+    + '                   E.g. \'disabled=true\' will be a boolean true\n'
+    + '                   and both \'name=foo\' and \'name="true"\'\n'
+    + '                   will be strings.\n'
+    + '\n'
+    + 'Examples:\n'
+    + '    # Create an image from VM 5f7a53e9-fc4d-d94b-9205-9ff110742aaf.\n'
+    + '    echo \'{"name": "foo", "version": "1.0.0"}\' \\\n'
+    + '        | imgadm create -m - -s /path/to/prepare-image \\\n'
+    + '            5f7a53e9-fc4d-d94b-9205-9ff110742aaf\n'
+    + '    \n'
+    + '    # Specify manifest data as arguments.\n'
+    + '    imgadm create -s prep-image 5f7a53e9-fc4d-d94b-9205-9ff110742aaf \\\n'
+    + '        name=foo version=1.0.0\n'
+    + '    \n'
+    + '    # Write the manifest and image file to "/var/tmp".\n'
+    + '    imgadm create -s prep-image 5f7a53e9-fc4d-d94b-9205-9ff110742aaf \\\n'
+    + '        name=foo version=1.0.0 -o /var/tmp\n'
+    + '    \n'
+    + '    # Publish directly to an image repository (IMGAPI server).\n'
+    + '    imgadm create -s prep-image 5f7a53e9-fc4d-d94b-9205-9ff110742aaf \\\n'
+    + '        name=foo version=1.0.0 --publish https://images.example.com\n'
+    + '    \n'
+    + '    # Create an image from the prepared and shutdown VM\n'
+    + '    # 5f7a53e9-fc4d-d94b-9205-9ff110742aaf, using some manifest JSON\n'
+    + '    # data from stdin.\n'
+    + '    echo \'{"name": "foo", "version": "1.0.0"}\' \\\n'
+    + '        | imgadm create -m - 5f7a53e9-fc4d-d94b-9205-9ff110742aaf\n'
+    /* END JSSTYLED */
+);
+CLI.prototype.do_create.helpOpts = {
+    helpCol: 19
+};
+CLI.prototype.do_create.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['m'],
+        type: 'string',
+        helpArg: '<manifest>',
+        help: 'Path to image manifest data (as JSON) to include in the '
+            + 'created manifest. Specify "-" to read manifest JSON from stdin.'
+    },
+    {
+        names: ['output-template', 'o'],
+        type: 'string',
+        helpArg: '<path>',
+        help: 'Path prefix to which to save the created manifest '
+            + 'and image file. By default "NAME-VER.imgmanifest '
+            + 'and "NAME-VER.zfs[.EXT]" are saved to the current '
+            + 'dir. If "PATH" is a dir, then the files are saved '
+            + 'to it. If the basename of "PATH" is not a dir, '
+            + 'then "PATH.imgmanifest" and "PATH.zfs[.EXT]" are '
+            + 'created.'
+    },
+    {
+        names: ['compression', 'c'],
+        type: 'string',
+        helpArg: '<comp>',
+        help: 'One of "none", "gzip", "xz" or "bzip2" for the compression '
+            + 'to use on the image file, if any. Default is "none".'
+    },
+    {
+        names: ['incremental', 'i'],
+        type: 'bool',
+        help: 'Build an incremental image (based on the "@final" '
+            + 'snapshot of the source image for the VM).'
+    },
+    {
+        group: ''
+    },
+    {
+        names: ['max-origin-depth'],
+        type: 'positiveInteger',
+        helpArg: '<num>',
+        help: 'Maximum origin depth to allow when creating '
+            + 'incremental images. E.g. a value of 3 means that '
+            + 'the image will only be created if there are no more '
+            + 'than 3 parent images in the origin chain.'
+    },
+    {
+        group: ''
+    },
+    {
+        names: ['s'],
+        type: 'string',
+        helpArg: '<prepare-image-path>',
+        help: 'Path to a script that is run inside the VM to '
+            + 'prepare it for imaging. Specifying this triggers the '
+            + 'full snapshot/prepare-image/create-image/rollback '
+            + 'automatic image creation process (see notes above). '
+            + 'There is a contract with "imgadm" that a  '
+            + 'prepare-image script must follow. See the "PREPARE '
+            + 'IMAGE SCRIPT" section in "man imgadm".'
+    },
+    {
+        group: ''
+    },
+    {
+        names: ['publish', 'p'],
+        type: 'string',
+        helpArg: '<url>',
+        help: 'Publish directly to the given image source '
+            + '(an IMGAPI server). You may not specify both '
+            + '"-p" and "-o".'
+    },
+    {
+        names: ['quiet', 'q'],
+        type: 'bool',
+        help: 'Disable progress bar in upload.'
+    }
+];
+
+
+/**
+ * `imgadm publish -m <manifest> -f <file> <imgapi-url>`
+ */
+CLI.prototype.do_publish = function do_publish(subcmd, opts, args, cb) {
+    var self = this;
+    if (opts.help) {
+        self.do_help('help', {}, [subcmd], cb);
+        return;
+    }
+    if (args.length !== 1) {
+        cb(new errors.UsageError(format(
+            'incorrect number of args (%d): "%s"',
+            args.length, args.join(' '))));
+        return;
+    }
+    assert.string(opts.m, '-m <manifest>');
+    assert.string(opts.f, '-f <file>');
+    assert.optionalBool(opts.quiet, '-q');
+    var url = args[0];
+    assert.string(url, '<imgapi-url>');
+
+    // 1. Validate args.
+    if (!fs.existsSync(opts.m)) {
+        cb(new errors.UsageError(format(
+            'manifest path does not exist: "%s"', opts.m)));
+        return;
+    }
+    if (!fs.existsSync(opts.f)) {
+        cb(new errors.UsageError(format(
+            'file path does not exist: "%s"', opts.f)));
+        return;
+    }
+    try {
+        var manifest = JSON.parse(fs.readFileSync(opts.m, 'utf8'));
+    } catch (err) {
+        cb(new errors.InvalidManifestError(err));
+        return;
+    }
+
+    var pubOpts = {
+        file: opts.f,
+        manifest: manifest,
+        url: url,
+        quiet: opts.quiet
+    };
+    self.tool.publishImage(pubOpts, function (pubErr) {
+        if (pubErr) {
+            cb(pubErr);
+        } else {
+            console.log('Successfully published image %s to %s',
+                manifest.uuid, url);
+            cb();
+        }
+    });
+};
+CLI.prototype.do_publish.help = (
+    /* BEGIN JSSTYLED */
+    'Publish an image (local manifest and data) to a remote IMGAPI repo.\n'
+    + '\n'
+    + 'Typically the local manifest and image file are created with\n'
+    + '"imgadm create ...". Note that "imgadm create" supports a\n'
+    + '"-p/--publish" option to publish directly in one step.\n'
+    + 'Limitation: This does not yet support *authentication* that some\n'
+    + 'IMGAPI image repositories require.\n'
+    + '\n'
+    + 'Usage:\n'
+    + '    {{name}} publish [<options>] -m <manifest> -f <file> <imgapi-url>\n'
+    + '\n'
+    + '{{options}}'
+    /* END JSSTYLED */
+);
+CLI.prototype.do_publish.options = [
+    {
+        names: ['help', 'h'],
+        type: 'bool',
+        help: 'Show this help.'
+    },
+    {
+        names: ['m'],
+        type: 'string',
+        helpArg: '<manifest>',
+        help: 'Required. Path to the image manifest to import.'
+    },
+    {
+        names: ['f'],
+        type: 'string',
+        helpArg: '<file>',
+        help: 'Required. Path to the image file to import.'
+    },
+    {
+        names: ['quiet', 'q'],
+        type: 'bool',
+        help: 'Disable progress bar in upload.'
+    }
+];
+
+
+
+// ---- exports
+
+module.exports = CLI;
diff --git a/tools/buildimage/lib/imgadm/lib/common.js b/tools/buildimage/lib/imgadm/lib/common.js
new file mode 100644
index 0000000..a99c271
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/common.js
@@ -0,0 +1,846 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * Dump for shared stuff for this package.
+ */
+
+var p = console.log;
+var assert = require('assert-plus');
+var async = require('async');
+var child_process = require('child_process'),
+    exec = child_process.exec,
+    execFile = child_process.execFile,
+    spawn = child_process.spawn;
+var format = require('util').format;
+var fs = require('fs');
+var path = require('path');
+var tty = require('tty');
+var mod_url = require('url');
+
+var errors = require('./errors'),
+    InternalError = errors.InternalError;
+
+
+
+// ---- globals
+
+var NAME = 'imgadm';
+var MANIFEST_V = 2;
+var DEFAULT_SOURCE = {type: 'imgapi', url: 'https://images.joyent.com'};
+
+var DB_DIR = '/var/imgadm';
+
+var VALID_COMPRESSIONS = ['none', 'bzip2', 'gzip', 'xz'];
+
+var VALID_SOURCE_TYPES = ['imgapi', 'dsapi', 'docker'];
+
+
+var _versionCache = null;
+function getVersion() {
+    if (_versionCache === null)
+        _versionCache = require('../package.json').version;
+    return _versionCache;
+}
+
+
+var DOWNLOAD_DIR = '/var/tmp/.imgadm-downloads';
+
+function downloadFileFromUuid(uuid) {
+    assert.string(uuid, 'uuid');
+    return path.join(DOWNLOAD_DIR, uuid + '.file');
+}
+
+
+function indent(s, indentStr) {
+    if (!indentStr) indentStr = '    ';
+    var lines = s.split(/\r?\n/g);
+    return indentStr + lines.join('\n' + indentStr);
+}
+
+
+function objCopy(obj, target) {
+    if (!target) {
+        target = {};
+    }
+    Object.keys(obj).forEach(function (k) {
+        target[k] = obj[k];
+    });
+    return target;
+}
+
+/**
+ * Merge the second object's keys into the first and return the first.
+ *
+ * Note: The first given object is modified in-place.
+ */
+function objMerge(a, b) {
+    Object.keys(b).forEach(function (k) {
+        a[k] = b[k];
+    });
+    return a;
+}
+
+
+var UUID_RE = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/;
+function assertUuid(uuid) {
+    if (!UUID_RE.test(uuid)) {
+        throw new errors.InvalidUUIDError(uuid);
+    }
+}
+
+
+/**
+ * Convert a boolean or string representation into a boolean, or raise
+ * TypeError trying.
+ *
+ * @param value {Boolean|String} The input value to convert.
+ * @param default_ {Boolean} The default value is `value` is undefined.
+ * @param errName {String} The name to include in the possibly
+ *      raised TypeError.
+ */
+function boolFromString(value, default_, errName) {
+    if (value === undefined) {
+        return default_;
+    } else if (value === 'false' || value === 'no') {
+        return false;
+    } else if (value === 'true' || value === 'yes') {
+        return true;
+    } else if (typeof (value) === 'boolean') {
+        return value;
+    } else {
+        throw new TypeError(
+            format('invalid value for %s: %j', errName, value));
+    }
+}
+
+/**
+ * Return a string suitable and convenient for a file name.
+ */
+var _pathSlugifyString = /[^\w\s\._-]/g;
+var _pathSlugifyHyphenate = /[-\s]+/g;
+function pathSlugify(s) {
+    assert.string(s, 's');
+    s = s.replace(_pathSlugifyString, '').trim().toLowerCase();
+    s = s.replace(_pathSlugifyHyphenate, '-');
+    return s;
+}
+
+
+
+/**
+ * Return an array of manifest fields that differ between the two given
+ * image manifests. The 'requirements' object is descended into to give
+ * more specific diff info.
+ */
+function diffManifestFields(a, b) {
+    var diffs = [];  // List of field names with diffs.
+    Object.keys(b).forEach(function (field) {
+        if (field === 'requirements') {
+            if (a[field] === undefined) {
+                diffs.push(field);
+            }
+            return;
+        }
+        if (JSON.stringify(b[field]) !==
+            JSON.stringify(a[field])) {
+            diffs.push(field);
+        }
+    });
+    Object.keys(a).forEach(function (field) {
+        if (b[field] === undefined) {
+            diffs.push(field);
+        }
+    });
+    if (b.requirements && a.requirements) {
+        Object.keys(b.requirements).forEach(function (field) {
+            if (JSON.stringify(b.requirements[field]) !==
+                JSON.stringify(a.requirements[field])) {
+                diffs.push('requirements.' + field);
+            }
+        });
+        Object.keys(a.requirements).forEach(function (field) {
+            if (b.requirements[field] === undefined) {
+                diffs.push('requirements.' + field);
+            }
+        });
+    }
+    return diffs;
+}
+
+
+/**
+ * Return an 80-column wrapped string.
+ */
+function textWrap(text) {
+    var width = 80;
+    var words = text.split(/\s+/g).reverse();
+    var lines = [];
+    var line = '';
+    while (words.length) {
+        var word = words.pop();
+        if (line.length + 1 + word.length >= width) {
+            lines.push(line);
+            line = '';
+        }
+        if (line.length)
+            line += ' ' + word;
+        else
+            line += word;
+    }
+    lines.push(line);
+    return lines.join('\n');
+}
+
+
+
+/**
+ * Adapted from <http://stackoverflow.com/a/18650828>
+ */
+function humanSizeFromBytes(bytes) {
+    assert.number(bytes, 'bytes');
+    var sizes = ['B', 'KiB', 'MiB', 'GiB', 'TiB'];
+    if (bytes === 0) {
+        return '0 B';
+    }
+    var i = Number(Math.floor(Math.log(bytes) / Math.log(1024)));
+    var s = String(bytes / Math.pow(1024, i));
+    var precision1 = (s.indexOf('.') === -1
+        ? s + '.0' : s.slice(0, s.indexOf('.') + 2));
+    return format('%s %s', precision1, sizes[i]);
+}
+
+
+/**
+ * Prompt a user for a y/n answer.
+ *
+ *      cb('y')        user entered in the affirmative
+ *      cb('n')        user entered in the negative
+ *      cb(false)      user ^C'd
+ */
+function promptYesNo(opts_, cb) {
+    assert.object(opts_, 'opts');
+    assert.string(opts_.msg, 'opts.msg');
+    assert.optionalString(opts_.default, 'opts.default');
+    var opts = objCopy(opts_);
+
+    // Setup stdout and stdin to talk to the controlling terminal if
+    // process.stdout or process.stdin is not a TTY.
+    var stdout;
+    if (opts.stdout) {
+        stdout = opts.stdout;
+    } else if (process.stdout.isTTY) {
+        stdout = process.stdout;
+    } else {
+        opts.stdout_fd = fs.openSync('/dev/tty', 'r+');
+        stdout = opts.stdout = new tty.WriteStream(opts.stdout_fd);
+    }
+    var stdin;
+    if (opts.stdin) {
+        stdin = opts.stdin;
+    } else if (process.stdin.isTTY) {
+        stdin = process.stdin;
+    } else {
+        opts.stdin_fd = fs.openSync('/dev/tty', 'r+');
+        stdin = opts.stdin = new tty.ReadStream(opts.stdin_fd);
+    }
+
+    stdout.write(opts.msg);
+    stdin.setEncoding('utf8');
+    stdin.setRawMode(true);
+    stdin.resume();
+    var input = '';
+    stdin.on('data', onData);
+
+    function postInput() {
+        stdin.setRawMode(false);
+        stdin.pause();
+        stdin.write('\n');
+        stdin.removeListener('data', onData);
+    }
+
+    function finish(rv) {
+        if (opts.stdout_fd !== undefined) {
+            stdout.end();
+            delete opts.stdout_fd;
+        }
+        if (opts.stdin_fd !== undefined) {
+            stdin.end();
+            delete opts.stdin_fd;
+        }
+        cb(rv);
+    }
+
+    function onData(ch) {
+        ch = ch + '';
+
+        switch (ch) {
+        case '\n':
+        case '\r':
+        case '\u0004':
+            // They've finished typing their answer
+            postInput();
+            var answer = input.toLowerCase();
+            if (answer === '' && opts.default) {
+                finish(opts.default);
+            } else if (answer === 'yes' || answer === 'y') {
+                finish('y');
+            } else if (answer === 'no' || answer === 'n') {
+                finish('n');
+            } else {
+                stdout.write('Please enter "y", "yes", "n" or "no".\n');
+                promptYesNo(opts, cb);
+                return;
+            }
+            break;
+        case '\u0003':
+            // Ctrl C
+            postInput();
+            finish(false);
+            break;
+        default:
+            // More plaintext characters
+            stdout.write(ch);
+            input += ch;
+            break;
+        }
+    }
+}
+
+
+
+
+// TODO: persist "?channel=<channel>"
+function normUrlFromUrl(u) {
+    // `url.parse('example.com:9999')` is not what you expect. Make sure we
+    // have a protocol.
+    if (! /^\w+:\/\// .test(u)) {
+        u = 'http://' + u;
+    }
+
+    var parsed = mod_url.parse(u);
+
+    // Don't want trailing '/'.
+    if (parsed.pathname.slice(-1) === '/') {
+        parsed.pathname = parsed.pathname.slice(0, -1);
+    }
+
+    // Drop redundant ports.
+    if (parsed.port
+        && ((parsed.protocol === 'https:' && parsed.port === '443')
+        || (parsed.protocol === 'http:' && parsed.port === '80'))) {
+        parsed.port = '';
+        parsed.host = parsed.hostname;
+    }
+
+    return mod_url.format(parsed);
+}
+
+
+/**
+ * A convenience wrapper around `child_process.execFile` to take away some
+ * logging and error handling boilerplate.
+ *
+ * @param args {Object}
+ *      - argv {Array} Required.
+ *      - execOpts {Array} Exec options.
+ *      - log {Bunyan Logger} Required. Use to log details at trace level.
+ * @param cb {Function} `function (err, stdout, stderr)` where `err` here is
+ *      an `errors.InternalError` wrapper around the child_process error.
+ */
+function execFilePlus(args, cb) {
+    assert.object(args, 'args');
+    assert.arrayOfString(args.argv, 'args.argv');
+    assert.optionalObject(args.execOpts, 'args.execOpts');
+    assert.object(args.log, 'args.log');
+    assert.func(cb);
+    var argv = args.argv;
+    var execOpts = args.execOpts;
+
+    // args.log.trace({exec: true, argv: argv, execOpts: execOpts},
+    //      'exec start');
+    execFile(argv[0], argv.slice(1), execOpts, function (err, stdout, stderr) {
+        args.log.trace({exec: true, argv: argv, execOpts: execOpts, err: err,
+            stdout: stdout, stderr: stderr}, 'exec done');
+        if (err) {
+            var msg = format(
+                'exec error:\n'
+                + '\targv: %j\n'
+                + '\texit status: %s\n'
+                + '\tstdout:\n%s\n'
+                + '\tstderr:\n%s',
+                argv, err.code, stdout.trim(), stderr.trim());
+            cb(new InternalError({cause: err, message: msg}), stdout, stderr);
+        } else {
+            cb(null, stdout, stderr);
+        }
+    });
+}
+
+
+/**
+ * A convenience wrapper around `child_process.exec` to take away some
+ * logging and error handling boilerplate.
+ *
+ * @param args {Object}
+ *      - command {String} Required.
+ *      - log {Bunyan Logger} Required. Use to log details at trace level.
+ *      - execOpts {Array} Optional. child_process.exec options.
+ *      - errMsg {String} Optional. Error string to use in error message on
+ *        failure.
+ * @param cb {Function} `function (err, stdout, stderr)` where `err` here is
+ *      an `errors.InternalError` wrapper around the child_process error.
+ */
+function execPlus(args, cb) {
+    assert.object(args, 'args');
+    assert.string(args.command, 'args.command');
+    assert.optionalString(args.errMsg, 'args.errMsg');
+    assert.optionalObject(args.execOpts, 'args.execOpts');
+    assert.object(args.log, 'args.log');
+    assert.func(cb);
+    var command = args.command;
+    var execOpts = args.execOpts;
+
+    // args.log.trace({exec: true, command: command, execOpts: execOpts},
+    //      'exec start');
+    exec(command, execOpts, function (err, stdout, stderr) {
+        args.log.trace({exec: true, command: command, execOpts: execOpts,
+            err: err, stdout: stdout, stderr: stderr}, 'exec done');
+        if (err) {
+            var msg = format(
+                '%s:\n'
+                + '\tcommand: %s\n'
+                + '\texit status: %s\n'
+                + '\tstdout:\n%s\n'
+                + '\tstderr:\n%s',
+                args.errMsg || 'exec error', command, err.code,
+                stdout.trim(), stderr.trim());
+            cb(new InternalError({cause: err, message: msg}), stdout, stderr);
+        } else {
+            cb(null, stdout, stderr);
+        }
+    });
+}
+
+
+/**
+ * Call `vmadm stop UUID`.
+ *
+ * @param uuid {String} The current snapshot name.
+ * @param options {Object}
+ *      - force {Boolean} Optional. Use '-F' option to 'vmadm stop'.
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err)`
+ */
+function vmStop(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.optionalBool(options.force, 'options.force');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var optStr = '';
+    if (options.force) {
+        optStr += ' -F';
+    }
+    var cmd = format('/usr/sbin/vmadm stop%s %s', optStr, uuid);
+    options.log.trace({cmd: cmd}, 'start vmStop');
+    exec(cmd, function (err, stdout, stderr) {
+        options.log.trace({cmd: cmd, err: err, stdout: stdout, stderr: stderr},
+            'finish vmStop');
+        callback(err);
+    });
+}
+
+
+/**
+ * Call `vmadm start UUID`.
+ *
+ * @param uuid {String} The current snapshot name.
+ * @param options {Object}
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err)`
+ */
+function vmStart(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.optionalBool(options.force, 'options.force');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var optStr = '';
+    if (options.force) {
+        optStr += ' -F';
+    }
+    var cmd = format('/usr/sbin/vmadm start%s %s', optStr, uuid);
+    options.log.trace({cmd: cmd}, 'start vmStart');
+    exec(cmd, function (err, stdout, stderr) {
+        options.log.trace({cmd: cmd, err: err, stdout: stdout, stderr: stderr},
+            'finish vmStart');
+        callback(err);
+    });
+}
+
+/**
+ * Call `vmadm get UUID`.
+ *
+ * @param uuid {String} The current snapshot name.
+ * @param options {Object}
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err, vm)`
+ */
+function vmGet(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var cmd = format('/usr/sbin/vmadm get %s', uuid);
+    // options.log.trace({cmd: cmd}, 'start vmGet');
+    exec(cmd, function (err, stdout, stderr) {
+        // options.log.trace(
+        //    {cmd: cmd, err: err, stdout: stdout, stderr: stderr},
+        //    'finish vmGet');
+        if (err) {
+            callback(new InternalError({
+                cause: err,
+                message: format('error getting VM %s info', uuid)
+            }));
+            return;
+        }
+        try {
+            var vm = JSON.parse(stdout);
+            callback(null, vm);
+        } catch (e) {
+            callback(e);
+        }
+    });
+}
+
+/**
+ * Wait for a particular key (and optionally, value) in a VM's
+ * customer_metadata to show up.
+ *
+ * @param uuid {String} The VM uuid.
+ * @param options {Object}
+ *      - key {String} The customer_metadata key to wait for.
+ *      - value {String} Optional. If given, a key *value* to wait for. If not
+ *        given, then this just waits for the presence of `key`.
+ *      - values {Array of String} Optional. An *array*
+ *        of values can be given, in which case it will return if the value
+ *        matches any of those.
+ *      - timeout {Number} The number of ms (approximately) after which
+ *        to timeout with an error. If not given, then never times out.
+ *      - interval {Number} The number of ms between polls. Default is 1000ms.
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err, vm)`
+ */
+function vmWaitForCustomerMetadatum(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.string(options.key, 'options.key');
+    assert.optionalString(options.value, 'options.value');
+    assert.optionalArrayOfString(options.values, 'options.values');
+    assert.optionalNumber(options.timeout, 'options.timeout');
+    assert.optionalNumber(options.interval, 'options.interval');
+    assert.func(callback);
+    var interval = options.interval || 1000;
+    var key = options.key;
+
+    function match(val) {
+        if (options.value !== undefined) {
+            return val === options.value;
+        } else if (options.values !== undefined) {
+            return options.values.indexOf(val) !== -1;
+        } else {
+            return val !== undefined;
+        }
+    }
+
+    var start = Date.now();
+    var vm;
+    async.doUntil(
+        function getIt(next) {
+            setTimeout(function () {
+                vmGet(uuid, options, function (err, vm_) {
+                    vm = vm_;
+                    next(err);
+                });
+            }, interval);
+        },
+        function testIt() {
+            options.log.trace({vm: uuid},
+                'test for customer_metadata "%s" key match', options.key);
+            return (match(vm.customer_metadata[key])
+                || (options.timeout && Date.now() - start >= options.timeout));
+        },
+        function done(err) {
+            if (err) {
+                callback(err);
+            } else if (match(vm.customer_metadata[key])) {
+                callback(null, vm);
+            } else {
+                var extra = '';
+                if (options.value) {
+                    extra = format(' to bet set to "%s"', options.value);
+                } else if (options.values) {
+                    extra = format(' to bet set to one of "%s"',
+                        options.values.join('", "'));
+                }
+                callback(new errors.TimeoutError(format('timeout (%dms) '
+                    + 'waiting for VM %s customer_metadata "%s" key%s',
+                    options.timeout, uuid, key, extra)));
+            }
+        }
+    );
+}
+
+
+/**
+ * Wait for the given VM to enter the given state.
+ *
+ * @param uuid {String} The VM uuid.
+ * @param options {Object}
+ *      - state {String} The state to wait for.
+ *      - timeout {Number} The number of ms (approximately) after which
+ *        to timeout with an error. If not given, then never times out.
+ *      - interval {Number} The number of ms between polls. Default is 1000ms.
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err, vm)`
+ */
+function vmWaitForState(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.string(options.state, 'options.state');
+    assert.optionalNumber(options.timeout, 'options.timeout');
+    assert.optionalNumber(options.interval, 'options.interval');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var interval = options.interval || 1000;
+
+    var start = Date.now();
+    var vm;
+    async.doUntil(
+        function getIt(next) {
+            setTimeout(function () {
+                vmGet(uuid, options, function (err, vm_) {
+                    vm = vm_;
+                    next(err);
+                });
+            }, interval);
+        },
+        function testIt() {
+            options.log.trace({vm: uuid, state: vm.state},
+                'test for state "%s"', options.state);
+            return vm.state === options.state
+                || (options.timeout
+                    && Date.now() - start >= options.timeout);
+        },
+        function done(err) {
+            if (err) {
+                callback(err);
+            } else if (vm.state === options.state) {
+                callback(null, vm);
+            } else {
+                callback(new errors.TimeoutError(format('timeout (%dms) '
+                    + 'waiting for VM %s to enter "%s" state: current '
+                    + 'state is "%s"', options.timeout, uuid, options.state,
+                    vm.state)));
+            }
+
+        }
+    );
+}
+
+
+/**
+ * Halt (aka `vmadm stop -F UUID`) this VM if it is not stopped.
+ *
+ * @param uuid {String} The current snapshot name.
+ * @param options {Object}
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err)`
+ */
+function vmHaltIfNotStopped(uuid, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+
+    vmGet(uuid, options, function (err, vm) {
+        if (err) {
+            callback(err);
+        } else if (vm.state === 'stopped') {
+            callback();
+        } else {
+            vmStop(uuid, {force: true, log: options.log}, callback);
+        }
+    });
+}
+
+
+/**
+ * Call `vmadm update UUID <<UPDATE`.
+ *
+ * @param uuid {String} The current snapshot name.
+ * @param update {String} The current snapshot name.
+ * @param options {Object}
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err)`
+ */
+function vmUpdate(uuid, update, options, callback) {
+    assert.string(uuid, 'uuid');
+    assert.object(update, 'update');
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var argv = ['/usr/sbin/vmadm', 'update', uuid];
+    options.log.trace({argv: argv, update: update}, 'start vmUpdate');
+
+    var vmadm = spawn(argv[0], argv.slice(1));
+    var stdout = [];
+    var stderr = [];
+    vmadm.stdout.setEncoding('utf8');
+    vmadm.stderr.setEncoding('utf8');
+    vmadm.stdout.on('data', function (s) { stdout.push(s); });
+    vmadm.stderr.on('data', function (s) { stderr.push(s); });
+    vmadm.on('close', function () {
+        done();
+    });
+    var exitStatus;
+    vmadm.on('exit', function (code) {
+        exitStatus = code;
+        done();
+    });
+    vmadm.stdin.write(JSON.stringify(update));
+    vmadm.stdin.end();
+
+    var nDoneCalls = 0;
+    function done() {
+        nDoneCalls++;
+        if (nDoneCalls !== 2) {
+            return;
+        }
+        options.log.trace({argv: argv, exitStatus: exitStatus,
+            stdout: stdout, stderr: stderr}, 'finish vmUpdate');
+        // 'exit' and 'close' called.
+        if (exitStatus !== 0) {
+            callback(new InternalError({
+                message: format('vmadm update failed (%s): %s',
+                                exitStatus, stderr.join(''))
+            }));
+        } else {
+            callback();
+        }
+    }
+}
+
+
+/**
+ * "cosmic ray" stuff for testing error code paths
+ *
+ * To support testing some error code paths we support inducing some errors
+ * via "IMGADM_TEST_*_COSMIC_RAY" environment variables, where "*" is an
+ * action like "DOWNLOAD".
+ *
+ * If defined it must be a comma-separated list of numbers (from zero to one).
+ * Each number is a *probability* of failure (i.e. of having a cosmic ray)
+ * for the Nth action (e.g. for the 0th, 1st, ... download). The "N" here is
+ * a global count from `imgadm` invocation.
+ *
+ * E.g.: The following will result in the 3rd attempted
+ * download failing:
+ *      IMGADM_TEST_DOWNLOAD_COSMIC_RAY=0,0,1 imgadm import busybox:latest
+ *
+ * Usage in code:
+ *      var cosmicRay = common.testForCosmicRay('download');
+ *      ...
+ *      if (cosmicRay) {
+ *          return cb(new Error('download cosmic ray'));
+ *      }
+ */
+var cosmicRayCountFromName = {};
+
+function testForCosmicRay(name) {
+    assert.string(name, 'name');
+
+    if (cosmicRayCountFromName[name] === undefined) {
+        cosmicRayCountFromName[name] = 0;
+    }
+    var index = cosmicRayCountFromName[name]++;
+    var prob = 0;
+    var envvar = 'IMGADM_TEST_' + name.toUpperCase() + '_COSMIC_RAY';
+
+    if (process.env[envvar]) {
+        // JSSTYLED
+        var probs = process.env[envvar].split(/,/g);
+        if (index < probs.length) {
+            prob = Number(probs[index]);
+            assert.number(prob, envvar + '[' + index + ']');
+        }
+    }
+    var cosmicRay = prob > 0 && Math.random() <= prob;
+
+    return cosmicRay;
+}
+
+
+
+
+
+// ---- exports
+
+module.exports = {
+    NAME: NAME,
+    MANIFEST_V: MANIFEST_V,
+    DEFAULT_SOURCE: DEFAULT_SOURCE,
+    DB_DIR: DB_DIR,
+    VALID_COMPRESSIONS: VALID_COMPRESSIONS,
+    VALID_SOURCE_TYPES: VALID_SOURCE_TYPES,
+    getVersion: getVersion,
+    DOWNLOAD_DIR: DOWNLOAD_DIR,
+    downloadFileFromUuid: downloadFileFromUuid,
+    indent: indent,
+    objCopy: objCopy,
+    objMerge: objMerge,
+    UUID_RE: UUID_RE,
+    assertUuid: assertUuid,
+    boolFromString: boolFromString,
+    pathSlugify: pathSlugify,
+    diffManifestFields: diffManifestFields,
+    textWrap: textWrap,
+    humanSizeFromBytes: humanSizeFromBytes,
+    promptYesNo: promptYesNo,
+    normUrlFromUrl: normUrlFromUrl,
+    execFilePlus: execFilePlus,
+    execPlus: execPlus,
+
+    vmStop: vmStop,
+    vmStart: vmStart,
+    vmGet: vmGet,
+    vmUpdate: vmUpdate,
+    vmWaitForState: vmWaitForState,
+    vmHaltIfNotStopped: vmHaltIfNotStopped,
+    vmWaitForCustomerMetadatum: vmWaitForCustomerMetadatum,
+
+    testForCosmicRay: testForCosmicRay
+};
diff --git a/tools/buildimage/lib/imgadm/lib/configuration.js b/tools/buildimage/lib/imgadm/lib/configuration.js
new file mode 100644
index 0000000..3fad9ce
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/configuration.js
@@ -0,0 +1,138 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2013, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * imgadm configuration:
+ *
+ * - `userAgentExtra`: Optional string appended to user-agent used for
+ *   remote requests.
+ * - `upgradedToVer`: Current imgadm DB version. This is controlled
+ *   by "upgrade.js".
+ * - `sources`: Array of image source objects. Controlled by "*source*"
+ *   methods in "imgadm.js".
+ * - `dockerImportSkipUuids`: Optional boolean (default true). If set
+ *   false, then calls of `DockerSource.getImportInfo` will not skip
+ *   a given argument that is a UUID. This is true by default to avoid
+ *   querying a docker source for import info for arguments (UUIDs) that
+ *   are almost certainly not Docker image ids. Having this be
+ *   configurable is mostly an out in case a valid case come ups with
+ *   a docker repo that is a UUID.
+ */
+
+var p = console.warn;
+
+var assert = require('assert-plus');
+var format = require('util').format;
+var fs = require('fs');
+var mkdirp = require('mkdirp');
+var path = require('path');
+
+var common = require('./common');
+var errors = require('./errors');
+
+
+
+// ---- globals
+
+var CONFIG_PATH = common.DB_DIR + '/imgadm.conf';
+
+var DEFAULT_CONFIG = {
+    dockerImportSkipUuids: true
+};
+
+
+
+// ---- config routines
+
+/**
+ * @param opts {Object}
+ *      - log {Bunyan logger}
+ * @param cb {Function} `function (err, config)`.
+ */
+function loadConfig(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.log, 'opts.log');
+    assert.func(cb, 'cb');
+
+    var config = common.objCopy(DEFAULT_CONFIG);
+    fs.exists(CONFIG_PATH, function (exists) {
+        if (!exists) {
+            cb(null, config);
+            return;
+        }
+        opts.log.trace({path: CONFIG_PATH}, 'read config file');
+        fs.readFile(CONFIG_PATH, 'utf8', function (err, content) {
+            try {
+                var fileConfig = JSON.parse(content);
+            } catch (e) {
+                cb(new errors.ConfigError(e, format(
+                    'config file "%s" is not valid JSON', CONFIG_PATH)));
+                return;
+            }
+            Object.keys(fileConfig).forEach(function (k) {
+                config[k] = fileConfig[k];
+            });
+            cb(null, config);
+        });
+    });
+}
+
+
+/**
+ * Save out the current config.
+ *
+ * Dev Note: This *does* write out `DEFAULT_CONFIG` vars. That should be fine
+ * for now.
+ *
+ * @param opts {Object}
+ *      - config {Object} The configuration to save.
+ *      - log {Bunyan logger}
+ * @param cb {Function} `function (err)`
+ */
+function saveConfig(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.config, 'opts.config');
+    assert.object(opts.log, 'opts.log');
+    assert.func(cb, 'cb');
+
+    opts.log.debug({config: opts.config}, 'save config to %s', CONFIG_PATH);
+    var configDir = path.dirname(CONFIG_PATH);
+    mkdirp(configDir, function (dirErr) {
+        if (dirErr) {
+            cb(dirErr);
+            return;
+        }
+        var str = JSON.stringify(opts.config, null, 2);
+        fs.writeFile(CONFIG_PATH, str, 'utf8', cb);
+    });
+}
+
+
+
+// ---- exports
+
+module.exports = {
+    loadConfig: loadConfig,
+    saveConfig: saveConfig
+};
diff --git a/tools/buildimage/lib/imgadm/lib/database.js b/tools/buildimage/lib/imgadm/lib/database.js
new file mode 100644
index 0000000..03fbffa
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/database.js
@@ -0,0 +1,171 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ */
+
+/*
+ * The interface to the imgadm "database" under "/var/imgadm" (excepting
+ * the "/var/imgadm/imgadm.conf" config file).
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var format = require('util').format;
+var fs = require('fs');
+var mkdirp = require('mkdirp');
+var path = require('path');
+
+var common = require('./common');
+
+
+
+// ---- internal support stuff
+
+function Database(opts) {
+    assert.optionalObject(opts, 'opts');
+    if (!opts)
+        opts = {};
+    assert.optionalObject(opts.log, 'opts.log');
+
+    this.log = opts.log;
+}
+
+Database.prototype._dbImagePath = function _dbImagePath(zpool, uuid) {
+    return path.resolve(common.DB_DIR, 'images', zpool + '-' + uuid + '.json');
+};
+
+
+/**
+ * Load the image info for this image from the imgadm db.
+ *
+ * This never callsback with an error. Basically we treat the imgadm db
+ * of image info as a cache: if we don't have the manifest info, then we
+ * keep going. A debug message is logged if there is a corrupt db file that
+ * is ignored.
+ *
+ * If no image info is found in the db, then this returns the minimal
+ * `imageInfo`:  `{manifest: {uuid: UUID}, zpool: ZPOOL}`
+ *
+ * @param opts {Object}:
+ *      - @param uuid {String}
+ *      - @param zpool {String}
+ * @param cb {Function} `function (err, imageInfo)`
+ */
+Database.prototype.loadImage = function loadImage(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.uuid(opts.uuid, 'opts.uuid');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.func(cb, 'cb');
+
+    var dbImagePath = self._dbImagePath(opts.zpool, opts.uuid);
+    fs.readFile(dbImagePath, 'utf8', function (err, content) {
+        var info = null;
+        if (!err) {
+            try {
+                info = JSON.parse(content);
+            } catch (synErr) {
+                if (self.log) {
+                    self.log.debug(synErr, 'corrupt "%s"', dbImagePath);
+                }
+            }
+            assert.equal(info.manifest.uuid, opts.uuid, format(
+                'UUID for image in "%s" is wrong', dbImagePath));
+        }
+        if (!info) {
+            info = {manifest: {uuid: opts.uuid}, zpool: opts.zpool};
+        }
+        cb(null, info);
+    });
+};
+
+
+/**
+ * Delete image info for this image from the imgadm db.
+ *
+ * @param opts {Object}:
+ *      - @param uuid {String}
+ *      - @param zpool {String}
+ * @param cb {Function} `function (err)`  It is *not* an error if the
+ *      db image file does not exist (imgadm supports handling images that
+ *      aren't in the imgadm db).
+ */
+Database.prototype.deleteImage = function deleteImage(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.uuid(opts.uuid, 'opts.uuid');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.func(cb, 'cb');
+
+    var dbImagePath = self._dbImagePath(opts.zpool, opts.uuid);
+    fs.exists(dbImagePath, function (exists) {
+        if (!exists) {
+            cb();
+            return;
+        } else {
+            fs.unlink(dbImagePath, cb);
+        }
+    });
+};
+
+
+/**
+ * Save image info to the db.
+ *
+ * @param imageInfo {Object} Holds image details, with keys:
+ *      - manifest {Object}
+ *      - zpool {String} The zpool on which the image is installed.
+ *      - source {String} The source object.
+ * @param cb {Function} `function (err)`
+ */
+Database.prototype.addImage = function addImage(imageInfo, cb) {
+    var self = this;
+    assert.object(imageInfo, 'imageInfo');
+    assert.object(imageInfo.manifest, 'imageInfo.manifest');
+    assert.string(imageInfo.zpool, 'imageInfo.zpool');
+    assert.optionalObject(imageInfo.source, 'imageInfo.source');
+
+    var dbImagePath = self._dbImagePath(imageInfo.zpool,
+                                        imageInfo.manifest.uuid);
+    var dbImageDir = path.dirname(dbImagePath);
+    mkdirp(dbImageDir, function (dirErr) {
+        if (dirErr) {
+            cb(dirErr);
+            return;
+        }
+        var dbData = {
+            manifest: imageInfo.manifest,
+            zpool: imageInfo.zpool,
+            source: (imageInfo.source ? imageInfo.source.url : undefined)
+        };
+        var content = JSON.stringify(dbData, null, 2) + '\n';
+        fs.writeFile(dbImagePath, content, 'utf8', cb);
+    });
+};
+
+
+
+// ---- exports
+
+module.exports = Database;
diff --git a/tools/buildimage/lib/imgadm/lib/errors.js b/tools/buildimage/lib/imgadm/lib/errors.js
new file mode 100644
index 0000000..c60a665
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/errors.js
@@ -0,0 +1,827 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * Error classes that imgadm may produce.
+ */
+
+var util = require('util'),
+    format = util.format;
+var assert = require('assert-plus');
+var verror = require('verror'),
+    WError = verror.WError,
+    VError = verror.VError;
+
+
+
+// ---- internal support stuff
+
+function _indent(s, indent) {
+    if (!indent) indent = '    ';
+    var lines = s.split(/\r?\n/g);
+    return indent + lines.join('\n' + indent);
+}
+
+
+
+// ---- error classes
+
+/**
+ * Base imgadm error. Instances will always have a string `message` and
+ * a string `code` (a CamelCase string). The possible codes are those
+ * for every error subclass here, plus the possible `restCode` error
+ * responses from IMGAPI.
+ * See <https://mo.joyent.com/docs/imgapi/master/#errors>.
+ */
+function ImgadmError(options) {
+    assert.object(options, 'options');
+    assert.string(options.message, 'options.message');
+    assert.string(options.code, 'options.code');
+    assert.optionalObject(options.cause, 'options.cause');
+    assert.optionalNumber(options.statusCode, 'options.statusCode');
+    var self = this;
+
+    var args = [];
+    if (options.cause) args.push(options.cause);
+    if (options.message) {
+        args.push('%s');
+        args.push(options.message);
+    }
+    WError.apply(this, args);
+
+    var extra = Object.keys(options).filter(
+        function (k) { return ['cause', 'message'].indexOf(k) === -1; });
+    extra.forEach(function (k) {
+        self[k] = options[k];
+    });
+}
+util.inherits(ImgadmError, WError);
+
+function InternalError(options) {
+    assert.object(options, 'options');
+    assert.optionalString(options.source, 'options.source');
+    assert.optionalObject(options.cause, 'options.cause');
+    assert.string(options.message, 'options.message');
+    var message = options.message;
+    if (options.source) {
+        message = options.source + ': ' + message;
+    }
+    ImgadmError.call(this, {
+        cause: options.cause,
+        message: message,
+        code: 'InternalError',
+        exitStatus: 1
+    });
+}
+util.inherits(InternalError, ImgadmError);
+
+/**
+ * Usage:
+ *      new ManifestValidationError(errors)
+ *      new ManifestValidationError(cause, errors)
+ *
+ * I.e. optional *first* arg "cause", per WError style.
+ */
+function ManifestValidationError(cause, errors) {
+    if (errors === undefined) {
+        errors = cause;
+        cause = undefined;
+    }
+    assert.arrayOfObject(errors, 'errors');
+    var message = errors.map(function (e) {
+        if (e.message) {
+            return format('%s (%s)', e.field, e.message);
+        } else if (e.code === 'Invalid') {
+            return e.field;
+        } else {
+            return format('%s (%s)', e.field, e.code);
+        }
+    });
+    message = format('invalid manifest: %s', message.join(', '));
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'ManifestValidation'
+    });
+}
+util.inherits(ManifestValidationError, ImgadmError);
+
+/**
+ * Errors when attempting to install/import an image when
+ * `requirements.min_platform` or `requirements.max_platform` fail.
+ *
+ * // JSSTYLED
+ * https://github.com/joyent/sdc-imgapi/blob/master/docs/index.md#manifest-requirementsmin_platform
+ */
+function MinPlatformError(platVer, platTimestamp, minPlatSpec) {
+    assert.string(platVer, 'platVer');
+    assert.string(platTimestamp, 'platTimestamp');
+    assert.object(minPlatSpec, 'minPlatSpec');
+    var message = format('current platform version, %s/%s, does not satisfy '
+        + 'requirements.min_platform=%j', platVer, platTimestamp, minPlatSpec);
+    ImgadmError.call(this, {
+        message: message,
+        code: 'MinPlatform'
+    });
+}
+util.inherits(MinPlatformError, ImgadmError);
+
+function MaxPlatformError(platVer, platTimestamp, maxPlatSpec) {
+    assert.string(platVer, 'platVer');
+    assert.string(platTimestamp, 'platTimestamp');
+    assert.object(maxPlatSpec, 'maxPlatSpec');
+    var message = format('current platform version, %s/%s, does not satisfy '
+        + 'requirements.max_platform=%j', platVer, platTimestamp, maxPlatSpec);
+    ImgadmError.call(this, {
+        message: message,
+        code: 'MaxPlatform'
+    });
+}
+util.inherits(MaxPlatformError, ImgadmError);
+
+
+function NoSourcesError() {
+    ImgadmError.call(this, {
+        message: 'imgadm has no configured sources',
+        code: 'NoSources',
+        exitStatus: 1
+    });
+}
+util.inherits(NoSourcesError, ImgadmError);
+
+function SourcePingError(cause, source) {
+    if (source === undefined) {
+        source = cause;
+        cause = undefined;
+    }
+    assert.object(source, 'source');
+    var details = '';
+    if (cause) {
+        details = ': ' + cause.toString();
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('unexpected ping error with "%s" image source "%s"%s',
+            source.type, source.url, details),
+        code: 'SourcePing',
+        exitStatus: 1
+    });
+}
+util.inherits(SourcePingError, ImgadmError);
+
+/**
+ * This is thrown if, while importing image A from a source IMGAPI, the image
+ * has an origin image B that is *not in that source*. That means there is
+ * a problem with the IMGAPI source: it is meant to be an invariant that
+ * an IMGAPI source has all images that make up the full origin chain for
+ * its images.
+ */
+function OriginNotFoundInSourceError(cause, originUuid, source) {
+    if (source === undefined) {  // `cause` is optional
+        source = originUuid;
+        originUuid = cause;
+        cause = undefined;
+    }
+    assert.string(originUuid, 'originUuid');
+    assert.object(source, 'source');
+    var details = '';
+    if (cause) {
+        details = ': ' + cause.toString();
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format(
+            'origin image "%s" does not exist in image source "%s"%s',
+            originUuid, source.url, details),
+        code: 'OriginNotFoundInSource',
+        source: source.url,
+        exitStatus: 1
+    });
+}
+util.inherits(OriginNotFoundInSourceError, ImgadmError);
+
+function ImageNotFoundError(cause, uuid) {
+    if (uuid === undefined) {
+        uuid = cause;
+        cause = undefined;
+    }
+    assert.string(uuid, 'uuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('image "%s" was not found', uuid),
+        code: 'ImageNotFound',
+        exitStatus: 1
+    });
+}
+util.inherits(ImageNotFoundError, ImgadmError);
+
+function VmNotFoundError(cause, uuid) {
+    if (uuid === undefined) {
+        uuid = cause;
+        cause = undefined;
+    }
+    assert.string(uuid);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('vm "%s" was not found', uuid),
+        code: 'VmNotFound',
+        exitStatus: 1
+    });
+}
+util.inherits(VmNotFoundError, ImgadmError);
+
+// A VM must be prepared and stopped before it can be used by 'imgadm create'.
+function VmNotStoppedError(cause, uuid) {
+    if (uuid === undefined) {
+        uuid = cause;
+        cause = undefined;
+    }
+    assert.string(uuid);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('vm "%s" is not stopped', uuid),
+        code: 'VmNotStopped',
+        exitStatus: 1
+    });
+}
+util.inherits(VmNotStoppedError, ImgadmError);
+
+// A VM must have an origin image to 'imgadm create' an *incremental* image.
+function VmHasNoOriginError(cause, vmUuid) {
+    if (vmUuid === undefined) {
+        vmUuid = cause;
+        cause = undefined;
+    }
+    assert.string(vmUuid, 'vmUuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('cannot create an incremental image: vm "%s" has '
+            + 'no origin', vmUuid),
+        code: 'VmHasNoOrigin',
+        exitStatus: 1
+    });
+}
+util.inherits(VmHasNoOriginError, ImgadmError);
+
+function PrepareImageError(cause, vmUuid, details) {
+    if (details === undefined) {
+        details = vmUuid;
+        vmUuid = cause;
+        cause = undefined;
+    }
+    assert.string(vmUuid, 'vmUuid');
+    assert.string(details, 'details');
+    var extra = '';
+    if (details) {
+        if (details.indexOf('\n') !== -1) {
+            extra = ':\n' + _indent('...\n' + details);
+        } else {
+            extra = ': ' + details;
+        }
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('prepare-image script error while preparing VM %s%s',
+            vmUuid, extra),
+        code: 'PrepareImageError',
+        exitStatus: 1
+    });
+}
+util.inherits(PrepareImageError, ImgadmError);
+
+/**
+ * When the prepare-image script (used by `imgadm create -s prep-script`)
+ * does not set the 'prepare-image:state=running' mdata to indicate that it
+ * started running.
+ */
+function PrepareImageDidNotRunError(cause, vmUuid) {
+    if (vmUuid === undefined) {
+        vmUuid = cause;
+        cause = undefined;
+    }
+    assert.string(vmUuid, 'vmUuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('prepare-image script did not run on VM %s boot',
+            vmUuid),
+        code: 'PrepareImageDidNotRun',
+        exitStatus: 1
+    });
+}
+util.inherits(PrepareImageDidNotRunError, ImgadmError);
+
+function TimeoutError(cause, msg) {
+    if (msg === undefined) {
+        msg = cause;
+        cause = undefined;
+    }
+    assert.string(msg, 'msg');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: msg,
+        code: 'Timeout',
+        exitStatus: 1
+    });
+}
+util.inherits(TimeoutError, ImgadmError);
+
+// For *incremental* image creation the origin image must have a '@final'
+// snapshot from which the incr zfs send is taken. '@final' is what 'imgadm
+// install' ensures, but imported datasets from earlier 'imgadm' or pre-imgadm
+// might not have one.
+function OriginHasNoFinalSnapshotError(cause, originUuid) {
+    if (originUuid === undefined) {
+        originUuid = cause;
+        cause = undefined;
+    }
+    assert.string(originUuid, 'originUuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('cannot create an incremental image: origin image "%s" '
+            + 'has no "@final" snapshot (sometimes this can be fixed by '
+            + '"imgadm update")', originUuid),
+        code: 'OriginHasNoFinalSnapshot',
+        exitStatus: 1
+    });
+}
+util.inherits(OriginHasNoFinalSnapshotError, ImgadmError);
+
+function ActiveImageNotFoundError(cause, arg) {
+    if (arg === undefined) {
+        arg = cause;
+        cause = undefined;
+    }
+    assert.string(arg, 'arg');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('an active image "%s" was not found in image sources',
+            arg),
+        code: 'ActiveImageNotFound',
+        exitStatus: 1
+    });
+}
+util.inherits(ActiveImageNotFoundError, ImgadmError);
+
+function ImageNotActiveError(cause, uuid) {
+    if (uuid === undefined) {
+        uuid = cause;
+        cause = undefined;
+    }
+    assert.string(uuid);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('image "%s" is not active', uuid),
+        code: 'ImageNotActive',
+        exitStatus: 1
+    });
+}
+util.inherits(ImageNotActiveError, ImgadmError);
+
+function ImageNotInstalledError(cause, zpool, uuid) {
+    if (uuid === undefined) {
+        // `cause` was not provided.
+        uuid = zpool;
+        zpool = cause;
+        cause = undefined;
+    }
+    assert.string(zpool, 'zpool');
+    assert.string(uuid, 'uuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('image "%s" was not found on zpool "%s"', uuid, zpool),
+        code: 'ImageNotInstalled',
+        exitStatus: 3
+    });
+}
+util.inherits(ImageNotInstalledError, ImgadmError);
+
+function ImageHasDependentClonesError(cause, imageInfo) {
+    if (imageInfo === undefined) {
+        imageInfo = cause;
+        cause = undefined;
+    }
+    assert.object(imageInfo, 'imageInfo');
+    assert.string(imageInfo.manifest.uuid, 'imageInfo.manifest.uuid');
+    var clones = imageInfo.children.clones;
+    assert.arrayOfString(clones, 'imageInfo.children.clones');
+    var message = format('image "%s" has dependent clones: %s',
+        imageInfo.manifest.uuid, clones[0]);
+    if (clones.length > 1) {
+        message += format(' and %d others...', clones.length - 1);
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'ImageHasDependentClones',
+        exitStatus: 1
+    });
+}
+util.inherits(ImageHasDependentClonesError, ImgadmError);
+
+function OriginNotInstalledError(cause, zpool, uuid) {
+    if (uuid === undefined) {
+        // `cause` was not provided.
+        uuid = zpool;
+        zpool = cause;
+        cause = undefined;
+    }
+    assert.string(zpool, 'zpool');
+    assert.string(uuid, 'uuid');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('origin image "%s" was not found on zpool "%s"',
+            uuid, zpool),
+        code: 'OriginNotInstalled',
+        exitStatus: 3
+    });
+}
+util.inherits(OriginNotInstalledError, ImgadmError);
+
+function MaxOriginDepthError(cause, max) {
+    if (max === undefined) {
+        // `cause` was not provided.
+        max = cause;
+        cause = undefined;
+    }
+    assert.number(max, 'MaxOriginDepth');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('cannot create image: maximum origin depth "%s" '
+            + 'has been reached', max),
+        code: 'MaxOriginDepth',
+        exitStatus: 1
+    });
+}
+util.inherits(MaxOriginDepthError, ImgadmError);
+
+function InvalidUUIDError(cause, uuid) {
+    if (uuid === undefined) {
+        uuid = cause;
+        cause = undefined;
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('invalid uuid: "%s"', uuid),
+        code: 'InvalidUUID',
+        exitStatus: 1
+    });
+}
+util.inherits(InvalidUUIDError, ImgadmError);
+
+function InvalidDockerInfoError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'InvalidDockerInfo',
+        exitStatus: 1
+    });
+}
+util.inherits(InvalidDockerInfoError, ImgadmError);
+
+function InvalidArgumentError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'InvalidArgument',
+        exitStatus: 1
+    });
+}
+util.inherits(InvalidArgumentError, ImgadmError);
+
+function InvalidManifestError(cause) {
+    assert.optionalObject(cause);
+    var message = 'manifest is invalid';
+    if (cause) {
+        message += ': ' + (cause.message || String(cause));
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'InvalidManifest',
+        exitStatus: 1
+    });
+}
+util.inherits(InvalidManifestError, ImgadmError);
+
+function UnexpectedNumberOfSnapshotsError(uuid, snapnames) {
+    assert.string(uuid, 'uuid');
+    assert.arrayOfString(snapnames, 'snapnames');
+    var extra = '';
+    if (snapnames.length) {
+        extra = ': ' + snapnames.join(', ');
+    }
+    ImgadmError.call(this, {
+        message: format(
+            'image "%s" has an unexpected number of snapshots (%d)%s',
+            uuid, snapnames.length, extra),
+        code: 'UnexpectedNumberOfSnapshots',
+        exitStatus: 1
+    });
+}
+util.inherits(UnexpectedNumberOfSnapshotsError, ImgadmError);
+
+function ImageMissingOriginalSnapshotError(uuid, datasetGuid) {
+    assert.string(uuid, 'uuid');
+    assert.optionalString(datasetGuid, 'datasetGuid');
+    var extra = '';
+    if (datasetGuid) {
+        extra = ' (expected a snapshot with guid ' + datasetGuid + ')';
+    }
+    ImgadmError.call(this, {
+        message: format('image "%s" is missing its original snapshot%s',
+            uuid, extra),
+        code: 'ImageMissingOriginalSnapshot',
+        exitStatus: 1
+    });
+}
+util.inherits(ImageMissingOriginalSnapshotError, ImgadmError);
+
+function FileSystemError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'FileSystem',
+        exitStatus: 1
+    });
+}
+util.inherits(FileSystemError, ImgadmError);
+
+function UncompressionError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'UncompressionError',
+        exitStatus: 1
+    });
+}
+util.inherits(UncompressionError, ImgadmError);
+
+function NotSupportedError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'NotSupported',
+        exitStatus: 1
+    });
+}
+util.inherits(NotSupportedError, ImgadmError);
+
+function UsageError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'Usage',
+        exitStatus: 1
+    });
+}
+util.inherits(UsageError, ImgadmError);
+
+function UnknownOptionError(cause, option) {
+    if (option === undefined) {
+        option = cause;
+        cause = undefined;
+    }
+    assert.string(option);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('unknown option: "%s"', option),
+        code: 'UnknownOption',
+        exitStatus: 1
+    });
+}
+util.inherits(UnknownOptionError, ImgadmError);
+
+function UnknownCommandError(cause, command) {
+    if (command === undefined) {
+        command = cause;
+        cause = undefined;
+    }
+    assert.string(command);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('unknown command: "%s"', command),
+        code: 'UnknownCommand',
+        exitStatus: 1
+    });
+}
+util.inherits(UnknownCommandError, ImgadmError);
+
+function ClientError(source, cause) {
+    assert.string(source, 'source');
+    assert.object(cause, 'cause');
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('%s: %s', source, cause),
+        code: 'ClientError',
+        exitStatus: 1
+    });
+}
+ClientError.description = 'An error from a syscall in the IMGAPI client.';
+util.inherits(ClientError, ImgadmError);
+
+
+function APIError(source, cause) {
+    assert.string(source, 'source');
+    assert.object(cause, 'cause');
+    assert.optionalNumber(cause.statusCode, 'cause.statusCode');
+    assert.string(cause.body.code, 'cause.body.code');
+    assert.string(cause.body.message, 'cause.body.message');
+    var message = cause.body.message;
+    if (cause.body.errors) {
+        cause.body.errors.forEach(function (e) {
+            message += format('\n    %s: %s', e.field, e.code);
+            if (e.message) {
+                message += ': ' + e.message;
+            }
+        });
+    }
+    ImgadmError.call(this, {
+        cause: cause,
+        message: format('%s: %s', source, message),
+        code: cause.body.code,
+        statusCode: cause.statusCode,
+        exitStatus: 1
+    });
+}
+APIError.description = 'An error from the IMGAPI http request.';
+util.inherits(APIError, ImgadmError);
+
+
+function DownloadError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.optionalObject(cause);
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'DownloadError'
+    });
+}
+util.inherits(DownloadError, ImgadmError);
+
+function UploadError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.optionalObject(cause);
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'UploadError'
+    });
+}
+util.inherits(UploadError, ImgadmError);
+
+function ConfigError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.optionalObject(cause);
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'ConfigError'
+    });
+}
+util.inherits(ConfigError, ImgadmError);
+
+
+function UpgradeError(cause, message) {
+    if (message === undefined) {
+        message = cause;
+        cause = undefined;
+    }
+    assert.optionalObject(cause);
+    assert.string(message);
+    ImgadmError.call(this, {
+        cause: cause,
+        message: message,
+        code: 'UpgradeError'
+    });
+}
+util.inherits(UpgradeError, ImgadmError);
+
+
+/**
+ * Multiple ImgadmErrors in a group.
+ */
+function MultiError(errs) {
+    assert.arrayOfObject(errs, 'errs');
+    var lines = [format('multiple (%d) errors', errs.length)];
+    for (var i = 0; i < errs.length; i++) {
+        var err = errs[i];
+        lines.push(format('    error (%s): %s', err.code, err.message));
+    }
+    ImgadmError.call(this, {
+        cause: errs[0],
+        message: lines.join('\n'),
+        code: 'MultiError',
+        exitStatus: 1
+    });
+}
+MultiError.description = 'Multiple IMGADM errors.';
+util.inherits(MultiError, ImgadmError);
+
+
+
+// ---- exports
+
+module.exports = {
+    ImgadmError: ImgadmError,
+    InternalError: InternalError,
+    InvalidUUIDError: InvalidUUIDError,
+    InvalidDockerInfoError: InvalidDockerInfoError,
+    InvalidArgumentError: InvalidArgumentError,
+    MinPlatformError: MinPlatformError,
+    MaxPlatformError: MaxPlatformError,
+    NoSourcesError: NoSourcesError,
+    SourcePingError: SourcePingError,
+    OriginNotFoundInSourceError: OriginNotFoundInSourceError,
+    ImageNotFoundError: ImageNotFoundError,
+    VmNotFoundError: VmNotFoundError,
+    VmNotStoppedError: VmNotStoppedError,
+    VmHasNoOriginError: VmHasNoOriginError,
+    PrepareImageError: PrepareImageError,
+    PrepareImageDidNotRunError: PrepareImageDidNotRunError,
+    TimeoutError: TimeoutError,
+    OriginHasNoFinalSnapshotError: OriginHasNoFinalSnapshotError,
+    ManifestValidationError: ManifestValidationError,
+    ActiveImageNotFoundError: ActiveImageNotFoundError,
+    ImageNotActiveError: ImageNotActiveError,
+    ImageNotInstalledError: ImageNotInstalledError,
+    ImageHasDependentClonesError: ImageHasDependentClonesError,
+    OriginNotInstalledError: OriginNotInstalledError,
+    MaxOriginDepthError: MaxOriginDepthError,
+    InvalidManifestError: InvalidManifestError,
+    UnexpectedNumberOfSnapshotsError: UnexpectedNumberOfSnapshotsError,
+    ImageMissingOriginalSnapshotError: ImageMissingOriginalSnapshotError,
+    FileSystemError: FileSystemError,
+    UncompressionError: UncompressionError,
+    NotSupportedError: NotSupportedError,
+    UsageError: UsageError,
+    UnknownOptionError: UnknownOptionError,
+    UnknownCommandError: UnknownCommandError,
+    ClientError: ClientError,
+    APIError: APIError,
+    DownloadError: DownloadError,
+    UploadError: UploadError,
+    ConfigError: ConfigError,
+    UpgradeError: UpgradeError,
+    MultiError: MultiError
+};
diff --git a/tools/buildimage/lib/imgadm/lib/imgadm.js b/tools/buildimage/lib/imgadm/lib/imgadm.js
new file mode 100644
index 0000000..55927fd
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/imgadm.js
@@ -0,0 +1,4329 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * The main imgadm functionality. The CLI is a light wrapper around this tool.
+ *
+ *      var imgadm = require('./imgadm');
+ *      var bunyan = require('bunyan');
+ *      var log = bunyan.createLogger({name: 'foo'});
+ *      imgadm.createTool({log: log}, function (err, tool) {
+ *
+ *          tool.listImages(function (err, images) { ... });
+ *          // ...
+ *
+ *      });
+ */
+
+var p = console.warn;
+
+var assert = require('assert-plus');
+var async = require('async');
+var child_process = require('child_process'),
+    spawn = child_process.spawn,
+    execFile = child_process.execFile,
+    exec = child_process.exec;
+var crypto = require('crypto');
+var dsapi = require('sdc-clients/lib/dsapi');
+var EventEmitter = require('events').EventEmitter;
+var findit2 = require('findit2');
+var fs = require('fs');
+var genUuid = require('node-uuid');
+var imgapi = require('sdc-clients/lib/imgapi');
+var imgmanifest = require('imgmanifest');
+var lock = require('./locker.js').lock;
+var mkdirp = require('mkdirp');
+var once = require('once');
+var path = require('path');
+var ProgressBar = require('progbar').ProgressBar;
+var rimraf = require('rimraf');
+var url = require('url');
+var util = require('util'),
+    format = util.format;
+var vasync = require('vasync');
+var zfs = require('./zfs.js').zfs;
+
+var common = require('./common'),
+    NAME = common.NAME,
+    DB_DIR = common.DB_DIR,
+    indent = common.indent,
+    objCopy = common.objCopy,
+    assertUuid = common.assertUuid,
+    execFilePlus = common.execFilePlus,
+    execPlus = common.execPlus;
+var configuration = require('./configuration');
+var Database = require('./database');
+var errors = require('./errors');
+var magic = require('./magic');
+var mod_sources = require('./sources');
+var upgrade = require('./upgrade');
+
+
+
+// ---- globals
+
+var CONFIG_PATH = DB_DIR + '/imgadm.conf';
+var DEFAULT_SDC_VERSION = '7.0';
+var DEFAULT_CONFIG = {};
+var SET_REQUIREMENTS_BRAND_BRANDS = ['bhyve', 'lx', 'kvm'];
+
+/* BEGIN JSSTYLED */
+// In zones, we don't have 'SDC Version' in sysinfo, but we know
+// we're always at least SDC 7.0.
+var VMADM_FS_NAME_RE = /^([a-zA-Z0-9][a-zA-Z0-9\/\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})(-disk\d+)?$/;
+var VMADM_IMG_NAME_RE = /^([a-zA-Z0-9][a-zA-Z0-9\/\._-]*)\/([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})$/;
+var UUID_RE = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/;
+/* END JSSTYLED */
+
+var UA = 'imgadm/' + common.getVersion()
+    + ' (' + 'node/' + process.versions.node + '; '
+    + 'OpenSSL/' + process.versions.openssl + ')';
+
+
+
+// ---- internal support stuff
+
+function getSysinfo(callback) {
+    assert.func(callback, 'callback');
+    execFile('/usr/bin/sysinfo', function (err, stdout, stderr) {
+        if (err) {
+            callback(err);
+        } else {
+            // Explicitly want to abort/coredump on this not being parsable.
+            var sysinfo = JSON.parse(stdout.trim());
+            callback(null, sysinfo);
+        }
+    });
+}
+
+
+/**
+ * Return an error if min_platform or max_platform isn't satisfied with the
+ * current platform version.
+ *
+ * @param opts:
+ *      - sysinfo {Object} sysinfo for this platform
+ *      - manifest {Object} the manifest to check
+ * @returns null or an error
+ */
+function checkMinMaxPlatformSync(opts) {
+    assert.object(opts, 'opts');
+    assert.object(opts.manifest, 'opts.manifest');
+    assert.object(opts.sysinfo, 'opts.sysinfo');
+
+    var minPlatSpec = opts.manifest.requirements
+        && opts.manifest.requirements.min_platform;
+    var maxPlatSpec = opts.manifest.requirements
+        && opts.manifest.requirements.max_platform;
+    if (!minPlatSpec && !maxPlatSpec) {
+        return null;
+    }
+
+    // SDC 6.5 sysinfo is missing 'SDC Version' key in sysinfo.
+    var platVer = opts.sysinfo['SDC Version'] || DEFAULT_SDC_VERSION;
+    var platTimestamp = opts.sysinfo['Live Image'];
+
+    if (minPlatSpec) {
+        if (minPlatSpec[platVer]) {
+            if (platTimestamp < minPlatSpec[platVer]) {
+                return new errors.MinPlatformError(platVer,
+                    platTimestamp, minPlatSpec);
+            }
+        } else {
+            /*
+             * From the IMGAPI docs:
+             * 2. if SDC version is greater than the lowest key,
+             *    e.g. if "7.0" for the example above, then this
+             *    image may be used on this platform.
+             */
+            var lowestSpecVer = Object.keys(minPlatSpec).sort()[0];
+            if (platVer < lowestSpecVer) {
+                return new errors.MinPlatformError(platVer,
+                    platTimestamp, minPlatSpec);
+            }
+        }
+    }
+
+    if (maxPlatSpec) {
+        if (maxPlatSpec[platVer]) {
+            if (platTimestamp > maxPlatSpec[platVer]) {
+                return new errors.MaxPlatformError(platVer,
+                    platTimestamp, maxPlatSpec);
+            }
+        } else {
+            /*
+             * From the IMGAPI docs:
+             * 1. if SDC version is greater than the highest key,
+             *    e.g. if "7.2" for the example above, then this
+             *    image may not be used on this platform.
+             */
+            var highestSpecVer = Object.keys(maxPlatSpec)
+                .sort().slice(-1)[0];
+            if (platVer > highestSpecVer) {
+                return new errors.MaxPlatformError(platVer,
+                    platTimestamp, maxPlatSpec);
+            }
+        }
+    }
+
+    return null;
+}
+
+
+/**
+ * Call `zfs destroy -r` on the given dataset name.
+ *
+ * TODO: use zfs.js (OS-1919).
+ */
+function zfsDestroy(dataset, log, callback) {
+    assert.string(dataset, 'dataset');
+    assert.object(log, 'log');
+    assert.func(callback, 'callback');
+    var cmd = format('/usr/sbin/zfs destroy -r %s', dataset);
+    exec(cmd, function (err, stdout, stderr) {
+        log.trace({cmd: cmd, err: err, stdout: stdout, stderr: stderr},
+            'zfsDestroy');
+        callback(err);
+    });
+}
+
+/**
+ * Call `zfs rename -r SNAPSHOT SNAPSHOT`.
+ *
+ * @param a {String} The current snapshot name.
+ * @param b {String} The snapshot name to which to rename.
+ * @param options {Object}
+ *      - recursive {Boolean} Optional. Use '-r' arg to 'zfs rename'.
+ *      - log {Bunyan Logger}
+ * @param callback {Function} `function (err)`
+ */
+function zfsRenameSnapshot(a, b, options, callback) {
+    assert.string(a, 'a');
+    assert.string(b, 'b');
+    assert.object(options, 'options');
+    assert.optionalBool(options.recursive, 'options.recursive');
+    assert.object(options.log, 'options.log');
+    assert.func(callback);
+    var optStr = '';
+    if (options.recursive) {
+        optStr += ' -r';
+    }
+    var cmd = format('/usr/sbin/zfs rename%s %s', optStr, a, b);
+    options.log.trace({cmd: cmd}, 'start zfsRenameSnapshot');
+    exec(cmd, function (err, stdout, stderr) {
+        options.log.trace({cmd: cmd, err: err, stdout: stdout, stderr: stderr},
+            'finish zfsRenameSnapshot');
+        callback(err);
+    });
+}
+
+/**
+ * Get details on a ZFS dataset.
+ *
+ * @param name {String} The zfs dataset name, "$pool/$uuid".
+ * @param properties {Array} Optional array of property names to get.
+ *      "name" is always included. "children" is special: it does extra work
+ *      to gather the list of child snapshots and dependent clones.
+ * @param callback {Function} `function (err, dataset)`
+ *      Returns `callback(null, null)` if the dataset name doesn't exist.
+ *
+ * TODO: use zfs.js (OS-1919).
+ */
+function getZfsDataset(name, properties, callback) {
+    assert.string(name, 'name');
+    if (callback === undefined) {
+        callback = properties;
+        properties = [];
+    }
+    assert.arrayOfString(properties, 'properties');
+
+    if (properties.indexOf('name') === -1) {
+        properties.push('name');
+    }
+    var cIdx = properties.indexOf('children');
+    if (cIdx !== -1) {
+        properties.splice(cIdx);
+    }
+    var dataset;
+
+    function getDataset(next) {
+        var cmd = format('/usr/sbin/zfs list -H -p -o %s %s',
+            properties.join(','), name);
+        exec(cmd, {maxBuffer: 10485760}, function (err, stdout, stderr) {
+            if (err) {
+                // `zfs list` *seems* to exit 2 for bogus properties and 1 for
+                // non-existant dataset.
+                if (err.code === 1) {
+                    dataset = null;
+                    next();
+                    return;
+                } else {
+                    next(new errors.InternalError({
+                        cause: err,
+                        message: format('error running "%s": %s', cmd,
+                            stderr.split('\n', 1)[0])
+                    }));
+                    return;
+                }
+            }
+            var values = stdout.trim().split('\t');
+            dataset = {};
+            for (var i = 0; i < properties.length; i++) {
+                dataset[properties[i]] = values[i] === '-' ? null : values[i];
+            }
+            next();
+        });
+    }
+
+    function getChildSnapshots(next) {
+        if (!dataset) {
+            next();
+            return;
+        }
+        dataset.children = {};
+        var cmd = format('/usr/sbin/zfs list -t all -pHr -o name %s', name);
+        exec(cmd, {maxBuffer: 10485760}, function (err, stdout, stderr) {
+            if (err) {
+                next(new errors.InternalError({
+                    cause: err,
+                    message: format('error running "%s": %s', cmd,
+                        stderr.split('\n', 1)[0])
+                }));
+                return;
+            }
+            dataset.children.snapshots = stdout.trim().split(/\n/g).slice(1);
+            next();
+        });
+    }
+
+    /**
+     * Dependent clones of a dataset are zfs filesystems or volumes
+     * (-t filesystem,volume)
+     * created by `zfs clone` of a snapshot of the dataset in question.
+     * This snapshot is the `origin` property of that clone. A snapshot
+     * is named <dataset>@<snapshot-name>. Hence we can get a list via:
+     *
+     *      zfs list -t filesystem,volume -o origin,name -pH | grep '^NAME@'
+     *
+     * where 'NAME' is the dataset name.
+     */
+    function getDependentClones(next) {
+        if (!dataset) {
+            next();
+            return;
+        }
+        var cmd = '/usr/sbin/zfs list -t filesystem,volume -o origin,name -pH';
+        exec(cmd, {maxBuffer: 10485760}, function (err, stdout, stderr) {
+            if (err) {
+                next(new errors.InternalError({
+                    cause: err,
+                    message: format('error running "%s": %s', cmd, stderr)
+                }));
+                return;
+            }
+            var clones = dataset.children.clones = [];
+            var lines = stdout.trim().split(/\n/g);
+            var marker = name + '@';
+            for (var i = 0; i < lines.length; i++) {
+                var line = lines[i];
+                if (line.slice(0, marker.length) !== marker)
+                    continue;
+                clones.push(line.split(/\t/g)[1]);
+            }
+            next();
+        });
+    }
+
+    var funcs = [getDataset];
+    if (cIdx !== -1) {
+        funcs.push(getChildSnapshots);
+        funcs.push(getDependentClones);
+    }
+    async.waterfall(funcs, function (err) {
+        callback(err, dataset);
+    });
+}
+
+
+function checkFileChecksum(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.string(opts.file, 'opts.file');
+    assert.string(opts.checksum, 'opts.checksum'); // 'type:hexdigest'
+    assert.func(cb, 'cb');
+
+    var onceCb = once(cb);
+    var bits = opts.checksum.split(':');
+    var hash = crypto.createHash(bits[0]);
+
+    var stream = fs.createReadStream(opts.file);
+    stream.on('data', function (chunk) {
+        hash.update(chunk);
+    });
+    stream.on('error', onceCb);
+    stream.on('end', function () {
+        var checksumActual = hash.digest('hex');
+        if (checksumActual !== bits[1]) {
+            onceCb(new errors.DownloadError(format('file checksum (%s) '
+                + 'error: expected "%s", file "%s" checksum is "%s"',
+                bits[0], bits[1], opts.file, checksumActual)));
+        } else {
+            onceCb();
+        }
+    });
+}
+
+
+
+// ---- IMGADM tool
+
+function IMGADM(options) {
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+
+    this.log = options.log;
+    this._manifestFromUuid = null;
+    this.sources = null;
+    this._db = new Database(options);
+}
+
+IMGADM.prototype.init = function init(callback) {
+    var self = this;
+
+    var zonename;
+
+    function findZonename(next) {
+        execFile('/usr/bin/zonename', function _zonename(err, stdout, stderr) {
+            if (!err) {
+                zonename = stdout.trim();
+                if (zonename === 'global') {
+                    cb(new errors.UsageError('this version of imgadm only '
+                        + 'supports non-global zones'));
+                    return;
+                }
+            }
+            next(err);
+        });
+    }
+
+    function findZonesPool(next) {
+        execFile('/usr/sbin/zpool', [
+            'list',
+            '-Hpo',
+            'name'
+        ], function _onZpoolList(err, stdout, stderr) {
+            if (!err) {
+                if (stdout.trim() !== 'zones') {
+                    cb(new errors.UsageError('this version of imgadm only '
+                        + 'supports zpools named "zones"'));
+                    return;
+                }
+            }
+            next(err);
+        });
+    }
+
+    function findDelegated(next) {
+        var dsname = 'zones/' + zonename + '/data';
+
+        execFile('/usr/sbin/zfs', [
+            'list',
+            '-Hpo',
+            'name',
+            dsname
+        ], function _onZpoolList(err, stdout, stderr) {
+            if (!err) {
+                if (stdout.trim() !== dsname) {
+                    cb(new errors.UsageError('this version of imgadm only '
+                        + 'supports zones with delegated datasets named '
+                        + '"data"'));
+                    return;
+                }
+                self.DEFAULT_ZPOOL = common.DEFAULT_ZPOOL = dsname;
+            }
+            next(err);
+        });
+    }
+
+    function loadConfig(next) {
+        configuration.loadConfig({log: self.log}, function (err, config) {
+            self.config = config;
+            next(err);
+        });
+    }
+
+    function setUserAgent(next) {
+        self.userAgent = UA;
+        if (self.config && self.config.userAgentExtra) {
+            if (typeof (self.config.userAgentExtra) !== 'string') {
+                next(new errors.ConfigError(format(
+                    '"userAgentExtra" in config file "%s" is not a string',
+                    CONFIG_PATH)));
+                return;
+            }
+            self.userAgent += ' ' + self.config.userAgentExtra;
+        }
+        next();
+    }
+
+    function upgradeDb(next) {
+        upgrade.upgradeIfNecessary(self, next);
+    }
+
+    function addSources(next) {
+        self.sources = [];
+        var sourcesInfo = self.config.sources || [common.DEFAULT_SOURCE];
+        self.log.trace({sourcesInfo: sourcesInfo}, 'init: add sources');
+        async.forEachSeries(
+            sourcesInfo,
+            function oneSource(sourceInfo, nextSource) {
+                self._addSource(sourceInfo, true, nextSource);
+            },
+            function doneSources(err) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                next();
+            }
+        );
+    }
+
+    async.series([
+        findZonename,
+        findZonesPool,
+        findDelegated,
+        loadConfig,
+        setUserAgent,
+        upgradeDb,
+        addSources
+    ], callback);
+};
+
+
+IMGADM.prototype.saveConfig = function saveConfig(cb) {
+    assert.func(cb, 'cb');
+    var saveOpts = {log: this.log, config: this.config};
+    configuration.saveConfig(saveOpts, cb);
+};
+
+
+/**
+ * Add a source to the current IMGADM object, if it isn't already a source.
+ * It normalizes and handles DNS lookup as required.
+ *
+ * Note that this does *not* update the IMGADM config file.
+ *
+ * @param source {Object} A source info object with these keys:
+ *      - url {String}
+ *      - type {String}
+ *      - insecure {Boolean} Optional. Default false.
+ * @param skipPingCheck {Boolean} Whether to do a ping check on the new
+ *      source. This is done to verify that the given URL doesn't have
+ *      typos. By default the ping check is done when adding a source
+ *      (unless it is an existing source, i.e. if `source` is already a `Source`
+ *      instance).
+ * @param callback {Function} `function (err, changed, source)` where `changed`
+ *      is a boolean indicating if the config changed as a result.
+ */
+IMGADM.prototype._addSource = function _addSource(
+        sourceInfo, skipPingCheck, callback) {
+    assert.object(sourceInfo, 'sourceInfo');
+    assert.string(sourceInfo.url, 'sourceInfo.url');
+    assert.string(sourceInfo.type, 'sourceInfo.type');
+    assert.optionalBool(sourceInfo.insecure, 'sourceInfo.secure');
+    assert.bool(skipPingCheck, 'skipPingCheck');
+    assert.func(callback, 'callback');
+    var self = this;
+
+    // No-op if already have this URL/TYPE/INSECURE.
+    var normUrl = common.normUrlFromUrl(sourceInfo.url);
+    for (var i = 0; i < self.sources.length; i++) {
+        if (self.sources[i].normUrl === normUrl
+            && self.sources[i].type === sourceInfo.type
+            && self.sources[i].insecure === sourceInfo.insecure)
+        {
+            return callback(null, false, self.sources[i]);
+        }
+    }
+
+    // Else make a new Source instance.
+    var source = self.sourceFromInfo(sourceInfo);
+
+    if (skipPingCheck) {
+        self.sources.push(source);
+        callback(null, true, source);
+    } else {
+        source.ping(function (pingErr) {
+            if (pingErr) {
+                callback(pingErr);
+                return;
+            }
+            self.sources.push(source);
+            callback(null, true, source);
+        });
+    }
+};
+
+IMGADM.prototype.sourceFromInfo = function sourceFromInfo(sourceInfo) {
+    assert.object(sourceInfo, 'sourceInfo');
+    assert.string(sourceInfo.type, 'sourceInfo.type');
+
+    return mod_sources.createSource(sourceInfo.type, {
+        url: sourceInfo.url,
+        insecure: sourceInfo.insecure,
+        log: this.log,
+        userAgent: this.userAgent,
+        config: this.config
+    });
+};
+
+
+/**
+ * Remove a source from the current IMGADM object.
+ *
+ * Note that this does *not* update the IMGADM config file.
+ *
+ * @param sourceUrl {String}
+ * @param callback {Function} `function (err, deleted)` where `deleted` is
+ *      an array of `Source` instances deleted, if any.
+ */
+IMGADM.prototype._delSource = function _delSource(sourceUrl, callback) {
+    assert.string(sourceUrl, 'sourceUrl');
+    var normSourceUrl = common.normUrlFromUrl(sourceUrl);
+    var deleted = [];
+    this.sources = this.sources.filter(function (s) {
+        if (s.normUrl !== normSourceUrl) {
+            return true;
+        } else {
+            deleted.push(s);
+            return false;
+        }
+    });
+    callback(null, deleted.length ? deleted : null);
+};
+
+
+/**
+ * Add a source and update the on-disk config.
+ *
+ * @param sourceInfo {Object} Image source object with these keys:
+ *      - url {String}
+ *      - type {String}
+ *      - insecure {Boolean} Optional. Default false.
+ * @param skipPingCheck {Boolean} Whether to do a ping check on the new
+ *      source URL. Default false.
+ * @param callback {Function} `function (err, changed, source)`
+ */
+IMGADM.prototype.configAddSource = function configAddSource(
+        sourceInfo, skipPingCheck, callback) {
+    assert.object(sourceInfo, 'sourceInfo');
+    assert.string(sourceInfo.url, 'sourceInfo.url');
+    assert.string(sourceInfo.type, 'sourceInfo.type');
+    assert.bool(skipPingCheck, 'skipPingCheck');
+    assert.func(callback, 'callback');
+    var self = this;
+
+    self._addSource(sourceInfo, skipPingCheck, function (addErr, ch, source) {
+        if (addErr) {
+            callback(addErr);
+        } else if (ch) {
+            if (!self.config.sources) {
+                // Was implicitly getting the default source. Let's keep it.
+                self.config.sources = [common.DEFAULT_SOURCE];
+            }
+            self.config.sources.push(source.toJSON());
+            self.saveConfig(function (saveErr) {
+                if (saveErr) {
+                    callback(saveErr);
+                    return;
+                }
+                self.log.debug({source: source}, 'added source');
+                callback(null, true, source);
+            });
+        } else {
+            callback(null, false, source);
+        }
+    });
+};
+
+
+/**
+ * Delete a source URL and update the on-disk config.
+ *
+ * @param sourceUrl {String}
+ * @param callback {Function} `function (err, deleted)` where `deleted` is
+ *      an array of `Source` instances deleted, if any.
+ */
+IMGADM.prototype.configDelSourceUrl = function configDelSourceUrl(
+        sourceUrl, callback) {
+    assert.string(sourceUrl, 'sourceUrl');
+    var self = this;
+
+    self._delSource(sourceUrl, function (delErr, deleted) {
+        if (delErr) {
+            callback(delErr);
+        } else if (deleted) {
+            self.config.sources = self.sources.map(function (s) {
+                return s.toJSON();
+            });
+            self.saveConfig(function (saveErr) {
+                if (saveErr) {
+                    callback(saveErr);
+                    return;
+                }
+                self.log.debug({sourceUrl: sourceUrl}, 'deleted source url');
+                callback(null, deleted);
+            });
+        } else {
+            callback(null, null);
+        }
+    });
+};
+
+
+/**
+ * Update sources with the given URLs.
+ *
+ * Dev Notes: The histrionics below are to avoid re-running ping checks
+ * on already existing source URLs.
+ *
+ * @param sourcesInfo {Array} Array of source info objects (with type and
+ *      url keys, and optionally an 'insecure' key).
+ * @param skipPingCheck {Boolean} Whether to do a ping check on the new
+ *      source URL. Default false. However, a ping check is not done
+ *      on already existing sources.
+ * @param callback {Function} `function (err, changes)` where `changes` is
+ *      a list of changes of the form `{type: <type>, url: <url>}` where
+ *      `type` is one of 'reorder', 'add', 'del'.
+ */
+IMGADM.prototype.updateSources = function updateSources(
+        sourcesInfo, skipPingCheck, callback) {
+    assert.arrayOfObject(sourcesInfo, 'sourcesInfo');
+    assert.bool(skipPingCheck, 'skipPingCheck');
+    assert.func(callback, 'callback');
+    var self = this;
+    var i, j;
+
+    // Validate types
+    for (i = 0; i < sourcesInfo.length; i++) {
+        var si = sourcesInfo[i];
+        assert.string(si.url, format('sourcesInfo[%d].url', i));
+        assert.string(si.type, format('sourcesInfo[%d].type', i));
+        assert.optionalBool(si.insecure, format('sourcesInfo[%d].insecure', i));
+        if (common.VALID_SOURCE_TYPES.indexOf(si.type) === -1) {
+            callback(new errors.ConfigError(format(
+                'type "%s" for source url "%s" is invalid: must be one of "%s"',
+                si.type, si.url, common.VALID_SOURCE_TYPES.join('", "'))));
+        }
+    }
+
+    var changes = [];
+    var oldSources = self.sources.slice();
+    var newSources = [];
+    for (i = 0; i < sourcesInfo.length; i++) {
+        var sourceInfo = sourcesInfo[i];
+        var idx = -1;
+        for (j = 0; j < oldSources.length; j++) {
+            var old = oldSources[j];
+            if (old && old.type === sourceInfo.type
+                && old.url === sourceInfo.url
+                && old.insecure === sourceInfo.insecure)
+            {
+                idx = j;
+                break;
+            }
+        }
+        if (idx === -1) {
+            newSources.push(sourceInfo);
+        } else {
+            newSources.push(self.sources[idx]);
+            oldSources[idx] = null;
+        }
+    }
+    oldSources
+        .filter(function (s) { return s !== null; })
+        .forEach(function (s) { changes.push({type: 'del', source: s}); });
+    if (changes.length === 0) {
+        changes.push({type: 'reorder'});
+    }
+
+    self.sources = [];
+    async.forEachSeries(
+        newSources,
+        function oneSource(s, next) {
+            self._addSource(s, skipPingCheck, function (err, changed, source) {
+                if (err) {
+                    next(err);
+                } else {
+                    assert.ok(changed);
+                    if (! mod_sources.isSource(s)) {
+                        // Add to 'changes' with the actual `Source` instance.
+                        changes.push({type: 'add', source: source});
+                    }
+                    next();
+                }
+            });
+        },
+        function doneSources(err) {
+            if (err) {
+                callback(err);
+                return;
+            }
+            self.config.sources = self.sources.map(function (s) {
+                return s.toJSON();
+            });
+            self.saveConfig(function (saveErr) {
+                if (saveErr) {
+                    callback(saveErr);
+                    return;
+                }
+                callback(null, changes);
+            });
+        }
+    );
+};
+
+
+IMGADM.prototype._errorFromClientError = function _errorFromClientError(
+        clientUrl, err) {
+    assert.string(clientUrl, 'clientUrl');
+    assert.object(err, 'err');
+    if (err.body && err.body.code) {
+        return new errors.APIError(clientUrl, err);
+    } else if (err.errno) {
+        return new errors.ClientError(clientUrl, err);
+    } else {
+        return new errors.InternalError({message: err.message,
+            clientUrl: clientUrl, cause: err});
+    }
+};
+
+
+
+/**
+ * Save image info to the db.
+ *
+ * @param imageInfo {Object} Holds image details, with keys:
+ *      - manifest {Object}
+ *      - zpool {String} The zpool on which the image is installed.
+ *      - source {String} The source object.
+ * @param callback {Function} `function (err)`
+ */
+IMGADM.prototype.dbAddImage = function dbAddImage(imageInfo, callback) {
+    this._db.addImage(imageInfo, callback);
+};
+
+
+/**
+ * Load images from the system and merge in manifest data from the imgadm
+ * cache/database.
+ *
+ * @param callback {Function} `function (err, imagesInfo)`
+ */
+IMGADM.prototype._loadImages = function _loadImages(callback) {
+    var self = this;
+    var i;
+
+    // Get a list of provisionable images. Here 'provisionable' means that
+    // we are also constrained by 'vmadm create' rules. That means a
+    // zfs "filesystem" (for zones) or "volume" (for KVM VMs) named
+    // "$zpoolname/$uuid" whose mountpoint is not a zone root. Full images
+    // won't have an origin, incremental images will.
+    //
+    // These conditions can conceivably include non-images: any clone not a
+    // zone and named "ZPOOL/UUID". For this reason, any zfs dataset with
+    // the property imgadm:ignore=true will be excluded, as an out.
+    //
+    // If necessary we could consider only include those with an origin
+    // (i.e. incremental images) that also have a "@final" snapshot, as
+    // recent imgadm guarantees on import.
+    //
+    // We also count the usages of these images: zfs filesystems with the
+    // image as an origin.
+
+    /* BEGIN JSSTYLED */
+    // Example output:
+    //      0:global:running:/::liveimg:shared:
+    //      ...
+    //      21:dc5cbce7-798a-4bc8-bdc5-61b4be00a22e:running:/zones/dc5cbce7-798a-4bc8-bdc5-61b4be00a22e:dc5cbce7-798a-4bc8-bdc5-61b4be00a22e:joyent-minimal:excl:21
+    //      -:7970c690-1738-4e58-a04f-8ce4ea8ebfca:installed:/zones/7970c690-1738-4e58-a04f-8ce4ea8ebfca:7970c690-1738-4e58-a04f-8ce4ea8ebfca:kvm:excl:22
+    /* END JSSTYLED */
+    execPlus({
+        command: '/usr/sbin/zoneadm list -pc',
+        log: self.log,
+        errMsg: 'could not list zones',
+        execOpts: {
+            maxBuffer: 10485760  /* >200k hit in prod, 10M should suffice */
+        }
+    }, function (zErr, zStdout, zStderr) {
+        if (zErr) {
+            callback(zErr);
+            return;
+        }
+        var zLines = zStdout.trim().split('\n');
+        var zoneRoots = {};
+        zLines.forEach(function (zLine) {
+            var zoneRoot = zLine.split(/:/g)[3];
+            zoneRoots[zoneRoot] = true;
+        });
+
+        /*
+         * PERF Note: Snapshots are gathered to do that (hopefully rare)
+         * `hasFinalSnap` exclusions below. That can add 10%-20% (or
+         * theoretically) more time to `imgadm list`. If that's a problem
+         * we might want an option to exclude that processing if the caller
+         * is fine with false positives.
+         */
+        execPlus({
+            command: '/usr/sbin/zfs list -t filesystem,volume,snapshot -pH '
+                + '-o name,origin,mountpoint,imgadm:ignore',
+            log: self.log,
+            errMsg: 'could not load images',
+            execOpts: {
+                maxBuffer: 10485760  /* >200k hit in prod, 10M should suffice */
+            }
+        }, function (zfsErr, stdout, stderr) {
+            if (zfsErr) {
+                callback(zfsErr);
+                return;
+            }
+            var lines = stdout.trim().split('\n');
+            var name;
+
+            // First pass to gather which filesystems have '@final' snapshot.
+            var hasFinalSnap = {};  /* 'zones/UUID' => true */
+            for (i = 0; i < lines.length; i++) {
+                name = lines[i].split('\t', 1)[0];
+                if (name.slice(-6) === '@final') {
+                    hasFinalSnap[name.slice(0, -6)] = true;
+                }
+            }
+
+            var imageNames = [];
+            var usageFromImageName = {};
+            for (i = 0; i < lines.length; i++) {
+                var line = lines[i].trim();
+                if (line.length === 0)
+                    continue;
+                var parts = line.split('\t');
+                assert.equal(parts.length, 4);
+                name = parts[0];
+                var origin = parts[1];
+                var mountpoint = parts[2];
+                var ignore = parts[3];
+
+                if (!VMADM_FS_NAME_RE.test(name))
+                    continue;
+
+                if (
+                    /*
+                     * If it has a mountpoint from `zoneadm list` it is
+                     * a zone, not an image.
+                     */
+                    !zoneRoots[mountpoint]
+                    /*
+                     * If it doesn't match `VMADM_IMG_NAME_RE` it is a KVM
+                     * disk volume, e.g. 'zones/UUID-disk0' or a snapshot,
+                     * e.g. 'zones/UUID@SNAP'.
+                     */
+                    && VMADM_IMG_NAME_RE.test(name)
+                    /*
+                     * If it has a 'zones/UUID@final' origin (i.e. it was
+                     * cloned from a modern-enough imgadm that enforced @final),
+                     * but does *not* have a @final snapshot itself, then
+                     * this isn't an image.
+                     */
+                    && !(origin.slice(-6) === '@final' && !hasFinalSnap[name])
+                    )
+                {
+                    // Gracefully handle 'imgadm:ignore' boolean property.
+                    if (ignore !== '-') {
+                        try {
+                            ignore = common.boolFromString(ignore, false,
+                                '"imgadm:ignore" zfs property');
+                        } catch (e) {
+                            self.log.warn('dataset %s: %s', name, e);
+                            ignore = false;
+                        }
+                    } else {
+                        ignore = false;
+                    }
+                    if (!ignore) {
+                        imageNames.push(name);
+                    }
+                }
+                if (origin !== '-') {
+                    // This *may* be a filesystem using an image. See
+                    // joyent/smartos-live#180 for a counter-example.
+                    var oname = origin.split('@')[0];
+                    if (usageFromImageName[oname] === undefined) {
+                        usageFromImageName[oname] = [name];
+                    } else {
+                        usageFromImageName[oname].push(name);
+                    }
+                }
+            }
+
+            var imagesInfo = [];
+            async.forEachSeries(
+                imageNames,
+                function loadOne(imageName, next) {
+                    var parsed = VMADM_FS_NAME_RE.exec(imageName);
+                    var opts = {uuid: parsed[2], zpool: parsed[1]};
+                    self._db.loadImage(opts, function (err, info) {
+                        if (err) {
+                            next(err);
+                            return;
+                        }
+                        info.cloneNames = usageFromImageName[imageName] || [];
+                        info.clones = info.cloneNames.length;
+                        imagesInfo.push(info);
+                        next();
+                    });
+                },
+                function doneLoading(err) {
+                    if (err) {
+                        callback(err);
+                    } else {
+                        callback(null, imagesInfo);
+                    }
+                }
+            );
+        });
+    });
+};
+
+
+/**
+ * Load info on the given locally installed image uuid.
+ *
+ * We don't just load "$uuid.json" from the imgadm db, because there might
+ * be zombies (i.e. if the image was destroyed behind imgadm's back).
+ *
+ * @param options {Object} with:
+ *      - @param uuid {String}
+ *      - @param zpool {String}
+ *      - @param children {Boolean} Optional. Set to true to also gather a
+ *          list of child snapshots and dependent clones. Default is false.
+ * @param callback {Function} `function (err, imageInfo)`
+ *      If the image is not found it does `callback(null, null)`.
+ */
+IMGADM.prototype.getImage = function getImage(options, callback) {
+    assert.object(options, 'options');
+    assertUuid(options.uuid, 'options.uuid');
+    assert.string(options.zpool, 'options.zpool');
+    assert.optionalBool(options.children, 'options.children');
+    assert.func(callback, 'callback');
+    var self = this;
+
+    var name = format('%s/%s', options.zpool, options.uuid);
+    var properties = ['name'];
+    if (options.children) {
+        properties.push('children');
+    }
+    getZfsDataset(name, properties, function (zfsErr, dataset) {
+        if (zfsErr) {
+            callback(zfsErr);
+            return;
+        } else if (!dataset) {
+            callback(null, null);
+            return;
+        }
+        self._db.loadImage(options, function (loadErr, info) {
+            if (loadErr) {
+                callback(loadErr);
+                return;
+            }
+            if (options.children) {
+                info.children = dataset.children;
+            }
+            callback(null, info);
+        });
+    });
+};
+
+
+
+/**
+ * Return available images from all sources.
+ *
+ * Limitations:
+ * - This is not supported for Docker sources (they are skipped).
+ *
+ * @param cb {Function} `function (err, imagesInfo)`
+ *      If there is an error then `err` will be set. Note that `imagesInfo`
+ *      will still contain results. This is so that an error in one source
+ *      does not break everything.
+ */
+IMGADM.prototype.sourcesList = function sourcesList(cb) {
+    var self = this;
+
+    if (self.sources.length === 0) {
+        cb(new errors.NoSourcesError());
+        return;
+    }
+
+    var imagesFromSourceUrl = {};
+    var errs = [];
+    vasync.forEachParallel({
+        inputs: self.sources,
+        func: function oneSource(source, next) {
+            if (source.type === 'docker') {
+                next();
+                return;
+            }
+            source.listImages(function (err, images) {
+                if (err) {
+                    errs.push(err);
+                } else if (images) {
+                    imagesFromSourceUrl[source.url] = images;
+                }
+                next();
+            });
+        }
+    }, function finishSourcesList(err) {
+        if (!err && errs.length) {
+            err = (errs.length === 1 ? errs[0] : new errors.MultiError(errs));
+        }
+
+        var imagesInfo = [];
+        var imageFromUuid = {};
+        self.log.trace({imagesFromSourceUrl: imagesFromSourceUrl},
+            'images from each source');
+        var sourceUrls = Object.keys(imagesFromSourceUrl);
+        for (var i = 0; i < sourceUrls.length; i++) {
+            var images = imagesFromSourceUrl[sourceUrls[i]];
+            if (!images) {
+                continue;
+            }
+            for (var j = 0; j < images.length; j++) {
+                var image = images[j];
+                var uuid = image.uuid;
+                if (imageFromUuid[uuid] === undefined) {
+                    imageFromUuid[uuid] = image;
+                    imagesInfo.push({manifest: image, source: sourceUrls[i]});
+                }
+            }
+        }
+        cb(err, imagesInfo);
+    });
+};
+
+
+/**
+ * Get import info on the given image/repo from sources.
+ *
+ * @param opts {Object}
+ *      - @param arg {String} Required. The import arg, e.g. a UUID for an
+ *        IMGAPI source or a `docker pull ARG` for a Docker source.
+ *      - @param sources {Array} Optional. An optional override to the set
+ *        of sources to search. Defaults to `self.sources`.
+ *      - @param ensureActive {Boolean} Optional. Default true. Set to false
+ *        to have imgapi source searches exclude inactive images.
+ * @param cb {Function} `function (err, importInfo)` where `importInfo`
+ *      is `{uuid: <uuid>, source: <source>, ...opt source-specific fields...}`
+ */
+IMGADM.prototype.sourcesGetImportInfo =
+        function sourcesGetImportInfo(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.string(opts.arg, 'opts.arg');
+    assert.optionalArrayOfObject(opts.sources, 'opts.sources');
+    assert.optionalBool(opts.ensureActive, 'opts.ensureActive');
+    var ensureActive = (opts.ensureActive === undefined
+            ? true : opts.ensureActive);
+    assert.func(cb, 'cb');
+
+    var sources = opts.sources || self.sources;
+    if (sources.length === 0) {
+        cb(new errors.NoSourcesError());
+        return;
+    }
+
+    var importInfo = null;
+    var errs = [];
+    vasync.forEachPipeline({
+        inputs: sources,
+        func: function oneSource(source, next) {
+            if (importInfo) {
+                next();
+                return;
+            }
+            var getOpts = {
+                arg: opts.arg,
+                ensureActive: ensureActive
+            };
+            source.getImportInfo(getOpts, function (err, info) {
+                if (err) {
+                    errs.push(err);
+                } else if (info) {
+                    importInfo = info;
+                    importInfo.source = source;
+                }
+                next();
+            });
+        }
+    }, function finish(err) {
+        if (!err && errs.length) {
+            err = (errs.length === 1 ? errs[0] : new errors.MultiError(errs));
+        }
+        cb(err, importInfo);
+    });
+};
+
+
+/**
+ * List locally install images.
+ *
+ * Here `imagesInfo` is an array of objects like this:
+ *      {
+ *          manifest: {
+ *              uuid: UUID,
+ *              ...     // may only be uuid if don't have IMGAPI manifest info
+ *              ...
+ *          },
+ *          source: SOURCE-URL,
+ *          clones: N   // number of zfs clones from this image
+ *          cloneNames: ['zones/UUID1', ...]    // if `opts.cloneNames`
+ *      }
+ *
+ * @param callback {Function} `function (err, imagesInfo)`
+ */
+IMGADM.prototype.listImages = function listImages(callback) {
+    this._loadImages(function (err, imagesInfo) {
+        if (err) {
+            callback(err);
+        } else {
+            callback(null, imagesInfo);
+        }
+    });
+};
+
+
+/**
+ * Delete the given image.
+ *
+ * Dev notes:
+ * - Bail if have child clones (We don't support a '-R' recursive delete
+ *   option like `zfs destroy -R`. Too dangerous.)
+ * - `zfs destroy ZPOOL/UUID` before updating imgadm db, in case we fail
+ *   on a race (e.g., someone just cloned it).
+ * - Remove imgadm db info.
+ *
+ * @param options {Object}:
+ *      - @param uuid {String}
+ *      - @param zpool {String}
+ *      - @param skipChecks {Boolean} Optional. Default false. If true, will
+ *        skip the (slightly costly) check for whether the image exists
+ *        and has dependent clones.
+ * @param callback {Function} `function (err)`
+ */
+IMGADM.prototype.deleteImage = function deleteImage(options, callback) {
+    var self = this;
+    assert.object(options, 'options');
+    assertUuid(options.uuid, 'options.uuid');
+    assert.string(options.zpool, 'options.zpool');
+    assert.optionalBool(options.skipChecks, 'options.skipChecks');
+    assert.func(callback, 'callback');
+    var uuid = options.uuid;
+    var zpool = options.zpool;
+
+    vasync.pipeline({funcs: [
+        function checks(_, next) {
+            if (options.skipChecks) {
+                next();
+                return;
+            }
+
+            var getOpts = {uuid: uuid, zpool: zpool, children: true};
+            self.getImage(getOpts, function (err, imageInfo) {
+                if (err) {
+                    next(err);
+                } else if (!imageInfo) {
+                    next(new errors.ImageNotInstalledError(zpool, uuid));
+                } else if (imageInfo.children.clones.length > 0) {
+                    next(new errors.ImageHasDependentClonesError(imageInfo));
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function del(_, next) {
+            execPlus({
+                command: format('/usr/sbin/zfs destroy -r %s/%s', zpool, uuid),
+                log: self.log,
+                errMsg: format('error deleting image "%s"', uuid)
+            }, function (err, stdout, stderr) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                self._db.deleteImage(options, next);
+            });
+        }
+    ]}, callback);
+};
+
+
+/**
+ * Import (find, download and install) the given image and, if necessary, its
+ * ancestry.
+ *
+ * @param opts {Object}
+ *      - @param importInfo {Object} Source-specific import info (from
+ *        `source.getImportInfo()`.
+ *      - @param zpool {String} The zpool to which to import.
+ *      - @param zstream {Boolean} Optional. Default false. If true, indicates
+ *        the GetImageFile will be a raw ZFS dataset stream.
+ *      - @param quiet {Boolean} Optional. Default false. Set to true
+ *        to not have a progress bar for the install.
+ *      - @param logCb {Function} Optional. A function that is called
+ *        with progress messages. It should support printf-like syntax,
+ *        e.g. passing console.log is legal.
+ * @param cb {Function} `function (err)`
+ */
+IMGADM.prototype.importImage = function importImage(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.importInfo, 'opts.importInfo');
+    assert.object(opts.importInfo.source, 'opts.importInfo.source');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.optionalBool(opts.zstream, 'opts.zstream');
+    assert.optionalBool(opts.quiet, 'opts.quiet');
+    assert.optionalFunc(opts.logCb, 'opts.logCb');
+
+    var manifest = opts.importInfo.manifest;
+    if (manifest) {
+        // Ensure this image is active.
+        if (manifest.state !== 'active') {
+            cb(new errors.ImageNotActiveError(manifest.uuid));
+            return;
+        }
+    }
+
+    this._importImage(opts, cb);
+};
+
+
+/**
+ * Download one image file to a local temp directory.
+ *
+ * @param opts {Object}
+ *      - source
+ *      - bar
+ *      - logCb
+ *      - importInfo
+ *      - imgMeta
+ *      - @param zstream {Boolean} Optional. Default false. If true, indicates
+ *        the GetImageFile will be a raw ZFS dataset stream.
+ * @param cb {Function} `function (err, downloadInfo)` where `downloadInfo` is
+ *      {
+ *          "path": "/var/tmp/.imgadm-downloads/$uuid.file",
+ *          "size": <content-length>
+ *      }
+ */
+IMGADM.prototype._downloadImageFile = function _downloadImageFile(opts, cb) {
+    var self = this;
+    assert.func(cb, 'cb');
+    assert.object(opts, 'opts');
+    assert.object(opts.source, 'opts.source');
+    assert.optionalObject(opts.bar, 'opts.bar');
+    assert.optionalBool(opts.zstream, 'opts.zstream');
+    assert.func(opts.logCb, 'opts.logCb');
+    // As from `source.getImportInfo`.
+    assert.object(opts.importInfo, 'opts.importInfo');
+    // As from `source.getImgMeta`.
+    assert.object(opts.imgMeta, 'opts.imgMeta');
+    assert.optionalNumber(opts.imgMeta.size, 'opts.imgMeta.size');
+    assert.optionalString(opts.imgMeta.checksum, 'opts.imgMeta.checksum');
+
+    var log = self.log;
+    var uuid = opts.importInfo.uuid;
+    var zstream = Boolean(opts.zstream);
+    var downFile = common.downloadFileFromUuid(uuid);
+    var context = {};
+    var cosmicRay = common.testForCosmicRay('download');
+
+    /**
+     * Return an event emitter on which we announce the 'content-length' when
+     * we have it.
+     */
+    var ee = new EventEmitter();
+
+    vasync.pipeline({arg: context, funcs: [
+        function skipIfPreDownloaded(ctx, next) {
+            if (! fs.existsSync(downFile)) {
+                next();
+                return;
+            }
+
+            // If have an expected size, ensure any pre-downloaded file
+            // matches that.
+            if (opts.imgMeta.size) {
+                ctx.downFileStats = fs.statSync(downFile);
+                if (ctx.downFileStats.size !== opts.imgMeta.size) {
+                    log.info({uuid: uuid, downFile: downFile,
+                        actualSize: ctx.downFileStats.size,
+                        expectedSize: opts.imgMeta.size},
+                        'unexpected size for pre-downloaded image %s file, '
+                        + 'deleting and re-downloading', uuid);
+                    rimraf.sync(downFile);
+                    next();
+                    return;
+                }
+            }
+
+            // If have an expected checksum, ensure any pre-downloaded file
+            // matches that. On a match we skip out and use pre-downloaded file.
+            if (opts.imgMeta.checksum) {
+                var checkOpts = {
+                    file: downFile,
+                    checksum: opts.imgMeta.checksum
+                };
+                checkFileChecksum(checkOpts, function (err) {
+                    if (err) {
+                        log.info({err: err, uuid: uuid, downFile: downFile,
+                            expectedChecksum: opts.imgMeta.checksum},
+                            'unexpected checksum for pre-downloaded '
+                            + 'image %s file, re-downloading', uuid);
+                        rimraf.sync(downFile);
+                        next();
+                    } else {
+                        log.info({uuid: uuid, downFile: downFile},
+                            'using pre-downloaded image file (checksum match)');
+                        next(true); // early abort
+                    }
+                });
+            } else {
+                next();
+            }
+        },
+
+        function mkdirpDownDir(ctx, next) {
+            mkdirp(common.DOWNLOAD_DIR, next);
+        },
+
+        function getStream(ctx, next) {
+            ctx.stream = opts.source.getImgFileStream(opts.importInfo,
+                function (err, stream) {
+                    ctx.stream = stream;
+                    next(err);
+                }
+            );
+        },
+
+        function checkContentLength(ctx, next) {
+            if (zstream) {
+                next();
+                return;
+            }
+
+            ctx.cLen = Number(ctx.stream.headers['content-length']);
+            if (isNaN(ctx.cLen)) {
+                next(new errors.DownloadError('unexpected '
+                    + 'missing or invalid Content-Length header: '
+                    + ctx.stream.headers['content-length']));
+                return;
+            } else if (opts.imgMeta.size) {
+                // Sanity check: content-length === imgMeta.size
+                if (opts.imgMeta.size !== ctx.cLen) {
+                    next(new errors.DownloadError(format('unexpected '
+                        + 'mismatch between expected size, %d, and '
+                        + 'Content-Length header, %d',
+                        opts.imgMeta.size, ctx.cLen)));
+                    return;
+                }
+            } else {
+                // If have a pre-downloaded file of the right size, then use it.
+                if (ctx.downFileStats && ctx.downFileStats.size === ctx.cLen)
+                {
+                    log.info({uuid: uuid, downFile: downFile},
+                        'using pre-downloaded image file '
+                        + '(Content-Length match)');
+                    next(true); // early abort
+                    return;
+                }
+            }
+
+            ee.emit('content-length', ctx.cLen);
+
+            next();
+        },
+
+        function downloadIt(ctx, next_) {
+            var next = once(next_);
+
+            var cosmicRayFunc;
+            if (cosmicRay) {
+                cosmicRayFunc = once(function () {
+                    next(new errors.DownloadError(format(
+                        'image %s cosmic ray error', uuid)));
+                    ctx.stream.unpipe(ctx.fout);
+                });
+            }
+
+            // Track size and checksum for checking.
+            ctx.bytesDownloaded = 0;
+            if (!zstream && opts.imgMeta.checksum) {
+                ctx.checksum = opts.imgMeta.checksum.split(':');
+                ctx.checksumHash = crypto.createHash(ctx.checksum[0]);
+                log.debug({uuid: uuid}, 'creating %s checksum hash',
+                    ctx.checksum[0]);
+            } else if (ctx.stream.headers['content-md5']) {
+                ctx.contentMd5 = ctx.stream.headers['content-md5'];
+                ctx.md5sumHash = crypto.createHash('md5');
+                log.debug({uuid: uuid}, 'creating content-md5 checksum hash');
+            }
+            ctx.stream.on('data', function (chunk) {
+                if (opts.bar)
+                    opts.bar.advance(chunk.length);
+                ctx.bytesDownloaded += chunk.length;
+                if (cosmicRay) {
+                    cosmicRayFunc();
+                }
+                if (ctx.checksumHash) {
+                    ctx.checksumHash.update(chunk);
+                }
+                if (ctx.md5sumHash) {
+                    ctx.md5sumHash.update(chunk);
+                }
+            });
+
+            ctx.downFilePartial = downFile + '.partial';
+            ctx.fout = fs.createWriteStream(ctx.downFilePartial);
+            ctx.stream.on('error', next);
+            ctx.fout.on('error', next);
+            ctx.fout.on('finish', next);
+            ctx.stream.pipe(ctx.fout);
+            ctx.stream.resume();
+        },
+
+        /**
+         * Ensure the streamed image data matches expected checksum and size.
+         */
+        function checksum(ctx, next) {
+            var errs = [];
+
+            if (ctx.cLen !== undefined && ctx.bytesDownloaded !== ctx.cLen) {
+                errs.push(new errors.DownloadError(format('image %s file size '
+                    + 'error: expected %d bytes, downloaded %d bytes',
+                    uuid, ctx.cLen, ctx.bytesDownloaded)));
+            }
+
+            if (ctx.checksumHash) {
+                var checksumActual = ctx.checksumHash.digest('hex');
+                if (checksumActual !== ctx.checksum[1]) {
+                    errs.push(new errors.DownloadError(format('image %s file '
+                        + 'checksum (%s) error: expected "%s", downloaded '
+                        + 'checksum was "%s"', uuid, ctx.checksum[0],
+                        ctx.checksum[1], checksumActual)));
+                }
+            }
+
+            if (ctx.md5sumHash) {
+                var md5sumActual = ctx.md5sumHash.digest('base64');
+                if (md5sumActual !== ctx.contentMd5) {
+                    errs.push(new errors.DownloadError(format('image %s file '
+                        + 'Content-MD5 error: expected "%s", downloaded '
+                        + 'checksum was "%s"', uuid,
+                        ctx.contentMd5, md5sumActual)));
+                }
+            }
+
+            if (errs.length === 1) {
+                next(errs[0]);
+            } else if (errs.length > 1) {
+                next(new errors.MultiError(errs));
+            } else {
+                log.info({uuid: opts.importInfo.uuid},
+                    'download passed size and checksum checks');
+                next();
+            }
+        },
+
+        function mvToFinalName(ctx, next) {
+            fs.rename(ctx.downFilePartial, downFile, function (err) {
+                delete ctx.downFilePartial;
+                next(err);
+            });
+        }
+
+    ]}, function (err) {
+        if (err === true) { // Signal for early abort.
+            err = null;
+        }
+
+        if (err) {
+            if (context.downFilePartial) {
+                rimraf(context.downFilePartial, function (rmErr) {
+                    if (rmErr) {
+                        log.warn({err: rmErr, uuid: uuid,
+                            path: context.downFilePartial},
+                            'could not remove partial download file');
+                    }
+                    cb(err);
+                });
+            } else {
+                cb(err);
+            }
+        } else {
+            var downloadInfo = {
+                path: downFile,
+                size: context.bytesDownloaded || opts.imgMeta.size
+            };
+            cb(null, downloadInfo);
+        }
+    });
+
+    return ee;
+};
+
+
+
+/**
+ * Do the work for `importImage`.
+ *
+ * tl;dr on import process:
+ *  - Gather `installedImageFromName` and `irecs` (Import RECords, one for each
+ *    image to download).
+ *  - `getMetaQ` to get meta info (i.e. the manifest et al) from source
+ *  - `downloadQ` to download all the image files to /var/tmp
+ *  - `installQ` to install each image in order to the zpool
+ */
+IMGADM.prototype._importImage = function _importImage(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.object(opts.importInfo, 'opts.importInfo');
+    assert.uuid(opts.importInfo.uuid, 'opts.importInfo.uuid');
+    assert.object(opts.importInfo.source, 'opts.importInfo.source');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.optionalBool(opts.zstream, 'opts.zstream');
+    assert.optionalBool(opts.quiet, 'opts.quiet');
+    assert.optionalFunc(opts.logCb, 'opts.logCb');
+
+    // Print timing info.
+    // var _TIMES = {};
+    // function TIME(name) {
+    //     if (_TIMES[name]) {
+    //         logCb('TIME(%s): %ss', name, (Date.now() - _TIMES[name]) / 1000);
+    //     }
+    //     _TIMES[name] = Date.now();
+    // }
+    function TIME() { }  // uncomment to disable timings
+
+    var log = self.log;
+    var logCb = opts.logCb || function () {};
+    var zpool = opts.zpool;
+    var importInfo = opts.importInfo;
+    var source = importInfo.source;
+    // If this will be a raw zstream, then we ignore
+    // 'manifest.files[0].{sha1|size}'.
+    var zstream = Boolean(opts.zstream);
+
+    // TODO: refactor: move these to `ctx`.
+    var canCloseInstallQ = false;
+    var onDeck = {};  // <uuid> -> <irec>; `irec` stands for `import record`
+    var bar;  // progress bar
+    var unlockInfos;
+    var irecs;
+
+    // `bar.log` conflicts with `logCb`. It would require
+    // something more capable than `logCb` to do right.
+    var barLogCb = function (msg) {
+        if (bar) {
+            bar.log(msg);
+        } else {
+            logCb(msg);
+        }
+    };
+
+    logCb('Importing %s from "%s"',
+        source.titleFromImportInfo(opts.importInfo), source.url);
+
+    var context = {};
+    vasync.pipeline({arg: context, funcs: [
+        function gatherSysinfo(ctx, next) {
+            getSysinfo(function (err, sysinfo) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                ctx.sysinfo = sysinfo;
+                next();
+            });
+        },
+
+        /**
+         * "irec" == import record, one for each image/layer we need to
+         * download and install.
+         */
+        function createIrecs(ctx, next) {
+            vasync.parallel({funcs: [
+                function loadInstalledImages(nextGather) {
+                    TIME('loadImages');
+                    self._loadImages(function onLoadImages(err, imagesInfo) {
+                        TIME('loadImages');
+                        if (err) {
+                            nextGather(err);
+                            return;
+                        }
+
+                        ctx.installedImageFromName = {};
+                        for (var i = 0; i < imagesInfo.length; i++) {
+                            var info = imagesInfo[i];
+                            var name = info.zpool + '/' + info.manifest.uuid;
+                            ctx.installedImageFromName[name] = info;
+                        }
+                        nextGather();
+                    });
+                },
+
+                function getTargetImgAncestry(nextGather) {
+                    logCb('Gather image %s ancestry', importInfo.uuid);
+                    TIME('ancestry');
+                    source.getImgAncestry(importInfo, function (err, ancestry) {
+                        TIME('ancestry');
+                        ctx.ancestry = ancestry;
+                        log.debug({err: err, ancestry: ancestry},
+                            'img ancestry');
+                        if (err) {
+                            nextGather(err);
+                            return;
+                        }
+                        irecs = ancestry.map(function (a) {
+                            return {
+                                uuid: a.uuid,
+                                // Prefer the top `importInfo` for the top-level
+                                // image as it may have more fields.
+                                importInfo: (a.uuid === importInfo.uuid
+                                    ? importInfo
+                                    : a)
+                            };
+                        });
+                        nextGather();
+                    });
+                }
+            ]}, next);
+        },
+
+        function filterOutAlreadyInstalled(ctx, next) {
+            ctx.isInstalledFromUuid = {};
+            var filteredIrecs = [];
+            for (var i = 0; i < irecs.length; i++) {
+                var irec = irecs[i];
+                var info = ctx.installedImageFromName[zpool + '/' + irec.uuid];
+                if (info) {
+                    ctx.isInstalledFromUuid[irec.uuid] = true;
+                    logCb('Image %s already installed', irec.uuid);
+                } else {
+                    filteredIrecs.push(irec);
+                }
+            }
+            irecs = filteredIrecs;
+            next();
+        },
+
+        function acquireLocks(ctx, next) {
+            var lockOpts = {
+                uuids: irecs.map(function (irec) { return irec.uuid; }),
+                logCb: logCb
+            };
+            self._lockAcquire(lockOpts, function (err, unlockInfos_) {
+                unlockInfos = unlockInfos_;
+                next(err);
+            });
+        },
+
+        // TODO: This should be done for *all* the irecs instead of just
+        //       the top level. Release the lock for each already installed.
+        //       If irecs.length goes to zero, then done.
+        function checkIfImportedAfterLock(ctx, next) {
+            var getOpts = {
+                uuid: opts.importInfo.uuid,
+                zpool: opts.zpool
+            };
+            self.getImage(getOpts, function (getErr, ii) {
+                if (getErr) {
+                    next(getErr);
+                } else if (ii) {
+                    logCb('Image %s (%s@%s) was imported while '
+                        + 'waiting on lock', ii.manifest.uuid,
+                        ii.manifest.name, ii.manifest.version);
+                    next(true);  // early abort
+                } else {
+                    next();
+                }
+            });
+        },
+
+        /**
+         * Get imgMeta for all import records.
+         *
+         * We *could* break this out to separate Q so could get downloads
+         * started before having all meta.
+         */
+        function getMeta(ctx, next) {
+            var onceNext = once(next);
+            var cosmicRay = common.testForCosmicRay('get_meta');
+
+            var getMetaQ = vasync.queuev({
+                concurrency: 5,
+                worker: function getManifestIfNotInstalled(irec, nextManifest) {
+                    if (cosmicRay) {
+                        nextManifest(new errors.InternalError({
+                            message: 'getMeta cosmic ray'
+                        }));
+                        return;
+                    }
+
+                    source.getImgMeta(irec.importInfo, function (err, imgMeta) {
+                        if (err) {
+                            nextManifest(err);
+                            return;
+                        }
+                        // Note: the image *manifest* is `imgMeta.manifest`.
+                        irec.imgMeta = imgMeta;
+                        log.info({irec: irec}, 'got irec.imgMeta');
+
+                        nextManifest(checkMinMaxPlatformSync({
+                            sysinfo: ctx.sysinfo,
+                            manifest: imgMeta.manifest
+                        }));
+                    });
+                }
+            });
+
+            getMetaQ.on('end', function doneManifests() {
+                TIME('manifests');
+                onceNext();
+            });
+
+            function onTaskEnd(taskErr) {
+                if (taskErr && !getMetaQ.killed) {
+                    log.info({err: taskErr}, 'abort getMeta');
+                    logCb('Aborting (%s)', taskErr.message);
+                    getMetaQ.kill();
+                    onceNext(taskErr);
+                }
+            }
+
+            TIME('manifests');
+            getMetaQ.push(irecs, onTaskEnd);
+            getMetaQ.close();
+        },
+
+        /**
+         * Here we run downloads (`downloadQ`, concurrency=5) and installs
+         * into the zpool (`installQ`) in parallel. Most of the code is
+         * bookkeeping for:
+         * (a) error handling: abort cleanly on any error
+         * (b) installing in correct order: from base image up
+         * (c) cleaning up temp files
+         */
+        function downloadAndInstall(ctx, next) {
+            var onceNext = once(next);
+
+            var downloadQ = vasync.queuev({
+                concurrency: 5,
+                worker: function fetchImg(irec, nextDownload) {
+                    self.log.info({uuid: irec.uuid}, 'download image');
+                    var dlOpts = {
+                        source: source,
+                        importInfo: irec.importInfo,
+                        imgMeta: irec.imgMeta,
+                        zstream: zstream,
+                        bar: bar,
+                        logCb: logCb
+                    };
+                    var dlEvents = self._downloadImageFile(dlOpts,
+                            function (err, dlInfo) {
+                        if (err) {
+                            nextDownload(err);
+                            return;
+                        }
+
+                        self.log.info({uuid: irec.uuid, downloadInfo: dlInfo},
+                            'downloaded image');
+                        barLogCb(format('Downloaded image %s (%s)',
+                            irec.uuid, common.humanSizeFromBytes(dlInfo.size)));
+                        irec.downloadPath = dlInfo.path;
+
+                        var origin = irec.imgMeta.manifest.origin;
+                        if (!origin || ctx.isInstalledFromUuid[origin]) {
+                            if (!installQ.closed) {
+                                installQ.push(irec, onTaskEnd);
+                            }
+                        } else {
+                            onDeck[irec.uuid] = irec;
+                        }
+                        if (canCloseInstallQ
+                            && Object.keys(onDeck).length === 0)
+                        {
+                            installQ.close();
+                        }
+                        nextDownload();
+                    });
+
+                    dlEvents.once('content-length', function (cLen) {
+                        if (bar && !irec.imgMeta.size) {
+                            bar.resize(bar.pb_size + cLen);
+                        }
+                    });
+                }
+            });
+
+            downloadQ.on('end', function doneDownloads() {
+                TIME('downloads');
+                if (bar) {
+                    bar.end();
+                }
+                canCloseInstallQ = true;
+                log.debug('done downloads');
+            });
+
+            var installQ = vasync.queuev({
+                concurrency: 1,
+                worker: function installImg(irec, nextInstall) {
+                    TIME('install-'+irec.uuid);
+
+                    var installOpts = {
+                        source: source,
+                        zpool: zpool,
+                        imgMeta: irec.imgMeta,
+                        dsName: format('%s/%s', zpool, irec.uuid),
+                        filePath: irec.downloadPath,
+                        zstream: zstream,
+                        quiet: opts.quiet,
+                        logCb: barLogCb
+                    };
+                    self._installSingleImage(installOpts, function (err) {
+                        if (err) {
+                            nextInstall(err);
+                            return;
+                        }
+
+                        barLogCb(format('Imported image %s (%s@%s)',
+                            irec.uuid,
+                            irec.imgMeta.manifest.name,
+                            irec.imgMeta.manifest.version));
+
+                        rimraf(irec.downloadPath, function (rmErr) {
+                            if (rmErr) {
+                                nextInstall(rmErr);
+                                return;
+                            }
+
+                            ctx.isInstalledFromUuid[irec.uuid] = true;
+                            // We can now install any downloaded (i.e. on deck)
+                            // images whose origin was the image that we just
+                            // installed.
+                            // TODO: avoid iteration: there is just one child
+                            Object.keys(onDeck).forEach(function (uuid) {
+                                var onDeckIrec = onDeck[uuid];
+                                var origin = onDeckIrec.imgMeta.manifest.origin;
+                                if (origin === irec.uuid) {
+                                    log.debug({uuid: irec.uuid},
+                                        'putting img on installQ');
+                                    delete onDeck[uuid];
+                                    if (!installQ.closed) {
+                                        installQ.push(onDeckIrec, onTaskEnd);
+                                    }
+                                }
+                            });
+                            if (canCloseInstallQ
+                                && Object.keys(onDeck).length === 0)
+                            {
+                                installQ.close();
+                            }
+                            TIME('install-'+irec.uuid);
+                            nextInstall();
+                        });
+                    });
+                }
+            });
+
+            installQ.on('end', function doneInstalls() {
+                log.debug('done installs');
+                onceNext();
+            });
+
+
+            /**
+             * If there is a download or install error, abort. Vasync's
+             * `queue.kill()` does not stop running tasks (only prevents
+             * queued ones from being started), therefore we need
+             * `_downloadImageFile` and `_installSingleImage` to support
+             * being aborted.
+             */
+            var abortDAI = once(function _abortDownloadAndInstall(taskErr) {
+                if (bar) {
+                    bar.end({nocomplete: true});
+                }
+                log.info({err: taskErr}, 'abort download and install');
+                logCb('Aborting (%s)', taskErr.message);
+
+                downloadQ.kill();
+                installQ.kill();
+
+                // TODO: Abort any ongoing downloads and install.
+                // Object.keys(downloadQ.pending).forEach(function (id) {
+                //     var task = downloadQ.pending[id].task;
+                //     try {
+                //         task.abort();
+                //     } catch (e) {
+                //         log.warn({err: e, task: task},
+                //             'error aborting ongoing image download');
+                //     }
+                // });
+
+                onceNext(taskErr);
+            });
+
+            function onTaskEnd(taskErr) {
+                if (taskErr) {
+                    abortDAI(taskErr);
+                }
+            }
+
+            // The progress bar is complicated in that with Docker (v1)
+            // downloads we don't have image file size info yet.
+            var haveSizes = (!zstream
+                && irecs.filter(function (irec) { return irec.imgMeta.size; })
+                    .length === irecs.length);
+            var barOpts = {
+                filename: (irecs.length === 1 ? 'Download 1 image'
+                    : format('Download %d images', irecs.length))
+            };
+            if (haveSizes) {
+                var totalBytes = irecs
+                    .map(function (irec) { return irec.imgMeta.size; })
+                    .reduce(function (a, b) { return a + b; });
+                barOpts.size = totalBytes;
+                logCb('Must download and install %d image%s (%s)',
+                    irecs.length, (irecs.length === 1 ? '' : 's'),
+                    common.humanSizeFromBytes(totalBytes));
+            } else {
+                // We'll be resizing as we read Content-Length headers. We
+                // add a hack extra byte here to ensure we don't "complete"
+                // before all Content-Length headers have been included.
+                if (zstream) {
+                    barOpts.nosize = true;
+                } else {
+                    barOpts.size = 1;
+                }
+
+                logCb('Must download and install %d image%s',
+                    irecs.length, (irecs.length === 1 ? '' : 's'));
+            }
+            if (!opts.quiet && process.stderr.isTTY) {
+                bar = new ProgressBar(barOpts);
+            }
+
+            // Start it up.
+            irecs.reverse();
+            log.info({irecs: irecs, numInAncestry: ctx.ancestry.length,
+                numToInstall: irecs.length}, 'irecs to download and install');
+            TIME('downloads');
+            downloadQ.push(irecs, onTaskEnd);
+            downloadQ.close();
+        }
+
+    ]}, function finishUp(err) {
+        if (err === true) { // Signal for early abort.
+            err = null;
+        }
+
+        if (!unlockInfos) {
+            cb(err);
+            return;
+        }
+
+        var unlockOpts = {
+            unlockInfos: unlockInfos,
+            logCb: logCb
+        };
+        self._lockRelease(unlockOpts, function (unlockErr) {
+            var e = (err && unlockErr
+                ? new errors.MultiError([err, unlockErr])
+                : err || unlockErr);
+            cb(e);
+        });
+    });
+};
+
+
+
+/**
+ * Lock imports for the given `uuids`.
+ *
+ * When locking multiple UUIDs (typical for an image import with ancestry),
+ * it is expected that `opts.uuids` is in order from top image, its parent,
+ * etc. down to the base. Lock files are per-uuid and will be acquired in order.
+ * This should avoid deadlock if used consistently.
+ *
+ * @param opts {Object}
+ * @param cb {Function} `function (err, unlockInfos)`
+ */
+IMGADM.prototype._lockAcquire = function _lockAcquire(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.arrayOfString(opts.uuids, 'opts.uuids');
+    assert.func(opts.logCb, 'opts.logCb');
+    assert.func(cb, 'cb');
+
+    var self = this;
+    var log = self.log;
+    var unlockInfos = [];
+
+    vasync.forEachPipeline({
+        inputs: opts.uuids,
+        func: function lockOneUuid(uuid, next) {
+            var acquireLogTimeout = setTimeout(function () {
+                opts.logCb(format('Waiting for image %s import lock', uuid));
+            }, 1000);
+
+            var lockPath = self._lockPathFromUuid(uuid);
+            log.debug({uuid: uuid, lockPath: lockPath}, 'acquiring lock');
+
+            lock(lockPath, function (lockErr, unlockFn) {
+                if (acquireLogTimeout) {
+                    clearTimeout(acquireLogTimeout);
+                }
+                if (lockErr) {
+                    next(new errors.InternalError({
+                        message: 'error acquiring lock',
+                        uuid: uuid,
+                        lockPath: lockPath,
+                        cause: lockErr
+                    }));
+                    return;
+                }
+                log.debug({lockPath: lockPath, uuid: uuid}, 'acquired lock');
+                unlockInfos.push({
+                    uuid: uuid,
+                    lockPath: lockPath,
+                    unlockFn: unlockFn
+                });
+                next();
+            });
+        }
+    }, function finishLockAcquires(err) {
+        if (err) {
+            var unlockOpts = {
+                unlockInfos: unlockInfos,
+                logCb: opts.logCb
+            };
+            self._lockRelease(unlockOpts, function (unlockErr) {
+                if (unlockErr) {
+                    log.warn({unlockInfos: unlockInfos, err: unlockErr},
+                        'could not release all locks in _lockAcquire cleanup');
+                }
+                cb(err);
+            });
+        } else {
+            cb(null, unlockInfos);
+        }
+    });
+};
+
+
+IMGADM.prototype._lockRelease = function _lockRelease(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.arrayOfObject(opts.unlockInfos, 'opts.unlockInfos');
+    assert.func(opts.logCb, 'opts.logCb');
+    assert.func(cb, 'cb');
+
+    vasync.forEachPipeline({
+        inputs: opts.unlockInfos,
+        func: function unlockOne(unlockInfo, next) {
+            self.log.debug({unlockInfo: unlockInfo}, 'releasing lock');
+            unlockInfo.unlockFn(function (unlockErr) {
+                if (unlockErr) {
+                    next(new errors.InternalError({
+                        message: 'error releasing lock',
+                        lockPath: unlockInfo.lockPath,
+                        cause: unlockErr
+                    }));
+                    return;
+                }
+                self.log.debug({unlockInfo: unlockInfo}, 'released lock');
+                next();
+            });
+        }
+    }, cb);
+};
+
+
+/**
+ * Install the given image from the given `manifest` and image file path,
+ * `file`.
+ *
+ * It is up to the caller to ensure this UUID is not already installed.
+ *
+ * @param opts {Object}
+ *      - @param manifest {Object} The manifest to import.
+ *      - @param zpool {String} The zpool to which to import.
+ *      - @param file {String} Path to the image file.
+ *      - @param zstream {Boolean} Optional. Default false. If true, indicates
+ *        the GetImageFile will be a raw ZFS dataset stream.
+ *      - @param quiet {Boolean} Optional. Default false. Set to true
+ *        to not have a progress bar for the install.
+ *      - @param logCb {Function} A function that is called
+ *        with progress messages. Called as `logCb(<string>)`. E.g. passing
+ *        console.log is legal.
+ * @param cb {Function} `function (err)`
+ */
+IMGADM.prototype.installImage = function installImage(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.object(opts.manifest, 'opts.manifest');
+    assert.string(opts.zpool, 'opts.zpool');
+    assert.string(opts.file, 'opts.file');
+    assert.optionalBool(opts.zstream, 'opts.zstream');
+    assert.optionalBool(opts.quiet, 'opts.quiet');
+    assert.func(opts.logCb, 'opts.logCb');
+
+    // Upgrade manifest if required.
+    try {
+        var manifest = imgmanifest.upgradeManifest(opts.manifest);
+    } catch (err) {
+        cb(new errors.InvalidManifestError(err));
+        return;
+    }
+
+    var zstream = Boolean(opts.zstream);
+    var logCb = opts.logCb;
+    var imgMeta = {
+        manifest: manifest
+    };
+    var unlockInfos;
+
+    vasync.pipeline({funcs: [
+        function validateManifest(_, next) {
+            var errs = imgmanifest.validateMinimalManifest(manifest);
+            if (errs) {
+                next(new errors.ManifestValidationError(errs));
+            } else {
+                next();
+            }
+        },
+
+        function checkMinMaxPlatform(_, next) {
+            getSysinfo(function (err, sysinfo) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                next(checkMinMaxPlatformSync({
+                    sysinfo: sysinfo,
+                    manifest: manifest
+                }));
+            });
+        },
+
+        function acquireLock(_, next) {
+            var lockOpts = {
+                uuids: [manifest.uuid],
+                logCb: logCb
+            };
+            self._lockAcquire(lockOpts, function (err, unlockInfos_) {
+                unlockInfos = unlockInfos_;
+                next(err);
+            });
+        },
+
+        function checkIfImportedAfterLock(_, next) {
+            var getOpts = {
+                uuid: manifest.uuid,
+                zpool: opts.zpool
+            };
+            self.getImage(getOpts, function (getErr, ii) {
+                if (getErr) {
+                    next(getErr);
+                } else if (ii) {
+                    logCb('Image %s (%s@%s) was installed while '
+                        + 'waiting on lock', manifest.uuid, ii.manifest.name,
+                        ii.manifest.version);
+                    next(true);  // early abort
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function getAndCheckSize(_, next) {
+            if (zstream) {
+                next();
+                return;
+            }
+
+            fs.stat(opts.file, function (statErr, stats) {
+                if (statErr) {
+                    next(statErr);
+                    return;
+                }
+                var manSize = (manifest.files && manifest.files[0]
+                    && manifest.files[0].size);
+                if (manSize !== undefined && manSize != stats.size) {
+                    next(new errors.DownloadError(format('image file size '
+                        + 'error: manifest says %d bytes, %s is %d bytes',
+                        manSize, opts.file, stats.size)));
+                    return;
+                }
+                imgMeta.size = stats.size;
+                next();
+            });
+        },
+
+        function checkHash(_, next_) {
+            var next = once(next_);
+
+            if (zstream) {
+                next();
+                return;
+            }
+
+
+            var manSha1 = (manifest.files && manifest.files[0]
+                && manifest.files[0].sha1);
+            if (!manSha1) {
+                next();
+                return;
+            }
+
+            var hash = crypto.createHash('sha1');
+            var s = fs.createReadStream(opts.file);
+            s.on('data', function (chunk) {
+                hash.update(chunk);
+            });
+            s.on('error', function (err) {
+                next(err);
+            });
+            s.on('end', function () {
+                var actualSha1 = hash.digest('hex');
+                if (manSha1 != actualSha1) {
+                    next(new errors.DownloadError(format('image file '
+                        + 'checksum (sha1) error: manifest says "%s", '
+                        + '%s is "%s"', manSha1, opts.file, actualSha1)));
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function installIt(_, next) {
+            var installOpts = {
+                imgMeta: imgMeta,
+                filePath: opts.file,
+                dsName: format('%s/%s', opts.zpool, manifest.uuid),
+                zpool: opts.zpool,
+                zstream: opts.zstream,
+                quiet: opts.quiet,
+                logCb: logCb
+            };
+            self._installSingleImage(installOpts, function (err) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+
+                logCb('Installed image %s (%s@%s)',
+                    manifest.uuid, manifest.name, manifest.version);
+                next();
+            });
+        }
+
+    ]}, function finishInstallImage(err) {
+        if (err === true) { // Signal for early abort.
+            err = null;
+        }
+
+        if (!unlockInfos) {
+            cb(err);
+            return;
+        }
+
+        var unlockOpts = {
+            unlockInfos: unlockInfos,
+            logCb: logCb
+        };
+        self._lockRelease(unlockOpts, function (unlockErr) {
+            var e = (err && unlockErr
+                ? new errors.MultiError([err, unlockErr])
+                : err || unlockErr);
+            cb(e);
+        });
+    });
+};
+
+
+IMGADM.prototype._lockPathFromUuid = function _lockPathFromUuid(uuid) {
+    assertUuid(uuid, 'uuid');
+    return '/var/run/img.' + uuid + '.import.lock';
+};
+
+
+/**
+ * This handles creating an image in the zpool from a *single* docker
+ * layer.
+ *
+ * - if have origin:
+ *      zfs clone zones/$origin@final zones/$uuid
+ *   else:
+ *      zfs create zones/$uuid
+ *      mkdir zones/$uuid/root
+ *      crle ...
+ * - cd /zones/$uuid/root && tar xf $layerFile
+ * - handle .wh.* files
+ * - zfs snapshot zones/$uuid@final
+ *
+ * Dev Note: This presumes an imgadm lock is held for this image.
+ *
+ * Testing notes:
+ * - 'imgadm import tutum/influxdb' has a cbde4a8607af layer that is an
+ *   empty gzip. That breaks `zcat FILE | gtar xz -f` that was used in earlier
+ *   imgadm versions.
+ * - 'imgadm import learn/tutorial' (layer 8dbd9e392a96) uses xz compression.
+ * - 'imgadm import busybox' has layers with no compression.
+ * - TODO: what's a docker image using bzip2 compression?
+ */
+IMGADM.prototype._installDockerImage = function _installDockerImage(ctx, cb) {
+    var self = this;
+    assert.object(ctx, 'ctx');
+    assert.string(ctx.filePath, 'ctx.filePath');
+    assert.string(ctx.dsName, 'ctx.dsName');
+    assert.string(ctx.zpool, 'ctx.zpool');
+    assert.object(ctx.imgMeta.manifest, 'ctx.imgMeta.manifest');
+    assert.func(ctx.logCb, 'ctx.logCb');
+    assert.func(cb, 'cb');
+
+    var zpool = ctx.zpool;
+    var manifest = ctx.imgMeta.manifest;
+    var log = self.log;
+
+    var partialDsName = ctx.dsName + '-partial';
+    var zoneroot = format('/%s/root', partialDsName);
+
+    vasync.pipeline({funcs: [
+        /**
+         * A crashed earlier import of this image could have left a partial
+         * dataset around. Turf it (we hold the lock).
+         */
+        function deleteExistingPartial(_, next) {
+            getZfsDataset(partialDsName, ['name'], function (getErr, ds) {
+                if (getErr) {
+                    next(getErr);
+                } else if (!ds) {
+                    next();
+                } else {
+                    ctx.logCb('Warning: deleting partial dataset left over '
+                        + 'from earlier import attempt: ' + partialDsName);
+                    zfsDestroy(partialDsName, log, next);
+                }
+            });
+        },
+
+        function cloneOrigin(_, next) {
+            if (!manifest.origin) {
+                next();
+                return;
+            }
+            var argv = ['/usr/sbin/zfs', 'clone',
+                format('%s/%s@final', zpool, manifest.origin), partialDsName];
+            execFilePlus({argv: argv, log: log}, next);
+        },
+
+        function createNewZoneroot(_, next) {
+            if (manifest.origin) {
+                next();
+                return;
+            }
+            vasync.pipeline({funcs: [
+                function zfsCreate(_2, next2) {
+                    var argv = ['/usr/sbin/zfs', 'create', partialDsName];
+                    execFilePlus({argv: argv, log: log}, next2);
+                },
+                function mkZoneroot(_2, next2) {
+                    var argv = ['/usr/bin/mkdir', '-p', zoneroot];
+                    execFilePlus({argv: argv, log: log}, next2);
+                }
+            ]}, next);
+        },
+
+        function sniffCompression(_, next) {
+            assert.string(ctx.filePath, 'ctx.filePath');
+            magic.compressionTypeFromPath(ctx.filePath, function (err, cType) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                ctx.cType = cType; // one of: null, bzip2, gzip, xz
+                next();
+            });
+        },
+
+        /*
+         * '/usr/bin/tar' supports sniffing 'xz', but balks on some Mac tar
+         * goop (as in the learn/tutorial image). '/usr/bin/gtar' currently
+         * doesn't sniff 'xz' compression.
+         */
+        function extract(_, next) {
+            assert.string(ctx.filePath, 'ctx.filePath');
+
+            var command;
+            switch (ctx.cType) {
+            case null:
+                command = format(
+                    '/usr/img/sbin/chroot-gtar %s %s %s none',
+                    path.dirname(zoneroot),
+                    path.basename(zoneroot),
+                    ctx.filePath);
+                break;
+            case 'gzip':
+                command = format(
+                    '/usr/img/sbin/chroot-gtar %s %s %s gzip',
+                    path.dirname(zoneroot),
+                    path.basename(zoneroot),
+                    ctx.filePath);
+                break;
+            case 'bzip2':
+                command = format(
+                    '/usr/img/sbin/chroot-gtar %s %s %s bzip2',
+                    path.dirname(zoneroot),
+                    path.basename(zoneroot),
+                    ctx.filePath);
+                break;
+            case 'xz':
+                command = format(
+                    '/usr/img/sbin/chroot-gtar %s %s %s xz',
+                    path.dirname(zoneroot),
+                    path.basename(zoneroot),
+                    ctx.filePath);
+                break;
+            default:
+                throw new Error('unexpected compression type: ' + ctx.cType);
+            }
+
+            execPlus({
+                command: command,
+                log: log,
+                execOpts: {
+                    maxBuffer: 2 * 1024 * 1024
+                }
+            }, next);
+        },
+
+        function whiteout(_, next) {
+            var find = findit2(zoneroot);
+            var onceNext = once(next);
+            var toRemove = [];
+            find.on('file', function (file, stat) {
+                var base = path.basename(file);
+                if (base.slice(0, 4) === '.wh.') {
+                    toRemove.push(path.join(path.dirname(file), base.slice(4)));
+                    toRemove.push(file);
+                }
+            });
+            find.on('end', function () {
+                log.info({toRemove: toRemove}, 'whiteout files');
+                vasync.forEachPipeline({
+                    inputs: toRemove,
+                    func: rimraf
+                }, onceNext);
+            });
+            find.on('error', onceNext);
+        },
+
+        /**
+         * As a rule, we want all installed images on SmartOS to have their
+         * single base snapshot (from which VMs are cloned) called "@final".
+         * `vmadm` presumes this (tho allows for it not to be there for
+         * bwcompat). This "@final" snapshot is also necessary for
+         * `imgadm create -i` (i.e. incremental images).
+         */
+        function zfsSnapshot(_, next) {
+            var argv = ['/usr/sbin/zfs', 'snapshot', partialDsName + '@final'];
+            execFilePlus({argv: argv, log: log}, next);
+        },
+
+        /**
+         * We created the dataset to a "...-partial" temporary name.
+         * Rename it to the final name.
+         */
+        function renameToFinalDsName(_, next) {
+            var argv = ['/usr/sbin/zfs', 'rename', partialDsName, ctx.dsName];
+            execFilePlus({argv: argv, log: log}, next);
+        }
+
+    ]}, function finishUp(err) {
+        if (err) {
+            // Rollback the currently installed dataset, if necessary.
+            // Silently fail here (i.e. only log at debug level) because
+            // it is possible we errored out before the -partial dataset
+            // was created.
+            var argv = ['/usr/sbin/zfs', 'destroy', '-r',
+                partialDsName];
+            execFilePlus({argv: argv, log: log},
+                    function (rollbackErr, stdout, stderr) {
+                if (rollbackErr) {
+                    log.debug({argv: argv, err: rollbackErr,
+                        rollbackDsName: partialDsName},
+                        'error destroying partial dataset while rolling back');
+                }
+                cb(err);
+            });
+        } else {
+            cb(err);
+        }
+    });
+};
+
+
+IMGADM.prototype._installZfsImage = function _installZfsImage(ctx, cb) {
+    var self = this;
+    assert.object(ctx, 'ctx');
+    assert.string(ctx.filePath, 'ctx.filePath');
+    assert.string(ctx.dsName, 'ctx.dsName');
+    assert.string(ctx.zpool, 'ctx.zpool');
+    assert.object(ctx.imgMeta.manifest, 'ctx.imgMeta.manifest');
+    assert.number(ctx.imgMeta.size, 'ctx.imgMeta.size');
+    assert.optionalBool(ctx.zstream, 'ctx.zstream');
+    assert.optionalBool(ctx.quiet, 'ctx.quiet');
+
+    var zstream = Boolean(ctx.zstream);
+    var manifest = ctx.imgMeta.manifest;
+    var uuid = manifest.uuid;
+    var log = self.log;
+
+    vasync.pipeline({funcs: [
+        /**
+         * image file stream \                  [A]
+         *      | inflator (if necessary) \     [B]
+         *      | zfs recv                      [C]
+         */
+        function recvTheDataset(_, next) {
+            // To complete this stage we want to wait for all of:
+            // 1. the 'zfs receive' process to 'exit'.
+            // 2. the compressor process to 'exit' (if we are compressing)
+            // 3. the pipeline's std handles to 'close'
+            //
+            // If we get an error we "finish" right away. This `finish` stuff
+            // coordinates that.
+            var numToFinish = 2;  // 1 is added below if compressing.
+            var numFinishes = 0;
+            var finished = false;
+            function finish(err) {
+                numFinishes++;
+                if (finished) {
+                    /* jsl:pass */
+                } else if (err) {
+                    finished = true;
+                    self.log.trace({err: err}, 'recvTheDataset err');
+                    next(err);
+                } else if (numFinishes >= numToFinish) {
+                    finished = true;
+                    next();
+                }
+            }
+
+            if (!ctx.quiet && process.stderr.isTTY) {
+                ctx.bar = new ProgressBar({
+                    size: ctx.imgMeta.size,
+                    filename: ctx.dsName
+                });
+            }
+
+            // [A]
+            var stream = fs.createReadStream(ctx.filePath);
+            if (ctx.bar) {
+                stream.on('data', function (chunk) {
+                    ctx.bar.advance(chunk.length);
+                });
+            }
+            stream.on('error', finish);
+
+            // [B]
+            // If we are getting a raw ZFS stream, then ignore the
+            // manifest.files compression.
+            var compression = (zstream
+                ? 'none' : manifest.files[0].compression);
+            var uncompressor;
+            if (compression === 'bzip2') {
+                uncompressor = spawn('/usr/bin/bzip2', ['-cdfq']);
+                numToFinish++;
+            } else if (compression === 'gzip') {
+                uncompressor = spawn('/usr/bin/gzip', ['-cdfq']);
+                numToFinish++;
+            } else if (compression === 'xz') {
+                uncompressor = spawn('/usr/bin/xz', ['-cdfq']);
+                numToFinish++;
+            } else {
+                assert.equal(compression, 'none',
+                    format('image %s file compression: %s', uuid, compression));
+                uncompressor = null;
+            }
+            if (uncompressor) {
+                uncompressor.stderr.on('data', function (chunk) {
+                    console.error('Stderr from uncompression: %s',
+                        chunk.toString());
+                });
+                uncompressor.on('exit', function (code) {
+                    if (code !== 0) {
+                        var msg;
+                        if (compression === 'bzip2' && code === 2) {
+                            msg = format('%s uncompression error while '
+                                + 'importing: exit code %s (corrupt compressed '
+                                + 'file): usually indicates a network error '
+                                + 'while downloading, try again',
+                                compression, code);
+                        } else {
+                            msg = format('%s uncompression error while '
+                                + 'importing: exit code %s', compression, code);
+                        }
+                        finish(new errors.UncompressionError(msg));
+                    } else {
+                        finish();
+                    }
+                });
+            }
+
+            // [C]
+            ctx.partialDsName = ctx.dsName + '-partial';
+            var zfsRecv = spawn('/usr/sbin/zfs',
+                ['receive', ctx.partialDsName]);
+            zfsRecv.stderr.on('data', function (chunk) {
+                if (chunk.toString()
+                    .match(/SMF Initialization problems..svc:\//)) {
+                    return;
+                }
+                console.error('Stderr from zfs receive: %s',
+                    chunk.toString());
+            });
+            zfsRecv.stdout.on('data', function (chunk) {
+                if (chunk.toString()
+                    .match(/NFS plugin problem with SMF repository:/)) {
+                    return;
+                }
+                console.error('Stdout from zfs receive: %s',
+                    chunk.toString());
+            });
+            zfsRecv.on('exit', function (code) {
+                if (code !== 0) {
+                    finish(new errors.InternalError({message: format(
+                        'zfs receive error while importing: '
+                        + 'exit code %s', code)}));
+                } else {
+                    finish();
+                }
+            });
+
+            (uncompressor || zfsRecv).on('close', function () {
+                self.log.trace('image file receive pipeline closed');
+                finish();
+            });
+
+            if (uncompressor) {
+                uncompressor.stdout.pipe(zfsRecv.stdin);
+                stream.pipe(uncompressor.stdin);
+            } else {
+                stream.pipe(zfsRecv.stdin);
+            }
+        },
+
+        /**
+         * As a rule, we want all installed images on SmartOS to have their
+         * single base snapshot (from which VMs are cloned) called "@final".
+         * `vmadm` presumes this (tho allows for it not to be there for
+         * bwcompat). This "@final" snapshot is also necessary for
+         * `imgadm create -i` (i.e. incremental images).
+         *
+         * Here we ensure that the snapshot for this image is called "@final",
+         * renaming it if necessary.
+         */
+        function ensureFinalSnapshot(_, next) {
+            var properties = ['name', 'children'];
+            getZfsDataset(ctx.partialDsName, properties, function (zErr, ds) {
+                if (zErr) {
+                    next(zErr);
+                    return;
+                }
+                var snapshots = ds.children.snapshots;
+                var snapnames = snapshots.map(
+                    function (n) { return '@' + n.split(/@/g).slice(-1)[0]; });
+                if (snapshots.length !== 1) {
+                    next(new errors.UnexpectedNumberOfSnapshotsError(
+                        uuid, snapnames));
+                } else if (snapnames[0] !== '@final') {
+                    var curr = snapshots[0];
+                    var finalSnap = curr.split(/@/)[0] + '@final';
+                    zfsRenameSnapshot(curr, finalSnap,
+                        {recursive: true, log: log}, next);
+                } else {
+                    next();
+                }
+            });
+        },
+
+        /**
+         * We recv'd the dataset to a "...-partial" temporary name.
+         * Rename it to the final name.
+         */
+        function renameToFinalDsName(_, next) {
+            var cmd = format('/usr/sbin/zfs rename %s %s',
+                ctx.partialDsName, ctx.dsName);
+            log.trace({cmd: cmd}, 'rename tmp image');
+            exec(cmd, function (err, stdout, stderr) {
+                if (err) {
+                    log.error({cmd: cmd, err: err, stdout: stdout,
+                        stderr: stderr, partialDsName: ctx.partialDsName,
+                        dsName: ctx.dsName}, 'error renaming imported image');
+                    next(new errors.InternalError(
+                        {message: 'error importing'}));
+                } else {
+                    next();
+                }
+            });
+        }
+
+    ]}, function finishUp(err) {
+        vasync.pipeline({funcs: [
+            function stopProgressBar(_, next) {
+                if (ctx.bar) {
+                    ctx.bar.end();
+                }
+                next();
+            },
+            function rollbackPartialDsIfNecessary(_, next) {
+                if (err && ctx.partialDsName) {
+                    // Rollback the currently installed dataset, if necessary.
+                    // Silently fail here (i.e. only log at trace level) because
+                    // it is possible we errored out before the -partial
+                    // dataset was created.
+                    var cmd = format('/usr/sbin/zfs destroy -r %s',
+                        ctx.partialDsName);
+                    exec(cmd, function (rollbackErr, stdout, stderr) {
+                        if (rollbackErr) {
+                            log.trace({cmd: cmd, err: rollbackErr,
+                                stdout: stdout,
+                                stderr: stderr,
+                                rollbackDsName: ctx.partialDsName},
+                                'error destroying dataset while rolling back');
+                        }
+                        next();
+                    });
+                } else {
+                    next();
+                }
+            }
+        ]}, function done(finishUpErr) {
+            // We shouldn't ever get a `finishUpErr`. Let's be loud if we do.
+            if (finishUpErr) {
+                log.fatal({err: finishUpErr},
+                    'unexpected error finishing up image import');
+            }
+            cb(err || finishUpErr);
+        });
+    });
+};
+
+
+/**
+ * Install a given image file and manifest to the zpool and imgadm db.
+ *
+ * It is the responsibility of the caller to have the import lock.
+ */
+IMGADM.prototype._installSingleImage = function _installSingleImage(ctx, cb) {
+    var self = this;
+    assert.object(ctx, 'ctx');
+    assert.optionalObject(ctx.source, 'ctx.source');
+    assert.string(ctx.filePath, 'ctx.filePath');
+    assert.string(ctx.dsName, 'ctx.dsName');
+    assert.string(ctx.zpool, 'ctx.zpool');
+    assert.object(ctx.imgMeta.manifest, 'ctx.imgMeta.manifest');
+    assert.optionalBool(ctx.zstream, 'ctx.zstream');
+    assert.optionalBool(ctx.quiet, 'ctx.quiet');
+    assert.func(ctx.logCb, 'ctx.logCb');
+    assert.func(cb, 'cb');
+
+    var manifest = ctx.imgMeta.manifest;
+    var zstream = Boolean(ctx.zstream);
+
+    vasync.pipeline({funcs: [
+
+        /**
+         * Install the manifest *before the file*, because it is the presense
+         * of the file in the zpool that decides if there is actually an
+         * image. Therefore if we, for whatever reason, install the file in
+         * the zpool but do *not install the manifest in imgadm's db*, then
+         * we get a broken image. Further, for an image from a *docker* source
+         * we cannot `imgadm update` it to recover.
+         */
+        function saveManifestToDb(_, next) {
+            // Note that we have a DS to remove if the rest of the import fails.
+            ctx.installedDs = true;
+
+            var dbImageInfo = {
+                zpool: ctx.zpool,
+                manifest: manifest,
+                source: ctx.source
+            };
+            self.dbAddImage(dbImageInfo, function (addErr) {
+                if (addErr) {
+                    self.log.error({err: addErr, zpool: ctx.zpool,
+                        manifest: manifest},
+                        'error saving image to the database');
+                    next(new errors.InternalError(
+                        {message: 'error saving image manifest'}));
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function _installTheFile(_, next) {
+            if (!zstream && manifest.type === 'docker') {
+                self._installDockerImage(ctx, next);
+            } else {
+                self._installZfsImage(ctx, next);
+            }
+        }
+
+    ]}, function finishUp(err) {
+        if (err && ctx.installedDs) {
+            var cmd = format('/usr/sbin/zfs destroy -r %s', ctx.dsName);
+            exec(cmd, function (rollbackErr, stdout, stderr) {
+                if (rollbackErr) {
+                    self.log.trace({cmd: cmd, err: rollbackErr,
+                        stdout: stdout, stderr: stderr,
+                        rollbackDsName: ctx.dsName},
+                        'error destroying dataset while rolling back');
+                }
+                cb(err);
+            });
+        } else {
+            cb(err);
+        }
+    });
+};
+
+/**
+ * Update image database. I.e., attempt to gather info on installed images
+ * with no cached manifest info, from current image sources.
+ *
+ * Limitation: Doesn't support updating from docker sources.
+ *
+ * Dev Note: Currently this just writes progress (updated images) with
+ * `console.log`, which isn't very "library-like".
+ *
+ * @param opts {Object}
+ *      - uuids {Array} Optional array of uuids to which to limit processing.
+ *      - dryRun {Boolean} Default false. Just print changes that would be made
+ *        without making them.
+ * @param cb {Function} `function (err)`
+ */
+IMGADM.prototype.updateImages = function updateImages(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.optionalArrayOfString(opts.uuids, 'opts.uuids');
+    assert.optionalBool(opts.dryRun, 'opts.dryRun');
+    assert.func(cb, 'cb');
+    var self = this;
+    var updateErrs = [];
+
+    self.listImages(function (listErr, ii) {
+        if (listErr) {
+            cb(listErr);
+            return;
+        }
+
+        var imagesInfo;
+        if (opts.uuids) {
+            var iiFromUuid = {};
+            ii.forEach(function (i) { iiFromUuid[i.manifest.uuid] = i; });
+
+            imagesInfo = [];
+            var missing = [];
+            opts.uuids.forEach(function (u) {
+                if (!iiFromUuid[u]) {
+                    missing.push(u);
+                } else {
+                    imagesInfo.push(iiFromUuid[u]);
+                }
+            });
+            if (missing.length) {
+                cb(new errors.UsageError(
+                    'no installed image with the given UUID(s): '
+                    + missing.join(', ')));
+                return;
+            }
+        } else {
+            imagesInfo = ii;
+        }
+
+        vasync.forEachPipeline({
+            inputs: imagesInfo,
+            func: updateImage
+        }, function finishUpdateImages(err) {
+            if (err) {
+                cb(err);
+            } else if (updateErrs.length === 1) {
+                cb(updateErrs[0]);
+            } else if (updateErrs.length > 1) {
+                cb(new errors.MultiError(updateErrs));
+            } else {
+                cb();
+            }
+        });
+    });
+
+    function updateImage(ii, cb2) {
+        assert.object(ii.manifest, 'ii.manifest');
+        assert.string(ii.zpool, 'ii.zpool');
+
+        var uuid = ii.manifest.uuid;
+        var sii; // source importInfo
+        var snapshots;
+        vasync.pipeline({funcs: [
+            function getSource(_, next) {
+                var getOpts = {
+                    arg: uuid,
+                    ensureActive: false
+                };
+                self.sourcesGetImportInfo(getOpts, function (err, importInfo) {
+                    if (err) {
+                        next(err);
+                        return;
+                    }
+                    sii = importInfo;
+                    // Limitation: don't support docker sources, skip warnings
+                    // on them.
+                    if (!sii && ii.manifest.type !== 'docker') {
+                        console.log('warning: Could not find image %s in '
+                            + 'image sources (skipping)', uuid);
+                    }
+                    next();
+                });
+            },
+            function getSnapshots(_, next) {
+                if (!sii) {
+                    next();
+                    return;
+                }
+                var properties = ['name', 'children'];
+                var fsName = format('%s/%s', ii.zpool, uuid);
+                getZfsDataset(fsName, properties, function (zErr, ds) {
+                    if (zErr) {
+                        next(zErr);
+                        return;
+                    }
+                    snapshots = ds.children.snapshots;
+                    next();
+                });
+            },
+            function updateManifest(_, next) {
+                if (!sii) {
+                    next();
+                    return;
+                }
+                sii.zpool = ii.zpool;
+                var msg;
+                if (!ii.manifest.name) {
+                    // Didn't have any manifest details.
+                    msg = format('Added manifest info for image %s from "%s"',
+                        uuid, sii.source.url);
+                } else {
+                    var sm = sii.manifest;
+                    var m = ii.manifest;
+                    if (JSON.stringify(sm) === JSON.stringify(m)) {
+                        // No manifest changes.
+                        next();
+                        return;
+                    }
+                    var diffs = common.diffManifestFields(m, sm);
+                    // If 'diffs' is empty here, then the early out above just
+                    // had order differences.
+                    if (diffs.length === 0) {
+                        next();
+                        return;
+                    }
+                    msg = format('Updated %d manifest field%s for image '
+                        + '%s from "%s": %s', diffs.length,
+                        (diffs.length === 1 ? '' : 's'), uuid, sii.source.url,
+                        diffs.join(', '));
+                }
+                if (opts.dryRun) {
+                    console.log(msg);
+                    next();
+                    return;
+                }
+                self.dbAddImage(sii, function (dbAddErr) {
+                    if (dbAddErr) {
+                        next(dbAddErr);
+                        return;
+                    }
+                    console.log(msg);
+                    next();
+                });
+            },
+            function ensureFinalSnapshot(_, next) {
+                if (!sii) {
+                    next();
+                    return;
+                }
+                var finalSnapshot = format('%s/%s@final', ii.zpool, uuid);
+                if (snapshots.indexOf(finalSnapshot) !== -1) {
+                    next();
+                    return;
+                }
+
+                /**
+                 * We don't have a '@final' snapshot for this image.
+                 * - If there aren't *any* snapshots, then fail because the
+                 *   original has been deleted. For 'vmadm send/receive' to
+                 *   ever work the base snapshot for VMs must be the same
+                 *   original.
+                 * - If the source manifest info doesn't have a
+                 *   "files.0.dataset_guid" then skip (we can't check).
+                 * - If there are any, find the one that is the original
+                 *   (by machine dataset_guid to the zfs 'guid' property).
+                 */
+                if (snapshots.length === 0) {
+                    next(new errors.ImageMissingOriginalSnapshotError(uuid));
+                    return;
+                }
+
+                var expectedGuid = sii.manifest.files[0].dataset_guid;
+                if (!expectedGuid) {
+                    console.warn('imgadm: warn: cannot determine original '
+                        + 'snapshot for image "%s" (source info has no '
+                        + '"dataset_guid")', uuid);
+                    next();
+                    return;
+                }
+
+                var found = null;
+                var i = 0;
+                async.until(
+                    function testDone() {
+                        return found || i >= snapshots.length;
+                    },
+                    function checkOneSnapshot(nextSnapshot) {
+                        var snapshot = snapshots[i];
+                        i++;
+                        var props = ['name', 'guid'];
+                        getZfsDataset(snapshot, props, function (zErr, ds) {
+                            if (zErr) {
+                                nextSnapshot(zErr);
+                                return;
+                            }
+                            if (ds.guid === expectedGuid) {
+                                found = snapshot;
+                            }
+                            nextSnapshot();
+                        });
+                    },
+                    function doneSnapshots(sErr) {
+                        if (sErr) {
+                            next(sErr);
+                        } else if (!found) {
+                            next(new errors.ImageMissingOriginalSnapshotError(
+                                uuid, expectedGuid));
+                        } else {
+                            // Rename this snapshot to '@final'.
+                            zfsRenameSnapshot(
+                                found,
+                                finalSnapshot,
+                                {recursive: true, log: self.log},
+                                function (rErr) {
+                                    if (rErr) {
+                                        next(rErr);
+                                        return;
+                                    }
+                                    console.log('Renamed image %s original '
+                                        + 'snapshot from %s to %s', uuid,
+                                        found, finalSnapshot);
+                                    next();
+                                }
+                            );
+                        }
+                    }
+                );
+            }
+        ]}, cb2);
+    }
+};
+
+
+/**
+ * Remove unused images.
+ *
+ * @param opts {Object}
+ *      - dryRun {Boolean} Default false. Just print changes that would be made
+ *        without making them.
+ *      - @param logCb {Function} A function that is called
+ *        with progress messages. Should have the same signature as
+ *        `console.log`.
+ *      - @param force {Boolean} Optional. Default false. If true, skips
+ *        confirmation.
+ * @param cb {Function} `function (err, vacuumedImages)`
+ */
+IMGADM.prototype.vacuumImages = function vacuumImages(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.optionalBool(opts.dryRun, 'opts.dryRun');
+    assert.optionalBool(opts.force, 'opts.force');
+    assert.func(opts.logCb, 'opts.logCb');
+    assert.func(cb, 'cb');
+
+    var context = {
+        vacuumImages: []
+    };
+    vasync.pipeline({arg: context, funcs: [
+        function listAllImages(ctx, next) {
+            self.listImages(function (err, imagesInfo) {
+                ctx.imagesInfo = imagesInfo;
+                next(err);
+            });
+        },
+
+        function findThem(ctx, next) {
+            // First pass, setup structures.
+            var i, j, ds;
+            var clonesFromDs = {};  // dataset -> clone -> true
+            for (i = 0; i < ctx.imagesInfo.length; i++) {
+                var ii = ctx.imagesInfo[i];
+                ds = ii.zpool + '/' + ii.manifest.uuid;
+                clonesFromDs[ds] = {};
+                for (j = 0; j < ii.cloneNames.length; j++) {
+                    clonesFromDs[ds][ii.cloneNames[j]] = true;
+                }
+            }
+
+            // Figure out which we can delete.
+            var allToDel = [];
+            while (true) {
+                var toDel = [];
+                var remainingDatasets = Object.keys(clonesFromDs);
+                for (i = 0; i < remainingDatasets.length; i++) {
+                    ds = remainingDatasets[i];
+                    var clones = clonesFromDs[ds];
+                    if (Object.keys(clones).length === 0) {
+                        toDel.push(ds);
+                    }
+                }
+                if (toDel.length === 0) {
+                    break;
+                }
+                for (i = 0; i < toDel.length; i++) {
+                    var clone = toDel[i];
+                    for (j = 0; j < remainingDatasets.length; j++) {
+                        delete clonesFromDs[remainingDatasets[j]][clone];
+                    }
+                }
+                for (i = 0; i < toDel.length; i++) {
+                    delete clonesFromDs[toDel[i]];
+                }
+                allToDel = allToDel.concat(toDel);
+            }
+            self.log.trace({allToDel: allToDel}, 'vacuumImages.findThem');
+
+            var iiFromDs = {};
+            ctx.imagesInfo.forEach(function (ii_) {
+                iiFromDs[ii_.zpool + '/' + ii_.manifest.uuid] = ii_;
+            });
+            ctx.iiToDel = allToDel.map(
+                function (ds_) { return iiFromDs[ds_]; });
+
+            next();
+        },
+
+        function confirm(ctx, next) {
+            if (opts.force || ctx.iiToDel.length === 0) {
+                next();
+                return;
+            }
+
+            var summaries = ctx.iiToDel.map(function (ii) {
+                return format('%s (%s@%s)', ii.manifest.uuid, ii.manifest.name,
+                    ii.manifest.version);
+            });
+            opts.logCb('This will delete the following images:\n    '
+                + summaries.join('\n    '));
+
+            var msg;
+            if (ctx.iiToDel.length === 1) {
+                msg = 'Delete this image? [y/N] ';
+            } else {
+                msg = format('Delete these %d images? [y/N] ',
+                    ctx.iiToDel.length);
+            }
+            common.promptYesNo({msg: msg, default: 'n'}, function (answer) {
+                if (answer !== 'y') {
+                    opts.logCb('Aborting');
+                    next(true);
+                    return;
+                }
+                opts.logCb('');
+                next();
+            });
+        },
+
+        function deleteThem(ctx, next) {
+            vasync.forEachPipeline({
+                inputs: ctx.iiToDel,
+                func: function delImage(ii, nextIi) {
+                    var uuid = ii.manifest.uuid;
+                    if (opts.dryRun) {
+                        opts.logCb('[dry-run] Deleted image %s (%s@%s)',
+                            uuid, ii.manifest.name, ii.manifest.version);
+                        nextIi();
+                        return;
+                    }
+
+                    self.deleteImage({
+                        zpool: ii.zpool,
+                        uuid: uuid,
+                        skipChecks: true
+                    }, function (err) {
+                        if (err) {
+                            opts.logCb('Error deleting image %s (%s@%s): %s',
+                                uuid, ii.manifest.name, ii.manifest.version,
+                                err);
+                            nextIi(err);
+                        } else {
+                            opts.logCb('Deleted image %s (%s@%s)',
+                                uuid, ii.manifest.name, ii.manifest.version);
+                            nextIi();
+                        }
+                    });
+                }
+            }, next);
+        }
+    ]}, cb);
+};
+
+
+/**
+ * Create an image from the given VM and manifest data. There are two basic
+ * calling modes here:
+ * 1. A `options.prepareScript` is provided to be used to prepare the VM
+ *    before image creation. The running of the prepare script is gated by
+ *    a snapshot and rollback so that the end result is a VM that is unchanged.
+ *    This is desireable because (a) it is easier (fewer steps to follow
+ *    for imaging) and (b) the typical preparation script is destructive, so
+ *    gating with snapshotting makes the original VM re-usable. Note that
+ *    the snapshotting and preparation involve reboots of the VM (typically
+ *    two reboots).
+ *    Dev Note: This mode with prepareScript is called "autoprep" in vars
+ *    below.
+ * 2. The VM is already prepared (via the typical prepare-image scripts,
+ *    see <https://download.joyent.com/pub/prepare-image/>) and shutdown.
+ *    For this "mode" do NOT pass in `options.prepareScript`.
+ *
+ * @param options {Object}
+ *      - @param vmUuid {String} UUID of the VM from which to create the image.
+ *      - @param manifest {Object} Data to include in the created manifest.
+ *      - @param logCb {Function} Optional. A function that is called
+ *        with progress messages. Called as `logCb(<string>)`. E.g. passing
+ *        console.log is legal.
+ *      - @param compression {String} Optional compression type for the image
+ *        file. Default is 'none'.
+ *      - @param savePrefix {String} Optional. The file path prefix to which
+ *        to save the manifest and image files.
+ *      - @param incremental {Boolean} Optional. Default false. Create an
+ *        incremental image.
+ *      - @param prepareScript {String} Optional. A script to run to prepare
+ *        the VM for image. See note above.
+ *      - @param prepareTimeout {Number} Optional. Default is 300 (5 minutes).
+ *        The number of seconds before timing out any prepare *stage*. The
+ *        preparation stages are (starting from the VM being shutdown):
+ *        prepare-image running, prepare-image complete, VM stopped.
+ * @param callback {Function} `function (err, imageInfo)` where imageInfo
+ *      has `manifest` (the manifest object), `manifestPath` (the saved
+ *      manifest path) and `filePath` (the saved image file path) keys.
+ */
+IMGADM.prototype.createImage = function createImage(options, callback) {
+    var self = this;
+    assert.object(options, 'options');
+    assert.string(options.vmUuid, 'options.vmUuid');
+    assert.object(options.manifest, 'options.manifest');
+    assert.optionalFunc(options.logCb, 'options.logCb');
+    assert.optionalString(options.compression, 'options.compression');
+    assert.optionalBool(options.incremental, 'options.incremental');
+    assert.optionalString(options.prepareScript, 'options.prepareScript');
+    assert.optionalNumber(options.prepareTimeout, 'options.prepareTimeout');
+    assert.optionalNumber(options.maxOriginDepth, 'options.maxOriginDepth');
+    assert.optionalFunc(options.vmGet, 'options.vmGet');
+
+    var log = self.log;
+    var vmUuid = options.vmUuid;
+    var incremental = options.incremental || false;
+    var logCb = options.logCb || function () {};
+    var prepareScript = options.prepareScript;
+    var prepareTimeout = options.prepareTimeout || 300;  // in seconds
+    var maxOriginDepth = options.maxOriginDepth;
+
+    var vmInfo;
+    var snapname = '@imgadm-create-pre-prepare';
+    var sysinfo;
+    var vmZfsFilesystemName;
+    var vmZfsSnapnames;
+    var originInfo;
+    var originFinalSnap;
+    var imageInfo = {};
+    var finalSnapshot;
+    var toCleanup = {};
+
+    async.waterfall([
+        function validateVm(next) {
+            var vmGet = options.vmGet || common.vmGet;
+
+            vmGet(vmUuid, {log: log}, function (err, vm) {
+                // Currently `vmGet` doesn't distinguish bwtn some unexpected
+                // error and no such VM.
+                if (err) {
+                    next(new errors.VmNotFoundError(vmUuid));
+                    return;
+                }
+                if (!prepareScript && vm.state !== 'stopped') {
+                    next(new errors.VmNotStoppedError(vmUuid));
+                    return;
+                }
+                vmInfo = vm;
+                next();
+            });
+        },
+        function getVmInfo(next) {
+            var opts;
+            if (vmInfo.brand === 'kvm' || vmInfo.brand === 'bhyve') {
+                if (vmInfo.disks && vmInfo.disks[0]) {
+                    var disk = vmInfo.disks[0];
+                    vmZfsFilesystemName = disk.zfs_filesystem;
+
+                    if (disk.image_uuid) {
+                        opts = {uuid: disk.image_uuid, zpool: disk.zpool};
+                    }
+                }
+            } else {
+                opts = {uuid: vmInfo.image_uuid, zpool: vmInfo.zpool};
+                vmZfsFilesystemName = vmInfo.zfs_filesystem;
+            }
+            if (!opts) {
+                // Couldn't find an origin image.
+                log.debug('no origin image found');
+                next();
+                return;
+            }
+            self.getImage(opts, function (getErr, ii) {
+                if (getErr) {
+                    next(getErr);
+                    return;
+                }
+                log.debug({imageInfo: ii}, 'origin image');
+                originInfo = ii;
+                next();
+            });
+        },
+        function validateMaxOriginDepth(next) {
+            // If there is no origin, no depth was passed or origin doesn't
+            // have an origin itself
+            if (!originInfo || !maxOriginDepth || !originInfo.manifest.origin) {
+                next();
+                return;
+            }
+            var currentDepth = 1;
+            // One origin is already one level deep
+            var currentOrigin = originInfo;
+            var foundFirstOrigin = false;
+
+            // Recursively call getImage until we find the source origin
+            async.whilst(
+                function () {
+                    return currentDepth <= maxOriginDepth && !foundFirstOrigin;
+                },
+                function (cb) {
+                    if (!currentOrigin.manifest.origin) {
+                        foundFirstOrigin = true;
+                        cb();
+                        return;
+                    }
+                    var getOpts = {
+                        uuid: currentOrigin.manifest.origin,
+                        zpool: currentOrigin.zpool
+                    };
+                    self.getImage(getOpts, function (getErr, origImg) {
+                        if (getErr) {
+                            cb(getErr);
+                            return;
+                        }
+                        currentDepth++;
+                        currentOrigin = origImg;
+                        cb();
+                    });
+                },
+                function (err) {
+                    if (err) {
+                        next(err);
+                        return;
+                    }
+                    // If we exited the loop because we hit maxOriginDepth
+                    if (currentDepth > maxOriginDepth) {
+                        next(new errors.MaxOriginDepthError(maxOriginDepth));
+                        return;
+                    } else {
+                        next();
+                        return;
+                    }
+                }
+            );
+        },
+        function getSystemInfo(next) {
+            if (vmInfo.brand === 'kvm' || vmInfo.brand === 'bhyve') {
+                next();
+                return;
+            }
+            // We need `sysinfo` for smartos images. See below.
+            getSysinfo(function (err, sysinfo_) {
+                sysinfo = sysinfo_;
+                next(err);
+            });
+        },
+        function gatherManifest(next) {
+            var m = {
+                v: common.MANIFEST_V,
+                uuid: genUuid()
+            };
+            m = imageInfo.manifest = objCopy(options.manifest, m);
+            if (originInfo) {
+                var originManifest = originInfo.manifest;
+                logCb(format('Inheriting from origin image %s (%s %s)',
+                    originManifest.uuid, originManifest.name,
+                    originManifest.version));
+                // IMGAPI-227 TODO: document these and note them in the
+                // imgapi docs. These should come from imgmanifest constant.
+                var INHERITED_FIELDS = ['type', 'os', 'requirements',
+                    'users', 'billing_tags', 'traits', 'generate_passwords',
+                    'inherited_directories', 'nic_driver', 'disk_driver',
+                    'cpu_type', 'image_size'];
+                // TODO Should this *merge* requirements?
+                INHERITED_FIELDS.forEach(function (field) {
+                    if (!m.hasOwnProperty(field)
+                        && originManifest.hasOwnProperty(field))
+                    {
+                        var val = originManifest[field];
+                        // Drop empty arrays, e.g. `billing_tags`, just to
+                        // be leaner/cleaner.
+                        if (!Array.isArray(val) || val.length > 0) {
+                            m[field] = val;
+                        }
+                    }
+                });
+            }
+            if ((vmInfo.brand === 'joyent' || vmInfo.brand === 'joyent-minimal')
+                && !(options.manifest.requirements
+                    && options.manifest.requirements.min_platform))
+            {
+                // Unless an explicit min_platform is provided (possibly empty)
+                // the min_platform for a SmartOS image must be the current
+                // platform, b/c that's the SmartOS binary compat story.
+                if (!m.requirements)
+                    m.requirements = {};
+                m.requirements.min_platform = {};
+                m.requirements.min_platform[sysinfo['SDC Version']]
+                    = sysinfo['Live Image'];
+                log.debug({min_platform: m.requirements.min_platform},
+                    'set smartos image min_platform to current');
+            }
+            if (SET_REQUIREMENTS_BRAND_BRANDS.indexOf(vmInfo.brand) !== -1
+                && !(options.manifest.requirements
+                    && options.manifest.requirements.hasOwnProperty('brand')))
+            {
+                // Unless an explicit brand is provided (possibly empty)
+                // the brand for an image for one of these brands match the
+                // source VM since brand-specific changes may have been made
+                // and we can't guarantee it's compatible with other brands.
+                if (!m.requirements)
+                    m.requirements = {};
+                m.requirements.brand = vmInfo.brand;
+                log.debug({brand: m.requirements.brand},
+                    'set image requirements.brand to source VM brand');
+            }
+            if (incremental) {
+                if (!originInfo) {
+                    next(new errors.VmHasNoOriginError(vmUuid));
+                    return;
+                } else {
+                    m.origin = originInfo.manifest.uuid;
+                }
+            }
+            logCb(format('Manifest:\n%s',
+                indent(JSON.stringify(m, null, 2))));
+            next();
+        },
+        function validateManifest(next) {
+            var errs = imgmanifest.validateMinimalManifest(imageInfo.manifest);
+            if (errs) {
+                next(new errors.ManifestValidationError(errs));
+            } else {
+                next();
+            }
+        },
+        function ensureOriginFinalSnapshot(next) {
+            if (!incremental) {
+                next();
+                return;
+            }
+            originFinalSnap = format('%s/%s@final', originInfo.zpool,
+                imageInfo.manifest.origin);
+            getZfsDataset(originFinalSnap, function (err, ds) {
+                if (err) {
+                    next(err);
+                } else if (!ds) {
+                    next(new errors.OriginHasNoFinalSnapshotError(
+                        imageInfo.manifest.origin));
+                } else {
+                    next();
+                }
+            });
+        },
+
+        function getVmZfsDataset(next) {
+            // Get snapshot/children dataset details on the ZFS filesystem with
+            // which we are going to be mucking.
+            var properties = ['name', 'children'];
+            getZfsDataset(vmZfsFilesystemName, properties, function (zErr, ds) {
+                if (zErr) {
+                    next(zErr);
+                    return;
+                }
+                var snapshots = ds.children.snapshots;
+                vmZfsSnapnames = snapshots.map(
+                    function (n) { return '@' + n.split(/@/g).slice(-1)[0]; });
+                next();
+            });
+        },
+
+        // If `prepareScript` was given, here is where we need to:
+        // - snapshot the VM
+        // - prepare the VM
+        function autoprepStopVmIfNecessary(next) {
+            if (!prepareScript) {
+                next();
+            } else if (vmInfo.state !== 'stopped') {
+                logCb(format('Stopping VM %s to snapshot it', vmUuid));
+                toCleanup.autoprepStartVm = vmUuid; // Re-start it when done.
+                common.vmStop(vmUuid, {log: log}, next);
+            } else {
+                next();
+            }
+        },
+        function autoprepSnapshotDatasets(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+
+            var toSnapshot = [vmInfo.zfs_filesystem];
+            if ((vmInfo.brand === 'kvm' || vmInfo.brand === 'bhyve')
+                && vmInfo.disks) {
+
+                for (var i = 0; i < vmInfo.disks.length; i++) {
+                    toSnapshot.push(vmInfo.disks[i].zfs_filesystem);
+                }
+            }
+
+            logCb(format('Snapshotting VM "%s" to %s', vmUuid, snapname));
+            toCleanup.autoprepSnapshots = [];
+            async.eachSeries(
+                toSnapshot,
+                function snapshotOne(ds, nextSnapshot) {
+                    var snap = ds + snapname;
+                    zfs.snapshot(snap, function (zfsErr) {
+                        if (zfsErr) {
+                            nextSnapshot(new errors.InternalError({
+                                message: 'error creating snapshot',
+                                snap: snap,
+                                cause: zfsErr
+                            }));
+                            return;
+                        }
+                        toCleanup.autoprepSnapshots.push(snap);
+                        nextSnapshot();
+                    });
+                },
+                next);
+        },
+        function autoprepSetOperatorScript(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            var update = {
+                set_internal_metadata: {
+                    'operator-script': prepareScript
+                }
+            };
+            log.debug('set operator-script');
+            common.vmUpdate(vmUuid, update, {log: log}, next);
+        },
+        /**
+         * "Prepare" the VM by booting it, which should run the
+         * operator-script to prepare and shutdown. We track progress via
+         * the 'prepare-image:state' and 'prepare-image:error' keys on
+         * customer_metadata. See the "PREPARE IMAGE SCRIPT" section in the
+         * man page for the contract.
+         */
+        function autoprepClearMdata(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            var update = {
+                remove_customer_metadata: [
+                    'prepare-image:state',
+                    'prepare-image:error'
+                ]
+            };
+            log.debug('create prepare-image:* customer_metadata');
+            common.vmUpdate(vmUuid, update, {log: log}, next);
+        },
+        function autoprepBoot(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            logCb(format('Preparing VM %s (starting it)', vmUuid));
+            common.vmStart(vmUuid, {log: log}, next);
+        },
+        function autoprepWaitForRunning(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            var opts = {
+                log: log,
+                key: 'prepare-image:state',
+                // Don't explicitly check for value=running here because it is
+                // fine if it blows by to 'success' between our polling.
+                timeout: prepareTimeout * 1000,
+                interval: 2000
+            };
+            log.debug('wait for up to %ds for prepare-image:state signal '
+                + 'from operator-script', prepareTimeout);
+            common.vmWaitForCustomerMetadatum(vmUuid, opts, function (err, vm) {
+                if (err) {
+                    if (err.code === 'Timeout') {
+                        /**
+                         * This could mean any of:
+                         * - the VM has old guest tools that either don't run
+                         *   an 'sdc:operator-script' or don't have a working
+                         *   'mdata-put'
+                         * - the VM boot + time to get to prepare-image script
+                         *   setting 'prepare-image:state' mdata takes >5
+                         *   minutes
+                         * - the prepare-image script has a bug in that it does
+                         *   not set the 'prepare-image:state' mdata key to
+                         *   'running'
+                         * - the prepare-image script crashed early
+                         */
+                        logCb('Timeout waiting for prepare-image script to '
+                            + 'signal it started');
+                        log.debug('timeout waiting for operator-script to '
+                            + 'set prepare-image:state');
+                        next(new errors.PrepareImageDidNotRunError(vmUuid));
+                    } else {
+                        log.debug(err, 'unexpected error waiting for '
+                            + 'operator-script to set prepare-image:state');
+                        next(err);
+                    }
+                    return;
+                }
+                logCb('Prepare script is running');
+                vmInfo = vm;
+                next();
+            });
+        },
+        function autoprepWaitForComplete(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            var opts = {
+                log: log,
+                key: 'prepare-image:state',
+                values: ['success', 'error'],
+                timeout: prepareTimeout * 1000
+            };
+            log.debug('wait for up to %ds for prepare-image:state of "error" '
+                + 'or "success"', prepareTimeout);
+            common.vmWaitForCustomerMetadatum(vmUuid, opts, function (err, vm) {
+                if (err) {
+                    next(new errors.PrepareImageError(err, vmUuid,
+                        'prepare-image script did not complete'));
+                    return;
+                }
+                vmInfo = vm;
+                var cm = vm.customer_metadata;
+                log.debug({
+                    'prepare-image:state': cm['prepare-image:state'],
+                    'prepare-image:error': cm['prepare-image:error'],
+                    'prepare-image:progress': cm['prepare-image:progress']
+                }, 'prepare-image:state is set');
+                if (cm['prepare-image:state'] === 'error') {
+                    next(new errors.PrepareImageError(vmUuid,
+                        cm['prepare-image:error'] || ''));
+                } else {
+                    logCb('Prepare script succeeded');
+                    next();
+                }
+            });
+        },
+        function autoprepWaitForVmStopped(next) {
+            if (!prepareScript) {
+                next();
+                return;
+            }
+            var opts = {
+                state: 'stopped',
+                timeout: prepareTimeout * 1000,
+                log: log
+            };
+            log.debug('wait for up to %ds for VM to stop', prepareTimeout);
+            common.vmWaitForState(vmUuid, opts, function (err, vm) {
+                if (err) {
+                    next(new errors.PrepareImageError(err, vmUuid,
+                        'VM did not shutdown'));
+                    return;
+                }
+                var cm = vm.customer_metadata;
+                log.debug({
+                    'prepare-image:state': cm['prepare-image:state'],
+                    'prepare-image:error': cm['prepare-image:error'],
+                    'prepare-image:progress': cm['prepare-image:progress']
+                }, 'prepare-image stopped VM');
+                logCb('Prepare script stopped VM ' + vmUuid);
+                next();
+            });
+        },
+
+        function renameFinalSnapshotOutOfTheWay(next) {
+            // We use a snapshot named '@final'. If there is an existing one,
+            // rename it to '@final-$timestamp'.
+            if (vmZfsSnapnames.indexOf('@final') == -1) {
+                next();
+                return;
+            }
+            var curr = vmZfsFilesystemName + '@final';
+            var outofway = curr + '-' + Date.now();
+            logCb(format('Moving existing @final snapshot out of the '
+                + 'way to "%s"', outofway));
+            zfsRenameSnapshot(curr, outofway,
+                {recursive: true, log: log}, next);
+        },
+        function snapshotVm(next) {
+            // We want '@final' to be the snapshot in the created image -- see
+            // the notes in _installImage.
+            finalSnapshot = format('%s@final', vmZfsFilesystemName);
+            logCb(format('Snapshotting to "%s"', finalSnapshot));
+            zfs.snapshot(finalSnapshot, function (zfsErr) {
+                if (zfsErr) {
+                    next(new errors.InternalError({
+                        message: 'error creating final snapshot',
+                        finalSnapshot: finalSnapshot,
+                        cause: zfsErr
+                    }));
+                    return;
+                }
+                toCleanup.finalSnapshot = finalSnapshot;
+                next();
+            });
+        },
+        function sendImageFile(next) {
+            // 'zfs send' the image snapshot to a local file. We *could*
+            // stream directly to an optional IMGAPI target, but that makes
+            // it more difficult to do (a) sha1 pre-caculation for upload
+            // checking and (b) eventual re-upload support.
+
+            // To complete this stage we want to wait for all of:
+            // 1. the 'zfs send' process to 'exit'.
+            // 2. the compressor process to 'exit' (if we are compressing)
+            // 3. the pipeline's std handles to 'close'
+            //
+            // If we get an error we "finish" right away. This `finish` stuff
+            // coordinates that.
+            var numToFinish = 2;  // 1 is added below if compressing.
+            var numFinishes = 0;
+            var finished = false;
+            function finish(err) {
+                numFinishes++;
+                if (finished) {
+                    /* jsl:pass */
+                } else if (err) {
+                    finished = true;
+                    log.trace({err: err}, 'sendImageFile err');
+                    next(err);
+                } else if (numFinishes >= numToFinish) {
+                    finished = true;
+                    next();
+                }
+            }
+
+            imageInfo.filePath = options.savePrefix;
+            if (imageInfo.manifest.type === 'zvol') {
+                imageInfo.filePath += '.zvol';
+            } else {
+                imageInfo.filePath += '.zfs';
+            }
+            logCb(format('Sending image file to "%s"', imageInfo.filePath));
+
+            // Compression
+            var compression = options.compression || 'none';
+            var compressor;
+            if (compression === 'none') {
+                /* pass through */
+                compressor = null;
+            } else if (compression === 'bzip2') {
+                compressor = spawn('/usr/bin/bzip2', ['-cfq']);
+                imageInfo.filePath += '.bz2';
+                numToFinish++;
+            } else if (compression === 'gzip') {
+                if (fs.existsSync('/opt/local/bin/pigz')) {
+                    logCb('Compressing image with pigz');
+                    compressor = spawn('/opt/local/bin/pigz', ['-cfq']);
+                } else {
+                    logCb('Compressing image with gzip');
+                    compressor = spawn('/usr/bin/gzip', ['-cfq']);
+                }
+                imageInfo.filePath += '.gz';
+                numToFinish++;
+            } else if (compression === 'xz') {
+                compressor = spawn('/usr/bin/xz', ['-cfq']);
+                imageInfo.filePath += '.xz';
+                numToFinish++;
+            } else {
+                finish(new errors.UsageError(format(
+                    'unknown compression "%s"', compression)));
+                return;
+            }
+            if (compressor) {
+                toCleanup.compressor = compressor;
+                var compStderrChunks = [];
+                compressor.stderr.on('data', function (chunk) {
+                    compStderrChunks.push(chunk);
+                });
+                compressor.on('exit', function (code) {
+                    delete toCleanup.compressor;
+                    if (code !== 0) {
+                        toCleanup.filePath = imageInfo.filePath;
+                        var msg = format(
+                            'error compressing zfs stream: exit code %s\n'
+                            + '    compression: %s\n'
+                            + '    stderr:\n%s', code, compression,
+                            indent(compStderrChunks.join(''), '        '));
+                        log.debug(msg);
+                        finish(new errors.InternalError({message: msg}));
+                    } else {
+                        log.trace({compression: compression},
+                            'compressor exited successfully');
+                        finish();
+                    }
+                });
+            }
+
+            // Don't want '-p' or '-r' options to 'zfs send'.
+            var zfsArgs = ['send'];
+            if (incremental) {
+                zfsArgs.push('-i');
+                zfsArgs.push(originFinalSnap);
+            }
+            zfsArgs.push(finalSnapshot);
+            self.log.debug({cmd: ['/usr/sbin/zfs'].concat(zfsArgs)},
+                'spawn zfs send');
+            var zfsSend = spawn('/usr/sbin/zfs', zfsArgs);
+            var zfsStderrChunks = [];
+            zfsSend.stderr.on('data', function (chunk) {
+                zfsStderrChunks.push(chunk);
+            });
+            toCleanup.zfsSend = zfsSend;
+            zfsSend.on('exit', function (code) {
+                delete toCleanup.zfsSend;
+                if (code !== 0) {
+                    toCleanup.filePath = imageInfo.filePath;
+                    var msg = format('zfs send error: exit code %s\n'
+                        + '    cmd: /usr/sbin/zfs %s\n'
+                        + '    stderr:\n%s', code,
+                        zfsArgs.join(' '),
+                        indent(zfsStderrChunks.join(''), '        '));
+                    self.log.debug(msg);
+                    finish(new errors.InternalError({message: msg}));
+                } else {
+                    self.log.trace({zfsArgs: zfsArgs},
+                        'zfs send exited successfully');
+                    finish();
+                }
+            });
+
+            var size = 0;
+            var sha1Hash = crypto.createHash('sha1');
+            (compressor || zfsSend).stdout.on('data', function (chunk) {
+                size += chunk.length;
+                try {
+                    sha1Hash.update(chunk);
+                } catch (e) {
+                    self.log.debug({err: e}, 'hash update error');
+                    finish(new errors.InternalError({
+                        cause: e,
+                        message: format(
+                            'hash error calculating image file sha1: %s', e)
+                    }));
+                }
+            });
+            (compressor || zfsSend).on('close', function () {
+                imageInfo.manifest.files = [ {
+                    size: size,
+                    compression: compression,
+                    sha1: sha1Hash.digest('hex')
+                } ];
+
+                // This is our successful exit point from this step.
+                self.log.trace('image file send pipeline closed successfully');
+                finish();
+            });
+
+            var out = fs.createWriteStream(imageInfo.filePath);
+            if (compressor) {
+                // zfs send -> bzip2/gzip -> filePath
+                zfsSend.stdout.pipe(compressor.stdin);
+                compressor.stdout.pipe(out);
+            } else {
+                // zfs send -> filePath
+                zfsSend.stdout.pipe(out);
+            }
+        },
+        function saveManifest(next) {
+            var manifestPath = imageInfo.manifestPath
+                = options.savePrefix + '.imgmanifest';
+            logCb(format('Saving manifest to "%s"', manifestPath));
+            var manifestStr = JSON.stringify(imageInfo.manifest, null, 2);
+            fs.writeFile(manifestPath, manifestStr, 'utf8', function (wErr) {
+                if (wErr) {
+                    next(new errors.FileSystemError(wErr, format(
+                        'error saving manifest to "%s": %s', manifestPath,
+                        wErr)));
+                    return;
+                }
+                next();
+            });
+        }
+    ], function (err) {
+        async.series([
+            function cleanupZfsSend(next) {
+                if (!toCleanup.zfsSend) {
+                    next();
+                    return;
+                }
+                self.log.debug('killing zfsSend process');
+                toCleanup.zfsSend.on('exit', function () {
+                    self.log.debug('zfsSend process exited');
+                    next();
+                });
+                toCleanup.zfsSend.kill('SIGKILL');
+            },
+            function cleanupCompressor(next) {
+                if (!toCleanup.compressor) {
+                    next();
+                    return;
+                }
+                self.log.debug('killing compressor process');
+                toCleanup.compressor.on('exit', function () {
+                    self.log.debug('compressor process exited');
+                    next();
+                });
+                toCleanup.compressor.kill('SIGKILL');
+            },
+            function cleanupImageFile(next) {
+                if (!toCleanup.filePath) {
+                    next();
+                    return;
+                }
+                self.log.debug('remove incomplete image file "%s"',
+                    toCleanup.filePath);
+                rimraf(toCleanup.filePath, next);
+            },
+            function cleanupFinalSnapshot(next) {
+                if (!toCleanup.finalSnapshot) {
+                    next();
+                    return;
+                }
+                zfsDestroy(toCleanup.finalSnapshot, self.log, next);
+            },
+            /**
+             * Restoring the VM dataset(s) to their previous state in 3 parts:
+             * 1. ensure the VM is stopped (it is surprising if it isn't)
+             * 2. rollback all the zfs filesystems
+             * 3. destroy the snaps
+             */
+            function cleanupAutoprepSnapshots1(next) {
+                if (!toCleanup.autoprepSnapshots) {
+                    next();
+                    return;
+                }
+                logCb(format('Rollback VM %s to pre-prepare snapshot (cleanup)',
+                    vmUuid));
+                var opts = {log: self.log};
+                common.vmHaltIfNotStopped(vmUuid, opts, next);
+            },
+            function cleanupAutoprepSnapshots2(next) {
+                if (!toCleanup.autoprepSnapshots) {
+                    next();
+                    return;
+                }
+                async.eachSeries(
+                    toCleanup.autoprepSnapshots,
+                    function rollbackOne(snap, nextSnapshot) {
+                        self.log.debug('zfs rollback', snap);
+                        zfs.rollback(snap, nextSnapshot);
+                    },
+                    next);
+            },
+            function cleanupAutoprepSnapshots3(next) {
+                if (!toCleanup.autoprepSnapshots) {
+                    next();
+                    return;
+                }
+                async.eachSeries(
+                    toCleanup.autoprepSnapshots,
+                    function destroyOne(snap, nextSnapshot) {
+                        var re = new RegExp('/disk[0-9]*' + snapname + '$');
+
+                        if (vmInfo.brand === 'bhyve' && snap.match(re)) {
+                            // For bhyve brand, the disk snapshots will be gone
+                            // when the root snapshot is destroyed (because of
+                            // the -r) so, we only need to remove the root
+                            // snapshot here and skip diskX snapshots.
+                            self.log.debug({
+                                snapname: snap
+                            }, 'skipping deletion of bhyve disk snapshot');
+                            nextSnapshot();
+                            return;
+                        }
+
+                        zfsDestroy(snap, self.log, nextSnapshot);
+                    },
+                    next);
+            },
+            function cleanupAutoprepStartVm(next) {
+                if (!toCleanup.autoprepStartVm) {
+                    next();
+                    return;
+                }
+                logCb(format('Restarting VM %s (cleanup)',
+                    toCleanup.autoprepStartVm));
+                common.vmStart(toCleanup.autoprepStartVm,
+                    {log: self.log}, next);
+            }
+        ], function (cleanErr) {
+            var e = err || cleanErr;
+            if (err && cleanErr) {
+                e = new errors.MultiError([err, cleanErr]);
+            }
+            callback(e, imageInfo);
+        });
+    });
+};
+
+
+/**
+ * Publish the given image to the given IMGAPI.
+ *
+ * @param options {Object}
+ *      - @param manifest {Object} The manifest to import.
+ *      - @param file {String} The image file path to import.
+ *      - @param url {String} The IMGAPI URL to which to publish.
+ *      - @param quiet {Boolean} Optional. Default false. Set to true
+ *        to not have a progress bar for the file upload.
+ * @param callback {Function} `function (err, image)`
+ */
+IMGADM.prototype.publishImage = function publishImage(opts, callback) {
+    assert.object(opts, 'options');
+    assert.object(opts.manifest, 'options.manifest');
+    var manifest = opts.manifest;
+    assert.string(opts.file, 'options.file');
+    assert.string(opts.url, 'options.url');
+    assert.optionalBool(opts.quiet, 'options.quiet');
+    // At least currently we require the manifest to have the file info
+    // (as it does if created by 'imgadm create').
+    assert.arrayOfObject(manifest.files, 'options.manifest.files');
+    var manifestFile = manifest.files[0];
+    assert.object(manifestFile, 'options.manifest.files[0]');
+    assert.string(manifestFile.compression,
+        'options.manifestFile.files[0].compression');
+    var self = this;
+
+    var client = imgapi.createClient({
+        agent: false,
+        url: opts.url,
+        log: self.log.child({component: 'api', url: opts.url}, true),
+        rejectUnauthorized: (process.env.IMGADM_INSECURE !== '1'),
+        userAgent: self.userAgent
+    });
+    var uuid = manifest.uuid;
+    var rollbackImage;
+    var activatedImage;
+
+    async.series([
+        function importIt(next) {
+            client.adminImportImage(manifest, {}, function (err, image, res) {
+                self.log.trace({err: err, image: image, res: res},
+                    'AdminImportImage');
+                if (err) {
+                    next(self._errorFromClientError(opts.url, err));
+                    return;
+                }
+                console.log('Imported image %s (%s, %s, state=%s)',
+                    image.uuid, image.name, image.version, image.state);
+                rollbackImage = image;
+                next();
+            });
+        },
+        function addFile(next) {
+            var stream = fs.createReadStream(opts.file);
+            imgapi.pauseStream(stream);
+
+            var bar;
+            if (!opts.quiet && process.stderr.isTTY) {
+                bar = new ProgressBar({
+                    size: manifestFile.size,
+                    filename: uuid
+                });
+            }
+            stream.on('data', function (chunk) {
+                if (bar)
+                    bar.advance(chunk.length);
+            });
+            stream.on('end', function () {
+                if (bar)
+                    bar.end();
+            });
+
+            var fopts = {
+                uuid: uuid,
+                file: stream,
+                size: manifestFile.size,
+                compression: manifestFile.compression,
+                sha1: manifestFile.sha1
+            };
+            client.addImageFile(fopts, function (err, image, res) {
+                self.log.trace({err: err, image: image, res: res},
+                    'AddImageFile');
+                if (err) {
+                    if (bar)
+                        bar.end();
+                    next(self._errorFromClientError(opts.url, err));
+                    return;
+                }
+
+                console.log('Added file "%s" (compression "%s") to image %s',
+                    opts.file, manifestFile.compression, uuid);
+
+                // Verify uploaded size and sha1.
+                var expectedSha1 = manifestFile.sha1;
+                if (expectedSha1 !== image.files[0].sha1) {
+                    next(new errors.UploadError(format(
+                        'sha1 expected to be %s, but was %s',
+                        expectedSha1, image.files[0].sha1)));
+                    return;
+                }
+                var expectedSize = manifestFile.size;
+                if (expectedSize !== image.files[0].size) {
+                    next(new errors.UploadError(format(
+                        'size expected to be %s, but was %s',
+                        expectedSize, image.files[0].size)));
+                    return;
+                }
+
+                next();
+            });
+        },
+        function activateIt(next) {
+            client.activateImage(uuid, function (err, image, res) {
+                self.log.trace({err: err, image: image, res: res},
+                    'ActivateImage');
+                if (err) {
+                    next(self._errorFromClientError(opts.url, err));
+                    return;
+                }
+                activatedImage = image;
+                console.log('Activated image %s', uuid);
+                next();
+            });
+        }
+    ], function (err) {
+        if (err) {
+            if (rollbackImage) {
+                self.log.debug({err: err, rollbackImage: rollbackImage},
+                    'rollback partially imported image');
+                var delUuid = rollbackImage.uuid;
+                client.deleteImage(uuid, function (delErr, res) {
+                    self.log.trace({err: delErr, res: res}, 'DeleteImage');
+                    if (delErr) {
+                        self.log.debug({err: delErr}, 'error rolling back');
+                        console.log('Warning: Could not delete partially '
+                            + 'published image %s: %s', delUuid, delErr);
+                    }
+                    callback(err);
+                });
+            } else {
+                callback(err);
+            }
+        } else {
+            callback(null, activatedImage);
+        }
+    });
+};
+
+
+// ---- exports
+
+/**
+ * Create an IMGADM tool.
+ *
+ * @params options {Object}
+ *      - log {Bunyan Logger} Required.
+ * @params callback {Function} `function (err)`
+ */
+function createTool(options, callback) {
+    var tool = new IMGADM(options);
+    tool.init(function (err) {
+        if (err) {
+            callback(err);
+            return;
+        }
+        tool.log.trace({config: tool.config}, 'tool initialized');
+        callback(null, tool);
+    });
+}
+
+module.exports = {
+    createTool: createTool
+};
diff --git a/tools/buildimage/lib/imgadm/lib/locker.js b/tools/buildimage/lib/imgadm/lib/locker.js
new file mode 100644
index 0000000..0b9906a
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/locker.js
@@ -0,0 +1,177 @@
+/*
+ * Copyright (c) 2014, Joyent, Inc. All rights reserved.
+ */
+// vim: set sts=4 sw=4 et:
+
+// Ensure we're using the platform's node
+// require('/usr/node/node_modules/platform_node_version').assert();
+
+var mod_path = require('path');
+var mod_fs = require('fs');
+var mod_assert = require('assert');
+
+var mod_lockfd = require('lockfd');
+
+// If we fail to lock (i.e. the call to fcntl() in node-lockfd), and
+// the errno is in this list, then we should back off for some delay
+// and retry.  Note that an EDEADLK, in particular, is not necessarilly
+// a permanent failure in a program using multiple lock files through
+// multiple threads of control.
+var RETRY_CODES = [
+    'EAGAIN',
+    'ENOLCK',
+    'EDEADLK'
+];
+var RETRY_DELAY = 250; // ms
+
+var LOCKFILE_MODE = 0644;
+
+var LOCKFILES = [];
+var NEXT_HOLDER_ID = 1;
+
+function lockfile_create(path) {
+    path = mod_path.normalize(path);
+
+    mod_assert.strictEqual(lockfile_lookup(path), null);
+
+    var lf = {
+        lf_path: path,
+        lf_state: 'UNLOCKED',
+        lf_cbq: [],
+        lf_fd: -1,
+        lf_holder_id: -1
+    };
+
+    LOCKFILES.push(lf);
+
+    return (lf);
+}
+
+function lockfile_lookup(path) {
+    path = mod_path.normalize(path);
+
+    for (var i = 0; i < LOCKFILES.length; i++) {
+        var lf = LOCKFILES[i];
+
+        if (lf.lf_path === path)
+            return (lf);
+    }
+
+    return (null);
+}
+
+// Make an unlock callback for this lockfile to hand to the waiter for whom
+// we acquired the lock:
+function lockfile_make_unlock(lf) {
+    var holder_id;
+
+    mod_assert.strictEqual(lf.lf_holder_id, -1);
+
+    lf.lf_holder_id = holder_id = ++NEXT_HOLDER_ID;
+
+    return (function __unlock(ulcb) {
+        mod_assert.strictEqual(lf.lf_holder_id, holder_id,
+            'mismatched lock holder or already unlocked');
+        lf.lf_holder_id = -1;
+
+        mod_assert.strictEqual(lf.lf_state, 'LOCKED');
+        mod_assert.notStrictEqual(lf.lf_fd, -1);
+
+        lf.lf_state = 'UNLOCKING';
+
+        mod_fs.close(lf.lf_fd, function (err) {
+            lf.lf_state = 'UNLOCKED';
+            lf.lf_fd = -1;
+
+            ulcb(err);
+
+            lockfile_dispatch(lf);
+        });
+    });
+}
+
+function lockfile_dispatch(lf) {
+    if (lf.lf_state !== 'UNLOCKED')
+        return;
+
+    if (lf.lf_cbq.length === 0) {
+        // No more waiters to service for now.
+        return;
+    }
+
+    lockfile_to_locking(lf);
+}
+
+function lockfile_to_locking(lf) {
+    mod_assert.strictEqual(lf.lf_state, 'UNLOCKED');
+    mod_assert.strictEqual(lf.lf_fd, -1);
+
+    lf.lf_state = 'LOCKING';
+
+    // Open the lock file, creating it if it does not exist:
+    mod_fs.open(lf.lf_path, 'w+', LOCKFILE_MODE, function __opencb(err, fd) {
+        mod_assert.strictEqual(lf.lf_state, 'LOCKING');
+        mod_assert.strictEqual(lf.lf_fd, -1);
+
+        if (err) {
+            lf.lf_state = 'UNLOCKED';
+
+            // Dispatch error to the first waiter
+            lf.lf_cbq.shift()(err);
+            lockfile_dispatch(lf);
+            return;
+        }
+
+        lf.lf_fd = fd;
+
+        // Attempt to get an exclusive lock on the file via our file
+        // descriptor:
+        mod_lockfd.lockfd(lf.lf_fd, function __lockfdcb(_err) {
+            mod_assert.strictEqual(lf.lf_state, 'LOCKING');
+
+            if (_err) {
+                var do_retry = (RETRY_CODES.indexOf(_err.code) !== -1);
+
+                // We could not lock the file, so we should close our fd now:
+                mod_fs.close(lf.lf_fd, function __closecb(__err) {
+                    // It would be most unfortunate to fail here:
+                    mod_assert.ifError(__err);
+
+                    lf.lf_fd = -1;
+                    lf.lf_state = 'UNLOCKED';
+
+                    if (do_retry) {
+                        // Back off and try again.
+                        setTimeout(function __tocb() {
+                            lockfile_dispatch(lf);
+                        }, RETRY_DELAY);
+                        return;
+                    }
+
+                    // Report the condition to the first waiter:
+                    lf.lf_cbq.shift()(_err);
+
+                    lockfile_dispatch(lf);
+                });
+                return;
+            }
+
+            lf.lf_state = 'LOCKED';
+
+            // Dispatch locking success to first waiter, with unlock callback:
+            lf.lf_cbq.shift()(null, lockfile_make_unlock(lf));
+        });
+    });
+}
+
+exports.lock = function (path, callback) {
+    var lf = lockfile_lookup(path);
+    if (!lf) {
+        lf = lockfile_create(path);
+    }
+
+    lf.lf_cbq.push(callback);
+
+    lockfile_dispatch(lf);
+
+};
diff --git a/tools/buildimage/lib/imgadm/lib/magic.js b/tools/buildimage/lib/imgadm/lib/magic.js
new file mode 100644
index 0000000..9c89e07
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/magic.js
@@ -0,0 +1,102 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * Magic number sniffing of compression type of files.
+ */
+
+var assert = require('assert-plus');
+var format = require('util').format;
+var fs = require('fs');
+
+
+
+// ---- compression type sniffing
+
+var magicNumbers = {
+    // <compression type> : <magic number>
+    bzip2: new Buffer([0x42, 0x5A, 0x68]),
+    gzip:  new Buffer([0x1F, 0x8B, 0x08]),
+    xz:    new Buffer([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])
+};
+var maxMagicLen = 0;
+Object.keys(magicNumbers).forEach(function (type) {
+    maxMagicLen = Math.max(maxMagicLen, magicNumbers[type].length);
+});
+
+function bufNEquals(a, b, n) {
+    assert.ok(a.length >= n, format(
+        'buffer "a" length (%d) is shorter than "n" (%d)', a.length, n));
+    assert.ok(b.length >= n, format(
+        'buffer "b" length (%d) is shorter than "n" (%d)', b.length, n));
+
+    for (var i = 0; i < n; i++) {
+        if (a[i] !== b[i]) {
+            return false;
+        }
+    }
+    return true;
+}
+
+function compressionTypeFromBufSync(buf) {
+    var types = Object.keys(magicNumbers);
+    for (var i = 0; i < types.length; i++) {
+        var type = types[i];
+        var magic = magicNumbers[type];
+        if (bufNEquals(buf, magic, magic.length)) {
+            return type;
+        }
+    }
+    return null;
+}
+
+function compressionTypeFromPath(path, cb) {
+    fs.open(path, 'r', function (oErr, fd) {
+        if (oErr) {
+            cb(oErr);
+            return;
+        }
+        var buf = new Buffer(maxMagicLen);
+        fs.read(fd, buf, 0, buf.length, 0, function (rErr, bytesRead, buffer) {
+            if (rErr) {
+                cb(rErr);
+                return;
+            }
+            fs.close(fd, function (cErr) {
+                if (cErr) {
+                    cb(cErr);
+                    return;
+                }
+                cb(null, compressionTypeFromBufSync(buf));
+            });
+        });
+    });
+}
+
+
+// ---- exports
+
+module.exports = {
+    compressionTypeFromPath: compressionTypeFromPath
+};
diff --git a/tools/buildimage/lib/imgadm/lib/sources/docker.js b/tools/buildimage/lib/imgadm/lib/sources/docker.js
new file mode 100644
index 0000000..0ea6821
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/sources/docker.js
@@ -0,0 +1,386 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var concat = require('concat-stream');
+var drc = require('docker-registry-client');
+var imgmanifest = require('imgmanifest');
+var url = require('url');
+var util = require('util'),
+    format = util.format;
+var vasync = require('vasync');
+
+var common = require('../common');
+var errors = require('../errors');
+var Source = require('./source');
+
+
+
+// ---- globals
+
+var DOCKER_HUB_URL = 'https://docker.io';
+
+
+
+// ---- docker source
+
+function DockerSource(opts) {
+    assert.object(opts.config, 'opts.config');
+    assert.bool(opts.config.dockerImportSkipUuids,
+        'opts.config.dockerImportSkipUuids');
+
+    this.dockerImportSkipUuids = opts.config.dockerImportSkipUuids;
+
+    Source.call(this, opts);
+
+    this.index = drc.parseIndex(this.url);
+}
+util.inherits(DockerSource, Source);
+
+DockerSource.prototype.type = 'docker';
+
+DockerSource.prototype.ping = function ping(cb) {
+    var self = this;
+
+    drc.pingV2({
+        indexName: self.url,
+        log: self.log,
+        insecure: self.insecure
+    }, function (err) {
+        // Allow a 401 "Authentication is required" error.
+        if (err && err.statusCode !== 401) {
+            cb(new errors.SourcePingError(err, self));
+            return;
+        }
+        cb();
+    });
+};
+
+
+DockerSource.prototype._clientFromRepo = function _clientFromRepo(repo) {
+    assert.object(repo, 'repo');
+    // assert.equal(repo.index.name, this.index.name);
+
+    var key = repo.canonicalName;
+
+    if (this.__clientCache === undefined) {
+        this.__clientCache = {};
+    }
+
+    if (!this.__clientCache[key]) {
+        this.__clientCache[key] = drc.createClientV2({
+            maxSchemaVersion: 2,
+            repo: repo,
+            scheme: this.index.scheme,
+            log: this.log,
+            insecure: this.insecure
+        });
+    }
+    return this.__clientCache[key];
+};
+
+
+function _importInfoFromV21Manifest(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.dockerManifest, 'opts.dockerManifest');
+    assert.object(opts.rat, 'opts.rat');
+    assert.func(cb, 'cb');
+
+    var dockerManifest = opts.dockerManifest;
+    var imgJson;
+
+    // These digests are backwards (newest to oldest layer), so we reverse
+    // them to get the base layer first.
+    var layers = dockerManifest.fsLayers.slice();
+    layers = layers.reverse();
+
+    var lastDigest;
+    var layerDigests = layers.filter(
+        // Filter out duplicated layers here - i.e. those layers which are
+        // exactly the same as the previous layer, as there is no need to
+        // download and install the same layer over and over again. We hit
+        // this because v2.1 manifests use an empty bits layer for docker
+        // build commands that don't change the image, i.e. for metadata
+        // commands like ENV and ENTRYPOINT.
+        function _filterLayerDigest(l) {
+            if (l.blobSum === lastDigest) {
+                return false;
+            }
+            lastDigest = l.blobSum;
+            return true;
+        }
+    ).map(
+        function _mapLayerDigest(l) {
+            return l.blobSum;
+        }
+    );
+
+    try {
+        imgJson = JSON.parse(dockerManifest.history[0].v1Compatibility);
+    } catch (manifestErr) {
+        cb(new errors.ValidationFailedError(manifestErr, format(
+            'invalid "v1Compatibility" JSON in docker manifest: %s (%s)',
+            manifestErr, dockerManifest.history[0].v1Compatibility)));
+        return;
+    }
+
+    var rat = opts.rat;
+    var importInfo = {
+        repo: rat,
+        tag: rat.tag,    // the requested tag
+        tags: [rat.tag], // all the tags on that imgId
+        imgId: layerDigests[layerDigests.length - 1], // newest layer
+        imgJson: imgJson,
+        dockerManifest: dockerManifest,
+        layerDigests: layerDigests,
+        uuid: imgmanifest.imgUuidFromDockerDigests(layerDigests)
+    };
+    cb(null, importInfo);
+}
+
+
+/**
+ * Attempt to find import info for the given docker pull arg, `REPO[:TAG]`
+ * in this docker registry.
+ *
+ * If the given `arg` is not a valid identifier the response is `cb()`.
+ * Likewise, if the arg is not found in this docker source: `cb()`. IOW, this
+ * is how this image source says the `opts.arg` is not applicable.
+ */
+DockerSource.prototype.getImportInfo = function getImportInfo(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.string(opts.arg, 'opts.arg');
+    assert.func(cb, 'cb');
+
+    if (self.dockerImportSkipUuids && common.UUID_RE.test(opts.arg)) {
+        cb();
+        return;
+    }
+
+    /*
+     * Ignore: (a) a non-Docker IMGAPI/SDC image UUID, and (b) a Docker repo
+     * which includes a index name (aka registry host) that doesn't match.
+     */
+    try {
+        var rat = drc.parseRepoAndTag(opts.arg);
+    } catch(e) {
+        return cb();
+    }
+    
+    var importInfo;
+
+    var client = self._clientFromRepo(rat);
+    client.getManifest({ref: rat.tag}, function (err, dockerManifest, res) {
+        if (err) {
+            if (err.statusCode === 404) {
+                cb();
+            } else {
+                cb(err);
+            }
+            return;
+        }
+
+        assert.object(dockerManifest, 'manifest');
+        if (!dockerManifest.hasOwnProperty('schemaVersion')) {
+            cb(new errors.InvalidDockerInfoError(
+                'No docker manifest schemaVersion defined'));
+            return;
+        }
+
+        if (dockerManifest.schemaVersion !== 1
+                && dockerManifest.schemaVersion !== 2) {
+            cb(new errors.InvalidDockerInfoError(
+                'Unsupported docker manifest version: '
+                 + dockerManifest.schemaVersion));
+            return;
+        }
+
+        if (dockerManifest.schemaVersion === 1) {
+            _importInfoFromV21Manifest({
+                dockerManifest: dockerManifest,
+                rat: rat
+            }, cb);
+            return;
+        }
+
+        // For schemaVersion 2 manifests - must fetch the imgJson separately.
+        assert.equal(dockerManifest.schemaVersion, 2,
+            'dockerManifest.schemaVersion === 2');
+
+        var layerDigests = dockerManifest.layers.map(
+            function (l) {
+                return l.digest;
+            }
+        );
+
+        var configDigest = dockerManifest.config.digest;
+        client.createBlobReadStream({digest: configDigest},
+            function (err, stream, ress) {
+                if (err) {
+                    cb(err);
+                    return;
+                }
+                stream.pipe(concat(function (buf) {
+                    var imgJson;
+                    try {
+                        imgJson = JSON.parse(buf.toString());
+                    } catch (ex) {
+                        cb(ex);
+                        return;
+                    }
+    
+                    importInfo = {
+                        repo: rat,
+                        tag: rat.tag,   // the requested tag
+                        tags: [rat.tag], // all the tags on that imgId
+                        imgId: dockerManifest.layers[dockerManifest.layers.length-1].digest,
+                        imgJson: imgJson,
+                        dockerManifest: dockerManifest,
+                        layerDigests: layerDigests,
+                        uuid: imgmanifest.imgUuidFromDockerDigests(layerDigests)
+                    };
+                    cb(null, importInfo);
+                }));
+    
+                // stream error handling
+                stream.on('error', function (err) {
+                   console.error('read stream error:', err);
+                   cb(err);
+                });
+    
+                stream.resume();
+            }
+        );
+    });
+}
+
+
+DockerSource.prototype.titleFromImportInfo =
+function titleFromImportInfo(importInfo) {
+    return format('%s (%s:%s)', importInfo.uuid,
+        importInfo.repo.canonicalName, importInfo.tag);
+};
+
+
+DockerSource.prototype.getImgAncestry = function getImgAncestry(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.repo, 'opts.repo');
+    assert.object(opts.dockerManifest, 'opts.dockerManifest');
+    assert.object(opts.imgJson, 'opts.imgJson');
+    assert.arrayOfString(opts.layerDigests, 'opts.layerDigests');
+    assert.func(cb, 'cb');
+
+    var ancestry;
+    var digests = opts.layerDigests;
+    var imgJson = common.objCopy(opts.imgJson);
+    var parentDigest = null;
+
+    ancestry = digests.map(function (digest, idx) {
+        imgJson = common.objCopy(imgJson);
+        imgJson.parent = parentDigest;
+        imgJson.config = common.objCopy(imgJson.config);
+        imgJson.config.parent = parentDigest;
+        parentDigest = digest;
+        var layerDigests = digests.slice(0, idx+1);
+        var size = 0;
+        if (opts.dockerManifest.schemaVersion === 2) {
+            size = opts.dockerManifest.layers[idx].size;
+        }
+        return {
+            imgId: digest,
+            imgJson: imgJson,
+            layerDigests: layerDigests,
+            uuid: imgmanifest.imgUuidFromDockerDigests(layerDigests),
+            size: size,
+            repo: opts.repo
+        };
+    });
+    cb(null, ancestry);
+};
+
+
+DockerSource.prototype.getImgMeta = function getImgMeta(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.repo, 'opts.repo');
+    assert.string(opts.imgId, 'opts.imgId');
+    assert.arrayOfString(opts.layerDigests, 'opts.layerDigests');
+    assert.optionalArrayOfString(opts.tags, 'opts.tags');
+    assert.func(cb, 'cb');
+
+    var imgMeta = {
+        manifest: imgmanifest.imgManifestFromDockerInfo({
+            layerDigests: opts.layerDigests,
+            imgJson: opts.imgJson,
+            repo: opts.repo,
+            tags: opts.tags,
+            uuid: opts.uuid
+        })
+    };
+    cb(null, imgMeta);
+};
+
+
+/**
+ * Get a (paused) readable stream for the given image file.
+ *
+ * @param opts {Object} Image info, as from `getImportInfo` or an element of
+ *      the array returned from `getImgAncestry`.
+ * @param cb {Function} `function (err, stream)`
+ */
+DockerSource.prototype.getImgFileStream = function getImgFileStream(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.object(opts.repo, 'opts.repo');
+    assert.string(opts.imgId, 'opts.imgId');
+    assert.func(cb, 'cb');
+
+    var client = this._clientFromRepo(opts.repo);
+    client.createBlobReadStream({digest: opts.imgId}, function (err, stream) {
+        if (err) {
+            cb(err);
+            return;
+        }
+        cb(null, stream);
+    });
+};
+
+
+
+// ---- exports
+
+module.exports = DockerSource;
+
+module.exports.DOCKER_HUB_URL = DOCKER_HUB_URL;
+
+module.exports.isDockerPullArg = function isDockerPullArg(arg) {
+    try {
+        drc.parseRepoAndTag(arg);
+        return true;
+    } catch(e) {
+        return false;
+    }
+};
diff --git a/tools/buildimage/lib/imgadm/lib/sources/dsapi.js b/tools/buildimage/lib/imgadm/lib/sources/dsapi.js
new file mode 100644
index 0000000..e79a063
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/sources/dsapi.js
@@ -0,0 +1,92 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var dsapi = require('sdc-clients/lib/dsapi');
+var path = require('path');
+var util = require('util');
+
+var common = require('../common');
+var errors = require('../errors');
+var Source = require('./source');
+var ImgapiSource = require('./imgapi');
+
+
+// ---- dsapi source
+// Mostly like the 'imgapi' source with some diffs.
+
+function DsapiSource(opts) {
+    var self = this;
+
+    this.__defineGetter__('client', function () {
+        if (this._client === undefined) {
+            if (! /\/datasets\/?$/.test(self.normUrl)) {
+                throw new errors.ConfigError(format(
+                    '"dsapi" source URL does not end with "/datasets": "%s"',
+                    self.normUrl));
+            }
+            // drop 'datasets/' tail
+            var baseNormUrl = path.dirname(self.normUrl);
+            this._client = dsapi.createClient({
+                url: baseNormUrl,
+                log: self.log,
+                rejectUnauthorized: (opts.insecure !== undefined ?
+                    opts.insecure : process.env.IMGADM_INSECURE !== '1'),
+                userAgent: self.userAgent
+            });
+        }
+        return this._client;
+    });
+
+    Source.call(this, opts);
+}
+util.inherits(DsapiSource, ImgapiSource);
+
+DsapiSource.prototype.type = 'dsapi';
+
+DsapiSource.prototype.ping = function ping(cb) {
+    var self = this;
+    this.client.ping(function (err, pong, res) {
+        if (err || res.statusCode !== 200) {
+            if (res && res.headers['content-type'] !== 'application/json') {
+                var body = res.body;
+                if (body && body.length > 1024) {
+                    body = body.slice(0, 1024) + '...';
+                }
+                err = new Error(format(
+                    'statusCode %s, response not JSON:\n%s',
+                    res.statusCode, common.indent(body)));
+            }
+            cb(new errors.SourcePingError(err, self));
+            return;
+        }
+        cb();
+    });
+};
+
+
+module.exports = DsapiSource;
diff --git a/tools/buildimage/lib/imgadm/lib/sources/imgapi.js b/tools/buildimage/lib/imgadm/lib/sources/imgapi.js
new file mode 100644
index 0000000..270e93f
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/sources/imgapi.js
@@ -0,0 +1,264 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var format = require('util').format;
+var imgapi = require('sdc-clients/lib/imgapi');
+var imgmanifest = require('imgmanifest');
+var util = require('util');
+var vasync = require('vasync');
+
+var common = require('../common');
+var errors = require('../errors');
+var Source = require('./source');
+
+
+// ---- imgapi source
+
+function ImgapiSource(opts) {
+    var self = this;
+
+    this.__defineGetter__('client', function () {
+        if (this._client === undefined) {
+            this._client = imgapi.createClient({
+                url: self.normUrl,
+                version: '~2',
+                log: self.log,
+                rejectUnauthorized: (opts.insecure !== undefined ?
+                    opts.insecure : process.env.IMGADM_INSECURE !== '1'),
+                userAgent: self.userAgent
+            });
+        }
+        return this._client;
+    });
+
+    Source.call(this, opts);
+}
+util.inherits(ImgapiSource, Source);
+
+ImgapiSource.prototype.type = 'imgapi';
+
+ImgapiSource.prototype.ping = function ping(cb) {
+    var self = this;
+    this.client.ping(function (err, pong, res) {
+        if (err || res.statusCode !== 200 || !pong.imgapi) {
+            if (res && res.headers['content-type'] !== 'application/json') {
+                var body = res.body;
+                if (body && body.length > 1024) {
+                    body = body.slice(0, 1024) + '...';
+                }
+                err = new Error(format(
+                    'statusCode %s, response not JSON:\n%s',
+                    res.statusCode, common.indent(body)));
+            }
+            cb(new errors.SourcePingError(err, self));
+            return;
+        }
+        cb();
+    });
+};
+
+
+ImgapiSource.prototype.listImages = function listImages(cb) {
+    var self = this;
+    assert.func(cb, 'cb');
+
+    self.client.listImages({}, function (err, images) {
+        if (err) {
+            cb(self._errorFromClientError(err));
+            return;
+        }
+        cb(null, images);
+    });
+};
+
+
+/**
+ * This source includes the `manifest` on the returned `importInfo` because
+ * the manifest is returned with the endpoint used to find the image.
+ */
+ImgapiSource.prototype.getImportInfo = function getImportInfo(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.string(opts.arg, 'opts.arg');
+    assert.bool(opts.ensureActive, 'opts.ensureActive');
+    assert.optionalBool(opts.errOn404, 'opts.errOn404');
+    assert.func(cb, 'cb');
+
+    // By default we do *not* error on a 404 from the server.
+    var errOn404 = (opts.errOn404 !== undefined ? opts.errOn404 : false);
+
+    /*
+     * This can be called with non-IMGAPI import ids (e.g. a Docker repo:tag)
+     * as 'imgadm import ID' cycles through all sources looking for a relevant
+     * one. Just return empty to indicate N/A.
+     */
+    if (! common.UUID_RE.test(opts.arg)) {
+        return cb();
+    }
+
+    var importInfo = null;
+    self.client.getImage(opts.arg, function (err, manifest) {
+        if (err) {
+            if (err.statusCode !== 404 || errOn404) {
+                cb(err);
+                return;
+            }
+        }
+        if (manifest) {
+            if (opts.ensureActive) {
+                try {
+                    manifest = imgmanifest.upgradeManifest(manifest);
+                } catch (err) {
+                    cb(new errors.InvalidManifestError(err));
+                    return;
+                }
+            }
+            if (!opts.ensureActive || manifest.state === 'active') {
+                importInfo = {
+                    uuid: manifest.uuid,
+                    manifest: manifest
+                };
+            }
+        }
+        cb(null, importInfo);
+    });
+};
+
+ImgapiSource.prototype.titleFromImportInfo =
+function titleFromImportInfo(importInfo) {
+    return util.format('%s (%s@%s)', importInfo.manifest.uuid,
+        importInfo.manifest.name, importInfo.manifest.version);
+};
+
+ImgapiSource.prototype.getImgMeta = function getImgMeta(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.string(opts.uuid, 'opts.uuid');
+    assert.optionalObject(opts.manifest, 'opts.manifest');
+    assert.func(cb, 'cb');
+
+    var imgMeta;
+
+    if (opts.manifest) {
+        imgMeta = {
+            manifest: opts.manifest
+        };
+        if (opts.manifest.files && opts.manifest.files[0]) {
+            imgMeta.size = opts.manifest.files[0].size;
+            if (opts.manifest.files[0].sha1) {
+                imgMeta.checksum = 'sha1:' + opts.manifest.files[0].sha1;
+            }
+        }
+        cb(null, imgMeta);
+        return;
+    }
+
+    self.client.getImage(opts.uuid, function (err, manifest) {
+        if (err) {
+            cb(err);
+            return;
+        }
+        imgMeta = {
+            manifest: opts.manifest
+        };
+        if (opts.manifest.files && opts.manifest.files[0]) {
+            imgMeta.size = opts.manifest.files[0].size;
+            if (opts.manifest.files[0].sha1) {
+                imgMeta.checksum = 'sha1:' + opts.manifest.files[0].sha1;
+            }
+        }
+        cb(null, imgMeta);
+    });
+};
+
+
+ImgapiSource.prototype.getImgAncestry = function getImgAncestry(opts, cb) {
+    var self = this;
+    assert.object(opts, 'opts');
+    assert.string(opts.uuid, 'opts.uuid');
+    assert.object(opts.manifest, 'opts.manifest');
+    assert.func(cb, 'cb');
+
+    var ancestry = [
+        {
+            uuid: opts.uuid,
+            manifest: opts.manifest
+        }
+    ];
+
+    // Early out.
+    if (!opts.manifest.origin) {
+        cb(null, ancestry);
+        return;
+    }
+
+    // Keep getting origin until we hit the base (manifest with no origin).
+    getNextOrigin(opts.manifest.origin);
+
+    function getNextOrigin(uuid) {
+        var iOpts = {
+            arg: uuid,
+            ensureActive: true,
+            errOn404: true
+        };
+        self.getImportInfo(iOpts, function (err, importInfo) {
+            if (err) {
+                cb(err);
+            } else {
+                ancestry.push(importInfo);
+                if (importInfo.manifest.origin) {
+                    getNextOrigin(importInfo.manifest.origin);
+                } else {
+                    cb(null, ancestry);
+                }
+            }
+        });
+    }
+};
+
+
+
+/**
+ * Get a ReadableStream for the given image file.
+ *
+ * @param opts {Object} Source-specific details on the image. This
+ *      is meant to work if passed either:
+ *      - the `importInfo` result of `getImportInfo`, or
+ *      - an element of the ancestry array returned by `getImgAncestry`.
+ * @param cb {Function} `function (err, stream)`
+ */
+ImgapiSource.prototype.getImgFileStream = function getImgFileStream(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.string(opts.uuid, 'opts.uuid');
+    assert.func(cb, 'cb');
+
+    this.client.getImageFileStream(opts.uuid, cb);
+};
+
+
+module.exports = ImgapiSource;
diff --git a/tools/buildimage/lib/imgadm/lib/sources/index.js b/tools/buildimage/lib/imgadm/lib/sources/index.js
new file mode 100644
index 0000000..dbc677b
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/sources/index.js
@@ -0,0 +1,82 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2013, Joyent, Inc. All rights reserved.
+ */
+
+/**
+ * Abstracted API for talking to different imgadm sources: imgapi,
+ * dsapi (deprecated), docker (experimental).
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var imgapi = require('sdc-clients/lib/imgapi');
+var util = require('util');
+
+var common = require('../common');
+var errors = require('../errors');
+
+var Source = require('./source');
+var DockerSource = require('./docker');
+var DsapiSource = require('./dsapi');
+var ImgapiSource = require('./imgapi');
+
+
+// ---- exports
+
+/**
+ * Create an imgadm `Source`
+ */
+function createSource(type, opts) {
+    assert.string(type, 'type');
+    assert.optionalObject(opts, 'opts');
+
+    var source;
+    switch (type) {
+    case 'imgapi':
+        source = new ImgapiSource(opts);
+        break;
+    case 'docker':
+        source = new DockerSource(opts);
+        break;
+    case 'dsapi':
+        source = new DsapiSource(opts);
+        break;
+    default:
+        throw new Error(format('invalid source type: "%s"', type));
+    };
+
+    return source;
+}
+
+
+function isSource(s) {
+    return (s instanceof Source);
+}
+
+
+module.exports = {
+    createSource: createSource,
+    isSource: isSource
+};
diff --git a/tools/buildimage/lib/imgadm/lib/sources/source.js b/tools/buildimage/lib/imgadm/lib/sources/source.js
new file mode 100644
index 0000000..816692f
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/sources/source.js
@@ -0,0 +1,205 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2015, Joyent, Inc. All rights reserved.
+ */
+
+var assert = require('assert-plus');
+var format = require('util').format;
+
+var common = require('../common');
+var errors = require('../errors');
+
+
+
+// ---- Source interface
+
+function Source(opts) {
+    assert.object(opts, 'opts');
+    assert.string(opts.url, 'opts.url');
+    assert.optionalBool(opts.insecure, 'opts.insecure');
+    assert.object(opts.log, 'opts.log');
+    assert.string(opts.userAgent, 'opts.userAgent');
+
+    this.log = opts.log.child({
+        component: 'source',
+        source: {type: this.type, url: this.url, insecure: opts.insecure}
+    }, true);
+    this.url = opts.url;
+    this.insecure = opts.insecure;
+    this.normUrl = common.normUrlFromUrl(this.url);
+    this.userAgent = opts.userAgent;
+}
+
+/**
+ * Currently this is a convenience for *logging* a `Source` object, rather than
+ * a roundtripping serialization.
+ */
+Source.prototype.toJSON = function toJSON() {
+    return {type: this.type, url: this.url, insecure: this.insecure};
+};
+
+Source.prototype.toString = function toString() {
+    var extra = (this.insecure ? ' (insecure)' : '');
+    return format('"%s" image source "%s"%s',
+        this.type, this.url, extra);
+};
+
+
+Source.prototype._errorFromClientError = function _errorFromClientError(err) {
+    assert.object(err, 'err');
+    if (err.body && err.body.code) {
+        return new errors.APIError(this.url, err);
+    } else if (err.errno) {
+        return new errors.ClientError(this.url, err);
+    } else {
+        return new errors.InternalError({message: err.message,
+            clientUrl: this.url, cause: err});
+    }
+};
+
+
+/**
+ * Ping the source service. Return an error if the service isn't functional.
+ *
+ * @param cb {Function} `function (err)`
+ */
+Source.prototype.ping = function ping(cb) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * List all images in this repo.
+ * Note: DockerSource doesn't implement this.
+ *
+ * @param cb {Function} `function (err, images)`
+ */
+Source.prototype.listImages = function listImages(cb) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * Get the info necessary to import the image identified by `arg`, if present
+ * in this source.
+ *
+ * @param opts {Object}
+ *      - arg {String} The source-specific allowed import argument string.
+ * @param cb {Function} `function (err, importInfo)`. If a matching image is
+ *      not found in this source, then null values for both are returned.
+ *      For an `arg` that is inapplicable for the given source (e.g. an IMGAPI
+ *      UUID for a "docker" source), which will return `null` to indicate N/A.
+ *
+ *  importInfo = {
+ *      // Required
+ *      "uuid": "<uuid>",
+ *
+ *      // Sources-specific fields, as required by `getImgAncestry`,
+ *      // `getImgMeta`.
+ *      "manifest": {...},    // included by 'imgapi', 'dsapi'
+ *      ...
+ *  }
+ */
+Source.prototype.getImportInfo = function getImportInfo(opts, cb) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * Return a short title string for the given image. Synchronous.
+ */
+Source.prototype.titleFromImportInfo =
+function titleFromImportInfo(importInfo) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * Gather the ancestry of this image, i.e. the ordered array of image ids
+ * from top (this image) to bottom (the base non-incremental image).
+ *
+ * @param opts {Object} Source-specific details on the image to import. This
+ *      is meant to work if passed the `importInfo` result of `getImportInfo`.
+ * @param cb {Function} `function (err, ancestry)`
+ *      where `ancestry` is an array of objects where each object has:
+ *      - a image `uuid` field
+ *      - whatever fields are required by `getImgMeta`
+ *
+ *  ancestry = [
+ *      {
+ *          "uuid": "<uuid>",
+ *          // other Source-specific fields required by `getImgMeta`
+ *          ...
+ *      },
+ *      ...
+ *  ]
+ */
+Source.prototype.getImgAncestry = function getImgAncestry(opts, cb) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * Get metadata (including the manifest, and any other useful information
+ * for download and install) for the given image.
+ *
+ * @param opts {Object} Source-specific details on the image to import. This
+ *      is meant to work if passed either:
+ *      - the `importInfo` result of `getImportInfo`, or
+ *      - an element of the ancestry array returned by `getImgAncestry`.
+ * @param cb {Function} `function (err, imgMeta)` where `imgMeta` includes the
+ *      following fields, plus any optional source-specific fields:
+ *
+ *  imgMeta = {
+ *      // Required:
+ *      "manifest": {...},
+ *
+ *      // Optional:
+ *      "size": <size-of-the-file-in-bytes>,
+ *      "checksum": "<file checksum in the format TYPE:HEXDIGEST,
+ *          e.g. 'sha256:23498af90e8g9...'>",
+ *
+ *      // Optional extra source-specific fields:
+ *      ...
+ *  }
+ */
+Source.prototype.getImgMeta = function getImgMeta(opts, cb) {
+    throw new Error('not implemented');
+};
+
+
+/**
+ * Get a ReadableStream for the given image file.
+ *
+ * @param opts {Object} Source-specific details on the image. This
+ *      is meant to work if passed either:
+ *      - the `importInfo` result of `getImportInfo`, or
+ *      - an element of the ancestry array returned by `getImgAncestry`.
+ * @param cb {Function} `function (err, stream)`
+ */
+Source.prototype.getImgFileStream = function getImgFileStream(opts, cb) {
+    throw new Error('not implemented');
+};
+
+
+module.exports = Source;
diff --git a/tools/buildimage/lib/imgadm/lib/upgrade.js b/tools/buildimage/lib/imgadm/lib/upgrade.js
new file mode 100644
index 0000000..cdbe546
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/upgrade.js
@@ -0,0 +1,342 @@
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2013, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * Here is how imgadm upgrade is intented to work:
+ *
+ * - The imgadm config (/var/imgadm/imgadm.conf) has a `upgradedToVer` string.
+ * - On `imgadm.init()` we upgrade if necessary, as early as possible via
+ *   `upgrade.upgradeIfNecessary(...)`. This basically checks if there is
+ *   an upgrader function for a version > config.upgradedToVer.
+ * - There is an ordered array of upgraders something like:
+ *          var upgraders = [
+ *              ['2.0.0', upgradeTo200],
+ *              ['2.1.0', upgradeTo210],
+ *              ...
+ *          ];
+ *   Not every version will have an upgrader. Only if a DB upgrade is
+ *   necessary for that version.
+ *
+ * See each `upgradeTo*` function's comment for the how and why of each
+ * DB upgrade.
+ */
+
+var p = console.log;
+
+var assert = require('assert-plus');
+var async = require('async');
+var format = require('util').format;
+var fs = require('fs');
+var path = require('path');
+var vasync = require('vasync');
+
+var imgmanifest = require('imgmanifest');
+var errors = require('./errors');
+var common = require('./common'),
+    objCopy = common.objCopy,
+    assertUuid = common.assertUuid;
+
+
+
+// ---- internal support stuff
+
+function verInfoFromVer(ver) {
+    return ver.split(/\./g).map(
+        function (v) { return Number(v); });
+}
+
+
+
+// ---- upgraders
+
+/**
+ * Upgrade imgadm to v3.0.0
+ *
+ * imgadm 2 -> imgadm 3 simply requires a `type` value on each source object
+ * (the `sources` array in "/var/imgadm/imgadm.conf"). It must be one
+ * of `common.VALID_SOURCE_TYPES`.
+ *
+ * We use the same logic that was being used on the fly in imgadm v2 and lower:
+ * - If the url ends with `/datasets/?`, then `type="dsapi"`.
+ * - Else, default to "imgapi".
+ */
+function upgradeTo300(tool, callback) {
+    var log = tool.log.child({upgrade: true, upgradeTo300: true}, true);
+
+    vasync.pipeline({funcs: [
+        function upgradeSources(_, next) {
+            if (!tool.config.sources) {
+                next();
+                return;
+            }
+
+            log.info({sources: tool.config.sources}, 'config.sources before');
+            var changed = false;
+            tool.config.sources.forEach(function (s) {
+                if (!s.type) {
+                    // Per imgadm v1, the old source URL includes the
+                    // "/datasets/" subpath. That's not a completely reliable
+                    // marker, but we'll use that.
+                    var isDsapiUrl = /\/datasets\/?$/;
+                    if (isDsapiUrl.test(s.url)) {
+                        s.type = 'dsapi';
+                    } else {
+                        s.type = 'imgapi';
+                    }
+                    changed = true;
+                }
+            });
+
+            if (changed) {
+                log.info({sources: tool.config.sources},
+                    'config.sources updated');
+                tool.saveConfig(next);
+            } else {
+                next();
+            }
+        },
+
+        function updateConfigVer(_, next) {
+            tool.config.upgradedToVer = '3.0.0';
+            tool.saveConfig(next);
+        }
+    ]}, callback);
+}
+
+
+
+/**
+ * Upgrade DB to v2.0.0
+ *
+ * imgadm <unversioned> -> imgadm 2 was a big re-write. The old datasets
+ * API (DSAPI) was replaced by the Images API (IMGAPI). The dataset/image
+ * manifest changed quite a bit: URNs were deprecated, etc. The internal data
+ * was moved from '/var/db/imgadm' to '/var/imgadm'.
+ *
+ * @param tool {imgadm.IMGADM}
+ * @param callback {Function}
+ */
+function upgradeTo200(tool, callback) {
+
+    function upgradeManifest(ii, next) {
+        assert.object(ii.manifest, 'ii.manifest');
+        assert.string(ii.zpool, 'ii.zpool');
+
+        if (ii.manifest.name) {
+            // Already have manifest info -- possibly from earlier aborted
+            // upgrade, possibly from another source.
+            next();
+            return;
+        }
+        var uuid = ii.manifest.uuid;
+        var oldPath = format('/var/db/imgadm/%s.json', uuid);
+        if (! fs.existsSync(oldPath)) {
+            next();
+            return;
+        }
+        try {
+            var oldManifest = JSON.parse(fs.readFileSync(oldPath, 'utf8'));
+        } catch (ex) {
+            console.warn('imgadm: warning: could not load image %s info '
+                + 'from %s for upgrade: %s', uuid, oldPath, ex);
+            next();
+            return;
+        }
+        assert.string(oldManifest.name, 'oldManifest.name');
+        try {
+            var manifest = imgmanifest.upgradeManifest(oldManifest);
+        } catch (upErr) {
+            /* Pass through, because we expect validation to handle it. */
+        }
+        var imageInfo = {
+            manifest: manifest,
+            zpool: ii.zpool
+        };
+        // The old imgadm would cache the source URL here.
+        if (oldManifest._url) {
+            imageInfo.source = {url: oldManifest._url};
+        }
+        tool.dbAddImage(imageInfo, function (err) {
+            if (err) {
+                next(err);
+                return;
+            }
+            // Use 'warn' to put on stderr to hopefully not disrupt the
+            // command actually being run.
+            console.warn('Upgraded image %s data', uuid);
+            next();
+        });
+    }
+
+    /**
+     * For each installed image, get the manifest info (if necessary) from
+     * the old imgadm database: "/var/db/imgadm/$uuid.json".
+     */
+    function upgradeManifests(next) {
+        tool.listImages(function (listErr, imagesInfo) {
+            if (listErr) {
+                next();
+                return;
+            }
+            async.forEachSeries(imagesInfo, upgradeManifest, next);
+        });
+    }
+
+    /**
+     * Import source URLs from the old imgadm database if appropriate.
+     */
+    function upgradeSources(next) {
+        // If we already have configured sources: done. This means that
+        // someone has explicitly configured imgadm v2. We don't want to
+        // undo that.
+        if (tool.config.sources) {
+            next();
+            return;
+        }
+
+        // If no file from which to import: done.
+        var oldPath = '/var/db/imgadm/sources.list';
+        if (!fs.existsSync(oldPath)) {
+            next();
+            return;
+        }
+
+        // Load the old sources.
+        try {
+            var sourcesList = fs.readFileSync(oldPath, 'utf8');
+        } catch (err) {
+            next(err);
+            return;
+        }
+        var oldSources = sourcesList.trim().split(/\n/g).filter(function (ln) {
+            ln = ln.split('#')[0].trim();
+            if (ln.length === 0)
+                return false;
+            return true;
+        });
+
+        // If the old sources only include the single default, then skip it.
+        // The result is that imgadm v2 just uses the new default.
+        var OLD_DEFAULT_SOURCE = 'https://datasets.joyent.com/datasets/';
+        if (oldSources.length === 1 && oldSources[0] === OLD_DEFAULT_SOURCE) {
+            next();
+            return;
+        }
+
+        // Add each old source.
+        // Need to set `tool.sources` for the `configAddSource` code path.
+        // Doesn't matter anyway, as the subsequent `tool.init()` will reset
+        // it. We are just setting the config file here.
+        tool.sources = [];
+        async.forEachSeries(
+            oldSources,
+            function one(oldSource, nextSource) {
+                var source = {url: oldSource, type: 'dsapi'};
+                if (oldSource === OLD_DEFAULT_SOURCE) {
+                    source = common.DEFAULT_SOURCE;
+                }
+                tool.configAddSource(source, true, function (addErr, changed) {
+                    if (addErr) {
+                        nextSource(addErr);
+                        return;
+                    }
+                    if (changed) {
+                        console.warn('Upgrade: imported image source "%s"',
+                            oldSource);
+                    }
+                    nextSource();
+                });
+            },
+            next
+        );
+    }
+
+    function updateConfigVer(next) {
+        tool.config.upgradedToVer = '2.0.0';
+        tool.saveConfig(next);
+    }
+
+    async.series([upgradeManifests, upgradeSources, updateConfigVer],
+        callback);
+}
+
+
+var upgraders = [
+    ['2.0.0', upgradeTo200],
+    ['3.0.0', upgradeTo300]
+];
+var highestUpVer = upgraders[upgraders.length - 1][0];
+var highestUpVerInfo = verInfoFromVer(highestUpVer);
+
+
+
+
+// ---- exports
+
+function upgradeIfNecessary(tool, callback) {
+    var log = tool.log;
+    var currVer = tool.config.upgradedToVer || '1.0.0';
+    var currVerInfo = verInfoFromVer(currVer);
+    if (currVerInfo > highestUpVerInfo || currVer === highestUpVer) {
+        log.trace({currVer: currVer, highestUpVer: highestUpVer},
+            'upgrade not necessary');
+        callback();
+        return;
+    }
+    log.debug({currVer: currVer, highestUpVer: highestUpVer},
+        'upgrade necessary');
+
+    // Find start index in `upgraders`.
+    var idx;
+    for (var i = 0; i < upgraders.length; i++) {
+        var ver = upgraders[i][0];
+        var verInfo = verInfoFromVer(ver);
+        if (verInfo > currVerInfo) {
+            idx = i;
+            break;
+        }
+    }
+    if (idx === undefined) {
+        callback(new errors.UpgradeError(format(
+            'could not determine appropriate upgrader: currVer=%s '
+            + 'highestUpVer=%s', currVer, highestUpVer)));
+        return;
+    }
+
+    var todos = upgraders.slice(idx);
+    async.forEachSeries(
+        todos,
+        function upgradeOne(todo, next) {
+            var oneVer = todo[0];
+            var upgrader = todo[1];
+            log.debug('upgrade to %s', oneVer);
+            upgrader(tool, next);
+        },
+        callback
+    );
+}
+
+module.exports = {
+    upgradeIfNecessary: upgradeIfNecessary
+};
diff --git a/tools/buildimage/lib/imgadm/lib/zfs.js b/tools/buildimage/lib/imgadm/lib/zfs.js
new file mode 100644
index 0000000..30984e0
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/lib/zfs.js
@@ -0,0 +1,549 @@
+/*
+ * Copyright 2013 Joyent, Inc.  All rights reserved.
+ */
+
+var cp = require('child_process'),
+    fs = require('fs');
+
+var execFile = cp.execFile,
+    spawn    = cp.spawn;
+
+/*
+ * ZFS utilities paths
+ */
+exports.paths = {
+    'zpool': '/sbin/zpool',
+    'zfs': '/sbin/zfs'
+};
+
+var zpool = exports.zpool = function () { };
+
+// if zfs commands take longer than timeoutDuration it's an error
+var timeoutDuration = exports.timeoutDuration = 10 * 60 * 1000;
+
+function zfsErrorStr(error, stderr) {
+	if (!error)
+		return (null);
+
+	if (error.killed)
+		return ('Process killed due to timeout.');
+
+	return (error.message || (stderr ? stderr.toString() : ''));
+}
+
+function zfsError(error, stderr) {
+	return (new Error(zfsErrorStr(error, stderr)));
+}
+
+zpool.listFields_ = [ 'name', 'size', 'allocated', 'free', 'cap',
+    'health', 'altroot' ];
+
+zpool.listDisks = function () {
+	if (arguments.length !== 1)
+		throw Error('Invalid arguments');
+	var callback = arguments[0];
+
+	execFile('/usr/bin/diskinfo', [ '-Hp' ], { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(stderr.toString()));
+
+		var disks = [];
+		var rows = parseTabSeperatedTable(stdout);
+
+		for (var ii = 0; ii < rows.length; ii++) {
+			disks.push({
+			    type: rows[ii][0],
+			    name: rows[ii][1],
+			    vid: rows[ii][2],
+			    pid: rows[ii][3],
+			    size: rows[ii][4],
+			    removable: (rows[ii][5] === 'yes'),
+			    solid_state: (rows[ii][6] === 'yes')
+			});
+		}
+
+		return (callback(null, disks));
+	});
+};
+
+zpool.list = function () {
+	var pool, callback;
+	switch (arguments.length) {
+		case 1:
+			callback = arguments[0];
+			break;
+		case 2:
+			pool     = arguments[0];
+			callback = arguments[1];
+			break;
+		default:
+			throw Error('Invalid arguments');
+	}
+	var args = ['list', '-H', '-o', zpool.listFields_.join(',')];
+	if (pool)
+		args.push(pool);
+
+	execFile(exports.paths.zpool, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		var rows = parseTabSeperatedTable(stdout);
+		return (callback(null, zpool.listFields_, rows));
+	});
+};
+
+zpool.status = function (pool, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zpool, [ 'status', pool ],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		stdout = stdout.trim();
+		if (error || stdout == 'no pools available\n') {
+			callback(null, 'UNKNOWN');
+			return;
+		}
+
+		var lines = stdout.split('\n');
+		for (var i = 0; i < lines.length; i++) {
+			if (lines[i].trim().substr(0, 5) === 'state') {
+				return (callback(null,
+				    lines[i].trim().substr(7)));
+			}
+		}
+		callback(null, 'UNKNOWN');
+	});
+};
+
+/*
+ * zpool.create()
+ *
+ * This allows fine-grained control and exposes all features of the
+ * zpool create command, including log devices, cache devices, and hot spares.
+ * The input is an object of the form produced by the disklayout library.
+ */
+zpool.create = function (pool, config, force, callback) {
+	var args;
+
+	if (arguments.length === 3) {
+		callback = force;
+		force = false;
+	} else if (arguments.length !== 4) {
+		throw Error('Invalid arguments, 3 or 4 arguments required');
+	}
+
+	if (force === true) {
+		args = [ 'create', '-f', pool ];
+	} else {
+		args = [ 'create', pool ];
+	}
+
+	config.vdevs.forEach(function (vdev) {
+		if (vdev.type)
+			args.push(vdev.type);
+		if (vdev.devices) {
+			vdev.devices.forEach(function (dev) {
+				args.push(dev.name);
+			});
+		} else {
+			args.push(vdev.name);
+		}
+	});
+
+	if (config.spares) {
+		args.push('spare');
+		config.spares.forEach(function (dev) {
+			args.push(dev.name);
+		});
+	}
+
+	if (config.logs) {
+		args.push('log');
+		config.logs.forEach(function (dev) {
+			args.push(dev.name);
+		});
+	}
+
+	if (config.cache) {
+		args.push('cache');
+		config.cache.forEach(function (dev) {
+			args.push(dev.name);
+		});
+	}
+
+	execFile(exports.paths.zpool, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(stderr.toString()));
+		return (callback(null));
+	});
+};
+
+zpool.destroy = function (pool, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zpool, [ 'destroy', pool ],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(stderr.toString()));
+		return (callback(null));
+	});
+};
+
+zpool.upgrade = function (pool) {
+	var version = -1,
+	    callback;
+	if (arguments.length === 2) {
+		callback = arguments[1];
+	} else if (arguments.length === 3) {
+		version = arguments[1];
+		callback = arguments[2];
+	} else {
+		throw Error('Invalid arguments');
+	}
+
+	var args = [ 'upgrade' ];
+	if (version !== -1)
+		args.push(' -V ' + version);
+	args.push(pool);
+
+	execFile(exports.paths.zpool, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(stderr.toString()));
+		return (callback(null));
+	});
+};
+
+function parseTabSeperatedTable(data) {
+	var i, numLines, lines = data.trim().split('\n');
+	var rows = [];
+	for (i = 0, numLines = lines.length; i < numLines; i++) {
+		if (lines[i]) {
+			rows.push(lines[i].split('\t'));
+		}
+	}
+	return (rows);
+}
+
+/*
+ * Parse the output of `zfs get ...`, invoked by zfs.get below.  The output has
+ * the form:
+ *
+ *     <dataset name>    <property name>    <property value>
+ *
+ * and those fields are tab-separated.
+ */
+function parsePropertyList(data) {
+	var lines = data.trim().split('\n');
+	var properties = {};
+	lines.forEach(function (line) {
+		var fields = line.split('\t');
+		if (!properties[fields[0]])
+			properties[fields[0]] = {};
+		properties[fields[0]][fields[1]] = fields[2];
+	});
+
+	return (properties);
+}
+
+var zfs;
+exports.zfs = zfs = function () {};
+
+zfs.create = function (name, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, [ 'create', name ],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.set = function (name, properties, callback) {
+	if (arguments.length != 3)
+		throw Error('Invalid arguments');
+
+	var keys = Object.keys(properties);
+
+	// loop over and set all the properties using chained callbacks
+	(function () {
+		var next = arguments.callee;
+		if (!keys.length) {
+			callback();
+			return;
+		}
+		var key = keys.pop();
+
+		execFile(exports.paths.zfs,
+		    ['set', key + '=' + properties[key], name ],
+		    { timeout: timeoutDuration },
+		    function (error, stdout, stderr) {
+			if (error)
+				return (callback(zfsError(error, stderr)));
+			return (next()); // loop by calling enclosing function
+		});
+	})();
+};
+
+zfs.get = function (name, propNames, parseable, callback) {
+	if (arguments.length != 4)
+		throw Error('Invalid arguments');
+
+	var opts = '-H';
+	if (parseable)
+		opts += 'p';
+
+	var argv = [ 'get', opts, '-o', 'name,property,value',
+	    propNames.join(',')];
+	if (name)
+		argv.push(name);
+
+	execFile(exports.paths.zfs, argv, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+
+		return (callback(null, parsePropertyList(stdout)));
+	});
+};
+
+zfs.snapshot = function (name, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, ['snapshot', name],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.clone = function (snapshot, name, callback) {
+	if (arguments.length != 3)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, ['clone', snapshot, name],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.destroy = function (name, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, ['destroy', name],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.destroyAll = function (name, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, ['destroy', '-r',  name],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+/*
+ * zfs.list fields
+ */
+
+zfs.listFields_ = [ 'name', 'used', 'avail', 'refer', 'type', 'mountpoint' ];
+
+/*
+ * List datasets.
+ *
+ * @param {String} [name]
+ *   Dataset to list. If name is not given, `list` defaults to returning all
+ *   datasets.
+ *
+ * @param {Object} [options]
+ *   Options object:
+ *     - `type`: restrict dataset type (dataset, volume, snapshot or all)
+ *
+ * @param {Function} [callback]
+ *   Call `callback` when done. Function will be called with an error
+ *   parameter, a field names list and a array of arrays comprising the list
+ *   information.
+ *
+ */
+
+zfs.list = function () {
+	var dataset, callback,
+	    options = {};
+	switch (arguments.length) {
+		case 1:
+			callback = arguments[0];
+			break;
+		case 2:
+			dataset  = arguments[0];
+			callback = arguments[1];
+			break;
+		case 3:
+			dataset  = arguments[0];
+			options  = arguments[1];
+			callback = arguments[2];
+			break;
+		default:
+			throw Error('Invalid arguments');
+	}
+
+	options.type      = options.type || 'filesystem';
+	options.recursive = options.recursive || false;
+
+	var args = [ 'list', '-H', '-o', zfs.listFields_.join(','),
+	    '-t', options.type ];
+	if (options.recursive) args.push('-r');
+	if (dataset) args.push(dataset);
+
+	execFile(exports.paths.zfs, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		var rows = parseTabSeperatedTable(stdout);
+		return (callback(null, zfs.listFields_, rows));
+	});
+};
+
+zfs.send = function (snapshot, filename, callback) {
+	fs.open(filename, 'w', 400, function (error, fd) {
+		if (error)
+			return (callback(error));
+		// set the child to write to STDOUT with `fd`
+		var child = spawn(exports.paths.zfs,
+		    [ 'send', snapshot ], undefined, [ -1, fd ]);
+		child.addListener('exit', function (code) {
+			if (code) {
+				callback(new Error('Return code was ' + code));
+				return;
+			}
+			fs.close(fd, function () {
+				callback();
+			});
+		});
+
+		return (null);
+	});
+};
+
+zfs.receive = function (name, filename, callback) {
+	fs.open(filename, 'r', 400, function (error, fd) {
+		if (error)
+			return (callback(error));
+		// set the child to read from STDIN with `fd`
+		var child = spawn(exports.paths.zfs,
+		    [ 'receive', name ], undefined, [ fd ]);
+		child.addListener('exit', function (code) {
+			if (code) {
+				return (callback(new Error(
+				    'Return code was ' + code)));
+			}
+			fs.close(fd, function () {
+				return (callback());
+			});
+
+			return (null);
+		});
+
+		return (null);
+	});
+};
+
+zfs.list_snapshots = function () {
+	var snapshot, callback;
+	switch (arguments.length) {
+		case 1:
+			callback = arguments[0];
+			break;
+		case 2:
+			snapshot = arguments[0];
+			callback = arguments[1];
+			break;
+		default:
+			throw Error('Invalid arguments');
+	}
+	var args = ['list', '-H', '-t', 'snapshot'];
+	if (snapshot) args.push(snapshot);
+
+	execFile(exports.paths.zfs, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		var rows = parseTabSeperatedTable(stdout);
+		return (callback(error, zfs.listFields_, rows));
+	});
+};
+
+zfs.rollback = function (name, callback) {
+	if (arguments.length != 2)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, ['rollback', '-r', name],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.rename = function (name, newname, callback) {
+	if (arguments.length != 3)
+		throw Error('Invalid arguments');
+
+	execFile(exports.paths.zfs, [ 'rename', name, newname ],
+	    { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(zfsError(error, stderr)));
+		return (callback());
+	});
+};
+
+zfs.upgrade = function (name, version, callback) {
+	if (arguments.length === 2) {
+		callback = arguments[1];
+	} else if (arguments.length === 3) {
+		version = arguments[1];
+		callback = arguments[2];
+	} else {
+		throw Error('Invalid arguments');
+	}
+
+	name = arguments[0];
+
+	var args = [ 'upgrade' ];
+	if (version !== -1)
+		args.push(' -V ' + version);
+	args.push(name);
+
+	execFile(exports.paths.zfs, args, { timeout: timeoutDuration },
+	    function (error, stdout, stderr) {
+		if (error)
+			return (callback(new Error(stderr.toString())));
+		return (callback(null));
+	});
+};
diff --git a/tools/buildimage/lib/imgadm/package-lock.json b/tools/buildimage/lib/imgadm/package-lock.json
new file mode 100644
index 0000000..da8fd15
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/package-lock.json
@@ -0,0 +1,3607 @@
+{
+  "name": "imgadm",
+  "version": "3.9.0",
+  "lockfileVersion": 1,
+  "requires": true,
+  "dependencies": {
+    "@babel/code-frame": {
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.0.0.tgz",
+      "integrity": "sha512-OfC2uemaknXr87bdLUkWog7nYuliM9Ij5HUcajsVcMCpQrcLmtxRbVFTIqmcSkSeYRBFBRxs2FiUqFJDLdiebA==",
+      "dev": true,
+      "requires": {
+        "@babel/highlight": "^7.0.0"
+      }
+    },
+    "@babel/generator": {
+      "version": "7.1.6",
+      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.1.6.tgz",
+      "integrity": "sha512-brwPBtVvdYdGxtenbQgfCdDPmtkmUBZPjUoK5SXJEBuHaA5BCubh9ly65fzXz7R6o5rA76Rs22ES8Z+HCc0YIQ==",
+      "dev": true,
+      "requires": {
+        "@babel/types": "^7.1.6",
+        "jsesc": "^2.5.1",
+        "lodash": "^4.17.10",
+        "source-map": "^0.5.0",
+        "trim-right": "^1.0.1"
+      }
+    },
+    "@babel/helper-function-name": {
+      "version": "7.1.0",
+      "resolved": "https://registry.npmjs.org/@babel/helper-function-name/-/helper-function-name-7.1.0.tgz",
+      "integrity": "sha512-A95XEoCpb3TO+KZzJ4S/5uW5fNe26DjBGqf1o9ucyLyCmi1dXq/B3c8iaWTfBk3VvetUxl16e8tIrd5teOCfGw==",
+      "dev": true,
+      "requires": {
+        "@babel/helper-get-function-arity": "^7.0.0",
+        "@babel/template": "^7.1.0",
+        "@babel/types": "^7.0.0"
+      }
+    },
+    "@babel/helper-get-function-arity": {
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/@babel/helper-get-function-arity/-/helper-get-function-arity-7.0.0.tgz",
+      "integrity": "sha512-r2DbJeg4svYvt3HOS74U4eWKsUAMRH01Z1ds1zx8KNTPtpTL5JAsdFv8BNyOpVqdFhHkkRDIg5B4AsxmkjAlmQ==",
+      "dev": true,
+      "requires": {
+        "@babel/types": "^7.0.0"
+      }
+    },
+    "@babel/helper-split-export-declaration": {
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/@babel/helper-split-export-declaration/-/helper-split-export-declaration-7.0.0.tgz",
+      "integrity": "sha512-MXkOJqva62dfC0w85mEf/LucPPS/1+04nmmRMPEBUB++hiiThQ2zPtX/mEWQ3mtzCEjIJvPY8nuwxXtQeQwUag==",
+      "dev": true,
+      "requires": {
+        "@babel/types": "^7.0.0"
+      }
+    },
+    "@babel/highlight": {
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/@babel/highlight/-/highlight-7.0.0.tgz",
+      "integrity": "sha512-UFMC4ZeFC48Tpvj7C8UgLvtkaUuovQX+5xNWrsIoMG8o2z+XFKjKaN9iVmS84dPwVN00W4wPmqvYoZF3EGAsfw==",
+      "dev": true,
+      "requires": {
+        "chalk": "^2.0.0",
+        "esutils": "^2.0.2",
+        "js-tokens": "^4.0.0"
+      }
+    },
+    "@babel/parser": {
+      "version": "7.1.6",
+      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.1.6.tgz",
+      "integrity": "sha512-dWP6LJm9nKT6ALaa+bnL247GHHMWir3vSlZ2+IHgHgktZQx0L3Uvq2uAWcuzIe+fujRsYWBW2q622C5UvGK9iQ==",
+      "dev": true
+    },
+    "@babel/template": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.1.2.tgz",
+      "integrity": "sha512-SY1MmplssORfFiLDcOETrW7fCLl+PavlwMh92rrGcikQaRq4iWPVH0MpwPpY3etVMx6RnDjXtr6VZYr/IbP/Ag==",
+      "dev": true,
+      "requires": {
+        "@babel/code-frame": "^7.0.0",
+        "@babel/parser": "^7.1.2",
+        "@babel/types": "^7.1.2"
+      }
+    },
+    "@babel/traverse": {
+      "version": "7.1.6",
+      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.1.6.tgz",
+      "integrity": "sha512-CXedit6GpISz3sC2k2FsGCUpOhUqKdyL0lqNrImQojagnUMXf8hex4AxYFRuMkNGcvJX5QAFGzB5WJQmSv8SiQ==",
+      "dev": true,
+      "requires": {
+        "@babel/code-frame": "^7.0.0",
+        "@babel/generator": "^7.1.6",
+        "@babel/helper-function-name": "^7.1.0",
+        "@babel/helper-split-export-declaration": "^7.0.0",
+        "@babel/parser": "^7.1.6",
+        "@babel/types": "^7.1.6",
+        "debug": "^4.1.0",
+        "globals": "^11.1.0",
+        "lodash": "^4.17.10"
+      },
+      "dependencies": {
+        "debug": {
+          "version": "4.1.0",
+          "resolved": "https://registry.npmjs.org/debug/-/debug-4.1.0.tgz",
+          "integrity": "sha512-heNPJUJIqC+xB6ayLAMHaIrmN9HKa7aQO8MGqKpvCA+uJYVcvR6l5kgdrhRuwPFHU7P5/A1w0BjByPHwpfTDKg==",
+          "dev": true,
+          "requires": {
+            "ms": "^2.1.1"
+          }
+        },
+        "ms": {
+          "version": "2.1.1",
+          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
+          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
+          "dev": true
+        }
+      }
+    },
+    "@babel/types": {
+      "version": "7.1.6",
+      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.1.6.tgz",
+      "integrity": "sha512-DMiUzlY9DSjVsOylJssxLHSgj6tWM9PRFJOGW/RaOglVOK9nzTxoOMfTfRQXGUCUQ/HmlG2efwC+XqUEJ5ay4w==",
+      "dev": true,
+      "requires": {
+        "esutils": "^2.0.2",
+        "lodash": "^4.17.10",
+        "to-fast-properties": "^2.0.0"
+      }
+    },
+    "ajv": {
+      "version": "6.5.5",
+      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.5.5.tgz",
+      "integrity": "sha512-7q7gtRQDJSyuEHjuVgHoUa2VuemFiCMrfQc9Tc08XTAc4Zj/5U1buQJ0HU6i7fKjXU09SVgSmxa4sLvuvS8Iyg==",
+      "dev": true,
+      "requires": {
+        "fast-deep-equal": "^2.0.1",
+        "fast-json-stable-stringify": "^2.0.0",
+        "json-schema-traverse": "^0.4.1",
+        "uri-js": "^4.2.2"
+      }
+    },
+    "ansi-regex": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-2.1.1.tgz",
+      "integrity": "sha1-w7M6te42DYbg5ijwRorn7yfWVN8=",
+      "dev": true
+    },
+    "ansi-styles": {
+      "version": "3.2.1",
+      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-3.2.1.tgz",
+      "integrity": "sha512-VT0ZI6kZRdTh8YyJw3SMbYm/u+NqfsAxEpWO0Pf9sq8/e94WxxOpPKx9FR1FlyCtOVDNOQ+8ntlqFxiRc+r5qA==",
+      "dev": true,
+      "requires": {
+        "color-convert": "^1.9.0"
+      }
+    },
+    "argparse": {
+      "version": "1.0.10",
+      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
+      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
+      "dev": true,
+      "requires": {
+        "sprintf-js": "~1.0.2"
+      }
+    },
+    "asn1": {
+      "version": "0.2.4",
+      "resolved": "https://registry.npmjs.org/asn1/-/asn1-0.2.4.tgz",
+      "integrity": "sha512-jxwzQpLQjSmWXgwaCZE9Nz+glAG01yF1QnWgbhGwHI5A6FRIEY6IVqtHhIepHqI7/kyEyQEagBC5mBEFlIYvdg==",
+      "requires": {
+        "safer-buffer": "~2.1.0"
+      }
+    },
+    "asn1.js": {
+      "version": "2.2.1",
+      "resolved": "https://registry.npmjs.org/asn1.js/-/asn1.js-2.2.1.tgz",
+      "integrity": "sha1-yLpN1o6EQxKIEmIwyyBFvfqfv+E=",
+      "requires": {
+        "bn.js": "^2.0.0",
+        "inherits": "^2.0.1",
+        "minimalistic-assert": "^1.0.0"
+      }
+    },
+    "asn1.js-rfc3280": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/asn1.js-rfc3280/-/asn1.js-rfc3280-2.1.1.tgz",
+      "integrity": "sha1-LLxzng1C9nJc4duSggEqmnDp23A="
+    },
+    "assert-plus": {
+      "version": "0.1.5",
+      "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-0.1.5.tgz",
+      "integrity": "sha1-7nQAlBMALYTOxyGcasgRgS5yMWA="
+    },
+    "async": {
+      "version": "0.9.0",
+      "resolved": "http://registry.npmjs.org/async/-/async-0.9.0.tgz",
+      "integrity": "sha1-rDYTsdqb7RtHUQu0ZRuJMeRxRsc="
+    },
+    "asynckit": {
+      "version": "0.4.0",
+      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
+      "integrity": "sha1-x57Zf380y48robyXkLzDZkdLS3k=",
+      "dev": true
+    },
+    "aws-sign2": {
+      "version": "0.7.0",
+      "resolved": "https://registry.npmjs.org/aws-sign2/-/aws-sign2-0.7.0.tgz",
+      "integrity": "sha1-tG6JCTSpWR8tL2+G1+ap8bP+dqg=",
+      "dev": true
+    },
+    "aws4": {
+      "version": "1.8.0",
+      "resolved": "https://registry.npmjs.org/aws4/-/aws4-1.8.0.tgz",
+      "integrity": "sha512-ReZxvNHIOv88FlT7rxcXIIC0fPt4KZqZbOlivyWtXLt8ESx84zd3kMC6iK5jVeS2qt+g7ftS7ye4fi06X5rtRQ==",
+      "dev": true
+    },
+    "backoff": {
+      "version": "2.4.0",
+      "resolved": "https://registry.npmjs.org/backoff/-/backoff-2.4.0.tgz",
+      "integrity": "sha1-xaKIjnhKYeGNXLoxDvD1IfsQfU8=",
+      "requires": {
+        "precond": "0.2"
+      }
+    },
+    "balanced-match": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.0.tgz",
+      "integrity": "sha1-ibTRmasr7kneFk6gK4nORi1xt2c="
+    },
+    "base64url": {
+      "version": "1.0.6",
+      "resolved": "https://registry.npmjs.org/base64url/-/base64url-1.0.6.tgz",
+      "integrity": "sha1-1k03XWinxkDZEuI1jRcNylu1RoE=",
+      "requires": {
+        "concat-stream": "~1.4.7",
+        "meow": "~2.0.0"
+      }
+    },
+    "bcrypt-pbkdf": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/bcrypt-pbkdf/-/bcrypt-pbkdf-1.0.2.tgz",
+      "integrity": "sha1-pDAdOJtqQ/m2f/PKEaP2Y342Dp4=",
+      "requires": {
+        "tweetnacl": "^0.14.3"
+      }
+    },
+    "bind-obj-methods": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/bind-obj-methods/-/bind-obj-methods-2.0.0.tgz",
+      "integrity": "sha512-3/qRXczDi2Cdbz6jE+W3IflJOutRVica8frpBn14de1mBOkzDo+6tY33kNhvkw54Kn3PzRRD2VnGbGPcTAk4sw==",
+      "dev": true
+    },
+    "bluebird": {
+      "version": "3.5.3",
+      "resolved": "https://registry.npmjs.org/bluebird/-/bluebird-3.5.3.tgz",
+      "integrity": "sha512-/qKPUQlaW1OyR51WeCPBvRnAlnZFUJkCSG5HzGnuIqhgyJtF+T94lFnn33eiazjRm2LAHVy2guNnaq48X9SJuw==",
+      "dev": true
+    },
+    "bn.js": {
+      "version": "2.2.0",
+      "resolved": "https://registry.npmjs.org/bn.js/-/bn.js-2.2.0.tgz",
+      "integrity": "sha1-EhYrwq5x/EClYmwzQ486h1zTdiU="
+    },
+    "brace-expansion": {
+      "version": "1.1.11",
+      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
+      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
+      "requires": {
+        "balanced-match": "^1.0.0",
+        "concat-map": "0.0.1"
+      }
+    },
+    "brorand": {
+      "version": "1.1.0",
+      "resolved": "https://registry.npmjs.org/brorand/-/brorand-1.1.0.tgz",
+      "integrity": "sha1-EsJe/kCkXjwyPrhnWgoM5XsiNx8="
+    },
+    "browser-process-hrtime": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/browser-process-hrtime/-/browser-process-hrtime-1.0.0.tgz",
+      "integrity": "sha512-9o5UecI3GhkpM6DrXr69PblIuWxPKk9Y0jHBRhdocZ2y7YECBFCsHm79Pr3OyR2AvjhDkabFJaDJMYRazHgsow==",
+      "dev": true
+    },
+    "buffer-equal-constant-time": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/buffer-equal-constant-time/-/buffer-equal-constant-time-1.0.1.tgz",
+      "integrity": "sha1-+OcRMvf/5uAaXJaXpMbz5I1cyBk="
+    },
+    "buffer-from": {
+      "version": "1.1.1",
+      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.1.tgz",
+      "integrity": "sha512-MQcXEUbCKtEo7bhqEs6560Hyd4XaovZlO/k9V3hjVUF/zwW7KBVdSK4gIt/bzwS9MbR5qob+F5jusZsb0YQK2A==",
+      "dev": true
+    },
+    "bunyan": {
+      "version": "1.8.12",
+      "resolved": "https://registry.npmjs.org/bunyan/-/bunyan-1.8.12.tgz",
+      "integrity": "sha1-8VDw9nSKvdcq6uhPBEA74u8RN5c=",
+      "requires": {
+        "dtrace-provider": "~0.8",
+        "moment": "^2.10.6",
+        "mv": "~2",
+        "safe-json-stringify": "~1"
+      }
+    },
+    "camelcase": {
+      "version": "1.2.1",
+      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-1.2.1.tgz",
+      "integrity": "sha1-m7UwTS4LVmmLLHWLCKPqqdqlijk="
+    },
+    "camelcase-keys": {
+      "version": "1.0.0",
+      "resolved": "http://registry.npmjs.org/camelcase-keys/-/camelcase-keys-1.0.0.tgz",
+      "integrity": "sha1-vRoRv5sxoc5JNJOpMN4aC69K1+w=",
+      "requires": {
+        "camelcase": "^1.0.1",
+        "map-obj": "^1.0.0"
+      }
+    },
+    "capture-stack-trace": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/capture-stack-trace/-/capture-stack-trace-1.0.1.tgz",
+      "integrity": "sha512-mYQLZnx5Qt1JgB1WEiMCf2647plpGeQ2NMR/5L0HNZzGQo4fuSPnK+wjfPnKZV0aiJDgzmWqqkV/g7JD+DW0qw==",
+      "dev": true
+    },
+    "caseless": {
+      "version": "0.12.0",
+      "resolved": "https://registry.npmjs.org/caseless/-/caseless-0.12.0.tgz",
+      "integrity": "sha1-G2gcIf+EAzyCZUMJBolCDRhxUdw=",
+      "dev": true
+    },
+    "chalk": {
+      "version": "2.4.1",
+      "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.1.tgz",
+      "integrity": "sha512-ObN6h1v2fTJSmUXoS3nMQ92LbDK9be4TV+6G+omQlGJFdcUX5heKi1LZ1YnRMIgwTLEj3E24bT6tYni50rlCfQ==",
+      "dev": true,
+      "requires": {
+        "ansi-styles": "^3.2.1",
+        "escape-string-regexp": "^1.0.5",
+        "supports-color": "^5.3.0"
+      }
+    },
+    "clean-yaml-object": {
+      "version": "0.1.0",
+      "resolved": "https://registry.npmjs.org/clean-yaml-object/-/clean-yaml-object-0.1.0.tgz",
+      "integrity": "sha1-Y/sRDcLOGoTcIfbZM0h20BCui2g=",
+      "dev": true
+    },
+    "clone": {
+      "version": "0.1.8",
+      "resolved": "https://registry.npmjs.org/clone/-/clone-0.1.8.tgz",
+      "integrity": "sha1-mcgcaVD/wEGJMK6EFZzaklDqlQA="
+    },
+    "cmdln": {
+      "version": "3.2.1",
+      "resolved": "https://registry.npmjs.org/cmdln/-/cmdln-3.2.1.tgz",
+      "integrity": "sha1-jSGWdiWyXuNfyo6EU8zxD8zQTkU=",
+      "requires": {
+        "assert-plus": "^0.1.5",
+        "dashdash": "^1.7.1",
+        "extsprintf": "^1.2.0",
+        "verror": "^1.6.0"
+      }
+    },
+    "color-convert": {
+      "version": "1.9.3",
+      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
+      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
+      "dev": true,
+      "requires": {
+        "color-name": "1.1.3"
+      }
+    },
+    "color-name": {
+      "version": "1.1.3",
+      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
+      "integrity": "sha1-p9BVi9icQveV3UIyj3QIMcpTvCU=",
+      "dev": true
+    },
+    "color-support": {
+      "version": "1.1.3",
+      "resolved": "https://registry.npmjs.org/color-support/-/color-support-1.1.3.tgz",
+      "integrity": "sha512-qiBjkpbMLO/HL68y+lh4q0/O1MZFj2RX6X/KmMa3+gJD3z+WwI1ZzDHysvqHGS3mP6mznPckpXmw1nI9cJjyRg==",
+      "dev": true
+    },
+    "combined-stream": {
+      "version": "1.0.7",
+      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.7.tgz",
+      "integrity": "sha512-brWl9y6vOB1xYPZcpZde3N9zDByXTosAeMDo4p1wzo6UMOX4vumB+TP1RZ76sfE6Md68Q0NJSrE/gbezd4Ul+w==",
+      "dev": true,
+      "requires": {
+        "delayed-stream": "~1.0.0"
+      }
+    },
+    "concat-map": {
+      "version": "0.0.1",
+      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
+      "integrity": "sha1-2Klr13/Wjfd5OnMDajug1UBdR3s="
+    },
+    "concat-stream": {
+      "version": "1.4.10",
+      "resolved": "https://registry.npmjs.org/concat-stream/-/concat-stream-1.4.10.tgz",
+      "integrity": "sha1-rMO79WAsuMyYDGrIQPp9hgPj7zY=",
+      "requires": {
+        "inherits": "~2.0.1",
+        "readable-stream": "~1.1.9",
+        "typedarray": "~0.0.5"
+      }
+    },
+    "core-util-is": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
+      "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac="
+    },
+    "coveralls": {
+      "version": "3.0.2",
+      "resolved": "https://registry.npmjs.org/coveralls/-/coveralls-3.0.2.tgz",
+      "integrity": "sha512-Tv0LKe/MkBOilH2v7WBiTBdudg2ChfGbdXafc/s330djpF3zKOmuehTeRwjXWc7pzfj9FrDUTA7tEx6Div8NFw==",
+      "dev": true,
+      "requires": {
+        "growl": "~> 1.10.0",
+        "js-yaml": "^3.11.0",
+        "lcov-parse": "^0.0.10",
+        "log-driver": "^1.2.7",
+        "minimist": "^1.2.0",
+        "request": "^2.85.0"
+      },
+      "dependencies": {
+        "minimist": {
+          "version": "1.2.0",
+          "resolved": "http://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
+          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
+          "dev": true
+        }
+      }
+    },
+    "cross-spawn": {
+      "version": "4.0.2",
+      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-4.0.2.tgz",
+      "integrity": "sha1-e5JHYhwjrf3ThWAEqCPL45dCTUE=",
+      "dev": true,
+      "requires": {
+        "lru-cache": "^4.0.1",
+        "which": "^1.2.9"
+      }
+    },
+    "csv": {
+      "version": "1.2.1",
+      "resolved": "https://registry.npmjs.org/csv/-/csv-1.2.1.tgz",
+      "integrity": "sha1-UjHt/BxxUlEuxFeBB2p6l/9SXAw=",
+      "requires": {
+        "csv-generate": "^1.1.2",
+        "csv-parse": "^1.3.3",
+        "csv-stringify": "^1.1.2",
+        "stream-transform": "^0.2.2"
+      }
+    },
+    "csv-generate": {
+      "version": "1.1.2",
+      "resolved": "https://registry.npmjs.org/csv-generate/-/csv-generate-1.1.2.tgz",
+      "integrity": "sha1-7GsA7a7W5ZrZwgWC9MNk4osUYkA="
+    },
+    "csv-parse": {
+      "version": "1.3.3",
+      "resolved": "https://registry.npmjs.org/csv-parse/-/csv-parse-1.3.3.tgz",
+      "integrity": "sha1-0c/YdDwvhJoKuy/VRNtWaV0ZpJA="
+    },
+    "csv-stringify": {
+      "version": "1.1.2",
+      "resolved": "https://registry.npmjs.org/csv-stringify/-/csv-stringify-1.1.2.tgz",
+      "integrity": "sha1-d6QVJlgbzjOA8SsA18W7rHDIK1g=",
+      "requires": {
+        "lodash.get": "~4.4.2"
+      }
+    },
+    "dashdash": {
+      "version": "1.14.1",
+      "resolved": "https://registry.npmjs.org/dashdash/-/dashdash-1.14.1.tgz",
+      "integrity": "sha1-hTz6D3y+L+1d4gMmuN1YEDX24vA=",
+      "requires": {
+        "assert-plus": "^1.0.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "debug": {
+      "version": "2.6.9",
+      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
+      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
+      "requires": {
+        "ms": "2.0.0"
+      }
+    },
+    "delayed-stream": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
+      "integrity": "sha1-3zrhmayt+31ECqrgsp4icrJOxhk=",
+      "dev": true
+    },
+    "detect-node": {
+      "version": "2.0.4",
+      "resolved": "https://registry.npmjs.org/detect-node/-/detect-node-2.0.4.tgz",
+      "integrity": "sha512-ZIzRpLJrOj7jjP2miAtgqIfmzbxa4ZOr5jJc601zklsfEx9oTzmmj2nVpIPRpNlRTIh8lc1kyViIY7BWSGNmKw=="
+    },
+    "diff": {
+      "version": "1.4.0",
+      "resolved": "https://registry.npmjs.org/diff/-/diff-1.4.0.tgz",
+      "integrity": "sha1-fyjS657nsVqX79ic5j3P2qPMur8=",
+      "dev": true
+    },
+    "docker-registry-client": {
+      "version": "3.2.10",
+      "resolved": "https://registry.npmjs.org/docker-registry-client/-/docker-registry-client-3.2.10.tgz",
+      "integrity": "sha1-6Zm+n/xkIvsTs0kgtDF1P/CfL/o=",
+      "requires": {
+        "assert-plus": "^0.1.5",
+        "base64url": "1.x >=1.0.4",
+        "bunyan": "1.x >=1.3.3",
+        "jwk-to-pem": "1.2.0",
+        "jws": "3.1.0",
+        "restify-clients": "^1.4.0",
+        "restify-errors": "^3.0.0",
+        "strsplit": "1.x",
+        "tough-cookie": "2.0.x",
+        "vasync": "1.x >=1.6.1",
+        "verror": "1.x >=1.6.0",
+        "www-authenticate": "0.6.x >=0.6.2"
+      }
+    },
+    "domain-browser": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/domain-browser/-/domain-browser-1.2.0.tgz",
+      "integrity": "sha512-jnjyiM6eRyZl2H+W8Q/zLMA481hzi0eszAaBUzIVnmYVDBbnLxVNnfu1HgEBvCbL+71FrxMl3E6lpKH7Ge3OXA==",
+      "dev": true
+    },
+    "dtrace-provider": {
+      "version": "0.8.7",
+      "resolved": "https://registry.npmjs.org/dtrace-provider/-/dtrace-provider-0.8.7.tgz",
+      "integrity": "sha1-3JObTT4GIM/gwc2APQ0tftBP/QQ=",
+      "optional": true,
+      "requires": {
+        "nan": "^2.10.0"
+      }
+    },
+    "ecc-jsbn": {
+      "version": "0.1.2",
+      "resolved": "https://registry.npmjs.org/ecc-jsbn/-/ecc-jsbn-0.1.2.tgz",
+      "integrity": "sha1-OoOpBOVDUyh4dMVkt1SThoSamMk=",
+      "requires": {
+        "jsbn": "~0.1.0",
+        "safer-buffer": "^2.1.0"
+      }
+    },
+    "ecdsa-sig-formatter": {
+      "version": "1.0.10",
+      "resolved": "https://registry.npmjs.org/ecdsa-sig-formatter/-/ecdsa-sig-formatter-1.0.10.tgz",
+      "integrity": "sha1-HFlQAPBKiJffuFAAiSoPTDOvhsM=",
+      "requires": {
+        "safe-buffer": "^5.0.1"
+      }
+    },
+    "elliptic": {
+      "version": "3.1.0",
+      "resolved": "https://registry.npmjs.org/elliptic/-/elliptic-3.1.0.tgz",
+      "integrity": "sha1-whaC73YnabVqdCAWCRBdoR1fYMw=",
+      "requires": {
+        "bn.js": "^2.0.3",
+        "brorand": "^1.0.1",
+        "hash.js": "^1.0.0",
+        "inherits": "^2.0.1"
+      }
+    },
+    "escape-regexp-component": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/escape-regexp-component/-/escape-regexp-component-1.0.2.tgz",
+      "integrity": "sha1-nGO20LJf8qiMOtvRjFthrMO5+qI="
+    },
+    "escape-string-regexp": {
+      "version": "1.0.5",
+      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-1.0.5.tgz",
+      "integrity": "sha1-G2HAViGQqN/2rjuyzwIAyhMLhtQ=",
+      "dev": true
+    },
+    "esprima": {
+      "version": "4.0.1",
+      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
+      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
+      "dev": true
+    },
+    "esutils": {
+      "version": "2.0.2",
+      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.2.tgz",
+      "integrity": "sha1-Cr9PHKpbyx96nYrMbepPqqBLrJs=",
+      "dev": true
+    },
+    "events-to-array": {
+      "version": "1.1.2",
+      "resolved": "https://registry.npmjs.org/events-to-array/-/events-to-array-1.1.2.tgz",
+      "integrity": "sha1-LUH1Y+H+QA7Uli/hpNXGp1Od9/Y=",
+      "dev": true
+    },
+    "ewma": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/ewma/-/ewma-2.0.1.tgz",
+      "integrity": "sha512-MYYK17A76cuuyvkR7MnqLW4iFYPEi5Isl2qb8rXiWpLiwFS9dxW/rncuNnjjgSENuVqZQkIuR4+DChVL4g1lnw==",
+      "requires": {
+        "assert-plus": "^1.0.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "extend": {
+      "version": "3.0.2",
+      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
+      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
+      "dev": true
+    },
+    "extsprintf": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.2.0.tgz",
+      "integrity": "sha1-WtlGwi9bMrp/jNdCZxHG6KP8JSk="
+    },
+    "fast-decode-uri-component": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/fast-decode-uri-component/-/fast-decode-uri-component-1.0.0.tgz",
+      "integrity": "sha512-WQSYVKn6tDW/3htASeUkrx5LcnuTENQIZQPCVlwdnvIJ7bYtSpoJYq38MgUJnx1CQIR1gjZ8HJxAEcN4gqugBg=="
+    },
+    "fast-deep-equal": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-2.0.1.tgz",
+      "integrity": "sha1-ewUhjd+WZ79/Nwv3/bLLFf3Qqkk=",
+      "dev": true
+    },
+    "fast-json-stable-stringify": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.0.0.tgz",
+      "integrity": "sha1-1RQsDK7msRifh9OnYREGT4bIu/I=",
+      "dev": true
+    },
+    "fast-safe-stringify": {
+      "version": "1.2.3",
+      "resolved": "https://registry.npmjs.org/fast-safe-stringify/-/fast-safe-stringify-1.2.3.tgz",
+      "integrity": "sha512-QJYT/i0QYoiZBQ71ivxdyTqkwKkQ0oxACXHYxH2zYHJEgzi2LsbjgvtzTbLi1SZcF190Db2YP7I7eTsU2egOlw=="
+    },
+    "find-my-way": {
+      "version": "1.15.4",
+      "resolved": "https://registry.npmjs.org/find-my-way/-/find-my-way-1.15.4.tgz",
+      "integrity": "sha512-3XPCOhoGMPK6ELgUHd5BuNxsL+fTNM0EIrTlcLwjT2uZq22UHL4IQt5N54PIQblk164ioZATRov9mcuA4RB3eA==",
+      "requires": {
+        "fast-decode-uri-component": "^1.0.0",
+        "safe-regex": "^1.1.0",
+        "semver-store": "^0.3.0"
+      }
+    },
+    "findit2": {
+      "version": "2.2.3",
+      "resolved": "https://registry.npmjs.org/findit2/-/findit2-2.2.3.tgz",
+      "integrity": "sha1-WKRmaX34piBc39vzlVNri9d3pfY="
+    },
+    "foreground-child": {
+      "version": "1.5.6",
+      "resolved": "http://registry.npmjs.org/foreground-child/-/foreground-child-1.5.6.tgz",
+      "integrity": "sha1-T9ca0t/elnibmApcCilZN8svXOk=",
+      "dev": true,
+      "requires": {
+        "cross-spawn": "^4",
+        "signal-exit": "^3.0.0"
+      }
+    },
+    "forever-agent": {
+      "version": "0.6.1",
+      "resolved": "https://registry.npmjs.org/forever-agent/-/forever-agent-0.6.1.tgz",
+      "integrity": "sha1-+8cfDEGt6zf5bFd60e1C2P2sypE=",
+      "dev": true
+    },
+    "form-data": {
+      "version": "2.3.3",
+      "resolved": "https://registry.npmjs.org/form-data/-/form-data-2.3.3.tgz",
+      "integrity": "sha512-1lLKB2Mu3aGP1Q/2eCOx0fNbRMe7XdwktwOruhfqqd0rIJWwN4Dh+E3hrPSlDCXnSR7UtZ1N38rVXm+6+MEhJQ==",
+      "dev": true,
+      "requires": {
+        "asynckit": "^0.4.0",
+        "combined-stream": "^1.0.6",
+        "mime-types": "^2.1.12"
+      }
+    },
+    "formidable": {
+      "version": "1.2.1",
+      "resolved": "https://registry.npmjs.org/formidable/-/formidable-1.2.1.tgz",
+      "integrity": "sha512-Fs9VRguL0gqGHkXS5GQiMCr1VhZBxz0JnJs4JmMp/2jL18Fmbzvv7vOFRU+U8TBkHEE/CX1qDXzJplVULgsLeg=="
+    },
+    "fs-exists-cached": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/fs-exists-cached/-/fs-exists-cached-1.0.0.tgz",
+      "integrity": "sha1-zyVVTKBQ3EmuZla0HeQiWJidy84=",
+      "dev": true
+    },
+    "fs.realpath": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
+      "integrity": "sha1-FQStJSMVjKpA20onh8sBQRmU6k8=",
+      "dev": true
+    },
+    "function-loop": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/function-loop/-/function-loop-1.0.1.tgz",
+      "integrity": "sha1-gHa7MF6OajzO7ikgdl8zDRkPNAw=",
+      "dev": true
+    },
+    "get-stdin": {
+      "version": "4.0.1",
+      "resolved": "https://registry.npmjs.org/get-stdin/-/get-stdin-4.0.1.tgz",
+      "integrity": "sha1-uWjGsKBDhDJJAui/Gl3zJXmkUP4="
+    },
+    "getpass": {
+      "version": "0.1.7",
+      "resolved": "https://registry.npmjs.org/getpass/-/getpass-0.1.7.tgz",
+      "integrity": "sha1-Xv+OPmhNVprkyysSgmBOi6YhSfo=",
+      "requires": {
+        "assert-plus": "^1.0.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "glob": {
+      "version": "6.0.4",
+      "resolved": "https://registry.npmjs.org/glob/-/glob-6.0.4.tgz",
+      "integrity": "sha1-DwiGD2oVUSey+t1PnOJLGqtuTSI=",
+      "optional": true,
+      "requires": {
+        "inflight": "^1.0.4",
+        "inherits": "2",
+        "minimatch": "2 || 3",
+        "once": "^1.3.0",
+        "path-is-absolute": "^1.0.0"
+      }
+    },
+    "globals": {
+      "version": "11.9.0",
+      "resolved": "https://registry.npmjs.org/globals/-/globals-11.9.0.tgz",
+      "integrity": "sha512-5cJVtyXWH8PiJPVLZzzoIizXx944O4OmRro5MWKx5fT4MgcN7OfaMutPeaTdJCCURwbWdhhcCWcKIffPnmTzBg==",
+      "dev": true
+    },
+    "graceful-fs": {
+      "version": "4.1.15",
+      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.1.15.tgz",
+      "integrity": "sha512-6uHUhOPEBgQ24HM+r6b/QwWfZq+yiFcipKFrOFiBEnWdy5sdzYoi+pJeQaPI5qOLRFqWmAXUPQNsielzdLoecA==",
+      "dev": true
+    },
+    "growl": {
+      "version": "1.10.5",
+      "resolved": "https://registry.npmjs.org/growl/-/growl-1.10.5.tgz",
+      "integrity": "sha512-qBr4OuELkhPenW6goKVXiv47US3clb3/IbuWF9KNKEijAy9oeHxU9IgzjvJhHkUzhaj7rOUD7+YGWqUjLp5oSA==",
+      "dev": true
+    },
+    "handle-thing": {
+      "version": "1.2.5",
+      "resolved": "http://registry.npmjs.org/handle-thing/-/handle-thing-1.2.5.tgz",
+      "integrity": "sha1-/Xqtcmvxpf0W38KbL3pmAdJxOcQ="
+    },
+    "har-schema": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/har-schema/-/har-schema-2.0.0.tgz",
+      "integrity": "sha1-qUwiJOvKwEeCoNkDVSHyRzW37JI=",
+      "dev": true
+    },
+    "har-validator": {
+      "version": "5.1.3",
+      "resolved": "https://registry.npmjs.org/har-validator/-/har-validator-5.1.3.tgz",
+      "integrity": "sha512-sNvOCzEQNr/qrvJgc3UG/kD4QtlHycrzwS+6mfTrrSq97BvaYcPZZI1ZSqGSPR73Cxn4LKTD4PttRwfU7jWq5g==",
+      "dev": true,
+      "requires": {
+        "ajv": "^6.5.5",
+        "har-schema": "^2.0.0"
+      }
+    },
+    "has-flag": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
+      "integrity": "sha1-tdRU3CGZriJWmfNGfloH87lVuv0=",
+      "dev": true
+    },
+    "hash.js": {
+      "version": "1.1.5",
+      "resolved": "https://registry.npmjs.org/hash.js/-/hash.js-1.1.5.tgz",
+      "integrity": "sha512-eWI5HG9Np+eHV1KQhisXWwM+4EPPYe5dFX1UZZH7k/E3JzDEazVH+VGlZi6R94ZqImq+A3D1mCEtrFIfg/E7sA==",
+      "requires": {
+        "inherits": "^2.0.3",
+        "minimalistic-assert": "^1.0.1"
+      }
+    },
+    "hpack.js": {
+      "version": "2.1.6",
+      "resolved": "https://registry.npmjs.org/hpack.js/-/hpack.js-2.1.6.tgz",
+      "integrity": "sha1-h3dMCUnlE/QuhFdbPEVoH63ioLI=",
+      "requires": {
+        "inherits": "^2.0.1",
+        "obuf": "^1.0.0",
+        "readable-stream": "^2.0.1",
+        "wbuf": "^1.1.0"
+      },
+      "dependencies": {
+        "isarray": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
+          "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE="
+        },
+        "readable-stream": {
+          "version": "2.3.6",
+          "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.3.6.tgz",
+          "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
+          "requires": {
+            "core-util-is": "~1.0.0",
+            "inherits": "~2.0.3",
+            "isarray": "~1.0.0",
+            "process-nextick-args": "~2.0.0",
+            "safe-buffer": "~5.1.1",
+            "string_decoder": "~1.1.1",
+            "util-deprecate": "~1.0.1"
+          }
+        },
+        "string_decoder": {
+          "version": "1.1.1",
+          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
+          "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
+          "requires": {
+            "safe-buffer": "~5.1.0"
+          }
+        }
+      }
+    },
+    "http-deceiver": {
+      "version": "1.2.7",
+      "resolved": "https://registry.npmjs.org/http-deceiver/-/http-deceiver-1.2.7.tgz",
+      "integrity": "sha1-+nFolEq5pRnTN8sL7HKE3D5yPYc="
+    },
+    "http-signature": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/http-signature/-/http-signature-1.2.0.tgz",
+      "integrity": "sha1-muzZJRFHcvPZW2WmCruPfBj7rOE=",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "jsprim": "^1.2.2",
+        "sshpk": "^1.7.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "imgmanifest": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/imgmanifest/-/imgmanifest-3.0.0.tgz",
+      "integrity": "sha512-fq7Pqs4kdVbv2/pSyLdh25qpJwxITVQEQAqMH8XWfsHpwK1IjKoZjkXzfEmLCVHNoyIFYY35khnrMTnxLy/BSA==",
+      "requires": {
+        "assert-plus": "1.0.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "imurmurhash": {
+      "version": "0.1.4",
+      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
+      "integrity": "sha1-khi5srkoojixPcT7a21XbyMUU+o=",
+      "dev": true
+    },
+    "indent-string": {
+      "version": "1.2.2",
+      "resolved": "https://registry.npmjs.org/indent-string/-/indent-string-1.2.2.tgz",
+      "integrity": "sha1-25m8xYPrarux5I3LsZmamGBBy2s=",
+      "requires": {
+        "get-stdin": "^4.0.1",
+        "minimist": "^1.1.0",
+        "repeating": "^1.1.0"
+      },
+      "dependencies": {
+        "minimist": {
+          "version": "1.2.0",
+          "resolved": "http://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
+          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ="
+        }
+      }
+    },
+    "inflight": {
+      "version": "1.0.6",
+      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
+      "integrity": "sha1-Sb1jMdfQLQwJvJEKEHW6gWW1bfk=",
+      "requires": {
+        "once": "^1.3.0",
+        "wrappy": "1"
+      }
+    },
+    "inherits": {
+      "version": "2.0.3",
+      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
+      "integrity": "sha1-Yzwsg+PaQqUC9SRmAiSA9CCCYd4="
+    },
+    "is-finite": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/is-finite/-/is-finite-1.0.2.tgz",
+      "integrity": "sha1-zGZ3aVYCvlUO8R6LSqYwU0K20Ko=",
+      "requires": {
+        "number-is-nan": "^1.0.0"
+      }
+    },
+    "is-typedarray": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/is-typedarray/-/is-typedarray-1.0.0.tgz",
+      "integrity": "sha1-5HnICFjfDBsR3dppQPlgEfzaSpo=",
+      "dev": true
+    },
+    "isarray": {
+      "version": "0.0.1",
+      "resolved": "https://registry.npmjs.org/isarray/-/isarray-0.0.1.tgz",
+      "integrity": "sha1-ihis/Kmo9Bd+Cav8YDiTmwXR7t8="
+    },
+    "isexe": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
+      "integrity": "sha1-6PvzdNxVb/iUehDcsFctYz8s+hA=",
+      "dev": true
+    },
+    "isstream": {
+      "version": "0.1.2",
+      "resolved": "https://registry.npmjs.org/isstream/-/isstream-0.1.2.tgz",
+      "integrity": "sha1-R+Y/evVa+m+S4VAOaQ64uFKcCZo=",
+      "dev": true
+    },
+    "istanbul-lib-coverage": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.1.tgz",
+      "integrity": "sha512-nPvSZsVlbG9aLhZYaC3Oi1gT/tpyo3Yt5fNyf6NmcKIayz4VV/txxJFFKAK/gU4dcNn8ehsanBbVHVl0+amOLA==",
+      "dev": true
+    },
+    "istanbul-lib-instrument": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-3.0.0.tgz",
+      "integrity": "sha512-eQY9vN9elYjdgN9Iv6NS/00bptm02EBBk70lRMaVjeA6QYocQgenVrSgC28TJurdnZa80AGO3ASdFN+w/njGiQ==",
+      "dev": true,
+      "requires": {
+        "@babel/generator": "^7.0.0",
+        "@babel/parser": "^7.0.0",
+        "@babel/template": "^7.0.0",
+        "@babel/traverse": "^7.0.0",
+        "@babel/types": "^7.0.0",
+        "istanbul-lib-coverage": "^2.0.1",
+        "semver": "^5.5.0"
+      }
+    },
+    "js-tokens": {
+      "version": "4.0.0",
+      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
+      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
+      "dev": true
+    },
+    "js-yaml": {
+      "version": "3.12.0",
+      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.12.0.tgz",
+      "integrity": "sha512-PIt2cnwmPfL4hKNwqeiuz4bKfnzHTBv6HyVgjahA6mPLwPDzjDWrplJBMjHUFxku/N3FlmrbyPclad+I+4mJ3A==",
+      "dev": true,
+      "requires": {
+        "argparse": "^1.0.7",
+        "esprima": "^4.0.0"
+      }
+    },
+    "jsbn": {
+      "version": "0.1.1",
+      "resolved": "https://registry.npmjs.org/jsbn/-/jsbn-0.1.1.tgz",
+      "integrity": "sha1-peZUwuWi3rXyAdls77yoDA7y9RM="
+    },
+    "jsesc": {
+      "version": "2.5.2",
+      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-2.5.2.tgz",
+      "integrity": "sha512-OYu7XEzjkCQ3C5Ps3QIZsQfNpqoJyZZA99wd9aWd05NCtC5pWOkShK2mkL6HXQR6/Cy2lbNdPlZBpuQHXE63gA==",
+      "dev": true
+    },
+    "json-schema": {
+      "version": "0.2.3",
+      "resolved": "https://registry.npmjs.org/json-schema/-/json-schema-0.2.3.tgz",
+      "integrity": "sha1-tIDIkuWaLwWVTOcnvT8qTogvnhM="
+    },
+    "json-schema-traverse": {
+      "version": "0.4.1",
+      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
+      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
+      "dev": true
+    },
+    "json-stringify-safe": {
+      "version": "5.0.1",
+      "resolved": "https://registry.npmjs.org/json-stringify-safe/-/json-stringify-safe-5.0.1.tgz",
+      "integrity": "sha1-Epai1Y/UXxmg9s4B1lcB4sc1tus=",
+      "dev": true
+    },
+    "jsprim": {
+      "version": "1.4.1",
+      "resolved": "https://registry.npmjs.org/jsprim/-/jsprim-1.4.1.tgz",
+      "integrity": "sha1-MT5mvB5cwG5Di8G3SZwuXFastqI=",
+      "requires": {
+        "assert-plus": "1.0.0",
+        "extsprintf": "1.3.0",
+        "json-schema": "0.2.3",
+        "verror": "1.10.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "extsprintf": {
+          "version": "1.3.0",
+          "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.3.0.tgz",
+          "integrity": "sha1-lpGEQOMEGnpBT4xS48V06zw+HgU="
+        },
+        "verror": {
+          "version": "1.10.0",
+          "resolved": "https://registry.npmjs.org/verror/-/verror-1.10.0.tgz",
+          "integrity": "sha1-OhBcoXBTr1XW4nDB+CiGguGNpAA=",
+          "requires": {
+            "assert-plus": "^1.0.0",
+            "core-util-is": "1.0.2",
+            "extsprintf": "^1.2.0"
+          }
+        }
+      }
+    },
+    "jwa": {
+      "version": "1.1.6",
+      "resolved": "https://registry.npmjs.org/jwa/-/jwa-1.1.6.tgz",
+      "integrity": "sha512-tBO/cf++BUsJkYql/kBbJroKOgHWEigTKBAjjBEmrMGYd1QMBC74Hr4Wo2zCZw6ZrVhlJPvoMrkcOnlWR/DJfw==",
+      "requires": {
+        "buffer-equal-constant-time": "1.0.1",
+        "ecdsa-sig-formatter": "1.0.10",
+        "safe-buffer": "^5.0.1"
+      }
+    },
+    "jwk-to-pem": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/jwk-to-pem/-/jwk-to-pem-1.2.0.tgz",
+      "integrity": "sha1-rVbgWSc+bAXE+qAm4ooARrpDVNE=",
+      "requires": {
+        "asn1.js": "^2.2.0",
+        "asn1.js-rfc3280": "^2.1.0",
+        "elliptic": "^3.0.4"
+      }
+    },
+    "jws": {
+      "version": "3.1.0",
+      "resolved": "https://registry.npmjs.org/jws/-/jws-3.1.0.tgz",
+      "integrity": "sha1-iFqJEn0kEZoqk/I03dSSM3p8haA=",
+      "requires": {
+        "base64url": "~1.0.4",
+        "jwa": "^1.1.0"
+      }
+    },
+    "keep-alive-agent": {
+      "version": "0.0.1",
+      "resolved": "https://registry.npmjs.org/keep-alive-agent/-/keep-alive-agent-0.0.1.tgz",
+      "integrity": "sha1-RIR8o5TOjWtSGuhYFr1kUJlCs4U="
+    },
+    "lcov-parse": {
+      "version": "0.0.10",
+      "resolved": "https://registry.npmjs.org/lcov-parse/-/lcov-parse-0.0.10.tgz",
+      "integrity": "sha1-GwuP+ayceIklBYK3C3ExXZ2m2aM=",
+      "dev": true
+    },
+    "lockfd": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/lockfd/-/lockfd-2.0.1.tgz",
+      "integrity": "sha1-3ewsmMTfHlLMwAe8PIZrtJcaLfk=",
+      "requires": {
+        "v8plus": "~1.0.2"
+      }
+    },
+    "lodash": {
+      "version": "4.17.11",
+      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.11.tgz",
+      "integrity": "sha512-cQKh8igo5QUhZ7lg38DYWAxMvjSAKG0A8wGSVimP07SIUEK2UO+arSRKbRZWtelMtN5V0Hkwh5ryOto/SshYIg=="
+    },
+    "lodash.get": {
+      "version": "4.4.2",
+      "resolved": "https://registry.npmjs.org/lodash.get/-/lodash.get-4.4.2.tgz",
+      "integrity": "sha1-LRd/ZS+jHpObRDjVNBSZ36OCXpk="
+    },
+    "log-driver": {
+      "version": "1.2.7",
+      "resolved": "https://registry.npmjs.org/log-driver/-/log-driver-1.2.7.tgz",
+      "integrity": "sha512-U7KCmLdqsGHBLeWqYlFA0V0Sl6P08EE1ZrmA9cxjUE0WVqT9qnyVDPz1kzpFEP0jdJuFnasWIfSd7fsaNXkpbg==",
+      "dev": true
+    },
+    "lomstream": {
+      "version": "1.1.0",
+      "resolved": "https://registry.npmjs.org/lomstream/-/lomstream-1.1.0.tgz",
+      "integrity": "sha1-Kn+AZuw6tAvvKMo4SELnU0AYO/A=",
+      "requires": {
+        "assert-plus": "0.1.5",
+        "extsprintf": "1.3.0",
+        "vstream": "0.1.0"
+      },
+      "dependencies": {
+        "extsprintf": {
+          "version": "1.3.0",
+          "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.3.0.tgz",
+          "integrity": "sha1-lpGEQOMEGnpBT4xS48V06zw+HgU="
+        }
+      }
+    },
+    "lru-cache": {
+      "version": "4.1.3",
+      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-4.1.3.tgz",
+      "integrity": "sha512-fFEhvcgzuIoJVUF8fYr5KR0YqxD238zgObTps31YdADwPPAp82a4M8TrckkWyx7ekNlf9aBcVn81cFwwXngrJA==",
+      "requires": {
+        "pseudomap": "^1.0.2",
+        "yallist": "^2.1.2"
+      }
+    },
+    "map-obj": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/map-obj/-/map-obj-1.0.1.tgz",
+      "integrity": "sha1-2TPOuSBdgr3PSIb2dCvcK03qFG0="
+    },
+    "meow": {
+      "version": "2.0.0",
+      "resolved": "http://registry.npmjs.org/meow/-/meow-2.0.0.tgz",
+      "integrity": "sha1-j1MKjs9dQNP0tN+Tw0cpAPuiqPE=",
+      "requires": {
+        "camelcase-keys": "^1.0.0",
+        "indent-string": "^1.1.0",
+        "minimist": "^1.1.0",
+        "object-assign": "^1.0.0"
+      },
+      "dependencies": {
+        "minimist": {
+          "version": "1.2.0",
+          "resolved": "http://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
+          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ="
+        }
+      }
+    },
+    "mime": {
+      "version": "1.6.0",
+      "resolved": "https://registry.npmjs.org/mime/-/mime-1.6.0.tgz",
+      "integrity": "sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg=="
+    },
+    "mime-db": {
+      "version": "1.37.0",
+      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.37.0.tgz",
+      "integrity": "sha512-R3C4db6bgQhlIhPU48fUtdVmKnflq+hRdad7IyKhtFj06VPNVdk2RhiYL3UjQIlso8L+YxAtFkobT0VK+S/ybg==",
+      "dev": true
+    },
+    "mime-types": {
+      "version": "2.1.21",
+      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.21.tgz",
+      "integrity": "sha512-3iL6DbwpyLzjR3xHSFNFeb9Nz/M8WDkX33t1GFQnFOllWk8pOrh/LSrB5OXlnlW5P9LH73X6loW/eogc+F5lJg==",
+      "dev": true,
+      "requires": {
+        "mime-db": "~1.37.0"
+      }
+    },
+    "minimalistic-assert": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/minimalistic-assert/-/minimalistic-assert-1.0.1.tgz",
+      "integrity": "sha512-UtJcAD4yEaGtjPezWuO9wC4nwUnVH/8/Im3yEHQP4b67cXlD/Qr9hdITCU1xDbSEXg2XKNaP8jsReV7vQd00/A=="
+    },
+    "minimatch": {
+      "version": "3.0.4",
+      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.0.4.tgz",
+      "integrity": "sha512-yJHVQEhyqPLUTgt9B83PXu6W3rx4MvvHvSUvToogpwoGDOUQ+yDrR0HRot+yOCdCO7u4hX3pWft6kWBBcqh0UA==",
+      "requires": {
+        "brace-expansion": "^1.1.7"
+      }
+    },
+    "minimist": {
+      "version": "0.0.8",
+      "resolved": "http://registry.npmjs.org/minimist/-/minimist-0.0.8.tgz",
+      "integrity": "sha1-hX/Kv8M5fSYluCKCYuhqp6ARsF0="
+    },
+    "minipass": {
+      "version": "2.3.5",
+      "resolved": "https://registry.npmjs.org/minipass/-/minipass-2.3.5.tgz",
+      "integrity": "sha512-Gi1W4k059gyRbyVUZQ4mEqLm0YIUiGYfvxhF6SIlk3ui1WVxMTGfGdQ2SInh3PDrRTVvPKgULkpJtT4RH10+VA==",
+      "dev": true,
+      "requires": {
+        "safe-buffer": "^5.1.2",
+        "yallist": "^3.0.0"
+      },
+      "dependencies": {
+        "yallist": {
+          "version": "3.0.2",
+          "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.0.2.tgz",
+          "integrity": "sha1-hFK0u36Dx8GI2AQcGoN8dz1ti7k=",
+          "dev": true
+        }
+      }
+    },
+    "mkdirp": {
+      "version": "0.5.0",
+      "resolved": "http://registry.npmjs.org/mkdirp/-/mkdirp-0.5.0.tgz",
+      "integrity": "sha1-HXMHam35hs2TROFecfzAWkyavxI=",
+      "requires": {
+        "minimist": "0.0.8"
+      }
+    },
+    "moment": {
+      "version": "2.22.2",
+      "resolved": "https://registry.npmjs.org/moment/-/moment-2.22.2.tgz",
+      "integrity": "sha1-PCV/mDn8DpP/UxSWMiOeuQeD/2Y=",
+      "optional": true
+    },
+    "mooremachine": {
+      "version": "2.2.1",
+      "resolved": "https://registry.npmjs.org/mooremachine/-/mooremachine-2.2.1.tgz",
+      "integrity": "sha1-DZiRqnws8yynPnL1KjVh7Xh+Low=",
+      "requires": {
+        "assert-plus": ">=0.2.0 <0.3.0",
+        "dtrace-provider": "~0.8"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "0.2.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-0.2.0.tgz",
+          "integrity": "sha1-104bh+ev/A24qttwIfP+SBAasjQ="
+        }
+      }
+    },
+    "ms": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
+      "integrity": "sha1-VgiurfwAvmwpAd9fmGF4jeDVl8g="
+    },
+    "mv": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/mv/-/mv-2.1.1.tgz",
+      "integrity": "sha1-rmzg1vbV4KT32JN5jQPB6pVZtqI=",
+      "optional": true,
+      "requires": {
+        "mkdirp": "~0.5.1",
+        "ncp": "~2.0.0",
+        "rimraf": "~2.4.0"
+      },
+      "dependencies": {
+        "mkdirp": {
+          "version": "0.5.1",
+          "resolved": "http://registry.npmjs.org/mkdirp/-/mkdirp-0.5.1.tgz",
+          "integrity": "sha1-MAV0OOrGz3+MR2fzhkjWaX11yQM=",
+          "optional": true,
+          "requires": {
+            "minimist": "0.0.8"
+          }
+        },
+        "rimraf": {
+          "version": "2.4.5",
+          "resolved": "http://registry.npmjs.org/rimraf/-/rimraf-2.4.5.tgz",
+          "integrity": "sha1-7nEM5dk6j9uFb7Xqj/Di11k0sto=",
+          "optional": true,
+          "requires": {
+            "glob": "^6.0.1"
+          }
+        }
+      }
+    },
+    "nan": {
+      "version": "2.11.1",
+      "resolved": "https://registry.npmjs.org/nan/-/nan-2.11.1.tgz",
+      "integrity": "sha512-iji6k87OSXa0CcrLl9z+ZiYSuR2o+c0bGuNmXdrhTQTakxytAFsC56SArGYoiHlJlFoHSnvmhpceZJaXkVuOtA==",
+      "optional": true
+    },
+    "ncp": {
+      "version": "2.0.0",
+      "resolved": "http://registry.npmjs.org/ncp/-/ncp-2.0.0.tgz",
+      "integrity": "sha1-GVoh1sRuNh0vsSgbo4uR6d9727M=",
+      "optional": true
+    },
+    "negotiator": {
+      "version": "0.6.1",
+      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.1.tgz",
+      "integrity": "sha1-KzJxhOiZIQEXeyhWP7XnECrNDKk="
+    },
+    "node-uuid": {
+      "version": "1.4.1",
+      "resolved": "https://registry.npmjs.org/node-uuid/-/node-uuid-1.4.1.tgz",
+      "integrity": "sha1-Oa71EOWImj3KnIlbUGxzquG6wEg="
+    },
+    "nodeunit": {
+      "version": "0.7.4",
+      "resolved": "https://registry.npmjs.org/nodeunit/-/nodeunit-0.7.4.tgz",
+      "integrity": "sha1-yQje9/KZ++Zf96yIh4KVXEaq6fg=",
+      "dev": true,
+      "requires": {
+        "tap": ">=0.2.3"
+      }
+    },
+    "number-is-nan": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/number-is-nan/-/number-is-nan-1.0.1.tgz",
+      "integrity": "sha1-CXtgK1NCKlIsGvuHkDGDNpQaAR0="
+    },
+    "nyc": {
+      "version": "13.1.0",
+      "resolved": "https://registry.npmjs.org/nyc/-/nyc-13.1.0.tgz",
+      "integrity": "sha512-3GyY6TpQ58z9Frpv4GMExE1SV2tAgYqC7HSy2omEhNiCT3mhT9NyiOvIE8zkbuJVFzmvvNTnE4h/7/wQae7xLg==",
+      "dev": true,
+      "requires": {
+        "archy": "^1.0.0",
+        "arrify": "^1.0.1",
+        "caching-transform": "^2.0.0",
+        "convert-source-map": "^1.6.0",
+        "debug-log": "^1.0.1",
+        "find-cache-dir": "^2.0.0",
+        "find-up": "^3.0.0",
+        "foreground-child": "^1.5.6",
+        "glob": "^7.1.3",
+        "istanbul-lib-coverage": "^2.0.1",
+        "istanbul-lib-hook": "^2.0.1",
+        "istanbul-lib-instrument": "^3.0.0",
+        "istanbul-lib-report": "^2.0.2",
+        "istanbul-lib-source-maps": "^2.0.1",
+        "istanbul-reports": "^2.0.1",
+        "make-dir": "^1.3.0",
+        "merge-source-map": "^1.1.0",
+        "resolve-from": "^4.0.0",
+        "rimraf": "^2.6.2",
+        "signal-exit": "^3.0.2",
+        "spawn-wrap": "^1.4.2",
+        "test-exclude": "^5.0.0",
+        "uuid": "^3.3.2",
+        "yargs": "11.1.0",
+        "yargs-parser": "^9.0.2"
+      },
+      "dependencies": {
+        "align-text": {
+          "version": "0.1.4",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "kind-of": "^3.0.2",
+            "longest": "^1.0.1",
+            "repeat-string": "^1.5.2"
+          }
+        },
+        "amdefine": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "ansi-regex": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "append-transform": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "default-require-extensions": "^2.0.0"
+          }
+        },
+        "archy": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "arrify": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "async": {
+          "version": "1.5.2",
+          "bundled": true,
+          "dev": true
+        },
+        "balanced-match": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "brace-expansion": {
+          "version": "1.1.11",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "balanced-match": "^1.0.0",
+            "concat-map": "0.0.1"
+          }
+        },
+        "builtin-modules": {
+          "version": "1.1.1",
+          "bundled": true,
+          "dev": true
+        },
+        "caching-transform": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "make-dir": "^1.0.0",
+            "md5-hex": "^2.0.0",
+            "package-hash": "^2.0.0",
+            "write-file-atomic": "^2.0.0"
+          }
+        },
+        "camelcase": {
+          "version": "1.2.1",
+          "bundled": true,
+          "dev": true,
+          "optional": true
+        },
+        "center-align": {
+          "version": "0.1.3",
+          "bundled": true,
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "align-text": "^0.1.3",
+            "lazy-cache": "^1.0.3"
+          }
+        },
+        "cliui": {
+          "version": "2.1.0",
+          "bundled": true,
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "center-align": "^0.1.1",
+            "right-align": "^0.1.1",
+            "wordwrap": "0.0.2"
+          },
+          "dependencies": {
+            "wordwrap": {
+              "version": "0.0.2",
+              "bundled": true,
+              "dev": true,
+              "optional": true
+            }
+          }
+        },
+        "code-point-at": {
+          "version": "1.1.0",
+          "bundled": true,
+          "dev": true
+        },
+        "commondir": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "concat-map": {
+          "version": "0.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "convert-source-map": {
+          "version": "1.6.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "safe-buffer": "~5.1.1"
+          }
+        },
+        "cross-spawn": {
+          "version": "4.0.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "lru-cache": "^4.0.1",
+            "which": "^1.2.9"
+          }
+        },
+        "debug": {
+          "version": "3.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "ms": "2.0.0"
+          }
+        },
+        "debug-log": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "decamelize": {
+          "version": "1.2.0",
+          "bundled": true,
+          "dev": true
+        },
+        "default-require-extensions": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "strip-bom": "^3.0.0"
+          }
+        },
+        "error-ex": {
+          "version": "1.3.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "is-arrayish": "^0.2.1"
+          }
+        },
+        "es6-error": {
+          "version": "4.1.1",
+          "bundled": true,
+          "dev": true
+        },
+        "execa": {
+          "version": "0.7.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "cross-spawn": "^5.0.1",
+            "get-stream": "^3.0.0",
+            "is-stream": "^1.1.0",
+            "npm-run-path": "^2.0.0",
+            "p-finally": "^1.0.0",
+            "signal-exit": "^3.0.0",
+            "strip-eof": "^1.0.0"
+          },
+          "dependencies": {
+            "cross-spawn": {
+              "version": "5.1.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "lru-cache": "^4.0.1",
+                "shebang-command": "^1.2.0",
+                "which": "^1.2.9"
+              }
+            }
+          }
+        },
+        "find-cache-dir": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "commondir": "^1.0.1",
+            "make-dir": "^1.0.0",
+            "pkg-dir": "^3.0.0"
+          }
+        },
+        "find-up": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "locate-path": "^3.0.0"
+          }
+        },
+        "foreground-child": {
+          "version": "1.5.6",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "cross-spawn": "^4",
+            "signal-exit": "^3.0.0"
+          }
+        },
+        "fs.realpath": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "get-caller-file": {
+          "version": "1.0.3",
+          "bundled": true,
+          "dev": true
+        },
+        "get-stream": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "glob": {
+          "version": "7.1.3",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "fs.realpath": "^1.0.0",
+            "inflight": "^1.0.4",
+            "inherits": "2",
+            "minimatch": "^3.0.4",
+            "once": "^1.3.0",
+            "path-is-absolute": "^1.0.0"
+          }
+        },
+        "graceful-fs": {
+          "version": "4.1.11",
+          "bundled": true,
+          "dev": true
+        },
+        "handlebars": {
+          "version": "4.0.11",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "async": "^1.4.0",
+            "optimist": "^0.6.1",
+            "source-map": "^0.4.4",
+            "uglify-js": "^2.6"
+          },
+          "dependencies": {
+            "source-map": {
+              "version": "0.4.4",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "amdefine": ">=0.0.4"
+              }
+            }
+          }
+        },
+        "has-flag": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "hosted-git-info": {
+          "version": "2.7.1",
+          "bundled": true,
+          "dev": true
+        },
+        "imurmurhash": {
+          "version": "0.1.4",
+          "bundled": true,
+          "dev": true
+        },
+        "inflight": {
+          "version": "1.0.6",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "once": "^1.3.0",
+            "wrappy": "1"
+          }
+        },
+        "inherits": {
+          "version": "2.0.3",
+          "bundled": true,
+          "dev": true
+        },
+        "invert-kv": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "is-arrayish": {
+          "version": "0.2.1",
+          "bundled": true,
+          "dev": true
+        },
+        "is-buffer": {
+          "version": "1.1.6",
+          "bundled": true,
+          "dev": true
+        },
+        "is-builtin-module": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "builtin-modules": "^1.0.0"
+          }
+        },
+        "is-fullwidth-code-point": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "is-stream": {
+          "version": "1.1.0",
+          "bundled": true,
+          "dev": true
+        },
+        "isexe": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "istanbul-lib-coverage": {
+          "version": "2.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "istanbul-lib-hook": {
+          "version": "2.0.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "append-transform": "^1.0.0"
+          }
+        },
+        "istanbul-lib-report": {
+          "version": "2.0.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "istanbul-lib-coverage": "^2.0.1",
+            "make-dir": "^1.3.0",
+            "supports-color": "^5.4.0"
+          }
+        },
+        "istanbul-lib-source-maps": {
+          "version": "2.0.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "debug": "^3.1.0",
+            "istanbul-lib-coverage": "^2.0.1",
+            "make-dir": "^1.3.0",
+            "rimraf": "^2.6.2",
+            "source-map": "^0.6.1"
+          },
+          "dependencies": {
+            "source-map": {
+              "version": "0.6.1",
+              "bundled": true,
+              "dev": true
+            }
+          }
+        },
+        "istanbul-reports": {
+          "version": "2.0.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "handlebars": "^4.0.11"
+          }
+        },
+        "json-parse-better-errors": {
+          "version": "1.0.2",
+          "bundled": true,
+          "dev": true
+        },
+        "kind-of": {
+          "version": "3.2.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "is-buffer": "^1.1.5"
+          }
+        },
+        "lazy-cache": {
+          "version": "1.0.4",
+          "bundled": true,
+          "dev": true,
+          "optional": true
+        },
+        "lcid": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "invert-kv": "^1.0.0"
+          }
+        },
+        "load-json-file": {
+          "version": "4.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "graceful-fs": "^4.1.2",
+            "parse-json": "^4.0.0",
+            "pify": "^3.0.0",
+            "strip-bom": "^3.0.0"
+          }
+        },
+        "locate-path": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "p-locate": "^3.0.0",
+            "path-exists": "^3.0.0"
+          }
+        },
+        "lodash.flattendeep": {
+          "version": "4.4.0",
+          "bundled": true,
+          "dev": true
+        },
+        "longest": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "lru-cache": {
+          "version": "4.1.3",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "pseudomap": "^1.0.2",
+            "yallist": "^2.1.2"
+          }
+        },
+        "make-dir": {
+          "version": "1.3.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "pify": "^3.0.0"
+          }
+        },
+        "md5-hex": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "md5-o-matic": "^0.1.1"
+          }
+        },
+        "md5-o-matic": {
+          "version": "0.1.1",
+          "bundled": true,
+          "dev": true
+        },
+        "mem": {
+          "version": "1.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "mimic-fn": "^1.0.0"
+          }
+        },
+        "merge-source-map": {
+          "version": "1.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "source-map": "^0.6.1"
+          },
+          "dependencies": {
+            "source-map": {
+              "version": "0.6.1",
+              "bundled": true,
+              "dev": true
+            }
+          }
+        },
+        "mimic-fn": {
+          "version": "1.2.0",
+          "bundled": true,
+          "dev": true
+        },
+        "minimatch": {
+          "version": "3.0.4",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "brace-expansion": "^1.1.7"
+          }
+        },
+        "minimist": {
+          "version": "0.0.10",
+          "bundled": true,
+          "dev": true
+        },
+        "mkdirp": {
+          "version": "0.5.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "minimist": "0.0.8"
+          },
+          "dependencies": {
+            "minimist": {
+              "version": "0.0.8",
+              "bundled": true,
+              "dev": true
+            }
+          }
+        },
+        "ms": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "normalize-package-data": {
+          "version": "2.4.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "hosted-git-info": "^2.1.4",
+            "is-builtin-module": "^1.0.0",
+            "semver": "2 || 3 || 4 || 5",
+            "validate-npm-package-license": "^3.0.1"
+          }
+        },
+        "npm-run-path": {
+          "version": "2.0.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "path-key": "^2.0.0"
+          }
+        },
+        "number-is-nan": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "once": {
+          "version": "1.4.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "wrappy": "1"
+          }
+        },
+        "optimist": {
+          "version": "0.6.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "minimist": "~0.0.1",
+            "wordwrap": "~0.0.2"
+          }
+        },
+        "os-homedir": {
+          "version": "1.0.2",
+          "bundled": true,
+          "dev": true
+        },
+        "os-locale": {
+          "version": "2.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "execa": "^0.7.0",
+            "lcid": "^1.0.0",
+            "mem": "^1.1.0"
+          }
+        },
+        "p-finally": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "p-limit": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "p-try": "^2.0.0"
+          }
+        },
+        "p-locate": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "p-limit": "^2.0.0"
+          }
+        },
+        "p-try": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "package-hash": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "graceful-fs": "^4.1.11",
+            "lodash.flattendeep": "^4.4.0",
+            "md5-hex": "^2.0.0",
+            "release-zalgo": "^1.0.0"
+          }
+        },
+        "parse-json": {
+          "version": "4.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "error-ex": "^1.3.1",
+            "json-parse-better-errors": "^1.0.1"
+          }
+        },
+        "path-exists": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "path-is-absolute": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "path-key": {
+          "version": "2.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "path-type": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "pify": "^3.0.0"
+          }
+        },
+        "pify": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "pkg-dir": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "find-up": "^3.0.0"
+          }
+        },
+        "pseudomap": {
+          "version": "1.0.2",
+          "bundled": true,
+          "dev": true
+        },
+        "read-pkg": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "load-json-file": "^4.0.0",
+            "normalize-package-data": "^2.3.2",
+            "path-type": "^3.0.0"
+          }
+        },
+        "read-pkg-up": {
+          "version": "4.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "find-up": "^3.0.0",
+            "read-pkg": "^3.0.0"
+          }
+        },
+        "release-zalgo": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "es6-error": "^4.0.1"
+          }
+        },
+        "repeat-string": {
+          "version": "1.6.1",
+          "bundled": true,
+          "dev": true
+        },
+        "require-directory": {
+          "version": "2.1.1",
+          "bundled": true,
+          "dev": true
+        },
+        "require-main-filename": {
+          "version": "1.0.1",
+          "bundled": true,
+          "dev": true
+        },
+        "resolve-from": {
+          "version": "4.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "right-align": {
+          "version": "0.1.3",
+          "bundled": true,
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "align-text": "^0.1.1"
+          }
+        },
+        "rimraf": {
+          "version": "2.6.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "glob": "^7.0.5"
+          }
+        },
+        "safe-buffer": {
+          "version": "5.1.2",
+          "bundled": true,
+          "dev": true
+        },
+        "semver": {
+          "version": "5.5.0",
+          "bundled": true,
+          "dev": true
+        },
+        "set-blocking": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "shebang-command": {
+          "version": "1.2.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "shebang-regex": "^1.0.0"
+          }
+        },
+        "shebang-regex": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "signal-exit": {
+          "version": "3.0.2",
+          "bundled": true,
+          "dev": true
+        },
+        "source-map": {
+          "version": "0.5.7",
+          "bundled": true,
+          "dev": true,
+          "optional": true
+        },
+        "spawn-wrap": {
+          "version": "1.4.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "foreground-child": "^1.5.6",
+            "mkdirp": "^0.5.0",
+            "os-homedir": "^1.0.1",
+            "rimraf": "^2.6.2",
+            "signal-exit": "^3.0.2",
+            "which": "^1.3.0"
+          }
+        },
+        "spdx-correct": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "spdx-expression-parse": "^3.0.0",
+            "spdx-license-ids": "^3.0.0"
+          }
+        },
+        "spdx-exceptions": {
+          "version": "2.1.0",
+          "bundled": true,
+          "dev": true
+        },
+        "spdx-expression-parse": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "spdx-exceptions": "^2.1.0",
+            "spdx-license-ids": "^3.0.0"
+          }
+        },
+        "spdx-license-ids": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "string-width": {
+          "version": "2.1.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "is-fullwidth-code-point": "^2.0.0",
+            "strip-ansi": "^4.0.0"
+          }
+        },
+        "strip-ansi": {
+          "version": "4.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "ansi-regex": "^3.0.0"
+          }
+        },
+        "strip-bom": {
+          "version": "3.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "strip-eof": {
+          "version": "1.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "supports-color": {
+          "version": "5.4.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "has-flag": "^3.0.0"
+          }
+        },
+        "test-exclude": {
+          "version": "5.0.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "arrify": "^1.0.1",
+            "minimatch": "^3.0.4",
+            "read-pkg-up": "^4.0.0",
+            "require-main-filename": "^1.0.1"
+          }
+        },
+        "uglify-js": {
+          "version": "2.8.29",
+          "bundled": true,
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "source-map": "~0.5.1",
+            "uglify-to-browserify": "~1.0.0",
+            "yargs": "~3.10.0"
+          },
+          "dependencies": {
+            "yargs": {
+              "version": "3.10.0",
+              "bundled": true,
+              "dev": true,
+              "optional": true,
+              "requires": {
+                "camelcase": "^1.0.2",
+                "cliui": "^2.1.0",
+                "decamelize": "^1.0.0",
+                "window-size": "0.1.0"
+              }
+            }
+          }
+        },
+        "uglify-to-browserify": {
+          "version": "1.0.2",
+          "bundled": true,
+          "dev": true,
+          "optional": true
+        },
+        "uuid": {
+          "version": "3.3.2",
+          "bundled": true,
+          "dev": true
+        },
+        "validate-npm-package-license": {
+          "version": "3.0.3",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "spdx-correct": "^3.0.0",
+            "spdx-expression-parse": "^3.0.0"
+          }
+        },
+        "which": {
+          "version": "1.3.1",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "isexe": "^2.0.0"
+          }
+        },
+        "which-module": {
+          "version": "2.0.0",
+          "bundled": true,
+          "dev": true
+        },
+        "window-size": {
+          "version": "0.1.0",
+          "bundled": true,
+          "dev": true,
+          "optional": true
+        },
+        "wordwrap": {
+          "version": "0.0.3",
+          "bundled": true,
+          "dev": true
+        },
+        "wrap-ansi": {
+          "version": "2.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "string-width": "^1.0.1",
+            "strip-ansi": "^3.0.1"
+          },
+          "dependencies": {
+            "ansi-regex": {
+              "version": "2.1.1",
+              "bundled": true,
+              "dev": true
+            },
+            "is-fullwidth-code-point": {
+              "version": "1.0.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "number-is-nan": "^1.0.0"
+              }
+            },
+            "string-width": {
+              "version": "1.0.2",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "code-point-at": "^1.0.0",
+                "is-fullwidth-code-point": "^1.0.0",
+                "strip-ansi": "^3.0.0"
+              }
+            },
+            "strip-ansi": {
+              "version": "3.0.1",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "ansi-regex": "^2.0.0"
+              }
+            }
+          }
+        },
+        "wrappy": {
+          "version": "1.0.2",
+          "bundled": true,
+          "dev": true
+        },
+        "write-file-atomic": {
+          "version": "2.3.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "graceful-fs": "^4.1.11",
+            "imurmurhash": "^0.1.4",
+            "signal-exit": "^3.0.2"
+          }
+        },
+        "y18n": {
+          "version": "3.2.1",
+          "bundled": true,
+          "dev": true
+        },
+        "yallist": {
+          "version": "2.1.2",
+          "bundled": true,
+          "dev": true
+        },
+        "yargs": {
+          "version": "11.1.0",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "cliui": "^4.0.0",
+            "decamelize": "^1.1.1",
+            "find-up": "^2.1.0",
+            "get-caller-file": "^1.0.1",
+            "os-locale": "^2.0.0",
+            "require-directory": "^2.1.1",
+            "require-main-filename": "^1.0.1",
+            "set-blocking": "^2.0.0",
+            "string-width": "^2.0.0",
+            "which-module": "^2.0.0",
+            "y18n": "^3.2.1",
+            "yargs-parser": "^9.0.2"
+          },
+          "dependencies": {
+            "cliui": {
+              "version": "4.1.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "string-width": "^2.1.1",
+                "strip-ansi": "^4.0.0",
+                "wrap-ansi": "^2.0.0"
+              }
+            },
+            "find-up": {
+              "version": "2.1.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "locate-path": "^2.0.0"
+              }
+            },
+            "locate-path": {
+              "version": "2.0.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "p-locate": "^2.0.0",
+                "path-exists": "^3.0.0"
+              }
+            },
+            "p-limit": {
+              "version": "1.3.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "p-try": "^1.0.0"
+              }
+            },
+            "p-locate": {
+              "version": "2.0.0",
+              "bundled": true,
+              "dev": true,
+              "requires": {
+                "p-limit": "^1.1.0"
+              }
+            },
+            "p-try": {
+              "version": "1.0.0",
+              "bundled": true,
+              "dev": true
+            }
+          }
+        },
+        "yargs-parser": {
+          "version": "9.0.2",
+          "bundled": true,
+          "dev": true,
+          "requires": {
+            "camelcase": "^4.1.0"
+          },
+          "dependencies": {
+            "camelcase": {
+              "version": "4.1.0",
+              "bundled": true,
+              "dev": true
+            }
+          }
+        }
+      }
+    },
+    "oauth-sign": {
+      "version": "0.9.0",
+      "resolved": "https://registry.npmjs.org/oauth-sign/-/oauth-sign-0.9.0.tgz",
+      "integrity": "sha512-fexhUFFPTGV8ybAtSIGbV6gOkSv8UtRbDBnAyLQw4QPKkgNlsH2ByPGtMUqdWkos6YCRmAqViwgZrJc/mRDzZQ==",
+      "dev": true
+    },
+    "object-assign": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-1.0.0.tgz",
+      "integrity": "sha1-5l3Idm07R7S4MHRlyDEdoDCwcKY="
+    },
+    "obuf": {
+      "version": "1.1.2",
+      "resolved": "https://registry.npmjs.org/obuf/-/obuf-1.1.2.tgz",
+      "integrity": "sha512-PX1wu0AmAdPqOL1mWhqmlOd8kOIZQwGZw6rh7uby9fTc5lhaOWFLX3I6R1hrF9k3zUY40e6igsLGkDXK92LJNg=="
+    },
+    "once": {
+      "version": "1.3.1",
+      "resolved": "https://registry.npmjs.org/once/-/once-1.3.1.tgz",
+      "integrity": "sha1-8/Pk2lt9J7XHMpae4+Z+cpRXsx8=",
+      "requires": {
+        "wrappy": "1"
+      }
+    },
+    "opener": {
+      "version": "1.5.1",
+      "resolved": "https://registry.npmjs.org/opener/-/opener-1.5.1.tgz",
+      "integrity": "sha512-goYSy5c2UXE4Ra1xixabeVh1guIX/ZV/YokJksb6q2lubWu6UbvPQ20p542/sFIll1nl8JnCyK9oBaOcCWXwvA==",
+      "dev": true
+    },
+    "os-homedir": {
+      "version": "1.0.2",
+      "resolved": "http://registry.npmjs.org/os-homedir/-/os-homedir-1.0.2.tgz",
+      "integrity": "sha1-/7xJiDNuDoM94MFox+8VISGqf7M=",
+      "dev": true
+    },
+    "own-or": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/own-or/-/own-or-1.0.0.tgz",
+      "integrity": "sha1-Tod/vtqaLsgAD7wLyuOWRe6L+Nw=",
+      "dev": true
+    },
+    "own-or-env": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/own-or-env/-/own-or-env-1.0.1.tgz",
+      "integrity": "sha512-y8qULRbRAlL6x2+M0vIe7jJbJx/kmUTzYonRAa2ayesR2qWLswninkVyeJe4x3IEXhdgoNodzjQRKAoEs6Fmrw==",
+      "dev": true,
+      "requires": {
+        "own-or": "^1.0.0"
+      }
+    },
+    "path-is-absolute": {
+      "version": "1.0.1",
+      "resolved": "http://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
+      "integrity": "sha1-F0uSaHNVNP+8es5r9TpanhtcX18="
+    },
+    "performance-now": {
+      "version": "2.1.0",
+      "resolved": "https://registry.npmjs.org/performance-now/-/performance-now-2.1.0.tgz",
+      "integrity": "sha1-Ywn04OX6kT7BxpMHrjZLSzd8nns=",
+      "dev": true
+    },
+    "pidusage": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/pidusage/-/pidusage-1.2.0.tgz",
+      "integrity": "sha512-OGo+iSOk44HRJ8q15AyG570UYxcm5u+R99DI8Khu8P3tKGkVu5EZX4ywHglWSTMNNXQ274oeGpYrvFEhDIFGPg=="
+    },
+    "posix-getopt": {
+      "version": "0.0.1",
+      "resolved": "https://registry.npmjs.org/posix-getopt/-/posix-getopt-0.0.1.tgz",
+      "integrity": "sha1-ejFb5Hm/aTpXKA+ycmDpsGueb18="
+    },
+    "precond": {
+      "version": "0.2.3",
+      "resolved": "https://registry.npmjs.org/precond/-/precond-0.2.3.tgz",
+      "integrity": "sha1-qpWRvKokkj8eD0hJ0kD0fvwQdaw="
+    },
+    "process-nextick-args": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.0.tgz",
+      "integrity": "sha512-MtEC1TqN0EU5nephaJ4rAtThHtC86dNN9qCuEhtshvpVBkAW5ZO7BASN9REnF9eoXGcRub+pFuKEpOHE+HbEMw=="
+    },
+    "progbar": {
+      "version": "1.1.0",
+      "resolved": "http://registry.npmjs.org/progbar/-/progbar-1.1.0.tgz",
+      "integrity": "sha1-soUvW/qzKJSnSShIETuumCfAKrM=",
+      "requires": {
+        "assert-plus": "~0.1.5",
+        "readable-stream": "~1.0.27-1",
+        "sprintf": "~0.1.3"
+      },
+      "dependencies": {
+        "readable-stream": {
+          "version": "1.0.34",
+          "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-1.0.34.tgz",
+          "integrity": "sha1-Elgg40vIQtLyqq+v5MKRbuMsFXw=",
+          "requires": {
+            "core-util-is": "~1.0.0",
+            "inherits": "~2.0.1",
+            "isarray": "0.0.1",
+            "string_decoder": "~0.10.x"
+          }
+        }
+      }
+    },
+    "pseudomap": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/pseudomap/-/pseudomap-1.0.2.tgz",
+      "integrity": "sha1-8FKijacOYYkX7wqKw0wa5aaChrM="
+    },
+    "psl": {
+      "version": "1.1.29",
+      "resolved": "https://registry.npmjs.org/psl/-/psl-1.1.29.tgz",
+      "integrity": "sha512-AeUmQ0oLN02flVHXWh9sSJF7mcdFq0ppid/JkErufc3hGIV/AMa8Fo9VgDo/cT2jFdOWoFvHp90qqBH54W+gjQ==",
+      "dev": true
+    },
+    "punycode": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.1.1.tgz",
+      "integrity": "sha512-XRsRjdf+j5ml+y/6GKHPZbrF/8p2Yga0JPtdqTIY2Xe5ohJPD9saDJJLPvp9+NSBprVvevdXZybnj2cv8OEd0A==",
+      "dev": true
+    },
+    "qs": {
+      "version": "6.5.2",
+      "resolved": "https://registry.npmjs.org/qs/-/qs-6.5.2.tgz",
+      "integrity": "sha512-N5ZAX4/LxJmF+7wN74pUD6qAh9/wnvdQcjq9TZjevvXzSUo7bfmw91saqMjzGS2xq91/odN2dW/WOl7qQHNDGA=="
+    },
+    "readable-stream": {
+      "version": "1.1.14",
+      "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-1.1.14.tgz",
+      "integrity": "sha1-fPTFTvZI44EwhMY23SB54WbAgdk=",
+      "requires": {
+        "core-util-is": "~1.0.0",
+        "inherits": "~2.0.1",
+        "isarray": "0.0.1",
+        "string_decoder": "~0.10.x"
+      }
+    },
+    "repeating": {
+      "version": "1.1.3",
+      "resolved": "https://registry.npmjs.org/repeating/-/repeating-1.1.3.tgz",
+      "integrity": "sha1-PUEUIYh3U3SU+X93+Xhfq4EPpKw=",
+      "requires": {
+        "is-finite": "^1.0.0"
+      }
+    },
+    "request": {
+      "version": "2.88.0",
+      "resolved": "https://registry.npmjs.org/request/-/request-2.88.0.tgz",
+      "integrity": "sha512-NAqBSrijGLZdM0WZNsInLJpkJokL72XYjUpnB0iwsRgxh7dB6COrHnTBNwN0E+lHDAJzu7kLAkDeY08z2/A0hg==",
+      "dev": true,
+      "requires": {
+        "aws-sign2": "~0.7.0",
+        "aws4": "^1.8.0",
+        "caseless": "~0.12.0",
+        "combined-stream": "~1.0.6",
+        "extend": "~3.0.2",
+        "forever-agent": "~0.6.1",
+        "form-data": "~2.3.2",
+        "har-validator": "~5.1.0",
+        "http-signature": "~1.2.0",
+        "is-typedarray": "~1.0.0",
+        "isstream": "~0.1.2",
+        "json-stringify-safe": "~5.0.1",
+        "mime-types": "~2.1.19",
+        "oauth-sign": "~0.9.0",
+        "performance-now": "^2.1.0",
+        "qs": "~6.5.2",
+        "safe-buffer": "^5.1.2",
+        "tough-cookie": "~2.4.3",
+        "tunnel-agent": "^0.6.0",
+        "uuid": "^3.3.2"
+      },
+      "dependencies": {
+        "punycode": {
+          "version": "1.4.1",
+          "resolved": "https://registry.npmjs.org/punycode/-/punycode-1.4.1.tgz",
+          "integrity": "sha1-wNWmOycYgArY4esPpSachN1BhF4=",
+          "dev": true
+        },
+        "tough-cookie": {
+          "version": "2.4.3",
+          "resolved": "https://registry.npmjs.org/tough-cookie/-/tough-cookie-2.4.3.tgz",
+          "integrity": "sha512-Q5srk/4vDM54WJsJio3XNn6K2sCG+CQ8G5Wz6bZhRZoAe/+TxjWB/GlFAnYEbkYVlON9FMk/fE3h2RLpPXo4lQ==",
+          "dev": true,
+          "requires": {
+            "psl": "^1.1.24",
+            "punycode": "^1.4.1"
+          }
+        }
+      }
+    },
+    "restify": {
+      "version": "7.2.2",
+      "resolved": "https://registry.npmjs.org/restify/-/restify-7.2.2.tgz",
+      "integrity": "sha512-BqLuTVsEM2QXWnQbCY10djrKFXF+ry2PtHA/JVqBZC0LEFf0zz0ipcvh5hPCdjFIRVDCgx0acw/fF63E3DWUlw==",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "bunyan": "^1.8.12",
+        "csv": "^1.1.1",
+        "dtrace-provider": "^0.8.1",
+        "escape-regexp-component": "^1.0.2",
+        "ewma": "^2.0.1",
+        "find-my-way": "^1.13.0",
+        "formidable": "^1.2.1",
+        "http-signature": "^1.2.0",
+        "lodash": "^4.17.10",
+        "lru-cache": "^4.1.3",
+        "mime": "^1.5.0",
+        "negotiator": "^0.6.1",
+        "once": "^1.4.0",
+        "pidusage": "^1.2.0",
+        "qs": "^6.5.2",
+        "restify-errors": "^5.0.0",
+        "semver": "^5.4.1",
+        "spdy": "^3.4.7",
+        "uuid": "^3.1.0",
+        "vasync": "^1.6.4",
+        "verror": "^1.10.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "once": {
+          "version": "1.4.0",
+          "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
+          "integrity": "sha1-WDsap3WWHUsROsF9nFC6753Xa9E=",
+          "requires": {
+            "wrappy": "1"
+          }
+        },
+        "restify-errors": {
+          "version": "5.0.0",
+          "resolved": "https://registry.npmjs.org/restify-errors/-/restify-errors-5.0.0.tgz",
+          "integrity": "sha512-+vby9Kxf7qlzvbZSTIEGkIixkeHG+pVCl34dk6eKnL+ua4pCezpdLT/1/eabzPZb65ADrgoc04jeWrrF1E1pvQ==",
+          "requires": {
+            "assert-plus": "^1.0.0",
+            "lodash": "^4.2.1",
+            "safe-json-stringify": "^1.0.3",
+            "verror": "^1.8.1"
+          }
+        },
+        "vasync": {
+          "version": "1.6.4",
+          "resolved": "https://registry.npmjs.org/vasync/-/vasync-1.6.4.tgz",
+          "integrity": "sha1-3+k2Fq0OeugBszKp2Iv8XNyOHR8=",
+          "requires": {
+            "verror": "1.6.0"
+          },
+          "dependencies": {
+            "verror": {
+              "version": "1.6.0",
+              "resolved": "https://registry.npmjs.org/verror/-/verror-1.6.0.tgz",
+              "integrity": "sha1-fROyex+swuLakEBetepuW90lLqU=",
+              "requires": {
+                "extsprintf": "1.2.0"
+              }
+            }
+          }
+        },
+        "verror": {
+          "version": "1.10.0",
+          "resolved": "https://registry.npmjs.org/verror/-/verror-1.10.0.tgz",
+          "integrity": "sha1-OhBcoXBTr1XW4nDB+CiGguGNpAA=",
+          "requires": {
+            "assert-plus": "^1.0.0",
+            "core-util-is": "1.0.2",
+            "extsprintf": "^1.2.0"
+          }
+        }
+      }
+    },
+    "restify-clients": {
+      "version": "1.6.0",
+      "resolved": "https://registry.npmjs.org/restify-clients/-/restify-clients-1.6.0.tgz",
+      "integrity": "sha1-HqrBdhhRYhBNzFRvlElQtwIp+OU=",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "backoff": "^2.4.1",
+        "bunyan": "^1.8.3",
+        "dtrace-provider": "^0.8.3",
+        "fast-safe-stringify": "^1.1.3",
+        "keep-alive-agent": "0.0.1",
+        "lodash": "^4.7.0",
+        "lru-cache": "^4.0.1",
+        "mime": "^1.3.4",
+        "once": "^1.3.2",
+        "restify-errors": "^3.1.0",
+        "semver": "^5.0.1",
+        "tunnel-agent": "^0.6.0",
+        "uuid": "^3.0.1"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "backoff": {
+          "version": "2.5.0",
+          "resolved": "https://registry.npmjs.org/backoff/-/backoff-2.5.0.tgz",
+          "integrity": "sha1-9hbtqdPktmuMp/ynn2lXIsX44m8=",
+          "requires": {
+            "precond": "0.2"
+          }
+        },
+        "once": {
+          "version": "1.4.0",
+          "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
+          "integrity": "sha1-WDsap3WWHUsROsF9nFC6753Xa9E=",
+          "requires": {
+            "wrappy": "1"
+          }
+        }
+      }
+    },
+    "restify-errors": {
+      "version": "3.1.0",
+      "resolved": "https://registry.npmjs.org/restify-errors/-/restify-errors-3.1.0.tgz",
+      "integrity": "sha1-BrVHlHeHTAhW14KhLIcH3NrVPxY=",
+      "requires": {
+        "assert-plus": "^0.2.0",
+        "lodash": "^3.10.1",
+        "verror": "^1.6.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "0.2.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-0.2.0.tgz",
+          "integrity": "sha1-104bh+ev/A24qttwIfP+SBAasjQ="
+        },
+        "lodash": {
+          "version": "3.10.1",
+          "resolved": "http://registry.npmjs.org/lodash/-/lodash-3.10.1.tgz",
+          "integrity": "sha1-W/Rejkm6QYnhfUgnid/RW9FAt7Y="
+        }
+      }
+    },
+    "ret": {
+      "version": "0.1.15",
+      "resolved": "https://registry.npmjs.org/ret/-/ret-0.1.15.tgz",
+      "integrity": "sha512-TTlYpa+OL+vMMNG24xSlQGEJ3B/RzEfUlLct7b5G/ytav+wPrplCpVMFuwzXbkecJrb6IYo1iFb0S9v37754mg=="
+    },
+    "rimraf": {
+      "version": "2.2.8",
+      "resolved": "http://registry.npmjs.org/rimraf/-/rimraf-2.2.8.tgz",
+      "integrity": "sha1-5Dm+Kq7jJzIZUnMPmaiSnk/FBYI="
+    },
+    "safe-buffer": {
+      "version": "5.1.2",
+      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
+      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g=="
+    },
+    "safe-json-stringify": {
+      "version": "1.2.0",
+      "resolved": "https://registry.npmjs.org/safe-json-stringify/-/safe-json-stringify-1.2.0.tgz",
+      "integrity": "sha512-gH8eh2nZudPQO6TytOvbxnuhYBOvDBBLW52tz5q6X58lJcd/tkmqFR+5Z9adS8aJtURSXWThWy/xJtJwixErvg==",
+      "optional": true
+    },
+    "safe-regex": {
+      "version": "1.1.0",
+      "resolved": "http://registry.npmjs.org/safe-regex/-/safe-regex-1.1.0.tgz",
+      "integrity": "sha1-QKNmnzsHfR6UPURinhV91IAjvy4=",
+      "requires": {
+        "ret": "~0.1.10"
+      }
+    },
+    "safer-buffer": {
+      "version": "2.1.2",
+      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
+      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg=="
+    },
+    "sdc-clients": {
+      "version": "git://github.com/joyent/node-sdc-clients.git#28209abf97928bb3e256ea17a7f532e1b75c6032",
+      "from": "git://github.com/joyent/node-sdc-clients.git#28209ab",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "async": "~0.9.0",
+        "backoff": "^2.4.1",
+        "bunyan": "^1.8.1",
+        "clone": "0.1.8",
+        "jsprim": "1.4.1",
+        "lomstream": "1.1.0",
+        "lru-cache": "2.3.0",
+        "once": "^1.3.1",
+        "restify-clients": "^1.6.0",
+        "restify-errors": "^3.0.0",
+        "smartdc-auth": "2.5.2",
+        "sshpk": "^1.10.1",
+        "vasync": "^1.6.2",
+        "verror": "^1.6.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "backoff": {
+          "version": "2.5.0",
+          "resolved": "https://registry.npmjs.org/backoff/-/backoff-2.5.0.tgz",
+          "integrity": "sha1-9hbtqdPktmuMp/ynn2lXIsX44m8=",
+          "requires": {
+            "precond": "0.2"
+          }
+        },
+        "lru-cache": {
+          "version": "2.3.0",
+          "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-2.3.0.tgz",
+          "integrity": "sha1-HO4S1anyjtHuN+nDMriIjmuFQSo="
+        }
+      }
+    },
+    "select-hose": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/select-hose/-/select-hose-2.0.0.tgz",
+      "integrity": "sha1-Yl2GWPhlr0Psliv8N2o3NZpJlMo="
+    },
+    "semver": {
+      "version": "5.6.0",
+      "resolved": "https://registry.npmjs.org/semver/-/semver-5.6.0.tgz",
+      "integrity": "sha512-RS9R6R35NYgQn++fkDWaOmqGoj4Ek9gGs+DPxNUZKuwE183xjJroKvyo1IzVFeXvUrvmALy6FWD5xrdJT25gMg=="
+    },
+    "semver-store": {
+      "version": "0.3.0",
+      "resolved": "https://registry.npmjs.org/semver-store/-/semver-store-0.3.0.tgz",
+      "integrity": "sha512-TcZvGMMy9vodEFSse30lWinkj+JgOBvPn8wRItpQRSayhc+4ssDs335uklkfvQQJgL/WvmHLVj4Ycv2s7QCQMg=="
+    },
+    "signal-exit": {
+      "version": "3.0.2",
+      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.2.tgz",
+      "integrity": "sha1-tf3AjxKH6hF4Yo5BXiUTK3NkbG0=",
+      "dev": true
+    },
+    "smartdc-auth": {
+      "version": "2.5.2",
+      "resolved": "https://registry.npmjs.org/smartdc-auth/-/smartdc-auth-2.5.2.tgz",
+      "integrity": "sha1-dPNRGVi25axPHFWJktpgSeHfwDU=",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "bunyan": "1.5.1",
+        "clone": "0.1.5",
+        "dashdash": "1.10.1",
+        "http-signature": "^1.0.2",
+        "once": "1.3.0",
+        "sshpk": "^1.8.3",
+        "sshpk-agent": "^1.3.0",
+        "vasync": "1.4.3"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "bunyan": {
+          "version": "1.5.1",
+          "resolved": "https://registry.npmjs.org/bunyan/-/bunyan-1.5.1.tgz",
+          "integrity": "sha1-X259RMQ7lS9WsPQTCeOrEjkbTi0=",
+          "requires": {
+            "dtrace-provider": "~0.6",
+            "mv": "~2",
+            "safe-json-stringify": "~1"
+          }
+        },
+        "clone": {
+          "version": "0.1.5",
+          "resolved": "https://registry.npmjs.org/clone/-/clone-0.1.5.tgz",
+          "integrity": "sha1-RvKRQ9B2bWY9vX+At1IKFXg9IEI="
+        },
+        "dashdash": {
+          "version": "1.10.1",
+          "resolved": "https://registry.npmjs.org/dashdash/-/dashdash-1.10.1.tgz",
+          "integrity": "sha1-Cr8a+JqPUSmoHxjCs1sh3yJiL2A=",
+          "requires": {
+            "assert-plus": "0.1.x"
+          },
+          "dependencies": {
+            "assert-plus": {
+              "version": "0.1.5",
+              "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-0.1.5.tgz",
+              "integrity": "sha1-7nQAlBMALYTOxyGcasgRgS5yMWA="
+            }
+          }
+        },
+        "dtrace-provider": {
+          "version": "0.6.0",
+          "resolved": "https://registry.npmjs.org/dtrace-provider/-/dtrace-provider-0.6.0.tgz",
+          "integrity": "sha1-CweNVReTfYcxAUUtkUZzdVe3XlE=",
+          "optional": true,
+          "requires": {
+            "nan": "^2.0.8"
+          }
+        },
+        "extsprintf": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.0.0.tgz",
+          "integrity": "sha1-TVi4Fazlvr/E6/A8+YsKdgSpm4Y="
+        },
+        "json-schema": {
+          "version": "0.2.2",
+          "resolved": "https://registry.npmjs.org/json-schema/-/json-schema-0.2.2.tgz",
+          "integrity": "sha1-UDVPGfYDkXxpX3C4Wvp3w7DyNQY="
+        },
+        "jsprim": {
+          "version": "0.3.0",
+          "resolved": "https://registry.npmjs.org/jsprim/-/jsprim-0.3.0.tgz",
+          "integrity": "sha1-zRNGbqJIDb2DlqVw1H0x3aR2+LE=",
+          "requires": {
+            "extsprintf": "1.0.0",
+            "json-schema": "0.2.2",
+            "verror": "1.3.3"
+          },
+          "dependencies": {
+            "verror": {
+              "version": "1.3.3",
+              "resolved": "https://registry.npmjs.org/verror/-/verror-1.3.3.tgz",
+              "integrity": "sha1-impKw6jHdLb2h/7OSb3/14VS4s0=",
+              "requires": {
+                "extsprintf": "1.0.0"
+              }
+            }
+          }
+        },
+        "once": {
+          "version": "1.3.0",
+          "resolved": "https://registry.npmjs.org/once/-/once-1.3.0.tgz",
+          "integrity": "sha1-FRr4a/wfCMS58H0GqyUP/L61ZYE="
+        },
+        "vasync": {
+          "version": "1.4.3",
+          "resolved": "https://registry.npmjs.org/vasync/-/vasync-1.4.3.tgz",
+          "integrity": "sha1-yG1S4rcWE9Ke7fFZ8xNdvnSc7jc=",
+          "requires": {
+            "jsprim": "0.3.0",
+            "verror": "1.1.0"
+          }
+        },
+        "verror": {
+          "version": "1.1.0",
+          "resolved": "https://registry.npmjs.org/verror/-/verror-1.1.0.tgz",
+          "integrity": "sha1-KktOsUogcFHnWm+U7lExW/FzobA=",
+          "requires": {
+            "extsprintf": "1.0.0"
+          }
+        }
+      }
+    },
+    "source-map": {
+      "version": "0.5.7",
+      "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.5.7.tgz",
+      "integrity": "sha1-igOdLRAh0i0eoUyA2OpGi6LvP8w=",
+      "dev": true
+    },
+    "source-map-support": {
+      "version": "0.5.9",
+      "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.9.tgz",
+      "integrity": "sha512-gR6Rw4MvUlYy83vP0vxoVNzM6t8MUXqNuRsuBmBHQDu1Fh6X015FrLdgoDKcNdkwGubozq0P4N0Q37UyFVr1EA==",
+      "dev": true,
+      "requires": {
+        "buffer-from": "^1.0.0",
+        "source-map": "^0.6.0"
+      },
+      "dependencies": {
+        "source-map": {
+          "version": "0.6.1",
+          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
+          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
+          "dev": true
+        }
+      }
+    },
+    "spdy": {
+      "version": "3.4.7",
+      "resolved": "https://registry.npmjs.org/spdy/-/spdy-3.4.7.tgz",
+      "integrity": "sha1-Qv9B7OXMD5mjpsKKq7c/XDsDrLw=",
+      "requires": {
+        "debug": "^2.6.8",
+        "handle-thing": "^1.2.5",
+        "http-deceiver": "^1.2.7",
+        "safe-buffer": "^5.0.1",
+        "select-hose": "^2.0.0",
+        "spdy-transport": "^2.0.18"
+      }
+    },
+    "spdy-transport": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/spdy-transport/-/spdy-transport-2.1.1.tgz",
+      "integrity": "sha512-q7D8c148escoB3Z7ySCASadkegMmUZW8Wb/Q1u0/XBgDKMO880rLQDj8Twiew/tYi7ghemKUi/whSYOwE17f5Q==",
+      "requires": {
+        "debug": "^2.6.8",
+        "detect-node": "^2.0.3",
+        "hpack.js": "^2.1.6",
+        "obuf": "^1.1.1",
+        "readable-stream": "^2.2.9",
+        "safe-buffer": "^5.0.1",
+        "wbuf": "^1.7.2"
+      },
+      "dependencies": {
+        "isarray": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
+          "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE="
+        },
+        "readable-stream": {
+          "version": "2.3.6",
+          "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.3.6.tgz",
+          "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
+          "requires": {
+            "core-util-is": "~1.0.0",
+            "inherits": "~2.0.3",
+            "isarray": "~1.0.0",
+            "process-nextick-args": "~2.0.0",
+            "safe-buffer": "~5.1.1",
+            "string_decoder": "~1.1.1",
+            "util-deprecate": "~1.0.1"
+          }
+        },
+        "string_decoder": {
+          "version": "1.1.1",
+          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
+          "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
+          "requires": {
+            "safe-buffer": "~5.1.0"
+          }
+        }
+      }
+    },
+    "sprintf": {
+      "version": "0.1.5",
+      "resolved": "https://registry.npmjs.org/sprintf/-/sprintf-0.1.5.tgz",
+      "integrity": "sha1-j4PjmpMXwaUCy324BQ5Rxnn27c8="
+    },
+    "sprintf-js": {
+      "version": "1.0.3",
+      "resolved": "https://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
+      "integrity": "sha1-BOaSb2YolTVPPdAVIDYzuFcpfiw=",
+      "dev": true
+    },
+    "sshpk": {
+      "version": "1.15.2",
+      "resolved": "https://registry.npmjs.org/sshpk/-/sshpk-1.15.2.tgz",
+      "integrity": "sha512-Ra/OXQtuh0/enyl4ETZAfTaeksa6BXks5ZcjpSUNrjBr0DvrJKX+1fsKDPpT9TBXgHAFsa4510aNVgI8g/+SzA==",
+      "requires": {
+        "asn1": "~0.2.3",
+        "assert-plus": "^1.0.0",
+        "bcrypt-pbkdf": "^1.0.0",
+        "dashdash": "^1.12.0",
+        "ecc-jsbn": "~0.1.1",
+        "getpass": "^0.1.1",
+        "jsbn": "~0.1.0",
+        "safer-buffer": "^2.0.2",
+        "tweetnacl": "~0.14.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        }
+      }
+    },
+    "sshpk-agent": {
+      "version": "1.7.0",
+      "resolved": "https://registry.npmjs.org/sshpk-agent/-/sshpk-agent-1.7.0.tgz",
+      "integrity": "sha512-zR4GV5XYSypCusFzfTeTSXVqrFJJsK79Ec2KXZdo/x7qxBGSJPPZFtqMcqpXPaJ9VCK7Zn/vI+/kMrqeQILv4w==",
+      "requires": {
+        "assert-plus": "^1.0.0",
+        "mooremachine": "^2.0.1",
+        "readable-stream": "^2.1.4",
+        "sshpk": ">=1.14.0 < 1.15.0",
+        "verror": "^1.10.0"
+      },
+      "dependencies": {
+        "assert-plus": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+          "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "isarray": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
+          "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE="
+        },
+        "readable-stream": {
+          "version": "2.3.6",
+          "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.3.6.tgz",
+          "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
+          "requires": {
+            "core-util-is": "~1.0.0",
+            "inherits": "~2.0.3",
+            "isarray": "~1.0.0",
+            "process-nextick-args": "~2.0.0",
+            "safe-buffer": "~5.1.1",
+            "string_decoder": "~1.1.1",
+            "util-deprecate": "~1.0.1"
+          }
+        },
+        "sshpk": {
+          "version": "1.14.2",
+          "resolved": "https://registry.npmjs.org/sshpk/-/sshpk-1.14.2.tgz",
+          "integrity": "sha1-xvxhZIo9nE52T9P8306hBeSSupg=",
+          "requires": {
+            "asn1": "~0.2.3",
+            "assert-plus": "^1.0.0",
+            "bcrypt-pbkdf": "^1.0.0",
+            "dashdash": "^1.12.0",
+            "ecc-jsbn": "~0.1.1",
+            "getpass": "^0.1.1",
+            "jsbn": "~0.1.0",
+            "safer-buffer": "^2.0.2",
+            "tweetnacl": "~0.14.0"
+          }
+        },
+        "string_decoder": {
+          "version": "1.1.1",
+          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
+          "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
+          "requires": {
+            "safe-buffer": "~5.1.0"
+          }
+        },
+        "verror": {
+          "version": "1.10.0",
+          "resolved": "https://registry.npmjs.org/verror/-/verror-1.10.0.tgz",
+          "integrity": "sha1-OhBcoXBTr1XW4nDB+CiGguGNpAA=",
+          "requires": {
+            "assert-plus": "^1.0.0",
+            "core-util-is": "1.0.2",
+            "extsprintf": "^1.2.0"
+          }
+        }
+      }
+    },
+    "stack-utils": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-1.0.2.tgz",
+      "integrity": "sha512-MTX+MeG5U994cazkjd/9KNAapsHnibjMLnfXodlkXw76JEea0UiNzrqidzo1emMwk7w5Qhc9jd4Bn9TBb1MFwA==",
+      "dev": true
+    },
+    "stream-transform": {
+      "version": "0.2.2",
+      "resolved": "https://registry.npmjs.org/stream-transform/-/stream-transform-0.2.2.tgz",
+      "integrity": "sha1-dYZ0h/SVKPi/HYJJllh1PQLfeDg="
+    },
+    "string_decoder": {
+      "version": "0.10.31",
+      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-0.10.31.tgz",
+      "integrity": "sha1-YuIDvEF2bGwoyfyEMB2rHFMQ+pQ="
+    },
+    "strip-ansi": {
+      "version": "3.0.1",
+      "resolved": "http://registry.npmjs.org/strip-ansi/-/strip-ansi-3.0.1.tgz",
+      "integrity": "sha1-ajhfuIU9lS1f8F0Oiq+UJ43GPc8=",
+      "dev": true,
+      "requires": {
+        "ansi-regex": "^2.0.0"
+      }
+    },
+    "strsplit": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/strsplit/-/strsplit-1.0.0.tgz",
+      "integrity": "sha1-D97caOka3c/LLmvpwmJYGm6MKKo="
+    },
+    "supports-color": {
+      "version": "5.5.0",
+      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
+      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
+      "dev": true,
+      "requires": {
+        "has-flag": "^3.0.0"
+      }
+    },
+    "tabula": {
+      "version": "1.4.1",
+      "resolved": "https://registry.npmjs.org/tabula/-/tabula-1.4.1.tgz",
+      "integrity": "sha1-XvWV2rnFAhopGcxpIDul3XIxjy0=",
+      "requires": {
+        "assert-plus": "0.1.5",
+        "dashdash": "1.6.0",
+        "extsprintf": "1.2.0"
+      },
+      "dependencies": {
+        "dashdash": {
+          "version": "1.6.0",
+          "resolved": "https://registry.npmjs.org/dashdash/-/dashdash-1.6.0.tgz",
+          "integrity": "sha1-xLFDGPiO3q1HE6FpXigydqdUOWM=",
+          "requires": {
+            "assert-plus": "0.1.x"
+          }
+        }
+      }
+    },
+    "tap": {
+      "version": "12.1.0",
+      "resolved": "https://registry.npmjs.org/tap/-/tap-12.1.0.tgz",
+      "integrity": "sha512-sfN9XqRzG9NIC8qDxVLg2/RQbknBqVoeZ8G/g4e4PVpuCT6iqNuuK+ISF1gpXgUT8gY3kSrKcrwBbo3sEV5+YQ==",
+      "dev": true,
+      "requires": {
+        "bind-obj-methods": "^2.0.0",
+        "bluebird": "^3.5.3",
+        "browser-process-hrtime": "^1.0.0",
+        "capture-stack-trace": "^1.0.0",
+        "clean-yaml-object": "^0.1.0",
+        "color-support": "^1.1.0",
+        "coveralls": "^3.0.2",
+        "domain-browser": "^1.2.0",
+        "foreground-child": "^1.3.3",
+        "fs-exists-cached": "^1.0.0",
+        "function-loop": "^1.0.1",
+        "glob": "^7.1.3",
+        "isexe": "^2.0.0",
+        "js-yaml": "^3.12.0",
+        "minipass": "^2.3.5",
+        "mkdirp": "^0.5.1",
+        "nyc": "^13.1.0",
+        "opener": "^1.5.1",
+        "os-homedir": "^1.0.2",
+        "own-or": "^1.0.0",
+        "own-or-env": "^1.0.1",
+        "rimraf": "^2.6.2",
+        "signal-exit": "^3.0.0",
+        "source-map-support": "^0.5.9",
+        "stack-utils": "^1.0.0",
+        "tap-mocha-reporter": "^3.0.7",
+        "tap-parser": "^7.0.0",
+        "tmatch": "^4.0.0",
+        "trivial-deferred": "^1.0.1",
+        "tsame": "^2.0.1",
+        "write-file-atomic": "^2.3.0",
+        "yapool": "^1.0.0"
+      },
+      "dependencies": {
+        "glob": {
+          "version": "7.1.3",
+          "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.3.tgz",
+          "integrity": "sha512-vcfuiIxogLV4DlGBHIUOwI0IbrJ8HWPc4MU7HzviGeNho/UJDfi6B5p3sHeWIQ0KGIU0Jpxi5ZHxemQfLkkAwQ==",
+          "dev": true,
+          "requires": {
+            "fs.realpath": "^1.0.0",
+            "inflight": "^1.0.4",
+            "inherits": "2",
+            "minimatch": "^3.0.4",
+            "once": "^1.3.0",
+            "path-is-absolute": "^1.0.0"
+          }
+        },
+        "mkdirp": {
+          "version": "0.5.1",
+          "resolved": "http://registry.npmjs.org/mkdirp/-/mkdirp-0.5.1.tgz",
+          "integrity": "sha1-MAV0OOrGz3+MR2fzhkjWaX11yQM=",
+          "dev": true,
+          "requires": {
+            "minimist": "0.0.8"
+          }
+        },
+        "rimraf": {
+          "version": "2.6.2",
+          "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-2.6.2.tgz",
+          "integrity": "sha512-lreewLK/BlghmxtfH36YYVg1i8IAce4TI7oao75I1g245+6BctqTVQiBP3YUJ9C6DQOXJmkYR9X9fCLtCOJc5w==",
+          "dev": true,
+          "requires": {
+            "glob": "^7.0.5"
+          }
+        }
+      }
+    },
+    "tap-mocha-reporter": {
+      "version": "3.0.7",
+      "resolved": "https://registry.npmjs.org/tap-mocha-reporter/-/tap-mocha-reporter-3.0.7.tgz",
+      "integrity": "sha512-GHVXJ38C3oPRpM3YUc43JlGdpVZYiKeT1fmAd3HH2+J+ZWwsNAUFvRRdoGsXLw9+gU9o+zXpBqhS/oXyRQYwlA==",
+      "dev": true,
+      "requires": {
+        "color-support": "^1.1.0",
+        "debug": "^2.1.3",
+        "diff": "^1.3.2",
+        "escape-string-regexp": "^1.0.3",
+        "glob": "^7.0.5",
+        "js-yaml": "^3.3.1",
+        "readable-stream": "^2.1.5",
+        "tap-parser": "^5.1.0",
+        "unicode-length": "^1.0.0"
+      },
+      "dependencies": {
+        "glob": {
+          "version": "7.1.3",
+          "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.3.tgz",
+          "integrity": "sha512-vcfuiIxogLV4DlGBHIUOwI0IbrJ8HWPc4MU7HzviGeNho/UJDfi6B5p3sHeWIQ0KGIU0Jpxi5ZHxemQfLkkAwQ==",
+          "dev": true,
+          "requires": {
+            "fs.realpath": "^1.0.0",
+            "inflight": "^1.0.4",
+            "inherits": "2",
+            "minimatch": "^3.0.4",
+            "once": "^1.3.0",
+            "path-is-absolute": "^1.0.0"
+          }
+        },
+        "isarray": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
+          "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE=",
+          "dev": true,
+          "optional": true
+        },
+        "readable-stream": {
+          "version": "2.3.6",
+          "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.3.6.tgz",
+          "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "core-util-is": "~1.0.0",
+            "inherits": "~2.0.3",
+            "isarray": "~1.0.0",
+            "process-nextick-args": "~2.0.0",
+            "safe-buffer": "~5.1.1",
+            "string_decoder": "~1.1.1",
+            "util-deprecate": "~1.0.1"
+          }
+        },
+        "string_decoder": {
+          "version": "1.1.1",
+          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
+          "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
+          "dev": true,
+          "optional": true,
+          "requires": {
+            "safe-buffer": "~5.1.0"
+          }
+        },
+        "tap-parser": {
+          "version": "5.4.0",
+          "resolved": "https://registry.npmjs.org/tap-parser/-/tap-parser-5.4.0.tgz",
+          "integrity": "sha512-BIsIaGqv7uTQgTW1KLTMNPSEQf4zDDPgYOBRdgOfuB+JFOLRBfEu6cLa/KvMvmqggu1FKXDfitjLwsq4827RvA==",
+          "dev": true,
+          "requires": {
+            "events-to-array": "^1.0.1",
+            "js-yaml": "^3.2.7",
+            "readable-stream": "^2"
+          }
+        }
+      }
+    },
+    "tap-parser": {
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/tap-parser/-/tap-parser-7.0.0.tgz",
+      "integrity": "sha512-05G8/LrzqOOFvZhhAk32wsGiPZ1lfUrl+iV7+OkKgfofZxiceZWMHkKmow71YsyVQ8IvGBP2EjcIjE5gL4l5lA==",
+      "dev": true,
+      "requires": {
+        "events-to-array": "^1.0.1",
+        "js-yaml": "^3.2.7",
+        "minipass": "^2.2.0"
+      }
+    },
+    "tmatch": {
+      "version": "4.0.0",
+      "resolved": "https://registry.npmjs.org/tmatch/-/tmatch-4.0.0.tgz",
+      "integrity": "sha512-Ynn2Gsp+oCvYScQXeV+cCs7citRDilq0qDXA6tuvFwDgiYyyaq7D5vKUlAPezzZR5NDobc/QMeN6e5guOYmvxg==",
+      "dev": true
+    },
+    "to-fast-properties": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/to-fast-properties/-/to-fast-properties-2.0.0.tgz",
+      "integrity": "sha1-3F5pjL0HkmW8c+A3doGk5Og/YW4=",
+      "dev": true
+    },
+    "tough-cookie": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/tough-cookie/-/tough-cookie-2.0.0.tgz",
+      "integrity": "sha1-Qc4Icgs1z5C+sETdJgn7GekocY8="
+    },
+    "trim-right": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/trim-right/-/trim-right-1.0.1.tgz",
+      "integrity": "sha1-yy4SAwZ+DI3h9hQJS5/kVwTqYAM=",
+      "dev": true
+    },
+    "trivial-deferred": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/trivial-deferred/-/trivial-deferred-1.0.1.tgz",
+      "integrity": "sha1-N21NKdlR1jaKb3oK6FwvTV4GWPM=",
+      "dev": true
+    },
+    "tsame": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/tsame/-/tsame-2.0.1.tgz",
+      "integrity": "sha512-jxyxgKVKa4Bh5dPcO42TJL22lIvfd9LOVJwdovKOnJa4TLLrHxquK+DlGm4rkGmrcur+GRx+x4oW00O2pY/fFw==",
+      "dev": true
+    },
+    "tunnel-agent": {
+      "version": "0.6.0",
+      "resolved": "https://registry.npmjs.org/tunnel-agent/-/tunnel-agent-0.6.0.tgz",
+      "integrity": "sha1-J6XeoGs2sEoKmWZ3SykIaPD8QP0=",
+      "requires": {
+        "safe-buffer": "^5.0.1"
+      }
+    },
+    "tweetnacl": {
+      "version": "0.14.5",
+      "resolved": "https://registry.npmjs.org/tweetnacl/-/tweetnacl-0.14.5.tgz",
+      "integrity": "sha1-WuaBd/GS1EViadEIr6k/+HQ/T2Q="
+    },
+    "typedarray": {
+      "version": "0.0.6",
+      "resolved": "https://registry.npmjs.org/typedarray/-/typedarray-0.0.6.tgz",
+      "integrity": "sha1-hnrHTjhkGHsdPUfZlqeOxciDB3c="
+    },
+    "unicode-length": {
+      "version": "1.0.3",
+      "resolved": "https://registry.npmjs.org/unicode-length/-/unicode-length-1.0.3.tgz",
+      "integrity": "sha1-Wtp6f+1RhBpBijKM8UlHisg1irs=",
+      "dev": true,
+      "requires": {
+        "punycode": "^1.3.2",
+        "strip-ansi": "^3.0.1"
+      },
+      "dependencies": {
+        "punycode": {
+          "version": "1.4.1",
+          "resolved": "https://registry.npmjs.org/punycode/-/punycode-1.4.1.tgz",
+          "integrity": "sha1-wNWmOycYgArY4esPpSachN1BhF4=",
+          "dev": true
+        }
+      }
+    },
+    "uri-js": {
+      "version": "4.2.2",
+      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.2.2.tgz",
+      "integrity": "sha512-KY9Frmirql91X2Qgjry0Wd4Y+YTdrdZheS8TFwvkbLWf/G5KNJDCh6pKL5OZctEW4+0Baa5idK2ZQuELRwPznQ==",
+      "dev": true,
+      "requires": {
+        "punycode": "^2.1.0"
+      }
+    },
+    "util-deprecate": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
+      "integrity": "sha1-RQ1Nyfpw3nMnYvvS1KKJgUGaDM8="
+    },
+    "uuid": {
+      "version": "3.3.2",
+      "resolved": "https://registry.npmjs.org/uuid/-/uuid-3.3.2.tgz",
+      "integrity": "sha512-yXJmeNaw3DnnKAOKJE51sL/ZaYfWJRl1pK9dr19YFCu0ObS231AB1/LbqTKRAQ5kw8A90rA6fr4riOUpTZvQZA=="
+    },
+    "v8plus": {
+      "version": "1.0.3",
+      "resolved": "https://registry.npmjs.org/v8plus/-/v8plus-1.0.3.tgz",
+      "integrity": "sha1-DJ7SNfTLXLxQkccJm72amBavK+k=",
+      "requires": {
+        "posix-getopt": "~0.0.1"
+      }
+    },
+    "vasync": {
+      "version": "1.6.2",
+      "resolved": "https://registry.npmjs.org/vasync/-/vasync-1.6.2.tgz",
+      "integrity": "sha1-Vo7c9AsrXDWxzASMrQhd5HOXA/s=",
+      "requires": {
+        "verror": "1.1.0"
+      },
+      "dependencies": {
+        "extsprintf": {
+          "version": "1.0.0",
+          "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.0.0.tgz",
+          "integrity": "sha1-TVi4Fazlvr/E6/A8+YsKdgSpm4Y="
+        },
+        "verror": {
+          "version": "1.1.0",
+          "resolved": "https://registry.npmjs.org/verror/-/verror-1.1.0.tgz",
+          "integrity": "sha1-KktOsUogcFHnWm+U7lExW/FzobA=",
+          "requires": {
+            "extsprintf": "1.0.0"
+          }
+        }
+      }
+    },
+    "verror": {
+      "version": "1.6.0",
+      "resolved": "https://registry.npmjs.org/verror/-/verror-1.6.0.tgz",
+      "integrity": "sha1-fROyex+swuLakEBetepuW90lLqU=",
+      "requires": {
+        "extsprintf": "1.2.0"
+      }
+    },
+    "vstream": {
+      "version": "0.1.0",
+      "resolved": "https://registry.npmjs.org/vstream/-/vstream-0.1.0.tgz",
+      "integrity": "sha1-E1hxkPNOcrp6B+u6p+cKwUex+30=",
+      "requires": {
+        "assert-plus": "0.1.5",
+        "extsprintf": "1.2.0"
+      }
+    },
+    "wbuf": {
+      "version": "1.7.3",
+      "resolved": "https://registry.npmjs.org/wbuf/-/wbuf-1.7.3.tgz",
+      "integrity": "sha512-O84QOnr0icsbFGLS0O3bI5FswxzRr8/gHwWkDlQFskhSPryQXvrTMxjxGP4+iWYoauLoBvfDpkrOauZ+0iZpDA==",
+      "requires": {
+        "minimalistic-assert": "^1.0.0"
+      }
+    },
+    "which": {
+      "version": "1.3.1",
+      "resolved": "https://registry.npmjs.org/which/-/which-1.3.1.tgz",
+      "integrity": "sha512-HxJdYWq1MTIQbJ3nw0cqssHoTNU267KlrDuGZ1WYlxDStUtKUhOaJmh112/TZmHxxUfuJqPXSOm7tDyas0OSIQ==",
+      "dev": true,
+      "requires": {
+        "isexe": "^2.0.0"
+      }
+    },
+    "wrappy": {
+      "version": "1.0.2",
+      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
+      "integrity": "sha1-tSQ9jz7BqjXxNkYFvA0QNuMKtp8="
+    },
+    "write-file-atomic": {
+      "version": "2.3.0",
+      "resolved": "https://registry.npmjs.org/write-file-atomic/-/write-file-atomic-2.3.0.tgz",
+      "integrity": "sha512-xuPeK4OdjWqtfi59ylvVL0Yn35SF3zgcAcv7rBPFHVaEapaDr4GdGgm3j7ckTwH9wHL7fGmgfAnb0+THrHb8tA==",
+      "dev": true,
+      "requires": {
+        "graceful-fs": "^4.1.11",
+        "imurmurhash": "^0.1.4",
+        "signal-exit": "^3.0.2"
+      }
+    },
+    "www-authenticate": {
+      "version": "0.6.2",
+      "resolved": "https://registry.npmjs.org/www-authenticate/-/www-authenticate-0.6.2.tgz",
+      "integrity": "sha1-t6fUh73FqLQjpNj9X5xmGt3lDr8="
+    },
+    "yallist": {
+      "version": "2.1.2",
+      "resolved": "https://registry.npmjs.org/yallist/-/yallist-2.1.2.tgz",
+      "integrity": "sha1-HBH5IY8HYImkfdUS+TxmmaaoHVI="
+    },
+    "yapool": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/yapool/-/yapool-1.0.0.tgz",
+      "integrity": "sha1-9pPymjFbUNmp2iZGp6ZkXJaYW2o=",
+      "dev": true
+    }
+  }
+}
diff --git a/tools/buildimage/lib/imgadm/package.json b/tools/buildimage/lib/imgadm/package.json
new file mode 100644
index 0000000..6425d1e
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/package.json
@@ -0,0 +1,36 @@
+{
+  "name": "imgadm",
+  "description": "Manage SmartOS virtual machine images.",
+  "version": "3.9.0",
+  "author": "Joyent (joyent.com)",
+  "private": true,
+  "dependencies": {
+    "assert-plus": "0.1.5",
+    "async": "0.9.0",
+    "backoff": "2.4.0",
+    "bunyan": "1.8.12",
+    "cmdln": "3.2.1",
+    "concat-stream": "1.4.10",
+    "docker-registry-client": "3.2.10",
+    "extsprintf": "1.2.0",
+    "findit2": "2.2.3",
+    "imgmanifest": "3.0.0",
+    "lockfd": "2.0.1",
+    "mkdirp": "0.5.0",
+    "node-uuid": "1.4.1",
+    "once": "1.3.1",
+    "progbar": "1.1.0",
+    "restify": "7.2.2",
+    "rimraf": "2.2.8",
+    "sdc-clients": "git://github.com/joyent/node-sdc-clients.git#28209ab",
+    "tabula": "1.4.1",
+    "vasync": "1.6.2",
+    "verror": "1.6.0"
+  },
+  "devDependencies": {
+    "nodeunit": "0.7.4"
+  },
+  "engines": {
+    "node": ">=0.8"
+  }
+}
diff --git a/tools/buildimage/lib/imgadm/sbin/imgadm b/tools/buildimage/lib/imgadm/sbin/imgadm
new file mode 100755
index 0000000..5788553
--- /dev/null
+++ b/tools/buildimage/lib/imgadm/sbin/imgadm
@@ -0,0 +1,42 @@
+#!/usr/node/bin/node --abort_on_uncaught_exception
+/*
+ * CDDL HEADER START
+ *
+ * The contents of this file are subject to the terms of the
+ * Common Development and Distribution License, Version 1.0 only
+ * (the "License").  You may not use this file except in compliance
+ * with the License.
+ *
+ * You can obtain a copy of the license at http://smartos.org/CDDL
+ *
+ * See the License for the specific language governing permissions
+ * and limitations under the License.
+ *
+ * When distributing Covered Code, include this CDDL HEADER in each
+ * file.
+ *
+ * If applicable, add the following below this CDDL HEADER, with the
+ * fields enclosed by brackets "[]" replaced with your own identifying
+ * information: Portions Copyright [yyyy] [name of copyright owner]
+ *
+ * CDDL HEADER END
+ *
+ * Copyright (c) 2018, Joyent, Inc. All rights reserved.
+ *
+ * * *
+ * imgadm -- manage images on SmartOS
+ */
+
+var cmdln = require('cmdln');
+
+var CLI = require('../lib/cli');
+
+
+function main(argv) {
+    var cli = new CLI();
+    cmdln.main(cli, {argv: argv, showCode: true});
+}
+
+if (require.main === module) {
+    main(process.argv);
+}
diff --git a/tools/buildimage/package-lock.json b/tools/buildimage/package-lock.json
new file mode 100644
index 0000000..4f16859
--- /dev/null
+++ b/tools/buildimage/package-lock.json
@@ -0,0 +1,54 @@
+{
+    "name": "buildimage",
+    "version": "0.0.2",
+    "lockfileVersion": 1,
+    "requires": true,
+    "dependencies": {
+        "assert-plus": {
+            "version": "1.0.0",
+            "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
+            "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU="
+        },
+        "core-util-is": {
+            "version": "1.0.2",
+            "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
+            "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac="
+        },
+        "dashdash": {
+            "version": "1.14.1",
+            "resolved": "https://registry.npmjs.org/dashdash/-/dashdash-1.14.1.tgz",
+            "integrity": "sha1-hTz6D3y+L+1d4gMmuN1YEDX24vA=",
+            "requires": {
+                "assert-plus": "^1.0.0"
+            }
+        },
+        "extsprintf": {
+            "version": "1.4.0",
+            "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.4.0.tgz",
+            "integrity": "sha1-4mifjzVvrWLMplo6kcXfX5VRaS8="
+        },
+        "uuid": {
+            "version": "3.3.2",
+            "resolved": "https://registry.npmjs.org/uuid/-/uuid-3.3.2.tgz",
+            "integrity": "sha512-yXJmeNaw3DnnKAOKJE51sL/ZaYfWJRl1pK9dr19YFCu0ObS231AB1/LbqTKRAQ5kw8A90rA6fr4riOUpTZvQZA=="
+        },
+        "vasync": {
+            "version": "2.2.0",
+            "resolved": "https://registry.npmjs.org/vasync/-/vasync-2.2.0.tgz",
+            "integrity": "sha1-z951GGChWCLbOxMrxZsRakra8Bs=",
+            "requires": {
+                "verror": "1.10.0"
+            }
+        },
+        "verror": {
+            "version": "1.10.0",
+            "resolved": "https://registry.npmjs.org/verror/-/verror-1.10.0.tgz",
+            "integrity": "sha1-OhBcoXBTr1XW4nDB+CiGguGNpAA=",
+            "requires": {
+                "assert-plus": "^1.0.0",
+                "core-util-is": "1.0.2",
+                "extsprintf": "^1.2.0"
+            }
+        }
+    }
+}
diff --git a/tools/buildimage/package.json b/tools/buildimage/package.json
new file mode 100644
index 0000000..adb4f49
--- /dev/null
+++ b/tools/buildimage/package.json
@@ -0,0 +1,14 @@
+{
+    "name": "buildimage",
+    "description": "Triton Image Builder",
+    "version": "0.0.2",
+    "author": "Joyent (joyent.com)",
+    "private": true,
+    "dependencies": {
+        "assert-plus": "",
+        "dashdash": "",
+        "uuid": "",
+        "vasync": ""
+    },
+    "license": "MPL-2.0"
+}
diff --git a/tools/mk/Makefile.agent_prebuilt.defs b/tools/mk/Makefile.agent_prebuilt.defs
new file mode 100644
index 0000000..1edbfa7
--- /dev/null
+++ b/tools/mk/Makefile.agent_prebuilt.defs
@@ -0,0 +1,203 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Makefile.agent_prebuilt.defs: A Makefile for components that need to bundle
+# one of the Triton/Manta agents.
+#
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
+#
+
+#
+# This Makefile facilitates either downloading and caching a prebuilt agent
+# tarball or cloning a fresh copy of the required agent source repository
+# at the declared branch, building it once and caching the result.
+#
+# The supported agents are those commonly used by Triton or Manta components:
+#
+# TARGET     PKG              TARBALL
+# amon       amon-agent       amon/amon-agent-*.tgz
+# config     config-agent     config-agent/config-agent-*.tar.gz
+# mackerel   mackerel-pkg     mackerel/mackerel-pkg-*.tar.gz
+# minnow     minnow-pkg       minnow/minnow-pkg-*.tar.gz
+# registrar  registrar-pkg    registrar/registrar-pkg-*.tar.gz
+# waferlock  waferlock        waferlock/waferlock-pkg-*.tar.gz
+#
+# These can then be reused by the buildimage utility when assembling component
+# images. The agent deliverables get extracted to $(BUILDIMAGE_STAGEDIR)
+# during the build.
+#
+
+#
+# Usage:
+#
+# - `include deps/eng/tools/mk/Makefile.agent_prebuilt.defs` after this in your
+#   Makefile.
+# - `include deps/eng/tools/mk/Makefile.agent_prebuilt.targ` near the end of
+#   your Makefile.
+# - set $(AGENTS) to one or more of the TARGETS from the table above
+#
+# The 'buildimage' target will use $(AGENTS) to determine which agents to
+# build/download/extract to $(BUILDIMAGE_STAGEDIR) prior to assembling the
+# image.
+#
+
+#
+# When including this Makefile, you MAY specify:
+#
+# 	AGENT_PREBUILT_DOWNLOAD_URL  The dir in which to find agent tarballs. This
+#				can either be a *local directory* or *a
+#				URL* dir (with trailing '/') which serves
+#				Apache/Nginx dir listing HTML. This defaults to empty,
+#               as we prefer to build agents on the build machine of the
+#               component that's going to use them, rather than downloading
+#               prebuilt ones. (default: '')
+#
+#	AGENT_PREBUILT_BRANCH  Specify a particular branch of 'agent' builds
+#				from which to pull. Generally one should stick
+#				with the default.
+#				(default: master)
+#
+#	BUILD		top-level directory for built binaries
+#				(default: "build")
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+
+AGENT_USER = $(shell id -un)
+AGENT_PREBUILT_BRANCH ?= $(BRANCH)
+AGENT_PREBUILT_TRY_BRANCH ?= $(TRY_BRANCH)
+AGENT_PREBUILT_DIR ?= /var/tmp/agent-cache.$(AGENT_USER)
+
+#
+# To add a new agent to this file, define the following variables:
+#
+# <AGENT>_PREBUILT_GIT_URL			the git repository to clone
+# <AGENT>_PREBUILT_REPO				the local repository name
+# <AGENT>_PREBUILT_AGENT_TARGETS		the make targets in that repository to build
+# <AGENT>_PREBUILT_ROOTDIR			where in the image the package resides
+# <AGENT>_PREBUILT_TARBALL_PATTERN	a regexp to match the built/downloaded agent
+#
+# then add the logic to define <name>_PREBUILT_TARGETS, likely reused from
+# existing agent definitions.
+#
+
+#
+# sdc-amon
+#
+AMON_PREBUILT_GIT_URL =			https://github.com/joyent/sdc-amon.git
+AMON_PREBUILT_REPO = 			sdc-amon
+AMON_PREBUILT_AGENT_TARGETS =		distclean agent pkg_agent
+AMON_PREBUILT_ROOTDIR = 		root/opt
+AMON_PREBUILT_TARBALL_PATTERN =		build/amon-agent-.*.tgz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	AMON_PREBUILT_TARGETS = AMON-prebuilt-download
+else
+	AMON_PREBUILT_TARGETS = AMON-prebuilt-clone AMON-prebuilt-build
+endif
+AMON_PREBUILT_TARGETS += AMON-prebuilt-extract
+
+#
+# sdc-config-agent
+#
+CONFIG_PREBUILT_GIT_URL = 		https://github.com/joyent/sdc-config-agent.git
+CONFIG_PREBUILT_REPO = 			sdc-config-agent
+CONFIG_PREBUILT_AGENT_TARGETS =		distclean release
+CONFIG_PREBUILT_ROOTDIR = 		root/opt/smartdc
+CONFIG_PREBUILT_TARBALL_PATTERN = 	config-agent-.*.tar.gz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	CONFIG_PREBUILT_TARGETS = CONFIG-prebuilt-download
+else
+	CONFIG_PREBUILT_TARGETS = CONFIG-prebuilt-clone CONFIG-prebuilt-build
+endif
+CONFIG_PREBUILT_TARGETS += CONFIG-prebuilt-extract
+
+#
+# manta-mackerel
+#
+MACKEREL_PREBUILT_GIT_URL =		https://github.com/joyent/manta-mackerel.git
+MACKEREL_PREBUILT_REPO = 		manta-mackerel
+MACKEREL_PREBUILT_AGENT_TARGETS =	distclean release
+# intentionally left blank as the tarball includes root/opt/smartdc
+MACKEREL_PREBUILT_ROOTDIR =
+MACKEREL_PREBUILT_TARBALL_PATTERN =	mackerel-pkg-.*.tar.gz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	MACKEREL_PREBUILT_TARGETS= MACKEREL-prebuilt-download
+else
+	MACKEREL_PREBUILT_TARGETS = MACKEREL-prebuilt-clone MACKEREL-prebuilt-build
+endif
+MACKEREL_PREBUILT_TARGETS += MACKEREL-prebuilt-extract
+
+#
+# manta-minnow
+#
+MINNOW_PREBUILT_GIT_URL =		https://github.com/joyent/manta-minnow.git
+MINNOW_PREBUILT_REPO = 			manta-minnow
+MINNOW_PREBUILT_AGENT_TARGETS =		distclean release
+# intentionally left blank as the tarball includes root/opt/smartdc
+MINNOW_PREBUILT_ROOTDIR =
+MINNOW_PREBUILT_TARBALL_PATTERN =	minnow-pkg-.*.tar.gz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	MINNOW_PREBUILT_TARGETS= MINNOW-prebuilt-download
+else
+	MINNOW_PREBUILT_TARGETS = MINNOW-prebuilt-clone MINNOW-prebuilt-build
+endif
+MINNOW_PREBUILT_TARGETS += MINNOW-prebuilt-extract
+
+#
+# registrar
+#
+REGISTRAR_PREBUILT_GIT_URL =			https://github.com/joyent/registrar.git
+REGISTRAR_PREBUILT_REPO = 			registrar
+REGISTRAR_PREBUILT_AGENT_TARGETS = 		distclean release
+# intentionally left blank as the tarball includes root/opt/smartdc
+REGISTRAR_PREBUILT_ROOTDIR =
+REGISTRAR_PREBUILT_TARBALL_PATTERN =		registrar-pkg-.*.tar.gz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	REGISTRAR_PREBUILT_TARGETS= REGISTRAR-prebuilt-download
+else
+	REGISTRAR_PREBUILT_TARGETS = REGISTRAR-prebuilt-clone REGISTRAR-prebuilt-build
+endif
+REGISTRAR_PREBUILT_TARGETS += REGISTRAR-prebuilt-extract
+
+#
+# waferlock
+#
+WAFERLOCK_PREBUILT_GIT_URL =			https://github.com/joyent/waferlock.git
+WAFERLOCK_PREBUILT_REPO = 			waferlock
+WAFERLOCK_PREBUILT_AGENT_TARGETS = 		distclean release
+# intentionally left blank as the tarball includes root/opt/smartdc
+WAFERLOCK_PREBUILT_ROOTDIR =
+WAFERLOCK_PREBUILT_TARBALL_PATTERN =		waferlock-pkg-.*.tar.gz
+
+ifdef AGENT_PREBUILT_DOWNLOAD_URL
+	WAFERLOCK_PREBUILT_TARGETS= WAFERLOCK-prebuilt-download
+else
+	WAFERLOCK_PREBUILT_TARGETS = WAFERLOCK-prebuilt-clone WAFERLOCK-prebuilt-build
+endif
+WAFERLOCK_PREBUILT_TARGETS += WAFERLOCK-prebuilt-extract
diff --git a/tools/mk/Makefile.agent_prebuilt.targ b/tools/mk/Makefile.agent_prebuilt.targ
new file mode 100644
index 0000000..8aaad97
--- /dev/null
+++ b/tools/mk/Makefile.agent_prebuilt.targ
@@ -0,0 +1,120 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Makefile.agent_prebuilt.targ: Makefile for components that need to use
+# one of the Triton/Manta agents. Include Makefile.agent_prebuilt.defs and
+# this file, then add one of the *-prebuilt targets below.
+#
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to eng.git as normal, then do the following for each component that
+# uses eng.git:
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "Updated eng bits to get <describe your fix here>" deps/eng
+#
+
+AGENT_PREBUILT_DIR ?= \
+	$(error AGENT_PREBUILT_DIR is not set: was Makefile.agent_prebuilt.defs included?)
+
+BUILDIMAGE_STAGEDIR ?= \
+	$(error BUILDIMAGE_STAGEDIR is not set!)
+
+amon-prebuilt: $(AMON_PREBUILT_TARGETS)
+config-prebuilt: $(CONFIG_PREBUILT_TARGETS)
+mackerel-prebuilt: $(MACKEREL_PREBUILT_TARGETS)
+minnow-prebuilt: $(MINNOW_PREBUILT_TARGETS)
+registrar-prebuilt: $(REGISTRAR_PREBUILT_TARGETS)
+waferlock-prebuilt: $(WAFERLOCK_PREBUILT_TARGETS)
+
+%-prebuilt-download:
+	$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-U '$(AGENT_PREBUILT_DOWNLOAD_URL)' download
+
+#
+# Note that this target will only perform a build if we don't have a tarball
+# or if the git hash in the discovered tarball doesn't match the hash of the
+# cloned/checked-out source.
+#
+%-prebuilt-build: %-prebuilt-clone $(AGENT_PREBUILT_DIR)
+	$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-t '$($*_PREBUILT_AGENT_TARGETS)' build
+
+#
+# Clone a fresh copy of the agent's source, or checkout an existing copy
+# to the version specified by $($*_PREBUILT_BRANCH)
+#
+%-prebuilt-clone: $(AGENT_PREBUILT_DIR)
+	$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-t '$($*_PREBUILT_AGENT_TARGETS)' \
+		-u '$($*_PREBUILT_GIT_URL)' clone
+
+#
+# Just emit the tarball version
+#
+%-prebuilt-tarball: $(AGENT_PREBUILT_DIR)
+	@$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-U '$(AGENT_PREBUILT_DOWNLOAD_URL)' show_tarball
+
+#
+# Extract the tarball to the buildimage staging directory
+#
+%-prebuilt-extract:
+	mkdir -p $(BUILDIMAGE_STAGEDIR); \
+	cd $(BUILDIMAGE_STAGEDIR); \
+	$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-d '$($*_PREBUILT_ROOTDIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-U '$(AGENT_PREBUILT_DOWNLOAD_URL)' extract
+
+#
+# Clean a prebuilt agent. This does an rm -rf of the local repo
+# for the agent (it's the only way to be sure)
+#
+%-prebuilt-clean: $(AGENT_PREBUILT_DIR)
+	$(TOP)/deps/eng/tools/agent-prebuilt.sh \
+		-b '$(AGENT_PREBUILT_BRANCH)' \
+		-B '$(AGENT_PREBUILT_TRY_BRANCH)' \
+		-c '$(AGENT_PREBUILT_DIR)' \
+		-p '$($*_PREBUILT_TARBALL_PATTERN)' \
+		-r '$($*_PREBUILT_REPO)' \
+		-U '$(AGENT_PREBUILT_DOWNLOAD_URL)' clean
+
+$(AGENT_PREBUILT_DIR):
+	mkdir -p $@
diff --git a/tools/mk/Makefile.ctf.defs b/tools/mk/Makefile.ctf.defs
index bf16601..71f751e 100644
--- a/tools/mk/Makefile.ctf.defs
+++ b/tools/mk/Makefile.ctf.defs
@@ -9,11 +9,20 @@
 #
 
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
 #
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
+#
+
 # This Makefile uses the following definitions:
 #
 # 	CTFTOOLS	Directory in which to install ctftools once downloaded
diff --git a/tools/mk/Makefile.ctf.targ b/tools/mk/Makefile.ctf.targ
index bc5eb12..30fd9ba 100644
--- a/tools/mk/Makefile.ctf.targ
+++ b/tools/mk/Makefile.ctf.targ
@@ -15,11 +15,22 @@
 # include CTF information.  Download the program used to download and deploy
 # the Manta CTF tools.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
 #
+# Then push those changes to gerrit as usual for review.
+#
+
 $(STAMP_CTF_TOOLS):
 	$(MAKE_STAMP_REMOVE)
 	rm -rf $(CTFTOOLS)
diff --git a/tools/mk/Makefile.defs b/tools/mk/Makefile.defs
index 73dd612..f1ddbd3 100644
--- a/tools/mk/Makefile.defs
+++ b/tools/mk/Makefile.defs
@@ -10,11 +10,22 @@
 
 #
 # Makefile.defs: common defines.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+# Then push those changes to gerrit as usual for review.
+#
+
 #
 # This makefile defines some useful defines. Include it at the top of
 # your Makefile.
@@ -36,6 +47,12 @@
 #			Files in this directory are not intended to be shipped.
 #
 
+#
+# Note that variables that start with "ENGBLD_" are ones we expect developers
+# may want to override in their environment, usually to modify build output
+# destinations, but sometimes to modify the behavior of the build.
+#
+
 TOP := $(shell pwd)
 
 #
@@ -60,6 +77,9 @@ export V=1
 CACHE_DIR ?=		cache
 DISTCLEAN_FILES +=	$(CACHE_DIR)
 
+# Many components assemble *-pkg*.gz tarballs as build products
+CLEAN_FILES +=  $(NAME)-pkg*.gz
+
 #
 # EXPENSIVE TARGETS AND MAKE STAMP FILES
 #
@@ -103,3 +123,76 @@ CLEAN_FILES +=		$(MAKE_STAMPS_DIR)
 
 MAKE_STAMP_REMOVE =	mkdir -p $(@D); rm -f $(@)
 MAKE_STAMP_CREATE =	mkdir -p $(@D); touch $(@)
+
+#
+# Nearly all components in Triton/Manta currently require the build machine to
+# be running this platform image, validated as part of validate-buildenv.sh.
+# Makefiles that allow newer platforms should override this.
+#
+BUILD_PLATFORM=20151126T062538Z
+
+#
+# The manta path where the bits-upload target stores build artifacts, via
+# ./tools/bits-upload.sh. This can be a Manta path, or an absolute
+# filesystem path. If the latter, be sure to also set
+# $ENGBLD_BITS_UPLOAD_LOCAL=true, see below.
+#
+ENGBLD_DEST_OUT_PATH ?= /stor/builds
+
+#
+# Makefiles must declare whether they need to construct a ZFS image
+# by setting ENGBLD_USE_BUILDIMAGE to 'true'. We use this mechanism
+# so that we can conditionally add a buildimage dependency to the
+# 'bits-upload' target.
+#
+ifeq ($(ENGBLD_USE_BUILDIMAGE), true)
+BUILDIMAGE_TARG = buildimage
+else
+BUILDIMAGE_TARG =
+endif
+
+#
+# If bits-upload should use a local dest_dir, set that argument based on
+# $ENGBLD_BITS_UPLOAD_LOCAL in the environment.
+#
+ifeq ($(ENGBLD_BITS_UPLOAD_LOCAL), true)
+BITS_UPLOAD_LOCAL_ARG = -L
+else
+BITS_UPLOAD_LOCAL_ARG =
+endif
+
+#
+# If bits-upload should publish images to updates.joyent.com, set that argument
+# based on $ENGBLD_BITS_UPLOAD_IMGAPI in the environment.
+#
+ifeq ($(ENGBLD_BITS_UPLOAD_IMGAPI), true)
+BITS_UPLOAD_IMGAPI_ARG = -p
+else
+BITS_UPLOAD_IMGAPI_ARG =
+endif
+
+#
+# A directory for build artifacts, used by the bits-upload, publish and
+# buildimage targets. We use BITS_DIR rather than ENGBLD_BITS_DIR to remain
+# compatible with MG.
+#
+BITS_DIR ?= $(TOP)/bits
+
+#
+# A pointer to the buildimage tool, and a stamp-name used to install
+# its dependencies.
+#
+BUILDIMAGE = $(TOP)/deps/eng/tools/buildimage/bin/buildimage
+STAMP_BUILDIMAGE_PREP := $(MAKE_STAMPS_DIR)/buildimage-prep
+
+#
+# Metadata needed by buildimage to construct the image.
+# This gets used when generating the image's manifest file.
+#
+BUILDIMAGE_VERSION	= $(STAMP)
+BUILDIMAGE_STAGEDIR = /tmp/buildimage-$(NAME)-$(STAMP)
+BUILDIMAGE_MF           = \
+    {"name": "$(BUILDIMAGE_NAME)",\
+    "description": "$(BUILDIMAGE_DESC)",\
+    "version": "$(BUILDIMAGE_VERSION)"\
+    }
diff --git a/tools/mk/Makefile.deps b/tools/mk/Makefile.deps
index 91f8346..70b25ec 100644
--- a/tools/mk/Makefile.deps
+++ b/tools/mk/Makefile.deps
@@ -6,20 +6,26 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.deps: Makefile for including common tools as dependencies
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
 #
-# This file is separate from Makefile.targ so that teams can choose
-# independently whether to use the common targets in Makefile.targ and the
-# common tools here.
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.go_prebuilt.defs b/tools/mk/Makefile.go_prebuilt.defs
index 23c2ed8..f0c1492 100644
--- a/tools/mk/Makefile.go_prebuilt.defs
+++ b/tools/mk/Makefile.go_prebuilt.defs
@@ -11,10 +11,20 @@
 #
 # Makefile.go_prebuilt.defs: Makefile for obtaining a prebuilt Go toolchain.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.go_prebuilt.targ b/tools/mk/Makefile.go_prebuilt.targ
index d0f998c..fd2f242 100644
--- a/tools/mk/Makefile.go_prebuilt.targ
+++ b/tools/mk/Makefile.go_prebuilt.targ
@@ -11,10 +11,20 @@
 #
 # Makefile.go_prebuilt.targ: Makefile for obtaining a prebuilt Go toolchain.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.manpages.defs b/tools/mk/Makefile.manpages.defs
index 6da7876..471eb84 100644
--- a/tools/mk/Makefile.manpages.defs
+++ b/tools/mk/Makefile.manpages.defs
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2016, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.manpages.defs: targets for building manual pages.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.manpages.targ b/tools/mk/Makefile.manpages.targ
index 11f242b..cd27edc 100644
--- a/tools/mk/Makefile.manpages.targ
+++ b/tools/mk/Makefile.manpages.targ
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2016, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.manpages.targ: targets for building manual pages.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.node.defs b/tools/mk/Makefile.node.defs
index 487824d..692d8da 100644
--- a/tools/mk/Makefile.node.defs
+++ b/tools/mk/Makefile.node.defs
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node.defs: Makefile for building and bundling your own Node.js.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.node.targ b/tools/mk/Makefile.node.targ
index bf53f78..a610f53 100644
--- a/tools/mk/Makefile.node.targ
+++ b/tools/mk/Makefile.node.targ
@@ -6,16 +6,26 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node.targ: See Makefile.node.defs.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 ifneq ($(shell uname -s),SunOS)
diff --git a/tools/mk/Makefile.node_modules.defs b/tools/mk/Makefile.node_modules.defs
index ec8cc8e..ac2edf8 100644
--- a/tools/mk/Makefile.node_modules.defs
+++ b/tools/mk/Makefile.node_modules.defs
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node_modules.defs: Makefile for using NPM modules.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.node_modules.targ b/tools/mk/Makefile.node_modules.targ
index 0156bce..3fa2cf8 100644
--- a/tools/mk/Makefile.node_modules.targ
+++ b/tools/mk/Makefile.node_modules.targ
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node_modules.targ: See comments in Makefile.node_modules.defs.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 STAMP_NODE_MODULES ?= $(error You must include Makefile.node_modules.defs \
@@ -24,7 +34,7 @@ STAMP_NODE_MODULES ?= $(error You must include Makefile.node_modules.defs \
 # If the "package.json" file changes, we need to rebuild the contents of
 # the "node_modules" directory.
 #
-$(STAMP_NODE_MODULES): package.json | $(NPM_EXEC)
+$(STAMP_NODE_MODULES): package.json $(STAMP_NODE_PREBUILT) | $(NPM_EXEC)
 	$(MAKE_STAMP_REMOVE)
 	rm -rf node_modules
 	$(NPM_ENV) $(NPM) install
diff --git a/tools/mk/Makefile.node_prebuilt.defs b/tools/mk/Makefile.node_prebuilt.defs
index 2129742..d56785e 100644
--- a/tools/mk/Makefile.node_prebuilt.defs
+++ b/tools/mk/Makefile.node_prebuilt.defs
@@ -5,16 +5,26 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node_prebuilt.defs: Makefile for including a prebuilt Node.js build.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
 #
 
 #
diff --git a/tools/mk/Makefile.node_prebuilt.targ b/tools/mk/Makefile.node_prebuilt.targ
index 6877333..99f34fb 100644
--- a/tools/mk/Makefile.node_prebuilt.targ
+++ b/tools/mk/Makefile.node_prebuilt.targ
@@ -6,18 +6,28 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.node_prebuilt.targ: Makefile for including a prebuilt Node.js
 # build.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
 
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
+#
 
 NODE_PREBUILT_TARBALL ?= $(error NODE_PREBUILT_TARBALL is not set: was Makefile.node_prebuilt.defs included?)
 
diff --git a/tools/mk/Makefile.smf.defs b/tools/mk/Makefile.smf.defs
index b988bbe..4e96c52 100644
--- a/tools/mk/Makefile.smf.defs
+++ b/tools/mk/Makefile.smf.defs
@@ -6,16 +6,28 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.smf.defs: common targets for SMF manifests
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
+#
+
 #
 # This Makefile uses the following definitions:
 #
diff --git a/tools/mk/Makefile.smf.targ b/tools/mk/Makefile.smf.targ
index f78de96..f36c56e 100644
--- a/tools/mk/Makefile.smf.targ
+++ b/tools/mk/Makefile.smf.targ
@@ -6,17 +6,28 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.smf.targ: see Makefile.smf.defs.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
 #
+# Then push those changes to gerrit as usual for review.
+#
+
 .PHONY: check-manifests
 check-manifests: $(SMF_MANIFESTS:%=%.smfchk)
 
diff --git a/tools/mk/Makefile.targ b/tools/mk/Makefile.targ
index 8ae89c2..209de52 100644
--- a/tools/mk/Makefile.targ
+++ b/tools/mk/Makefile.targ
@@ -1,39 +1,63 @@
-#
+
 # This Source Code Form is subject to the terms of the Mozilla Public
 # License, v. 2.0. If a copy of the MPL was not distributed with this
 # file, You can obtain one at http://mozilla.org/MPL/2.0/.
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
 # Makefile.targ: common targets.
 #
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
+
+#
+# NOTE: This makefile comes from the "eng" repo. If you find yourself changing
+# this file, you should ensure that you test all consumers of it, since
+# eng.git is a git submodule of several repositories. After testing, push
+# changes to the eng.git gerrit project as normal, then do the following for
+# each component that uses eng.git, likely reusing the original ticket subject
+# for the commit message as was used for the eng.git push.
+#
+#    $ git submodule update --remote deps/eng
+#    $ git add deps/eng
+#    $ git commit -m "TOOLS-xxxx some description" deps/eng
+#
+# Then push those changes to gerrit as usual for review.
+#
+
 #
 # This Makefile defines several useful targets and rules. You can use it by
 # including it from a Makefile that specifies some of the variables below.
 #
 # Targets defined in this Makefile:
 #
-#	check	Checks JavaScript files for lint and style
-#		Checks bash scripts for syntax
-#		Checks SMF manifests for validity against the SMF DTD
+#	buildimage	Builds an image
+#	check		Checks JavaScript files for lint and style
+#			Checks bash scripts for syntax
+#			Checks SMF manifests for validity against the SMF DTD
 #
-#	clean	Removes built files
+#	clean		Removes built files
 #
-#	docs	Builds restdown documentation in docs/
+#	docs		Builds restdown documentation in docs/
 #
-#	prepush	Depends on "check" and "test"
+#	prepublish	Is depended upon by "publish", saves the $(STAMP)
+#			of our last published bits, used by bits-upload.sh,
+#			as well as data about the build environment
 #
-#	test	Does nothing (you should override this)
+#	prepush		Depends on "check" and "test"
 #
-#	xref	Generates cscope (source cross-reference index)
+#	show-buildenv	Emits the pkgsrc version required for this component,
+#			if available
+#
+#	test		Does nothing (you should override this)
+#
+#	validate-buildenv
+#			Runs a series of checks to determine if the build
+#			environment is valid for this component
+#
+#	xref		Generates cscope (source cross-reference index)
 #
 # For details on what these targets are supposed to do, see the Joyent
 # Engineering Guide.
@@ -104,7 +128,7 @@
 # Defaults for the various tools we use.
 #
 BASH		?= bash
-BASHSTYLE   ?= $(NODE) tools/bashstyle
+BASHSTYLE   	?= $(NODE) deps/eng/tools/bashstyle
 CP		?= cp
 CSCOPE		?= cscope
 CSCOPE_DIRS	?= .
@@ -130,7 +154,7 @@ endif
 # Defaults for other fixed values.
 #
 BUILD		?= build
-DISTCLEAN_FILES += $(BUILD)
+DISTCLEAN_FILES += $(BUILD) bits
 DOC_BUILD	= $(BUILD)/docs/public
 
 #
@@ -331,6 +355,119 @@ test:
 .PHONY: prepush
 prepush: check test
 
+#
+# Ensure we have a sane build environment. The script includes an escape
+# hatch in case of emergencies. set ENGBLD_SKIP_VALIDATE_BUILDENV=true in the
+# environment to have it always pass.
+#
+.PHONY: validate-buildenv
+validate-buildenv:
+	$(TOP)/deps/eng/tools/validate-buildenv.sh
+
+.PHONY: show-buildenv
+show-buildenv:
+	@$(TOP)/deps/eng/tools/validate-buildenv.sh -r
+
+#
+# Everything should depend on us having a valid build environment.
+#
+all release publish buildimage: validate-buildenv
+
+publish: prepublish
+
+#
+# Store some information about the build environment. The latest-build-stamp
+# file is used if running the 'bits-upload-latest' target. See bits-upload.sh.
+# When generating npm-ls.json output, we ignore errors since older versions
+# of npm seem to sometimes install packages that /opt/tools/bin/npm deems
+# "invalid". That shouldn't be allowed to fail the build.
+#
+.PHONY: prepublish
+prepublish:
+	-mkdir -p $(BITS_DIR)/$(NAME)
+	echo $(STAMP) > $(BITS_DIR)/$(NAME)/latest-build-stamp
+	@echo "Generating $(BITS_DIR)/$(NAME)/build-environment"
+	@if [[ "$$(uname -s)" == "SunOS" ]]; then \
+		MAKE_PID=$$(/usr/bin/ps -o ppid= -p $$$$); \
+		BUILD_IMG_UUID=$$(/usr/bin/pfexec /usr/sbin/mdata-get sdc:image_uuid); \
+		echo hostname: $$(/usr/bin/hostname) > $(BITS_DIR)/$(NAME)/build-environment; \
+		/usr/bin/cat /etc/pkgsrc_version >> $(BITS_DIR)/$(NAME)/build-environment; \
+		echo image_uuid: $$BUILD_IMG_UUID >> $(BITS_DIR)/$(NAME)/build-environment; \
+	fi
+	@echo "Generating $(BITS_DIR)/$(NAME)/npm-ls.json"
+	-/opt/tools/bin/npm ls --json > $(BITS_DIR)/$(NAME)/npm-ls.json
+
+#
+# The list of pkgsrc packages that should be installed in the
+# image that the 'buildimage' target constructs. Set here rather than
+# in Makefile.defs to ensure it's always computed after $(BUILDIMAGE_PKGSRC)
+# is set.
+#
+ifdef BUILDIMAGE_PKGSRC
+BUILDIMAGE_PKGSRC_ARGS = -p $$(echo $(BUILDIMAGE_PKGSRC) | sed -e 's/ /,/g')
+else
+BUILDIMAGE_PKGSRC_ARGS =
+endif
+
+.PHONY: buildimage
+buildimage: stamp-buildimage-prep release $(AGENTS:%=%-prebuilt)
+	mkdir -p $(BITS_DIR)/$(NAME)
+	mkdir -p $(BUILDIMAGE_STAGEDIR)
+	cd $(BUILDIMAGE_STAGEDIR) ; \
+	$(TOP)/deps/eng/tools/buildimage-extract-pkg.sh $(BUILDIMAGE_PKG)
+	pfexec chown -R root:root $(BUILDIMAGE_STAGEDIR)
+	cd $(BUILDIMAGE_STAGEDIR); \
+	pfexec $(BUILDIMAGE) \
+		-i $(BASE_IMAGE_UUID) \
+		-d $(BUILDIMAGE_STAGEDIR)/root \
+		-m '$(BUILDIMAGE_MF)' \
+		$(BUILDIMAGE_PKGSRC_ARGS) \
+		-P $(NAME)-zfs
+	cp /tmp/$(NAME)-zfs-$(STAMP).zfs.gz $(BITS_DIR)/$(NAME)
+	cp /tmp/$(NAME)-zfs-$(STAMP).imgmanifest $(BITS_DIR)/$(NAME)
+	pfexec rm /tmp/$(NAME)-zfs-$(STAMP).zfs.gz
+	pfexec rm /tmp/$(NAME)-zfs-$(STAMP).imgmanifest
+	pfexec rm -rf $(BUILDIMAGE_STAGEDIR)
+
+#
+# Upload the build products from this component's ./bits directory
+# to either manta or a filesystem path.
+#
+.PHONY: bits-upload
+bits-upload: publish $(BUILDIMAGE_TARG)
+	$(TOP)/deps/eng/tools/bits-upload.sh \
+		-b $(BRANCH) \
+		-B "$(TRY_BRANCH)" \
+		$(BITS_UPLOAD_LOCAL_ARG) \
+		$(BITS_UPLOAD_IMGAPI_ARG) \
+		-d $(ENGBLD_DEST_OUT_PATH)/$(NAME) \
+		-n $(NAME) \
+		-t $(STAMP)
+
+#
+# A convenience target that doesn't require us to do a full build. We derive
+# the timestamp for the bits being uploaded from the latest-build-stamp file
+# in build/bits directory, produced by the 'prepublish' target.
+#
+.PHONY: bits-upload-latest
+bits-upload-latest:
+	$(TOP)/deps/eng/tools/bits-upload.sh \
+		-b $(BRANCH) \
+		-B "$(TRY_BRANCH)" \
+		$(BITS_UPLOAD_LOCAL_ARG) \
+		$(BITS_UPLOAD_IMGAPI_ARG) \
+		-d $(ENGBLD_DEST_OUT_PATH)/$(NAME) \
+		-n $(NAME)
+
+#
+# Do an npm install for the dependencies of buildimage itself.
+#
+$(STAMP_BUILDIMAGE_PREP):
+	$(MAKE_STAMP_REMOVE); \
+	cd $(TOP)/deps/eng/tools/buildimage; \
+	$(MAKE) buildimage-prep
+	$(MAKE_STAMP_CREATE)
+
 #
 # This rule automatically exposes every "stamp" file as a target that can be
 # invoked manually as "stamp-$STAMP_NAME".  For example, if a stamp has been
@@ -346,3 +483,10 @@ prepush: check test
 #
 stamp-%: $(MAKE_STAMPS_DIR)/%
 	@:
+
+#
+# Allow for easier Makefile debugging. 'make print-FOO' will emit the value
+# of $(FOO).
+#
+print-%:
+	@echo '$*=$($*)'
diff --git a/tools/mkrepo b/tools/mkrepo
index 3b0d624..b06ff46 100755
--- a/tools/mkrepo
+++ b/tools/mkrepo
@@ -7,7 +7,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var child_process = require('child_process');
@@ -26,11 +26,11 @@ var DIRS = [
     'smf',
     'smf/manifests',
     'test',
-    'tools',
-    'tools/mk'
+    'tools'
 ];
 
 var SUBMODULES = {
+    'eng': 'https://github.com/joyent/eng.git',
     'javascriptlint': 'https://github.com/davepacheco/javascriptlint.git',
     'jsstyle': 'https://github.com/davepacheco/jsstyle.git',
     'restdown': 'https://github.com/trentm/restdown.git'
diff --git a/tools/validate-buildenv.sh b/tools/validate-buildenv.sh
new file mode 100755
index 0000000..c9b5a01
--- /dev/null
+++ b/tools/validate-buildenv.sh
@@ -0,0 +1,650 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Check if the current build machine is supported for building this component
+# and that the build environment seems sane.
+# This is specifically a bash script because we're using its associative array
+# support.
+#
+# Meant to be run from the top level of a git repository before commencing a
+# build. It checks the following:
+#
+# - the pkgsrc version is compatible with one derived from $NODE_PREBUILT_IMAGE
+#   or $BASE_IMAGE_UUID
+# - our devzone has a delegated dataset
+# - the list of pkgsrc packages match the ones installed on jenkins-agent images
+# - the RBAC profiles(1) of the user, looking for 'Primary Administrator' or
+#   uid=0
+# - the build environment has a $PATH with /opt/local/bin before /usr/bin et al
+# - our build platform for this component, BUILD_PLATFORM, matches uname -vish
+# - several non-pkgsrc programs needed by the build are availabe on the $PATH
+#
+
+#
+# For the NODE_PREBUILT_IMAGE checks, we use this list from
+# From https://download.joyent.com/pub/build/sdcnode/README.html
+# the following images versions are supported:
+#
+#    sdc-smartos@1.6.3: fd2cc906-8938-11e3-beab-4359c665ac99
+#    sdc-multiarch@13.3.1: b4bdc598-8939-11e3-bea4-8341f6861379
+#    sdc-base@14.2.0: de411e86-548d-11e4-a4b7-3bb60478632a
+#    sdc-minimal-multiarch-lts@15.4.1: 18b094b0-eb01-11e5-80c1-175dac7ddf02
+#    triton-origin-multiarch-15.4.1@1.0.1: 04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f
+#    minimal-multiarch@18.1.0: 1ad363ec-3b83-11e8-8521-2f68a4a34d5d
+#
+# In the future, we would prefer if the pkgsrc versions were declared
+# directly in Makefiles without needing this lookup. (see TOOLS-2038)
+#
+
+#
+# NOTE If you modify this file, be sure to check that
+# jenkins-agent.git:/toolbox/auto-user-script.sh is in sync with the set
+# of pkgsrc packages installed per-pkgsrc version. It's not wonderful that
+# these lists are duplicated here :-/
+#
+
+if [[ -n "$ENGBLD_SKIP_VALIDATE_BUILDENV" ]]; then
+    echo "\$ENGBLD_SKIP_VALIDATE_BUILDENV set - not running build environment checks!"
+    exit 0
+fi
+
+if [[ $(uname -s) != "SunOS" ]]; then
+    echo "Only illumos build machines are supported."
+    echo "Set \$ENGBLD_SKIP_VALIDATE_BUILDENV in the environment".
+    echo "to override this."
+    echo "Exiting now."
+    exit 1
+fi
+
+# Used to cross-check declared NODE_PREBUILT_IMAGE to pkgsrc version.
+declare -A PKGSRC_MAP=(
+    [fd2cc906-8938-11e3-beab-4359c665ac99]=2011Q4
+    [b4bdc598-8939-11e3-bea4-8341f6861379]=2013Q3
+    [de411e86-548d-11e4-a4b7-3bb60478632a]=2014Q2
+    [18b094b0-eb01-11e5-80c1-175dac7ddf02]=2015Q4
+    [04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f]=2015Q4
+    [1ad363ec-3b83-11e8-8521-2f68a4a34d5d]=2018Q1
+)
+
+# Used to provide useful error messages to the user, mapping the
+# NODE_PREBUILT_IMAGE uuid to the human-friendly image name.
+declare -A SDC_MAP=(
+    [fd2cc906-8938-11e3-beab-4359c665ac99]=sdc-smartos@1.6.3
+    [b4bdc598-8939-11e3-bea4-8341f6861379]=sdc-multiarch@13.3.1
+    [de411e86-548d-11e4-a4b7-3bb60478632a]=sdc-base@14.2.0
+    [18b094b0-eb01-11e5-80c1-175dac7ddf02]=sdc-minimal-multiarch-lts@15.4.1
+    [04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f]=triton-origin-multiarch-15.4.1@1.0.1
+    [1ad363ec-3b83-11e8-8521-2f68a4a34d5d]=minimal-multiarch@18.1.0
+)
+
+# Used to provide useful error messages to the user, mapping the NODE_PREBUILT
+# image uuid to a corresponding jenkins-agent image uuid.
+# Jenkins agent images are built by https://github.com/joyent/jenkins-agent
+declare -A JENKINS_AGENT_MAP=(
+    [fd2cc906-8938-11e3-beab-4359c665ac99]=2faab421-b149-40c0-a643-6daf6d0c9c43
+    [b4bdc598-8939-11e3-bea4-8341f6861379]=ff40305d-9564-4890-87ad-acada25b5521
+    [de411e86-548d-11e4-a4b7-3bb60478632a]=079b3201-b0ea-4551-b092-d4c692350d7f
+    [18b094b0-eb01-11e5-80c1-175dac7ddf02]=fdf515d3-3efc-4931-8af8-92873e2ae945
+    [04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f]=fdf515d3-3efc-4931-8af8-92873e2ae945
+    [1ad363ec-3b83-11e8-8521-2f68a4a34d5d]=eb3e7e0a-7ed1-4489-abc4-d3b7cc771717
+)
+
+# For each pkgsrc version, set a list of packages that must be present
+PKGSRC_PKGS_2011Q4="
+    gcc-compiler
+    gcc-runtime
+    gcc-tools
+    cscope
+    gmake
+    scmgit-base
+    python26
+    png
+    GeoIP
+    GeoLiteCity
+    ghostscript
+    zookeeper-client
+    binutils
+    postgresql91-client-9.1.2
+    gsharutils
+    cdrtools
+    coreutils
+    pigz"
+
+PKGSRC_PKGS_2013Q3="
+    grep
+    build-essential
+    python27
+    py27-expat
+    coreutils
+    gsharutils
+    pigz"
+
+PKGSRC_PKGS_2014Q2="
+    grep
+    build-essential
+    python27
+    py27-expat
+    coreutils
+    gsharutils
+    pigz"
+
+PKGSRC_PKGS_2015Q4="
+    grep
+    build-essential
+    python27
+    py27-expat
+    coreutils
+    gsed
+    gsharutils
+    flex
+    pcre-8.41
+    pigz"
+
+PKGSRC_PKGS_2018Q1="
+    grep
+    build-essential
+    python27
+    py27-expat
+    coreutils
+    gsed
+    gsharutils
+    flex
+    pcre-8.42
+    pigz"
+
+UPDATES_URL="https://updates.joyent.com?channel=experimental"
+UPDATES_IMG_URL="https://updates.joyent.com/images/"
+
+#
+# Determine the pkgsrc release of this build machine and the sdcnode prebuilt
+# image, as declared by this component's Makefile. These variables get used by
+# other functions in this script, globals for now.
+#
+function get_pkgsrc_sdcnode_versions {
+
+    REQUIRED_IMAGE=$(
+        make -s --no-print-directory print-BASE_IMAGE_UUID 2> /dev/null |
+            cut -d= -f2)
+    PKGSRC_RELEASE=$(
+        grep ^release: /etc/pkgsrc_version | cut -d: -f2 | sed -e 's/ //g')
+
+    # If there's no BASE_IMAGE_UUID, use NODE_PREBUILT_IMAGE instead.
+    # In either case, what we really want to know is whether this build machine
+    # is running software compatible with the runtime that gets used for
+    # this component in Triton/Manta. This relies on the special 'print-VAR'
+    # target from Makefile.targ
+    if [[ -z "$REQUIRED_IMAGE" ]]; then
+        REQUIRED_IMAGE=$(
+            make -s --no-print-directory \
+                print-NODE_PREBUILT_IMAGE 2> /dev/null | cut -d= -f2)
+    fi
+
+}
+
+#
+# Check that this environment has a $PATH that finds /opt/local/bin before
+# /usr/bin, /bin and /opt/tools/bin. This is important for two reasons:
+#
+# 1. several of the Manta/Triton Makefiles have assumptions on the behaviour
+#    of some UNIX utilities that differ between GNU and Illumos variants
+#    (e.g. the way cp(1) treats symlinks)
+# 2. we compile with gcc 4.9.3 and not yet 7.3.x (which is in /opt/tools)
+#
+# Eventually, we may want to validate other aspects of the build environment,
+# or provide a way for the build to obtain a santized build environment, but
+# let's start here, since we know that failing this test definitely breaks
+# builds.
+#
+# Return 0 if it looks like $PATH is correctly set.
+#
+function validate_build_path {
+    echo $PATH | awk '{
+        pathlen = split($0, path_arr, ":");
+        found_optlocalbin = "false";
+        ret = 0;
+        for (i = 1; i <= pathlen; i++) {
+            if (path_arr[i] == "/opt/local/bin") {
+                found_optlocalbin = "true";
+                continue;
+            }
+            if ((path_arr[i] == "/usr/sbin" ||
+                    path_arr[i] == "/usr/bin" ||
+                    path_arr[i] == "/bin" ||
+                    path_arr[i] == "/sbin" ||
+                    path_arr[i] == "/opt/tools/bin") &&
+		        found_optlocalbin == "false") {
+                ret = 1;
+                break;
+            }
+        }
+        if (found_optlocalbin == "false")
+            ret = 1;
+
+        exit ret;
+    }'
+    result=$?
+    if [[ "$result" -ne 0 ]]; then
+        echo "Error: unexpected \$PATH"
+        echo ""
+        echo "The \$PATH in this shell environment has /bin, /usr/bin, /sbin"
+        echo "/usr/sbin or /opt/tools/bin appearing before /opt/local/bin."
+        echo ""
+        echo "Several of the Manta/Triton component Makefiles contain"
+        echo "assumptions on the GNU implementations of UNIX utilities."
+        echo ""
+        echo "/opt/tools/bin contains compilers that are not currently"
+        echo "supported by the build."
+        echo "The \$PATH should be changed so that /opt/local/bin appears"
+        echo "before /usr/bin, /usr/sbin, /opt/tools/bin and /bin."
+        echo ""
+        echo "The current path is:"
+        echo $PATH
+    fi
+    return $result
+}
+
+#
+# Check that this build machine is running a pkgsrc version appropriate for
+# building this component. Dispense advice on how to obtain jenkins-agent
+# images if this machine is not appropriate.
+#
+function validate_pkgsrc_version {
+
+    # Add an escape hatch.
+    if [[ -n "$ENGBLD_SKIP_VALIDATE_BUILD_PKGSRC" ]]; then
+        echo "Skipping pkgsrc build machine validity tests."
+        return 0
+    fi
+
+    if [[ -z "$REQUIRED_IMAGE" ]]; then
+        echo "Info: No apparent NODE_PREBUILT_IMAGE or BASE_IMAGE_UUID value."
+        echo "Perhaps this build machine will work?"
+        echo ""
+        return 0
+    fi
+
+    if [[ -z "${PKGSRC_MAP[$REQUIRED_IMAGE]}" ]]; then
+        echo "Error: unable to map $REQUIRED_IMAGE to a pkgsrc version"
+        echo "changes needed to 'validate-build-platform.sh'?"
+        echo ""
+        return 1
+    fi
+
+    if [[ "$PKGSRC_RELEASE" != "${PKGSRC_MAP[$REQUIRED_IMAGE]}" ]]; then
+
+        local SDC_IMAGE_NAME="${SDC_MAP[${REQUIRED_IMAGE}]}"
+        local JENKINS_IMAGE="${JENKINS_AGENT_MAP[${REQUIRED_IMAGE}]}"
+
+        local JENK_IMG_URL=${UPDATES_IMG_URL}${JENKINS_IMAGE}
+        echo "This build machine should not be used to build this component."
+        echo ""
+        echo "expected pkgsrc version ${PKGSRC_MAP[$REQUIRED_IMAGE]}"
+        echo " running pkgsrc version ${PKGSRC_RELEASE} "
+        echo ""
+        echo "This component should build on an image based on $SDC_IMAGE_NAME"
+        echo "The following jenkins-agent image will work: ${JENKINS_IMAGE}"
+        echo ""
+        echo "To retrieve this image on Triton, use:"
+        echo "# sdc-imgadm import -S '${UPDATES_URL}' ${JENKINS_IMAGE}"
+        echo ""
+        echo "on SmartOS, use:"
+        echo "# imgadm import -S '${UPDATES_URL}' ${JENKINS_IMAGE}"
+        echo ""
+        echo "or import by hand, with:"
+        echo "# curl -k -o img.manifest '${JENK_IMG_URL}?channel=experimental'"
+        echo "# curl -k -o img.gz '${JENK_IMG_URL}/file?channel=experimental'"
+        echo "and then"
+        echo "# imgadm install -m img.manifest -f img.gz"
+        echo ""
+        return 1
+    else
+        # The build machine pkgsrc version is valid for building this component.
+        return 0
+    fi
+}
+
+#
+# Return 0 if uid==0 or the current user has the 'Primary Administrator'
+# profile, returning 1 otherwise. Checking for uid==0 shouldn't really imply
+# privilege, but that's the current reality in illumos (sorry casper!)
+#
+function validate_rbac_profile {
+    /usr/bin/id | grep -q uid=0
+    if [[ $? -eq 0 ]]; then
+        return 0
+    fi
+
+    /usr/bin/profiles | grep -q 'Primary Administrator'
+    if [[ $? -eq 0 ]]; then
+        return 0
+    fi
+
+    echo "The current user should have the 'Primary Administrator' profile"
+    echo "which is needed to perform some parts of the build, e.g."
+    echo "'buildimage'."
+    echo "To configure this, as root, run:"
+    echo "# usermod -P 'Primary Administrator' $USER"
+    echo ""
+    return 1
+}
+
+#
+# Return 0 if it looks like we have a delegated dataset for this VM
+#
+function validate_delegated_dataset {
+    zonename=$(/usr/bin/zonename)
+    # it seems unlikely that someone's building in a gz, but it should be fine.
+    if [[ "$zonename" == "global" ]]; then
+        return 0
+    fi
+
+    has_delegated_ds=$(zfs list -H -o name zones/$zonename/data 2>/dev/null)
+    if [[ -z "$has_delegated_ds" ]]; then
+        local djc_base="https://docs.joyent.com/private-cloud/instances/"
+        echo "The current devzone does not have a delegated zfs dataset,"
+        echo "which is required for 'buildimage' to function."
+        echo "Please recreate this devzone, ensuring it has a delegated ds."
+        echo ""
+        echo "To do this, when using vmadm in SmartOS or sdc-vmapi in"
+        echo "Triton, add:"
+        echo "'delegate_dataset': true,"
+        echo "to the json configuration. If using the Triton admin interface,"
+        echo "select 'Delegate Dataset' when provisioning the instance."
+        echo "For more information, see:"
+        echo "$djc_base/delegated-data-sets"
+        echo ""
+        return 1
+    fi
+    return 0
+}
+
+#
+# Return 0 if $BUILD_PLATFORM in the component's Makefile matches the timestamp
+# encoded in uname -s output. We allow this check to be overridden
+# independently, since in development, not building on the official platform
+# image is common.
+#
+function validate_build_platform {
+    # for backwards compatibility, allow IGNORE_BUILD_PLATFORM_CHECK also.
+    if [[ -n "$IGNORE_BUILD_PLATFORM_CHECK" ||
+            -n "$ENGBLD_SKIP_VALIDATE_BUILD_PLATFORM" ]]; then
+        return 0
+    fi
+    current_platform=$(/usr/bin/uname -v | sed -e 's/.*_//')
+    component_platform=$(
+        make -s --no-print-directory print-BUILD_PLATFORM 2> /dev/null |
+            cut -d= -f2)
+
+    # some components do not set a required build platform.
+    if [[ -z "$component_platform" ]]; then
+        return 0
+    fi
+
+    # this seems unlikely.
+    if [[ -z "$current_platform" ]]; then
+        echo "WARNING: unable to determine current build platform!"
+        return 1
+    fi
+
+    if [[ "$component_platform" != "$current_platform" ]]; then
+        echo "The current platform image, $current_platform, is not valid."
+        echo "This component should instead be built on $component_platform"
+        echo ""
+        echo "To disable this check, set "
+        echo "\$ENGBLD_IGNORE_BUILD_PLATFORM_CHECK in the environment."
+        echo ""
+        return 1
+    fi
+    return 0
+}
+
+#
+# Emit a line of the form "<pkgsrc release> <one word description>"
+#
+function print_required_pkgsrc_version {
+    if [[ -n "$REQUIRED_IMAGE" ]]; then
+        echo "${PKGSRC_MAP[$REQUIRED_IMAGE]} ${SDC_MAP[$REQUIRED_IMAGE]}"
+        exit 0
+    else
+        exit 1
+    fi
+}
+
+#
+# Check that a list of pkgsrc packages appropriate to this release are
+# installed. For now, we don't care about version numbers.
+#
+function validate_pkgsrc_pkgs {
+
+    # Add an escape hatch.
+    if [[ -n "$ENGBLD_SKIP_VALIDATE_BUILD_PKGSRC" ]]; then
+        echo "Skipping pkgsrc package version validity tests."
+        return 0
+    fi
+
+    if [[ -z "$PKGSRC_RELEASE" ]]; then
+        echo "Unable to determine pkgsrc release"
+        return 1
+    fi
+
+    PKGSRC_VAR_NAME=PKGSRC_PKGS_${PKGSRC_RELEASE}
+    EXPECTED_PKGS=${!PKGSRC_VAR_NAME}
+    PKG_LIST_FILE=$(mktemp /tmp/validate_build_pkgsrc.XXXXXX)
+    /opt/local/bin/pkgin list | cut -f 1 > $PKG_LIST_FILE
+
+    MISSING_PKGS=""
+    for pkg in ${EXPECTED_PKGS}; do
+        FOUND=""
+        grep -q "$pkg-[0-9].*" $PKG_LIST_FILE
+        if [[ $? -eq 0 ]]; then
+            FOUND=true
+        fi
+        grep -q "$pkg " $PKG_LIST_FILE
+        if [[ $? -eq 0 ]]; then
+            FOUND=true
+        fi
+        if [[ -z "$FOUND" ]]; then
+            MISSING_PKGS="$MISSING_PKGS $pkg"
+        fi
+    done
+    rm $PKG_LIST_FILE
+
+    if [[ -n "$MISSING_PKGS" ]]; then
+        echo "The following packages should be installed for $PKGSRC_RELEASE:"
+        echo "$MISSING_PKGS"
+
+        # add a special-case for scmgit on smartos 1.6.3, where the version
+        # from pkgsrc isn't modern enough. In particular, our tarball supports
+        # TLSv1.2. Newer jenkins-agent images have fixed this by symlinking
+        # to the version of git from /opt/tools instead, but warn just in case.
+        if [[ "$PKGSRC_RELEASE" == "2011Q4" ]]; then
+            JDEV="https://us-east.manta.joyent.com/Joyent_Dev/public/bits/"
+            MODERN_GIT_TARBALL="modern-git-20170223a.tar.gz"
+            echo "Note: the version of scmgit from pkgsrc may be too old."
+            echo "Please verify that /opt/local/bin/git (which may be a "
+            echo "symlink) is at least at version 2.12.0, or download the"
+            echo "newer version from $JDEV/$MODERN_GIT_TARBALL"
+        fi
+
+        return 1
+    fi
+    return 0
+}
+
+#
+# Check that this system has /opt/tools/bin. Note that /opt/tools delivers
+# its own pkgsrc contents and is a wholly separate pkgsrc installation than
+# /opt/local/bin.
+#
+function validate_opt_tools {
+    if [[ ! -f /opt/tools/bin/pkgin ]]; then
+
+        local JENKINS_IMAGE="${JENKINS_AGENT_MAP[${REQUIRED_IMAGE}]}"
+        echo "This build zone is missing /opt/tools/bin, which is"
+        echo "needed in order to run certain parts of the build, notably"
+        echo "the 'buildimage' target."
+        echo ""
+        echo "All modern jenkins-agent images contain these, so using"
+        echo "this image will work as a build zone: $JENKINS_IMAGE"
+        echo ""
+        echo "Alternatively, you can install the current pkgsrc bootstrap bits"
+        echo "which deliver /opt/tools. Run the following:"
+        echo ""
+        BOOTSTRAP_URL="https://pkgsrc.joyent.com/packages/SmartOS/bootstrap/"
+        BOOTSTRAP_TAR="bootstrap-2018Q3-tools.tar.gz"
+        BOOTSTRAP_SHA="2244695a8ec0960e26c6f83cbe159a5269033d6a"
+        echo "curl -k -o /var/tmp/${BOOTSTRAP_TAR} \\"
+        echo "    ${BOOTSTRAP_URL}/${BOOTSTRAP_TAR}"
+        echo ""
+        echo " ( verify that the SHA-1 sum of the tar file is $BOOTSTRAP_SHA )"
+        echo ""
+        echo "tar -zxpf /var/tmp/${BOOTSTRAP_TAR} -C /"
+        echo "rm /var/tmp/${BOOTSTRAP_TAR}"
+        echo ""
+        return 1
+    else
+        # Validate we have an expected set of packages
+        PKG_LIST_FILE=$(mktemp /tmp/validate_build_pkgsrc.XXXXXX)
+        /opt/tools/bin/pkgin list | cut -f 1 > $PKG_LIST_FILE
+
+        EXPECTED_PKGS="curl
+            git-base
+            git-docs
+            git-contrib
+            openjdk8
+            nodejs-6.14.4
+            npm"
+
+        MISSING_PKGS=""
+        for pkg in ${EXPECTED_PKGS}; do
+            FOUND=""
+            grep -q "$pkg-[0-9].*" $PKG_LIST_FILE
+            if [[ $? -eq 0 ]]; then
+                FOUND=true
+            fi
+            grep -q "$pkg " $PKG_LIST_FILE
+            if [[ $? -eq 0 ]]; then
+                FOUND=true
+            fi
+            if [[ -z "$FOUND" ]]; then
+                MISSING_PKGS="$MISSING_PKGS $pkg"
+            fi
+        done
+        rm $PKG_LIST_FILE
+
+        if [[ -n "$MISSING_PKGS" ]]; then
+            echo "The following packages must be installed in /opt/tools:"
+            echo ""
+            echo "$MISSING_PKGS"
+            echo ""
+            echo "Use /opt/tools/bin/pkgin in <package name> ..."
+            echo ""
+            return 1
+        fi
+    fi
+    return 0
+}
+
+#
+# Check that several programs needed by the build which aren't available from
+# pkgsrc are available somewhere on the path. Trust that the versions present
+# are sufficient.
+#
+function validate_non_pkgsrc_bins {
+    REQUIRED_PROGS="mmd5
+        mmkdir
+        mput
+        msign
+        updates-imgadm"
+
+    MISSING_PROGS=""
+
+    for prog in ${REQUIRED_PROGS}; do
+        command -v $prog > /dev/null
+        if [[ $? -ne 0 ]]; then
+            MISSING_PROGS="$prog $MISSING_PROGS"
+        fi
+    done
+
+    if [[ -n "$MISSING_PROGS" ]]; then
+        echo "The following programs were not found in \$PATH:"
+        echo ""
+        echo "$MISSING_PROGS"
+        echo ""
+        echo "These should be installed by hand. If we're running on a "
+        echo "'jenkins-agent' image, they may be found in /root/bin and "
+        echo "this should be added to \$PATH."
+        echo ""
+        echo "Otherwise, the following command will install the required"
+        echo "programs:"
+        echo ""
+        echo "   \$ npm install manta imgapi-cli"
+        echo ""
+        return 1
+    fi
+    return 0
+}
+
+function usage {
+    echo "Usage: validate-build-platform [-h] [-r]"
+    echo "  -h       print usage"
+    echo "  -r       only print required pkgsrc release and description"
+    exit 2
+}
+
+#
+# Main
+#
+while getopts "rh" opt; do
+    case "${opt}" in
+        r)
+            do_required_version=true
+            ;;
+        h)
+            do_usage=true
+            ;;
+    esac
+done
+
+if [[ -n "${do_usage}" ]]; then
+    usage
+fi
+
+get_pkgsrc_sdcnode_versions
+
+if [[ -n "${do_required_version}" ]]; then
+    print_required_pkgsrc_version
+    exit $?
+else
+    RESULT=0
+    validate_pkgsrc_version
+    RESULT=$(( $RESULT + $? ))
+    validate_pkgsrc_pkgs
+    RESULT=$(( $RESULT + $? ))
+    validate_rbac_profile
+    RESULT=$(( $RESULT + $? ))
+    validate_delegated_dataset
+    RESULT=$(( $RESULT + $? ))
+    validate_build_path
+    RESULT=$(( $RESULT + $? ))
+    validate_build_platform
+    RESULT=$(( $RESULT + $? ))
+    validate_opt_tools
+    RESULT=$(( $RESULT + $? ))
+    validate_non_pkgsrc_bins
+    RESULT=$(( $RESULT + $? ))
+    if [[ "$RESULT" -gt 0 ]]; then
+        exit 1
+    else
+        exit 0
+    fi
+fi
-- 
2.21.0

