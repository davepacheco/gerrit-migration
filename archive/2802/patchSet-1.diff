From 6bea44ed942f39ba683c2fb193476b2467faf673 Mon Sep 17 00:00:00 2001
From: Jordan Hendricks <jordan.hendricks@joyent.com>
Date: Mon, 24 Apr 2017 17:40:23 +0000
Subject: [PATCH] MANTA-3226 Manta garbage collection needs to support
 multipart uploads

---
 bin/gc_create_links.js               |   3 +-
 bin/gc_links.pl                      |   3 +-
 bin/kick_off_mpu_gc.js               | 357 +++++++++++++++++++++++++++
 bin/mdemux.js                        |   9 +-
 bin/moray_gc.js                      |   1 -
 bin/mpu_gc.js                        |  74 ++++++
 bin/mpu_gc_links.pl                  |  50 ++++
 bin/mpu_gc_pg_transform.js           | 100 ++++++++
 bin/mpu_gc_transform.js              | 100 ++++++++
 bin/mpu_moray_gc.js                  |  88 +++++++
 config.json                          |  20 ++
 docs/gc-overview.md                  |   2 +-
 lib/index.js                         |  29 +++
 lib/moray_cleaner.js                 |  14 +-
 lib/mpu/common.js                    | 246 ++++++++++++++++++
 lib/mpu/mpuBatchStream.js            | 170 +++++++++++++
 lib/mpu/mpuMorayCleanerStream.js     |  99 ++++++++
 lib/mpu/mpuUnlinkLiveRecordStream.js | 177 +++++++++++++
 lib/mpu/mpuVerifyStream.js           | 157 ++++++++++++
 lib/mpu_garbage_collector.js         | 110 +++++++++
 lib/mpu_gc_pg_row_transformer.js     | 157 ++++++++++++
 package.json                         |   3 +
 sapi_manifests/mola/template         |  10 +-
 script.sh                            |   7 +
 24 files changed, 1976 insertions(+), 10 deletions(-)
 create mode 100755 bin/kick_off_mpu_gc.js
 create mode 100755 bin/mpu_gc.js
 create mode 100755 bin/mpu_gc_links.pl
 create mode 100755 bin/mpu_gc_pg_transform.js
 create mode 100755 bin/mpu_gc_transform.js
 create mode 100755 bin/mpu_moray_gc.js
 create mode 100644 config.json
 create mode 100644 lib/mpu/common.js
 create mode 100644 lib/mpu/mpuBatchStream.js
 create mode 100644 lib/mpu/mpuMorayCleanerStream.js
 create mode 100644 lib/mpu/mpuUnlinkLiveRecordStream.js
 create mode 100644 lib/mpu/mpuVerifyStream.js
 create mode 100644 lib/mpu_garbage_collector.js
 create mode 100644 lib/mpu_gc_pg_row_transformer.js
 create mode 100755 script.sh

diff --git a/bin/gc_create_links.js b/bin/gc_create_links.js
index 19f6120..34cf995 100755
--- a/bin/gc_create_links.js
+++ b/bin/gc_create_links.js
@@ -40,7 +40,8 @@ var MANTA_CONFIG = (process.env.MANTA_CONFIG ||
                     '/opt/smartdc/common/etc/config.json');
 var MANTA_CLIENT = manta.createClientFromFileSync(MANTA_CONFIG, LOG);
 var MANTA_USER = MANTA_CLIENT.user;
-var MANTA_DIR = '/' + MANTA_USER + '/stor/manta_gc/all/do';
+var MANTA_GC_DIR = (process.env.MANTA_GC_DIR || 'manta_gc');
+var MANTA_DIR = '/' + MANTA_USER + '/stor/' + MANTA_GC_DIR + '/all/do';
 var AUDIT = {
         'audit': true,
         'cronExec': 1,
diff --git a/bin/gc_links.pl b/bin/gc_links.pl
index 2d19829..c51e0c2 100755
--- a/bin/gc_links.pl
+++ b/bin/gc_links.pl
@@ -14,9 +14,8 @@
 # mako.  This should go away post-haste after the stream to many mpipes
 # is written.
 ###############################################################################
-
 if (@ARGV < 3) {
-    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " +
+    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " .
         "[manta object prefix]\n";
     exit 1;
 }
diff --git a/bin/kick_off_mpu_gc.js b/bin/kick_off_mpu_gc.js
new file mode 100755
index 0000000..0493be0
--- /dev/null
+++ b/bin/kick_off_mpu_gc.js
@@ -0,0 +1,357 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var fs = require('fs');
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var manta = require('manta');
+var path = require('path');
+
+
+
+///--- Global Objects
+
+var NAME = 'mola-mpu-gc';
+var LOG = bunyan.createLogger({
+        level: (process.env.LOG_LEVEL || 'info'),
+        name: NAME,
+        stream: process.stdout
+});
+var MOLA_CONFIG = (process.env.MOLA_CONFIG ||
+                   '/opt/smartdc/mola/etc/config.json');
+var MOLA_CONFIG_OBJ = JSON.parse(fs.readFileSync(MOLA_CONFIG));
+var MANTA_CLIENT = manta.createClientFromFileSync(MOLA_CONFIG, LOG);
+var MANTA_USER = MANTA_CLIENT.user;
+
+
+///--- Global Constants
+
+var MP = '/' + MANTA_USER + '/stor';
+var MANTA_DUMP_NAME_PREFIX = 'manta-';
+var MANTA_UPLOADS_NAME_PREFIX = 'manta_uploads-';
+
+
+
+///--- Helpers
+
+/*
+ * Helper that sets up necessary environment variables for the commands run as
+ * part of a phase in the MPU GC job.
+ *
+ * Inputs:
+ *  - opts: an options blob that must include:
+ *      - jobName: name of the job to pass to the job manager
+ *      - marlinPathToAsset: the relative path of a tarball that is unpacked as
+ *          an asset in the job
+ */
+function getEnvCommon(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.jobName, 'opts.jobName');
+        assert.string(opts.marlinPathToAsset, 'opts.marlinPathToAsset');
+
+/* BEGIN JSSTYLED */
+        return (' \
+set -o pipefail && \
+export MANTA_USER=' + MANTA_USER + ' && \
+export MANTA_MPU_GC=' + opts.jobName + ' && \
+export MARLIN_JOB=$(echo $MANTA_OUTPUT_BASE | cut -d "/" -f 4) && \
+export NOW=$(date "+%Y-%m-%d-%H-%M-%S") && \
+cd /assets/ && gtar -xzf ' + opts.marlinPathToAsset + ' && cd mola && \
+');
+/* END JSSTYLED */
+}
+
+
+
+/*
+ * Returns the command that is run during the map phase of the MPU GC job.
+ * This command calls into bin/mpu_gc_pg_transform.js, which transforms
+ * input from the dump into tab-separated records that can be processed
+ * by the reduce phase of the job.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - earliestDumpDate: TODO
+ *      - numberReducers: number of reducers to assign to the job
+ *      - objectId: optional objectId TODO
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuPgTransformCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.earliestDumpDate, 'opts.earliestDumpDate');
+        assert.number(opts.numberReducers, 'opts.numberReducers');
+
+/* BEGIN JSSTYLED */
+        var grepForObject = '';
+        if (opts.objectId) {
+                grepForObject = ' | grep ' + opts.objectId + ' | ';
+        }
+        return (getEnvCommon(opts) + ' \
+export MORAY_SHARD=$(echo $mc_input_key | cut -d "/" -f 5) && \
+export DUMP_DATE=$(basename $mc_input_key | sed \'s/^\\w*-//; s/.\\w*$//;\') && \
+gzcat -f | \
+  ./build/node/bin/node ./bin/mpu_gc_pg_transform.js -d $DUMP_DATE \
+    -e ' + opts.earliestDumpDate + ' \
+    -m $MORAY_SHARD' + grepForObject + ' | \
+  msplit -n ' + opts.numberReducers + ' \
+');
+/* END JSSTYLED */
+}
+
+
+/*
+ * Returns the command that is run during the reduce phase of the MPU GC job.
+ * This phase calls into bin/mpu_gc.js, which is a thin wrapper that calls into
+ * lib/mpu_garbage_colector.js, which performs the actual logic of deciding
+ * what mako and moray actions need to be taken.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - gracePeriodSeconds: optional TODO
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuGcCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.optionalNumber(opts.gracePeriodSeconds,
+            'opts.gracePeriodSeconds');
+
+        var gracePeriodOption = '';
+        if (opts.gracePeriodSeconds) {
+                gracePeriodOption = ' -g ' + opts.gracePeriodSeconds;
+        }
+        //We use a UUID only because there's no way (yet) to get a reference
+        // to which reducer this is running on.
+/* BEGIN JSSTYLED */
+        return (getEnvCommon(opts) + ' \
+export UUID=$(uuid) && \
+export MANTA_PRE=/$MANTA_USER/stor/$MANTA_MPU_GC/all && \
+export MANTA_FILE_PRE=$MANTA_PRE/done/$NOW-$MARLIN_JOB-X-$UUID && \
+export MANTA_PATTERN=$MANTA_FILE_PRE-{1}-{2} && \
+export MANTA_LINKS=$MANTA_PRE/do/$NOW-$MARLIN_JOB-X-$UUID-links && \
+export PERL=/usr/perl5/bin/perl && \
+export LINKS_FILE=./links.txt && \
+sort | \
+./build/node/bin/node ./bin/mpu_gc.js' + gracePeriodOption + ' | \
+./bin/mpu_gc_links.pl $MANTA_USER $LINKS_FILE $MANTA_FILE_PRE | \
+./build/node/bin/node ./bin/mdemux.js -p $MANTA_PATTERN && \
+cat $LINKS_FILE | mpipe $MANTA_LINKS \
+');
+/* END JSSTYLED */
+}
+
+
+function parseOptions() {
+        var option;
+        //First take what's in the config file, override what's on the
+        // command line, and use the defaults if all else fails.
+        var opts = MOLA_CONFIG_OBJ;
+        opts.shards = opts.shards || [];
+        var parser = new getopt.BasicParser('a:d:g:m:no:p:r:t',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'a':
+                        opts.assetFile = option.optarg;
+                        break;
+                case 'd':
+                        opts.gcReduceDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                case 'm':
+                        opts.shards.push(option.optarg);
+                        break;
+                case 'n':
+                        opts.noJobStart = true;
+                        break;
+                case 'o':
+                        opts.objectId = option.optarg;
+                        break;
+                case 'p':
+                        opts.gcMapDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'r':
+                        opts.gcReduceMemory = parseInt(option.optarg, 10);
+                        break;
+                // TODO what is this for?
+                case 't':
+                        opts.jobName = 'manta_mpu_gc_test';
+                        opts.jobRoot = MP + '/manta_mpu_gc_test';
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+
+        //Set up some defaults...
+        opts.jobName = opts.jobName || 'manta_mpu_gc';
+        opts.jobRoot = opts.jobRoot || MP + '/manta_mpu_gc';
+
+        opts.assetDir = opts.jobRoot + '/assets';
+        opts.assetObject = opts.assetDir + '/mola.tar.gz';
+        opts.assetFile = opts.assetFile ||
+                '/opt/smartdc/common/bundle/mola.tar.gz';
+
+        opts.gcMapDisk = opts.gcMapDisk || 32;
+        opts.gcReduceMemory = opts.gcReduceMemory || 8192;
+        opts.gcReduceDisk = opts.gcReduceDisk || 32;
+        opts.marlinPathToAsset = opts.assetObject.substring(1);
+        opts.marlinAssetObject = opts.assetObject;
+
+        opts.directories = [
+                opts.jobRoot + '/all',
+                opts.jobRoot + '/all/do',
+                opts.jobRoot + '/all/done',
+                opts.jobRoot + '/mako',
+                opts.jobRoot + '/moray'
+        ];
+
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-a asset_file]';
+        str += ' [-g grace_period_seconds]';
+        str += ' [-m moray_shard]';
+        str += ' [-n no_job_start]';
+        str += ' [-o object_id]';
+        str += ' [-r marlin_reducer_memory]';
+        str += ' [-t output_to_test]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+/*
+ * Returns a job definition for the MPU GC job that can be passed to the
+ * job manager.
+ *
+ * Inputs:
+ *  - opts: options blob passed to helpers creating phases of the job (see
+ *          those functions for documentation)
+ *  - cb: callback of the form cb(err, job)
+ */
+function getMpuGcJob(opts, cb) {
+        //We use the number of shards + 1 so that we know
+        // we are always using multiple reducers.  There's
+        // no reason this can't be much more.
+        opts.numberReducers = opts.shards.length + 1;
+
+        var pgCmd = getMpuPgTransformCmd(opts);
+        var gcCmd = getMpuGcCmd(opts);
+        var job = {
+                phases: [ {
+                        type: 'storage-map',
+                        exec: pgCmd,
+                        disk: opts.gcMapDisk
+                }, {
+                        type: 'reduce',
+                        count: opts.numberReducers,
+                        memory: opts.gcReduceMemory,
+                        disk: opts.gcReduceDisk,
+                        exec: gcCmd
+                } ]
+        };
+
+        LOG.info({ job: job }, 'MPU GC Marlin Job Definition');
+
+        cb(null, job);
+}
+
+
+//Expects the filename to be in the format:
+// /.../manta-2012-11-30-23-00-07.gz
+// Returns: 2012-11-30-23-00-07
+function extractDate(p) {
+        var filename = path.basename(p);
+        var d = filename.substring(filename.indexOf('-') + 1);
+        d = d.substring(0, d.indexOf('.'));
+        return (d);
+}
+
+
+/*
+ * Determines what input objects to pass to the MPU GC job.
+ * TODO
+ *
+ * Inputs:
+ *  - opts: an options block passed directly to common.findObjectsForShards
+ *  - cb: callback of the form cb(err, objects)
+ */
+function findMpuGcObjects(opts, cb) {
+        LOG.info({ opts: opts }, 'Finding MPU Gc Objects.');
+        var shards = opts.shards;
+
+        if (shards.length === 0) {
+                cb(new Error('No shards specified.'));
+                return;
+        }
+
+        lib.common.findObjectsForShards({
+                'log': LOG,
+                'shards': shards,
+                'client': MANTA_CLIENT,
+                'tablePrefixes': [
+                        MANTA_DUMP_NAME_PREFIX,
+                        MANTA_UPLOADS_NAME_PREFIX
+                ]
+        }, function (err, results) {
+                if (err) {
+                        cb(err);
+                        return;
+                }
+
+                var objects = [];
+                var dates = [];
+
+                for (var j = 0; j < results.length; ++j) {
+                        var obj = results[j];
+                        objects.push(obj);
+                        //Get the date from the filename...
+                        dates.push(extractDate(obj));
+                }
+
+                dates.sort();
+                LOG.info({
+                        dates: dates,
+                        objects: objects
+                }, 'found mpu gc objects');
+                opts.earliestDumpDate = dates[0];
+                cb(null, objects);
+        });
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+
+_opts.getJobDefinition = getMpuGcJob;
+_opts.getJobObjects = findMpuGcObjects;
+
+var jobManager = lib.createJobManager(_opts, MANTA_CLIENT, LOG);
+jobManager.run(function () {
+        MANTA_CLIENT.close();
+        LOG.info('Done for now.');
+});
diff --git a/bin/mdemux.js b/bin/mdemux.js
index 311947d..2958be1 100755
--- a/bin/mdemux.js
+++ b/bin/mdemux.js
@@ -21,8 +21,11 @@ var util = require('util');
 var vasync = require('vasync');
 
 
-
-/**
+/*
+ *
+ * TODO clean this example up: the -f flag isn't real, and mpipe does not do
+ * `mpipe -p`, which this example kind of implies
+ *
  * Bucketize by fields in a line, uploading to manta via mpipe.  For example,
  * this will bucketize quotes into last/first name files, given a stream
  * of records with lines like:
@@ -31,6 +34,7 @@ var vasync = require('vasync');
  *    -p /$MANTA_USER/stor/quotes/{2}/{1}/quotes.txt
  *
  * The -p is required.  -f defaults to 1, -d defaults to (tab).
+ *
  */
 
 
@@ -311,6 +315,7 @@ DemuxFileStream.prototype._write = function dfsWrite(line, _, done) {
 };
 
 
+///--- Main
 
 var _opts = parseOptions();
 
diff --git a/bin/moray_gc.js b/bin/moray_gc.js
index 98487f6..7bd3d06 100755
--- a/bin/moray_gc.js
+++ b/bin/moray_gc.js
@@ -31,7 +31,6 @@ var stream = require('stream');
 
 var VE = verror.VError;
 
-
 var LOG = bunyan.createLogger({
         level: (process.env.LOG_LEVEL || 'info'),
         name: 'moray_gc',
diff --git a/bin/mpu_gc.js b/bin/mpu_gc.js
new file mode 100755
index 0000000..8798c44
--- /dev/null
+++ b/bin/mpu_gc.js
@@ -0,0 +1,74 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+
+
+
+///--- Helpers
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('g:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-g grace_period_seconds]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+//As a convience, seconds to millis
+if (_opts.gracePeriodSeconds) {
+        _opts.gracePeriodMillis = _opts.gracePeriodSeconds * 1000;
+}
+
+var _garbageCollector = lib.createMpuGarbageCollector(_opts);
+_garbageCollector.on('moray', function (moray) {
+        console.log('moray\t' + moray.toString());
+});
+
+_garbageCollector.on('mako', function (mako) {
+        console.log('mako\t' + mako.toString());
+});
+
+_garbageCollector.on('error', function (err) {
+        console.error({ err: err }, 'Error with line, exiting.');
+        process.exit(1);
+});
+
+process.stdin.resume();
diff --git a/bin/mpu_gc_links.pl b/bin/mpu_gc_links.pl
new file mode 100755
index 0000000..153af6e
--- /dev/null
+++ b/bin/mpu_gc_links.pl
@@ -0,0 +1,50 @@
+#!/usr/bin/env perl
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+###############################################################################
+# Acts as a filter to output all the links that must be made for moray and
+# mako.  This should go away post-haste after the stream to many mpipes
+# is written.
+###############################################################################
+
+
+if (@ARGV < 3) {
+    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " .
+        "[manta object prefix]\n";
+    exit 1;
+}
+$user = $ARGV[0];
+$file = $ARGV[1];
+$prefix = $ARGV[2];
+$dir = 'manta_mpu_gc';
+
+while($line = <STDIN>) {
+    @parts = split(/\t/, $line);
+    #Parts 0 will be either "mako" or "moray"
+    #Parts 1 will be the node or shard id
+    $k{$parts[0]}{$parts[1]} = 1;
+    print $line;
+}
+
+open(OUT, ">$file");
+for $node (sort keys %{ $k{"mako"} } ) {
+    $object = "$prefix-mako-$node";
+    $k = (split(/\//, $object))[-1];
+    print OUT "mmkdir /$user/stor/$dir/mako/$node\n";
+    print OUT "mln $object /$user/stor/$dir/mako/$node/$k\n";
+}
+for $shard (sort keys %{ $k{"moray"} } ) {
+    $object = "$prefix-moray-$shard";
+    $k = (split(/\//, $object))[-1];
+    print OUT "mmkdir /$user/stor/$dir/moray/$shard\n";
+    print OUT "mln $prefix-moray-$shard /$user/stor/$dir/moray/$shard/$k\n";
+}
+close(OUT);
diff --git a/bin/mpu_gc_pg_transform.js b/bin/mpu_gc_pg_transform.js
new file mode 100755
index 0000000..e6a1364
--- /dev/null
+++ b/bin/mpu_gc_pg_transform.js
@@ -0,0 +1,100 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2014, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+var util = require('util');
+
+
+
+///--- Helpers
+
+function isValidDate(date) {
+        return (util.isDate(date) && !isNaN(date.getTime()));
+}
+
+function parseDate(dateString) {
+        //So we're forcing a weird format here.  File dates come in the format
+        // 2012-10-18-23-00-02.
+        var parts = dateString.split('-');
+        if (parts.length != 6) {
+                usage('Invalid date: ' + dateString);
+        }
+        var ds = parts[0] + '-' + parts[1] + '-' + parts[2] + 'T' +
+                parts[3] + ':' + parts[4] + ':' + parts[5] + 'Z';
+        var date = new Date(ds);
+        if (isValidDate(date)) {
+                return (date);
+        }
+        //We'll let the caller catch this.
+        return (dateString);
+}
+
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('d:e:m:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'd':
+                        opts.dumpDate = parseDate(option.optarg);
+                        break;
+                case 'e':
+                        opts.earliestDumpDate = parseDate(option.optarg);
+                        break;
+                case 'm':
+                        opts.morayHostname = option.optarg;
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+        if (!opts.dumpDate) {
+                usage('-d [dump_date] is a required argument');
+        }
+        if (!opts.earliestDumpDate) {
+                usage('-e [earliest_dump_date] is a required argument');
+        }
+        if (!opts.morayHostname) {
+                usage('-m [moray_hostname] is a required argument');
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-d dump_date] [-e earliest_dump_time] [-m moray_hostname]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+
+var _gcPgRowTransformer = lib.createMpuGcPgRowTransformer(_opts);
+_gcPgRowTransformer.on('row', function (row) {
+        console.log(row.toString());
+});
+
+process.stdin.resume();
diff --git a/bin/mpu_gc_transform.js b/bin/mpu_gc_transform.js
new file mode 100755
index 0000000..016756b
--- /dev/null
+++ b/bin/mpu_gc_transform.js
@@ -0,0 +1,100 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+var util = require('util');
+
+
+
+///--- Helpers
+
+function isValidDate(date) {
+        return (util.isDate(date) && !isNaN(date.getTime()));
+}
+
+function parseDate(dateString) {
+        //So we're forcing a weird format here.  File dates come in the format
+        // 2012-10-18-23-00-02.
+        var parts = dateString.split('-');
+        if (parts.length != 6) {
+                usage('Invalid date: ' + dateString);
+        }
+        var ds = parts[0] + '-' + parts[1] + '-' + parts[2] + 'T' +
+                parts[3] + ':' + parts[4] + ':' + parts[5] + 'Z';
+        var date = new Date(ds);
+        if (isValidDate(date)) {
+                return (date);
+        }
+        //We'll let the caller catch this.
+        return (dateString);
+}
+
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('d:e:m:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'd':
+                        opts.dumpDate = parseDate(option.optarg);
+                        break;
+                case 'e':
+                        opts.earliestDumpDate = parseDate(option.optarg);
+                        break;
+                case 'm':
+                        opts.morayHostname = option.optarg;
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+        if (!opts.dumpDate) {
+                usage('-d [dump_date] is a required argument');
+        }
+        if (!opts.earliestDumpDate) {
+                usage('-e [earliest_dump_date] is a required argument');
+        }
+        if (!opts.morayHostname) {
+                usage('-m [moray_hostname] is a required argument');
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-d dump_date] [-e earliest_dump_time] [-m moray_hostname]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+
+var _gcPgRowTransformer = lib.createMpuGcPgRowTransformer(_opts);
+_gcPgRowTransformer.on('row', function (row) {
+        console.log(row.toString());
+});
+
+process.stdin.resume();
diff --git a/bin/mpu_moray_gc.js b/bin/mpu_moray_gc.js
new file mode 100755
index 0000000..f7fc748
--- /dev/null
+++ b/bin/mpu_moray_gc.js
@@ -0,0 +1,88 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+var http = require('http');
+
+var bunyan = require('bunyan');
+var fs = require('fs');
+var lstream = require('lstream');
+var mahi = require('mahi');
+var manta = require('manta');
+var vstream = require('vstream');
+
+var lib = require('../lib');
+var mpu = require('../lib/mpu');
+
+
+var LOG = bunyan.createLogger({
+        //level: (process.env.LOG_LEVEL || 'info'),
+        level: (process.env.LOG_LEVEL || 'trace'),
+        name: 'mpu_gc_streams',
+        stream: process.stdout,
+        serializers: bunyan.stdSerializers
+});
+
+var MANTA_CONFIG = (process.env.MANTA_CONFIG ||
+                    '/opt/smartdc/common/etc/config.json');
+var CONFIG = JSON.parse(fs.readFileSync(MANTA_CONFIG, { encoding: 'utf8' }));
+
+var MANTA_CLIENT = manta.createClientFromFileSync(MANTA_CONFIG, LOG);
+var MAHI_CLIENT = mahi.createClient(CONFIG.auth);
+
+
+var mmcls = vstream.wrapStream(
+        new mpu.createMpuMorayCleanerStream({
+                log: LOG,
+                dryRun: true,
+                verbose: true
+        }
+));
+
+var mpuGcStreams = new vstream.PipelineStream({
+        streams: [
+                vstream.wrapTransform(new lstream({ highWaterMark: 0 })),
+                vstream.wrapTransform(new mpu.createMpuBatchStream({ log: LOG })),
+                vstream.wrapTransform(new mpu.createMpuVerifyStream({ log: LOG })),
+                vstream.wrapTransform(new mpu.createMpuUnlinkLiveRecordStream({
+                        log: LOG,
+                        dryRun: true,
+                        verbose: true,
+                        mantaClient: MANTA_CLIENT,
+                        mahiClient: MAHI_CLIENT,
+                        type: 'partRecords'
+                })),
+                vstream.wrapTransform(new mpu.createMpuUnlinkLiveRecordStream({
+                        log: LOG,
+                        dryRun: true,
+                        verbose: true,
+                        mantaClient: MANTA_CLIENT,
+                        mahiClient: MAHI_CLIENT,
+                        type: 'uploadRecord'
+                })),
+                mmcls
+        ],
+
+        streamOpts: {
+                highWaterMark: 0,
+                objectMode: true
+        }
+});
+
+// TODO comment explaining why we do this here and not on mpuGcStreams
+mmcls.on('finish', function cleanup() {
+        MAHI_CLIENT.close();
+        MANTA_CLIENT.close();
+});
+
+//var s = fs.createReadStream('/root/mola/test-file.txt');
+var s = fs.createReadStream('/root/mola/non-sorted-batch.txt');
+//var s = fs.createReadStream('/root/mola/test-file-simple.txt');
+s.pipe(mpuGcStreams);
diff --git a/config.json b/config.json
new file mode 100644
index 0000000..6e1e562
--- /dev/null
+++ b/config.json
@@ -0,0 +1,20 @@
+{
+        "sapi": {
+                "url": "http://sapi.emy-13.joyent.us"
+        },
+        "manta_url": "https://manta.emy-13.joyent.us",
+        "manta": {
+                "url": "https://manta.emy-13.joyent.us",
+                "user": "poseidon",
+                "sign": {
+                        "key": "/root/.ssh/id_rsa-poseidon",
+                        "keyId": "ef:0e:27:45:c5:95:4e:92:ba:ab:03:17:e5:3a:60:14"
+                },
+                "retry": {
+                        "attempts": 5,
+                        "minTimeout": 1000
+                },
+                "connectTimeout": 1000,
+                "rejectUnauthorized": false
+        }
+}
diff --git a/docs/gc-overview.md b/docs/gc-overview.md
index 868a21b..c9ff06a 100644
--- a/docs/gc-overview.md
+++ b/docs/gc-overview.md
@@ -170,7 +170,7 @@ A cron runs in the cron zone that will periodically look in:
     /poseidon/stor/manta_gc/all/do/
 
 Download, and execute the instructions.  Once the links are successfully created,
-the links file is deleted.  The executable is in `mola/bin/gc_create_links.sh`.
+the links file is deleted.  The executable is in `mola/bin/gc_create_links.js`.
 
 ## Phase 3: Moray Cleanup
 
diff --git a/lib/index.js b/lib/index.js
index 4e2dc34..59dd9ae 100644
--- a/lib/index.js
+++ b/lib/index.js
@@ -17,6 +17,8 @@ var CruftCollector = require('./cruft_collector');
 var CruftRowTransformer = require('./cruft_row_transformer');
 var GarbageCollector = require('./garbage_collector');
 var GcPgRowTransformer = require('./gc_pg_row_transformer');
+var MpuGarbageCollector = require('./mpu_garbage_collector');
+var MpuGcPgRowTransformer = require('./mpu_gc_pg_row_transformer');
 var JobManager = require('./job_manager');
 var MorayCleaner = require('./moray_cleaner');
 var Rebalancer = require('./rebalancer');
@@ -86,6 +88,17 @@ function createGarbageCollector(opts, listener) {
 }
 
 
+function createMpuGarbageCollector(opts, listener) {
+        assert.object(opts.reader);
+        if (opts.gracePeriodMillis) {
+                assert.number(opts.gracePeriodMillis);
+        }
+
+        var mpuGarbageCollector = new MpuGarbageCollector(opts, listener);
+        return (mpuGarbageCollector);
+}
+
+
 function createJobManager(opts, mantaClient, log) {
         assert.object(opts);
         assert.object(mantaClient);
@@ -117,6 +130,20 @@ function createGcPgRowTransformer(opts, listener) {
 }
 
 
+function createMpuGcPgRowTransformer(opts, listener) {
+        assert.object(opts, 'opts missing');
+        assert.object(opts.reader, 'opts.reader missing');
+        assert.ok(util.isDate(opts.dumpDate),
+                  'opts.dumpDate isnt Date');
+        assert.ok(util.isDate(opts.earliestDumpDate),
+                  'opts.earliestDumpDate isnt Date');
+        assert.string(opts.morayHostname, 'Moray hostname missing');
+
+        var mpuGcPgRowTransformer = new MpuGcPgRowTransformer(opts, listener);
+        return (mpuGcPgRowTransformer);
+}
+
+
 function createRebalancer(opts, listener) {
         assert.object(opts, 'opts missing');
         assert.object(opts.reader, 'opts.reader missing');
@@ -147,9 +174,11 @@ module.exports = {
         createCruftCollector: createCruftCollector,
         createCruftRowTransformer: createCruftRowTransformer,
         createGarbageCollector: createGarbageCollector,
+        createMpuGarbageCollector: createMpuGarbageCollector,
         createGcPgRowTransformer: createGcPgRowTransformer,
         createJobManager: createJobManager,
         createMorayCleaner: createMorayCleaner,
+        createMpuGcPgRowTransformer: createMpuGcPgRowTransformer,
         createRebalancer: createRebalancer,
         createSchemaReader: createSchemaReader
 };
diff --git a/lib/moray_cleaner.js b/lib/moray_cleaner.js
index ec5a981..49a55d1 100644
--- a/lib/moray_cleaner.js
+++ b/lib/moray_cleaner.js
@@ -23,7 +23,9 @@ var BatchStream = require('./batch_stream').BatchStream;
 
 ///--- Globals
 
-var MORAY_BUCKET = 'manta_delete_log';
+var MANTA_DELETE_BUCKET = 'manta_delete_log';
+var MANTA_FINALIZING_BUCKET = 'manta_uploads';
+
 var MORAY_CONNECT_TIMEOUT = 10000;
 var MORAY_PORT = 2020;
 
@@ -62,6 +64,7 @@ function deleteFromMoray(opts, cb) {
         var self = opts.self;
         var lines = opts.lines;
         var expectedShard = opts.expectedShard;
+        var bucket = opts.bucket;
         var client = opts.client;
         var ms = 'moray';
 
@@ -114,7 +117,7 @@ function deleteFromMoray(opts, cb) {
         filter += ')';
 
         var startDate = new Date();
-        client.deleteMany(MORAY_BUCKET, filter, function (err) {
+        client.deleteMany(bucket, filter, function (err) {
                 var endDate = new Date();
                 var latency = endDate.getTime() - startDate.getTime();
 
@@ -205,9 +208,13 @@ function MorayCleanerStream(opts) {
         assert.object(opts, 'opts');
         assert.object(opts.log, 'opts.log');
         assert.string(opts.shard, 'opts.shard');
+        assert.string(opts.bucket, 'opts.bucket');
         assert.string(opts.object, 'opts.object');
         assert.object(opts.parent, 'opts.parent');
 
+        assert.ok((opts.bucket === MANTA_DELETE_BUCKET) ||
+                  (opts.bucket === MANTA_FINALIZING_BUCKET));
+
         stream.Writable.call(this, {
                 objectMode: true,
                 highWaterMark: 0
@@ -215,6 +222,7 @@ function MorayCleanerStream(opts) {
 
         self.mcs_log = opts.log;
         self.mcs_shard = opts.shard;
+        self.mcs_bucket = opts.bucket;
         self.mcs_object = opts.object;
         self.mcs_parent = opts.parent;
         self.mcs_client = null;
@@ -278,6 +286,7 @@ MorayCleanerStream.prototype.mcsCommit = function mcsCommit(batch, done) {
                 self: self.mcs_parent,
                 lines: batch.entries,
                 expectedShard: self.mcs_shard,
+                bucket: self.mcs_bucket,
                 client: self.mcs_client
         }, function (err) {
                 if (err) {
@@ -317,6 +326,7 @@ MorayCleaner.prototype.cleanStream = function cleanStream(opts) {
 
         var cleaner = new MorayCleanerStream({
                 shard: opts.shard,
+                bucket: opts.bucket,
                 object: opts.object,
                 parent: self,
                 log: log
diff --git a/lib/mpu/common.js b/lib/mpu/common.js
new file mode 100644
index 0000000..0c6c4c5
--- /dev/null
+++ b/lib/mpu/common.js
@@ -0,0 +1,246 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var sprintf = util.format;
+
+var MPU_MORAY_BUCKET = 'manta_uploads';
+
+var MPU_PART_OBJECT = 'part';
+var MPU_UPLOAD_DIRECTORY = 'directory';
+
+var MPUOBJ_PART = '2_partRecord';
+var MPUOBJ_UPLOADDIR = '1_uploadRecord';
+var MPUOBJ_FINALIZINGRECORD = '0_finalizingRecord';
+
+var MPU_FR_TYPE_COMMIT = 'commit';
+var MPU_FR_TYPE_ABORT = 'abort';
+
+var MPU_RECORD_ATTR_UPLOADID = 'uploadId';
+var MPU_RECORD_ATTR_MPUOBJ = 'mpuObject';
+var MPU_RECORD_ATTR_DATE = 'date';
+var MPU_RECORD_ATTR_SHARD = 'shard';
+var MPU_RECORD_ATTR_KEY = 'key';
+
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MULRS_TYPE_PART = mulrs.MULRS_TYPE_PART;
+var MULRS_TYPE_UPLOADDIR = mulrs.MULRS_TYPE_UPLOADDIR;
+
+
+/*
+ * TODO this one needs a comment!
+ */
+function recordToObject(record) {
+        assert.string(record);
+
+        var split = record.split('\t');
+        assert.ok(split.length >= 4, sprintf('record must contain at least 4 ' +
+                'tab-separated fields: \"%s\"', record));
+
+        var uploadId = split[0];
+        var mpuObject = split[1];
+        var date = split[2];
+        var key;
+
+        assert.ok(mpuObject === MPUOBJ_PART ||
+                mpuObject === MPUOBJ_UPLOADDIR ||
+                mpuObject === MPUOBJ_FINALIZINGRECORD,
+                sprintf('invalid mpu object type: \"%s\"', mpuObject));
+
+        if (mpuObject === MPUOBJ_FINALIZINGRECORD) {
+                assert.ok(split.length == 6, sprintf('finalizing record must ' +
+                        'contain 6 tab-separated fields: \"%s\"', record));
+
+                var shard = split[3];
+                key = split[4];
+                var finalizingType = split[5];
+
+                assert.ok(finalizingType === MPU_FR_TYPE_COMMIT ||
+                          finalizingType === MPU_FR_TYPE_ABORT);
+
+                return new FinalizingRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        shard: shard,
+                        date: date,
+                        type: finalizingType
+                });
+        } else {
+                assert.ok(split.length == 4, 'upload/part records must ' +
+                        'contain 4 tab-separated fields');
+
+                key = split[3];
+
+                var mulrsType;
+                if (mpuObject === MPUOBJ_UPLOADDIR) {
+                        mulrsType = MULRS_TYPE_UPLOADDIR;
+                } else {
+                        mulrsType = MULRS_TYPE_PART;
+                }
+                assert.string(mulrsType);
+
+                return new LiveRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        type: mulrsType,
+                        date: date
+
+                });
+        }
+}
+
+/*
+ * Represents a finalizing record in the streams that process the metadata
+ * record cleanup.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": the Moray key for this record
+ *   - "shard": Moray shard of the record
+ *   - "date": date on the Moray record
+ *
+ */
+function FinalizingRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.string(opts.shard, 'opts.shard');
+        assert.string(opts.date, 'opts.date');
+        assert.string(opts.type, 'opts.type');
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.shard = opts.shard;
+        this.date = opts.date;
+        this.type = opts.type;
+
+        this.toString = function toString() {
+                return (this.uploadId + '\t' +
+                        MPUOBJ_FINALIZINGRECORD + '\t' +
+                        this.date + '\t' +
+                        this.shard + '\t' +
+                        this.type + '\t' +
+                        this.key);
+        };
+}
+
+/*
+ * Represents a "live" Manta record in the streams that process the metadata
+ * record cleanup. In particular, a live record is either the part record or
+ * upload record of a given MPU.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": key to record in Moray
+ *   - "date": date on the Moray record
+ *   - "type": either "uploadRecord" or "partRecord"
+ *
+ */
+function LiveRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.string(opts.date, 'opts.date');
+        assert.string(opts.type, 'opts.type');
+        assert.ok(opts.type === MULRS_TYPE_PART ||
+                  opts.type === MULRS_TYPE_UPLOADDIR);
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.date = opts.date;
+        this.type = opts.type;
+
+        this.toString = function toString() {
+                return (this.uploadId + '\t' +
+                        this.type + '\t' +
+                        this.date + '\t' +
+                        this.key);
+        };
+}
+
+
+/*
+ * Represents a collection of all of the records related to a given multipart
+ * upload.
+ *
+ * Parameters:
+ * - opts: an options option with the following required properties:
+ *   - "uploadId": the MPU upload id
+ *   - "finalizingRecord": a tab-separated string representing the finalizing
+ *      record of this MPU that can be passed into the FinalizingRecord
+ *      constructor
+ *
+ * The following properties are optional:
+ *   - "uploadRecord": tab-separated string representing the upload record of
+ *      this MPU
+ *   - "partRecords": an array of tab-separated strings representing the part
+ *     records. If this property is present, the "uploadRecord" property must be
+ *     present as well.
+ */
+function MpuGcBatch(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.object(opts.finalizingRecord, 'opts.finalizingRecord');
+        assert.ok(opts.finalizingRecord instanceof FinalizingRecord);
+
+        /*
+         * It's possible there is a finalizing record and no upload or part
+         * records. But if we have don't have an upload record, we shouldn't see
+         * any part records.
+         */
+        assert.optionalObject(opts.uploadRecord, 'opts.uploadRecord');
+        if (opts.uploadRecord) {
+                assert.ok(opts.uploadRecord instanceof LiveRecord);
+                assert.ok(opts.uploadRecord.type === MPUOBJ_UPLOADDIR);
+
+                assert.optionalArrayOfObject(opts.partRecords,
+                        'opts.partRecords');
+                if (opts.partRecords) {
+                        opts.partRecords.forEach(function (r) {
+                                assert.ok(r instanceof LiveRecord);
+                                assert.ok(r.type === MPUOBJ_PART);
+                        });
+                }
+        } else {
+                assert.ok(!opts.partRecords, 'Part records must have an ' +
+                        'associated upload record');
+        }
+
+        var self = this;
+        self.uploadId = opts.uploadId;
+        self.finalizingRecord = opts.finalizingRecord;
+        self.uploadRecord = opts.uploadRecord;
+        self.partRecords = opts.partRecords;
+}
+
+module.exports = {
+        recordToObject: recordToObject,
+        MpuGcBatch: MpuGcBatch,
+        LiveRecord: LiveRecord,
+        FinalizingRecord: FinalizingRecord,
+
+        MPU_PART_OBJECT: MPU_PART_OBJECT,
+        MPU_UPLOAD_DIRECTORY: MPU_UPLOAD_DIRECTORY,
+
+        MPUOBJ_PART: MPUOBJ_PART,
+        MPUOBJ_UPLOADDIR: MPUOBJ_UPLOADDIR,
+        MPUOBJ_FINALIZINGRECORD: MPUOBJ_FINALIZINGRECORD,
+
+        MPU_RECORD_ATTR_UPLOADID: MPU_RECORD_ATTR_UPLOADID,
+        MPU_RECORD_ATTR_MPUOBJ: MPU_RECORD_ATTR_MPUOBJ,
+        MPU_RECORD_ATTR_DATE: MPU_RECORD_ATTR_DATE,
+        MPU_RECORD_ATTR_SHARD: MPU_RECORD_ATTR_SHARD,
+        MPU_RECORD_ATTR_KEY: MPU_RECORD_ATTR_KEY,
+        MPU_MORAY_BUCKET: MPU_MORAY_BUCKET
+};
diff --git a/lib/mpu/mpuBatchStream.js b/lib/mpu/mpuBatchStream.js
new file mode 100644
index 0000000..64dab05
--- /dev/null
+++ b/lib/mpu/mpuBatchStream.js
@@ -0,0 +1,170 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./common');
+
+var sprintf = util.format;
+
+/*
+ * MpuBatchStream: Collects all records in a stream for related mulitpart
+ * uploads into a single batch, and passes this batch along to the next stream.
+ *
+ * NOTE: This stream assumes the input is sorted by upload ID and will throw an
+ * exception if it encounters the same upload ID twice.
+ *
+ * Parameters:
+ * - "opts": an options object with the following required parameters:
+ *      - "log": a bunyan logger
+ */
+function MpuBatchStream(opts) {
+        var self = this;
+
+        assert.object(opts, 'opts');
+        assert.object(opts.log, 'opts.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+        self.log = opts.log;
+
+        /* Current batch pointers */
+        self.mpu_batch = [];            // array of record objects in the batch
+        self.mpu_uploadId = null;       // current upload ID
+
+        /*
+         * Keep track of upload ids we've seen to ensure the input is, in fact,
+         * in sorted order. We maintain some state about these to ease
+         * port-mortem debugging if this stream throws because the input isn't
+         * sorted, which could lead to metadata cruft from MPUs.
+         */
+        self.mpu_UPLOAD_IDS = {};
+}
+util.inherits(MpuBatchStream, stream.Transform);
+
+/*
+ * Sends the current batch to the next stream, and resets the internal stream
+ * state to prepare for a new batch.
+ */
+MpuBatchStream.prototype.commitBatch = function commitBatch() {
+        var self = this;
+        assert.string(self.mpu_uploadId);
+        assert.ok(self.mpu_batch.length > 0, sprintf('no records for batch ' +
+                        '(upload id %s)', self.mpu_uploadId));
+        assert.object(self.mpu_UPLOAD_IDS[self.mpu_uploadId]);
+
+        var batch = {
+                uploadId: self.mpu_uploadId,
+                records: self.mpu_batch
+        };
+
+        self.mpu_UPLOAD_IDS[self.mpu_uploadId].status = 'completed';
+        self.push(batch);
+
+        self.mpu_uploadId = null;
+        self.mpu_batch = [];
+};
+
+/*
+ * Sets the upload ID for the current batch, and throws an exception if we've
+ * seen this upload ID in a previous batch on this stream.
+ *
+ * Parameters:
+ * - "id": upload ID for the new batch
+ */
+MpuBatchStream.prototype.createBatch = function createBatch(id) {
+        var self = this;
+
+        assert.uuid(id, 'id');
+        assert.ok(self.mpu_uploadId === null, 'other batch in process');
+
+        if (self.mpu_UPLOAD_IDS[id]) {
+                var msg = sprintf('Upload id \"%s\" has already been ' +
+                        'processed. This is very bad. Some records may not ' +
+                        'be garbage collected properly as a result.', id);
+                self.log.fatal(msg);
+                throw (new Error(msg));
+        } else {
+                self.mpu_uploadId = id;
+                self.mpu_UPLOAD_IDS[id] = {
+                        uploadId: id,
+                        status: 'processing',
+                        numRecords: 0
+                };
+        }
+};
+
+/*
+ * Push a record object onto the current batch.
+ *
+ * Parameters:
+ *  - "r": record object to push
+ */
+MpuBatchStream.prototype.batchPush = function batchPush(r) {
+        assert.object(r, 'r');
+
+        var self = this;
+        self.mpu_batch.push(r);
+
+        var b = self.mpu_UPLOAD_IDS[r.uploadId];
+        b.numRecords++;
+
+        assert.ok(b.numRecords === self.mpu_batch.length,
+                  sprintf('mismatch of batch count (%d) ' +
+                          'and `numRecords` count (%d)',
+                          self.mpu_batch.length,
+                          b.numRecords));
+};
+
+MpuBatchStream.prototype._transform = function mbsTransform(record, _, cb) {
+        assert.string(record, 'record');
+        var self = this;
+
+        var r = mpuCommon.recordToObject(record);
+
+        if (self.mpu_uploadId === null) {
+                self.createBatch(r.uploadId);
+        }
+
+        /*
+         * If this has the same upload ID as the previous upload, add it to the
+         * batch; otherwise, commit the previous batch, start a new one, and add
+         * the current record to the new batch.
+         */
+        if (self.mpu_uploadId === r.uploadId) {
+                self.batchPush(r);
+                setImmediate(cb);
+        } else {
+                self.commitBatch();
+
+                self.createBatch(r.uploadId);
+                self.batchPush(r);
+
+                setImmediate(cb);
+        }
+};
+
+MpuBatchStream.prototype._flush = function mbsFlush(cb) {
+        var self = this;
+
+        // Make sure to commit an outstanding batch.
+        if (self.mpu_batch.length > 0) {
+                self.commitBatch();
+        }
+
+        setImmediate(cb);
+};
+
+module.exports = MpuBatchStream;
diff --git a/lib/mpu/mpuMorayCleanerStream.js b/lib/mpu/mpuMorayCleanerStream.js
new file mode 100644
index 0000000..6012a21
--- /dev/null
+++ b/lib/mpu/mpuMorayCleanerStream.js
@@ -0,0 +1,99 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+var moray = require('moray');
+
+var mpuCommon = require('./common');
+
+/*
+ * MpuMorayCleanerStream: Deletes the finalizing record for the MPU.
+ */
+function MpuMorayCleanerStream(opts) {
+        assert.object(opts, 'opts');
+        assert.object(opts.log, 'opts.log');
+        assert.optionalBool(opts.dryRun, 'opts.dryRun');
+        assert.optionalBool(opts.verbose, 'opts.verbose');
+
+        stream.Writable.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = opts.log;
+        this.morayClients = {};
+        this.dryRun = opts.dryRun;
+        this.verbose = opts.verbose;
+
+        var self = this;
+        this.on('finish', function () {
+                for (var c in self.morayClients) {
+                        var client = self.morayClients[c];
+                        client.close();
+                }
+        });
+}
+util.inherits(MpuMorayCleanerStream, stream.Writable);
+module.exports = MpuMorayCleanerStream;
+
+MpuMorayCleanerStream.prototype.deleteFinalizingRecord =
+function deleteFinalizingRecord(shard, key, cb) {
+        var self = this;
+
+        if (!self.morayClients[shard]) {
+                //TODO timeout, other options to creating client
+                self.morayClients[shard] = moray.createClient({
+                        log: self.log,
+                        srvDomain: shard
+                });
+        }
+
+        assert.object(self.morayClients[shard]);
+        self.morayClients[shard].delObject(mpuCommon.MPU_MORAY_BUCKET, key, cb);
+};
+
+MpuMorayCleanerStream.prototype._write = function mmcsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+
+        var fr = batch.finalizingRecord;
+        assert.string(fr.uploadId, 'fr.uploadId');
+        assert.ok(fr.uploadId === batch.uploadId, 'upload ID of finalizing ' +
+                'record does not match batch uploadId');
+        assert.string(fr.key, 'fr.key');
+        assert.string(fr.shard, 'fr.shard');
+        assert.string(fr.date, 'fr.date');
+
+        var self = this;
+        if (self.verbose) {
+                console.log('delObject ' + fr.key);
+        }
+
+        if (!self.dryRun) {
+                self.deleteFinalizingRecord(fr.shard, fr.key, function (err) {
+                        if (err) {
+                                self.log.error({
+                                        uploadId: batch.uploadId,
+                                        err: err
+                                }, 'mpu moray cleaner stream failure');
+                                cb(err);
+                        } else {
+                                cb();
+                        }
+                });
+        } else {
+                //self.log.info('mmcs cb: ' + fr.key);
+                cb();
+        }
+};
diff --git a/lib/mpu/mpuUnlinkLiveRecordStream.js b/lib/mpu/mpuUnlinkLiveRecordStream.js
new file mode 100644
index 0000000..eff0f4b
--- /dev/null
+++ b/lib/mpu/mpuUnlinkLiveRecordStream.js
@@ -0,0 +1,177 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var mahi = require('mahi');
+var stream = require('stream');
+var util = require('util');
+var vasync = require('vasync');
+
+var sprintf = util.format;
+
+var mpuCommon = require('./common');
+
+var MULRS_TYPE_PART = 'partRecords';
+var MULRS_TYPE_UPLOADDIR = 'uploadRecord';
+
+
+/*
+ * MpuUnlinkStream: Unlinks parts directory and its contents.
+ */
+function MpuUnlinkLiveRecordStream(opts) {
+        assert.object(opts, 'opts');
+        assert.object(opts.log, 'opts.log');
+        assert.string(opts.type, 'opts.type');
+        assert.ok(opts.type === 'partRecords' || opts.type === 'uploadRecord');
+        assert.object(opts.mantaClient, 'opts.mantaClient');
+        assert.object(opts.mahiClient, 'opts.mahiClient');
+        assert.optionalBool(opts.dryRun, 'opts.dryRun');
+        assert.optionalBool(opts.verbose, 'opts.verbose');
+
+        stream.Transform.call(this, {
+                objectMode: true,
+                highWaterMark: 0
+        });
+
+        this.log = opts.log;
+        this.mantaClient = opts.mantaClient;
+        this.mahiClient = opts.mahiClient;
+        this.type = opts.type;
+        this.dryRun = opts.dryRun;
+        this.verbose = opts.verbose;
+}
+util.inherits(MpuUnlinkLiveRecordStream, stream.Transform);
+
+MpuUnlinkLiveRecordStream.prototype._transform =
+function mulrsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+        assert.optionalObject(batch.uploadRecord, 'batch.uploadRecord');
+        assert.optionalArrayOfObject(batch.partRecords, 'batch.partRecords');
+
+        var self = this;
+        //self.log.info('unlink ' + batch.uploadId);
+        if (!batch[self.type]) {
+                self.push(batch);
+                //self.log.info('mulrs cb (no unlink code run, type ' + self.type + '): ' + batch.uploadId);
+                setImmediate(cb);
+                return;
+        }
+        assert.ok(batch.uploadRecord, 'batch must have an upload record');
+
+        /*
+         * Moray stores a normalized key, but we will need the account
+         * associated with each MPU to remove the file through the front door.
+         */
+        var uuid, account;
+        var s = batch.uploadRecord.key.split('/');
+        assert(s.length >= 2);
+        uuid = s[1];
+
+        self.mahiClient.getAccountById(uuid, function (err, info) {
+                /*
+                 * If we can't resolve the account information, we will have to
+                 * drop this batch, as there's no way for us to remove the
+                 * records from the front door.
+                 */
+                if (err) {
+                        self.log.error({
+                                uploadId: batch.uploadId,
+                                err: err
+                        }, 'error fetching account info for batch');
+                        setImmediate(cb);
+                        return;
+                }
+
+                account = info.account.login;
+                assert.string(account, 'account');
+
+                var inputs;
+                if (self.type === MULRS_TYPE_UPLOADDIR) {
+                        inputs = [ batch.uploadRecord ];
+                } else {
+                        assert.ok(self.type === MULRS_TYPE_PART,
+                                sprintf('invalid type: \"%s\"', self.type));
+                        inputs = batch.partRecords;
+                }
+                assert.arrayOfObject(inputs, 'inputs');
+
+                var opts = {
+                        query: {
+                                override: true
+                        }
+                };
+
+                function unlink(p, ucb) {
+                        self.mantaClient.unlink(p, opts, function (err2, res) {
+                                if (err2 && res.statusCode !== 404) {
+                                        errs.push(err);
+                                }
+
+                                ucb();
+                        });
+                }
+
+                var errs = [];
+                vasync.forEachParallel({
+                        func: function optionalUnlinkLiveRecord(r, vcb) {
+                                assert.string(r.key);
+                                var mantaPath = r.key.replace(uuid, account);
+                                //self.log.info('key: \"' + r.key + '\", path: \"'
+                                        //+ mantaPath + '\"');
+
+                                if (self.verbose) {
+                                        console.error('unlink ' + mantaPath);
+                                }
+
+                                if (!self.dryRun) {
+                                        unlink(mantaPath, vcb);
+                                } else {
+                                        //self.log.info('mulrs cb (dry run): ' + batch.uploadId);
+                                        vcb();
+                                }
+                        },
+                        inputs: inputs
+                }, function (err3, results) {
+                        if (err3) {
+                                cb(err3);
+                        } else {
+                                if (errs.length > 0) {
+                                        errs.forEach(function (e) {
+                                                self.log.error({
+                                                        id: batch.uploadId,
+                                                        err: e
+                                                }, 'unlink live record ' +
+                                                   'stream failure');
+                                        });
+                                } else {
+                                        //self.log.info('pushing batch to next stream: ' + batch.uploadId);
+                                        self.push(batch);
+                                }
+
+                                //self.log.info('vasync cb: ' + batch.uploadId);
+                                cb();
+                        }
+                });
+        });
+};
+
+
+MpuUnlinkLiveRecordStream.prototype._flush = function mupsFlush(cb) {
+        setImmediate(cb);
+};
+
+module.exports = {
+        MULRS_TYPE_PART: MULRS_TYPE_PART,
+        MULRS_TYPE_UPLOADDIR: MULRS_TYPE_UPLOADDIR,
+
+        MpuUnlinkLiveRecordStream: MpuUnlinkLiveRecordStream
+};
diff --git a/lib/mpu/mpuVerifyStream.js b/lib/mpu/mpuVerifyStream.js
new file mode 100644
index 0000000..add099e
--- /dev/null
+++ b/lib/mpu/mpuVerifyStream.js
@@ -0,0 +1,157 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./common');
+
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MULRS_TYPE_PART = mulrs.MULRS_TYPE_PART;
+var MULRS_TYPE_UPLOADDIR = mulrs.MULRS_TYPE_UPLOADDIR;
+
+/*
+ * MpuVerifyStream: Given an input stream of a batch of upload records all
+ * for the same MPU, verifies that this MPU is a valid candidate for
+ * garbage collection.
+ *
+ * The MPU is a valid candidate for garbage collection if a finalizing
+ * record exists for the MPU.
+ */
+function MpuVerifyStream(opts) {
+        assert.object(opts, 'opts');
+        assert.object(opts.log, 'opts.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = opts.log;
+}
+util.inherits(MpuVerifyStream, stream.Transform);
+module.exports = MpuVerifyStream;
+
+/*
+ * Based on the records present, ensures that this MPU is valid to be garbage
+ * collected.
+ *
+ * Parameters:
+ * - id: upload ID
+ * - records: array of strings containing the related records
+ *
+ */
+MpuVerifyStream.prototype.validateMPU = function validateMPU(id, records, cb) {
+        assert.string(id, 'id');
+        assert.arrayOfObject(records, 'records');
+
+        var self = this;
+
+        var uploadRecord, partRecords, finalizingRecord = null;
+        var invalidBatch = false;
+
+        records.forEach(function (r) {
+                assert.ok(r instanceof mpuCommon.LiveRecord ||
+                          r instanceof mpuCommon.FinalizingRecord);
+                var rId = r.uploadId;
+
+                if (id !== rId) {
+                        self.log.error({
+                                batchUploadId: id,
+                                recordUploadId: rId
+                        }, 'MPU records batch has records with different ' +
+                           'upload IDs');
+                        invalidBatch = true;
+                }
+
+                var mpuObject;
+                if (r instanceof mpuCommon.FinalizingRecord) {
+                        mpuObject = mpuCommon.MPUOBJ_FINALIZINGRECORD;
+                } else {
+                        if (r.type === MULRS_TYPE_PART) {
+                                mpuObject = mpuCommon.MPUOBJ_PART;
+                        } else {
+                                mpuObject = mpuCommon.MPUOBJ_UPLOADDIR;
+                        }
+                }
+                assert.ok(mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD ||
+                          mpuObject === mpuCommon.MPUOBJ_UPLOADDIR ||
+                          mpuObject === mpuCommon.MPUOBJ_PART);
+
+                if (mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD) {
+                        if (!finalizingRecord) {
+                                finalizingRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple finalizing records found for ' +
+                                   'the same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_UPLOADDIR) {
+                        if (!uploadRecord) {
+                                uploadRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple upload records found for the ' +
+                                   'same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_PART) {
+                        // TODO check uniqueness of parts?
+                        if (!partRecords) {
+                                partRecords = [];
+                        }
+
+                        partRecords.push(r);
+                } else {
+                       self.log.error({
+                                uploadId: id,
+                                record: r
+                       }, 'invalid MPU record (not a finalizing record, ' +
+                          'upload record, or part record');
+                        invalidBatch = true;
+                }
+        });
+
+        if (!invalidBatch && finalizingRecord) {
+                assert.ok(finalizingRecord);
+                assert.optionalObject(uploadRecord);
+                assert.optionalArrayOfObject(partRecords);
+
+                self.push({
+                        uploadId: id,
+                        finalizingRecord: finalizingRecord,
+                        uploadRecord: uploadRecord,
+                        partRecords: partRecords
+                });
+        }
+
+        setImmediate(cb);
+};
+
+MpuVerifyStream.prototype._transform = function mvsTransform(batch, _, cb) {
+        var self = this;
+
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.arrayOfObject(batch.records, 'batch.records');
+
+        self.validateMPU(batch.uploadId, batch.records, cb);
+};
+
+MpuVerifyStream.prototype._flush = function mvsFlush(cb) {
+        setImmediate(cb);
+};
diff --git a/lib/mpu_garbage_collector.js b/lib/mpu_garbage_collector.js
new file mode 100644
index 0000000..4f751b7
--- /dev/null
+++ b/lib/mpu_garbage_collector.js
@@ -0,0 +1,110 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var util = require('util');
+var events = require('events');
+var carrier = require('carrier');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./mpu/common');
+
+
+///--- Globals
+var DEFAULT_GRACE_PERIOD_MILLIS = 1000 * 60 * 60 * 24 * 2;  // 2 days
+
+///--- API
+
+/**
+ * Reads the sorted rows from a transformed PG dump and emits actions that
+ * should be taken to clean up mdko and moray.
+ *
+ * 'moray' objects have the following fields:
+ *   - morayHostname: The hostname of the moray shard
+ *   - date: The date for the record.
+ *   - key: The Moray key of the record.
+ *   - bucket: The Moray bucket of the record.
+ *   - type: The type of the record ('object' or 'directory').
+ *
+ * The objectId + the date is the primary key for figuring out what moray
+ * record to purge.
+ */
+function MpuGarbageCollector(opts, listener) {
+        var self = this;
+
+        var prev, curr, currFR;
+        self.gracePeriodMillis = opts.gracePeriodMillis ||
+                DEFAULT_GRACE_PERIOD_MILLIS;
+        self.carrier = carrier.carry(opts.reader);
+
+        if (listener) {
+                self.addListener('moray', listener);
+                self.addListener('mako', listener);
+        }
+
+        self.carrier.on('line', function (line) {
+                curr = mpuCommon.recordToObject(line);
+                curr.line = line;
+                currFR = takeAction(self, prev, curr, currFR);
+                prev = curr;
+                curr = null;
+        });
+
+        self.carrier.on('end', function () {
+                takeAction(self, prev, curr, currFR);
+        });
+}
+
+util.inherits(MpuGarbageCollector, events.EventEmitter);
+module.exports = MpuGarbageCollector;
+
+
+///--- Helpers
+
+
+/*
+ * TODO comment this
+ */
+function takeAction(gc, prev, curr, currFR) {
+        assert.optionalObject(prev, 'prev');
+        assert.ok(prev instanceof mpuCommon.LiveRecord ||
+                  prev instanceof mpuCommon.FinalizingRecord ||
+                  !prev);
+        assert.optionalObject(curr, 'curr');
+        assert.ok(curr instanceof mpuCommon.LiveRecord ||
+                  curr instanceof mpuCommon.FinalizingRecord ||
+                  !curr);
+        assert.optionalObject(currFR, 'currFR');
+        assert.ok(currFR instanceof mpuCommon.FinalizingRecord || !currFR);
+
+        if (prev && (!curr || (prev.uploadId !== curr.uploadId))) {
+                // We've seen all records related to the previous upload ID,
+                // so we know it's safe to delete the finalizing record of the
+                // upload, if the record exists.
+                if (currFR) {
+                        gc.emit('moray', currFR);
+                        currFR = null;
+                }
+        }
+
+        if (curr) {
+                if (curr.mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD) {
+                        currFR = curr;
+                } else {
+                        // Don't garbage collect any records for uploads that
+                        // don't have an associated finalizing record.
+                        if (currFR) {
+                                gc.emit('moray', curr);
+                        }
+                }
+        }
+
+        return (currFR);
+}
diff --git a/lib/mpu_gc_pg_row_transformer.js b/lib/mpu_gc_pg_row_transformer.js
new file mode 100644
index 0000000..7b4abfb
--- /dev/null
+++ b/lib/mpu_gc_pg_row_transformer.js
@@ -0,0 +1,157 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var events = require('events');
+var path = require('path');
+var util = require('util');
+
+var mpuCommon = require('./mpu/common');
+var SchemaReader = require('./schema_reader');
+
+
+///--- GLOBALS
+var PG_LIVE_MANTA_TABLE_NAME = 'manta';
+var PG_MANTA_UPLOADS_TABLE_NAME = 'manta_uploads';
+
+/* JSSTYLED */
+var UPLOADS_ROOT_PATH = /^\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/uploads\/?.*/;
+
+
+///--- API
+
+//TODO: may need the object ID. Not sure yet.
+/**
+ * This tranforms pg-dumped rows to rows useable for multipart upload
+ * garbage collection.
+ *
+ * The resulting rows emitted will have the following fields:
+ *  - uploadId: multipart upload uuid
+ *  - mpu_object: the type of object this record represents:
+ *      '0_finalizingRecord', '1_partRecord', or '2_UploadRecord'
+ *  - date: The time this row 'occured'
+ *  - morayHostname: The moray host from which the record originated.
+ *  - key: key for record in Moray
+ *  - type: 'finalizing' for finalizing records, 'object' for part records,
+ *      'directory' for upload records
+ *  - finalizingType: 'abort' or 'commit' (only for finalizing records)
+ *  - obj: The original object (only for the part and upload records)
+ *
+ * It also exposes a toString method for getting the row in a format
+ * suitable for sorting.
+ */
+function MpuGcPgRowTransformer(opts, listener) {
+        var self = this;
+        var reader = opts.reader;
+        var dumpDate = opts.dumpDate;
+        var earliestDumpDate = opts.earliestDumpDate;
+        var morayHostname = opts.morayHostname;
+
+        self.schemaReader = new SchemaReader(reader);
+
+        if (listener) {
+                self.addListener('row', listener);
+        }
+
+        function isMpuRecord(o) {
+                var t = o._value.type;
+                var k = o._value.key;
+                var u = o._value.upload;
+
+                if (k.match(UPLOADS_ROOT_PATH)) {
+                        return (t === 'object' ||
+                                (t === 'directory' && !!u));
+                }
+
+                return (false);
+        }
+
+        self.schemaReader.on('object', function (obj) {
+                var table = obj['__table'];
+                var row;
+
+                if (table === PG_LIVE_MANTA_TABLE_NAME) {
+                        if (isMpuRecord(obj)) {
+                            row = transformMpuRecord(obj, dumpDate,
+                                morayHostname);
+                        }
+                } else if (table === PG_MANTA_UPLOADS_TABLE_NAME) {
+                        row = transformFinalizingRecord(obj, earliestDumpDate,
+                            morayHostname);
+                }
+
+                if (row) {
+                        self.emit('row', row);
+                }
+        });
+
+        self.schemaReader.on('end', function () {
+                self.emit('end');
+        });
+}
+
+util.inherits(MpuGcPgRowTransformer, events.EventEmitter);
+module.exports = MpuGcPgRowTransformer;
+
+
+///--- Helpers
+
+function transformFinalizingRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_MANTA_UPLOADS_TABLE_NAME);
+        var value = obj['_value'];
+        var date = new Date(parseInt(obj['_mtime'], 10));
+
+        return new mpuCommon.FinalizingRecord({
+                uploadId: value.uploadId,
+                key: obj._key,
+                shard: morayHostname,
+                date: date,
+                type: value.finalizingType
+        });
+}
+
+function transformMpuRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_LIVE_MANTA_TABLE_NAME);
+        var value = obj['_value'];
+
+        var mpuObject, uploadId;
+        if (value.type === 'directory') {
+            mpuObject = mpuCommon.MPUOBJ_UPLOADDIR;
+            uploadId = value.upload.id;
+        } else if (value.type === 'object') {
+            mpuObject = mpuCommon.MPUOBJ_PART;
+            uploadId = path.basename(path.dirname(obj._key));
+        } else {
+            return (null);
+        }
+
+        // TODO: why is this check here?
+        if (!obj._key.match(UPLOADS_ROOT_PATH)) {
+                return (null);
+        }
+
+        var record = mpuCommon.LiveRecord({
+                key: obj._key,
+                date: dumpDate,
+                type: mpuObject,
+                uploadId: uploadId
+        });
+
+
+        if (mpuObject === mpuCommon.MPUOBJ_PART) {
+                record.makoObj = {
+                        owner: value.owner,
+                        objectId: value.objectId,
+                        sharks: value.sharks
+                };
+        }
+
+        return (record);
+}
diff --git a/package.json b/package.json
index 8d477f7..1c1b4b5 100644
--- a/package.json
+++ b/package.json
@@ -15,6 +15,8 @@
                 "lstream": "0.0.4",
                 "once": "1.3.1",
                 "manta-hk": "git+https://github.com/joyent/manta-hk.git#master",
+                "mahi": "git+https://github.com/joyent/node-mahi.git#master",
+                "manta-hk": "git+https://github.com/joyent/manta-hk.git#master",
                 "marlin": "git+https://github.com/joyent/manta-marlin.git#master",
                 "memorystream": "0.2.0",
                 "node-manta": "git+https://github.com/joyent/node-manta.git#master",
@@ -27,6 +29,7 @@
                 "vstream": "0.1.0"
         },
         "devDependencies": {
+                "libuuid": "0.1.2",
                 "nodeunit": "0.7.4"
         },
         "sdcDependencies": {
diff --git a/sapi_manifests/mola/template b/sapi_manifests/mola/template
index c12a616..7bf393e 100644
--- a/sapi_manifests/mola/template
+++ b/sapi_manifests/mola/template
@@ -20,7 +20,15 @@
         },
         "connectTimeout": 1000,
         "rejectUnauthorized": {{MANTA_REJECT_UNAUTHORIZED}}
-    }{{#AUDIT_MAP_DISK}},
+    },
+    "auth"; {
+        "url": "http://{{AUTH_SERVICE}}",
+        "maxAuthCacheSize": 1000,
+        "maxAuthCacheAgeMs": 300000,
+        "maxTranslationCacheSize": 1000,
+        "maxTranslationCacheAgeMs": 300000
+    },
+    {{#AUDIT_MAP_DISK}},
     "auditMapDisk": {{AUDIT_MAP_DISK}}{{/AUDIT_MAP_DISK}}{{#AUDIT_REDUCE_DISK}},
     "auditReduceDisk": {{AUDIT_REDUCE_DISK}}{{/AUDIT_REDUCE_DISK}}{{#AUDIT_REDUCE_MEMORY}},
     "auditReduceMemory": {{AUDIT_REDUCE_MEMORY}}{{/AUDIT_REDUCE_MEMORY}}{{#AUDIT_REDUCER_COUNT}},
diff --git a/script.sh b/script.sh
new file mode 100755
index 0000000..4cceb3f
--- /dev/null
+++ b/script.sh
@@ -0,0 +1,7 @@
+EARLIEST=$(ls tmp/ | sed 's/^\w*-//; s/.gz$//;' | sort | head -1); \
+for f in `ls tmp`; do \
+   export DD=$(echo $f | sed 's/^\w*-//; s/.gz$//;'); \
+   zcat tmp/$f | \
+   node ./bin/gc_pg_transform.js -d $DD -e $EARLIEST \
+     -m 1.moray.emy-13.joyent.us; \
+done | sort | node ./bin/gc.js -g 60
-- 
2.21.0

