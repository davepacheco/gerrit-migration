commit 2c38295fbac44fcd81d18ee9eb1dbf8a2c6447d2 (refs/changes/02/2802/4)
Author: Jordan Hendricks <jordan.hendricks@joyent.com>
Date:   2017-10-18T19:40:03+00:00 (2 years ago)
    
    MANTA-3226 Manta garbage collection needs to support multipart uploads

diff --git a/Makefile b/Makefile
index 50ff1c0..6053521 100644
--- a/Makefile
+++ b/Makefile
@@ -25,7 +25,7 @@
 #
 # Tools
 #
-NODEUNIT        := ./node_modules/.bin/nodeunit
+NODEUNIT        := ./node_modules/.bin/nodeunit --reporter=tap
 NPM             := npm
 
 #
diff --git a/bin/gc_links.pl b/bin/gc_links.pl
index 2d19829..c51e0c2 100755
--- a/bin/gc_links.pl
+++ b/bin/gc_links.pl
@@ -14,9 +14,8 @@
 # mako.  This should go away post-haste after the stream to many mpipes
 # is written.
 ###############################################################################
-
 if (@ARGV < 3) {
-    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " +
+    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " .
         "[manta object prefix]\n";
     exit 1;
 }
diff --git a/bin/kick_off_mpu_gc.js b/bin/kick_off_mpu_gc.js
new file mode 100755
index 0000000..efb1276
--- /dev/null
+++ b/bin/kick_off_mpu_gc.js
@@ -0,0 +1,359 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var fs = require('fs');
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var manta = require('manta');
+var path = require('path');
+
+/*
+ * Kicks off the MPU GC job, which pg-transforms the PG backups, sorts them, and
+ * determines which MPU-related records can be garbage collected.
+ *
+ * This script is analogous to bin/kick_off_gc.js for normal GC.
+ */
+
+///--- Global Objects
+
+var NAME = 'mola-mpu-gc';
+var LOG = bunyan.createLogger({
+        level: (process.env.LOG_LEVEL || 'info'),
+        name: NAME,
+        stream: process.stdout
+});
+var MOLA_CONFIG = (process.env.MOLA_CONFIG ||
+                   '/opt/smartdc/mola/etc/config.json');
+var MOLA_CONFIG_OBJ = JSON.parse(fs.readFileSync(MOLA_CONFIG));
+var MANTA_CLIENT = manta.createClientFromFileSync(MOLA_CONFIG, LOG);
+var MANTA_USER = MANTA_CLIENT.user;
+
+
+///--- Global Constants
+
+var MP = '/' + MANTA_USER + '/stor';
+var MANTA_DUMP_NAME_PREFIX = 'manta-';
+var MANTA_UPLOADS_NAME_PREFIX = 'manta_uploads-';
+
+
+///--- Helpers
+
+/*
+ * Helper that sets up necessary environment variables for the commands run as
+ * part of a phase in the MPU GC job.
+ *
+ * Inputs:
+ *  - opts: an options blob that must include:
+ *      - jobName: name of the job to pass to the job manager
+ *      - marlinPathToAsset: the relative path of a tarball that is unpacked as
+ *          an asset in the job
+ */
+function getEnvCommon(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.jobName, 'opts.jobName');
+        assert.string(opts.marlinPathToAsset, 'opts.marlinPathToAsset');
+
+/* BEGIN JSSTYLED */
+        return (' \
+set -o pipefail && \
+export MANTA_USER=' + MANTA_USER + ' && \
+export MANTA_MPU_GC=' + opts.jobName + ' && \
+export MARLIN_JOB=$(echo $MANTA_OUTPUT_BASE | cut -d "/" -f 4) && \
+export NOW=$(date "+%Y-%m-%d-%H-%M-%S") && \
+cd /assets/ && gtar -xzf ' + opts.marlinPathToAsset + ' && cd mola && \
+');
+/* END JSSTYLED */
+}
+
+
+/*
+ * Returns the command that is run during the map phase of the MPU GC job.
+ * This command calls into bin/mpu_gc_pg_transform.js, which transforms
+ * input from the dump into tab-separated records that can be processed
+ * by the reduce phase of the job.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - earliestDumpDate: the earliest dump date to use
+ *      - numberReducers: number of reducers to assign to the job
+ *      - objectId: optional objectId TODO
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuPgTransformCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.earliestDumpDate, 'opts.earliestDumpDate');
+        assert.number(opts.numberReducers, 'opts.numberReducers');
+
+/* BEGIN JSSTYLED */
+        var grepForObject = '';
+        if (opts.objectId) {
+                grepForObject = ' | grep ' + opts.objectId + ' | ';
+        }
+        return (getEnvCommon(opts) + ' \
+export MORAY_SHARD=$(echo $mc_input_key | cut -d "/" -f 5) && \
+export DUMP_DATE=$(basename $mc_input_key | sed \'s/^\\w*-//; s/.\\w*$//;\') && \
+gzcat -f | \
+  ./build/node/bin/node ./bin/mpu_gc_pg_transform.js -d $DUMP_DATE \
+    -e ' + opts.earliestDumpDate + ' \
+    -m $MORAY_SHARD' + grepForObject + ' | \
+  msplit -n ' + opts.numberReducers + ' \
+');
+/* END JSSTYLED */
+}
+
+
+/*
+ * Returns the command that is run during the reduce phase of the MPU GC job.
+ * This phase calls into bin/mpu_gc.js, which is a thin wrapper that calls into
+ * lib/mpu_garbage_colector.js, which performs the actual logic of deciding
+ * what mako and moray actions need to be taken.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - gracePeriodSeconds: optional grace period for MPU
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuGcCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.optionalNumber(opts.gracePeriodSeconds,
+            'opts.gracePeriodSeconds');
+
+        var gracePeriodOption = '';
+        if (opts.gracePeriodSeconds) {
+                gracePeriodOption = ' -g ' + opts.gracePeriodSeconds;
+        }
+        /*
+         * As the normal GC job does, we use a UUID only because there's no way
+         * (yet) to get a reference to which reducer this is running on.
+         */
+/* BEGIN JSSTYLED */
+        return (getEnvCommon(opts) + ' \
+export UUID=$(uuid) && \
+export MANTA_PRE=/$MANTA_USER/stor/$MANTA_MPU_GC/all && \
+export MANTA_MPU_GC_CLEANUP_FILE=$MANTA_PRE/do/$NOW-$MARLIN_JOB-X-$UUID && \
+export LINKS_FILE=./links.txt && \
+sort | \
+./build/node/bin/node ./bin/mpu_gc.js' + gracePeriodOption + ' | \
+mpipe $MANTA_MPU_GC_CLEANUP_FILE \
+');
+/* END JSSTYLED */
+}
+
+function parseOptions() {
+        var option;
+        /*
+         * First take what's in the config file, override what's on the
+         * command line, and use the defaults if all else fails.
+         */
+        var opts = MOLA_CONFIG_OBJ;
+        opts.shards = opts.shards || [];
+        var parser = new getopt.BasicParser('a:d:g:m:no:p:r:t',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'a':
+                        opts.assetFile = option.optarg;
+                        break;
+                case 'd':
+                        opts.gcReduceDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                case 'm':
+                        opts.shards.push(option.optarg);
+                        break;
+                case 'n':
+                        opts.noJobStart = true;
+                        break;
+                case 'o':
+                        opts.objectId = option.optarg;
+                        break;
+                case 'p':
+                        opts.gcMapDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'r':
+                        opts.gcReduceMemory = parseInt(option.optarg, 10);
+                        break;
+                // TODO what is this for?
+                case 't':
+                        opts.jobName = 'manta_mpu_gc_test';
+                        opts.jobRoot = MP + '/manta_mpu_gc_test';
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+
+        opts.jobName = opts.jobName || 'manta_mpu_gc';
+        opts.jobRoot = opts.jobRoot || MP + '/manta_mpu_gc';
+
+        opts.assetDir = opts.jobRoot + '/assets';
+        opts.assetObject = opts.assetDir + '/mola.tar.gz';
+        opts.assetFile = opts.assetFile ||
+                '/opt/smartdc/common/bundle/mola.tar.gz';
+
+        opts.gcMapDisk = opts.gcMapDisk || 32;
+        opts.gcReduceMemory = opts.gcReduceMemory || 8192;
+        opts.gcReduceDisk = opts.gcReduceDisk || 32;
+        opts.marlinPathToAsset = opts.assetObject.substring(1);
+        opts.marlinAssetObject = opts.assetObject;
+
+        opts.directories = [
+                opts.jobRoot + '/all',
+                opts.jobRoot + '/all/do',
+                opts.jobRoot + '/all/done',
+                opts.jobRoot + '/moray'
+        ];
+
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-a asset_file]';
+        str += ' [-g grace_period_seconds]';
+        str += ' [-m moray_shard]';
+        str += ' [-n no_job_start]';
+        str += ' [-o object_id]';
+        str += ' [-r marlin_reducer_memory]';
+        str += ' [-t output_to_test]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+/*
+ * Returns a job definition for the MPU GC job that can be passed to the
+ * job manager.
+ *
+ * Inputs:
+ *  - opts: options blob passed to helpers creating phases of the job (see
+ *          those functions for documentation)
+ *  - cb: callback of the form cb(err, job)
+ */
+function getMpuGcJob(opts, cb) {
+        /*
+         * As with the regular GC job, use the number of shards + 1 reducers so
+         * that we are always using multiple reducers.
+         */
+        opts.numberReducers = opts.shards.length + 1;
+
+        var mpuPgCmd = getMpuPgTransformCmd(opts);
+        var mpuGcCmd = getMpuGcCmd(opts);
+
+        var job = {
+                phases: [ {
+                        type: 'storage-map',
+                        exec: mpuPgCmd,
+                        disk: opts.gcMapDisk
+                }, {
+                        type: 'reduce',
+                        count: opts.numberReducers,
+                        memory: opts.gcReduceMemory,
+                        disk: opts.gcReduceDisk,
+                        exec: mpuGcCmd
+                } ]
+        };
+
+        LOG.info({
+                job: job
+        }, 'MPU GC Marlin Job Definition');
+
+        cb(null, job);
+}
+
+
+//Expects the filename to be in the format:
+// /.../manta-2012-11-30-23-00-07.gz
+// Returns: 2012-11-30-23-00-07
+function extractDate(p) {
+        var filename = path.basename(p);
+        var d = filename.substring(filename.indexOf('-') + 1);
+        d = d.substring(0, d.indexOf('.'));
+        return (d);
+}
+
+
+/*
+ * Determines what input objects to pass to the MPU GC job.
+ *
+ * Inputs:
+ *  - opts: an options block passed directly to common.findObjectsForShards
+ *  - cb: callback of the form cb(err, objects)
+ */
+function findMpuGcObjects(opts, cb) {
+        LOG.info({ opts: opts }, 'Finding MPU Gc Objects.');
+        var shards = opts.shards;
+
+        if (shards.length === 0) {
+                cb(new Error('No shards specified.'));
+                return;
+        }
+
+        lib.common.findObjectsForShards({
+                'log': LOG,
+                'shards': shards,
+                'client': MANTA_CLIENT,
+                'tablePrefixes': [
+                        MANTA_DUMP_NAME_PREFIX,
+                        MANTA_UPLOADS_NAME_PREFIX
+                ]
+        }, function (err, results) {
+                if (err) {
+                        cb(err);
+                        return;
+                }
+
+                var objects = [];
+                var dates = [];
+
+                for (var j = 0; j < results.length; ++j) {
+                        var obj = results[j];
+                        objects.push(obj);
+                        // Get the date from the filename.
+                        dates.push(extractDate(obj));
+                }
+
+                dates.sort();
+                LOG.info({
+                        dates: dates,
+                        objects: objects
+                }, 'found mpu gc objects');
+                opts.earliestDumpDate = dates[0];
+                cb(null, objects);
+        });
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+
+_opts.getJobDefinition = getMpuGcJob;
+_opts.getJobObjects = findMpuGcObjects;
+
+var jobManager = lib.createJobManager(_opts, MANTA_CLIENT, LOG);
+jobManager.run(function () {
+        MANTA_CLIENT.close();
+        LOG.info('Done for now.');
+});
diff --git a/bin/mdemux.js b/bin/mdemux.js
index 311947d..2958be1 100755
--- a/bin/mdemux.js
+++ b/bin/mdemux.js
@@ -21,8 +21,11 @@ var util = require('util');
 var vasync = require('vasync');
 
 
-
-/**
+/*
+ *
+ * TODO clean this example up: the -f flag isn't real, and mpipe does not do
+ * `mpipe -p`, which this example kind of implies
+ *
  * Bucketize by fields in a line, uploading to manta via mpipe.  For example,
  * this will bucketize quotes into last/first name files, given a stream
  * of records with lines like:
@@ -31,6 +34,7 @@ var vasync = require('vasync');
  *    -p /$MANTA_USER/stor/quotes/{2}/{1}/quotes.txt
  *
  * The -p is required.  -f defaults to 1, -d defaults to (tab).
+ *
  */
 
 
@@ -311,6 +315,7 @@ DemuxFileStream.prototype._write = function dfsWrite(line, _, done) {
 };
 
 
+///--- Main
 
 var _opts = parseOptions();
 
diff --git a/bin/mpu_gc.js b/bin/mpu_gc.js
new file mode 100755
index 0000000..dbc1475
--- /dev/null
+++ b/bin/mpu_gc.js
@@ -0,0 +1,70 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+
+
+
+///--- Helpers
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('g:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-g grace_period_seconds]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+//As a convience, seconds to millis
+if (_opts.gracePeriodSeconds) {
+        _opts.gracePeriodMillis = _opts.gracePeriodSeconds * 1000;
+}
+
+var _garbageCollector = lib.createMpuGarbageCollector(_opts);
+_garbageCollector.on('mpuCleanup', function (moray) {
+        console.log(moray.toString());
+});
+
+_garbageCollector.on('error', function (err) {
+        console.error({ err: err }, 'Error with line, exiting.');
+        process.exit(1);
+});
+
+process.stdin.resume();
diff --git a/bin/mpu_gc_pg_transform.js b/bin/mpu_gc_pg_transform.js
new file mode 100755
index 0000000..85d58e0
--- /dev/null
+++ b/bin/mpu_gc_pg_transform.js
@@ -0,0 +1,107 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+var util = require('util');
+
+/*
+ * Transforms the unpacked dump into records using the format specified by
+ * lib/mpu_gc_pg_row_transformer.js.
+ *
+ * This is analogous to bin/gc_pg_transform.js and lib/gc_pg_row_transformer.js
+ * for normal GC.
+ */
+
+///--- Helpers
+
+function isValidDate(date) {
+        return (util.isDate(date) && !isNaN(date.getTime()));
+}
+
+function parseDate(dateString) {
+        // So we're forcing a weird format here.  File dates come in the format
+        // 2012-10-18-23-00-02.
+        var parts = dateString.split('-');
+        if (parts.length != 6) {
+                usage('Invalid date: ' + dateString);
+        }
+        var ds = parts[0] + '-' + parts[1] + '-' + parts[2] + 'T' +
+                parts[3] + ':' + parts[4] + ':' + parts[5] + 'Z';
+        var date = new Date(ds);
+        if (isValidDate(date)) {
+                return (date);
+        }
+        // We'll let the caller catch this.
+        return (dateString);
+}
+
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('d:e:m:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'd':
+                        opts.dumpDate = parseDate(option.optarg);
+                        break;
+                case 'e':
+                        opts.earliestDumpDate = parseDate(option.optarg);
+                        break;
+                case 'm':
+                        opts.morayHostname = option.optarg;
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+
+        if (!opts.dumpDate) {
+                usage('-d [dump_date] is a required argument');
+        }
+        if (!opts.earliestDumpDate) {
+                usage('-e [earliest_dump_date] is a required argument');
+        }
+        if (!opts.morayHostname) {
+                usage('-m [moray_hostname] is a required argument');
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-d dump_date] [-e earliest_dump_time] [-m moray_hostname]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+
+var _gcPgRowTransformer = lib.createMpuGcPgRowTransformer(_opts);
+_gcPgRowTransformer.on('row', function (row) {
+        console.log(row.toString());
+});
+
+process.stdin.resume();
diff --git a/boot/setup.sh b/boot/setup.sh
index 00b1181..1c3f50e 100755
--- a/boot/setup.sh
+++ b/boot/setup.sh
@@ -7,7 +7,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2017, Joyent, Inc.
 #
 
 set -o xtrace
@@ -52,9 +52,13 @@ function manta_setup_mola {
     mkdir -p /opt/smartdc/common/bundle
     cd /opt/smartdc && tar -chzf /opt/smartdc/common/bundle/mola.tar.gz mola; cd -
     echo '0 2 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_pg_transform.js >>/var/log/mola-pg-transform.log 2>&1' >>$crontab
+    echo '0 3 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_mpu_pg_transform.js >>/var/log/mola-mpu-pg-transform.log 2>&1' >>$crontab
+
     echo '5 8 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_gc.js >>/var/log/mola.log 2>&1' >>$crontab
+    echo '5 9 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_mpu_gc.js >>/var/log/mola-mpu-gc.log 2>&1' >>$crontab
     echo '10 11 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/gc_create_links.js >>/var/log/mola-gc-create-links.log 2>&1' >>$crontab
     echo '15 12 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/moray_gc.js >>/var/log/mola-moray-gc.log 2>&1' >>$crontab
+    echo '15 13 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_mpu_cleanup.js >>/var/log/mola-mpu-cleanup.log 2>&1' >>$crontab
     echo '20 14 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_audit.js >>/var/log/mola-audit.log 2>&1' >>$crontab
 
     #Metering
@@ -70,9 +74,12 @@ function manta_setup_mola {
     [[ $? -eq 0 ]] || fatal "Unable import crons"
 
     manta_add_logadm_entry "mola-pg-transform" "/var/log" "exact"
+    manta_add_logadm_entry "mola-mpu-pg-transform" "/var/log" "exact"
     manta_add_logadm_entry "mola" "/var/log" "exact"
+    manta_add_logadm_entry "mola-mpu-gc" "/var/log" "exact"
     manta_add_logadm_entry "mola-gc-create-links" "/var/log" "exact"
     manta_add_logadm_entry "mola-moray-gc" "/var/log" "exact"
+    manta_add_logadm_entry "mola-mpu-cleanup" "/var/log" "exact"
     manta_add_logadm_entry "mola-audit" "/var/log" "exact"
     manta_add_logadm_entry "mackerel" "/var/log" "exact"
 
diff --git a/deps/manta-scripts b/deps/manta-scripts
index 4b86dd1..cd72e80 160000
--- a/deps/manta-scripts
+++ b/deps/manta-scripts
@@ -1 +1 @@
-Subproject commit 4b86dd132d68cb177f066a83d90b8fdc9ac2cde9
+Subproject commit cd72e801576de5a4b1aec35a7f79409d3f1eebb5
diff --git a/docs/gc-overview.md b/docs/gc-overview.md
index 868a21b..c9ff06a 100644
--- a/docs/gc-overview.md
+++ b/docs/gc-overview.md
@@ -170,7 +170,7 @@ A cron runs in the cron zone that will periodically look in:
     /poseidon/stor/manta_gc/all/do/
 
 Download, and execute the instructions.  Once the links are successfully created,
-the links file is deleted.  The executable is in `mola/bin/gc_create_links.sh`.
+the links file is deleted.  The executable is in `mola/bin/gc_create_links.js`.
 
 ## Phase 3: Moray Cleanup
 
diff --git a/lib/index.js b/lib/index.js
index 4e2dc34..59dd9ae 100644
--- a/lib/index.js
+++ b/lib/index.js
@@ -17,6 +17,8 @@ var CruftCollector = require('./cruft_collector');
 var CruftRowTransformer = require('./cruft_row_transformer');
 var GarbageCollector = require('./garbage_collector');
 var GcPgRowTransformer = require('./gc_pg_row_transformer');
+var MpuGarbageCollector = require('./mpu_garbage_collector');
+var MpuGcPgRowTransformer = require('./mpu_gc_pg_row_transformer');
 var JobManager = require('./job_manager');
 var MorayCleaner = require('./moray_cleaner');
 var Rebalancer = require('./rebalancer');
@@ -86,6 +88,17 @@ function createGarbageCollector(opts, listener) {
 }
 
 
+function createMpuGarbageCollector(opts, listener) {
+        assert.object(opts.reader);
+        if (opts.gracePeriodMillis) {
+                assert.number(opts.gracePeriodMillis);
+        }
+
+        var mpuGarbageCollector = new MpuGarbageCollector(opts, listener);
+        return (mpuGarbageCollector);
+}
+
+
 function createJobManager(opts, mantaClient, log) {
         assert.object(opts);
         assert.object(mantaClient);
@@ -117,6 +130,20 @@ function createGcPgRowTransformer(opts, listener) {
 }
 
 
+function createMpuGcPgRowTransformer(opts, listener) {
+        assert.object(opts, 'opts missing');
+        assert.object(opts.reader, 'opts.reader missing');
+        assert.ok(util.isDate(opts.dumpDate),
+                  'opts.dumpDate isnt Date');
+        assert.ok(util.isDate(opts.earliestDumpDate),
+                  'opts.earliestDumpDate isnt Date');
+        assert.string(opts.morayHostname, 'Moray hostname missing');
+
+        var mpuGcPgRowTransformer = new MpuGcPgRowTransformer(opts, listener);
+        return (mpuGcPgRowTransformer);
+}
+
+
 function createRebalancer(opts, listener) {
         assert.object(opts, 'opts missing');
         assert.object(opts.reader, 'opts.reader missing');
@@ -147,9 +174,11 @@ module.exports = {
         createCruftCollector: createCruftCollector,
         createCruftRowTransformer: createCruftRowTransformer,
         createGarbageCollector: createGarbageCollector,
+        createMpuGarbageCollector: createMpuGarbageCollector,
         createGcPgRowTransformer: createGcPgRowTransformer,
         createJobManager: createJobManager,
         createMorayCleaner: createMorayCleaner,
+        createMpuGcPgRowTransformer: createMpuGcPgRowTransformer,
         createRebalancer: createRebalancer,
         createSchemaReader: createSchemaReader
 };
diff --git a/lib/moray_cleaner.js b/lib/moray_cleaner.js
index ec5a981..49a55d1 100644
--- a/lib/moray_cleaner.js
+++ b/lib/moray_cleaner.js
@@ -23,7 +23,9 @@ var BatchStream = require('./batch_stream').BatchStream;
 
 ///--- Globals
 
-var MORAY_BUCKET = 'manta_delete_log';
+var MANTA_DELETE_BUCKET = 'manta_delete_log';
+var MANTA_FINALIZING_BUCKET = 'manta_uploads';
+
 var MORAY_CONNECT_TIMEOUT = 10000;
 var MORAY_PORT = 2020;
 
@@ -62,6 +64,7 @@ function deleteFromMoray(opts, cb) {
         var self = opts.self;
         var lines = opts.lines;
         var expectedShard = opts.expectedShard;
+        var bucket = opts.bucket;
         var client = opts.client;
         var ms = 'moray';
 
@@ -114,7 +117,7 @@ function deleteFromMoray(opts, cb) {
         filter += ')';
 
         var startDate = new Date();
-        client.deleteMany(MORAY_BUCKET, filter, function (err) {
+        client.deleteMany(bucket, filter, function (err) {
                 var endDate = new Date();
                 var latency = endDate.getTime() - startDate.getTime();
 
@@ -205,9 +208,13 @@ function MorayCleanerStream(opts) {
         assert.object(opts, 'opts');
         assert.object(opts.log, 'opts.log');
         assert.string(opts.shard, 'opts.shard');
+        assert.string(opts.bucket, 'opts.bucket');
         assert.string(opts.object, 'opts.object');
         assert.object(opts.parent, 'opts.parent');
 
+        assert.ok((opts.bucket === MANTA_DELETE_BUCKET) ||
+                  (opts.bucket === MANTA_FINALIZING_BUCKET));
+
         stream.Writable.call(this, {
                 objectMode: true,
                 highWaterMark: 0
@@ -215,6 +222,7 @@ function MorayCleanerStream(opts) {
 
         self.mcs_log = opts.log;
         self.mcs_shard = opts.shard;
+        self.mcs_bucket = opts.bucket;
         self.mcs_object = opts.object;
         self.mcs_parent = opts.parent;
         self.mcs_client = null;
@@ -278,6 +286,7 @@ MorayCleanerStream.prototype.mcsCommit = function mcsCommit(batch, done) {
                 self: self.mcs_parent,
                 lines: batch.entries,
                 expectedShard: self.mcs_shard,
+                bucket: self.mcs_bucket,
                 client: self.mcs_client
         }, function (err) {
                 if (err) {
@@ -317,6 +326,7 @@ MorayCleaner.prototype.cleanStream = function cleanStream(opts) {
 
         var cleaner = new MorayCleanerStream({
                 shard: opts.shard,
+                bucket: opts.bucket,
                 object: opts.object,
                 parent: self,
                 log: log
diff --git a/lib/mpu/common.js b/lib/mpu/common.js
new file mode 100644
index 0000000..000ef61
--- /dev/null
+++ b/lib/mpu/common.js
@@ -0,0 +1,242 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+
+///--- Globals
+
+var sprintf = util.format;
+
+var MPU_MORAY_BUCKET = 'manta_uploads';
+
+/*
+ * Internal constants used to differentiate between parts and upload records, as
+ * they are often used in the same context.
+ */
+var MPU_PART = 'partRecord';
+var MPU_UPLOADDIR = 'uploadRecord';
+
+/*
+ * MPU object values used by the record transformation step of the GC job
+ * (bin/mpu_gc_pg_transform.js). They are prepended with a numeral to ensure
+ * they sort in a given order: namely, that the finalizing record will be listed
+ * first in a sorted list.
+ */
+var MPUOBJ_PART = '2_partRecord';
+var MPUOBJ_UPLOADDIR = '1_uploadRecord';
+var MPUOBJ_FINALIZINGRECORD = '0_finalizingRecord';
+
+/*
+ * Types of finalizing records. The type doesn't make a difference with regard
+ * to garbage collection, but it is good to have these recorded in the state of
+ * MPUs for debugging purposes.
+ */
+var MPU_FR_TYPE_COMMIT = 'commit';
+var MPU_FR_TYPE_ABORT = 'abort';
+
+
+var MPU_RECORD_ATTR_UPLOADID = 'uploadId';
+var MPU_RECORD_ATTR_MPUOBJ = 'mpuObject';
+var MPU_RECORD_ATTR_DATE = 'date';
+var MPU_RECORD_ATTR_SHARD = 'shard';
+var MPU_RECORD_ATTR_KEY = 'key';
+
+/*
+ * Given a string in a known format (namely, the same one produced by the
+ * toString method on a FinalizingRecord or LiveRecord object), returns a
+ * FinalizingRecord or LiveRecord object with the fields from the string.
+ *
+ * This function expects the string to match the format expected and will fail
+ * assertions if it does not. The responsibility is on the caller to ensure that
+ * the string is the correct format.
+ *
+ * In particular, the format for a finalizing record is a tab-separated list of
+ * the following fields:
+ *      [upload id]
+ *      0_finalizingRecord
+ *      [DATE]
+ *      [SHARD]
+ *      {commit,abort}
+ *      [manta_uploads KEY]
+ *
+ * In particular, the format for a live record is a tab-separated list of the
+ * following fields:
+ *      [upload id]
+ *      {1_uploadRecord, 2_partRecord}
+ *      [DATE]
+ *      [manta KEY]
+ */
+function recordToObject(record) {
+        assert.string(record);
+
+        var split = record.split('\t');
+        assert.ok(split.length >= 4, sprintf('record must contain at least 4 ' +
+                'tab-separated fields: \"%s\"', record));
+
+        var uploadId = split[0];
+        var mpuObject = split[1];
+        var date = new Date(split[2]);
+        var key;
+
+        assert.object(date, sprintf('unable to parse date: %s', split[2]));
+        assert.ok(date instanceof Date, 'invalid date');
+        assert.ok(mpuObject === MPUOBJ_PART ||
+                mpuObject === MPUOBJ_UPLOADDIR ||
+                mpuObject === MPUOBJ_FINALIZINGRECORD,
+                sprintf('invalid mpu object type: \"%s\"', mpuObject));
+
+        if (mpuObject === MPUOBJ_FINALIZINGRECORD) {
+                assert.ok(split.length === 6, sprintf('finalizing record ' +
+                        'must contain 6 tab-separated fields: \"%s\"', record));
+
+                var shard = split[3];
+                var finalizingType = split[4];
+                key = split[5];
+
+                assert.ok(finalizingType === MPU_FR_TYPE_COMMIT ||
+                          finalizingType === MPU_FR_TYPE_ABORT,
+                          sprintf('invalid finalizing type: %s',
+                                finalizingType));
+
+                return new FinalizingRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        shard: shard,
+                        date: date,
+                        type: finalizingType
+                });
+        } else {
+                assert.ok(split.length === 4, 'upload/part records must ' +
+                        'contain 4 tab-separated fields');
+
+                key = split[3];
+
+                var mulrsType;
+                if (mpuObject === MPUOBJ_UPLOADDIR) {
+                        mulrsType = MPU_UPLOADDIR;
+                } else {
+                        mulrsType = MPU_PART;
+                }
+                assert.string(mulrsType);
+
+                return new LiveRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        type: mulrsType,
+                        date: date
+
+                });
+        }
+}
+
+/*
+ * Represents a finalizing record in the streams that process the metadata
+ * record cleanup.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": the Moray key for this record
+ *   - "shard": Moray shard of the record
+ *   - "date": date on the Moray record
+ *
+ */
+function FinalizingRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.string(opts.shard, 'opts.shard');
+        assert.object(opts.date, 'opts.date');
+        assert.ok(opts.date instanceof Date, 'invalid date');
+        assert.string(opts.type, 'opts.type');
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.shard = opts.shard;
+        this.date = opts.date;
+        this.type = opts.type;
+}
+
+FinalizingRecord.prototype.toString = function frToString() {
+        return (this.uploadId + '\t' +
+                MPUOBJ_FINALIZINGRECORD + '\t' +
+                this.date.toISOString() + '\t' +
+                this.shard + '\t' +
+                this.type + '\t' +
+                this.key);
+};
+
+/*
+ * Represents a "live" Manta record in the streams that process the metadata
+ * record cleanup. In particular, a live record is either the part record or
+ * upload record of a given MPU.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": key to record in Moray
+ *   - "date": date on the Moray record
+ *   - "type": either "uploadRecord" or "partRecord"
+ *
+ */
+function LiveRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.object(opts.date, 'opts.date');
+        assert.ok(opts.date instanceof Date, 'invalid date');
+        assert.string(opts.type, 'opts.type');
+        assert.ok(opts.type === MPU_PART ||
+                  opts.type === MPU_UPLOADDIR,
+                  sprintf('invalid type: %s', opts.type));
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.date = opts.date;
+        this.type = opts.type;
+}
+
+LiveRecord.prototype.toString = function lrToString() {
+        var mpuObj;
+        if (this.type === MPU_PART) {
+                mpuObj = MPUOBJ_PART;
+        } else {
+                mpuObj = MPUOBJ_UPLOADDIR;
+        }
+
+        return (this.uploadId + '\t' +
+                mpuObj + '\t' +
+                this.date.toISOString() + '\t' +
+                this.key);
+};
+
+
+
+module.exports = {
+        recordToObject: recordToObject,
+        LiveRecord: LiveRecord,
+        FinalizingRecord: FinalizingRecord,
+
+        MPU_PART: MPU_PART,
+        MPU_UPLOADDIR: MPU_UPLOADDIR,
+
+        MPUOBJ_PART: MPUOBJ_PART,
+        MPUOBJ_UPLOADDIR: MPUOBJ_UPLOADDIR,
+        MPUOBJ_FINALIZINGRECORD: MPUOBJ_FINALIZINGRECORD,
+
+        MPU_RECORD_ATTR_UPLOADID: MPU_RECORD_ATTR_UPLOADID,
+        MPU_RECORD_ATTR_MPUOBJ: MPU_RECORD_ATTR_MPUOBJ,
+        MPU_RECORD_ATTR_DATE: MPU_RECORD_ATTR_DATE,
+        MPU_RECORD_ATTR_SHARD: MPU_RECORD_ATTR_SHARD,
+        MPU_RECORD_ATTR_KEY: MPU_RECORD_ATTR_KEY,
+        MPU_MORAY_BUCKET: MPU_MORAY_BUCKET
+};
diff --git a/lib/mpu/index.js b/lib/mpu/index.js
new file mode 100644
index 0000000..1c15907
--- /dev/null
+++ b/lib/mpu/index.js
@@ -0,0 +1,38 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var MpuBatchStream = require('./mpuBatchStream');
+var MpuVerifyStream = require('./mpuVerifyStream');
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MpuUnlinkLiveRecordStream = mulrs.MpuUnlinkLiveRecordStream;
+var MpuMorayCleanerStream = require('./mpuMorayCleanerStream');
+
+function createMpuBatchStream(opts) {
+        return (new MpuBatchStream(opts));
+}
+
+function createMpuVerifyStream(opts) {
+        return (new MpuVerifyStream(opts));
+}
+
+function createMpuUnlinkLiveRecordStream(opts) {
+        return (new MpuUnlinkLiveRecordStream(opts));
+}
+
+function createMpuMorayCleanerStream(opts) {
+        return (new MpuMorayCleanerStream(opts));
+}
+
+module.exports = {
+        createMpuBatchStream: createMpuBatchStream,
+        createMpuVerifyStream: createMpuVerifyStream,
+        createMpuUnlinkLiveRecordStream: createMpuUnlinkLiveRecordStream,
+        createMpuMorayCleanerStream: createMpuMorayCleanerStream
+};
diff --git a/lib/mpu/mpuBatchStream.js b/lib/mpu/mpuBatchStream.js
new file mode 100644
index 0000000..a89b9a8
--- /dev/null
+++ b/lib/mpu/mpuBatchStream.js
@@ -0,0 +1,174 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./common');
+
+var sprintf = util.format;
+
+/*
+ * MpuBatchStream: Collects all records in a stream for related mulitpart
+ * uploads into a single batch, and passes this batch along to the next stream.
+ *
+ * NOTE: This stream assumes the input is sorted by upload ID and will throw an
+ * exception if it encounters the same upload ID twice.
+ *
+ * Parameters:
+ * - "args": an options object with the following required parameters:
+ *      - "log": a bunyan logger
+ */
+function MpuBatchStream(args) {
+        var self = this;
+
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+        self.log = args.log;
+
+        /* Current batch pointers */
+        self.mpu_batch = [];            // array of record objects in the batch
+        self.mpu_uploadId = null;       // current upload ID
+
+        /*
+         * Keep track of upload ids we've seen to ensure the input is, in fact,
+         * in sorted order. We maintain some state about these to ease
+         * port-mortem debugging if this stream throws because the input isn't
+         * sorted, which could lead to metadata cruft from MPUs.
+         */
+        self.mpu_UPLOAD_IDS = {};
+}
+util.inherits(MpuBatchStream, stream.Transform);
+
+/*
+ * Sends the current batch to the next stream, and resets the internal stream
+ * state to prepare for a new batch.
+ */
+MpuBatchStream.prototype.commitBatch = function commitBatch() {
+        var self = this;
+        assert.string(self.mpu_uploadId);
+        assert.ok(self.mpu_batch.length > 0, sprintf('no records for batch ' +
+                        '(upload id %s)', self.mpu_uploadId));
+        assert.object(self.mpu_UPLOAD_IDS[self.mpu_uploadId]);
+
+        var batch = {
+                uploadId: self.mpu_uploadId,
+                records: self.mpu_batch
+        };
+
+        self.mpu_UPLOAD_IDS[self.mpu_uploadId].status = 'completed';
+        self.push(batch);
+
+        self.mpu_uploadId = null;
+        self.mpu_batch = [];
+};
+
+/*
+ * Sets the upload ID for the current batch, and throws an exception if we've
+ * seen this upload ID in a previous batch on this stream.
+ *
+ * Parameters:
+ * - "id": upload ID for the new batch
+ */
+MpuBatchStream.prototype.createBatch = function createBatch(id) {
+        assert.uuid(id, 'id');
+        var self = this;
+
+        assert.ok(self.mpu_uploadId === null, 'other batch in process');
+
+        if (self.mpu_UPLOAD_IDS[id]) {
+                var msg = sprintf('Upload id \"%s\" has already been ' +
+                        'processed. This is very bad. Some records may not ' +
+                        'be garbage collected properly as a result.', id);
+                self.log.fatal({
+                        uploadId: id,
+                        previousBatch: self.mpu_UPLOAD_IDS[id]
+                }, msg);
+                throw (new Error(msg));
+        } else {
+                self.mpu_uploadId = id;
+                self.mpu_UPLOAD_IDS[id] = {
+                        uploadId: id,
+                        status: 'processing',
+                        numRecords: 0
+                };
+        }
+};
+
+/*
+ * Push a record object onto the current batch.
+ *
+ * Parameters:
+ *  - "r": record object to push
+ */
+MpuBatchStream.prototype.batchPush = function batchPush(r) {
+        assert.object(r, 'r');
+
+        var self = this;
+        self.mpu_batch.push(r);
+
+        var b = self.mpu_UPLOAD_IDS[r.uploadId];
+        b.numRecords++;
+
+        assert.ok(b.numRecords === self.mpu_batch.length,
+                  sprintf('mismatch of batch count (%d) ' +
+                          'and `numRecords` count (%d)',
+                          self.mpu_batch.length,
+                          b.numRecords));
+};
+
+MpuBatchStream.prototype._transform = function mbsTransform(record, _, cb) {
+        assert.string(record, 'record');
+        var self = this;
+
+        var r = mpuCommon.recordToObject(record);
+        assert.object(r, 'r');
+
+        if (self.mpu_uploadId === null) {
+                self.createBatch(r.uploadId);
+        }
+
+        /*
+         * If this has the same upload ID as the previous upload, add it to the
+         * batch; otherwise, commit the previous batch, start a new one, and add
+         * the current record to the new batch.
+         */
+        if (self.mpu_uploadId === r.uploadId) {
+                self.batchPush(r);
+                setImmediate(cb);
+        } else {
+                self.commitBatch();
+
+                self.createBatch(r.uploadId);
+                self.batchPush(r);
+
+                setImmediate(cb);
+        }
+};
+
+MpuBatchStream.prototype._flush = function mbsFlush(cb) {
+        var self = this;
+
+        // Make sure to commit an outstanding batch.
+        if (self.mpu_batch.length > 0) {
+                self.commitBatch();
+        }
+
+        setImmediate(cb);
+};
+
+module.exports = MpuBatchStream;
diff --git a/lib/mpu/mpuMorayCleanerStream.js b/lib/mpu/mpuMorayCleanerStream.js
new file mode 100644
index 0000000..8d0ccbc
--- /dev/null
+++ b/lib/mpu/mpuMorayCleanerStream.js
@@ -0,0 +1,137 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+var moray = require('moray');
+
+var mpuCommon = require('./common');
+
+
+///--- Globals
+
+var MORAY_CONNECT_TIMEOUT = 10000;
+var MORAY_PORT = 2020;
+
+/*
+ * MpuMorayCleanerStream: Deletes the finalizing record for the MPU.
+ */
+function MpuMorayCleanerStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        stream.Writable.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = args.log;
+        this.morayClients = {};
+        this.dryRun = args.dryRun;
+        this.verbose = args.verbose;
+
+        var self = this;
+        this.on('finish', function () {
+                for (var c in self.morayClients) {
+                        var client = self.morayClients[c];
+                        client.close();
+                }
+        });
+}
+util.inherits(MpuMorayCleanerStream, stream.Writable);
+module.exports = MpuMorayCleanerStream;
+
+MpuMorayCleanerStream.prototype.getMorayClient =
+function getMorayClient(shard, cb) {
+        assert.string(shard, 'shard');
+        assert.func(cb, 'cb');
+
+        var self = this;
+        if (self.morayClients[shard]) {
+                cb(self.morayClients[shard]);
+                return;
+        }
+
+        var client = moray.createClient({
+                log: self.log,
+                connectTimeout: MORAY_CONNECT_TIMEOUT,
+                host: shard,
+                port: MORAY_PORT
+        });
+
+        client.on('connect', function () {
+                self.log.info({ shard: shard }, 'Connected to shard.');
+                if (!self.morayClients[shard]) {
+                        self.morayClients[shard] = client;
+                }
+                cb(self.morayClients[shard]);
+        });
+};
+
+MpuMorayCleanerStream.prototype.deleteFinalizingRecord =
+function deleteFinalizingRecord(shard, key, cb) {
+        var self = this;
+
+        self.getMorayClient(shard, function (client) {
+                assert.object(client);
+                client.delObject(mpuCommon.MPU_MORAY_BUCKET, key, cb);
+        });
+};
+
+MpuMorayCleanerStream.prototype._write = function mmcsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+
+        var fr = batch.finalizingRecord;
+        assert.string(fr.uploadId, 'fr.uploadId');
+        assert.ok(fr.uploadId === batch.uploadId, 'upload ID of finalizing ' +
+                'record does not match batch uploadId');
+        assert.string(fr.key, 'fr.key');
+        assert.string(fr.shard, 'fr.shard');
+        assert.object(fr.date, 'fr.date');
+        assert.ok(fr.date instanceof Date, 'invalid date');
+
+        var self = this;
+        if (self.verbose) {
+                console.error('delObject ' + fr.key);
+        }
+
+        if (!self.dryRun) {
+                self.deleteFinalizingRecord(fr.shard, fr.key, function (err) {
+                        if (err) {
+                                /*
+                                 * We don't want to throw an error here in case
+                                 * this is an isolated problem, so log an error
+                                 * and continue.
+                                 */
+                                self.log.error({
+                                        uploadId: batch.uploadId,
+                                        shard: fr.shard,
+                                        key: fr.key,
+                                        err: err
+                                }, 'mpu moray cleaner stream failure');
+                        } else {
+                                self.log.info({
+                                        key: fr.key,
+                                        shard: fr.shard
+                                }, 'delobject');
+                        }
+
+                        cb();
+                });
+        } else {
+                cb();
+        }
+};
diff --git a/lib/mpu/mpuUnlinkLiveRecordStream.js b/lib/mpu/mpuUnlinkLiveRecordStream.js
new file mode 100644
index 0000000..73a1f6b
--- /dev/null
+++ b/lib/mpu/mpuUnlinkLiveRecordStream.js
@@ -0,0 +1,190 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var mahi = require('mahi');
+var stream = require('stream');
+var util = require('util');
+var vasync = require('vasync');
+
+var sprintf = util.format;
+
+var mpuCommon = require('./common');
+
+var MULRS_TYPE_PART = 'partRecords';
+var MULRS_TYPE_UPLOADDIR = 'uploadRecord';
+
+
+/*
+ * MpuUnlinkStream: Unlinks live records in Manta as part of the MPU garbage
+ * collection process. Depending on the arguments to its constructor, this
+ * stream will unlink a collection of parts in an upload directory or the upload
+ * directory itself.
+ *
+ * Parameters:
+ *  - args: an options block with the following required arguments:
+ *      - log:
+ *      - type:
+ *      - mantaClient:
+ *      - mahiClient:
+ *
+ *    and the following optional arguments:
+ *      - dryRun:
+ *      - verbose:
+ */
+function MpuUnlinkLiveRecordStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+        assert.string(args.type, 'args.type');
+        assert.ok(args.type === MULRS_TYPE_PART ||
+                args.type === MULRS_TYPE_UPLOADDIR);
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.mahiClient, 'args.mahiClient');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        stream.Transform.call(this, {
+                objectMode: true,
+                highWaterMark: 0
+        });
+
+        this.log = args.log;
+        this.mantaClient = args.mantaClient;
+        this.mahiClient = args.mahiClient;
+        this.type = args.type;
+        this.dryRun = args.dryRun;
+        this.verbose = args.verbose;
+}
+util.inherits(MpuUnlinkLiveRecordStream, stream.Transform);
+
+MpuUnlinkLiveRecordStream.prototype._transform =
+function mulrsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+        assert.optionalObject(batch.uploadRecord, 'batch.uploadRecord');
+        assert.optionalArrayOfObject(batch.partRecords, 'batch.partRecords');
+
+        var self = this;
+        if (!batch[self.type]) {
+        assert.object(batch, 'batch');
+                self.push(batch);
+                setImmediate(cb);
+                return;
+        }
+
+        /*
+         * Moray stores a normalized key, but we will need the account
+         * associated with each MPU to remove the file through the front door.
+         */
+        var uuid, account;
+        //assert.ok(batch.uploadRecord, 'batch must have an upload record');
+        //var s = batch.uploadRecord.key.split('/');
+        //assert(s.length >= 2);
+        var f = batch.finalizingRecord.key.split(':');
+        assert.ok(f.length == 2);
+        var s = f[1].split('/');
+        assert(s.length >= 2);
+        uuid = s[1];
+
+        self.mahiClient.getAccountById(uuid, function (err, info) {
+                /*
+                 * If we can't resolve the account information, we will have to
+                 * drop this batch, as there's no way for us to remove the
+                 * records from the front door.
+                 */
+                if (err) {
+                        self.log.error({
+                                uploadId: batch.uploadId,
+                                err: err
+                        }, 'error fetching account info for batch');
+                        setImmediate(cb);
+                        return;
+                }
+
+                account = info.account.login;
+                assert.string(account, 'account');
+
+                var inputs;
+                if (self.type === MULRS_TYPE_UPLOADDIR) {
+                        inputs = [ batch.uploadRecord ];
+                } else {
+                        assert.ok(self.type === MULRS_TYPE_PART,
+                                sprintf('invalid type: \"%s\"', self.type));
+                        inputs = batch.partRecords;
+                }
+                assert.arrayOfObject(inputs, 'inputs');
+
+                var opts = {
+                        query: {
+                                override: true
+                        }
+                };
+
+                function unlink(p, ucb) {
+                        self.mantaClient.unlink(p, opts, function (err2, res) {
+                                if (err2 && res.statusCode !== 404) {
+                                        errs.push(err);
+                                }
+
+                                ucb();
+                        });
+                }
+
+                var errs = [];
+                vasync.forEachParallel({
+                        func: function optionalUnlinkLiveRecord(r, vcb) {
+                                assert.string(r.key);
+                                var mantaPath = r.key.replace(uuid, account);
+
+                                if (self.verbose) {
+                                        console.error('unlink ' + mantaPath);
+                                }
+
+                                if (!self.dryRun) {
+                                        unlink(mantaPath, vcb);
+                                } else {
+                                        vcb();
+                                }
+                        },
+                        inputs: inputs
+                }, function (err3, results) {
+                        if (err3) {
+                                cb(err3);
+                        } else {
+                                if (errs.length > 0) {
+                                        errs.forEach(function (e) {
+                                                self.log.error({
+                                                        id: batch.uploadId,
+                                                        err: e
+                                                }, 'unlink live record ' +
+                                                   'stream failure');
+                                        });
+                                } else {
+                                        self.push(batch);
+                                }
+
+                                cb();
+                        }
+                });
+        });
+};
+
+
+MpuUnlinkLiveRecordStream.prototype._flush = function mupsFlush(cb) {
+        setImmediate(cb);
+};
+
+module.exports = {
+        MULRS_TYPE_PART: MULRS_TYPE_PART,
+        MULRS_TYPE_UPLOADDIR: MULRS_TYPE_UPLOADDIR,
+
+        MpuUnlinkLiveRecordStream: MpuUnlinkLiveRecordStream
+};
diff --git a/lib/mpu/mpuVerifyStream.js b/lib/mpu/mpuVerifyStream.js
new file mode 100644
index 0000000..478990b
--- /dev/null
+++ b/lib/mpu/mpuVerifyStream.js
@@ -0,0 +1,164 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./common');
+
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MULRS_TYPE_PART = mulrs.MULRS_TYPE_PART;
+var MULRS_TYPE_UPLOADDIR = mulrs.MULRS_TYPE_UPLOADDIR;
+
+/*
+ * MpuVerifyStream: Given an input stream of a batch of upload records all
+ * for the same MPU, verifies that this MPU is a valid candidate for
+ * garbage collection.
+ *
+ * The MPU is a valid candidate for garbage collection if a finalizing
+ * record exists for the MPU.
+ */
+function MpuVerifyStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = args.log;
+}
+util.inherits(MpuVerifyStream, stream.Transform);
+module.exports = MpuVerifyStream;
+
+/*
+ * Based on the records present, ensures that this MPU is valid to be garbage
+ * collected.
+ *
+ * Parameters:
+ * - id: upload ID
+ * - records: array of strings containing the related records
+ *
+ */
+MpuVerifyStream.prototype.validateMPU = function validateMPU(id, records, cb) {
+        assert.string(id, 'id');
+        assert.arrayOfObject(records, 'records');
+
+        var self = this;
+
+        var uploadRecord, partRecords, finalizingRecord;
+        var invalidBatch = false;
+
+        records.forEach(function (r) {
+                assert.ok(r instanceof mpuCommon.LiveRecord ||
+                          r instanceof mpuCommon.FinalizingRecord);
+
+                var rId = r.uploadId;
+                if (id !== rId) {
+                        self.log.error({
+                                batchUploadId: id,
+                                recordUploadId: rId
+                        }, 'MPU records batch has records with different ' +
+                           'upload IDs');
+                        invalidBatch = true;
+                }
+
+                var mpuObject;
+                if (r instanceof mpuCommon.FinalizingRecord) {
+                        mpuObject = mpuCommon.MPUOBJ_FINALIZINGRECORD;
+                } else {
+                        if (r.type === mpuCommon.MPU_PART) {
+                                mpuObject = mpuCommon.MPUOBJ_PART;
+                        } else {
+                                assert.ok(r.type === mpuCommon.MPU_UPLOADDIR);
+                                mpuObject = mpuCommon.MPUOBJ_UPLOADDIR;
+                        }
+                }
+                assert.ok(mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD ||
+                          mpuObject === mpuCommon.MPUOBJ_UPLOADDIR ||
+                          mpuObject === mpuCommon.MPUOBJ_PART);
+
+                if (mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD) {
+                        if (!finalizingRecord) {
+                                finalizingRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple finalizing records found for ' +
+                                   'the same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_UPLOADDIR) {
+                        if (!uploadRecord) {
+                                uploadRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple upload records found for the ' +
+                                   'same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_PART) {
+                        if (!partRecords) {
+                                partRecords = [];
+                        }
+
+                        partRecords.push(r);
+                } else {
+                       self.log.error({
+                                uploadId: id,
+                                record: r
+                       }, 'invalid MPU record (not a finalizing record, ' +
+                          'upload record, or part record');
+                        invalidBatch = true;
+                }
+        });
+
+        if (partRecords && partRecords.length > 0 && !uploadRecord) {
+                self.log.error({
+                        uploadId: id
+                }, 'part records found, but no upload record');
+                invalidBatch = true;
+        }
+
+        if (!invalidBatch && finalizingRecord) {
+                assert.ok(finalizingRecord);
+                assert.optionalObject(uploadRecord);
+                assert.optionalArrayOfObject(partRecords);
+
+                self.push({
+                        uploadId: id,
+                        finalizingRecord: finalizingRecord,
+                        uploadRecord: uploadRecord,
+                        partRecords: partRecords
+                });
+        }
+
+        setImmediate(cb);
+};
+
+MpuVerifyStream.prototype._transform = function mvsTransform(batch, _, cb) {
+        var self = this;
+
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.arrayOfObject(batch.records, 'batch.records');
+
+        self.validateMPU(batch.uploadId, batch.records, cb);
+};
+
+MpuVerifyStream.prototype._flush = function mvsFlush(cb) {
+        setImmediate(cb);
+};
diff --git a/lib/mpu_garbage_collector.js b/lib/mpu_garbage_collector.js
new file mode 100644
index 0000000..24ef97b
--- /dev/null
+++ b/lib/mpu_garbage_collector.js
@@ -0,0 +1,151 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var util = require('util');
+var events = require('events');
+var carrier = require('carrier');
+
+var mpuCommon = require('./mpu/common');
+
+
+///--- Globals
+
+var DEFAULT_GRACE_PERIOD_MILLIS = 1000 * 60 * 60 * 24 * 2;  // 2 days
+
+var sprintf = util.format;
+
+///--- API
+
+/*
+ * Emits 'cleanup' events for all MPU records that should be garbage collected.
+ *
+ * This object is analogous to the GarbageCollector object for normal GC. In the
+ * MPU case, only one type of event is emitted, as all records are cleaned up
+ * with the same cleanup scripts, unlike the normal GC case.
+ */
+function MpuGarbageCollector(opts, listener) {
+        assert.object(opts, 'opts');
+        assert.object(opts.reader, 'opts.reader');
+        assert.optionalObject(opts.listener, 'opts.listener');
+        assert.optionalObject(opts.gcDate, 'opts.gcDate');
+
+        var self = this;
+        if (opts.gcDate) {
+                self.gcDate = opts.gcDate;
+        } else  {
+                self.gcDate = Date.now();
+        }
+
+        var prev, curr, currFR;
+        self.gracePeriodMillis = opts.gracePeriodMillis ||
+                DEFAULT_GRACE_PERIOD_MILLIS;
+        self.carrier = carrier.carry(opts.reader);
+
+        if (listener) {
+                self.addListener('mpuCleanup', listener);
+        }
+
+        self.carrier.on('line', function (line) {
+                curr = mpuCommon.recordToObject(line);
+                currFR = takeAction(self, prev, curr, currFR);
+                prev = curr;
+                curr = null;
+        });
+
+        self.carrier.on('end', function () {
+                takeAction(self, prev, curr, currFR);
+                self.emit('end');
+        });
+}
+util.inherits(MpuGarbageCollector, events.EventEmitter);
+module.exports = MpuGarbageCollector;
+
+MpuGarbageCollector.prototype.withinGracePeriod =
+function withinGracePeriod(date) {
+        assert.object(date, 'date');
+        assert.ok(date instanceof Date, 'invalid date');
+
+        var self = this;
+
+        return ((self.gcDate - date) > self.gracePeriodMillis);
+};
+
+
+///--- Helpers
+
+/*
+ * Emits the 'mpuCleanup' event for the current finalizing record and/or the
+ * current object, if they should be garbage collected, and returns the current
+ * finalizing record for the current batch of MPU records.
+ *
+ * A record should be garbage collected if and only if it belongs to a finalized
+ * MPU -- that is, a finalizing record is present for the MPU -- and the date of
+ * the finalizing record's creation is before the grace period specified for the
+ * garbage collector.
+ *
+ * We can determine whether the current record and the current finalizing record
+ * in the stream can be garbage collected as follows. First, we inspect the
+ * previous record in the stream. If it has a different upload ID from the
+ * current record, then we have started looking at a new MPU, as we know the
+ * stream is sorted by upload ID. If a finalizing record for the previous MPU
+ * exists, we should emit a cleanup event for it. Next, we look at the current
+ * pointer to a finalizing record. If a finalizing record exists for this MPU,
+ * then we should emit a cleanup event for it. If the record itself is a
+ * finalizing record, then this record becomes the current finalizing record,
+ * and is returned from this function.
+ *
+ * Inputs:
+ * - gc: a MpuGarbageCollector object
+ * - prev: the previous record in the stream
+ * - curr: current record in the stream
+ * - currFR: current finalizing record pointer
+ *
+ */
+function takeAction(gc, prev, curr, currFR) {
+        assert.optionalObject(prev, 'prev');
+        assert.ok(prev instanceof mpuCommon.LiveRecord ||
+                  prev instanceof mpuCommon.FinalizingRecord ||
+                  !prev);
+        assert.optionalObject(curr, 'curr');
+        assert.ok(curr instanceof mpuCommon.LiveRecord ||
+                  curr instanceof mpuCommon.FinalizingRecord ||
+                  !curr);
+        assert.optionalObject(currFR, 'currFR');
+        assert.ok(currFR instanceof mpuCommon.FinalizingRecord || !currFR);
+
+        if (prev && (!curr || (prev.uploadId !== curr.uploadId))) {
+                /*
+                 * We've seen all records related to the previous upload ID,
+                 * so we know it's safe to delete the finalizing record of the
+                 * upload, if the record exists.
+                 */
+                if (currFR && gc.withinGracePeriod(currFR.date)) {
+                        gc.emit('mpuCleanup', currFR);
+                        currFR = null;
+                }
+        }
+
+        if (curr) {
+                if (curr instanceof mpuCommon.FinalizingRecord) {
+                        currFR = curr;
+                } else {
+                        /*
+                         * Don't garbage collect any records for uploads that
+                         * don't have an associated finalizing record.
+                         */
+                        if (currFR && gc.withinGracePeriod(currFR.date)) {
+                                gc.emit('mpuCleanup', curr);
+                        }
+                }
+        }
+
+        return (currFR);
+}
diff --git a/lib/mpu_gc_pg_row_transformer.js b/lib/mpu_gc_pg_row_transformer.js
new file mode 100644
index 0000000..5e5d7a6
--- /dev/null
+++ b/lib/mpu_gc_pg_row_transformer.js
@@ -0,0 +1,153 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var events = require('events');
+var path = require('path');
+var util = require('util');
+
+var mpuCommon = require('./mpu/common');
+
+var SchemaReader = require('./schema_reader');
+
+///--- GLOBALS
+
+var PG_LIVE_MANTA_TABLE_NAME = 'manta';
+var PG_MANTA_UPLOADS_TABLE_NAME = 'manta_uploads';
+
+/* JSSTYLED */
+var UPLOADS_ROOT_PATH = /^\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/uploads\/?.*/;
+
+
+///--- API
+
+/*
+ * This transforms pg-dumped rows to objects usable for multipart upload garbage
+ * collection.
+ *
+ * The resulting rows are emitted as an object: either a LiveRecord or a
+ * FinalizingRecord. LiveRecord objects represent live objects in Manta, which
+ * includes parts and upload directories for MPU garbage collection.
+ * FinalizingRecord objects map to finalizing records.
+ *
+ * Both objects expose a toString method for representing the row in a format
+ * suitable for sorting.
+ *
+ * The MpuGcPgRowTransformer is analogous to the GcPgRowTransformer object for
+ * normal garbage collection.
+ */
+function MpuGcPgRowTransformer(opts, listener) {
+        assert.object(opts, 'opts');
+        assert.object(opts.reader, 'opts.reader');
+        assert.ok(opts.dumpDate, 'opts.dumpDate');
+        assert.ok(opts.dumpDate instanceof Date, 'invalid date');
+        assert.string(opts.morayHostname, 'opts.morayHostname');
+
+        var self = this;
+        var reader = opts.reader;
+        var dumpDate = opts.dumpDate;
+        var earliestDumpDate = opts.earliestDumpDate;
+        var morayHostname = opts.morayHostname;
+
+        self.schemaReader = new SchemaReader(reader);
+
+        if (listener) {
+                self.addListener('row', listener);
+        }
+
+        function isMpuRecord(o) {
+                var t = o._value.type;
+                var k = o._value.key;
+                var u = o._value.upload;
+
+                if (k.match(UPLOADS_ROOT_PATH)) {
+                        return (t === 'object' ||
+                                (t === 'directory' && !!u));
+                }
+
+                return (false);
+        }
+
+        self.schemaReader.on('object', function (obj) {
+                var table = obj['__table'];
+                var row;
+
+                if (table === PG_LIVE_MANTA_TABLE_NAME) {
+                        if (isMpuRecord(obj)) {
+                            row = transformLiveRecord(obj, dumpDate,
+                                morayHostname);
+                        }
+                } else if (table === PG_MANTA_UPLOADS_TABLE_NAME) {
+                        row = transformFinalizingRecord(obj, earliestDumpDate,
+                            morayHostname);
+                }
+
+                if (row) {
+                        self.emit('row', row);
+                }
+        });
+
+        self.schemaReader.on('end', function () {
+                self.emit('end');
+        });
+}
+
+util.inherits(MpuGcPgRowTransformer, events.EventEmitter);
+module.exports = MpuGcPgRowTransformer;
+
+
+///--- Helpers
+
+function transformFinalizingRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_MANTA_UPLOADS_TABLE_NAME);
+        var value = obj['_value'];
+        var date = new Date(parseInt(obj['_mtime'], 10));
+
+        return new mpuCommon.FinalizingRecord({
+                uploadId: value.uploadId,
+                key: obj._key,
+                shard: morayHostname,
+                date: date,
+                type: value.finalizingType
+        });
+}
+
+function transformLiveRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_LIVE_MANTA_TABLE_NAME);
+        var value = obj['_value'];
+
+        var mpuObject, uploadId;
+        if (value.type === 'directory') {
+            mpuObject = mpuCommon.MPU_UPLOADDIR;
+            uploadId = value.upload.id;
+        } else if (value.type === 'object') {
+            mpuObject = mpuCommon.MPU_PART;
+            uploadId = path.basename(path.dirname(obj._key));
+        } else {
+            return (null);
+        }
+        assert.string(uploadId, 'uploadId');
+        assert.string(mpuObject, 'mpuObject');
+
+        if (!obj._key.match(UPLOADS_ROOT_PATH)) {
+                return (null);
+        }
+        assert.string(mpuObject);
+
+        var record = new mpuCommon.LiveRecord({
+                key: obj._key,
+                date: dumpDate,
+                type: mpuObject,
+                uploadId: uploadId
+        });
+        assert.object(record);
+
+        return (record);
+}
diff --git a/package.json b/package.json
index 8d477f7..98c0e4c 100644
--- a/package.json
+++ b/package.json
@@ -11,10 +11,11 @@
                 "carrier": "0.1.14",
                 "dashdash": "1.7.0",
                 "forkexec": "^1.1.0",
-                "jsprim": "^1.4.0",
+                "jsprim": "file:../node-jsprim",
                 "lstream": "0.0.4",
                 "once": "1.3.1",
                 "manta-hk": "git+https://github.com/joyent/manta-hk.git#master",
+                "mahi": "git+https://github.com/joyent/node-mahi.git#master",
                 "marlin": "git+https://github.com/joyent/manta-marlin.git#master",
                 "memorystream": "0.2.0",
                 "node-manta": "git+https://github.com/joyent/node-manta.git#master",
@@ -27,7 +28,9 @@
                 "vstream": "0.1.0"
         },
         "devDependencies": {
-                "nodeunit": "0.7.4"
+                "libuuid": "0.1.2",
+                "memorystream": "0.2.0",
+                "nodeunit": "0.9.1"
         },
         "sdcDependencies": {
                 "config-agent": ">=1.2.0"
diff --git a/sapi_manifests/mola/template b/sapi_manifests/mola/template
index c12a616..7bf393e 100644
--- a/sapi_manifests/mola/template
+++ b/sapi_manifests/mola/template
@@ -20,7 +20,15 @@
         },
         "connectTimeout": 1000,
         "rejectUnauthorized": {{MANTA_REJECT_UNAUTHORIZED}}
-    }{{#AUDIT_MAP_DISK}},
+    },
+    "auth"; {
+        "url": "http://{{AUTH_SERVICE}}",
+        "maxAuthCacheSize": 1000,
+        "maxAuthCacheAgeMs": 300000,
+        "maxTranslationCacheSize": 1000,
+        "maxTranslationCacheAgeMs": 300000
+    },
+    {{#AUDIT_MAP_DISK}},
     "auditMapDisk": {{AUDIT_MAP_DISK}}{{/AUDIT_MAP_DISK}}{{#AUDIT_REDUCE_DISK}},
     "auditReduceDisk": {{AUDIT_REDUCE_DISK}}{{/AUDIT_REDUCE_DISK}}{{#AUDIT_REDUCE_MEMORY}},
     "auditReduceMemory": {{AUDIT_REDUCE_MEMORY}}{{/AUDIT_REDUCE_MEMORY}}{{#AUDIT_REDUCER_COUNT}},
diff --git a/test/mpu/mpuBatchStream.test.js b/test/mpu/mpuBatchStream.test.js
new file mode 100644
index 0000000..c3cf179
--- /dev/null
+++ b/test/mpu/mpuBatchStream.test.js
@@ -0,0 +1,227 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var fs = require('fs');
+var jsprim = require('jsprim');
+var lstream = require('lstream');
+var MemoryStream = require('memorystream');
+var util = require('util');
+var uuid = require('libuuid');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mpuCommon = require('../../lib/mpu/common');
+
+///--- Globals
+
+var test = helper.test;
+var sprintf = util.format;
+
+var LOG = helper.createLogger('mpuBatchStream test');
+
+var MBS_ARGS = {
+        log: LOG
+};
+
+
+///--- Helpers
+
+function testMpuBatchStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfString(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+
+        var vsArgs = {
+                cb: args.testCb,
+                expect: args.output
+        };
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+        var mbs = new mpu.createMpuBatchStream(MBS_ARGS);
+        var vs = new inputs.ValidationStream(vsArgs);
+
+        args.input.forEach(function (i) {
+                r.push(i, 'utf8');
+        });
+        r.push(null);
+        r.pipe(mbs).pipe(vs);
+}
+
+
+///--- Tests
+
+test('single-record batch (FR only)', function (t) {
+        var input = [
+                inputs.FR_0
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple-record batch (FR, UR)', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0, inputs.OBJ_UR0
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple-record batch (with parts)', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0, inputs.PR_0[0]
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0, inputs.OBJ_UR0, inputs.OBJ_PR0[0]
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0, inputs.PR_0[0],
+                inputs.FR_2, inputs.UR_2,
+                inputs.FR_1, inputs.UR_1, inputs.PR_1[0], inputs.PR_1[1],
+                        inputs.PR_1[2]
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('records out of order', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0,
+                inputs.FR_2, inputs.UR_2,
+                inputs.PR_0[0]
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.fail('records out of order');
+                        if (ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        var d = require('domain').create();
+        d.on('error', function (err) {
+                t.ok(err, 'no error');
+                t.done();
+        });
+        d.run(function () {
+                testMpuBatchStream(args);
+        });
+});
diff --git a/test/mpu/mpuMorayCleanerStream.test.js b/test/mpu/mpuMorayCleanerStream.test.js
new file mode 100644
index 0000000..9e152e0
--- /dev/null
+++ b/test/mpu/mpuMorayCleanerStream.test.js
@@ -0,0 +1,241 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var fs = require('fs');
+var jsprim = require('jsprim');
+var lstream = require('lstream');
+var MemoryStream = require('memorystream');
+var util = require('util');
+var uuid = require('libuuid');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mpuCommon = require('../../lib/mpu/common');
+
+///--- Globals
+
+var test = helper.test;
+var sprintf = util.format;
+
+var LOG = helper.createLogger('mpuBatchStream test');
+
+var MPU_MORAY_BUCKET = 'manta_uploads';
+
+
+///--- Helpers
+
+function testMpuMorayCleanerStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfString(args.shards, 'args.shards');
+        assert.ok(args.shards.length > 0, 'at least 1 shard must be specified');
+        assert.func(args.delObjectFunc, 'args.delObjectFunc');
+        assert.func(args.testCb, 'args.testCb');
+
+        var mockMorayClients = {};
+        var clientsClosed = [];
+        args.shards.forEach(function (i) {
+                mockMorayClients[i] = {
+                        id: i,
+                        delObject: args.delObjectFunc,
+                        close: function close() {
+                                clientsClosed.push(i);
+                        }
+                };
+        });
+
+        var mmcs = new mpu.createMpuMorayCleanerStream({
+                log: LOG
+        });
+        mmcs.morayClients = mockMorayClients;
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mmcs);
+
+        mmcs.on('finish', function () {
+                args.testCb(clientsClosed);
+        });
+}
+
+///--- Tests
+
+test('one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0);
+
+                keys.push(key);
+                dcb();
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        t.ok(jsprim.deepEqual(clientsClosed, shards));
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0, inputs.SHARD_1, inputs.SHARD_2 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0,
+                inputs.KEY_FR2,
+                inputs.KEY_FR1
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0 ||
+                        key === inputs.KEY_FR1 ||
+                        key === inputs.KEY_FR2);
+
+                keys.push(key);
+                dcb();
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        shards.forEach(function (s) {
+                                t.ok(clientsClosed.indexOf(s) !== -1);
+                        });
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
+
+test('deleteFinalizingRecord returns error', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0, inputs.SHARD_1, inputs.SHARD_2 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0,
+                inputs.KEY_FR2,
+                inputs.KEY_FR1
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0 ||
+                        key === inputs.KEY_FR1 ||
+                        key === inputs.KEY_FR2);
+
+                keys.push(key);
+                var err;
+                if (key === inputs.KEY_FR2) {
+                        err = new Error('simulated moray error');
+                }
+
+                dcb(err);
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        shards.forEach(function (s) {
+                                t.ok(clientsClosed.indexOf(s) !== -1);
+                        });
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
diff --git a/test/mpu/mpuUnlinkLiveRecordStream.test.js b/test/mpu/mpuUnlinkLiveRecordStream.test.js
new file mode 100644
index 0000000..1107473
--- /dev/null
+++ b/test/mpu/mpuUnlinkLiveRecordStream.test.js
@@ -0,0 +1,1153 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+
+///--- Globals
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mulrs = require('../../lib/mpu/mpuUnlinkLiveRecordStream');
+var test = helper.test;
+
+var LOG = helper.createLogger('mpuUnlinkStream test');
+
+///--- Helpers
+
+function testMpuUnlinkLiveRecordStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+        assert.string(args.type, 'args.type');
+        assert.ok(args.type === mulrs.MULRS_TYPE_PART ||
+                args.type === mulrs.MULRS_TYPE_UPLOADDIR);
+        assert.func(args.unlinkFunc, 'args.unlinkFunc');
+        assert.func(args.getAccountByIdFunc, 'args.getAccountByIdFunc');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        var mockMahiClient = {
+                getAccountById: args.getAccountByIdFunc
+        };
+
+        var mockMantaClient = {
+                unlink: args.unlinkFunc
+        };
+
+        var mvs = new mpu.createMpuUnlinkLiveRecordStream({
+                log: LOG,
+                type: args.type,
+                mantaClient: mockMantaClient,
+                mahiClient: mockMahiClient,
+                dryRun: args.dryRun,
+                verbose: args.verbose
+        });
+
+        var vsOpts = {
+                cb: args.testCb,
+                expect: args.output
+        };
+        var vs = new inputs.ValidationStream(vsOpts);
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mvs).pipe(vs);
+}
+
+///--- Tests: upload directory
+
+test('upload directory: one batch (no parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_0
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: one batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR1,
+                inputs.PATH_UR2
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: multiple batches (one with no UR)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+//TODO: update
+test('upload directory: 404 returned during unlink', function (t) {
+        /*
+         * Deliberately return a 404 for the upload directory. In this case, we
+         * would still expect to see the batch pushed to the next stream.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                if (p === inputs.PATH_UR2) {
+                        ucb(new Error('simulated 404'), {
+                                statusCode: 404
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+test('upload directory: error returned during unlink', function (t) {
+        /*
+         * Deliberately fail a request for one of the upload directory unlinks.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                // Fail one of the requests.
+                if (p === inputs.PATH_UR2) {
+                        ucb(new Error('simulated server error'), {
+                                statusCode: 503
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: error returned during getAccountById', function (t) {
+        /*
+         * Deliberately fail a request for one of the uuid lookups from mahi.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+
+                var err, login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                        err = new Error('simulated mahi error');
+                }
+
+                gcb(err, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+
+///--- Tests: part records
+
+test('parts: one batch (1 part)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR1[0]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: one batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1],
+                inputs.PATH_PR1[2]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: multiple batches (1 part, 3 parts, 0 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1],
+                inputs.PATH_PR1[2]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+//TODO: update
+test('parts: 404 returned during unlink', function (t) {
+        /*
+         * Deliberately return a 404 for a part. In this case, we
+         * would still expect to see the batch pushed to the next stream.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1]
+        ];
+
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                if (p === inputs.PATH_PR1[0]) {
+                        ucb(new Error('simulated 404'), {
+                                statusCode: 404
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+test('parts: error returned during unlink', function (t) {
+        /*
+         * Deliberately fail a request for one of the part unlinks.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [ input[0], input[1] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                // Fail one of the requests.
+                if (p === inputs.PATH_PR1[0]) {
+                        ucb(new Error('simulated server error'), {
+                                statusCode: 503
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: error returned during getAccountById', function (t) {
+        /*
+         * Deliberately fail a request for one of the uuid lookups from mahi.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                override: true
+                        }
+                }));
+                paths.push(p);
+
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+
+                var err, login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                        err = new Error('simulated mahi error');
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(err, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
diff --git a/test/mpu/mpuVerifyStream.test.js b/test/mpu/mpuVerifyStream.test.js
new file mode 100644
index 0000000..139f26d
--- /dev/null
+++ b/test/mpu/mpuVerifyStream.test.js
@@ -0,0 +1,829 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+
+///--- Globals
+
+var assert = require('assert-plus');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var test = helper.test;
+
+var LOG = helper.createLogger('mpuVerifyStream test');
+
+var MVS_ARGS = {
+        log: LOG
+};
+
+///--- Helpers
+
+function testMpuVerifyStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+
+        var vsArgs = {
+                cb: args.testCb,
+                expect: args.output
+        };
+
+        var mvs = new mpu.createMpuVerifyStream(MVS_ARGS);
+        var vs = new inputs.ValidationStream(vsArgs);
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mvs).pipe(vs);
+}
+
+///--- Tests
+
+test('single-record batch (FR only, commit)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: undefined,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('single-record batch (FR only, abort)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: undefined,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+
+test('multiple-record batch (FR, UR)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple-record batch (1 part)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple-record batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+// Bad Input: We expect batches with bad input to be dropped from the stream.
+
+test('batch with different upload ids between FR and UR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('batch with different upload ids between FR and PR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+test('batch with different upload ids between UR and PR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+test('batch with different upload ids: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('missing FR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('missing FR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_FR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: multiple batches', function (t) {
+        var input = [
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple UR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('parts but no UR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('parts but no UR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
diff --git a/test/mpu/testInputs.js b/test/mpu/testInputs.js
new file mode 100644
index 0000000..bf4d820
--- /dev/null
+++ b/test/mpu/testInputs.js
@@ -0,0 +1,253 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var stream = require('stream');
+var util = require('util');
+
+var mpuCommon = require('../../lib/mpu/common');
+
+
+///--- Globals
+
+var MORAY_1 = '1.moray.coal.joyent.us';
+var MORAY_2 = '2.moray.coal.joyent.us';
+
+
+// Batch 0: Committed MPU with finalizing record, upload record, 1 part records
+var ID_0 = '07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var DATE_0 =  new Date();
+var SHARD_0 =  MORAY_1;
+/* BEGIN JSSTYLED */
+var KEY_FR0 = '07cff761-33c7-c9ad-a9a0-d3303afa1490:/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/stor/batch0';
+var KEY_UR0 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var KEY_PR0_0 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490/0';
+/* END JSSTYLED */
+var FR_0 = [ ID_0, '0_finalizingRecord', DATE_0, SHARD_0, 'commit', KEY_FR0 ]
+        .join('\t');
+var UR_0 = [ ID_0, '1_uploadRecord', DATE_0, KEY_UR0 ].join('\t');
+var PR_0 = [ [ ID_0, '2_partRecord', DATE_0, KEY_PR0_0 ].join('\t') ];
+var OBJ_FR0 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_0,
+        key: KEY_FR0,
+        shard: SHARD_0,
+        date: DATE_0,
+        type: 'commit'
+});
+assert.object(OBJ_FR0, 'failed to create test finalizing record 0 obj');
+var OBJ_UR0 = new mpuCommon.LiveRecord({
+        uploadId: ID_0,
+        key: KEY_UR0,
+        date: DATE_0,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR0, 'failed to create test upload record 0 obj');
+var OBJ_PR0 = [
+        new mpuCommon.LiveRecord({
+                uploadId: ID_0,
+                key: KEY_PR0_0,
+                date: DATE_0,
+                type: 'partRecord'
+        })
+];
+OBJ_PR0.forEach(function (o) {
+        assert.object(o, 'failed to create test part record 0 obj');
+});
+var ACCT_ID_0 = '4204a7f8-3d97-ec27-c16d-f2f49366cc3c';
+var ACCT_LOGIN_0 = 'testuser0';
+var PATH_UR0 = '/' + ACCT_LOGIN_0 +
+        '/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var PATH_PR0 = [
+        '/' + ACCT_LOGIN_0 + '/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490/0'
+];
+
+
+// Batch 1: Aborted MPU with finalizing record, upload record, 3 part records
+var ACCT_ID_1 = 'fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8';
+var ACCT_LOGIN_1 = 'testuser1';
+var PATH_UR1 = '/' + ACCT_LOGIN_1 +
+        '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var PATH_PR1 = [
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/0',
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/1',
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/2'
+];
+
+var ID_1 = 'c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var DATE_1 =  new Date();
+var SHARD_1 =  MORAY_1;
+/* BEGIN JSSTYLED */
+var KEY_FR1 = 'c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a:/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/stor/batch1';
+var KEY_UR1 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var KEY_PR1_0 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/0';
+var KEY_PR1_1 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/1';
+var KEY_PR1_2 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/2';
+/* END JSSTYLED */
+var FR_1 = [ ID_1, '0_finalizingRecord', DATE_1, SHARD_1, 'abort', KEY_FR1 ]
+        .join('\t');
+var UR_1 = [ ID_1, '1_uploadRecord', DATE_1, KEY_UR1 ].join('\t');
+var PR_1 = [ [ ID_1, '2_partRecord', DATE_1, KEY_PR1_0 ].join('\t'),
+             [ ID_1, '2_partRecord', DATE_1, KEY_PR1_1 ].join('\t'),
+             [ ID_1, '2_partRecord', DATE_1, KEY_PR1_2 ].join('\t')
+];
+var OBJ_FR1 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_1,
+        key: KEY_FR1,
+        shard: SHARD_1,
+        date: DATE_1,
+        type: 'abort'
+});
+assert.object(OBJ_FR1, 'failed to create test finalizing record 1 obj');
+var OBJ_UR1 = new mpuCommon.LiveRecord({
+        uploadId: ID_1,
+        key: KEY_UR1,
+        date: DATE_1,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR1, 'failed to create test upload record 1 obj');
+var OBJ_PR1 = [
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_0,
+                date: DATE_1,
+                type: 'partRecord'
+        }),
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_1,
+                date: DATE_1,
+                type: 'partRecord'
+        }),
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_2,
+                date: DATE_1,
+                type: 'partRecord'
+        })
+];
+OBJ_PR1.forEach(function (o) {
+        assert.object(o, 'failed to create test part record 1 objs');
+});
+
+
+// Batch 2: Committed MPU with finalizing record, upload record
+var ACCT_ID_2 = '88af09d7-4845-e09a-8998-d7d04a88b879';
+var ACCT_LOGIN_2 = 'testuser2';
+var PATH_UR2 = '/' + ACCT_LOGIN_2 +
+        '/uploads/3/38aecc30-9a8c-63a4-f906-e512f02f5915';
+
+var ID_2 = '38aecc30-9a8c-63a4-f906-e512f02f5915';
+var DATE_2 =  new Date();
+var SHARD_2 =  MORAY_2;
+/* BEGIN JSSTYLED */
+var KEY_FR2 = '38aecc30-9a8c-63a4-f906-e512f02f5915:/88af09d7-4845-e09a-8998-d7d04a88b879/stor/batch2';
+var KEY_UR2 = '/88af09d7-4845-e09a-8998-d7d04a88b879/uploads/3/38aecc30-9a8c-63a4-f906-e512f02f5915';
+/* END JSSTYLED */
+var FR_2 = [ ID_2, '0_finalizingRecord', DATE_2, SHARD_2, 'abort', KEY_FR2 ]
+        .join('\t');
+var UR_2 = [ ID_2, '1_uploadRecord', DATE_2, KEY_UR2 ].join('\t');
+var OBJ_FR2 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_2,
+        key: KEY_FR2,
+        shard: SHARD_2,
+        date: DATE_2,
+        type: 'abort'
+});
+assert.object(OBJ_FR2, 'failed to create test finalizing record 2 obj');
+var OBJ_UR2 = new mpuCommon.LiveRecord({
+        uploadId: ID_2,
+        key: KEY_UR2,
+        date: DATE_2,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR2, 'failed to create test upload record 2 obj');
+
+function ValidationStream(args) {
+        assert.object(args, 'args');
+        assert.func(args.cb, 'args.cb');
+        assert.array(args.expect, 'args.expect');
+
+        stream.Writable.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        var self = this;
+        self.vs_received = [];
+
+        self._write = function _write(chunk, _, cb) {
+                self.vs_received.push(chunk);
+                cb();
+        };
+
+        self.on('finish', function onFinish() {
+                var ok = jsprim.deepEqual(self.vs_received, args.expect);
+                args.cb(ok, self.vs_received);
+        });
+}
+util.inherits(ValidationStream, stream.Writable);
+
+
+module.exports = {
+        ID_0: ID_0,
+        DATE_0: DATE_0,
+        SHARD_0: SHARD_0,
+        KEY_FR0: KEY_FR0,
+        KEY_UR0: KEY_UR0,
+        KEY_PR0_0: KEY_PR0_0,
+        FR_0: FR_0,
+        UR_0: UR_0,
+        PR_0: PR_0,
+        OBJ_FR0: OBJ_FR0,
+        OBJ_UR0: OBJ_UR0,
+        OBJ_PR0: OBJ_PR0,
+        ACCT_ID_0: ACCT_ID_0,
+        ACCT_LOGIN_0: ACCT_LOGIN_0,
+        PATH_UR0: PATH_UR0,
+        PATH_PR0: PATH_PR0,
+
+        ID_1: ID_1,
+        DATE_1: DATE_1,
+        SHARD_1: SHARD_1,
+        KEY_FR1: KEY_FR1,
+        KEY_UR1: KEY_UR1,
+        KEY_PR1_0: KEY_PR1_0,
+        KEY_PR1_1: KEY_PR1_1,
+        KEY_PR1_2: KEY_PR1_2,
+        FR_1: FR_1,
+        UR_1: UR_1,
+        PR_1: PR_1,
+        OBJ_FR1: OBJ_FR1,
+        OBJ_UR1: OBJ_UR1,
+        OBJ_PR1: OBJ_PR1,
+        ACCT_ID_1: ACCT_ID_1,
+        ACCT_LOGIN_1: ACCT_LOGIN_1,
+        PATH_UR1: PATH_UR1,
+        PATH_PR1: PATH_PR1,
+
+        ID_2: ID_2,
+        DATE_2: DATE_2,
+        SHARD_2: SHARD_2,
+        KEY_FR2: KEY_FR2,
+        KEY_UR2: KEY_UR2,
+        FR_2: FR_2,
+        UR_2: UR_2,
+        OBJ_FR2: OBJ_FR2,
+        OBJ_UR2: OBJ_UR2,
+        ACCT_ID_2: ACCT_ID_2,
+        ACCT_LOGIN_2: ACCT_LOGIN_2,
+        PATH_UR2: PATH_UR2,
+
+        ValidationStream: ValidationStream
+};
diff --git a/test/mpu_garbage_collector.test.js b/test/mpu_garbage_collector.test.js
new file mode 100644
index 0000000..80a63b4
--- /dev/null
+++ b/test/mpu_garbage_collector.test.js
@@ -0,0 +1,1207 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var libuuid = require('libuuid');
+var util = require('util');
+var vstream = require('vstream');
+
+var helper = require('./helper.js');
+var lib = require('../lib');
+var mpuCommon = require('../lib/mpu/common');
+var MemoryStream = require('memorystream');
+
+
+///--- Globals
+
+var DEF_GRACE_PERIOD_MILLIS = 60 * 60 * 24 * 2 * 1000; // 2 days
+var MORAY_1 = '1.moray.coal.joyent.us';
+var MORAY_2 = '2.moray.coal.joyent.us';
+
+var OWNER_0 = libuuid.create();
+var OWNER_1 = libuuid.create();
+var ID_0 = libuuid.create();
+var ID_1 = libuuid.create();
+var ID_2 = libuuid.create();
+var ID_3 = libuuid.create();
+
+var DATE_GC = new Date('2017-08-30T00:00:00');
+var DATE_OUTSIDE_GP = new Date('2017-08-27T00:00:00');
+var DATE_WITHIN_GP = new Date('2017-08-29T00:00:00');
+
+var test = helper.test;
+
+
+///--- Helpers
+
+function uploadRecord(id, date, key) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+
+        return (id + '\t1_uploadRecord\t' + date + '\t' + key);
+}
+
+function partRecord(id, date, key) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+
+        return (id + '\t2_partRecord\t' + date + '\t' + key);
+}
+
+function commitRecord(id, date, owner, shard) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(owner, 'owner');
+        assert.string(shard, 'shard');
+
+        var key = finalizingRecordKey(id, owner);
+
+        return (id + '\t0_finalizingRecord\t' + date + '\t' + shard +
+                '\tcommit\t' + key);
+}
+
+function abortRecord(id, date, key, shard) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+        assert.string(shard, 'shard');
+
+        return (id + '\t0_finalizingRecord\t' + date + '\t' + shard +
+                '\tabort\t' + key);
+}
+
+function checkMoray(moray, morayHostname, objectId, date) {
+        assert.equal(moray.morayHostname, morayHostname);
+        assert.equal(moray.objectId, objectId);
+        assert.equal(moray.date - 0, date - 0);
+}
+
+function partRecordKey(id, owner, partNum) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+        assert.number(partNum, 'partNum');
+        assert.ok(partNum >= 0 && partNum < 10000, 'invalid partNum');
+
+        return ('/' + owner + '/uploads/' + id.substring(0, 2) + '/' + id +
+                '/' + partNum);
+}
+
+function uploadRecordKey(id, owner) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+
+        return ('/' + owner + '/uploads/' + id.substring(0, 2) + '/' + id);
+}
+
+function finalizingRecordKey(id, owner) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+
+        return (id + ':' + uploadRecordKey(id, owner));
+}
+
+///--- Tests: all within grace period
+
+test('single batch: finalizing record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: upload record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: part record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: upload and part records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalizing record and upload record', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalizing record, upload record, part records',
+function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing records only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_0, MORAY_2),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_1),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_1, MORAY_2),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        inputs.forEach(function (r) {
+                if (r !== '') {
+                        expect.push(mpuCommon.recordToObject(r));
+                }
+        });
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all upload records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all part records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // not finalized
+                partRecord(ID_1, date, partRecordKey(ID_1, OWNER_1, 0)),
+
+                // not finalized
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('no finalizing records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+                partRecord(ID_1, date, partRecordKey(ID_1, OWNER_1, 0)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[10]));
+        expect.push(mpuCommon.recordToObject(inputs[11]));
+        expect.push(mpuCommon.recordToObject(inputs[12]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing record only batch at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('upload record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('upload record only batch at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('part record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                commitRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+
+});
+
+test('part record at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                commitRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+
+///--- Tests: testing grace period
+
+test('single batch: finalizing record only, within grace period',
+function (t) {
+        var date = DATE_WITHIN_GP.toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: multiple records, within grace period', function (t) {
+        var date = DATE_WITHIN_GP.toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalized, barely within grace period',
+function (t) {
+        var ms = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS + 1000;
+        var date = new Date(ms).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalized, barely outside grace period',
+function (t) {
+        var ms = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS - 1000;
+        var date = new Date(ms).toISOString();
+
+        var inputs = [
+                // finalized, outside grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized, some within grace period', function (t) {
+        var outsideGpMs = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS - 1000;
+        var outsideGp = new Date(outsideGpMs).toISOString();
+
+        var withinGpMs = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS + 1000;
+        var withinGp = new Date(withinGpMs).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, withinGp, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, withinGp, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized, outside grace period
+                commitRecord(ID_1, outsideGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, outsideGp, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized, within grace period
+                abortRecord(ID_2, withinGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, withinGp, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized, outside grace period
+                abortRecord(ID_3, outsideGp, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, outsideGp, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, outsideGp, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized, some within custom grace period', function (t) {
+        var gracePeriod = 1000;
+
+        var outsideGpMs = DATE_GC.valueOf() - gracePeriod - 1000;
+        var outsideGp = new Date(outsideGpMs).toISOString();
+
+        var withinGpMs = DATE_GC.valueOf() - gracePeriod + 1000;
+        var withinGp = new Date(withinGpMs).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, withinGp, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, withinGp, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized, outside grace period
+                commitRecord(ID_1, outsideGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, outsideGp, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized, within grace period
+                abortRecord(ID_2, withinGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, withinGp, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized, outside grace period
+                abortRecord(ID_3, outsideGp, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, outsideGp, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, outsideGp, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                gracePeriodMillis: gracePeriod
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
