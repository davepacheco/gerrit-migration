commit ab52106c891544d1d7dfe32d9acafd8745cde173 (refs/changes/02/2802/15)
Author: Jordan Hendricks <jordan.hendricks@joyent.com>
Date:   2018-01-03T23:25:15+00:00 (1 year, 9 months ago)
    
    MANTA-3226 Manta garbage collection needs to support multipart uploads

diff --git a/Makefile b/Makefile
index 50ff1c0..14fa7d7 100644
--- a/Makefile
+++ b/Makefile
@@ -5,7 +5,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 #
@@ -25,7 +25,7 @@
 #
 # Tools
 #
-NODEUNIT        := ./node_modules/.bin/nodeunit
+NODEUNIT        := ./node_modules/.bin/nodeunit --reporter=tap
 NPM             := npm
 
 #
diff --git a/bin/gc_links.pl b/bin/gc_links.pl
index 2d19829..5e835f9 100755
--- a/bin/gc_links.pl
+++ b/bin/gc_links.pl
@@ -6,7 +6,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 ###############################################################################
@@ -14,9 +14,8 @@
 # mako.  This should go away post-haste after the stream to many mpipes
 # is written.
 ###############################################################################
-
 if (@ARGV < 3) {
-    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " +
+    print "Usage: ".$ENV{"_"}." [manta_user] [output file] " .
         "[manta object prefix]\n";
     exit 1;
 }
diff --git a/bin/kick_off_mpu_cleanup.js b/bin/kick_off_mpu_cleanup.js
new file mode 100755
index 0000000..bd06b98
--- /dev/null
+++ b/bin/kick_off_mpu_cleanup.js
@@ -0,0 +1,1081 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var dashdash = require('dashdash');
+var fs = require('fs');
+var http = require('http');
+var lstream = require('lstream');
+var mahi = require('mahi');
+var manta = require('manta');
+var path = require('path');
+var util = require('util');
+var vasync = require('vasync');
+var vstream = require('vstream');
+
+var lib = require('../lib');
+var mpu = require('../lib/mpu');
+
+/*
+ * bin/kick_off_mpu_cleanup.js: MPU GC Cleanup Script
+ *
+ *
+ * SUMMARY:
+ *
+ * This script coordinates the cleanup of parts, upload directories and
+ * finalizing records for multipart uploads based on the instruction files
+ * generated by the MPU GC job (defined in bin/kick_off_mpu_gc.js).
+ *
+ * Generally, the instruction files are output by the MPU GC job at
+ * /poseidon/stor/manta_mpu_gc/cleanup. Once the script completes, it links a
+ * copy of the instructions at /poseidon/stor/manta_mpu_gc/completed for
+ * posterity, and unlinks the original copy in the cleanup directory.
+ *
+ *
+ * PREREQUISITES:
+ *
+ * In order to run this script, you should verify you have the following:
+ *      - instruction files, either in Manta or locally, that match the format
+ *        specified in lib/mpu/common.js (such as the output of the MPU GC job)
+ *      - a configuration file with a valid Manta client configuration and Mahi
+ *        client configuration, with the path to this config in the environment
+ *        variable $MANTA_CONFIG (or /opt/smartdc/mola/etc/config.json)
+ *
+ *
+ * INSTRUCTION FILES:
+ *
+ * Instruction files contain a list of part records, upload directories, and
+ * finalizing records to delete. The lists are sorted by upload ID, and each
+ * record is on its own line. The format of each line is documented in
+ * lib/mpu/common.js.
+ *
+ * By default, the script is designed for the typical production use case,
+ * shipped in the Manta "ops" zone and scheduled to run in crontab. In this
+ * case, the script will operate on all instruction files in Manta at:
+ *
+ *      /poseidon/stor/manta_mpu_gc/cleanup
+ *
+ * You may also instead specify particular instruction files in Manta to use
+ * with the `-r` or `-i` flags.
+ *
+ * When the instructions are fetched from Manta, after executing the cleanup
+ * instructions, the script will unlink the instruction files from their
+ * original source directory after making a copy of them in:
+ *
+ *      /poseidon/stor/manta_mpu_gc/completed
+ *
+ * For debugging purposes, it is often useful to to specify local copies of
+ * instruction files instead. You may specify local files using the `-f` flag.
+ * Local files are not uploaded in any fashion to Manta.
+ *
+ *
+ * CLEANUP STREAMS IMPLEMENTATION:
+ *
+ * For each instruction file in $MPU_GC_CLEANUP_DIR, the script will
+ * instantiate a pipeline of node streams that perform distinct tasks related
+ * to the cleanup of the stream. These tasks are as follows:
+ *      1. Parse the instruction file into a stream of lines. (Each line
+ *         represents a single record.)
+ *      2. Collect records related to the same MPU, based on sorted order, into
+ *         a single javascript object.
+ *      3. For each MPU, verify that the records match the invariants we know to
+ *         be true about finalized multipart uploads; for instance, there must
+ *         be a finalizing record.
+ *      4. For each MPU, unlink all part records, if any exist, from the front
+ *         door of Manta.
+ *      5. For each MPU, unlink the upload directory, if it exists, from the
+ *         front door of Manta.
+ *      6. For each MPU, delete its finalizing record directly from Moray.
+ *
+ * These steps map directly to the following stream implementations. See the
+ * source files of each stream for details:
+ *      0. lstream
+ *      1. MpuBatchStream
+ *      2. MpuVerifyStream
+ *      3. MpuUnlinkLiveRecordStream (type='partRecords')
+ *      4. MpuUnlinkLiveRecordStream (type='uploadRecord')
+ *      5. MpuMorayCleanerStream
+ *
+ *
+ * SCRIPT OPTIONS & DEBUGGING:
+ *
+ * A combination of the `-n` and `-v` flags is useful to see what the script
+ * would do without deletion of any data, including instruction files.
+ *
+ * Using the `-r`, `-f` or `-i` flags allow you to run the script on
+ * particular input files.
+ *
+ * This script uses bunyan logging to document its progress. Such log messages
+ * may be useful for debugging problems.
+ *
+ */
+
+///--- Globals
+
+// Logging setup
+var LOG_LEVEL = process.env.LOG_LEVEL || 'info';
+var LOG = bunyan.createLogger({
+        level: LOG_LEVEL,
+        name: 'mpu_gc_cleanup',
+        stream: process.stdout,
+        serializers: bunyan.stdSerializers
+});
+
+// Configuration
+var MANTA_CONFIG = (process.env.MANTA_CONFIG ||
+                    '/opt/smartdc/mola/etc/config.json');
+var CONFIG = JSON.parse(fs.readFileSync(MANTA_CONFIG, { encoding: 'utf8' }));
+var MANTA_CLIENT = manta.createClientFromFileSync(MANTA_CONFIG, LOG);
+var MANTA_USER = MANTA_CLIENT.user;
+var MAHI_CLIENT = mahi.createClient(CONFIG.auth);
+
+// Relevant Manta paths
+var MPU_GC_ROOT = '/' + MANTA_USER + '/stor/manta_mpu_gc';
+var MPU_GC_CLEANUP_DIR = MPU_GC_ROOT + '/cleanup';
+var MPU_GC_COMPLETED_DIR = MPU_GC_ROOT + '/completed';
+
+var RAW_STATS_SUMMARY = {};
+
+var CLEANUP_STREAM_BATCH = 'MpuBatchStream';
+var CLEANUP_STREAM_VERIFY = 'MpuVerifyStream';
+var CLEANUP_STREAM_UNLINKPARTS = 'MpuUnlinkLivePartRecordsStream';
+var CLEANUP_STREAM_UNLINKUPLOADDIR = 'MpuUnlinkLiveUploadRecordStream';
+var CLEANUP_STREAM_DELFR = 'MpuMorayCleanerStream';
+
+var MPU_CLEANUP_DEF_CURRENCY = 10;
+
+var sprintf = util.format;
+
+
+///--- Helpers
+
+function getOptions() {
+        var options = [
+                {
+                        names: [ 'dryRun', 'n' ],
+                        type: 'bool',
+                        help: 'Perform a dry run of the cleanup: not ' +
+                              'removing any records, deleting input ' +
+                              'instructions or uploading completed ' +
+                              'instructions to Manta.'
+                },
+                {
+                        names: ['verbose', 'v'],
+                        type: 'bool',
+                        help: 'Print out deletion commands to stderr.'
+                },
+                {
+                        names: ['file', 'f'],
+                        type: 'arrayOfString',
+                        help: 'Local file to use for cleanup instructions. ' +
+                              'Only remote files, local files, or an ' +
+                              'instruction directory in Manta may be used. ' +
+                              'Local files will not be uploaded to Manta ' +
+                              'after processing. ',
+                        helpArg: 'FILE'
+                },
+                {
+                        names: ['remoteFile', 'r'],
+                        type: 'arrayOfString',
+                        help: 'File in Manta to use for cleanup ' +
+                              'instructions. Remote instructions are not ' +
+                              'deleted or uploaded as completed to Manta. ' +
+                              'Only remote files, local files, ' +
+                              'or an instruction directory in Manta may be ' +
+                              'used.',
+                        helpArg: 'FILE'
+                },
+                {
+                        names: ['concurrency', 'c'],
+                        type: 'positiveInteger',
+                        default: MPU_CLEANUP_DEF_CURRENCY,
+                        help: 'Number of cleanup instructions to execute ' +
+                              'concurrently.'
+                },
+                {
+                        names: ['cleanupDir', 'i'],
+                        type: 'string',
+                        default: MPU_GC_CLEANUP_DIR,
+                        help: 'Directory in Manta to look for cleanup ' +
+                              'instructions. After processing, instruction ' +
+                              'files in this directory will be linked to a ' +
+                              'completed instructions directory, and the ' +
+                              'original files will be deleted from Manta. ' +
+                              'Use this flag in conjunction with -d to ' +
+                              'specify a completed instructions directory; ' +
+                              'otherwise, the default completed directory ' +
+                              'will be used. ',
+                        helpArg: 'DIR'
+                },
+                {
+                        names: ['completedDir', 'd'],
+                        type: 'string',
+                        default: MPU_GC_COMPLETED_DIR,
+                        help: 'Directory in Manta to store completed cleanup ' +
+                              'instructions. ' +
+                              'Use this flag in conjunction with -i to ' +
+                              'specify a cleanup instructions directory; ' +
+                              'otherwise, the default cleanup directory ' +
+                              'will be used.',
+                        helpArg: 'DIR'
+                },
+                {
+                        names: ['help', 'h'],
+                        type: 'bool',
+                        help: 'Print this help and exit.'
+                }
+        ];
+
+        var parser = dashdash.createParser({options: options});
+        var o;
+        try {
+                o = parser.parse(process.argv);
+        } catch (e) {
+                console.error('error: %s', e.message);
+                usage();
+                process.exit(1);
+        }
+
+        function usage() {
+                var help = 'usage: ' + path.basename(process.argv[1]);
+                help += ' [OPTIONS]\n\n';
+                help += 'options:\n';
+                help += parser.help().trimRight();
+                console.log(help);
+        }
+
+        if (o.help) {
+                usage();
+                process.exit(0);
+        }
+
+        if (o.file && o.remoteFile) {
+                var msg = 'only one of --file and --remoteFile may be used';
+                console.error('error: %s', msg);
+                usage();
+                process.exit(1);
+        }
+
+        return (o);
+}
+
+/*
+ * Returns a new pipeline stream suitable for cleaning up MPU garbage.
+ *
+ * Parameters:
+ * - args: an arguments object with the following properties:
+ *      - log: a bunyan logger, which will have children loggers created for
+ *             each stream
+ *      - mantaClient: a Manta client
+ *      - mahiClient: a Mahi client
+ *      - instrFile: for logging purposes, the path to the instructions file in
+ *                   Manta that will be used with this stream
+ *      - onFinishCb: callback function to be called when the stream has
+ *                    finished processing its input
+ *      - dryRun: optional bool, which, if true, will do a dry run (no deletion
+ *        of metadata records)
+ *      - verbose: optional bool, which, if true, will print out each action
+ *        taken by the cleanup streams to stderr
+ *
+ */
+function newMpuGcStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.mahiClient, 'args.mahiClient');
+        assert.string(args.instrFile, 'args.instrFile');
+        assert.func(args.onFinishCb, 'args.onFinishCb');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        // Step 0: Parse file into lines
+        var ls = vstream.wrapTransform(new lstream({
+                highWaterMark: 0
+        }));
+
+        // Step 1: Collect together batches of records for each MPU
+        var mbs = vstream.wrapTransform(new mpu.createMpuBatchStream({
+                log: args.log.child({
+                        step: 1,
+                        streamName: CLEANUP_STREAM_BATCH,
+                        instrFile: args.instrFile
+                })
+        }));
+
+        // Step 2: Sanity check each MPU batch
+        var mvs = vstream.wrapTransform(new mpu.createMpuVerifyStream({
+                log: args.log.child({
+                        step: 2,
+                        streamName: CLEANUP_STREAM_VERIFY,
+                        instrFile: args.instrFile
+                })
+        }));
+
+        // Step 3: Unlink parts for each MPU
+        var mulrsPR = vstream.wrapTransform(
+                new mpu.createMpuUnlinkLiveRecordStream({
+                        log: args.log.child({
+                                step: 3,
+                                streamName: CLEANUP_STREAM_UNLINKPARTS,
+                                instrFile: args.instrFile,
+                                type: 'partRecords'
+                        }),
+                        dryRun: args.dryRun,
+                        verbose: args.verbose,
+                        mantaClient: args.mantaClient,
+                        mahiClient: args.mahiClient,
+                        type: 'partRecords'
+        }));
+
+        // Step 4: Unlink upload directory for each MPU
+        var mulrsUR = vstream.wrapTransform(
+                new mpu.createMpuUnlinkLiveRecordStream({
+                        log: args.log.child({
+                                step: 4,
+                                streamName: CLEANUP_STREAM_UNLINKUPLOADDIR,
+                                instrFile: args.instrFile,
+                                type: 'uploadRecord'
+                        }),
+                        dryRun: args.dryRun,
+                        verbose: args.verbose,
+                        mantaClient: args.mantaClient,
+                        mahiClient: args.mahiClient,
+                        type: 'uploadRecord'
+        }));
+
+        // Step 5: Delete finalizing record for each MPU
+        var mmcs = vstream.wrapStream(
+                new mpu.createMpuMorayCleanerStream({
+                        log: args.log.child({
+                                step: 5,
+                                streamName: CLEANUP_STREAM_DELFR,
+                                instrFile: args.instrFile
+                        }),
+                        dryRun: args.dryRun,
+                        verbose: args.verbose
+        }));
+
+        /*
+         * Set up a stats object that we can use to infer more information about
+         * what happened in this stream when it has completed.
+         */
+        RAW_STATS_SUMMARY[args.instrFile] = {};
+
+        function updateStats(name) {
+                assert.string(name, 'name');
+                RAW_STATS_SUMMARY[args.instrFile][name] = this.getStats();
+        }
+
+        mbs.on('finish', updateStats.bind(mbs, CLEANUP_STREAM_BATCH));
+        mvs.on('finish', updateStats.bind(mvs, CLEANUP_STREAM_VERIFY));
+        mulrsPR.on('finish',
+                updateStats.bind(mulrsPR, CLEANUP_STREAM_UNLINKPARTS));
+        mulrsUR.on('finish',
+                updateStats.bind(mulrsUR, CLEANUP_STREAM_UNLINKUPLOADDIR));
+        mmcs.on('finish', function () {
+                updateStats.call(mmcs, CLEANUP_STREAM_DELFR);
+
+                /*
+                 * This is the last stream in the pipeline, so invoke the
+                 * caller's callback function.
+                 */
+                args.onFinishCb();
+        });
+
+        var mpuGcStreams = new vstream.PipelineStream({
+                streams: [
+                        ls,
+                        mbs,
+                        mvs,
+                        mulrsPR,
+                        mulrsUR,
+                        mmcs
+                ],
+
+                streamOpts: {
+                        highWaterMark: 0,
+                        objectMode: true
+                }
+        });
+
+        return (mpuGcStreams);
+}
+
+/*
+ * Given a raw stats object from an MPU GC pipeline stream, format it to be more
+ * informative for users reading the logs.
+ */
+function summarizeStats(stats) {
+        assert.object(stats, 'stats');
+
+        // Total batches in and out of the cleanup pipeline
+        var numInputBatches = stats[CLEANUP_STREAM_BATCH].numBatches;
+        var numOutputBatches = stats[CLEANUP_STREAM_DELFR].numBatchesOutput;
+        var batchSummary = {
+                'numInput': numInputBatches,
+                'numProcessed': numOutputBatches
+        };
+
+        // Dropped batches broken down by phase
+        var mbsNd, mvsNd, mulrsPRNd, mulrsURNd, mmcsNd;
+        mbsNd = 0; // MpuBatchStream doesn't drop any batches
+        mvsNd = stats[CLEANUP_STREAM_VERIFY].numBatchesDropped;
+        mulrsPRNd = stats[CLEANUP_STREAM_UNLINKPARTS].numBatchesDropped;
+        mulrsURNd = stats[CLEANUP_STREAM_UNLINKUPLOADDIR].numBatchesDropped;
+        mmcsNd = stats[CLEANUP_STREAM_DELFR].numBatchesDropped;
+        var droppedBatchesSummary = {};
+        droppedBatchesSummary[CLEANUP_STREAM_BATCH] = mbsNd;
+        droppedBatchesSummary[CLEANUP_STREAM_VERIFY] = mvsNd;
+        droppedBatchesSummary[CLEANUP_STREAM_UNLINKPARTS] = mulrsPRNd;
+        droppedBatchesSummary[CLEANUP_STREAM_UNLINKUPLOADDIR] = mulrsURNd;
+        droppedBatchesSummary[CLEANUP_STREAM_DELFR] = mmcsNd;
+
+        // Total records seen, as told by the first stream in the pipeline
+        var mvsNpr, mvsNur, mvsNfr, mvsNr;
+        mvsNpr = stats[CLEANUP_STREAM_VERIFY].numPRInput;
+        mvsNur = stats[CLEANUP_STREAM_VERIFY].numURInput;
+        mvsNfr = stats[CLEANUP_STREAM_VERIFY].numFRInput;
+        mvsNr = stats[CLEANUP_STREAM_VERIFY].numRecordsInput;
+        var totalRecordsSummary = {
+                'partRecords': mvsNpr,
+                'uploadRecords':  mvsNur,
+                'finalizingRecords':  mvsNfr,
+                'total': mvsNr
+        };
+
+        // Total records garbage collected
+        var mulrsPRNr, mulrsURNr, mmcsNr;
+        mulrsPRNr = stats[CLEANUP_STREAM_UNLINKPARTS].numRecordsUnlinked;
+        mulrsURNr = stats[CLEANUP_STREAM_UNLINKUPLOADDIR].numRecordsUnlinked;
+        mmcsNr = stats[CLEANUP_STREAM_DELFR].numRecordsDeleted;
+
+        var cleanedRecordsSummary = {
+                'partRecords': mulrsPRNr,
+                'uploadRecords': mulrsURNr,
+                'finalizingRecords': mmcsNr,
+                'total': mulrsPRNr + mulrsURNr + mmcsNr
+        };
+
+        var recordSummary = {
+                'numInputRecords': totalRecordsSummary,
+                'numRecordsRemoved': cleanedRecordsSummary
+        };
+
+
+        var sum = {
+                'summaryByMpu': batchSummary,
+                'summaryByRecordType': recordSummary,
+                'numBatchesDroppedByPhase': droppedBatchesSummary
+        };
+
+        return (sum);
+}
+
+/*
+ * Fetches entries from Manta for the input directory. These entries represent
+ * the inputs to the pipeline of MPU GC streams.
+ *
+ * Parameters:
+ * - args: an arguments object with the following values:
+ *      - mantaClient: a Manta client
+ *      - log: a bunyan logger
+ *      - dir: full Manta path representing input directory
+ * - cb: callback function of the form cb(err, entries)
+ */
+function getInputsFromDir(args, cb) {
+        assert.object(args, 'args');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.log, 'args.log');
+        assert.string(args.dir, 'args.dir');
+        assert.func(cb, 'cb');
+
+        var log = args.log;
+
+        log.debug({
+                dir: args.dir
+        }, 'getInputsFromDir: entered');
+
+
+        var entries = [];
+        args.mantaClient.ls(args.dir, function (err, res) {
+                if (err) {
+                        cb(err);
+                }
+
+                res.on('entry', function (e) {
+                        entries.push(e.parent + '/' + e.name);
+                });
+
+
+                res.on('end', function () {
+                        log.debug({
+                                dir: args.dir,
+                                entries: entries
+                        }, 'getInputsFromDir: done');
+
+                        cb(null, entries);
+                });
+        });
+}
+
+/*
+ * For a list of inputs to use for the MPU GC stream pipeline, fetch the input
+ * from Manta as a Readable stream.
+ *
+ * Parameters:
+ * - args: an arguments object with the following values:
+ *      - mantaClient: a Manta client
+ *      - log: a bunyan logger
+ *      - inputs: array of strings representing full Manta paths of objects that
+ *        will be fetched and returned as a stream
+ * - cb: callback of the form cb(err, streamObjs)
+ */
+function getInputStreams(args, cb) {
+        assert.object(args, 'args');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.log, 'args.log');
+        assert.arrayOfString(args.inputs, 'args.inputs');
+        assert.func(cb, 'cb');
+
+        var log = args.log;
+        var client = args.mantaClient;
+        var streamObjs = [];
+
+        log.debug({
+                inputs: args.inputs
+        }, 'getInputStreams: entered');
+
+        function mantaGet(p, mcb) {
+                assert.string(p, 'p');
+
+                client.get(p, function (merr, s) {
+                        if (merr) {
+                                var msg = sprintf('failed to ' +
+                                        'retrieve input file %s', p);
+                                log.error(msg, merr);
+                                mcb();
+                                return;
+                        }
+
+                        streamObjs.push({
+                                stream: s,
+                                file: p
+                        });
+                        mcb();
+                });
+        }
+
+        vasync.forEachParallel({
+                inputs: args.inputs,
+                func: mantaGet
+        }, function (err) {
+                log.debug({
+                        inputs: args.inputs
+                }, 'getInputStreams: done');
+
+                cb(err, streamObjs);
+        });
+}
+
+
+/*
+ * For a given stream of instructions, instantiate an MPU pipeline cleanup
+ * stream, and pipe the instructions to it. Once the cleanup pipeline has
+ * completed, the caller-provided callback is called.
+ *
+ * Parameters:
+ * - args: an arguments object with the following values:
+ *      - stream: Readable stream to pipe into the MPU GC streams pipeline
+ *      - input: string representing the full path in Manta used to create the
+ *        stream
+ *      - mantaClient: a Manta client
+ *      - mahiClient: a Mahi client
+ *      - log: a bunyan logger
+ *      - dryRun: optional bool, which, if true, will do a dry run of MPU GC
+ *        cleanup (no deletion of metadata records)
+ *      - verbose: optional bool, which, if true, will print out each action
+ *        taken by the cleanup streams to stderr
+ * - cb: callback function
+ */
+function cleanupFromStream(args, cb) {
+        assert.object(args, 'args');
+        assert.object(args.stream, 'args.stream');
+        assert.string(args.instrFile, 'args.instrFile');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.mahiClient, 'args.mahiClient');
+        assert.object(args.log, 'args.log');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+        assert.func(cb, 'cb');
+
+        var log = args.log;
+
+        log.info({
+                instrFile: args.instrFile
+        }, 'cleanupFromStream: entered');
+
+        function onFinish() {
+                log.info({
+                        instrFile: args.instrFile,
+                        completed: args.completed
+                }, 'cleanupFromStream: done');
+
+                cb();
+        }
+
+        var mpuGcStreamArgs = {
+                mantaClient: args.mantaClient,
+                mahiClient: args.mahiClient,
+                log: args.log,
+                onFinishCb: onFinish,
+                instrFile: args.instrFile,
+                dryRun: args.dryRun,
+                verbose: args.verbose
+        };
+
+        args.stream.pipe(newMpuGcStream(mpuGcStreamArgs));
+}
+
+
+/*
+ * For a list of completed instruction files in Manta, link these files to the
+ * input completedDir in Manta, and unlink the original file from Manta.
+ *
+ * Parameters:
+ * - args: an arguments object with the following values:
+ *      - mantaClient: a Manta client
+ *      - log: a bunyan logger
+ *      - completed: array of Manta paths to link into `completedDir`, and
+ *        subsequently unlink from Manta
+ *      - completedDir: directory in Manta to place completed instruction files
+ *      - dryRun: optional bool, which, if true, will not link or unlink the
+ *        instruction files in Manta
+ *      - verbose: optional bool, which, if true, will print out the link/unlink
+ *        actions that are (or would be taken, with -n) to stderr
+ * - cb: callback of the form cb(err)
+ */
+function linkAndDelCompleted(args, cb) {
+        assert.object(args, 'args');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.log, 'args.log');
+        assert.arrayOfString(args.completed, 'args.completed');
+        assert.string(args.completedDir, 'args.completedDir');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+        assert.func(cb, 'cb');
+
+        var log = args.log;
+
+        log.debug({
+                files: args.completed,
+                linkDir: args.completedDir,
+                dryRun: args.dryRun ? true : false,
+                verbose: args.verbose ? true : false
+        }, 'linkAndDelCompleted: entered');
+
+
+        function linkCompleted(arg, lccb) {
+                assert.string(arg.src, 'arg.src');
+                assert.string(arg.dest, 'arg.dest');
+                assert.object(arg.client, 'arg.client');
+
+                if (args.verbose) {
+                        console.error('link ' + arg.src + ' to ' + arg.dest);
+                }
+
+                if (!args.dryRun) {
+                        arg.client.ln(arg.src, arg.dest, function (err) {
+                                if (err) {
+                                        log.error({
+                                                src: arg.src,
+                                                dest: arg.dest,
+                                                err: err
+                                        }, 'could not link instruction file');
+                                } else {
+                                        log.info({
+                                                src: arg.src,
+                                                dest: arg.dest
+                                        }, 'instructions file linked');
+                                }
+
+                                lccb(err);
+                        });
+                } else {
+                        setImmediate(lccb);
+                }
+        }
+
+        function delCompleted(arg, dccb) {
+                assert.string(arg.src, 'arg.src');
+                assert.object(arg.client, 'arg.client');
+
+                if (args.verbose) {
+                        console.error('unlink ' + arg.src);
+                }
+
+                if (!args.dryRun) {
+                        arg.client.unlink(arg.src, function (err) {
+                                if (err) {
+                                        log.error({
+                                                file: arg.src,
+                                                err: err
+                                        }, 'could not unlink instruction file');
+                                } else {
+                                        log.info({
+                                                src: arg.src
+                                        }, 'instructions file unlinked');
+                                }
+
+                                dccb(err);
+                        });
+                } else {
+                        setImmediate(dccb);
+                }
+        }
+
+        vasync.forEachParallel({
+                inputs: args.completed,
+                func: function linkAndDel(p, lcb) {
+                        var src = p;
+                        var dest = args.completedDir + '/' + path.basename(p);
+
+                        vasync.pipeline({
+                                arg: {
+                                        src: src,
+                                        dest: dest,
+                                        client: args.mantaClient
+                                },
+                                funcs: [
+                                        linkCompleted,
+                                        delCompleted
+                                ]
+                        }, function (perr, r) {
+                                lcb(perr);
+                        });
+                }
+        }, function (err, _) {
+                log.debug({
+                        files: args.completed,
+                        linkDir: args.completedDir,
+                        dryRun: args.dryRun ? true : false,
+                        verbose: args.verbose ? true : false
+                }, 'linkAndDelCompleted: done');
+
+                cb(err);
+        });
+}
+
+/*
+ * For a list of streams containing instructions for the MPU GC streams
+ * pipeline, instantiate a new version of the MPU GC pipeline, and pipe the
+ * stream to it.
+ *
+ * Streams that successfully made it through the cleanup pipeline are pushed to
+ * an array of Manta paths that is passed as the second argument to the callback
+ * function.
+ *
+ * NOTE: Because PipelineStreams can use a lot of memory, we may need to tweak
+ * how many of these streams we instantiate at a time in the future.
+ *
+ * Parameters:
+ * - args: an arguments object with the following values:
+ *      - toCleanup: array of Readable streams constructed from instruction
+ *        files
+ *      - mantaClient: a Manta client
+ *      - mahiClient: a Mahi client
+ *      - log: a bunyan logger
+ *      - dryRun: optional bool, which, if true, will do a dry run of MPU GC
+ *        cleanup (no deletion of metadata records)
+ *      - verbose: optional bool, which, if true, will print out each action
+ *        taken by the cleanup streams to stderr
+ * - cb: callback function of the form cb(completed)
+ */
+function runCleanupInstructions(args, cb) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.toCleanup, 'args.toCleanup');
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.mahiClient, 'args.mahiClient');
+        assert.number(args.concurrency, 'args.concurrency');
+        assert.object(args.log, 'args.log');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+        assert.func(cb, 'cb');
+
+        var done = [];
+
+        function runCleanup(s, rcb) {
+                assert.object(s, 's');
+                assert.object(s.stream, 's.stream');
+                assert.string(s.file, 's.file');
+
+                cleanupFromStream({
+                        mantaClient: args.mantaClient,
+                        mahiClient: args.mahiClient,
+                        log: args.log,
+                        dryRun: args.dryRun,
+                        verbose: args.verbose,
+                        stream: s.stream,
+                        instrFile: s.file
+                }, function () {
+                        done.push(s.file);
+                        rcb();
+                });
+        }
+
+        var q = vasync.queue(runCleanup, args.concurrency);
+        q.on('end', function () {
+                cb(done);
+        });
+
+        q.push(args.toCleanup);
+        q.close();
+}
+
+
+function scriptFinish() {
+        // Close open clients.
+        MAHI_CLIENT.close();
+        MANTA_CLIENT.close();
+
+        var allStats = [];
+        for (var i in completed) {
+                var f = completed[i];
+                allStats.push({
+                        'instructionFile': f,
+                        'stats': summarizeStats(RAW_STATS_SUMMARY[f])
+                });
+        }
+
+        // Log what we did for posterity.
+        LOG.info({
+                instrFiles: instrFiles,
+                completed: completed,
+                stats: allStats
+        }, 'MPU cleanup script finished.');
+
+        process.exit(exitCode);
+}
+
+
+///--- Main
+
+var userOpts = getOptions();
+var exitCode = 0;
+
+/*
+ * Array of strings representing all input instruction files.
+ */
+var instrFiles;
+
+/*
+ * An array of objects containing the stream fetched for each input file. Each
+ * object is of the form:
+ *  {
+ *      stream: Readable stream
+ *      file: Manta path to object
+ *  }
+ *
+ * The set of files contained in all objects in this array are a subset of those
+ * contained in `inputs`. If there are no errors fetching each input, we would
+ * expect the length of `inputs` and `sObjs` to be the same. If there is an
+ * error fetching some of the objects, we still attempt to use the instructions
+ * that were successfully fetched.
+ */
+var toCleanup;
+
+/*
+ * An array of strings representing the instruction files whose instructions
+ * were successfully completed. This set of files is a subset of those contained
+ * in `toCleanup`.
+ */
+var completed;
+
+if (!userOpts.file) {
+        /*
+         * Typical production case. Possible fatal errors are:
+         *      - errors in listing instruction files from Manta
+         *      - inability to finish all instruction files cleanup streams
+         *      - inability to link and delete instruction files from Manta
+         */
+        vasync.pipeline({
+                funcs: [
+                        /*
+                         * First, determine what cleanup instruction files exist
+                         * in Manta, or skip this if the user specified specific
+                         * files to use.
+                         */
+                        function getInputs(_, cb) {
+                                if (userOpts.remoteFile) {
+                                        instrFiles = userOpts.remoteFile;
+                                        setImmediate(cb);
+                                        return;
+                                }
+
+                                var dir = userOpts.cleanupDir;
+
+                                getInputsFromDir({
+                                        mantaClient: MANTA_CLIENT,
+                                        log: LOG,
+                                        dir: dir
+                                }, function (err, inputs) {
+                                        if (err) {
+                                                LOG.fatal({
+                                                        err: err,
+                                                        dir: dir
+                                                }, 'error listing input files');
+
+                                                cb(err);
+                                        } else {
+                                                instrFiles = inputs;
+
+                                                LOG.info({
+                                                        instrFiles: inputs
+                                                }, 'instruction files fetched');
+                                                cb();
+                                        }
+                                });
+                        },
+
+                        /*
+                         * Fetch each cleanup file as a Readable stream.
+                         */
+                        function getStreams(_, cb) {
+                                getInputStreams({
+                                        mantaClient: MANTA_CLIENT,
+                                        log: LOG,
+                                        inputs: instrFiles
+                                }, function (err, sObjs) {
+                                        /*
+                                         * On error, only stop the pipeline if
+                                         * we don't get any valid streams to use
+                                         * for cleanup.
+                                         */
+                                        if (err && sObjs &&
+                                                sObjs.length === 0) {
+
+                                                LOG.fatal({
+                                                        err: err,
+                                                        instrFiles: instrFiles
+                                                }, 'could not fetch any ' +
+                                                        'input files');
+
+                                                cb(err);
+                                        } else {
+                                                toCleanup = sObjs;
+
+                                                var cFiles = [];
+                                                toCleanup.forEach(function (s) {
+                                                        cFiles.push(s.file);
+                                                });
+                                                LOG.info({
+                                                        instrFiles: cFiles
+                                                }, 'fetched instructions ' +
+                                                        'from Manta');
+
+                                                cb();
+                                        }
+                                });
+                        },
+
+                        /*
+                         * Start an instance of an MPU GC cleanup pipeline for
+                         * each stream of instructions we have.
+                         */
+                        function executeCleanupInstructions(_, cb) {
+                                runCleanupInstructions({
+                                        toCleanup: toCleanup,
+                                        mantaClient: MANTA_CLIENT,
+                                        mahiClient: MAHI_CLIENT,
+                                        log: LOG,
+                                        concurrency: userOpts.concurrency,
+                                        dryRun: userOpts.dryRun,
+                                        verbose: userOpts.verbose
+                                }, function (c) {
+                                        completed = c;
+                                        LOG.info({
+                                                completed: completed
+                                        }, 'completed MPU GC ' +
+                                            'cleanup instructions');
+                                        cb();
+                                });
+                        },
+
+                        /*
+                         * Finally, link the instruction files in the
+                         * "completed" directory of Manta to indicate they've
+                         * been processed, then unlink them from the input
+                         * directory.
+                         */
+                        function linkAndDelCompletedInstructions(_, cb) {
+                                // Skip this step for remote mode.
+                                if (userOpts.remoteFile) {
+                                        setImmediate(cb);
+                                        return;
+                                }
+
+                                linkAndDelCompleted({
+                                        mantaClient: MANTA_CLIENT,
+                                        log: LOG,
+                                        completed: completed,
+                                        completedDir: userOpts.completedDir,
+                                        dryRun: userOpts.dryRun,
+                                        verbose: userOpts.verbose
+                                }, function (err) {
+                                        if (err) {
+                                                LOG.fatal({
+                                                        err: err
+                                                }, 'could not cleanup ' +
+                                                        'all instruction ' +
+                                                        'files');
+                                                cb(err);
+                                        } else {
+                                                cb();
+                                        }
+                                });
+                        }
+                ]}, function (verr, results) {
+                        if (verr) {
+                                exitCode = 1;
+                                LOG.error(verr);
+                        }
+
+                        scriptFinish();
+        });
+} else {
+        /*
+         * Local file case. We only execute the cleanup instructions here; we do
+         * not upload any instruction files to Manta.
+         */
+        toCleanup = [];
+        instrFiles = [];
+        userOpts.file.forEach(function (f) {
+                instrFiles.push(f);
+                toCleanup.push({
+                        stream: fs.createReadStream(f),
+                        file: f
+                });
+        });
+
+        runCleanupInstructions({
+                toCleanup: toCleanup,
+                mantaClient: MANTA_CLIENT,
+                mahiClient: MAHI_CLIENT,
+                log: LOG,
+                concurrency: userOpts.concurrency,
+                dryRun: userOpts.dryRun,
+                verbose: userOpts.verbose
+        }, function (c) {
+                completed = c;
+                scriptFinish();
+        });
+}
diff --git a/bin/kick_off_mpu_gc.js b/bin/kick_off_mpu_gc.js
new file mode 100755
index 0000000..bb46f97
--- /dev/null
+++ b/bin/kick_off_mpu_gc.js
@@ -0,0 +1,371 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var fs = require('fs');
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var manta = require('manta');
+var path = require('path');
+
+/*
+ * Kicks off the MPU GC job, which pg-transforms the PG backups, sorts them, and
+ * determines which MPU-related records can be garbage collected.
+ *
+ * This script is analogous to bin/kick_off_gc.js for normal GC.
+ */
+
+///--- Global Objects
+
+var NAME = 'mola-mpu-gc';
+var LOG = bunyan.createLogger({
+        level: (process.env.LOG_LEVEL || 'info'),
+        name: NAME,
+        stream: process.stdout
+});
+var MOLA_CONFIG = (process.env.MOLA_CONFIG ||
+                   '/opt/smartdc/mola/etc/config.json');
+var MOLA_CONFIG_OBJ = JSON.parse(fs.readFileSync(MOLA_CONFIG));
+var MANTA_CLIENT = manta.createClientFromFileSync(MOLA_CONFIG, LOG);
+var MANTA_USER = MANTA_CLIENT.user;
+
+
+///--- Global Constants
+
+var MP = '/' + MANTA_USER + '/stor';
+var MANTA_DUMP_NAME_PREFIX = 'manta-';
+var MANTA_UPLOADS_NAME_PREFIX = 'manta_uploads-';
+
+
+///--- Helpers
+
+/*
+ * Helper that sets up necessary environment variables for the commands run as
+ * part of a phase in the MPU GC job.
+ *
+ * Inputs:
+ *  - opts: an options blob that must include:
+ *      - jobName: name of the job to pass to the job manager
+ *      - marlinPathToAsset: the relative path of a tarball that is unpacked as
+ *          an asset in the job
+ */
+function getEnvCommon(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.jobName, 'opts.jobName');
+        assert.string(opts.marlinPathToAsset, 'opts.marlinPathToAsset');
+
+/* BEGIN JSSTYLED */
+        return (' \
+set -o pipefail && \
+export MANTA_USER=' + MANTA_USER + ' && \
+export MANTA_MPU_GC=' + opts.jobName + ' && \
+export MARLIN_JOB=$(echo $MANTA_OUTPUT_BASE | cut -d "/" -f 4) && \
+export NOW=$(date "+%Y-%m-%d-%H-%M-%S") && \
+cd /assets/ && gtar -xzf ' + opts.marlinPathToAsset + ' && cd mola && \
+');
+/* END JSSTYLED */
+}
+
+
+/*
+ * Returns the command that is run during the map phase of the MPU GC job.
+ * This command calls into bin/mpu_gc_pg_transform.js, which transforms
+ * input from the dump into tab-separated records that can be processed
+ * by the reduce phase of the job.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - earliestDumpDate: the earliest dump date to use
+ *      - numberReducers: number of reducers to assign to the job
+ *      - objectId: optional objectId
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuPgTransformCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.string(opts.earliestDumpDate, 'opts.earliestDumpDate');
+        assert.number(opts.numberReducers, 'opts.numberReducers');
+
+/* BEGIN JSSTYLED */
+        var grepForObject = '';
+        if (opts.objectId) {
+                grepForObject = ' | grep ' + opts.objectId + ' | ';
+        }
+        return (getEnvCommon(opts) + ' \
+export MORAY_SHARD=$(echo $mc_input_key | cut -d "/" -f 5) && \
+export DUMP_DATE=$(basename $mc_input_key | sed \'s/^\\w*-//; s/.\\w*$//;\') && \
+gzcat -f | \
+  ./build/node/bin/node ./bin/mpu_gc_pg_transform.js -d $DUMP_DATE \
+    -e ' + opts.earliestDumpDate + ' \
+    -m $MORAY_SHARD' + grepForObject + ' | \
+  msplit -n ' + opts.numberReducers + ' \
+');
+/* END JSSTYLED */
+}
+
+
+/*
+ * Returns the command that is run during the reduce phase of the MPU GC job.
+ * This phase calls into bin/mpu_gc.js, which is a thin wrapper that calls into
+ * lib/mpu_garbage_collector.js, which performs the actual logic of deciding
+ * what mako and moray actions need to be taken.
+ *
+ * Inputs:
+ *  - opts: an options blob with the following values:
+ *      - gracePeriodSeconds: optional grace period for MPU
+ *      - jobName: required for getEnvCommon
+ *      - marlinPathToAsset: required for getEnvCommon
+ */
+function getMpuGcCmd(opts) {
+        assert.object(opts, 'opts');
+        assert.optionalNumber(opts.gracePeriodSeconds,
+            'opts.gracePeriodSeconds');
+
+        var gracePeriodOption = '';
+        if (opts.gracePeriodSeconds) {
+                gracePeriodOption = ' -g ' + opts.gracePeriodSeconds;
+        }
+        /*
+         * As the normal GC job does, we use a UUID only because there's no way
+         * (yet) to get a reference to which reducer this is running on.
+         */
+/* BEGIN JSSTYLED */
+        return (getEnvCommon(opts) + ' \
+export UUID=$(uuid) && \
+export MANTA_PRE=/$MANTA_USER/stor/$MANTA_MPU_GC && \
+export MANTA_MPU_GC_CLEANUP_FILE=$MANTA_PRE/cleanup/$NOW-$MARLIN_JOB-X-$UUID && \
+sort | \
+./build/node/bin/node ./bin/mpu_gc.js' + gracePeriodOption + ' | \
+mpipe $MANTA_MPU_GC_CLEANUP_FILE \
+');
+/* END JSSTYLED */
+}
+
+function parseOptions() {
+        var option;
+        /*
+         * First take what's in the config file, override what's on the
+         * command line, and use the defaults if all else fails.
+         */
+        var opts = MOLA_CONFIG_OBJ;
+        opts.shards = opts.shards || [];
+        var parser = new getopt.BasicParser('a:bd:g:s:m:no:p:r:t',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'a':
+                        opts.assetFile = option.optarg;
+                        break;
+                case 'b':
+                        opts.mapPhaseOnly = true;
+                        break;
+                case 'd':
+                        opts.gcReduceDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                case 's':
+                        opts.maxHoursInPast = parseInt(option.optarg, 10);
+                        break;
+                case 'm':
+                        opts.shards.push(option.optarg);
+                        break;
+                case 'n':
+                        opts.noJobStart = true;
+                        break;
+                case 'o':
+                        opts.objectId = option.optarg;
+                        break;
+                case 'p':
+                        opts.gcMapDisk = parseInt(option.optarg, 10);
+                        break;
+                case 'r':
+                        opts.gcReduceMemory = parseInt(option.optarg, 10);
+                        break;
+                case 't':
+                        opts.jobName = 'manta_mpu_gc_test';
+                        opts.jobRoot = MP + '/manta_mpu_gc_test';
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+
+        opts.jobName = opts.jobName || 'manta_mpu_gc';
+        opts.jobRoot = opts.jobRoot || MP + '/manta_mpu_gc';
+
+        opts.assetDir = opts.jobRoot + '/assets';
+        opts.assetObject = opts.assetDir + '/mola.tar.gz';
+        opts.assetFile = opts.assetFile ||
+                '/opt/smartdc/common/bundle/mola.tar.gz';
+
+        opts.gcMapDisk = opts.gcMapDisk || 32;
+        opts.gcReduceMemory = opts.gcReduceMemory || 8192;
+        opts.gcReduceDisk = opts.gcReduceDisk || 32;
+        opts.marlinPathToAsset = opts.assetObject.substring(1);
+        opts.marlinAssetObject = opts.assetObject;
+
+        opts.directories = [
+                opts.jobRoot + '/cleanup',
+                opts.jobRoot + '/completed'
+        ];
+
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-a asset_file]';
+        str += ' [-g grace_period_seconds]';
+        str += ' [-m moray_shard]';
+        str += ' [-n no_job_start]';
+        str += ' [-o object_id]';
+        str += ' [-r marlin_reducer_memory]';
+        str += ' [-t output_to_test]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+/*
+ * Returns a job definition for the MPU GC job that can be passed to the
+ * job manager.
+ *
+ * Inputs:
+ *  - opts: options blob passed to helpers creating phases of the job (see
+ *          those functions for documentation)
+ *  - cb: callback of the form cb(err, job)
+ */
+function getMpuGcJob(opts, cb) {
+        /*
+         * As with the regular GC job, use the number of shards + 1 reducers so
+         * that we are always using multiple reducers.
+         */
+        opts.numberReducers = opts.shards.length + 1;
+
+        var mpuPgCmd = getMpuPgTransformCmd(opts);
+        var mpuGcCmd = getMpuGcCmd(opts);
+
+        var phases = [
+                {
+                        type: 'storage-map',
+                        exec: mpuPgCmd,
+                        disk: opts.gcMapDisk
+                }
+        ];
+
+        if (!opts.mapPhaseOnly) {
+                phases.push({
+                        type: 'reduce',
+                        count: opts.numberReducers,
+                        memory: opts.gcReduceMemory,
+                        disk: opts.gcReduceDisk,
+                        exec: mpuGcCmd
+                });
+        }
+
+        var job = {
+                phases: phases
+        };
+
+        LOG.info({
+                job: job
+        }, 'MPU GC Marlin Job Definition');
+
+        cb(null, job);
+}
+
+
+// Expects the filename to be in the format:
+//      /.../manta-2012-11-30-23-00-07.gz
+//
+// Returns: 2012-11-30-23-00-07
+function extractDate(p) {
+        var filename = path.basename(p);
+        var d = filename.substring(filename.indexOf('-') + 1);
+        d = d.substring(0, d.indexOf('.'));
+        return (d);
+}
+
+
+/*
+ * Determines what input objects to pass to the MPU GC job.
+ *
+ * Inputs:
+ *  - opts: an options block passed directly to common.findObjectsForShards
+ *  - cb: callback of the form cb(err, objects)
+ */
+function findMpuGcObjects(opts, cb) {
+        LOG.info({ opts: opts }, 'Finding MPU Gc Objects.');
+        var shards = opts.shards;
+
+        if (shards.length === 0) {
+                cb(new Error('No shards specified.'));
+                return;
+        }
+
+        lib.common.findObjectsForShards({
+                'log': LOG,
+                'shards': shards,
+                'client': MANTA_CLIENT,
+                'tablePrefixes': [
+                        MANTA_DUMP_NAME_PREFIX,
+                        MANTA_UPLOADS_NAME_PREFIX
+                ],
+                'maxHoursInPast': opts.maxHoursInPast
+        }, function (err, results) {
+                if (err) {
+                        cb(err);
+                        return;
+                }
+
+                var objects = [];
+                var dates = [];
+
+                for (var j = 0; j < results.length; ++j) {
+                        var obj = results[j];
+                        objects.push(obj);
+                        // Get the date from the filename.
+                        dates.push(extractDate(obj));
+                }
+
+                dates.sort();
+                LOG.info({
+                        dates: dates,
+                        objects: objects
+                }, 'found mpu gc objects');
+                opts.earliestDumpDate = dates[0];
+                cb(null, objects);
+        });
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+
+_opts.getJobDefinition = getMpuGcJob;
+_opts.getJobObjects = findMpuGcObjects;
+
+var jobManager = lib.createJobManager(_opts, MANTA_CLIENT, LOG);
+jobManager.run(function () {
+        MANTA_CLIENT.close();
+        LOG.info('Done for now.');
+});
diff --git a/bin/mdemux.js b/bin/mdemux.js
index 311947d..d0d8e33 100755
--- a/bin/mdemux.js
+++ b/bin/mdemux.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var assert = require('assert-plus');
@@ -21,8 +21,11 @@ var util = require('util');
 var vasync = require('vasync');
 
 
-
-/**
+/*
+ *
+ * TODO clean this example up: the -f flag isn't real, and mpipe does not do
+ * `mpipe -p`, which this example kind of implies
+ *
  * Bucketize by fields in a line, uploading to manta via mpipe.  For example,
  * this will bucketize quotes into last/first name files, given a stream
  * of records with lines like:
@@ -31,6 +34,7 @@ var vasync = require('vasync');
  *    -p /$MANTA_USER/stor/quotes/{2}/{1}/quotes.txt
  *
  * The -p is required.  -f defaults to 1, -d defaults to (tab).
+ *
  */
 
 
@@ -311,6 +315,7 @@ DemuxFileStream.prototype._write = function dfsWrite(line, _, done) {
 };
 
 
+///--- Main
 
 var _opts = parseOptions();
 
diff --git a/bin/mpu_gc.js b/bin/mpu_gc.js
new file mode 100755
index 0000000..49d7a89
--- /dev/null
+++ b/bin/mpu_gc.js
@@ -0,0 +1,83 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var bunyan = require('bunyan');
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+
+
+///--- Globals
+
+var LOG = bunyan.createLogger({
+        level: (process.env.LOG_LEVEL || 'info'),
+        name: 'mpu_gc',
+        stream: process.stderr,
+        serializers: bunyan.stdSerializers
+});
+
+
+///--- Helpers
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('g:', process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'g':
+                        opts.gracePeriodSeconds = parseInt(option.optarg, 10);
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-g grace_period_seconds]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+_opts.log = LOG.child({
+        component: 'MpuGarbageCollector'
+});
+
+// As a convenience seconds to millis
+if (_opts.gracePeriodSeconds) {
+        _opts.gracePeriodMillis = _opts.gracePeriodSeconds * 1000;
+}
+
+var _garbageCollector = lib.createMpuGarbageCollector(_opts);
+_garbageCollector.on('mpuCleanup', function (record) {
+        console.log(record.toString());
+});
+
+_garbageCollector.on('error', function (err) {
+        console.error({ err: err }, 'Error with line, exiting.');
+        process.exit(1);
+});
+
+process.stdin.resume();
diff --git a/bin/mpu_gc_pg_transform.js b/bin/mpu_gc_pg_transform.js
new file mode 100755
index 0000000..cc03ae3
--- /dev/null
+++ b/bin/mpu_gc_pg_transform.js
@@ -0,0 +1,107 @@
+#!/usr/bin/env node
+// -*- mode: js -*-
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var getopt = require('posix-getopt');
+var lib = require('../lib');
+var path = require('path');
+var util = require('util');
+
+/*
+ * Transforms the unpacked dump into records using the format specified by
+ * lib/mpu_gc_pg_row_transformer.js.
+ *
+ * This is analogous to bin/gc_pg_transform.js and lib/gc_pg_row_transformer.js
+ * for normal GC.
+ */
+
+///--- Helpers
+
+function isValidDate(date) {
+        return (util.isDate(date) && !isNaN(date.getTime()));
+}
+
+function parseDate(dateString) {
+        // So we're forcing a weird format here.  File dates come in the format
+        // 2012-10-18-23-00-02.
+        var parts = dateString.split('-');
+        if (parts.length != 6) {
+                usage('Invalid date: ' + dateString);
+        }
+        var ds = parts[0] + '-' + parts[1] + '-' + parts[2] + 'T' +
+                parts[3] + ':' + parts[4] + ':' + parts[5] + 'Z';
+        var date = new Date(ds);
+        if (isValidDate(date)) {
+                return (date);
+        }
+        // We'll let the caller catch this.
+        return (dateString);
+}
+
+
+function parseOptions() {
+        var option;
+        var opts = {};
+        var parser = new getopt.BasicParser('d:e:m:',
+                                            process.argv);
+        while ((option = parser.getopt()) !== undefined && !option.error) {
+                switch (option.option) {
+                case 'd':
+                        opts.dumpDate = parseDate(option.optarg);
+                        break;
+                case 'e':
+                        opts.earliestDumpDate = parseDate(option.optarg);
+                        break;
+                case 'm':
+                        opts.morayHostname = option.optarg;
+                        break;
+                default:
+                        usage('Unknown option: ' + option.option);
+                        break;
+                }
+        }
+
+        if (!opts.dumpDate) {
+                usage('-d [dump_date] is a required argument');
+        }
+        if (!opts.earliestDumpDate) {
+                usage('-e [earliest_dump_date] is a required argument');
+        }
+        if (!opts.morayHostname) {
+                usage('-m [moray_hostname] is a required argument');
+        }
+        return (opts);
+}
+
+
+function usage(msg) {
+        if (msg) {
+                console.error(msg);
+        }
+        var str  = 'usage: ' + path.basename(process.argv[1]);
+        str += ' [-d dump_date] [-e earliest_dump_time] [-m moray_hostname]';
+        console.error(str);
+        process.exit(1);
+}
+
+
+
+///--- Main
+
+var _opts = parseOptions();
+_opts.reader = process.stdin;
+
+var _gcPgRowTransformer = lib.createMpuGcPgRowTransformer(_opts);
+_gcPgRowTransformer.on('row', function (row) {
+        console.log(row.toString());
+});
+
+process.stdin.resume();
diff --git a/boot/setup.sh b/boot/setup.sh
index 00b1181..773698a 100755
--- a/boot/setup.sh
+++ b/boot/setup.sh
@@ -7,7 +7,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2018, Joyent, Inc.
 #
 
 set -o xtrace
@@ -52,9 +52,12 @@ function manta_setup_mola {
     mkdir -p /opt/smartdc/common/bundle
     cd /opt/smartdc && tar -chzf /opt/smartdc/common/bundle/mola.tar.gz mola; cd -
     echo '0 2 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_pg_transform.js >>/var/log/mola-pg-transform.log 2>&1' >>$crontab
+
     echo '5 8 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_gc.js >>/var/log/mola.log 2>&1' >>$crontab
+    echo '5 9 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_mpu_gc.js >>/var/log/mola-mpu-gc.log 2>&1' >>$crontab
     echo '10 11 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/gc_create_links.js >>/var/log/mola-gc-create-links.log 2>&1' >>$crontab
     echo '15 12 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/moray_gc.js >>/var/log/mola-moray-gc.log 2>&1' >>$crontab
+    echo '15 13 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_mpu_cleanup.js >>/var/log/mola-mpu-cleanup.log 2>&1' >>$crontab
     echo '20 14 * * * cd /opt/smartdc/mola && ./build/node/bin/node ./bin/kick_off_audit.js >>/var/log/mola-audit.log 2>&1' >>$crontab
 
     #Metering
@@ -71,8 +74,10 @@ function manta_setup_mola {
 
     manta_add_logadm_entry "mola-pg-transform" "/var/log" "exact"
     manta_add_logadm_entry "mola" "/var/log" "exact"
+    manta_add_logadm_entry "mola-mpu-gc" "/var/log" "exact"
     manta_add_logadm_entry "mola-gc-create-links" "/var/log" "exact"
     manta_add_logadm_entry "mola-moray-gc" "/var/log" "exact"
+    manta_add_logadm_entry "mola-mpu-cleanup" "/var/log" "exact"
     manta_add_logadm_entry "mola-audit" "/var/log" "exact"
     manta_add_logadm_entry "mackerel" "/var/log" "exact"
 
diff --git a/docs/gc-overview.md b/docs/gc-overview.md
index 868a21b..327178c 100644
--- a/docs/gc-overview.md
+++ b/docs/gc-overview.md
@@ -10,7 +10,7 @@ apisections:
 -->
 
 <!--
-    Copyright (c) 2014, Joyent, Inc.
+    Copyright (c) 2018, Joyent, Inc.
 -->
 
 # Overview
@@ -170,7 +170,7 @@ A cron runs in the cron zone that will periodically look in:
     /poseidon/stor/manta_gc/all/do/
 
 Download, and execute the instructions.  Once the links are successfully created,
-the links file is deleted.  The executable is in `mola/bin/gc_create_links.sh`.
+the links file is deleted.  The executable is in `mola/bin/gc_create_links.js`.
 
 ## Phase 3: Moray Cleanup
 
diff --git a/docs/mpu-gc-overview.md b/docs/mpu-gc-overview.md
new file mode 100644
index 0000000..a39c5c7
--- /dev/null
+++ b/docs/mpu-gc-overview.md
@@ -0,0 +1,210 @@
+---
+title: Mola Multipart Upload GC Overview
+markdown2extras: tables, code-friendly
+apisections:
+---
+<!--
+    This Source Code Form is subject to the terms of the Mozilla Public
+    License, v. 2.0. If a copy of the MPL was not distributed with this
+    file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+    Copyright (c) 2018, Joyent, Inc.
+-->
+
+# Overview
+
+Using the multipart upload API, Manta users are able to upload objects in chunks
+called "parts", then commit or abort the upload. Committing the MPU exposes a
+new object in Manta, and aborting cancels it, which prevents the upload from
+later being committed.
+
+Parts are represented as objects in Manta, and they are stored in a directory
+referred to as the "upload directory" of an MPU. We also store an additional
+record in Moray on the same shard as the target object of the MPU. This record,
+called the "finalizing record", allows clients to query the status of
+an MPU after it has been finalized, for some amount of time before data
+associated with MPU state is cleaned up.
+
+For all finalized MPUs, we leave some garbage in the system that needs to be
+cleaned up. In particular, we need to remove:
+- part metadata records and their associated data on mako
+- upload directory records in Moray
+- finalizing records in the Moray `manta_uploads` bucket
+
+It is worth noting that these records do not necessarily exist on the same
+shard. As such, in order to determine that an MPU can be safely garbage
+collected, we need a more global view of the system than needed with normal GC.
+
+Finalizing records are removed directly from Moray. Parts and upload directories
+are removed using an operator-only query parameter through the front door of
+Manta. This allows us to do all of the normal verification associated with
+normal object and directory removal. This strategy does induce some additional
+latency for garbage collection of parts, as they will incur the grace period and
+tombstone period from normal GC.
+
+# MPU GC vs. Existing GC
+
+The MPU GC process was designed based on the current garbage collection
+implementation, deviating where it seems reasonable to.
+
+The first half of the process, as with normal GC, is a Manta job that operates
+on Moray shard database dumps. Many of the scripts for MPU GC are modeled
+directly from existing GC scripts and will look quite similar to them.
+
+The second half of the MPU GC process looks much different than normal GC. In
+normal GC, instructions for individual moray zones and mako zones are uploaded
+to Manta, and executed later for each zone. This approach is not tenable for MPU
+GC. Records for a given MPU can exist on more than one shard, and thus we need a
+more global view of the system in order to clean up records in a safe way.
+Instead, the MPU GC job produces one logical list of instructions, which
+represent a list of records to delete. These instructions are carried out by a
+"cleanup" script that deletes records in a safe order.
+
+# MPU GC Implementation Details
+
+## Input
+
+1. Moray shard dumps. Currently located at:
+
+    /poseidon/stor/manatee_backups/[shard]/[date]/[table]-[date].gz
+
+The two tables required for MPU garbage collection are:
+
+1. `manta`: Record of the set of 'live' objects, including part records and
+upload directories.
+2. `manta_uploads`: Record of finalized MPUs.
+
+## Phase 1: Marlin job
+
+The MPU garbage collection job is kicked off from the "ops" zone deployed as
+part of Manta. The cron invokes `mola/bin/kick_off_mpu_gc.js`, which does a few
+things:
+
+1. Verifies that an MPU GC job is not currently running
+2. Finds the latest Moray dumps and does some verification
+3. Sets up assets and directories required by MPU GC
+4. Kicks off a marlin job
+
+All output for the Marlin job is located under:
+
+    /poseidon/stor/manta_mpu_gc
+
+From a high-level, the Marlin job does the following:
+
+1. Transforms all MPU-related live records in the `manta` table and all rows in
+the `manta_uploads` table from the Moray dumps into objects representing each
+record. The representation of these records include the multipart upload ID,
+the date the record was produced, and the type of MPU record it is: a part
+record, an upload record, or a finalizing record. Finalizing records also
+contain their shard and the Moray key for the record; part and upload records
+contain the record's path in Manta.
+2. The records for each MPU are then sent to a number of reducers, where the
+reducer is guaranteed to have all records for a given MPU.
+3. Reducers sort the set of rows so that records for the same MPU are grouped
+together, then sorted in the order of: finalizing record, upload record, part
+records.  The reducer can iterate over these rows and determine whether records
+for a given MPU should be deleted: in particular, that it has a finalizing
+record and that the finalizing record was created before a system-wide grace
+period .
+
+The output of the Marlin job is a set of instructions lists that can be safely
+deleted by the cleanup script. These outputs are stored at:
+
+    /poseidon/stor/manta_mpu_gc/cleanup/[date]-[job_id]-X-[uuid]
+
+There is one output file per reducer in the job.
+
+## Phase 2: Cleanup
+
+This phase is responsible for the actual cleanup of the records that need to be
+garbage collected. The cron invokes `mola/bin/kick_off_mpu_cleanup.js`, which
+will look at the files in the cleanup directory that are output by the MPU GC
+job.
+
+For each file in the cleanup directory, the script will:
+
+1. Get a stream using the node-manta client that represents the contents of the
+file.
+2. Collect related MPU records together, which should be in the same sorted
+order as created in the MPU GC job, using `mola/lib/mpu/mpuBatchStream.js`.
+3. Double check that all records are present as expected, using
+`mola/lib/mpu/mpuVerifyStream.js`.
+4. Delete part records, if they exist, from the Manta front door for each MPU
+batch, using `mola/lib/mpu/mpuUnlinkLiveRecordStream.js`.
+5. Delete the upload record, if it exists, from the Manta front door for each
+MPU batch, using `mola/lib/mpu/mpuUnlinkLiveRecordStream.js`.
+6. Delete the finalizing record for each MPU using
+`mola/lib/mpu/mpuMorayCleanerStream.js`.
+7. To maintain the cleanup instructions for debugging purposes, link the cleanup
+file to:
+
+    /poseidon/stor/manta_mpu_gc/completed/[date]-[job_id]-X-[uuid]
+
+8. Delete the original cleanup file from Manta.
+
+If at any point in steps 2-6, an error occurs for a given MPU, the script will
+log an error and drop the MPU from the stream. This ensures no other records
+will be garbage collected for the MPU. (The cleanup script itself will continue
+trying to clean up other MPUs in the instructions stream, as they may not be
+affected by the same errors as other MPUs.)
+
+The order of record deletion is key here to ensure MPUs are cleaned up in a safe
+order: The finalizing record must be deleted last, as it is the definitive
+evidence that an MPU was deleted. Parts are entries in the upload directory, so
+they should be deleted prior to the upload directory. This means part records
+are deleted first, followed by the upload directory, followed by the finalizing
+record.
+
+If an MPU could not be fully cleaned up by the cleanup script due to a transient
+error, at the least, the finalizing record is preserved, and the MPU will be
+listed in the instructions produced by the next run of the MPU GC job.
+
+# Running a GC manually
+
+For testing purposes, or if a job fails, it is often useful to be able to run
+the MPU GC job manually.
+
+## Kick of the Marlin job from the ops zone
+
+The first stage is to kick off the MPU GC job.
+
+```
+ops$ /opt/smartdc/mola/bin/kick_off_mpu_gc.js | bunyan
+```
+
+This will use the defaults for the environment.  Note that
+kicking off a GC job requires db dumps to be recent -- by default, within the
+past 24 hours.  Please refer to the
+[System Crons](system-crons.md) for the timeline.
+
+If you just want to check on the last job run:
+
+```
+ops$ mjob get $(mget -q /poseidon/stor/manta_mpu_gc/jobs.json | json -ak | tail -1)
+```
+
+This stage produces as many files as there are reducers for the job that are
+stored under:
+
+`/poseidon/stor/manta_mpu_gc/cleanup`
+
+## Run the cleanup script
+
+From the ops zone, kick off the cleanup pipeline:
+
+```
+ops$ /opt/smartdc/mola/bin/kick_off_mpu_gc_cleanup.js | bunyan
+```
+
+As this script runs, it will delete files from the cleanup directory and will
+link its completed input to:
+
+    /poseidon/stor/manta_mpu_gc/completed/[date]-[job_id]-X-[uuid]
+
+
+# See Also
+
+* [RFD 65](https://github.com/joyent/rfd/tree/master/rfd/0065): Multipart
+Uploads for Manta.
diff --git a/docs/system-crons.md b/docs/system-crons.md
index 2b33f60..978652e 100644
--- a/docs/system-crons.md
+++ b/docs/system-crons.md
@@ -10,7 +10,7 @@ apisections:
 -->
 
 <!--
-    Copyright (c) 2014, Joyent, Inc.
+    Copyright (c) 2018, Joyent, Inc.
 -->
 
 # Overview
@@ -38,6 +38,9 @@ Here is a json representation of the dependency tree:
                     "moray-gc": null,
                     "mako-gc": null
                 }
+            },
+            "mpu-gc": {
+                "mpu-cleanup": null
             }
         }
     }
@@ -64,6 +67,10 @@ And a description of each of those:
 * mako-gc: Runs on each Mako, takes output from gc/gc-create-links to find and
   tombstone dead objects.  Also removes object tombstoned some number of days
   ago (21 days as of this writing).
+* mpu-gc: Runs as a Manta job. Takes output from sql-to-json to determine what
+  records need to be garbage collected as a result of multipart uploads.
+* mpu-cleanup: Runs from the ops zone. Executes the instructions provided by the
+  output of mpu-gc to clean up records related to multipart uploads.
 
 NOTE: There are three additional jobs scheduled in cron that don't aren't
 listed here. They are hourly compute metering, hourly request metering and a
@@ -99,6 +106,9 @@ the [cron configuration][cron] and the [manifest file][manifest].
 |                                                      |gc-l|inks
 |                                                           |moray-gc
 |                                                           |mako-gc
+|
+|                                             |mpu-gc            |
+|                                                                |mpu-cleanup
 |    |(daily-metering)
 |----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
 | 00 | 01 | 02 | 03 | 04 | 05 | 06 | 07 | 08 | 09 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 |
@@ -109,9 +119,11 @@ the [cron configuration][cron] and the [manifest file][manifest].
 | postgres                | (in manatee zone)        | maintenance |      00:00 |
 | sql-to-json             | kick_off_pg_transform.js | meta        |      02:00 |
 | gc                      | kick_off_gc.js           | maintenance |      08:05 |
+| mpu-gc                  | kick_off_mpu_gc.js       | maintenance |      09:05 |
 | storage-hourly-metering | meter-storage.sh         | metering    |      08:15 |
 | gc-links                | gc_create_links.js       | maintenance |      11:10 |
 | moray-gc                | moray_gc.js              | maintenance |      12:15 |
+| mpu-cleanup             | kick_off_mpu_cleanup.js  | maintenance |      13:15 |
 | audit                   | kick_off_audit.js        | maintenance |      14:20 |
 | [none]                  | daily.sh                 | metering    |      14:55 |
 | (daily-metering)        | meter-previous-day.sh    | metering    |      01:00 |
diff --git a/lib/common.js b/lib/common.js
index c9d178b..d634932 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var assert = require('assert-plus');
@@ -318,7 +318,8 @@ function findObjectsForShards(opts, cb) {
                                 'shard': s,
                                 'client': opts.client,
                                 'tablePrefixes': opts.tablePrefixes,
-                                'timestamp': opts.timestamp
+                                'timestamp': opts.timestamp,
+                                'maxHoursInPast': opts.maxHoursInPast
                         });
                 })
         }, function (err, results) {
diff --git a/lib/index.js b/lib/index.js
index 4e2dc34..9ebb24c 100644
--- a/lib/index.js
+++ b/lib/index.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var assert = require('assert-plus');
@@ -17,6 +17,8 @@ var CruftCollector = require('./cruft_collector');
 var CruftRowTransformer = require('./cruft_row_transformer');
 var GarbageCollector = require('./garbage_collector');
 var GcPgRowTransformer = require('./gc_pg_row_transformer');
+var MpuGarbageCollector = require('./mpu_garbage_collector');
+var MpuGcPgRowTransformer = require('./mpu_gc_pg_row_transformer');
 var JobManager = require('./job_manager');
 var MorayCleaner = require('./moray_cleaner');
 var Rebalancer = require('./rebalancer');
@@ -86,6 +88,17 @@ function createGarbageCollector(opts, listener) {
 }
 
 
+function createMpuGarbageCollector(opts, listener) {
+        assert.object(opts.reader);
+        if (opts.gracePeriodMillis) {
+                assert.number(opts.gracePeriodMillis);
+        }
+
+        var mpuGarbageCollector = new MpuGarbageCollector(opts, listener);
+        return (mpuGarbageCollector);
+}
+
+
 function createJobManager(opts, mantaClient, log) {
         assert.object(opts);
         assert.object(mantaClient);
@@ -117,6 +130,20 @@ function createGcPgRowTransformer(opts, listener) {
 }
 
 
+function createMpuGcPgRowTransformer(opts, listener) {
+        assert.object(opts, 'opts missing');
+        assert.object(opts.reader, 'opts.reader missing');
+        assert.ok(util.isDate(opts.dumpDate),
+                  'opts.dumpDate isnt Date');
+        assert.ok(util.isDate(opts.earliestDumpDate),
+                  'opts.earliestDumpDate isnt Date');
+        assert.string(opts.morayHostname, 'Moray hostname missing');
+
+        var mpuGcPgRowTransformer = new MpuGcPgRowTransformer(opts, listener);
+        return (mpuGcPgRowTransformer);
+}
+
+
 function createRebalancer(opts, listener) {
         assert.object(opts, 'opts missing');
         assert.object(opts.reader, 'opts.reader missing');
@@ -147,9 +174,11 @@ module.exports = {
         createCruftCollector: createCruftCollector,
         createCruftRowTransformer: createCruftRowTransformer,
         createGarbageCollector: createGarbageCollector,
+        createMpuGarbageCollector: createMpuGarbageCollector,
         createGcPgRowTransformer: createGcPgRowTransformer,
         createJobManager: createJobManager,
         createMorayCleaner: createMorayCleaner,
+        createMpuGcPgRowTransformer: createMpuGcPgRowTransformer,
         createRebalancer: createRebalancer,
         createSchemaReader: createSchemaReader
 };
diff --git a/lib/moray_cleaner.js b/lib/moray_cleaner.js
index ec5a981..6db76c4 100644
--- a/lib/moray_cleaner.js
+++ b/lib/moray_cleaner.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var assert = require('assert-plus');
@@ -23,7 +23,9 @@ var BatchStream = require('./batch_stream').BatchStream;
 
 ///--- Globals
 
-var MORAY_BUCKET = 'manta_delete_log';
+var MANTA_DELETE_BUCKET = 'manta_delete_log';
+var MANTA_FINALIZING_BUCKET = 'manta_uploads';
+
 var MORAY_CONNECT_TIMEOUT = 10000;
 var MORAY_PORT = 2020;
 
@@ -62,6 +64,7 @@ function deleteFromMoray(opts, cb) {
         var self = opts.self;
         var lines = opts.lines;
         var expectedShard = opts.expectedShard;
+        var bucket = opts.bucket;
         var client = opts.client;
         var ms = 'moray';
 
@@ -114,7 +117,7 @@ function deleteFromMoray(opts, cb) {
         filter += ')';
 
         var startDate = new Date();
-        client.deleteMany(MORAY_BUCKET, filter, function (err) {
+        client.deleteMany(bucket, filter, function (err) {
                 var endDate = new Date();
                 var latency = endDate.getTime() - startDate.getTime();
 
@@ -205,9 +208,13 @@ function MorayCleanerStream(opts) {
         assert.object(opts, 'opts');
         assert.object(opts.log, 'opts.log');
         assert.string(opts.shard, 'opts.shard');
+        assert.string(opts.bucket, 'opts.bucket');
         assert.string(opts.object, 'opts.object');
         assert.object(opts.parent, 'opts.parent');
 
+        assert.ok((opts.bucket === MANTA_DELETE_BUCKET) ||
+                  (opts.bucket === MANTA_FINALIZING_BUCKET));
+
         stream.Writable.call(this, {
                 objectMode: true,
                 highWaterMark: 0
@@ -215,6 +222,7 @@ function MorayCleanerStream(opts) {
 
         self.mcs_log = opts.log;
         self.mcs_shard = opts.shard;
+        self.mcs_bucket = opts.bucket;
         self.mcs_object = opts.object;
         self.mcs_parent = opts.parent;
         self.mcs_client = null;
@@ -278,6 +286,7 @@ MorayCleanerStream.prototype.mcsCommit = function mcsCommit(batch, done) {
                 self: self.mcs_parent,
                 lines: batch.entries,
                 expectedShard: self.mcs_shard,
+                bucket: self.mcs_bucket,
                 client: self.mcs_client
         }, function (err) {
                 if (err) {
@@ -317,6 +326,7 @@ MorayCleaner.prototype.cleanStream = function cleanStream(opts) {
 
         var cleaner = new MorayCleanerStream({
                 shard: opts.shard,
+                bucket: opts.bucket,
                 object: opts.object,
                 parent: self,
                 log: log
diff --git a/lib/mpu/common.js b/lib/mpu/common.js
new file mode 100644
index 0000000..f4e980c
--- /dev/null
+++ b/lib/mpu/common.js
@@ -0,0 +1,228 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var util = require('util');
+
+
+///--- Globals
+
+var sprintf = util.format;
+
+var MPU_MORAY_BUCKET = 'manta_uploads';
+
+/*
+ * Internal constants used to differentiate between parts and upload records, as
+ * they are often used in the same context.
+ */
+var MPU_PART = 'partRecord';
+var MPU_UPLOADDIR = 'uploadRecord';
+
+/*
+ * MPU object values used by the record transformation step of the GC job
+ * (bin/mpu_gc_pg_transform.js). They are prepended with a numeral to ensure
+ * they sort in a given order: namely, that the finalizing record will be listed
+ * first in a sorted list.
+ */
+var MPUOBJ_PART = '2_partRecord';
+var MPUOBJ_UPLOADDIR = '1_uploadRecord';
+var MPUOBJ_FINALIZINGRECORD = '0_finalizingRecord';
+
+/*
+ * Types of finalizing records. The type doesn't make a difference with regard
+ * to garbage collection, but it is good to have these recorded in the state of
+ * MPUs for debugging purposes.
+ */
+var MPU_FR_TYPE_COMMIT = 'commit';
+var MPU_FR_TYPE_ABORT = 'abort';
+
+
+/*
+ * Given a string in a known format (namely, the same one produced by the
+ * toString method on a FinalizingRecord or LiveRecord object), returns a
+ * FinalizingRecord or LiveRecord object with the fields from the string.
+ *
+ * This function expects the string to match the specified format and will fail
+ * assertions if it does not. The responsibility is on the caller to ensure that
+ * the string is the correct format.
+ *
+ * In particular, the format for a finalizing record is a tab-separated list of
+ * the following fields:
+ *      [upload id]
+ *      0_finalizingRecord
+ *      [DATE]
+ *      [SHARD]
+ *      {commit,abort}
+ *      [manta_uploads KEY]
+ *
+ * In particular, the format for a live record is a tab-separated list of the
+ * following fields:
+ *      [upload id]
+ *      {1_uploadRecord, 2_partRecord}
+ *      [DATE]
+ *      [manta KEY]
+ */
+function recordToObject(record) {
+        assert.string(record);
+
+        var split = record.split('\t');
+        assert.ok(split.length >= 4, sprintf('record must contain at least 4 ' +
+                'tab-separated fields: \"%s\"', record));
+
+        var uploadId = split[0];
+        var mpuObject = split[1];
+        var date = new Date(split[2]);
+        var key;
+
+        assert.object(date, sprintf('unable to parse date: %s', split[2]));
+        assert.ok(date instanceof Date, 'invalid date');
+        assert.ok(mpuObject === MPUOBJ_PART ||
+                mpuObject === MPUOBJ_UPLOADDIR ||
+                mpuObject === MPUOBJ_FINALIZINGRECORD,
+                sprintf('invalid mpu object type: \"%s\"', mpuObject));
+
+        if (mpuObject === MPUOBJ_FINALIZINGRECORD) {
+                assert.ok(split.length === 6, sprintf('finalizing record ' +
+                        'must contain 6 tab-separated fields: \"%s\"', record));
+
+                var shard = split[3];
+                var finalizingType = split[4];
+                key = split[5];
+
+                assert.ok(finalizingType === MPU_FR_TYPE_COMMIT ||
+                          finalizingType === MPU_FR_TYPE_ABORT,
+                          sprintf('invalid finalizing type: %s',
+                                finalizingType));
+
+                return new FinalizingRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        shard: shard,
+                        date: date,
+                        type: finalizingType
+                });
+        } else {
+                assert.ok(split.length === 4, 'upload/part records must ' +
+                        'contain 4 tab-separated fields');
+
+                key = split[3];
+
+                var mulrsType;
+                if (mpuObject === MPUOBJ_UPLOADDIR) {
+                        mulrsType = MPU_UPLOADDIR;
+                } else {
+                        mulrsType = MPU_PART;
+                }
+
+                return new LiveRecord({
+                        uploadId: uploadId,
+                        key: key,
+                        type: mulrsType,
+                        date: date
+
+                });
+        }
+}
+
+/*
+ * Represents a finalizing record in the streams that process the metadata
+ * record cleanup.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": the Moray key for this record
+ *   - "shard": Moray shard of the record
+ *   - "date": date on the Moray record
+ *   - "type": finalizing type of the MPU
+ */
+function FinalizingRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.string(opts.shard, 'opts.shard');
+        assert.object(opts.date, 'opts.date');
+        assert.ok(opts.date instanceof Date, 'invalid date');
+        assert.string(opts.type, 'opts.type');
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.shard = opts.shard;
+        this.date = opts.date;
+        this.type = opts.type;
+}
+
+FinalizingRecord.prototype.toString = function frToString() {
+        return (this.uploadId + '\t' +
+                MPUOBJ_FINALIZINGRECORD + '\t' +
+                this.date.toISOString() + '\t' +
+                this.shard + '\t' +
+                this.type + '\t' +
+                this.key);
+};
+
+/*
+ * Represents a "live" Manta record in the streams that process the metadata
+ * record cleanup. In particular, a live record is either the part record or
+ * upload record of a given MPU.
+ *
+ * Parameters:
+ * - opts: an object with the following required properties:
+ *   - "uploadId": the MPU upload ID
+ *   - "key": key to record in Moray
+ *   - "date": date on the Moray record
+ *   - "type": either "uploadRecord" or "partRecord"
+ *
+ */
+function LiveRecord(opts) {
+        assert.string(opts.uploadId, 'opts.uploadId');
+        assert.string(opts.key, 'opts.key');
+        assert.object(opts.date, 'opts.date');
+        assert.ok(opts.date instanceof Date, 'invalid date');
+        assert.string(opts.type, 'opts.type');
+        assert.ok(opts.type === MPU_PART ||
+                  opts.type === MPU_UPLOADDIR,
+                  sprintf('invalid type: %s', opts.type));
+
+        this.uploadId = opts.uploadId;
+        this.key = opts.key;
+        this.date = opts.date;
+        this.type = opts.type;
+}
+
+LiveRecord.prototype.toString = function lrToString() {
+        var mpuObj;
+        if (this.type === MPU_PART) {
+                mpuObj = MPUOBJ_PART;
+        } else {
+                mpuObj = MPUOBJ_UPLOADDIR;
+        }
+
+        return (this.uploadId + '\t' +
+                mpuObj + '\t' +
+                this.date.toISOString() + '\t' +
+                this.key);
+};
+
+
+
+module.exports = {
+        recordToObject: recordToObject,
+        LiveRecord: LiveRecord,
+        FinalizingRecord: FinalizingRecord,
+
+        MPU_PART: MPU_PART,
+        MPU_UPLOADDIR: MPU_UPLOADDIR,
+
+        MPUOBJ_PART: MPUOBJ_PART,
+        MPUOBJ_UPLOADDIR: MPUOBJ_UPLOADDIR,
+        MPUOBJ_FINALIZINGRECORD: MPUOBJ_FINALIZINGRECORD,
+
+        MPU_MORAY_BUCKET: MPU_MORAY_BUCKET
+};
diff --git a/lib/mpu/index.js b/lib/mpu/index.js
new file mode 100644
index 0000000..61e9cce
--- /dev/null
+++ b/lib/mpu/index.js
@@ -0,0 +1,38 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var MpuBatchStream = require('./mpuBatchStream');
+var MpuVerifyStream = require('./mpuVerifyStream');
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MpuUnlinkLiveRecordStream = mulrs.MpuUnlinkLiveRecordStream;
+var MpuMorayCleanerStream = require('./mpuMorayCleanerStream');
+
+function createMpuBatchStream(opts) {
+        return (new MpuBatchStream(opts));
+}
+
+function createMpuVerifyStream(opts) {
+        return (new MpuVerifyStream(opts));
+}
+
+function createMpuUnlinkLiveRecordStream(opts) {
+        return (new MpuUnlinkLiveRecordStream(opts));
+}
+
+function createMpuMorayCleanerStream(opts) {
+        return (new MpuMorayCleanerStream(opts));
+}
+
+module.exports = {
+        createMpuBatchStream: createMpuBatchStream,
+        createMpuVerifyStream: createMpuVerifyStream,
+        createMpuUnlinkLiveRecordStream: createMpuUnlinkLiveRecordStream,
+        createMpuMorayCleanerStream: createMpuMorayCleanerStream
+};
diff --git a/lib/mpu/mpuBatchStream.js b/lib/mpu/mpuBatchStream.js
new file mode 100644
index 0000000..27f2c78
--- /dev/null
+++ b/lib/mpu/mpuBatchStream.js
@@ -0,0 +1,200 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var mpuCommon = require('./common');
+
+var sprintf = util.format;
+
+/*
+ * MpuBatchStream: Collects all records in a stream for related mulitpart
+ * uploads into a single batch, and passes this batch along to the next stream.
+ *
+ * NOTE: This stream assumes the input is sorted by upload ID and will throw an
+ * exception if it encounters the same upload ID twice.
+ *
+ * Parameters:
+ * - "args": an options object with the following required parameters:
+ *      - "log": a bunyan logger
+ */
+function MpuBatchStream(args) {
+        var self = this;
+
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+        self.log = args.log;
+
+        /* Current batch pointers */
+        self.mbs_batch = [];            // array of record objects in the batch
+        self.mbs_uploadId = null;       // current upload ID
+
+        /*
+         * Keep track of upload ids we've seen to ensure the input is, in fact,
+         * in sorted order. We maintain some state about these to ease
+         * port-mortem debugging if this stream throws because the input isn't
+         * sorted, which could lead to metadata cruft from MPUs.
+         */
+        self.mbs_uploadIdMap = {};
+        self.mbs_numRecords = 0;
+}
+util.inherits(MpuBatchStream, stream.Transform);
+
+/*
+ * Sends the current batch to the next stream, and resets the internal stream
+ * state to prepare for a new batch.
+ */
+MpuBatchStream.prototype.mbs_commitBatch = function mbs_commitBatch() {
+        var self = this;
+        assert.string(self.mbs_uploadId);
+        assert.ok(self.mbs_batch.length > 0, sprintf('no records for batch ' +
+                        '(upload id %s)', self.mbs_uploadId));
+        assert.object(self.mbs_uploadIdMap[self.mbs_uploadId]);
+
+        var batch = {
+                uploadId: self.mbs_uploadId,
+                records: self.mbs_batch
+        };
+
+        self.mbs_uploadIdMap[self.mbs_uploadId].status = 'completed';
+        self.push(batch);
+
+        self.log.debug({
+                uploadId: self.mbs_uploadId,
+                batch: batch
+        }, 'committed batch');
+
+        self.mbs_uploadId = null;
+        self.mbs_batch = [];
+};
+
+/*
+ * Sets the upload ID for the current batch, and throws an exception if we've
+ * seen this upload ID in a previous batch on this stream.
+ *
+ * Parameters:
+ * - "id": upload ID for the new batch
+ */
+MpuBatchStream.prototype.mbs_createBatch = function mbs_createBatch(id) {
+        assert.uuid(id, 'id');
+        var self = this;
+
+        assert.ok(self.mbs_uploadId === null, 'other batch in process');
+
+        if (self.mbs_uploadIdMap[id]) {
+                var msg = sprintf('Upload id \"%s\" has already been ' +
+                        'processed. This is very bad. Some records may not ' +
+                        'be garbage collected properly as a result.', id);
+                self.log.fatal({
+                        uploadId: id,
+                        previousBatch: self.mbs_uploadIdMap[id]
+                }, msg);
+                throw (new Error(msg));
+        } else {
+                self.mbs_uploadId = id;
+                self.mbs_uploadIdMap[id] = {
+                        uploadId: id,
+                        status: 'processing',
+                        numRecords: 0
+                };
+        }
+};
+
+/*
+ * Push a record object onto the current batch.
+ *
+ * Parameters:
+ *  - "r": record object to push
+ */
+MpuBatchStream.prototype.mbs_batchPush = function mbs_batchPush(r) {
+        assert.object(r, 'r');
+
+        var self = this;
+        self.mbs_batch.push(r);
+
+        var b = self.mbs_uploadIdMap[r.uploadId];
+        b.numRecords++;
+
+        assert.ok(b.numRecords === self.mbs_batch.length,
+                  sprintf('mismatch of batch count (%d) ' +
+                          'and `numRecords` count (%d)',
+                          self.mbs_batch.length,
+                          b.numRecords));
+};
+
+MpuBatchStream.prototype._transform = function mbsTransform(record, _, cb) {
+        assert.string(record, 'record');
+        assert.func(cb, 'cb');
+        var self = this;
+
+        var r = mpuCommon.recordToObject(record);
+        assert.object(r, 'r');
+        self.mbs_numRecords++;
+
+        if (self.mbs_uploadId === null) {
+                self.mbs_createBatch(r.uploadId);
+        }
+
+        /*
+         * If this has the same upload ID as the previous upload, add it to the
+         * batch; otherwise, commit the previous batch, start a new one, and add
+         * the current record to the new batch.
+         */
+        if (self.mbs_uploadId === r.uploadId) {
+                self.mbs_batchPush(r);
+                setImmediate(cb);
+        } else {
+                self.mbs_commitBatch();
+
+                self.mbs_createBatch(r.uploadId);
+                self.mbs_batchPush(r);
+
+                setImmediate(cb);
+        }
+};
+
+MpuBatchStream.prototype._flush = function mbsFlush(cb) {
+        var self = this;
+
+        // Make sure to commit an outstanding batch.
+        if (self.mbs_batch.length > 0) {
+                self.mbs_commitBatch();
+        }
+
+        self.log.debug({
+                batches: self.mbs_uploadIdMap
+        }, 'completed batches');
+
+        self.log.info({
+                stats: self.getStats()
+        }, 'done');
+
+        setImmediate(cb);
+};
+
+
+MpuBatchStream.prototype.getStats = function getStats() {
+        var self = this;
+
+        return ({
+                numBatches: Object.keys(self.mbs_uploadIdMap).length,
+                numRecords: self.mbs_numRecords
+        });
+};
+
+module.exports = MpuBatchStream;
diff --git a/lib/mpu/mpuMorayCleanerStream.js b/lib/mpu/mpuMorayCleanerStream.js
new file mode 100644
index 0000000..3270dc5
--- /dev/null
+++ b/lib/mpu/mpuMorayCleanerStream.js
@@ -0,0 +1,181 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+var moray = require('moray');
+
+var mpuCommon = require('./common');
+
+
+///--- Globals
+
+var MORAY_CONNECT_TIMEOUT = 10000;
+var MORAY_PORT = 2020;
+
+/*
+ * MpuMorayCleanerStream: Deletes the finalizing record for the MPU.
+ */
+function MpuMorayCleanerStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        stream.Writable.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = args.log;
+        this.morayClients = {};
+        this.dryRun = args.dryRun;
+        this.verbose = args.verbose;
+
+        var self = this;
+
+        self.mcs_numBatchesInput = 0;
+        self.mcs_numRecordsDeleted = 0;
+        self.mcs_numBatchesDropped = 0;
+
+        self.on('finish', function () {
+                for (var c in self.morayClients) {
+                        var client = self.morayClients[c].client;
+                        client.close();
+                }
+
+                self.log.info({
+                        stats: self.getStats()
+                }, 'done');
+        });
+}
+util.inherits(MpuMorayCleanerStream, stream.Writable);
+module.exports = MpuMorayCleanerStream;
+
+MpuMorayCleanerStream.prototype.mcs_getMorayClient =
+function mcs_getMorayClient(shard, cb) {
+        assert.string(shard, 'shard');
+        assert.func(cb, 'cb');
+
+        var self = this;
+
+        function onConnect() {
+                self.log.info({ shard: shard }, 'Connected to shard.');
+                self.morayClients[shard].connected = true;
+                cb(self.morayClients[shard].client);
+        }
+
+        var cObj = self.morayClients[shard];
+        if (cObj) {
+                /*
+                 * We've already created a client at this point, so we will pass
+                 * it to the caller once it's connected.
+                 */
+                if (cObj.connected) {
+                        cb(self.morayClients[shard].client);
+                        return;
+                } else {
+                        assert.object(cObj.client, 'no client found');
+                        cObj.client.once('connect', onConnect);
+                        return;
+                }
+        }
+
+        var client = moray.createClient({
+                log: self.log,
+                connectTimeout: MORAY_CONNECT_TIMEOUT,
+                host: shard,
+                port: MORAY_PORT
+        });
+        self.morayClients[shard] = {
+                client: client,
+                connected: false
+        };
+
+        client.once('connect', onConnect);
+};
+
+MpuMorayCleanerStream.prototype.mcs_deleteFinalizingRecord =
+function mcs_deleteFinalizingRecord(shard, key, cb) {
+        var self = this;
+
+        self.mcs_getMorayClient(shard, function (client) {
+                assert.object(client);
+                client.delObject(mpuCommon.MPU_MORAY_BUCKET, key, cb);
+        });
+};
+
+MpuMorayCleanerStream.prototype._write = function mmcsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+
+        var fr = batch.finalizingRecord;
+        assert.string(fr.uploadId, 'fr.uploadId');
+        assert.ok(fr.uploadId === batch.uploadId, 'upload ID of finalizing ' +
+                'record does not match batch uploadId');
+        assert.string(fr.key, 'fr.key');
+        assert.string(fr.shard, 'fr.shard');
+        assert.object(fr.date, 'fr.date');
+        assert.ok(fr.date instanceof Date, 'invalid date');
+
+        var self = this;
+        self.mcs_numBatchesInput++;
+
+        if (self.verbose) {
+                console.error('delObject ' + fr.key);
+        }
+
+        if (!self.dryRun) {
+                self.mcs_deleteFinalizingRecord(fr.shard, fr.key,
+                   function (err) {
+                        if (err) {
+                                /*
+                                 * We don't want to throw an error here in case
+                                 * this is an isolated problem, so log an error
+                                 * and continue.
+                                 */
+                                self.log.error({
+                                        uploadId: batch.uploadId,
+                                        shard: fr.shard,
+                                        key: fr.key,
+                                        err: err
+                                }, 'mpu moray cleaner stream failure');
+
+                                self.mcs_numBatchesDropped++;
+                        } else {
+                                self.log.debug({
+                                        key: fr.key,
+                                        shard: fr.shard
+                                }, 'delobject');
+
+                                self.mcs_numRecordsDeleted++;
+                        }
+
+                        cb();
+                });
+        } else {
+                cb();
+        }
+};
+
+MpuMorayCleanerStream.prototype.getStats = function getStats() {
+        var self = this;
+
+        return ({
+                numBatchesInput: self.mcs_numBatchesInput,
+                numBatchesOutput: self.mcs_numBatchesInput -
+                        self.mcs_numBatchesDropped,
+                numRecordsDeleted: self.mcs_numRecordsDeleted,
+                numBatchesDropped: self.mcs_numBatchesDropped
+        });
+};
diff --git a/lib/mpu/mpuUnlinkLiveRecordStream.js b/lib/mpu/mpuUnlinkLiveRecordStream.js
new file mode 100644
index 0000000..353971f
--- /dev/null
+++ b/lib/mpu/mpuUnlinkLiveRecordStream.js
@@ -0,0 +1,230 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var mahi = require('mahi');
+var stream = require('stream');
+var util = require('util');
+var vasync = require('vasync');
+
+var sprintf = util.format;
+
+var mpuCommon = require('./common');
+
+var MULRS_TYPE_PART = 'partRecords';
+var MULRS_TYPE_UPLOADDIR = 'uploadRecord';
+
+var MULRS_DEF_CONCURRENCY = 100;
+
+
+/*
+ * MpuUnlinkStream: Unlinks live records in Manta as part of the MPU garbage
+ * collection process. Depending on the arguments to its constructor, this
+ * stream will unlink a collection of parts in an upload directory or the upload
+ * directory itself.
+ *
+ * Parameters:
+ *  - args: an options block with the following required arguments:
+ *      - log: a bunyan logger
+ *      - type: the type of this stream (see MULRS_* constants)
+ *      - mantaClient: a Manta client
+ *      - mahiClient: a mahi client
+ *
+ *    and the following optional arguments:
+ *      - dryRun: bool, that if true, will invoke this stream in "dryRun" mode
+ *                such that no records are unlinked from Manta
+ *      - verbose: bool, that if true, will print actions the stream is taking
+ *                 (or would take, if "dryRun" is true), to stderr
+ */
+function MpuUnlinkLiveRecordStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+        assert.string(args.type, 'args.type');
+        assert.ok(args.type === MULRS_TYPE_PART ||
+                args.type === MULRS_TYPE_UPLOADDIR);
+        assert.object(args.mantaClient, 'args.mantaClient');
+        assert.object(args.mahiClient, 'args.mahiClient');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        stream.Transform.call(this, {
+                objectMode: true,
+                highWaterMark: 0
+        });
+
+        this.log = args.log;
+        this.mantaClient = args.mantaClient;
+        this.mahiClient = args.mahiClient;
+        this.type = args.type;
+        this.dryRun = args.dryRun;
+        this.verbose = args.verbose;
+
+        this.mulrs_numRecordsSeen = 0;
+        this.mulrs_numRecordsUnlinked = 0;
+        this.mulrs_numBatchesDropped = 0;
+}
+util.inherits(MpuUnlinkLiveRecordStream, stream.Transform);
+
+MpuUnlinkLiveRecordStream.prototype._transform =
+function mulrsWrite(batch, _, cb) {
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.object(batch.finalizingRecord, 'batch.finalizingRecord');
+        assert.optionalObject(batch.uploadRecord, 'batch.uploadRecord');
+        assert.optionalArrayOfObject(batch.partRecords, 'batch.partRecords');
+
+        var self = this;
+        if (!batch[self.type]) {
+                assert.object(batch, 'batch');
+                self.push(batch);
+                setImmediate(cb);
+                return;
+        }
+
+        if (self.type === MULRS_TYPE_PART) {
+                assert.ok(batch.partRecords, 'batch.partRecords');
+                self.mulrs_numRecordsSeen += batch.partRecords.length;
+        } else {
+                self.mulrs_numRecordsSeen++;
+        }
+
+
+        /*
+         * Moray stores a normalized key, but we will need the account
+         * associated with each MPU to remove the file through the front door.
+         */
+        var uuid, account;
+        assert.ok(batch.uploadRecord, 'batch must have an upload record');
+        assert.ok(batch.uploadRecord.key);
+        var split = batch.uploadRecord.key.split('/');
+        assert.ok(split.length >= 2, 'path does not have enough values');
+        uuid = split[1];
+        assert.uuid(uuid, sprintf('invalid uuid: %s', uuid));
+
+        self.mahiClient.getAccountById(uuid, function (err, info) {
+                /*
+                 * If we can't resolve the account information, we will have to
+                 * drop this batch, as there's no way for us to remove the
+                 * records from the front door.
+                 *
+                 * Unfortunately, in the case where we cannot resolve a UUID
+                 * because the user has been deleted, any non-garbage collected
+                 * MPUs cannot be cleaned up by the normal cleanup stream
+                 * mechanism.
+                 */
+                if (err) {
+                        self.log.error({
+                                uploadId: batch.uploadId,
+                                accountUuid: uuid,
+                                err: err
+                        }, 'could not fetch account uuid->name mapping');
+
+                        self.mulrs_numBatchesDropped++;
+
+                        setImmediate(cb);
+                        return;
+                }
+
+                account = info.account.login;
+                assert.string(account, 'account');
+
+                var inputs;
+                if (self.type === MULRS_TYPE_UPLOADDIR) {
+                        inputs = [ batch.uploadRecord ];
+                } else {
+                        assert.ok(self.type === MULRS_TYPE_PART,
+                                sprintf('invalid type: \"%s\"', self.type));
+                        inputs = batch.partRecords;
+                }
+                assert.arrayOfObject(inputs, 'inputs');
+
+                var opts = {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                };
+                var valid = true;
+
+                function unlink(p, ucb) {
+                        self.mantaClient.unlink(p, opts, function (err2, res) {
+                                if (err2) {
+                                        self.log.error({
+                                                id: batch.uploadId,
+                                                err: err2,
+                                                accountUuid: uuid,
+                                                account: account,
+                                                path: p
+                                        }, 'unlink live record stream failure');
+                                        valid = false;
+                                } else {
+                                        self.mulrs_numRecordsUnlinked++;
+                                }
+
+                                ucb();
+                        });
+                }
+
+                var q = vasync.queue(function optionalUnlinkLiveRecord(r, vcb) {
+                                assert.string(r.key);
+                                var mantaPath = r.key.replace(uuid, account);
+
+                                if (self.verbose) {
+                                        console.error('unlink ' + mantaPath);
+                                }
+
+                                if (!self.dryRun) {
+                                        unlink(mantaPath, vcb);
+                                } else {
+                                        setImmediate(vcb);
+                                }
+                        }, MULRS_DEF_CONCURRENCY);
+
+                q.push(inputs);
+                q.close();
+
+                q.on('end', function () {
+                        if (valid) {
+                                self.push(batch);
+                        } else {
+                                self.mulrs_numBatchesDropped++;
+                        }
+
+                        cb();
+                });
+        });
+};
+
+MpuUnlinkLiveRecordStream.prototype._flush = function mupsFlush(cb) {
+        var self = this;
+
+        self.log.info({
+                stats: self.getStats()
+        }, 'done');
+
+        setImmediate(cb);
+};
+
+
+MpuUnlinkLiveRecordStream.prototype.getStats = function getStats() {
+        var self = this;
+
+        return ({
+                numRecordsSeen: self.mulrs_numRecordsSeen,
+                numRecordsUnlinked: self.mulrs_numRecordsUnlinked,
+                numBatchesDropped: self.mulrs_numBatchesDropped
+        });
+};
+
+module.exports = {
+        MULRS_TYPE_PART: MULRS_TYPE_PART,
+        MULRS_TYPE_UPLOADDIR: MULRS_TYPE_UPLOADDIR,
+
+        MpuUnlinkLiveRecordStream: MpuUnlinkLiveRecordStream
+};
diff --git a/lib/mpu/mpuVerifyStream.js b/lib/mpu/mpuVerifyStream.js
new file mode 100644
index 0000000..065aece
--- /dev/null
+++ b/lib/mpu/mpuVerifyStream.js
@@ -0,0 +1,235 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var stream = require('stream');
+var util = require('util');
+
+var assert = require('assert-plus');
+
+var sprintf = util.format;
+
+var mpuCommon = require('./common');
+
+var mulrs = require('./mpuUnlinkLiveRecordStream');
+var MULRS_TYPE_PART = mulrs.MULRS_TYPE_PART;
+var MULRS_TYPE_UPLOADDIR = mulrs.MULRS_TYPE_UPLOADDIR;
+
+/*
+ * MpuVerifyStream: Given an input stream of a batch of upload records all
+ * for the same MPU, verifies that this MPU is a valid candidate for
+ * garbage collection.
+ *
+ * The MPU is a valid candidate for garbage collection if a finalizing
+ * record exists for the MPU.
+ */
+function MpuVerifyStream(args) {
+        assert.object(args, 'args');
+        assert.object(args.log, 'args.log');
+
+        stream.Transform.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        this.log = args.log;
+
+        this.mvs_numBatchesInput = 0;
+        this.mvs_numBatchesDropped = 0;
+
+        this.mvs_numRecordsInput = 0;
+        this.mvs_numPRInput = 0;
+        this.mvs_numURInput = 0;
+        this.mvs_numFRInput = 0;
+
+        // number of each type of record that will be GC'd
+        this.mvs_numPartRecords = 0;
+        this.mvs_numUploadRecords = 0;
+        this.mvs_numFinalizingRecords = 0;
+}
+util.inherits(MpuVerifyStream, stream.Transform);
+module.exports = MpuVerifyStream;
+
+/*
+ * Based on the records present, ensures that this MPU is valid to be garbage
+ * collected.
+ */
+MpuVerifyStream.prototype.mvs_validateMPU =
+function mvs_validateMPU(id, records, cb) {
+        assert.string(id, 'id');
+        assert.arrayOfObject(records, 'records');
+
+        var self = this;
+
+        var uploadRecord, partRecords, finalizingRecord;
+        var invalidBatch = false;
+
+        records.forEach(function (r) {
+                assert.ok(r instanceof mpuCommon.LiveRecord ||
+                    r instanceof mpuCommon.FinalizingRecord,
+                    'invalid record object');
+
+                var rId = r.uploadId;
+                if (id !== rId) {
+                        self.log.error({
+                                batchUploadId: id,
+                                recordUploadId: rId
+                        }, 'MPU records batch has records with different ' +
+                           'upload IDs');
+                        invalidBatch = true;
+                }
+
+                var mpuObject;
+                if (r instanceof mpuCommon.FinalizingRecord) {
+                        mpuObject = mpuCommon.MPUOBJ_FINALIZINGRECORD;
+                } else {
+                        if (r.type === mpuCommon.MPU_PART) {
+                                mpuObject = mpuCommon.MPUOBJ_PART;
+                        } else {
+                                assert.ok(r.type === mpuCommon.MPU_UPLOADDIR);
+                                mpuObject = mpuCommon.MPUOBJ_UPLOADDIR;
+                        }
+                }
+                assert.ok(mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD ||
+                    mpuObject === mpuCommon.MPUOBJ_UPLOADDIR ||
+                    mpuObject === mpuCommon.MPUOBJ_PART,
+                    sprintf('invalid mpu object: %s', mpuObject));
+
+                if (mpuObject === mpuCommon.MPUOBJ_FINALIZINGRECORD) {
+                        self.mvs_numFRInput++;
+
+                        if (!finalizingRecord) {
+                                finalizingRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple finalizing records found for ' +
+                                   'the same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_UPLOADDIR) {
+                        self.mvs_numURInput++;
+
+                        if (!uploadRecord) {
+                                uploadRecord = r;
+                        } else {
+                                self.log.error({
+                                        uploadId: id,
+                                        record: r
+                                }, 'multiple upload records found for the ' +
+                                   'same upload ID');
+                                invalidBatch = true;
+                        }
+                } else if (mpuObject === mpuCommon.MPUOBJ_PART) {
+                        self.mvs_numPRInput++;
+
+                        if (!partRecords) {
+                                partRecords = [];
+                        }
+
+                        partRecords.push(r);
+                } else {
+                       self.log.error({
+                                uploadId: id,
+                                record: r
+                       }, 'invalid MPU record (not a finalizing record, ' +
+                          'upload record, or part record');
+                        invalidBatch = true;
+                }
+        });
+
+        if (partRecords && partRecords.length > 0 && !uploadRecord) {
+                self.log.error({
+                        uploadId: id
+                }, 'part records found, but no upload record');
+                invalidBatch = true;
+        }
+
+        if (!finalizingRecord) {
+                self.log.error({
+                        uploadId: id
+                }, 'no finalizing record found');
+                invalidBatch = true;
+        }
+
+        if (invalidBatch) {
+                self.mvs_numBatchesDropped++;
+        } else {
+                assert.ok(finalizingRecord, 'no finalizing record found');
+                assert.optionalObject(uploadRecord, 'upload record is not ' +
+                    'an object');
+                assert.optionalArrayOfObject(partRecords, 'part records are ' +
+                   'not an array of objects');
+
+                // First, update counters.
+                self.mvs_numFinalizingRecords++;
+                if (uploadRecord) {
+                        self.mvs_numUploadRecords++;
+                }
+                if (partRecords) {
+                        self.mvs_numPartRecords += partRecords.length;
+                }
+
+                self.push({
+                        uploadId: id,
+                        finalizingRecord: finalizingRecord,
+                        uploadRecord: uploadRecord,
+                        partRecords: partRecords
+                });
+        }
+
+        setImmediate(cb);
+};
+
+MpuVerifyStream.prototype._transform = function mvsTransform(batch, _, cb) {
+        var self = this;
+
+        assert.object(batch, 'batch');
+        assert.string(batch.uploadId, 'batch.uploadId');
+        assert.arrayOfObject(batch.records, 'batch.records');
+
+        self.mvs_numBatchesInput++;
+        self.mvs_numRecordsInput += batch.records.length;
+
+        self.mvs_validateMPU(batch.uploadId, batch.records, cb);
+};
+
+MpuVerifyStream.prototype._flush = function mvsFlush(cb) {
+        var self = this;
+
+        assert.ok((self.mvs_numBatchesInput - self.mvs_numBatchesDropped) ===
+                self.mvs_numFinalizingRecords,
+                'every valid MPU must have an associated finalizing record');
+
+        self.log.info({
+                stats: self.getStats()
+        }, 'done');
+
+        setImmediate(cb);
+};
+
+
+MpuVerifyStream.prototype.getStats = function getStats() {
+        var self = this;
+
+        assert.ok(self.mvs_numRecordsInput ===
+                (self.mvs_numPRInput + self.mvs_numURInput +
+                 self.mvs_numFRInput),
+                 'total mismatch');
+
+        return ({
+               numBatchesInput: self.mvs_numBatchesInput,
+               numBatchesDropped: self.mvs_numBatchesDropped,
+               numPRInput: self.mvs_numPRInput,
+               numURInput: self.mvs_numURInput,
+               numFRInput: self.mvs_numFRInput,
+               numRecordsInput: self.mvs_numRecordsInput
+        });
+};
diff --git a/lib/mpu_garbage_collector.js b/lib/mpu_garbage_collector.js
new file mode 100644
index 0000000..34b631e
--- /dev/null
+++ b/lib/mpu_garbage_collector.js
@@ -0,0 +1,171 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var util = require('util');
+var events = require('events');
+var carrier = require('carrier');
+
+var mpuCommon = require('./mpu/common');
+
+
+///--- Globals
+
+var DEFAULT_GRACE_PERIOD_MILLIS = 1000 * 60 * 60 * 24 * 2;  // 2 days
+
+var sprintf = util.format;
+
+///--- API
+
+/*
+ * Emits 'cleanup' events for all MPU records that should be garbage collected.
+ *
+ * This object is analogous to the GarbageCollector object for normal GC. In the
+ * MPU case, only one type of event is emitted, as all records are cleaned up
+ * with the same cleanup scripts, unlike the normal GC case.
+ */
+function MpuGarbageCollector(opts) {
+        assert.object(opts, 'opts');
+        assert.object(opts.reader, 'opts.reader');
+        assert.object(opts.log, 'opts.log');
+        assert.optionalObject(opts.gcDate, 'opts.gcDate');
+
+        var self = this;
+        self.log = opts.log;
+
+        if (opts.gcDate) {
+                self.gcDate = opts.gcDate;
+        } else  {
+                self.gcDate = Date.now();
+        }
+
+        var prev, curr, currFR;
+        self.gracePeriodMillis = opts.gracePeriodMillis ||
+                DEFAULT_GRACE_PERIOD_MILLIS;
+        self.carrier = carrier.carry(opts.reader);
+
+        self.mgc_numRecordsSeen = 0;
+        self.mgc_numRecordsEmitted = 0;
+        self.mgc_numRecordsGracePeriod = 0;
+
+        self.log.info({
+                gcDate: self.gcDate,
+                gracePeriodMillis: self.gracePeriodMillis
+        }, 'starting garbage collection');
+
+        self.carrier.on('line', function (line) {
+                self.mgc_numRecordsSeen++;
+
+                curr = mpuCommon.recordToObject(line);
+                currFR = takeAction(self, prev, curr, currFR);
+                prev = curr;
+                curr = null;
+        });
+
+        self.carrier.on('end', function () {
+                takeAction(self, prev, curr, currFR);
+                self.log.info({
+                        numRecordsSeen: self.mgc_numRecordsSeen,
+                        numRecordsToCleanup: self.mgc_numRecordsEmitted,
+                        numRecordsInGracePeriod: self.mgc_numRecordsGracePeriod
+                }, 'done');
+                self.emit('end');
+        });
+}
+util.inherits(MpuGarbageCollector, events.EventEmitter);
+module.exports = MpuGarbageCollector;
+
+MpuGarbageCollector.prototype.mgc_outsideGracePeriod =
+function mgc_outsideGracePeriod(date) {
+        assert.object(date, 'date');
+        assert.ok(date instanceof Date, 'invalid date');
+
+        var self = this;
+
+        return ((self.gcDate - date) > self.gracePeriodMillis);
+};
+
+
+///--- Helpers
+
+/*
+ * Emits the 'mpuCleanup' event for the current finalizing record and/or the
+ * current object, if they should be garbage collected, and returns the current
+ * finalizing record for the current batch of MPU records.
+ *
+ * A record should be garbage collected if and only if it belongs to a finalized
+ * MPU -- that is, a finalizing record is present for the MPU -- and the date of
+ * the finalizing record's creation is before the grace period specified for the
+ * garbage collector.
+ *
+ * We can determine whether the current record and the current finalizing record
+ * in the stream can be garbage collected as follows. First, we inspect the
+ * previous record in the stream. If it has a different upload ID from the
+ * current record, then we have started looking at a new MPU, as we know the
+ * stream is sorted by upload ID. If a finalizing record for the previous MPU
+ * exists, we should emit a cleanup event for it. Next, we look at the current
+ * pointer to a finalizing record. If a finalizing record exists for this MPU,
+ * then we should emit a cleanup event for it. If the record itself is a
+ * finalizing record, then this record becomes the current finalizing record,
+ * and is returned from this function.
+ *
+ * Inputs:
+ * - gc: a MpuGarbageCollector object
+ * - prev: the previous record in the stream
+ * - curr: current record in the stream
+ * - currFR: current finalizing record pointer
+ *
+ */
+function takeAction(gc, prev, curr, currFR) {
+        assert.optionalObject(prev, 'prev');
+        assert.ok(prev instanceof mpuCommon.LiveRecord ||
+                  prev instanceof mpuCommon.FinalizingRecord ||
+                  !prev);
+        assert.optionalObject(curr, 'curr');
+        assert.ok(curr instanceof mpuCommon.LiveRecord ||
+                  curr instanceof mpuCommon.FinalizingRecord ||
+                  !curr);
+        assert.optionalObject(currFR, 'currFR');
+        assert.ok(currFR instanceof mpuCommon.FinalizingRecord || !currFR);
+
+        if (prev && (!curr || (prev.uploadId !== curr.uploadId))) {
+                /*
+                 * We've seen all records related to the previous upload ID,
+                 * so we know it's safe to delete the finalizing record of the
+                 * upload, if the record exists.
+                 */
+                if (currFR) {
+                        if (gc.mgc_outsideGracePeriod(currFR.date)) {
+                                gc.mgc_numRecordsEmitted++;
+                                gc.emit('mpuCleanup', currFR);
+                                currFR = null;
+                        } else {
+                                gc.mgc_numRecordsGracePeriod++;
+                        }
+                }
+        }
+
+        if (curr && curr instanceof mpuCommon.FinalizingRecord) {
+                currFR = curr;
+        } else if (curr && currFR) {
+                /*
+                 * Don't garbage collect any records for uploads that
+                 * don't have an associated finalizing record.
+                 */
+                if (gc.mgc_outsideGracePeriod(currFR.date)) {
+                        gc.mgc_numRecordsEmitted++;
+                        gc.emit('mpuCleanup', curr);
+                } else {
+                        gc.mgc_numRecordsGracePeriod++;
+                }
+        }
+
+        return (currFR);
+}
diff --git a/lib/mpu_gc_pg_row_transformer.js b/lib/mpu_gc_pg_row_transformer.js
new file mode 100644
index 0000000..b4491e3
--- /dev/null
+++ b/lib/mpu_gc_pg_row_transformer.js
@@ -0,0 +1,153 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var events = require('events');
+var path = require('path');
+var util = require('util');
+
+var mpuCommon = require('./mpu/common');
+
+var SchemaReader = require('./schema_reader');
+
+///--- GLOBALS
+
+var PG_LIVE_MANTA_TABLE_NAME = 'manta';
+var PG_MANTA_UPLOADS_TABLE_NAME = 'manta_uploads';
+
+/* JSSTYLED */
+var UPLOADS_ROOT_PATH = /^\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\/uploads\/?.*/;
+
+
+///--- API
+
+/*
+ * This transforms pg-dumped rows to objects usable for multipart upload garbage
+ * collection.
+ *
+ * The resulting rows are emitted as an object: either a LiveRecord or a
+ * FinalizingRecord. LiveRecord objects represent live objects in Manta, which
+ * includes parts and upload directories for MPU garbage collection.
+ * FinalizingRecord objects map to finalizing records.
+ *
+ * Both objects expose a toString method for representing the row in a format
+ * suitable for sorting.
+ *
+ * The MpuGcPgRowTransformer is analogous to the GcPgRowTransformer object for
+ * normal garbage collection.
+ */
+function MpuGcPgRowTransformer(opts, listener) {
+        assert.object(opts, 'opts');
+        assert.object(opts.reader, 'opts.reader');
+        assert.ok(opts.dumpDate, 'opts.dumpDate');
+        assert.ok(opts.dumpDate instanceof Date, 'invalid date');
+        assert.string(opts.morayHostname, 'opts.morayHostname');
+
+        var self = this;
+        var reader = opts.reader;
+        var dumpDate = opts.dumpDate;
+        var earliestDumpDate = opts.earliestDumpDate;
+        var morayHostname = opts.morayHostname;
+
+        self.schemaReader = new SchemaReader(reader);
+
+        if (listener) {
+                self.addListener('row', listener);
+        }
+
+        function isMpuRecord(o) {
+                var t = o._value.type;
+                var k = o._value.key;
+                var u = o._value.upload;
+
+                if (k.match(UPLOADS_ROOT_PATH)) {
+                        return (t === 'object' ||
+                                (t === 'directory' && !!u));
+                }
+
+                return (false);
+        }
+
+        self.schemaReader.on('object', function (obj) {
+                var table = obj['__table'];
+                var row;
+
+                if (table === PG_LIVE_MANTA_TABLE_NAME) {
+                        if (isMpuRecord(obj)) {
+                            row = transformLiveRecord(obj, dumpDate,
+                                morayHostname);
+                        }
+                } else if (table === PG_MANTA_UPLOADS_TABLE_NAME) {
+                        row = transformFinalizingRecord(obj, earliestDumpDate,
+                            morayHostname);
+                }
+
+                if (row) {
+                        self.emit('row', row);
+                }
+        });
+
+        self.schemaReader.on('end', function () {
+                self.emit('end');
+        });
+}
+
+util.inherits(MpuGcPgRowTransformer, events.EventEmitter);
+module.exports = MpuGcPgRowTransformer;
+
+
+///--- Helpers
+
+function transformFinalizingRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_MANTA_UPLOADS_TABLE_NAME);
+        var value = obj['_value'];
+        var date = new Date(parseInt(obj['_mtime'], 10));
+
+        return new mpuCommon.FinalizingRecord({
+                uploadId: value.uploadId,
+                key: obj._key,
+                shard: morayHostname,
+                date: date,
+                type: value.finalizingType
+        });
+}
+
+function transformLiveRecord(obj, dumpDate, morayHostname) {
+        assert.string(obj['__table'], PG_LIVE_MANTA_TABLE_NAME);
+        var value = obj['_value'];
+
+        var mpuObject, uploadId;
+        if (value.type === 'directory') {
+            mpuObject = mpuCommon.MPU_UPLOADDIR;
+            uploadId = value.upload.id;
+        } else if (value.type === 'object') {
+            mpuObject = mpuCommon.MPU_PART;
+            uploadId = path.basename(path.dirname(obj._key));
+        } else {
+            return (null);
+        }
+        assert.string(uploadId, 'uploadId');
+        assert.string(mpuObject, 'mpuObject');
+
+        if (!obj._key.match(UPLOADS_ROOT_PATH)) {
+                return (null);
+        }
+        assert.string(mpuObject);
+
+        var record = new mpuCommon.LiveRecord({
+                key: obj._key,
+                date: dumpDate,
+                type: mpuObject,
+                uploadId: uploadId
+        });
+        assert.object(record);
+
+        return (record);
+}
diff --git a/package.json b/package.json
index 8d477f7..eeb6d69 100644
--- a/package.json
+++ b/package.json
@@ -11,10 +11,11 @@
                 "carrier": "0.1.14",
                 "dashdash": "1.7.0",
                 "forkexec": "^1.1.0",
-                "jsprim": "^1.4.0",
+                "jsprim": "2.0.0",
                 "lstream": "0.0.4",
                 "once": "1.3.1",
                 "manta-hk": "git+https://github.com/joyent/manta-hk.git#master",
+                "mahi": "2.0.1",
                 "marlin": "git+https://github.com/joyent/manta-marlin.git#master",
                 "memorystream": "0.2.0",
                 "node-manta": "git+https://github.com/joyent/node-manta.git#master",
@@ -22,12 +23,14 @@
                 "moray": "git+https://github.com/joyent/node-moray.git#fd5781bc25a9bfe2ba82167664639753fb9f0ca5",
                 "posix-getopt": "1.0.0",
                 "sprintf-js": "0.0.7",
-                "vasync": "1.6.1",
+                "vasync": "2.1.0",
                 "verror": "^1.9.0",
                 "vstream": "0.1.0"
         },
         "devDependencies": {
-                "nodeunit": "0.7.4"
+                "libuuid": "0.1.2",
+                "memorystream": "0.2.0",
+                "nodeunit": "0.9.1"
         },
         "sdcDependencies": {
                 "config-agent": ">=1.2.0"
diff --git a/sapi_manifests/mola/template b/sapi_manifests/mola/template
index c12a616..81e1393 100644
--- a/sapi_manifests/mola/template
+++ b/sapi_manifests/mola/template
@@ -20,6 +20,13 @@
         },
         "connectTimeout": 1000,
         "rejectUnauthorized": {{MANTA_REJECT_UNAUTHORIZED}}
+    },
+    "auth": {
+        "url": "http://{{AUTH_SERVICE}}",
+        "maxAuthCacheSize": 1000,
+        "maxAuthCacheAgeMs": 300000,
+        "maxTranslationCacheSize": 1000,
+        "maxTranslationCacheAgeMs": 300000
     }{{#AUDIT_MAP_DISK}},
     "auditMapDisk": {{AUDIT_MAP_DISK}}{{/AUDIT_MAP_DISK}}{{#AUDIT_REDUCE_DISK}},
     "auditReduceDisk": {{AUDIT_REDUCE_DISK}}{{/AUDIT_REDUCE_DISK}}{{#AUDIT_REDUCE_MEMORY}},
diff --git a/test/mpu/mpuBatchStream.test.js b/test/mpu/mpuBatchStream.test.js
new file mode 100644
index 0000000..37ce96b
--- /dev/null
+++ b/test/mpu/mpuBatchStream.test.js
@@ -0,0 +1,227 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var fs = require('fs');
+var jsprim = require('jsprim');
+var lstream = require('lstream');
+var MemoryStream = require('memorystream');
+var util = require('util');
+var uuid = require('libuuid');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mpuCommon = require('../../lib/mpu/common');
+
+///--- Globals
+
+var test = helper.test;
+var sprintf = util.format;
+
+var LOG = helper.createLogger('mpuBatchStream test');
+
+var MBS_ARGS = {
+        log: LOG
+};
+
+
+///--- Helpers
+
+function testMpuBatchStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfString(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+
+        var vsArgs = {
+                cb: args.testCb,
+                expect: args.output
+        };
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+        var mbs = new mpu.createMpuBatchStream(MBS_ARGS);
+        var vs = new inputs.ValidationStream(vsArgs);
+
+        args.input.forEach(function (i) {
+                r.push(i, 'utf8');
+        });
+        r.push(null);
+        r.pipe(mbs).pipe(vs);
+}
+
+
+///--- Tests
+
+test('single-record batch (FR only)', function (t) {
+        var input = [
+                inputs.FR_0
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple-record batch (FR, UR)', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0, inputs.OBJ_UR0
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple-record batch (with parts)', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0, inputs.PR_0[0]
+        ];
+
+        var output = [ {
+                uploadId: inputs.ID_0,
+                records: [
+                        inputs.OBJ_FR0, inputs.OBJ_UR0, inputs.OBJ_PR0[0]
+                ]
+        } ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0, inputs.PR_0[0],
+                inputs.FR_2, inputs.UR_2,
+                inputs.FR_1, inputs.UR_1, inputs.PR_1[0], inputs.PR_1[1],
+                        inputs.PR_1[2]
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuBatchStream(args);
+});
+
+test('records out of order', function (t) {
+        var input = [
+                inputs.FR_0, inputs.UR_0,
+                inputs.FR_2, inputs.UR_2,
+                inputs.PR_0[0]
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.fail('records out of order');
+                        if (ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        var d = require('domain').create();
+        d.on('error', function (err) {
+                t.ok(err, 'no error');
+                t.done();
+        });
+        d.run(function () {
+                testMpuBatchStream(args);
+        });
+});
diff --git a/test/mpu/mpuMorayCleanerStream.test.js b/test/mpu/mpuMorayCleanerStream.test.js
new file mode 100644
index 0000000..ea023d2
--- /dev/null
+++ b/test/mpu/mpuMorayCleanerStream.test.js
@@ -0,0 +1,259 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var events = require('events');
+var fs = require('fs');
+var jsprim = require('jsprim');
+var lstream = require('lstream');
+var MemoryStream = require('memorystream');
+var util = require('util');
+var uuid = require('libuuid');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mpuCommon = require('../../lib/mpu/common');
+
+///--- Globals
+
+var test = helper.test;
+var sprintf = util.format;
+
+var LOG = helper.createLogger('mpuBatchStream test');
+
+var MPU_MORAY_BUCKET = 'manta_uploads';
+
+
+///--- Helpers
+
+function testMpuMorayCleanerStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfString(args.shards, 'args.shards');
+        assert.ok(args.shards.length > 0, 'at least 1 shard must be specified');
+        assert.func(args.delObjectFunc, 'args.delObjectFunc');
+        assert.func(args.testCb, 'args.testCb');
+
+        var mockMorayClients = {};
+        var clientsClosed = [];
+
+        function MockMorayClient(opts) {
+                assert.object(opts, 'opts');
+                assert.string(opts.shard, 'opts.shard');
+
+                var self = this;
+                self.id = opts.shard;
+                self.delObject = opts.delObjectFunc;
+        }
+        util.inherits(MockMorayClient, events.EventEmitter);
+        MockMorayClient.prototype.close = function () {
+                clientsClosed.push(this.id);
+        };
+
+        args.shards.forEach(function (i) {
+                var client = new MockMorayClient({
+                        shard: i,
+                        delObjectFunc: args.delObjectFunc
+                });
+                mockMorayClients[i] = {
+                        client: client,
+                        connected: false
+                };
+
+                setImmediate(client.emit.bind(client, 'connect'));
+        });
+
+        var mmcs = new mpu.createMpuMorayCleanerStream({
+                log: LOG
+        });
+        mmcs.morayClients = mockMorayClients;
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mmcs);
+
+        mmcs.on('finish', function () {
+                args.testCb(clientsClosed);
+        });
+}
+
+///--- Tests
+
+test('one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0);
+
+                keys.push(key);
+                dcb();
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        t.ok(jsprim.deepEqual(clientsClosed, shards));
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0, inputs.SHARD_1, inputs.SHARD_2 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0,
+                inputs.KEY_FR2,
+                inputs.KEY_FR1
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0 ||
+                        key === inputs.KEY_FR1 ||
+                        key === inputs.KEY_FR2);
+
+                keys.push(key);
+                dcb();
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        shards.forEach(function (s) {
+                                t.ok(clientsClosed.indexOf(s) !== -1);
+                        });
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
+
+test('deleteFinalizingRecord returns error', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var shards = [ inputs.SHARD_0, inputs.SHARD_1, inputs.SHARD_2 ];
+        var keys = [];
+        var expected = [
+                inputs.KEY_FR0,
+                inputs.KEY_FR2,
+                inputs.KEY_FR1
+        ];
+
+        function delObject(bucket, key, dcb) {
+                t.ok(bucket === MPU_MORAY_BUCKET);
+                t.ok(key === inputs.KEY_FR0 ||
+                        key === inputs.KEY_FR1 ||
+                        key === inputs.KEY_FR2);
+
+                keys.push(key);
+                var err;
+                if (key === inputs.KEY_FR2) {
+                        err = new Error('simulated moray error');
+                }
+
+                dcb(err);
+        }
+
+        var args = {
+                input: input,
+                testCb: function cb(clientsClosed) {
+                        shards.forEach(function (s) {
+                                t.ok(clientsClosed.indexOf(s) !== -1);
+                        });
+                        t.ok(jsprim.deepEqual(keys, expected));
+                        t.done();
+                },
+                delObjectFunc: delObject,
+                shards: shards
+        };
+
+        testMpuMorayCleanerStream(args);
+});
diff --git a/test/mpu/mpuUnlinkLiveRecordStream.test.js b/test/mpu/mpuUnlinkLiveRecordStream.test.js
new file mode 100644
index 0000000..faaff04
--- /dev/null
+++ b/test/mpu/mpuUnlinkLiveRecordStream.test.js
@@ -0,0 +1,1167 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+
+///--- Globals
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var mulrs = require('../../lib/mpu/mpuUnlinkLiveRecordStream');
+var test = helper.test;
+
+var LOG = helper.createLogger('mpuUnlinkStream test');
+
+///--- Helpers
+
+function testMpuUnlinkLiveRecordStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+        assert.string(args.type, 'args.type');
+        assert.ok(args.type === mulrs.MULRS_TYPE_PART ||
+                args.type === mulrs.MULRS_TYPE_UPLOADDIR);
+        assert.func(args.unlinkFunc, 'args.unlinkFunc');
+        assert.func(args.getAccountByIdFunc, 'args.getAccountByIdFunc');
+        assert.optionalBool(args.dryRun, 'args.dryRun');
+        assert.optionalBool(args.verbose, 'args.verbose');
+
+        var mockMahiClient = {
+                getAccountById: args.getAccountByIdFunc
+        };
+
+        var mockMantaClient = {
+                unlink: args.unlinkFunc
+        };
+
+        var mvs = new mpu.createMpuUnlinkLiveRecordStream({
+                log: LOG,
+                type: args.type,
+                mantaClient: mockMantaClient,
+                mahiClient: mockMahiClient,
+                dryRun: args.dryRun,
+                verbose: args.verbose
+        });
+
+        var vsOpts = {
+                cb: args.testCb,
+                expect: args.output
+        };
+        var vs = new inputs.ValidationStream(vsOpts);
+
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mvs).pipe(vs);
+}
+
+///--- Tests: upload directory
+
+test('upload directory: one batch (no parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_0
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: one batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_3,
+                        finalizingRecord: inputs.OBJ_FR3,
+                        uploadRecord: inputs.OBJ_UR3,
+                        partRecords: [
+                                inputs.OBJ_PR3[0]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR1,
+                inputs.PATH_UR2,
+                inputs.PATH_UR3
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: multiple batches (one with no UR)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: 404 returned during unlink', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                if (p === inputs.PATH_UR2) {
+                        ucb(new Error('simulated 404'), {
+                                statusCode: 404
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+test('upload directory: error returned during unlink', function (t) {
+        /*
+         * Deliberately fail a request for one of the upload directory unlinks.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR2,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                // Fail one of the requests.
+                if (p === inputs.PATH_UR2) {
+                        ucb(new Error('simulated server error'), {
+                                statusCode: 503
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('upload directory: error returned during getAccountById', function (t) {
+        /*
+         * Deliberately fail a request for one of the uuid lookups from mahi.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_UR0,
+                inputs.PATH_UR1
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+
+                var err, login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                        err = new Error('simulated mahi error');
+                }
+
+                gcb(err, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_UPLOADDIR
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+
+///--- Tests: part records
+
+test('parts: one batch (1 part)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR1[0]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: one batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1],
+                inputs.PATH_PR1[2]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_1, 'uuid mismatch');
+                gcb(null, {
+                        account: {
+                                login: inputs.ACCT_LOGIN_1
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: multiple batches (1 part, 3 parts, 0 parts, 1 part)',
+function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_3,
+                        finalizingRecord: inputs.OBJ_FR3,
+                        uploadRecord: inputs.OBJ_UR3,
+                        partRecords: [
+                                inputs.OBJ_PR3[0]
+                        ]
+                }
+        ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1],
+                inputs.PATH_PR1[2],
+                inputs.PATH_PR3[0]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: input,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: 404 returned during unlink', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [ input[0], input[1] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1]
+        ];
+
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                if (p === inputs.PATH_PR1[0]) {
+                        ucb(new Error('simulated 404'), {
+                                statusCode: 404
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        console.log(paths, expected);
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+
+test('parts: error returned during unlink', function (t) {
+        /*
+         * Deliberately fail a request for one of the part unlinks.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [ input[0], input[1] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0],
+                inputs.PATH_PR1[0],
+                inputs.PATH_PR1[1]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                // Fail one of the requests.
+                if (p === inputs.PATH_PR1[0]) {
+                        ucb(new Error('simulated server error'), {
+                                statusCode: 503
+                        });
+                } else {
+                        var res = {
+                                statusCode: 204
+                        };
+
+                        ucb(null, res);
+                }
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+                var login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(null, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
+
+test('parts: error returned during getAccountById', function (t) {
+        /*
+         * Deliberately fail a request for one of the uuid lookups from mahi.
+         * We expect to see that batch dropped from the stream, but everything
+         * else to continue working.
+         */
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2
+                }
+        ];
+
+        var output = [ input[0], input[2] ];
+
+        var paths = [];
+        var expected = [
+                inputs.PATH_PR0[0]
+        ];
+        function unlink(p, opts, ucb) {
+                t.ok(typeof (opts) === 'object');
+                t.ok(jsprim.deepEqual(opts, {
+                        query: {
+                                allowMpuDeletes: true
+                        }
+                }));
+                paths.push(p);
+
+                var res = {
+                        statusCode: 204
+                };
+
+                ucb(null, res);
+        }
+
+        function getAccountById(uuid, gcb) {
+                t.ok(uuid === inputs.ACCT_ID_0 ||
+                        uuid === inputs.ACCT_ID_1 ||
+                        uuid == inputs.ACCT_ID_2, 'uuid mismatch');
+
+                var err, login;
+                if (uuid === inputs.ACCT_ID_0) {
+                        login = inputs.ACCT_LOGIN_0;
+                } else if (uuid === inputs.ACCT_ID_1) {
+                        login = inputs.ACCT_LOGIN_1;
+                        err = new Error('simulated mahi error');
+                } else {
+                        login = inputs.ACCT_LOGIN_2;
+                }
+
+                gcb(err, {
+                        account: {
+                                login: login
+                        }
+                });
+        }
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.ok(jsprim.deepEqual(paths, expected));
+                        t.done();
+                },
+                unlinkFunc: unlink,
+                getAccountByIdFunc: getAccountById,
+                type: mulrs.MULRS_TYPE_PART
+        };
+
+        testMpuUnlinkLiveRecordStream(args);
+});
diff --git a/test/mpu/mpuVerifyStream.test.js b/test/mpu/mpuVerifyStream.test.js
new file mode 100644
index 0000000..6436e24
--- /dev/null
+++ b/test/mpu/mpuVerifyStream.test.js
@@ -0,0 +1,829 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+
+///--- Globals
+
+var assert = require('assert-plus');
+var stream = require('stream');
+
+var helper = require('../helper');
+var inputs = require('./testInputs');
+var mpu = require('../../lib/mpu');
+var test = helper.test;
+
+var LOG = helper.createLogger('mpuVerifyStream test');
+
+var MVS_ARGS = {
+        log: LOG
+};
+
+///--- Helpers
+
+function testMpuVerifyStream(args) {
+        assert.object(args, 'args');
+        assert.arrayOfObject(args.input, 'args.input');
+        assert.arrayOfObject(args.output, 'args.output');
+        assert.func(args.testCb, 'args.testCb');
+
+        var vsArgs = {
+                cb: args.testCb,
+                expect: args.output
+        };
+
+        var mvs = new mpu.createMpuVerifyStream(MVS_ARGS);
+        var vs = new inputs.ValidationStream(vsArgs);
+        var r = new stream.Readable({
+                objectMode: true
+        });
+
+        args.input.forEach(function (i) {
+                r.push(i);
+        });
+        r.push(null);
+        r.pipe(mvs).pipe(vs);
+}
+
+///--- Tests
+
+test('single-record batch (FR only, commit)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: undefined,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('single-record batch (FR only, abort)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: undefined,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+
+test('multiple-record batch (FR, UR)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple-record batch (1 part)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple-record batch (3 parts)', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple batches', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+// Bad Input: We expect batches with bad input to be dropped from the stream.
+
+test('batch with different upload ids between FR and UR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('batch with different upload ids between FR and PR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+test('batch with different upload ids between UR and PR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+
+test('batch with different upload ids: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR1[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('missing FR', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('missing FR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_1,
+                        finalizingRecord: inputs.OBJ_FR1,
+                        uploadRecord: inputs.OBJ_UR1,
+                        partRecords: [
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_FR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: multiple batches', function (t) {
+        var input = [
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple UR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_UR1
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('multiple FR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_UR1,
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('parts but no UR: one batch', function (t) {
+        var input = [
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1]
+                        ]
+                }
+        ];
+
+        var output = [];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
+
+test('parts but no UR: multiple batches', function (t) {
+        var input = [
+                // valid batch
+                {
+                        uploadId: inputs.ID_0,
+                        records: [
+                                inputs.OBJ_FR0,
+                                inputs.OBJ_UR0,
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                // valid batch
+                {
+                        uploadId: inputs.ID_2,
+                        records: [
+                                inputs.OBJ_FR2,
+                                inputs.OBJ_UR2
+                        ]
+                },
+                // invalid batch
+                {
+                        uploadId: inputs.ID_1,
+                        records: [
+                                inputs.OBJ_FR1,
+                                inputs.OBJ_PR1[0],
+                                inputs.OBJ_PR1[1],
+                                inputs.OBJ_PR1[2]
+                        ]
+                }
+        ];
+
+        var output = [
+                {
+                        uploadId: inputs.ID_0,
+                        finalizingRecord: inputs.OBJ_FR0,
+                        uploadRecord: inputs.OBJ_UR0,
+                        partRecords: [
+                                inputs.OBJ_PR0[0]
+                        ]
+                },
+                {
+                        uploadId: inputs.ID_2,
+                        finalizingRecord: inputs.OBJ_FR2,
+                        uploadRecord: inputs.OBJ_UR2,
+                        partRecords: undefined
+                }
+        ];
+
+        var args = {
+                input: input,
+                output: output,
+                testCb: function cb(ok, actual) {
+                        t.ok(ok, 'valid stream output');
+                        if (!ok) {
+                                console.error('invalid output', actual);
+                        }
+                        t.done();
+                }
+        };
+
+        testMpuVerifyStream(args);
+});
diff --git a/test/mpu/testInputs.js b/test/mpu/testInputs.js
new file mode 100644
index 0000000..fff3883
--- /dev/null
+++ b/test/mpu/testInputs.js
@@ -0,0 +1,320 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var jsprim = require('jsprim');
+var stream = require('stream');
+var util = require('util');
+
+var mpuCommon = require('../../lib/mpu/common');
+
+
+///--- Globals
+
+var MORAY_1 = '1.moray.coal.joyent.us';
+var MORAY_2 = '2.moray.coal.joyent.us';
+
+
+// Batch 0: Committed MPU with finalizing record, upload record, 1 part records
+var ID_0 = '07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var DATE_0 =  new Date();
+var SHARD_0 =  MORAY_1;
+/* BEGIN JSSTYLED */
+var KEY_FR0 = '07cff761-33c7-c9ad-a9a0-d3303afa1490:/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/stor/batch0';
+var KEY_UR0 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var KEY_PR0_0 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490/0';
+/* END JSSTYLED */
+var FR_0 = [ ID_0, '0_finalizingRecord', DATE_0, SHARD_0, 'commit', KEY_FR0 ]
+        .join('\t');
+var UR_0 = [ ID_0, '1_uploadRecord', DATE_0, KEY_UR0 ].join('\t');
+var PR_0 = [ [ ID_0, '2_partRecord', DATE_0, KEY_PR0_0 ].join('\t') ];
+var OBJ_FR0 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_0,
+        key: KEY_FR0,
+        shard: SHARD_0,
+        date: DATE_0,
+        type: 'commit'
+});
+assert.object(OBJ_FR0, 'failed to create test finalizing record 0 obj');
+var OBJ_UR0 = new mpuCommon.LiveRecord({
+        uploadId: ID_0,
+        key: KEY_UR0,
+        date: DATE_0,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR0, 'failed to create test upload record 0 obj');
+var OBJ_PR0 = [
+        new mpuCommon.LiveRecord({
+                uploadId: ID_0,
+                key: KEY_PR0_0,
+                date: DATE_0,
+                type: 'partRecord'
+        })
+];
+OBJ_PR0.forEach(function (o) {
+        assert.object(o, 'failed to create test part record 0 obj');
+});
+var ACCT_ID_0 = '4204a7f8-3d97-ec27-c16d-f2f49366cc3c';
+var ACCT_LOGIN_0 = 'testuser0';
+var PATH_UR0 = '/' + ACCT_LOGIN_0 +
+        '/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490';
+var PATH_PR0 = [
+        '/' + ACCT_LOGIN_0 + '/uploads/0/07cff761-33c7-c9ad-a9a0-d3303afa1490/0'
+];
+
+
+// Batch 1: Aborted MPU with finalizing record, upload record, 3 part records
+var ACCT_ID_1 = 'fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8';
+var ACCT_LOGIN_1 = 'testuser1';
+var PATH_UR1 = '/' + ACCT_LOGIN_1 +
+        '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var PATH_PR1 = [
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/0',
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/1',
+        '/' + ACCT_LOGIN_1 +
+                '/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/2'
+];
+
+var ID_1 = 'c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var DATE_1 =  new Date();
+var SHARD_1 =  MORAY_1;
+/* BEGIN JSSTYLED */
+var KEY_FR1 = 'c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a:/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/stor/batch1';
+var KEY_UR1 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a';
+var KEY_PR1_0 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/0';
+var KEY_PR1_1 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/1';
+var KEY_PR1_2 = '/fdfe27dc-64bc-11e6-90f8-47c1ceb05dd8/uploads/c/c46e3e66-4311-6a11-8cf9-8d3fa69aaf0a/2';
+/* END JSSTYLED */
+var FR_1 = [ ID_1, '0_finalizingRecord', DATE_1, SHARD_1, 'abort', KEY_FR1 ]
+        .join('\t');
+var UR_1 = [ ID_1, '1_uploadRecord', DATE_1, KEY_UR1 ].join('\t');
+var PR_1 = [ [ ID_1, '2_partRecord', DATE_1, KEY_PR1_0 ].join('\t'),
+             [ ID_1, '2_partRecord', DATE_1, KEY_PR1_1 ].join('\t'),
+             [ ID_1, '2_partRecord', DATE_1, KEY_PR1_2 ].join('\t')
+];
+var OBJ_FR1 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_1,
+        key: KEY_FR1,
+        shard: SHARD_1,
+        date: DATE_1,
+        type: 'abort'
+});
+assert.object(OBJ_FR1, 'failed to create test finalizing record 1 obj');
+var OBJ_UR1 = new mpuCommon.LiveRecord({
+        uploadId: ID_1,
+        key: KEY_UR1,
+        date: DATE_1,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR1, 'failed to create test upload record 1 obj');
+var OBJ_PR1 = [
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_0,
+                date: DATE_1,
+                type: 'partRecord'
+        }),
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_1,
+                date: DATE_1,
+                type: 'partRecord'
+        }),
+        new mpuCommon.LiveRecord({
+                uploadId: ID_1,
+                key: KEY_PR1_2,
+                date: DATE_1,
+                type: 'partRecord'
+        })
+];
+OBJ_PR1.forEach(function (o) {
+        assert.object(o, 'failed to create test part record 1 objs');
+});
+
+
+// Batch 2: Committed MPU with finalizing record, upload record
+var ACCT_ID_2 = '88af09d7-4845-e09a-8998-d7d04a88b879';
+var ACCT_LOGIN_2 = 'testuser2';
+var PATH_UR2 = '/' + ACCT_LOGIN_2 +
+        '/uploads/3/38aecc30-9a8c-63a4-f906-e512f02f5915';
+
+var ID_2 = '38aecc30-9a8c-63a4-f906-e512f02f5915';
+var DATE_2 =  new Date();
+var SHARD_2 =  MORAY_2;
+/* BEGIN JSSTYLED */
+var KEY_FR2 = '38aecc30-9a8c-63a4-f906-e512f02f5915:/88af09d7-4845-e09a-8998-d7d04a88b879/stor/batch2';
+var KEY_UR2 = '/88af09d7-4845-e09a-8998-d7d04a88b879/uploads/3/38aecc30-9a8c-63a4-f906-e512f02f5915';
+/* END JSSTYLED */
+var FR_2 = [ ID_2, '0_finalizingRecord', DATE_2, SHARD_2, 'abort', KEY_FR2 ]
+        .join('\t');
+var UR_2 = [ ID_2, '1_uploadRecord', DATE_2, KEY_UR2 ].join('\t');
+var OBJ_FR2 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_2,
+        key: KEY_FR2,
+        shard: SHARD_2,
+        date: DATE_2,
+        type: 'abort'
+});
+assert.object(OBJ_FR2, 'failed to create test finalizing record 2 obj');
+var OBJ_UR2 = new mpuCommon.LiveRecord({
+        uploadId: ID_2,
+        key: KEY_UR2,
+        date: DATE_2,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR2, 'failed to create test upload record 2 obj');
+
+
+// Batch 3: Committed MPU with finalizing record, upload record, 1 part records,
+// and account uuid different from object path account
+var ID_3 = 'b3d58ef4-2277-4248-8cf0-c4243c4b0f83';
+var DATE_3 =  new Date();
+var SHARD_3 =  MORAY_2;
+/* BEGIN JSSTYLED */
+var KEY_FR3 = ID_3 + ':/1293dc6e-05a3-4651-baa3-1f74932f81b3/stor/batch3';
+var KEY_UR3 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/b/b3d58ef4-2277-4248-8cf0-c4243c4b0f83';
+var KEY_PR3_0 = '/4204a7f8-3d97-ec27-c16d-f2f49366cc3c/uploads/b/b3d58ef4-2277-4248-8cf0-c4243c4b0f83/0';
+/* END JSSTYLED */
+var FR_3 = [ ID_3, '0_finalizingRecord', DATE_3, SHARD_3, 'commit', KEY_FR3 ]
+        .join('\t');
+var UR_3 = [ ID_3, '1_uploadRecord', DATE_3, KEY_UR3 ].join('\t');
+var PR_3 = [ [ ID_3, '2_partRecord', DATE_3, KEY_PR3_0 ].join('\t') ];
+var OBJ_FR3 = new mpuCommon.FinalizingRecord({
+        uploadId: ID_3,
+        key: KEY_FR3,
+        shard: SHARD_3,
+        date: DATE_3,
+        type: 'commit'
+});
+assert.object(OBJ_FR3, 'failed to create test finalizing record 3 obj');
+var OBJ_UR3 = new mpuCommon.LiveRecord({
+        uploadId: ID_3,
+        key: KEY_UR3,
+        date: DATE_3,
+        type: 'uploadRecord'
+});
+assert.object(OBJ_UR3, 'failed to create test upload record 3 obj');
+var OBJ_PR3 = [
+        new mpuCommon.LiveRecord({
+                uploadId: ID_3,
+                key: KEY_PR3_0,
+                date: DATE_3,
+                type: 'partRecord'
+        })
+];
+OBJ_PR3.forEach(function (o) {
+        assert.object(o, 'failed to create test part record 3 obj');
+});
+var ACCT_ID_3 = '4204a7f8-3d97-ec27-c16d-f2f49366cc3c';
+var ACCT_LOGIN_3 = 'testuser0';
+var PATH_UR3 = '/' + ACCT_LOGIN_3 +
+        '/uploads/b/b3d58ef4-2277-4248-8cf0-c4243c4b0f83';
+var PATH_PR3 = [
+        '/' + ACCT_LOGIN_3 + '/uploads/b/b3d58ef4-2277-4248-8cf0-c4243c4b0f83/0'
+];
+
+
+function ValidationStream(args) {
+        assert.object(args, 'args');
+        assert.func(args.cb, 'args.cb');
+        assert.array(args.expect, 'args.expect');
+
+        stream.Writable.call(this, {
+            objectMode: true,
+            highWaterMark: 0
+        });
+
+        var self = this;
+        self.vs_received = [];
+
+        self._write = function _write(chunk, _, cb) {
+                self.vs_received.push(chunk);
+                cb();
+        };
+
+        self.on('finish', function onFinish() {
+                var ok = jsprim.deepEqual(self.vs_received, args.expect);
+                args.cb(ok, self.vs_received);
+        });
+}
+util.inherits(ValidationStream, stream.Writable);
+
+
+module.exports = {
+        ID_0: ID_0,
+        DATE_0: DATE_0,
+        SHARD_0: SHARD_0,
+        KEY_FR0: KEY_FR0,
+        KEY_UR0: KEY_UR0,
+        KEY_PR0_0: KEY_PR0_0,
+        FR_0: FR_0,
+        UR_0: UR_0,
+        PR_0: PR_0,
+        OBJ_FR0: OBJ_FR0,
+        OBJ_UR0: OBJ_UR0,
+        OBJ_PR0: OBJ_PR0,
+        ACCT_ID_0: ACCT_ID_0,
+        ACCT_LOGIN_0: ACCT_LOGIN_0,
+        PATH_UR0: PATH_UR0,
+        PATH_PR0: PATH_PR0,
+
+        ID_1: ID_1,
+        DATE_1: DATE_1,
+        SHARD_1: SHARD_1,
+        KEY_FR1: KEY_FR1,
+        KEY_UR1: KEY_UR1,
+        KEY_PR1_0: KEY_PR1_0,
+        KEY_PR1_1: KEY_PR1_1,
+        KEY_PR1_2: KEY_PR1_2,
+        FR_1: FR_1,
+        UR_1: UR_1,
+        PR_1: PR_1,
+        OBJ_FR1: OBJ_FR1,
+        OBJ_UR1: OBJ_UR1,
+        OBJ_PR1: OBJ_PR1,
+        ACCT_ID_1: ACCT_ID_1,
+        ACCT_LOGIN_1: ACCT_LOGIN_1,
+        PATH_UR1: PATH_UR1,
+        PATH_PR1: PATH_PR1,
+
+        ID_2: ID_2,
+        DATE_2: DATE_2,
+        SHARD_2: SHARD_2,
+        KEY_FR2: KEY_FR2,
+        KEY_UR2: KEY_UR2,
+        FR_2: FR_2,
+        UR_2: UR_2,
+        OBJ_FR2: OBJ_FR2,
+        OBJ_UR2: OBJ_UR2,
+        ACCT_ID_2: ACCT_ID_2,
+        ACCT_LOGIN_2: ACCT_LOGIN_2,
+        PATH_UR2: PATH_UR2,
+
+        ID_3: ID_3,
+        DATE_3: DATE_3,
+        SHARD_3: SHARD_3,
+        KEY_FR3: KEY_FR3,
+        KEY_UR3: KEY_UR3,
+        KEY_PR3_0: KEY_PR3_0,
+        FR_3: FR_3,
+        UR_3: UR_3,
+        PR_3: PR_3,
+        OBJ_FR3: OBJ_FR3,
+        OBJ_UR3: OBJ_UR3,
+        OBJ_PR3: OBJ_PR3,
+        ACCT_ID_3: ACCT_ID_3,
+        ACCT_LOGIN_3: ACCT_LOGIN_3,
+        PATH_UR3: PATH_UR3,
+        PATH_PR3: PATH_PR3,
+
+        ValidationStream: ValidationStream
+};
diff --git a/test/mpu_garbage_collector.test.js b/test/mpu_garbage_collector.test.js
new file mode 100644
index 0000000..a49ce1d
--- /dev/null
+++ b/test/mpu_garbage_collector.test.js
@@ -0,0 +1,1238 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var jsprim = require('jsprim');
+var libuuid = require('libuuid');
+var util = require('util');
+var vstream = require('vstream');
+
+var helper = require('./helper.js');
+var lib = require('../lib');
+var mpuCommon = require('../lib/mpu/common');
+var MemoryStream = require('memorystream');
+
+
+///--- Globals
+
+var DEF_GRACE_PERIOD_MILLIS = 60 * 60 * 24 * 2 * 1000; // 2 days
+var MORAY_1 = '1.moray.coal.joyent.us';
+var MORAY_2 = '2.moray.coal.joyent.us';
+
+var OWNER_0 = libuuid.create();
+var OWNER_1 = libuuid.create();
+var ID_0 = libuuid.create();
+var ID_1 = libuuid.create();
+var ID_2 = libuuid.create();
+var ID_3 = libuuid.create();
+
+var DATE_GC = new Date('2017-08-30T00:00:00');
+var DATE_OUTSIDE_GP = new Date('2017-08-27T00:00:00');
+var DATE_WITHIN_GP = new Date('2017-08-29T00:00:00');
+
+var LOG = bunyan.createLogger({
+        level: process.env.LOG_LEVEL || 'info',
+        name: 'mpu_garbage_collector_test',
+        stream: process.stdout,
+        serializers: bunyan.stdSerializers
+});
+
+var test = helper.test;
+
+
+///--- Helpers
+
+function uploadRecord(id, date, key) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+
+        return (id + '\t1_uploadRecord\t' + date + '\t' + key);
+}
+
+function partRecord(id, date, key) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+
+        return (id + '\t2_partRecord\t' + date + '\t' + key);
+}
+
+function commitRecord(id, date, owner, shard) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(owner, 'owner');
+        assert.string(shard, 'shard');
+
+        var key = finalizingRecordKey(id, owner);
+
+        return (id + '\t0_finalizingRecord\t' + date + '\t' + shard +
+                '\tcommit\t' + key);
+}
+
+function abortRecord(id, date, key, shard) {
+        assert.uuid(id, 'id');
+        assert.string(date, 'date');
+        assert.string(key, 'key');
+        assert.string(shard, 'shard');
+
+        return (id + '\t0_finalizingRecord\t' + date + '\t' + shard +
+                '\tabort\t' + key);
+}
+
+function checkMoray(moray, morayHostname, objectId, date) {
+        assert.equal(moray.morayHostname, morayHostname);
+        assert.equal(moray.objectId, objectId);
+        assert.equal(moray.date - 0, date - 0);
+}
+
+function partRecordKey(id, owner, partNum) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+        assert.number(partNum, 'partNum');
+        assert.ok(partNum >= 0 && partNum < 10000, 'invalid partNum');
+
+        return ('/' + owner + '/uploads/' + id.substring(0, 2) + '/' + id +
+                '/' + partNum);
+}
+
+function uploadRecordKey(id, owner) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+
+        return ('/' + owner + '/uploads/' + id.substring(0, 2) + '/' + id);
+}
+
+function finalizingRecordKey(id, owner) {
+        assert.uuid(id, 'id');
+        assert.uuid(owner, 'owner');
+
+        return (id + ':' + uploadRecordKey(id, owner));
+}
+
+///--- Tests: all within grace period
+
+test('single batch: finalizing record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: upload record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: part record only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: upload and part records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalizing record and upload record', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalizing record, upload record, part records',
+function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing records only', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_0, MORAY_2),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_1),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_1, MORAY_2),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        inputs.forEach(function (r) {
+                if (r !== '') {
+                        expect.push(mpuCommon.recordToObject(r));
+                }
+        });
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all upload records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all part records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // not finalized
+                partRecord(ID_1, date, partRecordKey(ID_1, OWNER_1, 0)),
+
+                // not finalized
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('no finalizing records', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+                partRecord(ID_1, date, partRecordKey(ID_1, OWNER_1, 0)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[10]));
+        expect.push(mpuCommon.recordToObject(inputs[11]));
+        expect.push(mpuCommon.recordToObject(inputs[12]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('finalizing record only batch at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // not finalized
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, date, partRecordKey(ID_3, OWNER_0, 0)),
+
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('upload record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                abortRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('upload record only batch at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_0, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // not finalized
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('part record only batch at beginning', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                commitRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+
+        expect.push(mpuCommon.recordToObject(inputs[9]));
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+
+});
+
+test('part record at end', function (t) {
+        var date = DATE_OUTSIDE_GP.toISOString();
+
+        var inputs = [
+                // finalized
+                commitRecord(ID_1, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, date, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized
+                abortRecord(ID_2, date, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, date, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, date, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized
+                commitRecord(ID_3, date, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, date, uploadRecordKey(ID_3, OWNER_0)),
+
+                // not finalized
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[5]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+
+        expect.push(mpuCommon.recordToObject(inputs[8]));
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+
+///--- Tests: testing grace period
+
+test('single batch: finalizing record only, within grace period',
+function (t) {
+        var date = DATE_WITHIN_GP.toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, date, OWNER_0, MORAY_1),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: multiple records, within grace period', function (t) {
+        var date = DATE_WITHIN_GP.toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalized, barely within grace period',
+function (t) {
+        var ms = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS + 1000;
+        var date = new Date(ms).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('single batch: finalized, barely outside grace period',
+function (t) {
+        var ms = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS - 1000;
+        var date = new Date(ms).toISOString();
+
+        var inputs = [
+                // finalized, outside grace period
+                abortRecord(ID_0, date, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, date, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, date, partRecordKey(ID_0, OWNER_0, 2)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+        expect.push(mpuCommon.recordToObject(inputs[1]));
+        expect.push(mpuCommon.recordToObject(inputs[2]));
+        expect.push(mpuCommon.recordToObject(inputs[3]));
+        expect.push(mpuCommon.recordToObject(inputs[4]));
+        expect.push(mpuCommon.recordToObject(inputs[0]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized, some within grace period', function (t) {
+        var outsideGpMs = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS - 1000;
+        var outsideGp = new Date(outsideGpMs).toISOString();
+
+        var withinGpMs = DATE_GC.valueOf() - DEF_GRACE_PERIOD_MILLIS + 1000;
+        var withinGp = new Date(withinGpMs).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, withinGp, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, withinGp, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized, outside grace period
+                commitRecord(ID_1, outsideGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, outsideGp, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized, within grace period
+                abortRecord(ID_2, withinGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, withinGp, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized, outside grace period
+                abortRecord(ID_3, outsideGp, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, outsideGp, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, outsideGp, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
+
+test('all finalized, some within custom grace period', function (t) {
+        var gracePeriod = 1000;
+
+        var outsideGpMs = DATE_GC.valueOf() - gracePeriod - 1000;
+        var outsideGp = new Date(outsideGpMs).toISOString();
+
+        var withinGpMs = DATE_GC.valueOf() - gracePeriod + 1000;
+        var withinGp = new Date(withinGpMs).toISOString();
+
+        var inputs = [
+                // finalized, within grace period
+                commitRecord(ID_0, withinGp, OWNER_0, MORAY_1),
+                uploadRecord(ID_0, withinGp, uploadRecordKey(ID_0, OWNER_0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 0)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 1)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 2)),
+                partRecord(ID_0, withinGp, partRecordKey(ID_0, OWNER_0, 3)),
+
+                // finalized, outside grace period
+                commitRecord(ID_1, outsideGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_1, outsideGp, uploadRecordKey(ID_1, OWNER_1)),
+
+                // finalized, within grace period
+                abortRecord(ID_2, withinGp, OWNER_1, MORAY_2),
+                uploadRecord(ID_2, withinGp, uploadRecordKey(ID_2, OWNER_1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 0)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 1)),
+                partRecord(ID_2, withinGp, partRecordKey(ID_2, OWNER_1, 2)),
+
+                // finalized, outside grace period
+                abortRecord(ID_3, outsideGp, OWNER_0, MORAY_2),
+                uploadRecord(ID_3, outsideGp, uploadRecordKey(ID_3, OWNER_0)),
+                partRecord(ID_3, outsideGp, partRecordKey(ID_3, OWNER_0, 0)),
+
+                ''
+        ];
+
+        var stream = new MemoryStream(inputs.join('\n'));
+        var gc = lib.createMpuGarbageCollector({
+                reader: stream,
+                gcDate: DATE_GC,
+                log: LOG,
+                gracePeriodMillis: gracePeriod
+        });
+        var expect = [];
+
+        expect.push(mpuCommon.recordToObject(inputs[7]));
+        expect.push(mpuCommon.recordToObject(inputs[6]));
+
+        expect.push(mpuCommon.recordToObject(inputs[14]));
+        expect.push(mpuCommon.recordToObject(inputs[15]));
+        expect.push(mpuCommon.recordToObject(inputs[13]));
+
+        var output = [];
+
+        gc.on('mpuCleanup', function (action) {
+                output.push(action);
+        });
+
+        gc.on('end', function () {
+                t.ok(jsprim.deepEqual(expect, output));
+                t.done();
+        });
+
+        process.nextTick(function () {
+                stream.end();
+        });
+});
