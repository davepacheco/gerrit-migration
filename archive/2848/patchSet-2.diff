commit 8f012e372f7ec26d52e54cee298e7bfc75dad43d (refs/changes/48/2848/2)
Author: Julien Gilli <julien.gilli@joyent.com>
Date:   2017-11-01T18:25:16-07:00 (1 year, 11 months ago)
    
    ZAPI-805 VM.internal_metadata field should be searchable

diff --git a/docs/index.md b/docs/index.md
index 18d7c2d..94411d9 100644
--- a/docs/index.md
+++ b/docs/index.md
@@ -388,6 +388,14 @@ following is the format of the ping response object.
             "error": "latest error encountered during moray buckets initialization"
           }
         }
+      },
+      "dataMigrations": {
+        "latestCompletedMigrations": {
+          "vms": 1
+        },
+        "latestErrors": {
+          "vms": "Error: error encountered during data migrations"
+        }
       }
     }
 
@@ -413,6 +421,18 @@ The `initialization.moray.status` property can have the following values:
 * `FAILED`: the moray buckets initialization has failed with a non transient
   error.
 
+The `dataMigrations` property is composed of two sub-properties:
+
+1. `latestCompletedMigrations`: an object that has properties whose names
+   identify data models (`vms`, `server_vms`, `vm_role_tags`) and whose values
+   indicate the sequence number of the latest migrations that completed
+   successfully for that model.
+
+2. `latestErrors`: an object structured similarly to
+   `latestCompletedMigrations`, but instead of values identifiying the latest
+   migration that completed successfully, they represent the latest error that
+   occured when migration the data for the corresponding data model.
+
 # VMs
 
 The Vms endpoint let us get information about VMs living on a SDC install; there is only one VMAPI instance per datacenter. VMAPI acts as an HTTP interface to VM data stored in Moray. VMAPI is used to obtain information about particular VMs, or when we need perform actions on them -- such as start, reboot, resize, etc.
@@ -428,22 +448,23 @@ will result in a request error.
 
 | Param            | Type                                             | Description                                     |
 | ---------------- | ------------------------------------------------ | ----------------------------------------------- |
-| uuid             | UUID                                             | VM uuid                                         |
-| owner_uuid       | UUID                                             | VM Owner                                        |
-| server_uuid      | UUID                                             | Server where the VM lives                       |
-| image_uuid       | UUID                                             | Image of the VM                                 |
+| alias            | String                                           | VM Alias|
 | billing_id       | UUID                                             | UUID of the package the VM was created with     |
 | brand            | String                                           | Brand of the VM (joyent, joyent-minimal or kvm) |
-| docker           | Boolean                                          | true if the VM is a docker VM, false otherwise  |
-| alias            | String                                           | VM Alias                                        |
-| state            | String                                           | running, stopped, active or destroyed           |
-| ram              | Number                                           | Amount of memory of the VM                      |
-| uuids            | String (comma-separated UUID values)             | List of VM UUIDs to match                       |
 | create_timestamp | Unix Time in milliseconds or UTC ISO Date String | VM creation timestamp                           |
+| docker           | Boolean                                          | true if the VM is a docker VM, false otherwise  |
+| fields           | String (comma-separated values)                  | Specify which VM fields to return, see below    |
+| image_uuid       | UUID                                             | Image of the VM                                 |
+| internal_metadata| String                                           | VM internal metadata, [see below](#internal-metadata)
+| owner_uuid       | UUID                                             | VM Owner                                        |
 | package_name     | String                                           | DEPRECATED: use billing_id                      |
 | package_version  | String                                           | DEPRECATED: use billing_id                      |
+| uuid             | UUID                                             | VM uuid                                         |
+| ram              | Number                                           | Amount of memory of the VM                      |
+| server_uuid      | UUID                                             | Server where the VM lives                       |
+| state            | String                                           | running, stopped, active or destroyed           |
+| uuids            | String (comma-separated UUID values)             | List of VM UUIDs to match                       |
 | tag.key          | String                                           | VM tags, see below                              |
-| fields           | String (comma-separated values)                  | Specify which VM fields to return, see below    |
 
 ### Specifying VM Fields to Return
 
@@ -678,6 +699,27 @@ result in a request error.
 
 VMs can also be searched by tags. Tags are key/value pairs that let us identify a vm by client-specific criteria. If a VM is tagged as 'role=master', then the search filter to be added to the request params should be 'tag.role=master'. When a tag value is '*', the search is performed for VMs that are tagged with any value of the specified key. Any number of tags can be specified. See the examples section for sample searches of VMs by tags.
 
+### Internal metadata
+
+VMs can be searched by internal metadata. Internal metadata is an object with
+keys and values that are always strings. There are no nested objects/properties.
+Pattern matching is not available, so matching needs to be exact.
+
+For example, to search for VMs with a `docker:logdriver` internal metadata key
+with a value of `"json-file"`, one can send the following query:
+
+```
+GET /vms?internal_metadata.docker:logdriver=json-file
+```
+
+There's two limitations to keep in mind:
+
+1. it is currently not possible to match a string in a given internal metadata
+   key that is larger than 100 characters
+
+2. it is currently not possible to match a string in a given internal metadata
+   key that represents an object
+
 ### ListVms Responses
 
 | Code | Description | Response            |
diff --git a/lib/apis/moray.js b/lib/apis/moray.js
index c314a3d..1f65c3e 100644
--- a/lib/apis/moray.js
+++ b/lib/apis/moray.js
@@ -32,6 +32,7 @@ var ldapjs = require('ldap-filter');
 var once = require('once');
 var restify = require('restify');
 var sprintf = require('sprintf').sprintf;
+var strsplit = require('strsplit');
 var util = require('util');
 var vasync = require('vasync');
 var verror = require('verror');
@@ -39,57 +40,142 @@ var verror = require('verror');
 var errors = require('../errors');
 var common = require('../common');
 
-var SELECT_ALL_FILTER = '(uuid=*)';
-var PARAM_FILTER = '(%s=%s)';
-var PARAM_FILTER_GE = '(%s>=%s)';
-var PARAM_FILTER_LE = '(%s<=%s)';
-var PARAM_FILTER_NE = '(!(%s=%s))';
-
 // Fields that are deprecated that we're going to remove from VMs as we put
 var DEPRECATED_VM_FIELDS = [
     'package_name',
     'package_version'
 ];
-
+var PARAM_FILTER = '(%s=%s)';
+var PARAM_FILTER_GE = '(%s>=%s)';
+var PARAM_FILTER_LE = '(%s<=%s)';
+var PARAM_FILTER_NE = '(!(%s=%s))';
+var SELECT_ALL_FILTER = '(uuid=*)';
+var VM_OBJECTS_DATA_VERSION = 1;
 
 /*
  * The constructor for the Moray class.
  *
- * @param {Object} morayClient - the instance of a moray client that will be
- * used by this Moray instance to perform all operations on the moray database.
- *
  * @param {Object} options - an object with the following properties:
  *
- *  - {Object} log (optional): an instance of a bunyan logger that will be used
- *    to log messages.
+ *  - {Object} bucketsConfig (required): an object representing the moray
+ *    buckets to setup.
  *
  *  - {Object} changefeedPublisher (required): an instance of
  *    changefeed.Publisher that will be used to publish changes to VM objects
  *    performed via this Moray abstraction layer.
+ *
+ *  - {Object} dataMigrations (optional): an object representing the data
+ *    migrations to run for the moray buckets specified in
+ *    "options.bucketsConfig".
+ *
+ *  - {Object} log (optional): an instance of a bunyan logger that will be used
+ *    to log messages.
+ *
+ *  - {Object} morayClient - the instance of a moray client that will be used by
+ *    this Moray instance to perform all operations on the moray database.
  */
-function Moray(morayClient, options) {
-    assert.object(morayClient, 'morayClient');
+function Moray(options) {
     assert.object(options, 'options');
-    assert.optionalObject(options.log, 'options.log');
+    assert.object(options.morayClient, 'options.morayClient');
+    assert.object(options.bucketsConfig, 'options.bucketsConfig');
     assert.object(options.changefeedPublisher, 'options.changefeedPublisher');
+    assert.optionalObject(options.log, 'options.log');
 
-    this._morayClient = morayClient;
-
-    this.log = options.log || bunyan.createLogger({
+    this._bucketsConfig = options.bucketsConfig;
+    this._changefeedPublisher = options.changefeedPublisher;
+    this._log = options._log || bunyan.createLogger({
         name: 'moray',
         level: options.logLevel || 'info',
         serializers: restify.bunyan.serializers
     });
-
-    this.changefeedPublisher = options.changefeedPublisher;
+    this._morayClient = options.morayClient;
 
     this._bucketsSetup = false;
-    this._settingUpBuckets = false;
     this._lastBucketsSetupError = null;
-
     this._reindexingBuckets = false;
+    this._settingUpBuckets = false;
+
+    this._latestCompletedMigration = undefined;
+
+    _validateBucketsConfig(this._bucketsConfig);
+}
+
+/*
+ * Validates that the buckets config "bucketsConfig" is sound, which currently
+ * only means that there is some data for all three models that the application
+ * uses (vms, server_vms and vm_role_tags). The rest of validation is delegated
+ * to Moray when actually setting up the buckets in "bucketsConfig".
+ */
+function _validateBucketsConfig(bucketsConfig) {
+    assert.object(bucketsConfig, 'bucketsConfig');
+    assert.object(bucketsConfig.vms, 'bucketsConfig.vms');
+    assert.object(bucketsConfig.server_vms, 'bucketsConfig.server_vms');
+    assert.object(bucketsConfig.vm_role_tags, 'bucketsConfig.vm_role_tags');
 }
 
+/*
+ * Validates that data migrations represented by "dataMigrations" are sound. For
+ * instance, it checks that for each model that needs to be migrated, its
+ * corresponding moray bucket configuration includes a "data_version" indexed
+ * field. It also makes sure that versioning of subsequent data migrations for a
+ * given model follows a sequence.
+ */
+Moray.prototype.validateDataMigrations =
+function validateDataMigrations(dataMigrations) {
+    var bucketName;
+    var expectedDataVersion;
+    var idx;
+    var migrationsForBucket;
+
+    assert.object(this._bucketsConfig, 'this._bucketsConfig');
+    assert.object(dataMigrations, 'dataMigrations');
+
+    for (bucketName in dataMigrations) {
+        assert.ok(this._bucketsConfig[bucketName], 'bucket ' + bucketName +
+            ' should be present in buckets config');
+        assert.ok(this._bucketsConfig[bucketName].schema.index.data_version,
+            'data_version indexed field should be present in buckets config');
+
+        migrationsForBucket = dataMigrations[bucketName];
+        expectedDataVersion = 1;
+        /*
+         * Validates that all data migrations that need to be performed are
+         * valid. For instance, that their DATA_VERSION numbers are a proper
+         * sequence starting at 1, and that they export a function named
+         * "migrateRecord".
+         */
+        for (idx = 0; idx < migrationsForBucket.length; ++idx) {
+            assert.equal(migrationsForBucket[idx].DATA_VERSION,
+                expectedDataVersion, 'Data version of migration ' + (idx + 1) +
+                    ' should be ' + expectedDataVersion);
+            assert.func(migrationsForBucket[idx].migrateRecord,
+                    'migrationsForBucket[' + idx + '].migrateRecord');
+            ++expectedDataVersion;
+        }
+    }
+};
+
+/*
+ * Returns whether the application model represented by the string "modelName"
+ * is valid. Currently it means it has a representation in Moray.
+ */
+Moray.prototype.isValidModelName = function isValidModelName(modelName) {
+    assert.string(modelName, 'modelName');
+    assert.object(this._bucketsConfig, 'this._bucketsConfig');
+
+    return Object.keys(this._bucketsConfig).indexOf(modelName) !== -1;
+};
+
+/*
+ * From a string representing an application model name "modelName", returns its
+ * corresponding Moray bucket name.
+ */
+Moray.prototype._modelToBucketName = function _modelToBucketName(modelName) {
+    assert.string(modelName, 'modelName');
+    assert.ok(this._bucketsConfig[modelName], 'this._bucketsConfig[' +
+        modelName + ']');
+    return this._bucketsConfig[modelName].name;
+};
 
 /*
  * Returns true if the "err" error object represents a transient error (an error
@@ -145,50 +231,44 @@ Moray.prototype.isBucketsSetupErrorTransient =
  * calling the 'callback' function passed as a parameter. Calling this method
  * while a previous call is still in flight will throw an error.
  */
-Moray.prototype.setupBuckets =
-    function setupBuckets(bucketsConfig, callback) {
-        assert.object(bucketsConfig, 'bucketsConfig');
-        assert.object(bucketsConfig.VMS, 'bucketsConfig.VMS');
-        assert.object(bucketsConfig.SERVER_VMS, 'bucketsConfig.SERVER_VMS');
-        assert.object(bucketsConfig.VM_ROLE_TAGS, 'bucketsConfig.VM_ROLE_TAGS');
-
-        var self = this;
-        var bucketsList = [];
-        var bucketConfig;
+Moray.prototype.setupBuckets = function setupBuckets(callback) {
+    var self = this;
+    var bucketsList = [];
+    var bucketConfig;
 
-        if (self._settingUpBuckets === true) {
-            throw new Error('setupBuckets cannot be called when a setup ' +
-                'process is in progress');
-        }
+    if (self._settingUpBuckets === true) {
+        throw new Error('setupBuckets cannot be called when a setup ' +
+            'process is in progress');
+    }
 
-        self._lastBucketsSetupError = null;
-        self._settingUpBuckets = true;
+    self._lastBucketsSetupError = null;
+    self._settingUpBuckets = true;
 
-        self.log.info({bucketsConfig: bucketsConfig},
-            'Setting up moray buckets...');
+    self._log.info({bucketsConfig: self._bucketsConfig},
+        'Setting up moray buckets...');
 
-        self._VMS_BUCKET_NAME = bucketsConfig.VMS.name;
-        self._VM_ROLE_TAGS_BUCKET_NAME = bucketsConfig.VM_ROLE_TAGS.name;
+    self._VMS_BUCKET_NAME = self._bucketsConfig.vms.name;
+    self._VM_ROLE_TAGS_BUCKET_NAME = self._bucketsConfig.vm_role_tags.name;
 
-        for (bucketConfig in bucketsConfig) {
-            bucketsList.push(bucketsConfig[bucketConfig]);
-        }
+    for (bucketConfig in self._bucketsConfig) {
+        bucketsList.push(self._bucketsConfig[bucketConfig]);
+    }
 
-        self._trySetupBuckets(bucketsList, function (setupBucketsErr) {
-            self._settingUpBuckets = false;
-            self._lastBucketsSetupError = setupBucketsErr;
+    self._trySetupBuckets(bucketsList, function (setupBucketsErr) {
+        self._settingUpBuckets = false;
+        self._lastBucketsSetupError = setupBucketsErr;
 
-            if (setupBucketsErr) {
-                self.log.error({ error: setupBucketsErr },
-                    'Error when setting up moray buckets');
-            } else {
-                self.log.info('Buckets have been setup successfully');
-                self._bucketsSetup = true;
-            }
+        if (setupBucketsErr) {
+            self._log.error({ error: setupBucketsErr },
+                'Error when setting up moray buckets');
+        } else {
+            self._log.info('Buckets have been setup successfully');
+            self._bucketsSetup = true;
+        }
 
-            callback(setupBucketsErr);
-        });
-    };
+        callback(setupBucketsErr);
+    });
+};
 
 
 /*
@@ -232,7 +312,7 @@ Moray.prototype._createMorayBucketsNotSetupErrMsg =
  */
 Moray.prototype.ping = function (callback) {
     // Default ping timeout is 1 second
-    return this._morayClient.ping({ log: this.log }, callback);
+    return this._morayClient.ping({ log: this._log }, callback);
 };
 
 
@@ -421,11 +501,46 @@ Moray.prototype._vmsListParams = function (params, cb) {
     }
 
     this._addTagsFilter(params, filter);
+    _addInternalMetadataFilter(params, filter);
 
     return cb(null, filter);
 };
 
+/*
+ * Augments the LDAP filter "filter" with a filter that represents any
+ * internal_metadata search parameter in "params". We consider that any
+ * validation on such parameters already took place, and thus we consider these
+ * parameters valid.
+ */
+function _addInternalMetadataFilter(params, filter) {
+    assert.object(params, 'params');
+    assert.arrayOfString(filter, 'filter');
+
+    var FILTER_KEY = 'internal_metadata_search_array';
+    var idx;
+    var metadataKey;
+    var metadataValue;
+    var paramNames = Object.keys(params);
+    var paramName;
+
+    for (idx = 0; idx < paramNames.length; ++idx) {
+        paramName = paramNames[idx];
+        if (paramName.indexOf('internal_metadata.') === 0) {
+            /*
+             * At this point we already validated that the internal_metadata
+             * query string parameter is well formed
+             * (internal_metadata.metadata_key=value), where "metadata_key" can
+             * be any non-empty string (e.g it can have dots in it), so it's
+             * fine to parse it without handling bad formats.
+             */
+            metadataKey = strsplit(paramName, '.', 2)[1];
+            metadataValue = params[paramName];
 
+            filter.push(sprintf(PARAM_FILTER, FILTER_KEY,
+                metadataKey + '=' + metadataValue));
+        }
+    }
+}
 /*
  * This is a bit different to getVm.
  * For this one we need exactly the VM that has the provided UUID
@@ -597,7 +712,7 @@ Moray.prototype.listVms = function listVms(params, raw, cb) {
             return cb(err);
         }
 
-        self.log.info({ filter: ldapFilter }, 'listVms filter');
+        self._log.info({ filter: ldapFilter }, 'listVms filter');
 
         var vm;
         var vms = [];
@@ -658,7 +773,7 @@ Moray.prototype.countVms = function countVms(params, cb) {
             limit: 1
         };
 
-        self.log.info({ filter: string }, 'countVms filter');
+        self._log.info({ filter: string }, 'countVms filter');
         var req = self._morayClient.findObjects(self._VMS_BUCKET_NAME, string,
             options);
         var count = 0;
@@ -725,7 +840,7 @@ Moray.prototype.putVm = function putVm(uuid, vm, oldVm, cb) {
     assert.object(oldVm, 'oldVm');
     assert.func(cb, 'cb');
 
-    assert.object(self.changefeedPublisher, 'self.changefeedPublisher');
+    assert.object(self._changefeedPublisher, 'self._changefeedPublisher');
 
     var VM_CHANGEFEED_RESOURCE_NAME = 'vm';
     var vmObject = self._toMorayVm(vm);
@@ -745,40 +860,40 @@ Moray.prototype.putVm = function putVm(uuid, vm, oldVm, cb) {
     oldVm = common.translateVm(oldVm, false);
     vm = common.translateVm(vm, false);
 
-    self.log.debug({oldVm: oldVm, vm: vm}, 'putting VM');
+    self._log.debug({vmObject: vmObject, oldVm: oldVm, vm: vm}, 'putting VM');
 
     self._morayClient.putObject(self._VMS_BUCKET_NAME, uuid, vmObject,
         function onPutObj(putObjErr) {
             var diffs;
 
             if (!putObjErr) {
-                self.log.debug('VM successfully put to moray');
+                self._log.debug('VM successfully put to moray');
 
-                if (oldVm && self.changefeedPublisher) {
-                    diffs = computeDiff(oldVm, vm, self.log);
-                    self.log.debug({diffs: diffs},
+                if (oldVm && self._changefeedPublisher) {
+                    diffs = computeDiff(oldVm, vm, self._log);
+                    self._log.debug({diffs: diffs},
                         'publishing change to changefeed');
-                    common.publishChange(self.changefeedPublisher,
+                    common.publishChange(self._changefeedPublisher,
                         VM_CHANGEFEED_RESOURCE_NAME, diffs, vm.uuid,
                         function onChangePublished(publishErr) {
                             if (publishErr) {
-                                self.log.error({
+                                self._log.error({
                                     err: publishErr
                                 }, 'error when publishing change to ' +
                                     'changefeed');
                             } else {
-                                self.log.debug('change published to ' +
+                                self._log.debug('change published to ' +
                                     'changefeed successfully');
                             }
 
                             cb(publishErr);
                         });
                 } else {
-                    self.log.debug('not publishing change to changefeed');
+                    self._log.debug('not publishing change to changefeed');
                     cb(putObjErr);
                 }
             } else {
-                self.log.error({err: putObjErr},
+                self._log.error({err: putObjErr},
                     'error when putting VM to moray');
                 cb(putObjErr);
             }
@@ -1141,17 +1256,17 @@ function _trySetupBucket(bucketName, bucketConfig, cb) {
         },
         function createBucket(oldBucketSchema, next) {
             if (!oldBucketSchema) {
-                self.log.info({bucketName: bucketName},
+                self._log.info({bucketName: bucketName},
                     'Bucket not found, creating it...');
                 self._createBucket(bucketName, bucketConfig.schema,
                     function createDone(createErr) {
                         if (createErr) {
-                            self.log.error({
+                            self._log.error({
                                 bucketName: bucketName,
                                 error: createErr.toString()
                             }, 'Error when creating bucket');
                         } else {
-                            self.log.info('Bucket ' +
+                            self._log.info('Bucket ' +
                                 bucketName +
                                     ' created successfully');
                         }
@@ -1159,7 +1274,7 @@ function _trySetupBucket(bucketName, bucketConfig, cb) {
                         next(createErr, oldBucketSchema);
                     });
              } else {
-                self.log.info({bucketName: bucketName},
+                self._log.info({bucketName: bucketName},
                     'Bucket already exists, not creating it.');
                 next(null, oldBucketSchema);
             }
@@ -1206,25 +1321,25 @@ function _trySetupBucket(bucketName, bucketConfig, cb) {
                     return;
                 }
 
-                self.log.info('Updating bucket ' + bucketName + ' from ' +
+                self._log.info('Updating bucket ' + bucketName + ' from ' +
                     'version ' + oldVersion + ' to version ' + newVersion +
                     '...');
 
                 self._updateBucket(bucketName, newBucketSchema,
                     function updateDone(updateErr) {
                         if (updateErr) {
-                            self.log.error({error: updateErr},
+                            self._log.error({error: updateErr},
                                 'Error when updating bucket ' +
                                     bucketName);
                         } else {
-                            self.log.info('Bucket ' + bucketName +
+                            self._log.info('Bucket ' + bucketName +
                                 ' updated successfully');
                         }
 
                         next(updateErr);
                     });
             } else {
-                self.log.info('Bucket ' + bucketName + ' already at version ' +
+                self._log.info('Bucket ' + bucketName + ' already at version ' +
                     '>= ' + newVersion + ', no need to update it');
                 next(null);
             }
@@ -1316,6 +1431,16 @@ Moray.prototype._toMorayVm = function (vm) {
         }
     }
 
+    /*
+     * Massage the internal_metadata object and write it to the indexed
+     * internal_metadadata_search_array field in a format that is searchable.
+     */
+    assert.optionalObject(vm.internal_metadata, 'vm.internal_metadata');
+    copy.internal_metadata_search_array =
+        common.internalMetadataToSearchArray(vm.internal_metadata);
+
+    copy.data_version = VM_OBJECTS_DATA_VERSION;
+
     return copy;
 };
 
@@ -1450,21 +1575,14 @@ Moray.prototype._reindexBucket =
     };
 
 /*
- * Reindexes all buckets represented by "bucketsConfig" and calls "callback"
- * when it's done.
- *
- * @param {Object} bucketsConfig - a map associating bucket "roles" (vms,
- *   server_vms, vms_role_tags) to objects representing their respective bucket
- *   configuration.
+ * Reindexes all buckets and calls "callback" when it's done.
  *
  * @param {Function} callback - a function called when either the reindexing
  *   process is complete for all buckets, or when an error occurs. It is called
  *   as "callback(null)" if the reindexing process completed with no error, or
  *   "callback(err)"" if the error "err" occurred.
  */
-Moray.prototype.reindexBuckets =
-    function reindexBuckets(bucketsConfig, callback) {
-    assert.object(bucketsConfig, 'bucketsConfig');
+Moray.prototype.reindexBuckets = function reindexBuckets(callback) {
     assert.func(callback, 'callback');
 
     var bucketsList = [];
@@ -1478,8 +1596,8 @@ Moray.prototype.reindexBuckets =
 
     self._reindexingBuckets = true;
 
-    for (bucketConfigName in bucketsConfig) {
-        bucketsList.push(bucketsConfig[bucketConfigName]);
+    for (bucketConfigName in this._bucketsConfig) {
+        bucketsList.push(this._bucketsConfig[bucketConfigName]);
     }
 
     vasync.forEachPipeline({
@@ -1489,14 +1607,14 @@ Moray.prototype.reindexBuckets =
 
             var bucketName = bucketConfig.name;
 
-            self.log.info('Reindexing bucket ' + bucketName + '...');
+            self._log.info('Reindexing bucket ' + bucketName + '...');
 
             self._reindexBucket(bucketName, function reindexDone(reindexErr) {
                 if (reindexErr) {
-                    self.log.error({err: reindexErr},
+                    self._log.error({err: reindexErr},
                         'Error when reindexing bucket ' + bucketName);
                 } else {
-                    self.log.info('Bucket ' + bucketName +
+                    self._log.info('Bucket ' + bucketName +
                         ' reindexed successfully');
                 }
 
@@ -1510,4 +1628,174 @@ Moray.prototype.reindexBuckets =
     });
 };
 
+/*
+ * Finds the next chunk of records that need to be changed to be migrated to
+ * version "version".
+ *
+ * @param {String} modelName: the name of the model (e.g "vms", "vm_role_tags",
+ *   "server_vms") for which to find records to migrate
+ *
+ * @param {Number} version: must be >= 1.
+ *
+ * @param {Object} options:
+ *   - log {Object}: the bunyan log instance to use to output log messages.
+ *
+ * @param {Function} callback: called with two parameters: (error, records)
+ *   where "error" is any error that occurred when trying to find those records,
+ *   and "records" is an array of objects representing VM objects that need to
+ *   be changed to be migrated to version "version".
+ */
+Moray.prototype.findRecordsToMigrate =
+function findRecordsToMigrate(modelName, version, options, callback) {
+    assert.string(modelName, 'bucketName');
+    assert.number(version, 'version');
+    assert.ok(version >= 1, 'version >= 1');
+    assert.object(options, 'options');
+    assert.func(callback, 'callback');
+
+    var bucketName = this._modelToBucketName(modelName);
+    var log = this._log;
+    var morayFilter;
+    var records = [];
+    var RETRY_DELAY_IN_MS = 10000;
+    var self = this;
+
+    /*
+     * !!!! WARNING !!!!
+     *
+     *  When updating these LDAP filters, make sure that they don't break the
+     * assumption below that an InvalidQueryError can be treated as a transient
+     * error.
+     *
+     * !!!! WARNING !!!!
+     */
+    if (version === 1) {
+        /*
+         * Version 1 is special, in the sense that there's no anterior version
+         * for which data_version has a value. Instead, the version before
+         * version 1 is represented by an absence of value for the data_version
+         * field.
+         */
+        morayFilter = '(!(data_version=*))';
+    } else {
+        /*
+         * For any migration whose version number is greater than one, they only
+         * migrate records at version N - 1. This is safe because:
+         *
+         * 1. all new records created are created at the latest version
+         *    supported by VMAPI
+         *
+         * 2. migrations are always done in sequence, starting from the
+         *    migration that migrates records without a data_version to records
+         *    with a data_version === 1.
+         */
+        morayFilter = util.format('(|(!(data_version=*))(data_version=%s))',
+            version - 1);
+    }
+
+    log.debug({filter: morayFilter, version: version},
+        'generated LDAP filter to find records at version less than given ' +
+            'version');
+
+    /*
+     * It would be useful to pass either the requireIndexes: true or
+     * requireOnlineReindexing: true options to findObjects here, as that would
+     * allow us to make sure that we can actually rely on the results from this
+     * query. However:
+     *
+     * 1. We don't want to rely on a specific version of the Moray server.
+     *    Support for these options is fairly new (see
+     *    http://smartos.org/bugview/MORAY-104 and
+     *    http://smartos.org/bugview/MORAY-428) and being able to perform data
+     *    migrations is a basic requirement of the service, so we don't want to
+     *    prevent that from happening if Moray was rolled back in a DC to a
+     *    version that doesn't support those flags. Moreover, at the time data
+     *    migrations were added, the latest version of the manta-moray image in
+     *    the "support" channel of updates.joyent.com did not include MORAY-104
+     *    or MORAY-428.
+     *
+     * 2. Since this filter uses only one field, Moray already has a mechanism
+     *    that will return an InvalidQueryError in case this field is not
+     *    indexed, which effectively acts similarly to those two different
+     *    options mentioned above.
+     */
+    var req = this._morayClient.findObjects(bucketName, morayFilter);
+
+    req.once('error', function onRecordsNotAtVersionError(err) {
+        log.error({err: err},
+            'Error when finding next chunk of records to migrate');
+
+        if (verror.hasCauseWithName(err, 'InvalidQueryError')) {
+            /*
+             * We treat InvalidQueryError here as a transient error and retry
+             * when it occurs because:
+             *
+             * 1. We know that the LDAP filter passed to the findObjects request
+             *    uses only one field, and that field was added with the same
+             *    code change than this code.
+             *
+             * 2. We know that data migrations are run *after* reindexing of all
+             *    buckets is completed and successful.
+             *
+             * As a result, we can rely on this field being indexed and
+             * searchable, and we know that an InvalidQueryError is returned by
+             * the Moray server only when the bucket cache of the Moray instance
+             * that responded has not been refreshed yet.
+             */
+            log.info('Scheduling retry in ' + RETRY_DELAY_IN_MS + ' ms');
+            setTimeout(function retry() {
+                log.info({version: version},
+                        'Retrying to find records at version less than');
+                self.findRecordsToMigrate(bucketName, version, options,
+                    callback);
+            }, RETRY_DELAY_IN_MS);
+        }
+    });
+
+    req.on('record', function onRecord(record) {
+        records.push(record);
+    });
+
+    req.once('end', function onEnd() {
+        callback(null, records);
+    });
+};
+
+/*
+ * Generates a Moray batch request to PUT all objects in the array of objects
+ * "records", and call "callback" when it's done.
+ *
+ * @params {String} modelName: the name of the model (e.g "vms", "vm_role_tags",
+ *   "server_vms") for which to generate a PUT batch operation
+ *
+ * @params {ArrayOfObjects} records
+ *
+ * @params {Function} callback(err)
+ */
+Moray.prototype.putBatch = function putBatch(modelName, records, callback) {
+    assert.string(modelName, 'modelName');
+    assert.arrayOfObject(records, 'records');
+    assert.func(callback, 'callback');
+
+    var bucketName = this._modelToBucketName(modelName);
+    assert.string(bucketName, 'bucketName');
+
+    this._morayClient.batch(records.map(function generateVmPutBatch(record) {
+        return {
+            bucket: bucketName,
+            operation: 'put',
+            key: record.value.uuid,
+            value: record.value,
+            etag: record._etag
+        };
+    }), function onBatch(batchErr, meta) {
+        /*
+         * We don't care about the data in "meta" for now (the list of etags
+         * resulting from writing all records), and adding it later would be
+         * backward compatible.
+         */
+        callback(batchErr);
+    });
+};
+
 module.exports = Moray;
diff --git a/lib/common/index.js b/lib/common/index.js
index 3ff088a..153aaf7 100644
--- a/lib/common/index.js
+++ b/lib/common/index.js
@@ -29,8 +29,9 @@ function mixinModule(modulePath) {
     }
 }
 
+mixinModule('./ldap-filter');
+mixinModule('./marker');
+mixinModule('./predicate');
 mixinModule('./util');
 mixinModule('./validation');
 mixinModule('./vm-common');
-mixinModule('./predicate');
-mixinModule('./marker');
diff --git a/lib/common/ldap-filter.js b/lib/common/ldap-filter.js
new file mode 100644
index 0000000..a0e12ca
--- /dev/null
+++ b/lib/common/ldap-filter.js
@@ -0,0 +1,34 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+
+/*
+ * Returns true if the LDAP filter string "ldapFilterString" represents an LDAP
+ * filter that filters on the field with name "fieldName".
+ */
+function ldapFilterFiltersOn(fieldName, ldapFilterString) {
+    var fieldPresentRegexp;
+
+    assert.string(fieldName, 'fieldName');
+    assert.optionalString(ldapFilterString, 'ldapFilterString');
+
+    if (ldapFilterString === undefined) {
+        return false;
+    }
+
+    fieldPresentRegexp = new RegExp('\\(' + fieldName + '=');
+
+    return fieldPresentRegexp.test(ldapFilterString);
+}
+
+module.exports = {
+    ldapFilterFiltersOn: ldapFilterFiltersOn
+};
\ No newline at end of file
diff --git a/lib/common/predicate.js b/lib/common/predicate.js
index b572fbd..d80a24e 100644
--- a/lib/common/predicate.js
+++ b/lib/common/predicate.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /*
@@ -13,8 +13,10 @@
  * predicate object
  */
 
-var ASSERT = require('assert').ok;
+var assert = require('assert-plus');
+var krill = require('krill');
 var util = require('util');
+
 var format = util.format;
 
 /*
@@ -210,8 +212,11 @@ function ldapPrintRel(pred, key) {
             break;
         default:
             if (typeof (field) === 'string' &&
-                field.match(/tag\.(.*)/)) {
+                field.match(/^tag\.(.*)$/)) {
                 string = printTags(field, pred[key][1]);
+            } else if (typeof (field) === 'string' &&
+                field.match(/^internal_metadata\.(.*)$/)) {
+                string = printInternalMetadata(field, pred[key][1]);
             } else {
                 string = printKeyValue(key, field, pred[key][1]);
             }
@@ -254,6 +259,17 @@ function printTags(field, value) {
     }
 }
 
+function printInternalMetadata(field, value) {
+    assert.string(field, 'field');
+    assert.string(value, 'value');
+
+    var match = field.match(/internal_metadata\.(.*)/);
+    var metadataKey = match[1];
+
+    return format('internal_metadata_search_array=%s',
+        metadataKey + '=' + value);
+}
+
 function printKeyValue(key, k, v) {
     return k + printStrings[key] + v;
 }
@@ -303,12 +319,12 @@ function ldapPrintGen(pred)
     }
 
     if (keysFound != 1)
-        ASSERT(false, console.log('Expected only ' +
+        assert.ok(false, util.format('Expected only ' +
             'one key for the specified predicate. Found %d. Looking ' +
             'at predicate %j', keysFound, pred));
 
     if (!ldapPrintFuncs[key])
-        ASSERT(false, console.log('Missing print ' +
+        assert.ok(false, util.format('Missing print ' +
             'function for key %s. Looking at predicate %j', key,
             pred));
 
@@ -330,3 +346,52 @@ function toLdapQuery(pred)
 }
 
 exports.toLdapQuery = toLdapQuery;
+
+/*
+ * Returns true if the JSON predicate represented by "predicateString" filters
+ * on the field with name "fieldName".
+ *
+ * @params {String} fieldName
+ *
+ * @params {String} predicateString
+ *
+ * @params {ArrayOfString} polymorphicParams - an array of field names that
+ *   should be considered polymorphic. A polymorphic field name is a name that
+ *   is used in the following form: "field_name.key=value", where the string
+ *   "key" is not static, and can change from one query to another.
+ */
+function jsonPredicateFiltersOn(fieldName, predicateString, polymorphicParams) {
+    assert.string(fieldName, 'fieldName');
+    assert.optionalString(predicateString, 'predicateString');
+    assert.optionalArrayOfString(polymorphicParams, 'polymorphicParams');
+
+    var idx;
+    var krillPred;
+    var predFields;
+    var parsedJsonPred;
+    var res = false;
+
+    try {
+        parsedJsonPred = JSON.parse(predicateString);
+    } catch (parseErr) {
+        return false;
+    }
+
+    krillPred = krill.createPredicate(parsedJsonPred);
+    predFields = krillPred.fields();
+
+    if (polymorphicParams && polymorphicParams.indexOf(fieldName) !== -1) {
+        for (idx = 0; idx < predFields.length; ++idx) {
+            if (predFields[idx].indexOf(fieldName + '.') === 0) {
+                res = true;
+                break;
+            }
+        }
+    } else {
+        res = predFields.indexOf(fieldName) !== -1;
+    }
+
+    return res;
+}
+
+exports.jsonPredicateFiltersOn = jsonPredicateFiltersOn;
\ No newline at end of file
diff --git a/lib/common/validation.js b/lib/common/validation.js
index 828e900..879679e 100644
--- a/lib/common/validation.js
+++ b/lib/common/validation.js
@@ -20,6 +20,7 @@ var jsprim = require('jsprim');
 var libuuid = require('libuuid');
 var net = require('net');
 var restify = require('restify');
+var strsplit = require('strsplit');
 var tritonTags = require('triton-tags');
 var verror = require('verror');
 
@@ -29,25 +30,22 @@ var markerUtils = require('./marker');
 var predicateUtils = require('./predicate');
 var sortValidation = require('../validation/sort');
 
-var UUID_RE = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
 var ALIAS_RE = /^[a-zA-Z0-9][a-zA-Z0-9\_\.\-]*$/;
-var RAM_RE = /^0$|^([1-9][0-9]*$)/;
-var TRITON_TAG_ROOT_RE = /^triton\./;
 /* JSSTYLED */
 var DOCKER_TAG_DEFAULT_RE = /^(?:sdc_docker$|docker:label:triton\.|docker:label:(?:com|io|org)\.docker(?:project)?\.)/;
-
+var DOCKER_TAG_RE = DOCKER_TAG_DEFAULT_RE;
 // For now, using the more limited labels allowed by RFC1123. RFC2181 supercedes
 // 1123, but the broader range of characters can sometimes cause problems with
 // other systems (e.g. see the underscore in RFC5321).
 var DNS_NAME_RE = /^[a-z0-9][a-z0-9\-]{0,62}(?:\.[a-z0-9][a-z0-9\-]{0,62})*$/i;
-
 /*JSSTYLED*/
 var IP_RE = /^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$/;
+var MAX_LIST_VMS_LIMIT = 1000;
 var PW_SUFFIX = /^(.*)_pw$/;
+var RAM_RE = /^0$|^([1-9][0-9]*$)/;
+var TRITON_TAG_ROOT_RE = /^triton\./;
+var UUID_RE = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
 
-var DOCKER_TAG_RE = DOCKER_TAG_DEFAULT_RE;
-
-var MAX_LIST_VMS_LIMIT = 1000;
 exports.MAX_LIST_VMS_LIMIT = MAX_LIST_VMS_LIMIT;
 
 var VALID_VM_BRANDS = [
@@ -697,21 +695,54 @@ function createValidateTimestampFn(field, options) {
     };
 }
 
-function createValidateTagFn(options) {
+/*
+ * Validate that the polymorphic parameter with name "paramName" has a key and
+ * value that are both valid non-empty strings.
+ */
+function validatePolymorphicParamStringKeyValue(paramName, key, value) {
+    assert.string(paramName, 'paramName');
+    assert.optionalString(key, 'key');
+    assert.optionalString(value, 'value');
+
+    if (typeof (key) !== 'string' || key.length === 0) {
+        return errors.invalidParamErr(paramName,
+            'Invalid ' + paramName + ' key: ' + JSON.stringify(key));
+    }
+    if (typeof (value) !== 'string' || value.length === 0) {
+        return errors.invalidParamErr(paramName,
+            'Invalid ' + paramName + ' value: ' + JSON.stringify(value));
+    }
+}
+
+function createValidatePolymorphicParamFn(options) {
     options = options || {};
     assert.object(options, 'options');
+    assert.string(options.paramName, options.paramName);
+    assert.func(options.validationFunc, 'options.validationFunc');
 
-    return function (params) {
-        var errs = [];
-        var paramName;
-        var tagValue;
+    var paramNameToTest = options.paramName;
+    var validationFunc = options.validationFunc;
 
-        for (paramName in params) {
-            if (validatorName(paramName) === 'tag') {
-                tagValue = params[paramName];
-                if (typeof (tagValue) !== 'string') {
-                    errs.push(errors.invalidParamErr(paramName,
-                        'Invalid tag: ' + tagValue));
+    return function validatePolymorphicParam(params) {
+        var errs = [];
+        var validationErr;
+        /*
+         * E.g 'tag.some_tag_name' or 'internal_metadata.docker:cmd'.
+         */
+        var fullyQualifiedParamName;
+        var paramKey;
+        var paramValue;
+
+        for (fullyQualifiedParamName in params) {
+            paramKey = polymorphicParamKey(fullyQualifiedParamName);
+
+            if (polymorphicParamName(fullyQualifiedParamName) ===
+                paramNameToTest) {
+                paramValue = params[fullyQualifiedParamName];
+                validationErr = validationFunc(paramNameToTest,
+                        paramKey, paramValue);
+                if (validationErr) {
+                    errs.push(validationErr);
                 }
             }
         }
@@ -1410,30 +1441,37 @@ function validateListVmsParams(params, callback) {
     async.series([
         function validateSingleParams(next) {
             var listVmValidators = {
-                owner_uuid: createValidateUUIDFn('owner_uuid'),
-                server_uuid: createValidateUUIDFn('server_uuid'),
-                uuid: createValidateUUIDFn('uuid'),
-                uuids: createValidateCSVFn('uuids', validUUID),
-                brand: createValidateStringsListFn('brand', VALID_VM_BRANDS),
                 alias: createValidateStringFn('alias', {re: ALIAS_RE}),
-                state: createValidateStringsListFn('state', VALID_VM_STATES),
-                ram: createValidateStringFn('ram', {re: RAM_RE}),
-                predicate: createValidateJSONPredicateFn('predicate'),
-                query: createValidateStringFn('query'),
-                docker: createValidateBooleanFn('docker'),
-                image_uuid: createValidateUUIDFn('image_uuid'),
                 billing_id: createValidateUUIDFn('billing_id'),
+                brand: createValidateStringsListFn('brand', VALID_VM_BRANDS),
                 create_timestamp: createValidateTimestampFn('create_timestamp'),
-                package_name: createValidateStringFn('package_name'),
-                package_version: createValidateStringFn('package_version'),
+                docker: createValidateBooleanFn('docker'),
                 fields: createValidateVmFieldsFn('fields'),
-                tag: createValidateTagFn(),
-                sort: createValidateSortFn('sort'),
+                image_uuid: createValidateUUIDFn('image_uuid'),
+                internal_metadata: createValidatePolymorphicParamFn({
+                    paramName: 'internal_metadata',
+                    validationFunc: validatePolymorphicParamStringKeyValue
+                }),
                 limit: createValidateNumberFn('limit',
                     {min: 1, max: MAX_LIST_VMS_LIMIT}),
-                offset: createValidateNumberFn('offset'),
                 marker: createValidateMarkerFn('marker',
-                    {sortParamName: 'sort'})
+                    {sortParamName: 'sort'}),
+                offset: createValidateNumberFn('offset'),
+                owner_uuid: createValidateUUIDFn('owner_uuid'),
+                package_name: createValidateStringFn('package_name'),
+                package_version: createValidateStringFn('package_version'),
+                predicate: createValidateJSONPredicateFn('predicate'),
+                query: createValidateStringFn('query'),
+                ram: createValidateStringFn('ram', {re: RAM_RE}),
+                server_uuid: createValidateUUIDFn('server_uuid'),
+                sort: createValidateSortFn('sort'),
+                state: createValidateStringsListFn('state', VALID_VM_STATES),
+                tag: createValidatePolymorphicParamFn({
+                    paramName: 'tag',
+                    validationFunc: validatePolymorphicParamStringKeyValue
+                }),
+                uuid: createValidateUUIDFn('uuid'),
+                uuids: createValidateCSVFn('uuids', validUUID)
             };
 
             return validateParams(listVmValidators, params, {strict: true},
@@ -2337,7 +2375,7 @@ function validateParams(customValidators, params, options, callback) {
                 continue;
             }
 
-            customValidatorName = validatorName(paramName);
+            customValidatorName = polymorphicParamName(paramName);
             customValidator = customValidators[customValidatorName];
             if (!customValidator)
                 validationErrors.push(new errors.invalidParamErr(paramName));
@@ -2363,10 +2401,19 @@ function validateParams(customValidators, params, options, callback) {
  * that use a dot to separate the parameter name "tag" from the tag key will
  * return "tag", and not "tag.key".
  */
-function validatorName(paramName) {
-    assert.string(paramName, 'paramName');
+function polymorphicParamName(paramString) {
+    assert.string(paramString, 'paramString');
 
-    return paramName.split('.')[0];
+    return paramString.split('.')[0];
+}
+
+function polymorphicParamKey(paramString) {
+    assert.string(paramString, 'paramString');
+
+    var paramStringCompoments = strsplit(paramString, '.', 2);
+    if (paramStringCompoments.length === 2) {
+        return paramStringCompoments[1];
+    }
 }
 
 function validVmField(field) {
@@ -2384,3 +2431,18 @@ function isSortOrderDescending(order) {
 }
 exports.isSortOrderDescending = isSortOrderDescending;
 exports.DEFAULT_SORT_ORDER = 'DESC';
+
+function hasPolymorphicParamWithName(fieldName, params) {
+    assert.string(fieldName, 'fieldName');
+    assert.object(params, 'params');
+
+    var paramName;
+    for (paramName in params) {
+        if (paramName.indexOf(fieldName + '.') === 0) {
+            return true;
+        }
+    }
+
+    return false;
+}
+exports.hasPolymorphicParamWithName = hasPolymorphicParamWithName;
\ No newline at end of file
diff --git a/lib/common/vm-common.js b/lib/common/vm-common.js
index 427cd93..9968499 100644
--- a/lib/common/vm-common.js
+++ b/lib/common/vm-common.js
@@ -8,7 +8,7 @@
  * Copyright 2016 Joyent, Inc.
  */
 
-var assert = require('assert');
+var assert = require('assert-plus');
 var restify = require('restify');
 var strsplit = require('strsplit');
 
@@ -464,3 +464,68 @@ exports.getStatuses = function (vms) {
 
     return status;
 };
+
+
+
+/*
+ * Generates an array of string that represents the data in the internal
+ * metadata object "internalMetadata" in a format that makes it storable in a
+ * moray indexed field that makes it searchable.
+ *
+ * There are a couple of things to keep in mind regarding that conversion:
+ *
+ * 1. We rely on the guarantee (see http://smartos.org/bugview/PROV-1113) that
+ *    internal metadata values are strings, and so there's no need to convert
+ *    some values to strings to make them searchable.
+ *
+ * 2. We intentionally *drop* all strings that are longer than a given threshold
+ *    to make them fit under an arbitrary length to avoid storing potentially
+ *    huge values (e.g docker:env or docker:cmd data) that would impact Moray
+ *    performance negatively. As a result the search facilities provided for
+ *    internal metadata is best effort only.
+ *
+ * 3. We don't store strings that represent objects.
+ */
+exports.internalMetadataToSearchArray =
+function internalMetadataToSearchArray(internalMetadata) {
+    assert.optionalObject(internalMetadata, 'internalMetadata');
+
+    var MAX_METADATA_VALUE_LENGTH = 100;
+    var metadataKey;
+    var metadataValue;
+    /*
+     * Using filters on array indexes with null values is not supported in Moray
+     * (see https://smartos.org/bugview/MORAY-450), so we manually set the
+     * internal_metadata_search_array value to the empty array when the VM
+     * object has no internal_metadata value.
+     */
+    var searchArray = [];
+
+    if (internalMetadata) {
+        for (metadataKey in internalMetadata) {
+            if (!internalMetadata.hasOwnProperty(metadataKey)) {
+                continue;
+            }
+
+            metadataValue = internalMetadata[metadataKey];
+            switch (typeof (metadataValue)) {
+                case 'string':
+                    if (metadataValue.length > MAX_METADATA_VALUE_LENGTH) {
+                        metadataValue = '';
+                    }
+                    break;
+                case 'number':
+                case 'boolean':
+                    metadataValue = metadataValue.toString();
+                    break;
+                default:
+                    metadataValue = '';
+                    break;
+            }
+
+            searchArray.push(metadataKey + '=' + metadataValue);
+        }
+    }
+
+    return searchArray;
+};
\ No newline at end of file
diff --git a/lib/data-migrations/controller.js b/lib/data-migrations/controller.js
new file mode 100644
index 0000000..2e05d21
--- /dev/null
+++ b/lib/data-migrations/controller.js
@@ -0,0 +1,301 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var backoff = require('backoff');
+var EventEmitter = require('events');
+var util = require('util');
+var vasync = require('vasync');
+var VError = require('verror');
+
+function DataMigrationsController(options) {
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.object(options.migrations, 'options.migrations');
+    assert.object(options.moray, 'options.moray');
+
+    EventEmitter.call(this);
+
+    this._latestErrors = undefined;
+    this._latestCompletedMigrations = {};
+    this._log = options.log;
+    this._migrations = options.migrations;
+    this._moray = options.moray;
+}
+util.inherits(DataMigrationsController, EventEmitter);
+
+function dataMigrationErrorTransient(error) {
+    assert.object(error, 'error');
+
+    var idx;
+    var nonTransientErrors = [
+        /*
+         * For now, we consider a bucket not found to be a non-transient error
+         * because it's not clear how that error would resolve itself by
+         * retrying the data migrations process.
+         */
+        'BucketNotFoundError',
+        'InvalidIndexTypeError',
+        'InvalidQueryError',
+        /*
+         * We consider NotIndexedError errors to be non-transient because data
+         * migrations happen *after any schema migration, including reindexing
+         * of all affected buckets* is considered to be complete. As a result,
+         * when data migrations start, the indexes that are present will not
+         * change, and so retrying on such an error would lead to the same error
+         * occurring.
+         */
+        'NotIndexedError',
+        /*
+         * Unless a specific data migration handles a UniqueAttributeError
+         * itself, we consider that retrying that migration would have the same
+         * result, so we treat it as a non-transient error.
+         */
+        'UniqueAttributeError'
+    ];
+
+    for (idx = 0; idx < nonTransientErrors.length; ++idx) {
+        if (VError.hasCauseWithName(error, nonTransientErrors[idx])) {
+            return false;
+        }
+    }
+
+    return true;
+}
+
+DataMigrationsController.prototype.getLatestCompletedMigrationForModel =
+function getLatestCompletedMigrationForModel(modelName) {
+    assert.string(modelName, 'modelName');
+
+    return this._latestCompletedMigrations[modelName];
+};
+
+DataMigrationsController.prototype.getLatestCompletedMigrations =
+function getLatestCompletedMigrations() {
+    return this._latestCompletedMigrations;
+};
+
+DataMigrationsController.prototype.getLatestErrors = function getLatestError() {
+    return this._latestErrors;
+};
+
+DataMigrationsController.prototype.start = function start() {
+    var dataMigrationsBackoff = backoff.exponential();
+    var moray = this._moray;
+    var self = this;
+
+    moray.validateDataMigrations(this._migrations);
+    this._latestErrors = undefined;
+
+    dataMigrationsBackoff.on('backoff',
+        function onDataMigrationBackoff(number, delay) {
+            self._log.info('Data migration backed off, will retry in %sms',
+                delay);
+        });
+
+    dataMigrationsBackoff.on('ready', function onMigrationReady(number, delay) {
+        self.runMigrations(function onMigrationsRan(dataMigrationErr) {
+            if (dataMigrationErr) {
+                self._log.error({
+                    err: dataMigrationErr,
+                    number: number,
+                    delay: delay
+                }, 'Error when running data migrations');
+
+                if (dataMigrationErrorTransient(dataMigrationErr)) {
+                    self._log.info('Error is transient, backing off');
+                    dataMigrationsBackoff.backoff();
+                } else {
+                    self._log.error(dataMigrationErr,
+                        'Error is not transient, emitting error');
+                    self.emit('error', dataMigrationErr);
+                }
+            } else {
+                self._log.info('All data migrations ran successfully');
+                self.emit('done');
+            }
+        });
+    });
+
+    dataMigrationsBackoff.backoff();
+};
+
+DataMigrationsController.prototype.runMigrations =
+function runMigrations(callback) {
+    var modelNames;
+    var log = this._log;
+    var self = this;
+
+    assert.object(this._migrations, 'this._dataMigrations');
+
+    log.info({dataMigrations: self._migrations}, 'Running data migrations');
+
+    modelNames = Object.keys(this._migrations);
+
+    /*
+     * We run data migrations in *parallel* on purpose. Data migrations are
+     * heavily I/O bound, and the number of records for each "model" (or Moray
+     * bucket) can vary widely. Thus, performing them in sequence would mean
+     * that the migration of a model with very few objects could be
+     * significantly delayed by the migration of a model with a much higher
+     * number of objects. Instead, data migrations process objects in chunks of
+     * a bounded number of objects (currently 1000, the default Moray "page"
+     * limit), and thus these data migrations are interleaved, making none of
+     * them blocked on each other.
+     */
+    vasync. forEachParallel({
+        func: function runAllMigrationsForSingleModel(modelName, done) {
+            self._runMigrationsForModel(modelName, self._migrations[modelName],
+                done);
+        },
+        inputs: modelNames
+    }, callback);
+};
+
+DataMigrationsController.prototype._runMigrationsForModel =
+function _runMigrationsForModel(modelName, dataMigrations, callback) {
+    assert.string(modelName, 'modelName');
+    assert.arrayOfObject(dataMigrations, 'dataMigrations');
+    assert.func(callback, 'callback');
+
+    assert.object(this._log, 'this._log');
+    var log = this._log;
+    var self = this;
+
+    log.info('Starting data migrations for model %s', modelName);
+    self._latestCompletedMigrations = {};
+
+    vasync.forEachPipeline({
+        func: function runSingleMigration(migration, next) {
+            assert.number(migration.DATA_VERSION, 'migration.DATA_VERSION');
+            assert.ok(migration.DATA_VERSION >= 1,
+                'migration.DATA_VERSION >= 1');
+
+            self._runSingleMigration(modelName, migration, {
+                log: log
+            }, function onMigration(migrationErr) {
+                if (migrationErr) {
+                    if (self._latestErrors === undefined) {
+                        self._latestErrors = {};
+                    }
+
+                    self._latestErrors[modelName] = migrationErr;
+
+                    log.error({err: migrationErr},
+                        'Error when running migration to data version: ' +
+                            migration.DATA_VERSION);
+                } else {
+                    self._latestCompletedMigrations[modelName] =
+                        migration.DATA_VERSION;
+                    if (self._latestErrors && self._latestErrors[modelName]) {
+                        delete self._latestErrors[modelName];
+                        if (Object.keys(self._latestErrors).length === 0) {
+                            self._latestErrors = undefined;
+                        }
+                    }
+                    log.info('Data migration to data version: ' +
+                        migration.DATA_VERSION + ' ran successfully');
+                }
+
+                next(migrationErr);
+            });
+        },
+        inputs: dataMigrations
+    }, function onAllMigrationsDone(migrationsErr, results) {
+        var err;
+
+        if (migrationsErr) {
+            err = new VError(migrationsErr, 'Failed to run data migrations');
+        }
+
+        callback(err);
+    });
+};
+
+DataMigrationsController.prototype._runSingleMigration =
+function _runSingleMigration(modelName, migration, options, callback) {
+    assert.string(modelName, 'modelName');
+    assert.object(migration, 'migration');
+    assert.func(migration.migrateRecord, 'migration.migrateRecord');
+    assert.number(migration.DATA_VERSION, 'migration.DATA_VERSION');
+    assert.ok(migration.DATA_VERSION >= 1,
+            'migration.DATA_VERSION >= 1');
+    assert.object(options, 'options');
+    assert.func(callback, 'callback');
+
+    var context = {};
+    var log = this._log;
+    var self = this;
+    var version = migration.DATA_VERSION;
+
+    log.info('Running migration for model %s to data version: %s', modelName,
+        version);
+
+    function processNextChunk() {
+        vasync.pipeline({arg: context, funcs: [
+            function findRecords(ctx, next) {
+                self._moray.findRecordsToMigrate(modelName, version, {
+                    log: log
+                }, function onFindRecords(findErr, records) {
+                    if (findErr) {
+                        log.error({err: findErr},
+                            'Error when finding records not at version: ' +
+                                version);
+                    } else {
+                        log.info('Found ' + records.length + ' records');
+                        ctx.records = records;
+                    }
+
+                    next(findErr);
+                });
+            },
+            function migrateRecords(ctx, next) {
+                var migrateRecordFunc = migration.migrateRecord;
+                var migratedRecords;
+                var records = ctx.records;
+
+                assert.arrayOfObject(records, 'records');
+
+                if (records.length === 0) {
+                    next();
+                    return;
+                }
+
+                migratedRecords = records.map(migrateRecordFunc);
+                log.trace({migratedRecords: migratedRecords},
+                    'Migrated records');
+
+                self._moray.putBatch(modelName, migratedRecords, next);
+            }
+        ]}, function onChunkProcessed(chunkProcessingErr) {
+            var records = context.records;
+
+            if (chunkProcessingErr) {
+                log.error({err: chunkProcessingErr},
+                    'Error when processing chunk');
+                callback(chunkProcessingErr);
+                return;
+            }
+
+            if (!records || records.length === 0) {
+                log.info('No more records at version: ' + version +
+                    ', migration done');
+                callback();
+            } else {
+                log.info('Processed ' + records.length + ' records, ' +
+                    'scheduling processing of next chunk');
+                setImmediate(processNextChunk);
+            }
+        });
+    }
+
+    processNextChunk();
+};
+module.exports = DataMigrationsController;
\ No newline at end of file
diff --git a/lib/data-migrations/loader.js b/lib/data-migrations/loader.js
new file mode 100644
index 0000000..c486374
--- /dev/null
+++ b/lib/data-migrations/loader.js
@@ -0,0 +1,255 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * This module implements a "loadMigrations" function that loads migration code
+ * from a directory on the filesystem. It is used both by the VMAPI server to
+ * load actual data migrations code and by tests exercising the data migrations
+ * process to load migration fixtures.
+ */
+
+var assert = require('assert-plus');
+var EventEmitter = require('events');
+var fs = require('fs');
+var path = require('path');
+var vasync = require('vasync');
+var util = require('util');
+
+var errors = require('../errors');
+
+var DEFAULT_MIGRATIONS_ROOT_PATH = path.resolve(__dirname, 'migrations');
+var InvalidDataMigrationFileNamesError =
+    errors.InvalidDataMigrationFileNamesError;
+/*
+ * A migration module file name *must* start with three digits (in order to make
+ * it clear when listing files the order with which the code in these files will
+ * be executed), and *must* end with a ".js" file extension.
+ */
+var MIGRATION_FILE_RE = /^\d{3}.*\.js$/;
+
+/*
+ * Loads all of the data migration code present in a data migrations directory.
+ * A data migrations directory is of the following form:
+ *
+ * data-migrations-root-dir/
+ *   vms/
+ *     001-some-data-migration.js
+ *     002-some-other-data-migration.js
+ *   server_vms/
+ *     001-some-data-migration.js
+ *     002-some-other-data-migration.js
+ *   vm_role_tags/
+ *     001-some-data-migration.js
+ *     002-some-other-data-migration.js
+ *
+ * The data migrations root dir ("data-migrations-root-dir" in the example
+ * above) can have any name. Each of its sub-directory must have the name of a
+ * VMAPI Moray bucket, but not all VMAPI Moray buckets must have a data
+ * migrations sub-directory: Moray buckets that don't need to have any migration
+ * running don't need to have an empty directory present.
+ *
+ * Each sub-directory must have files using the ".js" extension that can be
+ * loaded as a Node.js module using the "require" statement.
+ *
+ * For a given data migrations sub-directory, the alphanumerical order will be
+ * used to determine in which order each data migration is performed.
+ *
+ * @params {Object} options (optional)
+ *   - {String} migrationsRootPath: the root directory where the data migrations
+ *     modules are present
+ *
+ * @params {Function} callback (required): the function called when all data
+ *   migration modules have been loaded
+ */
+function loadMigrations(options, callback) {
+    var context = {
+        migrations: {}
+    };
+    var log;
+    var migrationsRootPath;
+
+    if (typeof (options) === 'function') {
+        callback = options;
+        options = undefined;
+    }
+
+    assert.object(options, 'options');
+    assert.object(options.log, 'options.log');
+    assert.optionalString(options.migrationsRootPath,
+        'options.migrationsRootPath');
+    assert.func(callback, 'callback');
+
+    log = options.log;
+
+    migrationsRootPath = options.migrationsRootPath;
+    if (migrationsRootPath === undefined) {
+        migrationsRootPath = DEFAULT_MIGRATIONS_ROOT_PATH;
+    }
+
+    log.info('Loading data migrations from root directory %s',
+        migrationsRootPath);
+
+    vasync.pipeline({arg: context, funcs: [
+        readRootlMigrationDir,
+        checkRootMigrationDirEntries,
+        readMigrationsDirs
+    ]}, function onMigrationsLoaded(err, results) {
+        if (err) {
+            log.error(err, 'Error when loading data migrations');
+        } else {
+            log.info('Data migrations loaded successfully');
+        }
+
+        callback(err, context.migrations);
+    });
+
+    /*
+     * First, read the sub-directories under the top-level root directory
+     * that represents the containers of migration files for each Moray
+     * bucket name.
+     */
+    function readRootlMigrationDir(ctx, next) {
+        log.debug('Reading root migration directory');
+        fs.readdir(migrationsRootPath,
+            function onRootDirRead(rootDirReadErr, dirEntries) {
+                if (rootDirReadErr) {
+                    log.debug(rootDirReadErr,
+                        'Error when reading root migration directory');
+                } else {
+                    log.debug({dirEntries: dirEntries},
+                        'Successfully read root migration directory');
+                }
+
+                ctx.migrationsDirPaths =
+                    dirEntries.map(function getFullPath(dirEntry) {
+                        return path.join(migrationsRootPath, dirEntry);
+                    });
+
+                next(rootDirReadErr);
+            });
+    }
+
+    /*
+     * Then, check that these directory entries are actually
+     * (sub-)directories, and not any type of directory entry (files, etc.).
+     */
+    function checkRootMigrationDirEntries(ctx, next) {
+        assert.arrayOfString(ctx.migrationsDirPaths,
+            'ctx.migrationsDirPaths');
+
+        log.debug({migrationsDirPaths: ctx.migrationsDirPaths},
+            'Checking top level migration dir entries');
+
+        vasync.forEachParallel({
+            func: function checkIsDirectory(dirPath, done) {
+                var err;
+
+                fs.lstat(dirPath,
+                    function onLstat(lstatErr, stats) {
+                        if (lstatErr) {
+                            done(lstatErr);
+                            return;
+                        }
+
+                        if (!stats || !stats.isDirectory()) {
+                            err = new Error(dirPath +
+                                ' is not a directory');
+                        }
+
+                        done(err);
+                    });
+            },
+            inputs: ctx.migrationsDirPaths
+        }, function onTopLevelDirsChecked(checkErr) {
+            if (checkErr) {
+                log.debug(checkErr,
+                    'Error when checking root migration dir entries');
+            } else {
+                log.debug('Checked root migration dir entries ' +
+                    'successfully');
+            }
+
+            next(checkErr);
+        });
+    }
+
+    /*
+     * Finally, load each file in those sub-directories as a JS module.
+     */
+    function readMigrationsDirs(ctx, next) {
+        log.debug('Reading data migrations subdirectories');
+
+        vasync.forEachParallel({func: function loadFiles(dirPath, done) {
+            var modelName = path.basename(dirPath);
+
+            log.debug({
+                dirPath: dirPath
+            }, 'Reading data migrations subdirectory');
+
+            fs.readdir(dirPath, function onDirRead(dirReadErr, migrationFiles) {
+                var invalidFileNames;
+
+                log.trace({migrationFiles: migrationFiles}, 'migration files');
+
+                if (dirReadErr) {
+                    log.error({
+                        dirPath: dirPath,
+                        err: dirReadErr
+                    }, 'Error when reading data migrations subdirectory');
+                    done(dirReadErr);
+                    return;
+                }
+
+                invalidFileNames =
+                    migrationFiles.filter(
+                        function isInvalidMigrationFilename(fileName) {
+                            return !MIGRATION_FILE_RE.test(fileName);
+                        });
+
+                log.trace({invalidFileNames: invalidFileNames},
+                    'Invalid file names %d', invalidFileNames.length);
+
+                if (invalidFileNames.length !== 0) {
+                    done(new
+                        InvalidDataMigrationFileNamesError(invalidFileNames));
+                    return;
+                }
+
+                /*
+                 * Array.sort() sorts "according to unicode code points", so
+                 * migration files will be sorted alphanumerically. E.g
+                 * 001-foo.js will be sorted (and thus run) before 002-bar.js.
+                 */
+                migrationFiles.sort();
+
+                ctx.migrations[modelName] =
+                    migrationFiles.map(function load(file) {
+                        return require(path.join(dirPath, file));
+                    });
+
+                done();
+            });
+        }, inputs: ctx.migrationsDirPaths
+        }, function onMigrationDirsRead(readDirsErr) {
+            if (readDirsErr) {
+                log.error({readDirsErr: readDirsErr},
+                    'Error when reading migration dirs');
+            } else {
+                log.info('Read migration dirs successfully');
+            }
+
+            next(readDirsErr);
+        });
+    }
+}
+
+module.exports = {
+    loadMigrations: loadMigrations
+};
\ No newline at end of file
diff --git a/lib/data-migrations/migrations/vms/001-internal-metadata-search.js b/lib/data-migrations/migrations/vms/001-internal-metadata-search.js
new file mode 100644
index 0000000..7ee8ac9
--- /dev/null
+++ b/lib/data-migrations/migrations/vms/001-internal-metadata-search.js
@@ -0,0 +1,55 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * This data migration is used to allow searching on the internal_metadata
+ * property of VM objects. It reads the content of the internal_metadata
+ * property of each VM object, and writes it to an indexed
+ * "internal_metadata_search_array" property in a way that is searchable.
+ */
+
+var assert = require('assert-plus');
+var common = require('../../../common');
+
+var DATA_VERSION = 1;
+
+function migrateRecord(record) {
+    var parsedInternalMetadata;
+    var recordValue;
+
+    assert.object(record, 'record');
+    assert.object(record.value, 'record.value');
+
+    recordValue = record.value;
+
+    if (recordValue.data_version !== undefined) {
+        return;
+    }
+
+    if (recordValue.internal_metadata !== null &&
+        recordValue.internal_metadata !== undefined) {
+        assert.string(record.value.internal_metadata,
+            'record.value.internal_metadata');
+
+        parsedInternalMetadata = JSON.parse(recordValue.internal_metadata);
+    }
+
+    recordValue.internal_metadata_search_array =
+        common.internalMetadataToSearchArray(parsedInternalMetadata);
+
+    recordValue.data_version = DATA_VERSION;
+
+    return record;
+}
+
+module.exports = {
+    migrateRecord: migrateRecord,
+    DATA_VERSION: DATA_VERSION
+};
\ No newline at end of file
diff --git a/lib/data-migrations/noop-controller.js b/lib/data-migrations/noop-controller.js
new file mode 100644
index 0000000..890ac93
--- /dev/null
+++ b/lib/data-migrations/noop-controller.js
@@ -0,0 +1,49 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+/*
+ * This module implements a mocked data migrations controller that immediattely
+ * emits an event signaling that all migrations completed successfully. It is
+ * meant to be used when a VmapiApp instance needs to be created but we don't
+ * really care about data migrations (e.g tests that do not test data migrations
+ * specifically).
+ */
+
+var assert = require('assert-plus');
+var EventEmitter = require('events');
+var util = require('util');
+
+function NoopDataMigrationsController() {
+    EventEmitter.call(this);
+}
+util.inherits(NoopDataMigrationsController, EventEmitter);
+
+NoopDataMigrationsController.prototype.start = function start() {
+    this.emit('done');
+};
+
+NoopDataMigrationsController.prototype.getLatestCompletedMigrations =
+function getLatestCompletedMigrations() {
+    return {};
+};
+
+NoopDataMigrationsController.prototype.getLatestErrors =
+function getLatestErrors() {
+    return undefined;
+};
+
+NoopDataMigrationsController.prototype.getLatestCompletedMigrationForModel =
+function getLatestCompletedMigrationForModel(modelName) {
+    assert.string(modelName, 'modelName');
+
+    return undefined;
+};
+
+module.exports = NoopDataMigrationsController;
\ No newline at end of file
diff --git a/lib/endpoints/ping.js b/lib/endpoints/ping.js
index 65536fd..0958e4d 100644
--- a/lib/endpoints/ping.js
+++ b/lib/endpoints/ping.js
@@ -29,6 +29,7 @@ var NOT_OK_OVERALL_STATUS = 'some services are not ready';
  * GET /ping
  */
 function ping(req, res, next) {
+    var dataMigrationsStatus = {};
     var morayInitialization;
     var morayStatus = OFFLINE_STATUS;
     var wfapiServiceStatus = OFFLINE_STATUS;
@@ -117,6 +118,28 @@ function ping(req, res, next) {
                 status: wfapiServiceStatus
             }, 'wfapi connectivity check results');
 
+            done();
+        },
+        function getDataMigrationsStatus(done) {
+            var latestErrors;
+            var modelName;
+
+            req.log.debug('Checking data migrations status');
+
+            if (req.app.dataMigrationsCtrl) {
+                dataMigrationsStatus.latestCompletedMigrations =
+                    req.app.dataMigrationsCtrl.getLatestCompletedMigrations();
+                latestErrors = req.app.dataMigrationsCtrl.getLatestErrors();
+            }
+
+            if (latestErrors) {
+                for (modelName in latestErrors) {
+                    latestErrors[modelName] =
+                        latestErrors[modelName].toString();
+                }
+                dataMigrationsStatus.latestErrors = latestErrors;
+            }
+
             done();
         }
     ]}, function allStatusInfoRetrieved(err) {
@@ -131,6 +154,7 @@ function ping(req, res, next) {
             responseCode = 503;
         }
 
+        response.dataMigrations = dataMigrationsStatus;
         response.healthy = overallHealthy;
         response.initialization = {
             moray: morayInitialization
diff --git a/lib/endpoints/vms.js b/lib/endpoints/vms.js
index 46b3257..7f0df10 100644
--- a/lib/endpoints/vms.js
+++ b/lib/endpoints/vms.js
@@ -181,7 +181,6 @@ function preFilterVms(req, res, next) {
     });
 }
 
-
 /*
  * GET /vms
  *
@@ -190,6 +189,39 @@ function preFilterVms(req, res, next) {
 function listVms(req, res, next) {
     req.log.trace('ListVms start');
 
+    function checkInternalMetadataSearchAvailable(done) {
+        var err;
+        var INTERNAL_METADATA_SEARCH_DATA_VER = 1;
+        var internalMetadataSearchUsed;
+        var latestCompletedDataMigration =
+            req.app.getLatestCompletedDataMigrationForModel('vms');
+        var LIST_VMS_POLYMORPHIC_PARAMS = ['internal_metadata', 'tags'];
+
+        internalMetadataSearchUsed =
+            common.hasPolymorphicParamWithName('internal_metadata',
+                req.params) ||
+            common.jsonPredicateFiltersOn('internal_metadata',
+                req.params.predicate, LIST_VMS_POLYMORPHIC_PARAMS) ||
+            common.ldapFilterFiltersOn('internal_metadata_search_array',
+                req.params.query);
+
+        req.log.trace({
+            latestCompletedDataMigration: latestCompletedDataMigration,
+            params: req.params
+        }, 'Checking if searching on internal_metadata is available');
+
+        if (internalMetadataSearchUsed &&
+            (latestCompletedDataMigration === undefined ||
+                latestCompletedDataMigration <
+                    INTERNAL_METADATA_SEARCH_DATA_VER)) {
+            err = new errors.DataVersionError('vms',
+                INTERNAL_METADATA_SEARCH_DATA_VER, latestCompletedDataMigration,
+                'internal_metadata search');
+        }
+
+        done(err);
+    }
+
     function validateParams(done) {
         req.log.trace({params: req.params}, 'validating request params');
 
@@ -253,7 +285,11 @@ function listVms(req, res, next) {
         });
     }
 
-    async.series([validateParams, list], function allDone(err) {
+    async.series([
+        validateParams,
+        checkInternalMetadataSearchAvailable,
+        list
+    ], function allDone(err) {
         if (err)
             req.log.debug({err: err});
         return next(err);
diff --git a/lib/errors.js b/lib/errors.js
index 230c649..4622e1d 100644
--- a/lib/errors.js
+++ b/lib/errors.js
@@ -264,4 +264,47 @@ function InvalidIndexesRemovalError(indexes) {
     this.message = 'Invalid removal of indexes: ' + indexes.join(', ');
 }
 util.inherits(InvalidIndexesRemovalError, Error);
-exports.InvalidIndexesRemovalError = InvalidIndexesRemovalError;
\ No newline at end of file
+exports.InvalidIndexesRemovalError = InvalidIndexesRemovalError;
+
+function DataVersionError(modelName, requiredVer, actualVer, featureDesc) {
+    var message;
+
+    assert.string(modelName, 'modelName');
+    assert.number(requiredVer, 'requiredVersion');
+    assert.optionalNumber(actualVer, 'actualVersion');
+    assert.string(featureDesc, 'featureDesc');
+
+    message = 'Data for model ' + modelName + ' not at required version ' +
+        requiredVer + ' to support ' + featureDesc + '. Current data ' +
+        'version is: ' + actualVer;
+
+    restify.ServiceUnavailableError.call(this, {
+        restCode: this.constructor.restCode,
+        statusCode: this.constructor.statusCode,
+        message: message,
+        body: {
+            code: this.constructor.restCode,
+            message: message
+        }
+    });
+}
+util.inherits(DataVersionError, Error);
+DataVersionError.prototype.name = 'DataVersionError';
+DataVersionError.restCode = 'DataVersion';
+DataVersionError.statusCode = 503;
+exports.DataVersionError = DataVersionError;
+
+function InvalidDataMigrationFileNamesError(fileNames) {
+    if (!(this instanceof InvalidDataMigrationFileNamesError)) {
+        throw new Error('InvalidDataMigrationFileNamesError must be used as ' +
+            'a constructor');
+    }
+
+    Error.call(this);
+
+    assert.arrayOfString(fileNames, 'fileNames');
+    this.name = this.constructor.name;
+    this.message = 'Invalid data migration file name: ' + fileNames.join(',');
+}
+util.inherits(InvalidDataMigrationFileNamesError, Error);
+exports.InvalidDataMigrationFileNamesError = InvalidDataMigrationFileNamesError;
\ No newline at end of file
diff --git a/lib/moray/moray-buckets-config.js b/lib/moray/moray-buckets-config.js
index e17927d..9178853 100644
--- a/lib/moray/moray-buckets-config.js
+++ b/lib/moray/moray-buckets-config.js
@@ -8,6 +8,14 @@
  * Copyright (c) 2017, Joyent, Inc.
  */
 
+/*
+ * For any Moray bucket in the bucket configurations below, the "data_version"
+ * field is used by data migrations to determine what records need to be
+ * migrated. A data migration module with a target migration version of N will
+ * fetch all records with a "data_version" number of N - 1, modify them (migrate
+ * them), and write them with a new "data_version" value of N.
+ */
+
 var VMS_BUCKET_CONFIG = {
     name: 'vmapi_vms',
     schema: {
@@ -25,10 +33,16 @@ var VMS_BUCKET_CONFIG = {
             alias: { type: 'string' },
             max_physical_memory: { type: 'number' },
             create_timestamp: { type: 'number' },
-            docker: { type: 'boolean' }
+            docker: { type: 'boolean' },
+            /*
+             * This indexed field is used to store the value of the
+             * "internal_metadata" field so that it is searchable.
+             */
+            internal_metadata_search_array: { type: '[string]' },
+            data_version: { type: 'number' }
         },
         options: {
-            version: 1
+            version: 2
         }
     }
 };
@@ -36,8 +50,11 @@ var VMS_BUCKET_CONFIG = {
 var SERVER_VMS_BUCKET_CONFIG = {
     name: 'vmapi_server_vms',
     schema: {
+        index: {
+            data_version: { type: 'number' }
+        },
         options: {
-            version: 1
+            version: 2
         }
     }
 };
@@ -46,16 +63,17 @@ var VM_ROLE_TAGS_BUCKET_CONFIG = {
     name: 'vmapi_vm_role_tags',
     schema: {
         index: {
-            role_tags: { type: '[string]' }
+            role_tags: { type: '[string]' },
+            data_version: { type: 'number' }
         },
         options: {
-            version: 1
+            version: 2
         }
     }
 };
 
 module.exports = {
-    VMS: VMS_BUCKET_CONFIG,
-    SERVER_VMS: SERVER_VMS_BUCKET_CONFIG,
-    VM_ROLE_TAGS: VM_ROLE_TAGS_BUCKET_CONFIG
+    vms: VMS_BUCKET_CONFIG,
+    server_vms: SERVER_VMS_BUCKET_CONFIG,
+    vm_role_tags: VM_ROLE_TAGS_BUCKET_CONFIG
 };
diff --git a/lib/moray/moray-buckets-initializer.js b/lib/moray/moray-buckets-initializer.js
index 27c4aa4..c7b9097 100644
--- a/lib/moray/moray-buckets-initializer.js
+++ b/lib/moray/moray-buckets-initializer.js
@@ -115,9 +115,8 @@ MorayBucketsInitializer.prototype.lastInitError = function lastInitError() {
  * unrecoverable.
  */
 MorayBucketsInitializer.prototype.start =
-    function start(moray, morayBucketsConfig) {
+    function start(moray) {
     assert.object(moray, 'moray');
-    assert.object(morayBucketsConfig, 'morayBucketsConfig');
 
     var self = this;
 
@@ -126,22 +125,21 @@ MorayBucketsInitializer.prototype.start =
     vasync.pipeline({arg: {}, funcs: [
         function setupBuckets(arg, next) {
             self.log.info('Starting setting up buckets');
-            self._setupBuckets(moray, morayBucketsConfig,
-                function onBucketsSetup(bucketsSetupErr) {
-                    if (!bucketsSetupErr) {
-                        self.log.info('Buckets setup successfully');
-                        self._status = 'BUCKETS_SETUP_DONE';
-                    } else {
-                        self.log.error({err: bucketsSetupErr},
-                            'Error when setting up buckets');
-                    }
-
-                    next(bucketsSetupErr);
-                });
+            self._setupBuckets(moray, function onBucketsSetup(bucketsSetupErr) {
+                if (!bucketsSetupErr) {
+                    self.log.info('Buckets setup successfully');
+                    self._status = 'BUCKETS_SETUP_DONE';
+                } else {
+                    self.log.error({err: bucketsSetupErr},
+                        'Error when setting up buckets');
+                }
+
+                next(bucketsSetupErr);
+            });
         },
         function reindexBuckets(arg, next) {
             self.log.info('Starting reindexing buckets');
-            self._reindexBuckets(moray, morayBucketsConfig,
+            self._reindexBuckets(moray,
                 function onBucketsReindexed(bucketsReindexErr) {
                     if (!bucketsReindexErr) {
                         self.log.info('Buckets reindexed successfully');
@@ -241,16 +239,14 @@ MorayBucketsInitializer.prototype._performBackedOffProcess =
 };
 
 MorayBucketsInitializer.prototype._setupBuckets =
-    function _setupBuckets(moray, morayBucketsConfig, callback) {
+    function _setupBuckets(moray, callback) {
     assert.object(moray, 'moray');
-    assert.object(morayBucketsConfig, 'morayBucketsConfig');
     assert.func(callback, 'callback');
 
     var self = this;
 
     self._performBackedOffProcess('buckets setup',
-        moray.setupBuckets.bind(moray,
-        morayBucketsConfig), {
+        moray.setupBuckets.bind(moray), {
             maxAttempts: self._maxBucketsSetupAttempts,
             isErrTransientFun:
                 moray.isBucketsSetupErrorTransient.bind(moray)
@@ -258,17 +254,15 @@ MorayBucketsInitializer.prototype._setupBuckets =
 };
 
 MorayBucketsInitializer.prototype._reindexBuckets =
-    function _reindexBuckets(moray, morayBucketsConfig, callback) {
+    function _reindexBuckets(moray, callback) {
 
     assert.object(moray, 'moray');
-    assert.object(morayBucketsConfig, 'morayBucketsConfig');
     assert.func(callback, 'callback');
 
     var self = this;
 
     self._performBackedOffProcess('buckets reindex',
-        moray.reindexBuckets.bind(moray,
-        morayBucketsConfig), {
+        moray.reindexBuckets.bind(moray), {
             maxAttempts: self._maxBucketsReindexAttempts,
             isErrTransientFun: function isReindexErrorTransient(err) {
                 /*
diff --git a/lib/moray/moray-init.js b/lib/moray/moray-init.js
index 32b0e39..269799e 100644
--- a/lib/moray/moray-init.js
+++ b/lib/moray/moray-init.js
@@ -138,9 +138,11 @@ function startMorayInit(options) {
         component: 'moray-buckets-initializer'
     }, true);
 
-    moray = new Moray(morayClient, {
-        log: morayStorageLog,
-        changefeedPublisher: changefeedPublisher
+    moray = new Moray({
+        changefeedPublisher: changefeedPublisher,
+        bucketsConfig: morayBucketsConfig,
+        morayClient: morayClient,
+        log: morayStorageLog
     });
 
     var morayBucketsInitializer = new MorayBucketsInitializer({
@@ -150,7 +152,7 @@ function startMorayInit(options) {
     });
 
     morayClient.on('connect', function onMorayClientConnected() {
-        morayBucketsInitializer.start(moray, morayBucketsConfig);
+        morayBucketsInitializer.start(moray);
     });
 
     return {
diff --git a/lib/vmapi.js b/lib/vmapi.js
index 1083edb..a9fa5f3 100644
--- a/lib/vmapi.js
+++ b/lib/vmapi.js
@@ -117,6 +117,16 @@ function VmapiApp(options) {
 
     this.options = options;
 
+    /*
+     * We make it mandatory to pass a data migrations controller so that we
+     * don't omit to pass it to the VMAPI application constructor by mistake at
+     * some point, even though technically in a lot of use cases (e.g tests)
+     * when we don't need to perform data migrations, it'd be perfectly fine to
+     * omit it.
+     */
+    assert.object(options.dataMigrationsCtrl, 'options.dataMigrationsCtrl');
+    this.dataMigrationsCtrl = options.dataMigrationsCtrl;
+
     validations.init(options);
     this._initApis(options);
 }
@@ -388,6 +398,17 @@ VmapiApp.prototype.listen = function (options, callback) {
     });
 };
 
+VmapiApp.prototype.getLatestCompletedDataMigrationForModel =
+function getLatestCompletedDataMigrationForModel(modelName) {
+    assert.ok(this.moray.isValidModelName(modelName), modelName + ' is valid');
+
+    var dataMigrationsCtrl = this.dataMigrationsCtrl;
+    if (dataMigrationsCtrl === undefined) {
+        return;
+    }
+
+    return dataMigrationsCtrl.getLatestCompletedMigrationForModel(modelName);
+};
 
 
 /*
diff --git a/package.json b/package.json
index 565d77b..df01a46 100644
--- a/package.json
+++ b/package.json
@@ -1,7 +1,7 @@
 {
   "name": "vmapi",
   "description": "VMs API",
-  "version": "9.1.0",
+  "version": "9.2.0",
   "author": "Joyent (joyent.com)",
   "private": true,
   "dependencies": {
@@ -15,6 +15,7 @@
     "deep-diff": "0.3.3",
     "effluent-logger": "git+https://github.com/joshwilsdon/effluent-logger.git#d662f161a07f94045ad2afb45442931511c40e51",
     "jsprim": "^1.2.2",
+    "krill": "1.0.1",
     "ldap-filter": "0.3.3",
     "libuuid": "0.2.1",
     "moray": "3.1.1",
diff --git a/server.js b/server.js
index d999891..5c2e567 100644
--- a/server.js
+++ b/server.js
@@ -23,6 +23,7 @@ var jsprim = require('jsprim');
 var path = require('path');
 var restify = require('restify');
 var sigyan = require('sigyan');
+var util = require('util');
 var vasync = require('vasync');
 
 var CNAPI = require('./lib/apis/cnapi');
@@ -33,8 +34,12 @@ var VmapiApp = require('./lib/vmapi');
 var WFAPI = require('./lib/apis/wfapi');
 
 var configLoader = require('./lib/config-loader');
+var DataMigrationsController = require('./lib/data-migrations/controller');
+var dataMigrationsLoader = require('./lib/data-migrations/loader');
 var morayInit = require('./lib/moray/moray-init.js');
 
+var DATA_MIGRATIONS;
+var dataMigrationCtrl;
 var morayBucketsInitializer;
 var morayClient;
 var moray;
@@ -122,14 +127,16 @@ function startVmapiService() {
     var changefeedPublisher;
     var configFilePath = path.join(__dirname, 'config.json');
     var config = configLoader.loadConfig(configFilePath);
-    config.version = version() || '7.0.0';
-
+    var dataMigrations;
+    var dataMigrationsCtrl;
     var vmapiLog = bunyan.createLogger({
         name: 'vmapi',
         level: config.logLevel,
         serializers: restify.bunyan.serializers
     });
 
+    config.version = version() || '7.0.0';
+
     // Increase/decrease loggers levels using SIGUSR2/SIGUSR1:
     sigyan.add([vmapiLog]);
 
@@ -152,7 +159,26 @@ function startVmapiService() {
                 next();
             });
         },
-        function initMorayApi(_, next) {
+        function loadDataMigrations(_, next) {
+            vmapiLog.info('Loading data migrations modules');
+
+            dataMigrationsLoader.loadMigrations({
+                log: vmapiLog.child({ component: 'migrations-loader' }, true)
+            }, function onMigrationsLoaded(migrationsLoadErr, migrations) {
+                if (migrationsLoadErr) {
+                    vmapiLog.error({err: migrationsLoadErr},
+                            'Error when loading data migrations modules');
+                } else {
+                    vmapiLog.info({migrations: migrations},
+                        'Loaded data migrations modules successfully!');
+                }
+
+                dataMigrations = migrations;
+                next(migrationsLoadErr);
+            });
+        },
+
+        function initMoray(_, next) {
             assert.object(changefeedPublisher, 'changefeedPublisher');
 
             var morayConfig = jsprim.deepCopy(config.moray);
@@ -169,15 +195,43 @@ function startVmapiService() {
             moray = moraySetup.moray;
 
             /*
-             * We don't want to wait for the Moray initialization process to
-             * be done before creating the HTTP server that will provide
-             * VMAPI's API endpoints, as:
+             * We don't set an 'error' event listener because we want the
+             * process to abort when there's a non-transient data migration
+             * error.
+             */
+            dataMigrationsCtrl = new DataMigrationsController({
+                log: vmapiLog.child({
+                    component: 'migrations-controller'
+                }, true),
+                migrations: dataMigrations,
+                moray: moray
+            });
+
+            /*
+             * We purposely start data migrations *only when all buckets are
+             * updated and reindexed*. Otherwise, if we we migrated records that
+             * have a value for a field for which a new index was just added,
+             * moray could discard that field when fetching the object using
+             * findObjects or getObject requests (See
+             * http://smartos.org/bugview/MORAY-104 and
+             * http://smartos.org/bugview/MORAY-428). We could thus migrate
+             * those records erroneously, and in the end write bogus data.
+             */
+            morayBucketsInitializer.on('done',
+                function onMorayBucketsInitialized() {
+                    dataMigrationsCtrl.start();
+                });
+
+            /*
+             * We don't want to wait for the Moray initialization process to be
+             * done before creating the HTTP server that will provide VMAPI's
+             * API endpoints, as:
              *
-             * 1. some endpoints can function properly without using
-             * the Moray storage layer.
+             * 1. some endpoints can function properly without using the Moray
+             *    storage layer.
              *
              * 2. some endpoints are needed to provide status information,
-             * including status information about the storage layer.
+             *    including status information about the storage layer.
              */
             next();
         },
@@ -197,21 +251,29 @@ function startVmapiService() {
                 error: err
             }, 'failed to initialize VMAPI\'s dependencies');
 
-            morayClient.close();
+            if (changefeedPublisher) {
+                changefeedPublisher.stop();
+            }
+
+            if (morayClient) {
+                morayClient.close();
+            }
+
             process.exitCode = 1;
         } else {
             var vmapiApp = new VmapiApp({
-                version: config.version,
-                log: vmapiLog.child({ component: 'http-api' }, true),
-                serverConfig: {
-                    bindPort: config.api.port
-                },
                 apiClients: apiClients,
                 changefeedPublisher: changefeedPublisher,
-                morayBucketsInitializer: morayBucketsInitializer,
+                dataMigrationsCtrl: dataMigrationsCtrl,
+                log: vmapiLog.child({ component: 'http-api' }, true),
                 moray: moray,
+                morayBucketsInitializer: morayBucketsInitializer,
                 overlay: config.overlay,
-                reserveKvmStorage: config.reserveKvmStorage
+                reserveKvmStorage: config.reserveKvmStorage,
+                serverConfig: {
+                    bindPort: config.api.port
+                },
+                version: config.version
             });
 
             vmapiApp.listen();
diff --git a/test/fixtures/data-migrations-invalid-filenames/vms/001-invalid-file-extension.foo b/test/fixtures/data-migrations-invalid-filenames/vms/001-invalid-file-extension.foo
new file mode 100644
index 0000000..e3e417b
--- /dev/null
+++ b/test/fixtures/data-migrations-invalid-filenames/vms/001-invalid-file-extension.foo
@@ -0,0 +1,9 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
\ No newline at end of file
diff --git a/test/fixtures/data-migrations-invalid-filenames/vms/invalid-file-name.js b/test/fixtures/data-migrations-invalid-filenames/vms/invalid-file-name.js
new file mode 100644
index 0000000..e3e417b
--- /dev/null
+++ b/test/fixtures/data-migrations-invalid-filenames/vms/invalid-file-name.js
@@ -0,0 +1,9 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
\ No newline at end of file
diff --git a/test/fixtures/data-migrations-valid/vms/001-foo-to-bar.js b/test/fixtures/data-migrations-valid/vms/001-foo-to-bar.js
new file mode 100644
index 0000000..f7cd137
--- /dev/null
+++ b/test/fixtures/data-migrations-valid/vms/001-foo-to-bar.js
@@ -0,0 +1,23 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+
+var DATA_VERSION = 1;
+
+module.exports = {
+    DATA_VERSION: DATA_VERSION,
+    migrateRecord: function migrateRecord(record) {
+        assert.object(record, 'record');
+        record.value.bar = 'foo';
+        record.value.data_version = DATA_VERSION;
+        return record;
+    }
+};
\ No newline at end of file
diff --git a/test/fixtures/vmapi-server-throwing-expected-stderr.txt b/test/fixtures/vmapi-server-throwing-expected-stderr.txt
index 116304b..15bcc9a 100644
--- a/test/fixtures/vmapi-server-throwing-expected-stderr.txt
+++ b/test/fixtures/vmapi-server-throwing-expected-stderr.txt
@@ -1,6 +1,6 @@
-/opt/smartdc/vmapi/test/fixtures/vmapi-server-with-throwing-handler.js:22
+/opt/smartdc/vmapi/test/fixtures/vmapi-server-with-throwing-handler.js:24
     throw new Error('boom');
     ^
 
 Error: boom
-    at Server.throwingRestifyHandler (/opt/smartdc/vmapi/test/fixtures/vmapi-server-with-throwing-handler.js:22:11)
\ No newline at end of file
+    at Server.throwingRestifyHandler (/opt/smartdc/vmapi/test/fixtures/vmapi-server-with-throwing-handler.js:24:11)
\ No newline at end of file
diff --git a/test/fixtures/vmapi-server-with-throwing-handler.js b/test/fixtures/vmapi-server-with-throwing-handler.js
index ff863ae..8041192 100644
--- a/test/fixtures/vmapi-server-with-throwing-handler.js
+++ b/test/fixtures/vmapi-server-with-throwing-handler.js
@@ -14,6 +14,8 @@ var path = require('path');
 var vasync = require('vasync');
 
 var changefeedUtils = require('../../lib/changefeed');
+var NoopDataMigrationsController =
+    require('../../lib/data-migrations/noop-controller');
 var VmapiApp = require('../../lib/vmapi');
 
 var UNIQUE_ENDPOINT_PATH = '/' + libuuid.create();
@@ -43,6 +45,7 @@ vasync.pipeline({funcs: [
                 bucketsSetup: function bucketsSetup() { return true; }
             },
             changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+            dataMigrationsCtrl: new NoopDataMigrationsController(),
             morayBucketsInitializer: {
                 status: function status() { return 'BUCKETS_REINDEX_DONE'; },
                 lastInitError: function lastInitError() { return null; }
diff --git a/test/lib/vm.js b/test/lib/vm.js
index 5f26a53..953074b 100644
--- a/test/lib/vm.js
+++ b/test/lib/vm.js
@@ -30,6 +30,7 @@ BunyanNoopLogger.prototype.end = function () {};
 function createTestVm(moray, options, vmParams, callback) {
     assert.object(moray, 'moray');
     assert.object(options, 'options');
+    assert.optionalObject(options.log, 'options.log');
     assert.object(vmParams, 'vmParams must be an object');
 
     var log = options.log || new BunyanNoopLogger();
diff --git a/test/vms.data-migrations.test.js b/test/vms.data-migrations.test.js
new file mode 100644
index 0000000..030c8e2
--- /dev/null
+++ b/test/vms.data-migrations.test.js
@@ -0,0 +1,614 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var bunyan = require('bunyan');
+var jsprim = require('jsprim');
+var libuuid = require('libuuid');
+var once = require('once');
+var path = require('path');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+var VError = require('verror');
+var VMAPI = require('sdc-clients').VMAPI;
+
+var changefeedUtils = require('../lib/changefeed');
+var common = require('./common');
+var DataMigrationsController = require('../lib/data-migrations/controller');
+var dataMigrationsLoader = require('../lib/data-migrations/loader');
+var morayInit = require('../lib/moray/moray-init');
+var testMoray = require('./lib/moray.js');
+var VmapiApp = require('../lib/vmapi');
+
+var MOCKED_WFAPI_CLIENT = {
+    connected: true,
+    connect: function mockedWfapiConnect(callback) {
+        callback();
+    }
+};
+
+var VMS_BUCKET_NAME = 'test_vmapi_vms_data_migrations';
+var SERVER_VMS_BUCKET_NAME = 'test_vmapi_server_vms_data_migrations';
+var ROLE_TAGS_BUCKET_NAME = 'test_vmapi_vm_role_tags_data_migrations';
+
+var VMS_BUCKET_CONFIG = {
+    name: VMS_BUCKET_NAME,
+    schema: {
+        index: {
+            foo: { type: 'string' },
+            bar: { type: 'string' },
+            data_version: { type: 'number' }
+        }
+    }
+};
+
+var SERVER_VMS_MORAY_BUCKET_CONFIG = {
+    name: SERVER_VMS_BUCKET_NAME,
+    schema: {}
+};
+
+var ROLE_TAGS_MORAY_BUCKET_CONFIG = {
+    name: ROLE_TAGS_BUCKET_NAME,
+    schema: {
+    }
+};
+
+var TEST_BUCKETS_CONFIG = {
+    vms: VMS_BUCKET_CONFIG,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG
+};
+
+/*
+ * The number of test objects is chosen so that it's larger than the default
+ * page for Moray requests (which is currently 1000). 2001 objects means that at
+ * least 3 Moray requests are necessary to read all records from the test moray
+ * buckets, and so that we go through 3 iterations of the read/transform/write
+ * cycle involved in migrating records.
+ */
+var NUM_TEST_OBJECTS = 2001;
+
+function findAllObjects(morayClient, bucketName, filter, callback) {
+    assert.object(morayClient, 'morayClient');
+    assert.string(bucketName, 'bucketName');
+    assert.func(callback, 'callback');
+
+    var callbackOnce = once(callback);
+    var allRecords = [];
+
+    var findAllObjectsReq = morayClient.findObjects(bucketName, filter);
+
+    findAllObjectsReq.once('error', function onError(findErr) {
+        cleanup();
+        callbackOnce(findErr);
+    });
+
+    findAllObjectsReq.on('record', function onRecord(record) {
+        allRecords.push(record);
+    });
+
+    findAllObjectsReq.once('end', function onGotAllRecords() {
+        cleanup();
+        callbackOnce(null, allRecords);
+    });
+
+    function cleanup() {
+        findAllObjectsReq.removeAllListeners('error');
+        findAllObjectsReq.removeAllListeners('record');
+        findAllObjectsReq.removeAllListeners('end');
+    }
+}
+
+function writeObjects(morayClient, bucketName, valueTemplate, nbObjects,
+    callback) {
+    assert.object(morayClient, 'morayClient');
+    assert.string(bucketName, 'bucketName');
+    assert.object(valueTemplate, 'valueTemplate');
+    assert.number(nbObjects, 'nbObjects');
+    assert.func(callback, 'callback');
+
+    var i;
+
+    var objectKeys = [];
+    for (i = 0; i < nbObjects; ++i) {
+        objectKeys.push(libuuid.create());
+    }
+
+    vasync.forEachParallel({
+        func: function writeObject(objectUuid, done) {
+            var newObjectValue = jsprim.deepCopy(valueTemplate);
+            newObjectValue.uuid = objectUuid;
+            morayClient.putObject(bucketName, objectUuid, newObjectValue, done);
+        },
+        inputs: objectKeys
+    }, callback);
+}
+
+exports.data_migrations_invalid_filenames = function (t) {
+    var dataMigrationsLoaderLogger = bunyan.createLogger({
+        name: 'data-migrations-loader',
+        level: 'debug',
+        serializers: restify.bunyan.serializers
+    });
+
+    dataMigrationsLoader.loadMigrations({
+        log: dataMigrationsLoaderLogger,
+        migrationsRootPath: path.resolve(__dirname, 'fixtures',
+            'data-migrations-invalid-filenames')
+    }, function onMigrationsLoaded(loadMigrationsErr, migrations) {
+        var expectedErrorName = 'InvalidDataMigrationFileNamesError';
+
+        t.ok(loadMigrationsErr,
+            'loading migrations with invalid filenames should error');
+
+        if (loadMigrationsErr) {
+            t.ok(VError.hasCauseWithName(loadMigrationsErr, expectedErrorName),
+                'error should have a cause of ' + expectedErrorName);
+        }
+
+        t.done();
+    });
+};
+
+exports.data_migrations = function (t) {
+    var context = {};
+    var TRANSIENT_ERROR_MSG = 'Mocked transient error';
+
+    vasync.pipeline({arg: context, funcs: [
+        function cleanup(ctx, next) {
+            testMoray.cleanupLeftoverBuckets([
+                VMS_BUCKET_NAME,
+                SERVER_VMS_BUCKET_NAME,
+                ROLE_TAGS_BUCKET_NAME
+            ],
+            function onCleanupLeftoverBuckets(cleanupErr) {
+                t.ok(!cleanupErr,
+                    'cleaning up leftover buckets should be successful');
+                next(cleanupErr);
+            });
+        },
+        function setupMorayBuckets(ctx, next) {
+            var morayBucketsInitializer;
+            var morayClient;
+            var moraySetup = morayInit.startMorayInit({
+                morayConfig: common.config.moray,
+                morayBucketsConfig: TEST_BUCKETS_CONFIG,
+                changefeedPublisher: changefeedUtils.createNoopCfPublisher()
+            });
+            var nextOnce = once(next);
+
+            ctx.moray = moraySetup.moray;
+            ctx.morayBucketsInitializer = morayBucketsInitializer =
+                moraySetup.morayBucketsInitializer;
+            ctx.morayClient = morayClient = moraySetup.morayClient;
+
+            function cleanUp() {
+                morayBucketsInitializer.removeAllListeners('error');
+                morayBucketsInitializer.removeAllListeners('done');
+            }
+
+            morayBucketsInitializer.on('done', function onMorayBucketsInit() {
+                t.ok(true,
+                    'original moray buckets setup should be ' +
+                        'successful');
+
+                cleanUp();
+                nextOnce();
+            });
+
+            morayBucketsInitializer.on('error',
+                function onMorayBucketsInitError(morayBucketsInitErr) {
+                    t.ok(!morayBucketsInitErr,
+                        'original moray buckets initialization should ' +
+                            'not error');
+
+                    cleanUp();
+                    nextOnce(morayBucketsInitErr);
+                });
+        },
+        function writeTestObjects(ctx, next) {
+            assert.object(ctx.morayClient, 'ctx.morayClient');
+
+            writeObjects(ctx.morayClient, VMS_BUCKET_NAME, {
+                foo: 'foo'
+            }, NUM_TEST_OBJECTS, function onTestObjectsWritten(writeErr) {
+                t.ok(!writeErr, 'writing test objects should not error, got: ' +
+                    util.inspect(writeErr));
+                next(writeErr);
+            });
+        },
+        function loadDataMigrations(ctx, next) {
+            var dataMigrationsLoaderLogger = bunyan.createLogger({
+                name: 'data-migrations-loader',
+                level: 'info',
+                serializers: restify.bunyan.serializers
+            });
+
+            dataMigrationsLoader.loadMigrations({
+                log: dataMigrationsLoaderLogger,
+                migrationsRootPath: path.resolve(__dirname, 'fixtures',
+                    'data-migrations-valid')
+            }, function onMigrationsLoaded(loadMigrationsErr, migrations) {
+                ctx.migrations = migrations;
+                next(loadMigrationsErr);
+            });
+        },
+        function createMigrationsController(ctx, next) {
+            assert.object(ctx.migrations, 'ctx.migrations');
+            assert.object(ctx.moray, 'ctx.moray');
+
+            ctx.dataMigrationsCtrl = new DataMigrationsController({
+                log: bunyan.createLogger({
+                    name: 'data-migratons-controller',
+                    level: 'info',
+                    serializers: restify.bunyan.serializers
+                }),
+                migrations: ctx.migrations,
+                moray: ctx.moray
+            });
+
+            next();
+        },
+        function startVmapiService(ctx, next) {
+            ctx.vmapiApp = new VmapiApp({
+                apiClients: {
+                    wfapi: MOCKED_WFAPI_CLIENT
+                },
+                changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: ctx.dataMigrationsCtrl,
+                morayBucketsInitializer: ctx.morayBucketsInitializer,
+                moray: ctx.moray
+            });
+
+            ctx.vmapiApp.listen({port: 0}, function onVmapiListening() {
+                var vmapiServerAddress = ctx.vmapiApp.server.address();
+                var vmapiServerUrl = 'http://' + vmapiServerAddress.address +
+                    ':' + vmapiServerAddress.port;
+
+                ctx.vmapiClient = new VMAPI({
+                    url: vmapiServerUrl
+                });
+
+                next();
+            });
+        },
+        function checkDataMigrationsNoneStarted(ctx, next) {
+            assert.object(ctx.vmapiClient, 'ctx.vmapiClient');
+
+            ctx.vmapiClient.ping(function onVmapiPing(pingErr, obj, req, res) {
+                t.ok(!pingErr, 'pinging VMAPI when data migrations have not ' +
+                    'started yet should not error');
+                t.ok(obj, 'pinging VMAPI when data migrations have not ' +
+                    'started should return a non-empty response');
+                if (obj) {
+                    t.ok(obj.dataMigrations &&
+                        obj.dataMigrations.latestCompletedMigrations,
+                        'ping response should have a ' +
+                            'dataMigrations.latestCompletedMigrations ' +
+                            'property');
+                }
+                next();
+            });
+        },
+        function injectTransientError(ctx, next) {
+            ctx.originalPutBatch = ctx.moray.putBatch;
+            ctx.moray.putBatch =
+                function mockedPutBatch(modelName, records, callback) {
+                    assert.string(modelName, 'modelName');
+                    assert.arrayOfObject(records, 'records');
+                    assert.func(callback, 'callback');
+
+                    callback(new Error(TRANSIENT_ERROR_MSG));
+                };
+            next();
+        },
+        function startMigrations(ctx, next) {
+            ctx.dataMigrationsCtrl.start();
+
+            ctx.dataMigrationsCtrl.once('done',
+                function onDataMigrationsDone() {
+                    t.ok(false, 'data migrations should not complete when ' +
+                        'transient error injected');
+                });
+
+            ctx.dataMigrationsCtrl.once('error',
+                function onDataMigrationsError(dataMigrationErr) {
+                    t.ok(false, 'data migrations should not error when ' +
+                        'transient error injected');
+                });
+
+                next();
+        },
+        function checkDataMigrationsTransientError(ctx, next) {
+            var MAX_NUM_TRIES = 20;
+            var NUM_TRIES = 0;
+            var RETRY_DELAY_IN_MS = 1000;
+
+            assert.object(ctx.vmapiClient, 'ctx.vmapiClient');
+
+            function doCheckMigrationsStatus() {
+                ++NUM_TRIES;
+
+                ctx.vmapiClient.ping(function onPing(pingErr, obj, req, res) {
+                    var foundExpectedErrMsg;
+                    var latestVmsMigrationsErr;
+
+                    console.log('pingErr:', pingErr);
+                    console.log('obj:', obj);
+
+                    t.ok(!pingErr, 'pinging VMAPI when data migrations fail ' +
+                        'should return a non-error status, got: ' + pingErr);
+                    t.ok(obj, 'pinging VMAPI when data migrations fail ' +
+                        'should return a non-empty response, got: ' + obj);
+                    if (obj.dataMigrations &&
+                        obj.dataMigrations.latestErrors &&
+                        obj.dataMigrations.latestErrors.vms) {
+                        latestVmsMigrationsErr =
+                            obj.dataMigrations.latestErrors.vms;
+                        foundExpectedErrMsg =
+                            latestVmsMigrationsErr.indexOf(TRANSIENT_ERROR_MSG)
+                                !== -1;
+                        t.ok(foundExpectedErrMsg,
+                            'data migrations latest error should include ' +
+                                TRANSIENT_ERROR_MSG + ', got: ' +
+                                obj.dataMigrations.latestErrors.vms);
+                        next();
+                    } else {
+                        if (NUM_TRIES >= MAX_NUM_TRIES) {
+                            t.ok(false, 'max number of tries exceeded');
+                            next();
+                        } else {
+                            setTimeout(doCheckMigrationsStatus,
+                                RETRY_DELAY_IN_MS);
+                        }
+                    }
+                });
+            }
+
+            doCheckMigrationsStatus();
+        },
+        function checkInternalMetadataSearchError(ctx, next) {
+            ctx.vmapiClient.listVms({'internal_metadata.foo': 'bar'},
+                function onListVms(listVmsErr, obj, req, res) {
+                    var expectedErrorName = 'DataVersionError';
+
+                    t.ok(listVmsErr, 'searching on internal_metadata when ' +
+                        'the corresponding data migration has not completed ' +
+                        'should error');
+                    if (listVmsErr) {
+                        t.equal(listVmsErr.name, expectedErrorName,
+                            'Error name should be: ' + expectedErrorName +
+                                ', got: ' + listVmsErr.name);
+                    }
+
+                    next();
+                });
+        },
+        function removeTransientError(ctx, next) {
+            ctx.dataMigrationsCtrl.removeAllListeners('done');
+            ctx.dataMigrationsCtrl.removeAllListeners('error');
+
+            ctx.moray.putBatch = ctx.originalPutBatch;
+
+            ctx.dataMigrationsCtrl.once('done',
+                function onDataMigrationsDone() {
+                    t.ok(true,
+                        'data migration should eventually complete ' +
+                            'successfully');
+                    next();
+                });
+
+            ctx.dataMigrationsCtrl.once('error',
+                function onDataMigrationsError(dataMigrationErr) {
+                    t.ok(false, 'data migrations should not error, got: ',
+                        util.inspect(dataMigrationErr));
+                    next(dataMigrationErr);
+                });
+        },
+        function readTestObjects(ctx, next) {
+            assert.object(ctx.morayClient, 'ctx.morayClient');
+
+            findAllObjects(ctx.morayClient, VMS_BUCKET_NAME, '(foo=*)',
+                function onFindAllObjects(findErr, objects) {
+                    var nonMigratedObjects;
+
+                    t.ok(!findErr,
+                        'reading all objects back should not error, got: ' +
+                            util.inspect(findErr));
+                    t.ok(objects,
+                        'reading all objects should not return empty response');
+
+                    if (objects) {
+                        nonMigratedObjects =
+                            objects.filter(function checkObjects(object) {
+                                return object.value.bar !== 'foo';
+                            });
+                        t.equal(nonMigratedObjects.length, 0,
+                            'data migrations should have migrated all objects' +
+                                ', got the following non-migrated objects: ' +
+                                nonMigratedObjects.join(', '));
+                    }
+
+                    next(findErr);
+                });
+        },
+        function checkDataMigrationsDone(ctx, next) {
+            var latestExpectedCompletedVmsMigration = 1;
+
+            assert.object(ctx.vmapiClient, 'ctx.vmapiClient');
+
+            ctx.vmapiClient.ping(function onVmapiPing(pingErr, obj, req, res) {
+                t.ok(!pingErr, 'ping VMAPI when data migrations suceeded ' +
+                    'should not error, got: ' + pingErr);
+                t.ok(obj, 'pinging VMAPI when data migrations succeeded ' +
+                    'should return a non-empty response');
+
+                if (obj &&
+                    obj.dataMigrations &&
+                    obj.dataMigrations.latestCompletedMigrations) {
+                    t.equal(obj.dataMigrations.latestCompletedMigrations.vms,
+                        latestExpectedCompletedVmsMigration,
+                        'latest completed data migration for vms model ' +
+                            'should be at version ' +
+                            latestExpectedCompletedVmsMigration);
+                } else {
+                    t.ok(false, 'pinging VMAPI when data migrations ' +
+                        'succeeded should return an object with latest ' +
+                        'completed migrations, got: ' + util.inspect(obj));
+                }
+
+                next();
+            });
+        }
+    ]}, function allMigrationsDone(allMigrationsErr) {
+        t.ok(!allMigrationsErr, 'data migrations test should not error');
+
+        context.morayClient.close();
+        context.vmapiClient.close();
+        context.vmapiApp.close();
+
+        t.done();
+    });
+};
+
+exports.data_migrations_non_transient_error = function (t) {
+    var context = {};
+
+    vasync.pipeline({arg: context, funcs: [
+        function cleanup(ctx, next) {
+            testMoray.cleanupLeftoverBuckets([
+                VMS_BUCKET_NAME,
+                SERVER_VMS_BUCKET_NAME,
+                ROLE_TAGS_BUCKET_NAME
+            ],
+            function onCleanupLeftoverBuckets(cleanupErr) {
+                t.ok(!cleanupErr,
+                    'cleaning up leftover buckets should be successful');
+                next(cleanupErr);
+            });
+        },
+        function setupMorayBuckets(ctx, next) {
+            var morayBucketsInitializer;
+            var morayClient;
+            var moraySetup = morayInit.startMorayInit({
+                morayConfig: common.config.moray,
+                morayBucketsConfig: TEST_BUCKETS_CONFIG,
+                changefeedPublisher: changefeedUtils.createNoopCfPublisher()
+            });
+            var nextOnce = once(next);
+
+            ctx.moray = moraySetup.moray;
+            ctx.morayBucketsInitializer = morayBucketsInitializer =
+                moraySetup.morayBucketsInitializer;
+            ctx.morayClient = morayClient = moraySetup.morayClient;
+
+            function cleanUp() {
+                morayBucketsInitializer.removeAllListeners('error');
+                morayBucketsInitializer.removeAllListeners('done');
+            }
+
+            morayBucketsInitializer.on('done', function onMorayBucketsInit() {
+                t.ok(true,
+                    'original moray buckets setup should be ' +
+                        'successful');
+
+                cleanUp();
+                nextOnce();
+            });
+
+            morayBucketsInitializer.on('error',
+                function onMorayBucketsInitError(morayBucketsInitErr) {
+                    t.ok(!morayBucketsInitErr,
+                        'original moray buckets initialization should ' +
+                            'not error');
+
+                    cleanUp();
+                    nextOnce(morayBucketsInitErr);
+                });
+        },
+        function writeTestObjects(ctx, next) {
+            assert.object(ctx.morayClient, 'ctx.morayClient');
+
+            writeObjects(ctx.morayClient, VMS_BUCKET_NAME, {
+                foo: 'foo'
+            }, NUM_TEST_OBJECTS, function onTestObjectsWritten(writeErr) {
+                t.ok(!writeErr, 'writing test objects should not error, got: ' +
+                    util.inspect(writeErr));
+                next(writeErr);
+            });
+        },
+        function loadDataMigrations(ctx, next) {
+            var dataMigrationsLoaderLogger = bunyan.createLogger({
+                name: 'data-migrations-loader',
+                level: 'info',
+                serializers: restify.bunyan.serializers
+            });
+
+            dataMigrationsLoader.loadMigrations({
+                log: dataMigrationsLoaderLogger,
+                migrationsRootPath: path.resolve(__dirname, 'fixtures',
+                    'data-migrations-valid')
+            }, function onMigrationsLoaded(loadMigrationsErr, migrations) {
+                ctx.migrations = migrations;
+                next(loadMigrationsErr);
+            });
+        },
+        function injectNonTransientError(ctx, next) {
+            ctx.originalPutBatch = ctx.moray.putBatch;
+            ctx.moray.putBatch =
+                function mockedPutBatch(modelName, records, callback) {
+                    assert.string(modelName, 'modelName');
+                    assert.arrayOfObject(records, 'records');
+                    assert.func(callback, 'callback');
+
+                    callback(new VError({
+                        name: 'BucketNotFoundError'
+                    }, 'non-transient error'));
+                };
+            next();
+        },
+        function startMigrations(ctx, next) {
+            assert.object(ctx.migrations, 'ctx.migrations');
+            assert.object(ctx.moray, 'ctx.moray');
+
+            ctx.dataMigrationsCtrl = new DataMigrationsController({
+                log: bunyan.createLogger({
+                    name: 'data-migratons-controller',
+                    level: 'info',
+                    serializers: restify.bunyan.serializers
+                }),
+                migrations: ctx.migrations,
+                moray: ctx.moray
+            });
+
+            ctx.dataMigrationsCtrl.start();
+
+            ctx.dataMigrationsCtrl.once('done',
+                function onDataMigrationsDone() {
+                    t.ok(false, 'data migration should not complete when ' +
+                        'non-transient error injected');
+                });
+
+            ctx.dataMigrationsCtrl.once('error',
+                function onDataMigrationsError(dataMigrationErr) {
+                    t.ok(true, 'data migrations should error when ' +
+                        'non-transient error injected, got: ' +
+                        dataMigrationErr.toString());
+                    next();
+                });
+        }
+    ]}, function allMigrationsDone(allMigrationsErr) {
+        t.equal(allMigrationsErr, undefined,
+                'data migrations test should not error');
+        context.morayClient.close();
+        t.done();
+    });
+};
diff --git a/test/vms.list-filter-internal-metadata.test.js b/test/vms.list-filter-internal-metadata.test.js
new file mode 100644
index 0000000..baa2f2a
--- /dev/null
+++ b/test/vms.list-filter-internal-metadata.test.js
@@ -0,0 +1,259 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2017, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var async = require('async');
+var bunyan = require('bunyan');
+var Logger = require('bunyan');
+var restify = require('restify');
+var util = require('util');
+var vasync = require('vasync');
+
+var changefeedUtils = require('../lib/changefeed');
+var common = require('./common');
+var morayInit = require('../lib/moray/moray-init');
+var validation = require('../lib/common/validation');
+var vmTest = require('./lib/vm');
+
+var client;
+var moray;
+var morayClient;
+
+var testLogger = bunyan.createLogger({
+    name: 'test-internal-metadata',
+    level: 'debug',
+    serializers: restify.bunyan.serializers
+});
+
+function runValidationErrorTestCase(t, testCase, callback) {
+    assert.object(t, 't');
+    assert.object(testCase, 'testCase');
+    assert.string(testCase.queryString, 'testCase.queryString');
+    assert.object(testCase.expectedErr, 'testCase.expectedErr');
+    assert.func(callback, 'callback');
+
+    var listVmsQuery = '/vms?' + testCase.queryString;
+
+    client.get(listVmsQuery, function onListVms(err, req, res, body) {
+        t.ok(err, 'listing VMs should error');
+        if (err) {
+            t.deepEqual(body, testCase.expectedErr,
+                'Error should be equal to ' +
+                    util.inspect(testCase.expectedErr) + ', got: ' +
+                    util.inspect(err));
+        }
+
+        callback();
+    });
+}
+
+function runValidTestCase(t, testCase, callback) {
+    assert.object(t, 't');
+    assert.object(testCase, 'testCase');
+    assert.arrayOfString(testCase.queryStrings, 'testCase.queryStrings');
+    assert.arrayOfObject(testCase.vmsToCreate, 'testCase.vmsToCreate');
+    assert.func(callback, 'callback');
+
+    var createdVmUuids = [];
+    var vmsToCreate = testCase.vmsToCreate;
+
+    vasync.pipeline({funcs: [
+        function createTestVms(_, next) {
+            vasync.forEachPipeline({
+                func: function createTestVm(vmParams, done) {
+                    vmTest.createTestVm(moray, {log: testLogger}, vmParams,
+                        function onVmCreated(vmCreatErr, vmUuid) {
+                            createdVmUuids.push(vmUuid);
+                            done(vmCreatErr);
+                        });
+                },
+                inputs: vmsToCreate
+            }, next);
+        },
+        function listVms(_, next) {
+            vasync.forEachPipeline({func: function doList(queryString, done) {
+                var idx;
+                var query = '/vms?' + queryString;
+                var returnedVm;
+
+                client.get(query, function onList(err, req, res, body) {
+                    t.ok(!err, 'listing VM with query string "' + query +
+                        '"should not error');
+                    t.ok(body, 'response should not be empty');
+                    if (body) {
+                        t.equal(body.length, vmsToCreate.length,
+                            'response should include ' +
+                                vmsToCreate.length + ' VMs, got: ' +
+                                body.length);
+
+                        for (idx = 0; idx < body.length; ++idx) {
+                            returnedVm = body[idx];
+                            t.notEqual(createdVmUuids.indexOf(returnedVm.uuid),
+                                -1,
+                                'returned VM UUID (' + returnedVm.uuid + ') ' +
+                                    'should be included in created VMs UUIDs ' +
+                                    '(' + createdVmUuids.join(', ') + ')');
+                        }
+                    }
+
+                    done();
+                });
+            }, inputs: testCase.queryStrings
+            }, next);
+        },
+        function deleteTestVms(_, next) {
+            vmTest.deleteTestVMs(moray, {}, next);
+        }
+    ]}, function onDone(err) {
+        t.ifError(err);
+        callback();
+    });
+}
+
+exports.setUp = function (callback) {
+    common.setUp(function (err, _client) {
+        assert.ifError(err);
+        assert.ok(_client, 'restify client');
+        client = _client;
+        callback();
+    });
+};
+
+exports.init_storage_layer = function (t) {
+    var morayBucketsInitializer;
+
+    var moraySetup = morayInit.startMorayInit({
+        morayConfig: common.config.moray,
+        maxBucketsReindexAttempts: 1,
+        maxBucketsSetupAttempts: 1,
+        changefeedPublisher: changefeedUtils.createNoopCfPublisher()
+    });
+
+    morayBucketsInitializer = moraySetup.morayBucketsInitializer;
+    morayClient = moraySetup.morayClient;
+    moray = moraySetup.moray;
+
+    morayBucketsInitializer.on('done', function onMorayStorageReady() {
+        t.done();
+    });
+};
+
+exports.cleanup_leftover_test_vms = function (t) {
+    vmTest.deleteTestVMs(moray, {}, function onTestVmsDeleted(delTestVmsErr) {
+        t.ifError(delTestVmsErr, 'Deleting test VMs should not error');
+        t.done();
+    });
+};
+
+exports.run_validation_error_tests = function (t) {
+    var testCases = [
+        {
+            queryString: 'internal_metadata.=foo',
+            expectedErr: {
+                code: 'ValidationFailed',
+                message: 'Invalid Parameters',
+                errors: [ {
+                    field: 'internal_metadata',
+                    code: 'Invalid',
+                    message: 'Invalid internal_metadata key: ""'
+                } ]
+            }
+        },
+        {
+            queryString: 'internal_metadata.foo=',
+            expectedErr: {
+                code: 'ValidationFailed',
+                message: 'Invalid Parameters',
+                errors: [ {
+                    field: 'internal_metadata',
+                    code: 'Invalid',
+                    message: 'Invalid internal_metadata value: ""'
+                } ]
+            }
+        }
+    ];
+
+    vasync.forEachPipeline({
+        func: runValidationErrorTestCase.bind(null, t),
+        inputs: testCases
+    }, function onAllValidationErrorTestCasesRan(err) {
+        t.done();
+    });
+};
+
+exports.run_valid_test_cases = function (t) {
+    var testCases = [
+        /*
+         * Simple key/value format.
+         */
+        {
+            vmsToCreate: [ {internal_metadata: {'key': 'foo'}} ],
+            queryStrings: [
+                'internal_metadata.key=foo',
+                'predicate=' + JSON.stringify({
+                    eq: ['internal_metadata.key', 'foo']
+                }),
+                'query=(internal_metadata_search_array=key=foo)'
+            ]
+        },
+        /*
+         * Dotted key.
+         */
+        {
+            vmsToCreate: [ {internal_metadata: {'some.key': 'foo'}} ],
+            queryStrings: [
+                'internal_metadata.some.key=foo',
+                'predicate=' + JSON.stringify({
+                    eq: ['internal_metadata.some.key', 'foo']
+                }),
+                'query=(internal_metadata_search_array=some.key=foo)'
+            ]
+        },
+        /*
+         * Namespaced key.
+         */
+        {
+            vmsToCreate: [ {internal_metadata: {'some:key': 'foo'}} ],
+            queryStrings: [
+                'internal_metadata.some:key=foo',
+                'predicate=' + JSON.stringify({
+                    eq: ['internal_metadata.some:key', 'foo']
+                }),
+                'query=(internal_metadata_search_array=some:key=foo)'
+            ]
+        },
+        /*
+         * Key with equal ("=") character in it.
+         */
+        {
+            vmsToCreate: [ {internal_metadata: {'some=key': 'foo'}} ],
+            queryStrings: [
+                'internal_metadata.some%3Dkey=foo',
+                'predicate=' + JSON.stringify({
+                    eq: ['internal_metadata.some=key', 'foo']
+                }),
+                'query=(internal_metadata_search_array=some=key=foo)'
+            ]
+        }
+    ];
+
+    vasync.forEachPipeline({
+        func: runValidTestCase.bind(null, t),
+        inputs: testCases
+    }, function onAllValidTestCasesRan(err) {
+        t.done();
+    });
+};
+
+exports.close_clients = function (t) {
+    morayClient.close();
+    client.close();
+    t.done();
+};
\ No newline at end of file
diff --git a/test/vms.reindex-moray-bucket-transient-error.test.js b/test/vms.reindex-moray-bucket-transient-error.test.js
index 7403526..f52316a 100644
--- a/test/vms.reindex-moray-bucket-transient-error.test.js
+++ b/test/vms.reindex-moray-bucket-transient-error.test.js
@@ -29,6 +29,8 @@ var vasync = require('vasync');
 var changefeedUtils = require('../lib/changefeed');
 var common = require('./common');
 var morayInit = require('../lib/moray/moray-init');
+var NoopDataMigrationsController =
+    require('../lib/data-migrations/noop-controller');
 var VmapiApp = require('../lib/vmapi');
 
 var TRANSIENT_ERROR_MSG = 'Mocked transient error';
@@ -57,9 +59,9 @@ var ROLE_TAGS_MORAY_BUCKET_CONFIG = {
 };
 
 var MORAY_BUCKETS_CONFIG = {
-    VMS: VMS_BUCKET_CONFIG,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG
+    vms: VMS_BUCKET_CONFIG,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG
 };
 
 exports.moray_init_transient_error = function (t) {
@@ -100,6 +102,7 @@ exports.moray_init_transient_error = function (t) {
                     wfapi: mockedWfapiClient
                 },
                 changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: new NoopDataMigrationsController(),
                 morayBucketsInitializer: morayBucketsInitializer,
                 moray: moray
             });
diff --git a/test/vms.update-moray-bucket-non-transient-error.test.js b/test/vms.update-moray-bucket-non-transient-error.test.js
index d1c132c..83b53d2 100644
--- a/test/vms.update-moray-bucket-non-transient-error.test.js
+++ b/test/vms.update-moray-bucket-non-transient-error.test.js
@@ -26,6 +26,8 @@ var vasync = require('vasync');
 var changefeedUtils = require('../lib/changefeed');
 var common = require('./common');
 var morayInit = require('../lib/moray/moray-init');
+var NoopDataMigrationsController =
+    require('../lib/data-migrations/noop-controller');
 var testMoray = require('./lib/moray');
 var VmapiApp = require('../lib/vmapi');
 
@@ -76,9 +78,9 @@ var ROLE_TAGS_MORAY_BUCKET_CONFIG = {
 };
 
 var morayBucketsConfigWithError = {
-    VMS: VMS_BUCKET_CONFIG_WITH_ERROR,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG
+    vms: VMS_BUCKET_CONFIG_WITH_ERROR,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG
 };
 
 exports.moray_init_non_transient_error = function (t) {
@@ -97,9 +99,9 @@ exports.moray_init_non_transient_error = function (t) {
     vasync.pipeline({funcs: [
         function cleanLeftoverTestBuckets(arg, next) {
             testMoray.cleanupLeftoverBuckets([
-                morayBucketsConfigWithError.VMS.name,
-                morayBucketsConfigWithError.SERVER_VMS.name,
-                morayBucketsConfigWithError.VM_ROLE_TAGS.name
+                morayBucketsConfigWithError.vms.name,
+                morayBucketsConfigWithError.server_vms.name,
+                morayBucketsConfigWithError.vm_role_tags.name
             ],
             function onCleanupLeftoverBuckets(cleanupErr) {
                 t.ifError(cleanupErr,
@@ -131,6 +133,7 @@ exports.moray_init_non_transient_error = function (t) {
                     wfapi: mockedWfapiClient
                 },
                 changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: new NoopDataMigrationsController(),
                 morayBucketsInitializer: morayBucketsInitializer,
                 moray: moray
             });
diff --git a/test/vms.update-moray-bucket-removes-index-fails.test.js b/test/vms.update-moray-bucket-removes-index-fails.test.js
index c48d4ba..a7da666 100644
--- a/test/vms.update-moray-bucket-removes-index-fails.test.js
+++ b/test/vms.update-moray-bucket-removes-index-fails.test.js
@@ -24,6 +24,8 @@ var vasync = require('vasync');
 var changefeedUtils = require('../lib/changefeed');
 var common = require('./common');
 var morayInit = require('../lib/moray/moray-init');
+var NoopDataMigrationsController =
+    require('../lib/data-migrations/noop-controller');
 var testMoray = require('./lib/moray');
 var VmapiApp = require('../lib/vmapi');
 
@@ -64,15 +66,15 @@ var ROLE_TAGS_MORAY_BUCKET_CONFIG = {
 };
 
 var morayBucketsConfigV0 = {
-    VMS: VMS_BUCKET_CONFIG_V0,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG
+    vms: VMS_BUCKET_CONFIG_V0,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG
 };
 
 var morayBucketsConfigV1 = {
-    VMS: VMS_BUCKET_CONFIG_V1,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG
+    vms: VMS_BUCKET_CONFIG_V1,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG
 };
 
 var morayBucketsInitializer;
@@ -94,9 +96,9 @@ exports.moray_init_invalid_index_removal = function (t) {
     vasync.pipeline({funcs: [
         function cleanLeftoverTestBuckets(arg, next) {
             testMoray.cleanupLeftoverBuckets([
-                morayBucketsConfigV0.VMS.name,
-                morayBucketsConfigV0.SERVER_VMS.name,
-                morayBucketsConfigV0.VM_ROLE_TAGS.name
+                morayBucketsConfigV0.vms.name,
+                morayBucketsConfigV0.server_vms.name,
+                morayBucketsConfigV0.vm_role_tags.name
             ],
             function onCleanupLeftoverBuckets(cleanupErr) {
                 t.ifError(cleanupErr,
@@ -153,6 +155,7 @@ exports.moray_init_invalid_index_removal = function (t) {
                     wfapi: mockedWfapiClient
                 },
                 changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: new NoopDataMigrationsController(),
                 morayBucketsInitializer: morayBucketsInitializer,
                 moray: moray
             });
diff --git a/test/vms.update-moray-bucket-transient-error.test.js b/test/vms.update-moray-bucket-transient-error.test.js
index 2d109fd..e91ebb5 100644
--- a/test/vms.update-moray-bucket-transient-error.test.js
+++ b/test/vms.update-moray-bucket-transient-error.test.js
@@ -26,6 +26,8 @@ var vasync = require('vasync');
 var changefeedUtils = require('../lib/changefeed');
 var common = require('./common');
 var morayInit = require('../lib/moray/moray-init');
+var NoopDataMigrationsController =
+    require('../lib/data-migrations/noop-controller');
 var VmapiApp = require('../lib/vmapi');
 
 var TRANSIENT_ERROR_MSG = 'Mocked transient error';
@@ -67,6 +69,7 @@ exports.moray_init_transient_error = function (t) {
                     wfapi: mockedWfapiClient
                 },
                 changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: new NoopDataMigrationsController(),
                 morayBucketsInitializer: morayBucketsInitializer,
                 moray: moray
             });
diff --git a/test/vms.update-moray-bucket-versioning.test.js b/test/vms.update-moray-bucket-versioning.test.js
index 7f4af20..469ddda 100644
--- a/test/vms.update-moray-bucket-versioning.test.js
+++ b/test/vms.update-moray-bucket-versioning.test.js
@@ -21,6 +21,8 @@ var VMAPI = require('sdc-clients').VMAPI;
 var changefeedUtils = require('../lib/changefeed');
 var common = require('./common');
 var morayInit = require('../lib/moray/moray-init');
+var NoopDataMigrationsController =
+    require('../lib/data-migrations/noop-controller');
 var testMoray = require('./lib/moray.js');
 var VmapiApp = require('../lib/vmapi');
 
@@ -122,21 +124,21 @@ var ROLE_TAGS_MORAY_BUCKET_CONFIG_V2 = {
 };
 
 var testBucketsConfigV0 = {
-    VMS: VMS_BUCKET_CONFIG_V0,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG_V0,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG_V0
+    vms: VMS_BUCKET_CONFIG_V0,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG_V0,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG_V0
 };
 
 var testBucketsConfigV1 = {
-    VMS: VMS_BUCKET_CONFIG_V1,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG_V1,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG_V1
+    vms: VMS_BUCKET_CONFIG_V1,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG_V1,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG_V1
 };
 
 var testBucketsConfigV2 = {
-    VMS: VMS_BUCKET_CONFIG_V2,
-    SERVER_VMS: SERVER_VMS_MORAY_BUCKET_CONFIG_V2,
-    VM_ROLE_TAGS: ROLE_TAGS_MORAY_BUCKET_CONFIG_V2
+    vms: VMS_BUCKET_CONFIG_V2,
+    server_vms: SERVER_VMS_MORAY_BUCKET_CONFIG_V2,
+    vm_role_tags: ROLE_TAGS_MORAY_BUCKET_CONFIG_V2
 };
 
 var NB_TEST_OBJECTS = 200;
@@ -321,6 +323,7 @@ function testMigrationToBucketsConfig(bucketsConfig, options, t, callback) {
                     wfapi: MOCKED_WFAPI_CLIENT
                 },
                 changefeedPublisher: changefeedUtils.createNoopCfPublisher(),
+                dataMigrationsCtrl: new NoopDataMigrationsController(),
                 morayBucketsInitializer: morayBucketsInitializer,
                 moray: storage
             });
diff --git a/tools/jsl.node.conf b/tools/jsl.node.conf
index 8bf9239..60a5944 100644
--- a/tools/jsl.node.conf
+++ b/tools/jsl.node.conf
@@ -119,6 +119,7 @@
 +define require
 +define setInterval
 +define setTimeout
++define setImmediate
 +define Buffer
 +define JSON
 +define Math
