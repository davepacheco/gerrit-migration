From a968cbeede4bff9f4c2b3f3603d029f2db13b929 Mon Sep 17 00:00:00 2001
From: Pedro Palazon Candel <pedro@joyent.com>
Date: Fri, 18 May 2018 11:37:07 +0200
Subject: [PATCH] TOOLS-1977 Modify `sdcadm post-setup ha-binder` to move insts
 to different servers Reviewed by: Marsell Kukuljevic <marsell@joyent.com>
 Approved by: Marsell Kukuljevic <marsell@joyent.com>

---
 .eslintrc                                    |    2 +-
 CHANGES.md                                   |    5 +
 docs/post-setup.md                           |    8 +-
 lib/cli/do_create.js                         |    2 +-
 lib/common.js                                |   95 +-
 lib/post-setup/ha-binder.js                  | 1258 ++++++------------
 lib/procedures/create-service-instance-v1.js |   45 +-
 lib/procedures/shared.js                     |  117 +-
 lib/sdcadm.js                                |   57 +-
 lib/steps/index.js                           |    3 +-
 lib/steps/zookeeper.js                       |  790 +++++++++++
 lib/vmadm.js                                 |    3 +-
 man/man1/sdcadm.1.ronn                       |   66 +-
 package.json                                 |    2 +-
 test/post-setup-ha-binder.test.js            |  230 ++++
 test/post-setup.test.js                      |   44 -
 16 files changed, 1670 insertions(+), 1057 deletions(-)
 create mode 100644 lib/steps/zookeeper.js
 create mode 100644 test/post-setup-ha-binder.test.js

diff --git a/.eslintrc b/.eslintrc
index 4116c30..65c08ff 100644
--- a/.eslintrc
+++ b/.eslintrc
@@ -6,7 +6,7 @@
         "plugin:joyent/lint"
     ],
     "parserOptions": {
-        "ecmaVersion": 5,
+        "ecmaVersion": 6,
         "sourceType": "script",
         "ecmaFeatures": {
         }
diff --git a/CHANGES.md b/CHANGES.md
index 385a85b..0059cfe 100644
--- a/CHANGES.md
+++ b/CHANGES.md
@@ -10,6 +10,11 @@
 
 # sdcadm Changelog
 
+## 1.17.4
+
+- TOOLS-1977 Modify `sdcadm post-setup ha-binder` to move insts to different servers
+- TOOLS-1224 `sdcadm <subcommand> -h|--help` hits SAPI to get the sdc app: that's overkill
+
 ## 1.17.3
 
 - TRITON-348 Support for using eslint
diff --git a/docs/post-setup.md b/docs/post-setup.md
index a743e32..8c080ec 100644
--- a/docs/post-setup.md
+++ b/docs/post-setup.md
@@ -11,7 +11,7 @@ apisections:
 -->
 
 <!--
-    Copyright 2017 Joyent, Inc.
+    Copyright 2018 Joyent, Inc.
 -->
 
 # Triton post-setup with sdcadm
@@ -49,15 +49,13 @@ In case this is a setup already being used by non-administrator users, it's a
 good idea to put the DC in maintenance first
 (`sdcadm dc-maint start`). Then:
 
-    sdcadm post-setup ha-binder \
-        --servers=`CN1_UUID` \
-        --servers=`CN2_UUID`
+    sdcadm post-setup ha-binder headnode CN1_UUID CN2_UUID
 
 This command will create 2 more binder instances, one placed on the CN
 identified by CN1\_UUID, and the other CN identified by CN2\_UUID.
 
 If you need to create a cluster of 5 instances, you just need to pass a couple
-additional CN UUIDs to this command together with the `--members=4` argument.
+additional CN UUIDs to this command.
 
 Once the binder instances have been configured, and all of them have joined
 the *"cluster"*, manatee and moray will be restarted to begin using this
diff --git a/lib/cli/do_create.js b/lib/cli/do_create.js
index 2e5b96a..17f5736 100644
--- a/lib/cli/do_create.js
+++ b/lib/cli/do_create.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright 2017 Joyent, Inc.
+ * Copyright 2018 Joyent, Inc.
  */
 
 var p = console.log;
diff --git a/lib/common.js b/lib/common.js
index 5fec74d..9533f9c 100644
--- a/lib/common.js
+++ b/lib/common.js
@@ -21,6 +21,7 @@ var util = require('util');
 var vasync = require('vasync');
 var backoff = require('backoff');
 var once = require('once');
+var sprintf = require('extsprintf').sprintf;
 
 var errors = require('./errors');
 var InternalError = errors.InternalError;
@@ -848,17 +849,29 @@ function manateeAdmRemote(opts, cb) {
             cb(execErr);
             return;
         }
+
+        var err, res, resErr, out;
+
+        if (stderr) {
+            err = stderr;
+        }
         try {
-            // Due to the -j option of sdc-oneachnode:
-            var res = JSON.parse(stdout);
-            var out = res[0].result.stdout.trim() || null;
-            var err = res[0].result.stderr.trim() || null;
-            cb(null, out, err);
-        } catch (_e) {
-            // In case of error, just return the raw result for later
-            // inspection, given it doesn't have the expected JSON format:
-            cb(execErr, stdout, stderr);
+            res = JSON.parse(stdout);
+        } catch (e) {
+            resErr = e;
+        }
+        if (!Array.isArray(res) || !res.length || !res[0].result) {
+            resErr = new errors.InternalError({
+                message: 'manatee-adm state: error: unable to connect to zk'
+            });
+        } else {
+            const output = res[0].result;
+            out = output.stdout ? output.stdout.trim() : '';
+            if (!err && output.stderr) {
+                err = output.stderr.trim();
+            }
         }
+        cb(resErr, out, err);
     });
 }
 
@@ -907,20 +920,17 @@ function manateeShardStatus(opts, cb) {
             return cb(err);
         }
 
-        var rawPgSt = JSON.parse(stdout);
-        if (!rawPgSt.length || !rawPgSt[0].result ||
-                rawPgSt[0].result.exit_status !== 0) {
-            return cb(new errors.InternalError({
-                message: 'Unexpected manatee-adm pg-status output'
-            }));
-        }
-        var pgSt = rawPgSt[0].result.stdout.trim().split('\n');
+        // We are intentionally ignoring `stderr` here. We already have all
+        // the information we need from this function from `stdout` which is
+        // the JSON parsed output of our cmd result.
+
+        var shardPgSt = {};
+
+        var pgSt = stdout.trim().split('\n');
         pgSt = pgSt.map(function (m) {
             return m.trim().split(/\s+/);
         });
 
-        var shardPgSt = {};
-
         pgSt.forEach(function (m) {
             if (m[0] === 'primary' || m[0] === 'sync') {
                 shardPgSt[m[0]] = {
@@ -965,8 +975,8 @@ function manateeFreeze(opts, cb) {
     manateeAdmRemote(opts, function (err, stdout, stderr) {
         if (err) {
             return cb(err);
-        } else if (stderr) {
-            return cb(new errors.InternalError(stderr));
+        } else if (stderr && stderr.indexOf('already been frozen') === -1) {
+            return cb(new errors.InternalError({message: stderr}));
         }
         return cb();
     });
@@ -1172,17 +1182,25 @@ function execRemote(opts, cb) {
             cb(execErr);
             return;
         }
+        var res, parseErr, out, err;
         try {
             // Due to the -j option of sdc-oneachnode:
-            var res = JSON.parse(stdout);
-            var out = res[0].result.stdout.trim() || null;
-            var err = res[0].result.stderr.trim() || null;
-            cb(null, out, err);
-        } catch (_e) {
-            // In case of error, just return the raw result for later
-            // inspection, given it doesn't have the expected JSON format:
-            cb(execErr, stdout, stderr);
+            res = JSON.parse(stdout);
+        } catch (e) {
+            parseErr = e;
         }
+        if (!Array.isArray(res) || !res.length || !res[0].result) {
+            parseErr = new errors.InternalError({
+                message: 'Unexpected sdc-oneachnode output'
+            });
+        } else {
+            const output = res[0].result;
+            out = output.stdout.trim() || null;
+            err = output.stderr ? new errors.InternalError({
+                message: output.stderr.trim()
+            }) : null;
+        }
+        cb(parseErr, out, err);
     });
 }
 
@@ -1671,6 +1689,22 @@ function serverAdminIpFromSysinfo(sysinfo) {
     return adminIp;
 }
 
+function utcTimestamp(start) {
+    assert.optionalDate(start, 'start');
+    if (!start) {
+        start = new Date();
+    }
+    var stamp = sprintf('%d%02d%02dT%02d%02d%02dZ',
+        start.getUTCFullYear(),
+        start.getUTCMonth() + 1,
+        start.getUTCDate(),
+        start.getUTCHours(),
+        start.getUTCMinutes(),
+        start.getUTCSeconds());
+
+    return stamp;
+}
+
 // --- exports
 
 module.exports = {
@@ -1707,6 +1741,7 @@ module.exports = {
     unmountUsbKey: unmountUsbKey,
     copyFile: copyFile,
     safeCycles: safeCycles,
-    serverAdminIpFromSysinfo: serverAdminIpFromSysinfo
+    serverAdminIpFromSysinfo: serverAdminIpFromSysinfo,
+    utcTimestamp: utcTimestamp
 };
 // vim: set softtabstop=4 shiftwidth=4:
diff --git a/lib/post-setup/ha-binder.js b/lib/post-setup/ha-binder.js
index 7b6e94f..1edb3ba 100644
--- a/lib/post-setup/ha-binder.js
+++ b/lib/post-setup/ha-binder.js
@@ -13,12 +13,8 @@
  */
 
 var p = console.log;
-var util = require('util');
-var path = require('path');
-var fs = require('fs');
 var sprintf = require('extsprintf').sprintf;
 var vasync = require('vasync');
-var mkdirp = require('mkdirp');
 
 var common = require('../common');
 var errors = require('../errors');
@@ -62,11 +58,9 @@ function do_ha_binder(subcmd, opts, args, cb) {
     if (opts.help) {
         this.do_help('help', {}, [subcmd], cb);
         return;
-    } else if (args.length > 0) {
-        cb(new errors.UsageError('too many args: ' + args));
-        return;
     }
 
+    // Deprecation warning for `sdcadm post-setup zookeeper`:
     if (subcmd === 'zookeeper') {
         self.progress('Warning: `sdcadm post-setup zookeeper` is deprecated.' +
             '\n' + common.indent(
@@ -74,40 +68,53 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 '         '));
     }
 
-    if (opts.members !== 2 && opts.members !== 4) {
-        cb(new errors.UsageError('Invalid number of binder cluster members: ' +
-            opts.members));
+    // Usage Error: we need at least one server:
+    var aLen = args.length;
+    if (!opts.servers && aLen !== 1 && aLen !== 3 && aLen !== 5) {
+        cb(new errors.UsageError('invalid number of args; 1, 3 or 5 servers ' +
+                    'are required'));
         return;
     }
 
-    if (!opts.servers || !opts.servers.length ||
-            opts.servers.length < (opts.members - 1)) {
-        cb(new errors.UsageError('Must specify ' +
-            (opts.members - 1) + ' servers'));
-        return;
-
+    // Deprecation warning for `-s|--servers` option:
+    if (opts.servers) {
+        self.progress('Warning: `-s|--servers` option is deprecated.\n' +
+            common.indent(
+                'Please use `sdcadm post-setup ha-binder SERVER ...` instead.',
+                '         '));
+        // We only allow 2 or 4 servers given to the backwards compat mode:
+        if (opts.servers.length !== 2 && opts.servers.length !== 4) {
+            cb(new errors.UsageError(
+                'Invalid number of binder cluster members: ' +
+                opts.servers.length + '. 2 or 4 servers are required'));
+        }
     }
 
     var app = self.sdcadm.sdc;
     var img, instances, history;
     var vms;
-    var oldVms;
+    var existingVmsUUIDs = [];
     var newVms = [];
-    var nextId = 0;
+    // The given server UUIDs, w/o validation:
+    var targetServerUUIDs = [];
+    // VMs we want to remove:
+    var instancesToDelete = [];
+    // Existing instances w/o modifications:
+    var remainingInstances = [];
+    // Servers we will create instances on:
     var servers = [];
     var changes = []; // used by history functions
     var arg = {}; // to pass to shared.js functions
-    var HA_ZK_JSON = [];
-    var moraySvc, manateeSvc;
-    var morayVms, manateeVms;
-    var shard;
-    var leaderIP;
-    var duplicatedServers = false;
-    var start = new Date();
-    var wrkDir;
-    var stamp;
-    var hasManatee21 = false;
+
     var willCreateInsts = true;
+    var willRemoveInsts = false;
+
+    // Used to call a lot of functions, let's save some duplication:
+    var commonOpts = {
+        sdcadm: self.sdcadm,
+        progress: self.progress,
+        log: self.log
+    };
 
     vasync.pipeline({arg: arg, funcs: [
         function getBinderSvc(ctx, next) {
@@ -117,12 +124,13 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 application_uuid: app.uuid
             }, function (svcErr, svcs) {
                 if (svcErr) {
-                    return next(svcErr);
+                    next(svcErr);
+                    return;
                 }
                 if (svcs.length) {
                     ctx.binderSvc = svcs[0];
                 }
-                return next();
+                next();
             });
         },
 
@@ -151,73 +159,187 @@ function do_ha_binder(subcmd, opts, args, cb) {
             self.progress('Getting SDC\'s binder vms from VMAPI');
             self.sdcadm.vmapi.listVms({
                 'tag.smartdc_role': 'binder',
-                state: 'running'
+                state: 'running',
+                sort: 'create_timestamp.asc'
             }, function (vmsErr, vms_) {
                 if (vmsErr) {
-                    return next(vmsErr);
+                    next(vmsErr);
+                    return;
                 }
                 vms = vms_;
-                oldVms = vms_.map(function (vm) {
+                existingVmsUUIDs = vms_.map(function (vm) {
                     return vm.uuid;
                 });
-                return next();
+                next();
             });
         },
 
-        function checkTargetServers(_, next) {
-            if (instances && instances.length === (opts.members + 1)) {
-                willCreateInsts = false;
-                next();
-                return;
-            }
-            self.progress('Verifying target severs "%j" exist', opts.servers);
-            self.sdcadm.cnapi.listServers(function (sErr, servers_) {
-                if (sErr) {
-                    return next(sErr);
+        function preloadCnapiServers(ctx, next) {
+            self.sdcadm.cnapi.listServers({
+                setup: true
+            }, function listServersCb(listServersErr, cnapiSetupServers) {
+                if (listServersErr) {
+                    next(listServersErr);
+                    return;
                 }
+                ctx.cnapiServers = cnapiSetupServers;
+                next();
+            });
+        },
 
-                var msg = 'Either you haven\'t provided ' + opts.members +
-                    ' valid Server UUIDs, or the ones you\'ve provided ' +
-                    'do not belong to servers setup in CNAPI.\nPlease ' +
-                    'provide the UUIDs for ' + opts.members +
-                    ' setup servers.';
-
-                servers = servers_.filter(function (s) {
-                    return (opts.servers.indexOf(s.uuid) !== -1);
+        // Backwards compatibility:
+        function getServersFromArgs(ctx, next) {
+            if (opts.servers) {
+                var headnodeUuid;
+                // We only support this backward compatible option if we have
+                // a binder instance on the headnode. Let's double check it:
+                const binderOnHeadnode = vms.some(function (vm) {
+                    return ctx.cnapiServers.some(function findHeadnode(server) {
+                        if (server.uuid === vm.server_uuid &&
+                            server.headnode) {
+                            headnodeUuid = server.uuid;
+                            return true;
+                        }
+                        return false;
+                    });
                 });
 
-                // Check if the minimum required number of servers have been
-                // provided (even duplicates):
-                if (opts.servers.length !== opts.members) {
-                    return next(new errors.UsageError(msg));
+                if (!binderOnHeadnode) {
+                    next(new errors.UsageError(
+                        '`-s|--servers` option is only supported when there ' +
+                        'is a binder instance running into the headnode'));
+                    return;
                 }
 
-                // Check if any of the provided servers is duplicate:
-                var unique = opts.servers.filter(function (item, pos, ary) {
-                    return (ary.indexOf(item) === pos);
-                });
+                targetServerUUIDs = opts.servers.concat(headnodeUuid);
+            } else {
+                targetServerUUIDs = args;
+            }
 
-                if (unique.length !== opts.servers.length) {
-                    duplicatedServers = true;
+            // Ensure we always have the server UUID, given hostnames are
+            // accepted as arguments:
+            var invalidUuidsOrHostnames = [];
+            targetServerUUIDs = targetServerUUIDs.map(function ensureUUIDs(s) {
+                if (common.UUID_RE.test(s)) {
+                    const validUuid = ctx.cnapiServers.some(function (server) {
+                        return (server.uuid && server.uuid === s);
+                    });
+                    if (!validUuid) {
+                        invalidUuidsOrHostnames.push(s);
+                    }
+                    return validUuid ? s : null;
+                } else {
+                    var sByHost = ctx.cnapiServers.filter(function byHost(sr) {
+                        return (sr.hostname === s);
+                    });
+
+                    if (!sByHost.length) {
+                        invalidUuidsOrHostnames.push(s);
+                    }
+                    return sByHost.length ? sByHost[0].uuid : null;
                 }
+            }).filter(function avoidNulls(x) {
+                return (x !== undefined && x !== null);
+            });
+            if (invalidUuidsOrHostnames.length) {
+                next(new errors.UsageError(
+                    'Must provide valid server UUIDs or hostnames. "' +
+                    invalidUuidsOrHostnames.join(', ') +
+                    '" are not valid setup servers.'));
+                return;
+            }
+            next();
+        },
 
-                if (unique.length !== servers.length) {
-                    return next(new errors.UsageError(msg));
+        function getModifications(_, next) {
+            // We may want to keep an instance into a given server and remove
+            // others from that server, for example, if going from:
+            // `sdcadm post-setup ha-binder headnode headnode headnode` to
+            // `sdcadm post-setup ha-binder headnode`; i.e, from HA back to
+            // non-HA
+            var finalServers = [].concat(targetServerUUIDs);
+            vms.forEach(function (vm) {
+                var pos = finalServers.indexOf(vm.server_uuid);
+                if (pos !== -1) {
+                    remainingInstances.push(vm);
+                    delete finalServers[pos];
+                } else {
+                    instancesToDelete.push(vm);
                 }
-                return next();
             });
+
+            if (instancesToDelete.length) {
+                willRemoveInsts = true;
+            }
+            var usedVms = [];
+            servers = targetServerUUIDs.filter(function (s) {
+                var instanceExists = remainingInstances.some(function (vm) {
+                    if (usedVms.indexOf(vm.uuid) !== -1) {
+                        return false;
+                    }
+                    if (vm.server_uuid === s) {
+                        usedVms.push(vm.uuid);
+                        return true;
+                    }
+                    return false;
+                });
+                return (!instanceExists);
+            });
+            if (servers.length) {
+                willCreateInsts = true;
+            } else {
+                willCreateInsts = false;
+            }
+            next();
         },
 
-        function getNextInstanceId(_, next) {
+        function checkMachinesToDelete(_, next) {
+            if (instancesToDelete.length && !opts.allow_delete) {
+                next(new errors.UsageError(
+                    'In order to remove existing binder instances ' +
+                    '"--allow-delete" option must be specified'));
+                return;
+            }
+            next();
+        },
+
+        function checkDuplicatedServers(_, next) {
+            var duplicates = targetServerUUIDs.some(function (ins, pos) {
+                return (targetServerUUIDs.indexOf(ins) !== pos);
+            });
+            if (duplicates && !opts.dev_allow_repeat_servers) {
+                next(new errors.UsageError(
+                    'In order to create more than one instance into the ' +
+                    'same server the option "--dev-allow-repeat-servers"' +
+                    ' must be specified'
+                ));
+                return;
+            }
+            next();
+        },
+
+        function checkAtLeastOneMachineRemains(_, next) {
+            if (!remainingInstances.length) {
+                next(new errors.UsageError(
+                    'At least one of the existing binder instances must ' +
+                    'remain after all the desired changes are executed.'));
+                return;
+            }
+            next();
+        },
+
+        function getNextInstanceId(ctx, next) {
             if (!willCreateInsts) {
                 next();
                 return;
             }
             self.progress('Calculating next binder instance alias');
-            nextId = instances.map(function (inst) {
-                return Number(inst.params.alias.replace('binder', ''));
-            }).sort().pop();
-            nextId = nextId + 1;
+            ctx.nextId = shared.getNextInstAliasOrdinal({
+                instances: instances,
+                change: {
+                    service: ctx.binderSvc
+                }
+            }).nextId;
             next();
         },
 
@@ -239,15 +361,18 @@ function do_ha_binder(subcmd, opts, args, cb) {
             });
         },
 
-        function instancesToBeCreated(ctx, next) {
-            if (!willCreateInsts) {
+        function changesToBeMade(ctx, next) {
+            if (!willCreateInsts && !willRemoveInsts) {
                 next();
                 return;
             }
-            self.progress('Determining binder instances to be created');
+
+            var lastId = servers.length + ctx.nextId;
             var i;
-            for (i = nextId; i < (opts.members + 1); i += 1) {
-                var change = {
+
+            for (i = ctx.nextId; i < lastId; i += 1) {
+                var server = servers.shift();
+                changes.push({
                     image: img,
                     type: 'add-instance',
                     service: ctx.binderSvc,
@@ -259,152 +384,44 @@ function do_ha_binder(subcmd, opts, args, cb) {
                         image: img.uuid,
                         // The binder's zk has zk_id of 1, next one needs to
                         // begin at 2, and so forth:
-                        zk_id: 2 + i
-                    }
-                };
-                change.inst.server = opts.servers[(i - 1)];
-                changes.push(change);
-            }
-            next();
-        },
-
-        function getMorayService(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Getting SDC\'s moray details from SAPI');
-            self.sdcadm.sapi.listServices({
-                name: 'moray',
-                application_uuid: app.uuid
-            }, function (svcErr, svcs) {
-                if (svcErr) {
-                    return next(svcErr);
-                }
-                if (!svcs.length) {
-                    return next(new errors.SDCClientError(new Error(
-                        'No services named "moray"'), 'sapi'));
-                }
-                moraySvc = svcs[0];
-                return next();
-            });
-        },
-
-        function getMorayVms(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Getting SDC\'s moray vms from VMAPI');
-            self.sdcadm.vmapi.listVms({
-                'tag.smartdc_role': 'moray',
-                state: 'running'
-            }, function (vmsErr, vms_) {
-                if (vmsErr) {
-                    return next(vmsErr);
-                }
-                morayVms = vms_;
-                return next();
-            });
-        },
-
-        function getManateeService(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Getting SDC\'s manatee details from SAPI');
-            self.sdcadm.sapi.listServices({
-                name: 'manatee',
-                application_uuid: app.uuid
-            }, function (svcErr, svcs) {
-                if (svcErr) {
-                    return next(svcErr);
-                }
-                if (!svcs.length) {
-                    return next(new errors.SDCClientError(new Error(
-                        'No services named "manatee"'), 'sapi'));
-                }
-                manateeSvc = svcs[0];
-                return next();
-            });
-        },
-
-        function getManateeVms(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
+                        zk_id: 1 + i,
+                        server: server
+                    },
+                    server: server
+                });
             }
-            self.progress('Getting SDC\'s manatees vms from VMAPI');
-            self.sdcadm.vmapi.listVms({
-                'tag.smartdc_role': 'manatee',
-                state: 'running'
-            }, function (vmsErr, vms_) {
-                if (vmsErr) {
-                    return next(vmsErr);
-                }
-                manateeVms = vms_;
-                return next();
-            });
-        },
 
-        function getShard(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Getting manatee shard status');
-            var vm = manateeVms[0];
-
-            shared.getShardState({
-                server: vm.server_uuid,
-                manateeUUID: vm.uuid,
-                log: self.sdcadm.log
-            }, function (err, st) {
-                if (err) {
-                    return next(err);
-                }
-                shard = st;
-                // Also set server uuid for each one of the manatees on the
-                // shard to simplify next steps:
-                manateeVms.forEach(function (v) {
-                    if (shard.primary.zoneId === v.uuid) {
-                        shard.primary.server = v.server_uuid;
-                    } else if (shard.sync &&
-                        shard.sync.zoneId === v.uuid) {
-                        shard.sync.server = v.server_uuid;
-                    } else if (shard.async && shard.async.length) {
-                        shard.async = shard.async.map(function (v2) {
-                            if (v2.zoneId === v.uuid) {
-                                v2.server = v.server_uuid;
-                            }
-                            return (v2);
-                        });
+            instancesToDelete.forEach(function (vm) {
+                changes.push({
+                    instance: vm.uuid,
+                    type: 'delete-instance',
+                    service: ctx.binderSvc,
+                    server: vm.server_uuid,
+                    image: img,
+                    inst: {
+                        type: 'vm',
+                        alias: vm.alias,
+                        image: vm.image_uuid,
+                        service: 'binder',
+                        server: vm.server_uuid
                     }
                 });
-                return next();
             });
+            next();
         },
 
-        // Check manatee-adm version in order to take advantage of latest
-        // available sub-commands if possible:
-        function getManateeVersion(_, next) {
-            if (!willCreateInsts) {
+        function getCoreZooKeeperConfig(ctx, next) {
+            if (!willCreateInsts && !willRemoveInsts) {
                 next();
                 return;
             }
-            self.sdcadm.imgapi.getImage(manateeVms[0].image_uuid, {
-            }, function (err, image) {
+            steps.getCoreZkConfig(commonOpts, function (err, zkCtx) {
                 if (err) {
                     next(err);
-                } else {
-                    var parts = image.version.split('-');
-                    var curVer = parts[parts.length - 2];
-                    if (curVer >= '20150320T174220Z') {
-                        hasManatee21 = true;
-                    }
-                    next();
+                    return;
                 }
+                ctx = Object.assign(ctx, zkCtx);
+                next();
             });
         },
 
@@ -419,8 +436,10 @@ function do_ha_binder(subcmd, opts, args, cb) {
             var out = [];
 
             changes.forEach(function (c) {
-                out.push(sprintf('Add instance "%s" in server %s',
-                    c.inst.alias, c.inst.server));
+                var cType = c.type.split('-').join(' ');
+                cType = cType[0].toUpperCase() + cType.slice(1);
+                out.push(sprintf('%s "%s" in server %s',
+                    cType, c.inst.alias, c.inst.server));
             });
 
             out.push('Update core VMs resolvers.');
@@ -443,248 +462,110 @@ function do_ha_binder(subcmd, opts, args, cb) {
             });
         },
 
-        function confirmDuplicatedServers(_, next) {
-            if (!duplicatedServers || opts.yes) {
+        // Wait until after prompt Yes/No:
+        function saveChangesToHistory(_, next) {
+            if (changes.length === 0) {
                 next();
                 return;
             }
-            p('');
-            p('You\'ve provided duplicated servers: %j.', opts.servers);
-            p('');
-            var msg = 'Are you sure you want to create more than one\n' +
-                'instance into the same server?  [y/N] ';
-            common.promptYesNo({msg: msg, default: 'n'}, function (answer) {
-                if (answer !== 'y') {
-                    p('Aborting ha-binder setup');
-                    cb();
-                    return;
-                }
-                p('');
-                next();
-            });
-        },
-
-        // Wait until after prompt Yes/No:
-        function saveChangesToHistory(_, next) {
             self.sdcadm.history.saveHistory({
                 changes: changes
             }, function (err, hst) {
                 if (err) {
-                    return next(err);
-                }
-                history = hst;
-                return next();
-            });
-        },
-
-        function createWrkDir(_, next) {
-            stamp = sprintf('%d%02d%02dT%02d%02d%02dZ',
-                start.getUTCFullYear(),
-                start.getUTCMonth() + 1,
-                start.getUTCDate(),
-                start.getUTCHours(),
-                start.getUTCMinutes(),
-                start.getUTCSeconds());
-            wrkDir = '/var/sdcadm/ha-binder/' + stamp;
-            self.progress('Create work dir: ' + wrkDir);
-
-            mkdirp(wrkDir, function (err) {
-                if (err) {
-                    next(new errors.InternalError({
-                        message: 'error creating work dir: ' + wrkDir,
-                        cause: err
-                    }));
+                    next(err);
                     return;
                 }
+                history = hst;
                 next();
             });
         },
 
-        function freezeManatee(_, next) {
-            if (!willCreateInsts) {
+        function freezeManatee(ctx, next) {
+            if (!willCreateInsts && !willRemoveInsts) {
                 next();
                 return;
             }
             self.progress('Freezing manatee shard');
             common.manateeFreeze({
-                vm: manateeVms[0].uuid,
-                server: manateeVms[0].server_uuid,
-                reason: 'ha-binder setup ' + stamp,
+                vm: ctx.manateeVms[0].uuid,
+                server: ctx.manateeVms[0].server_uuid,
+                reason: 'ha-binder setup',
                 log: self.log
             }, next);
         },
 
-        function disableZkForBakup(_, next) {
+        function createZkBackup(ctx, next) {
             if (!willCreateInsts) {
                 next();
                 return;
             }
-            self.progress('Disabling zookeeper for data backup');
-            shared.disableRemoteSvc({
-                server: vms[0].server_uuid,
-                zone: vms[0].uuid,
-                fmri: 'zookeeper',
-                log: self.log
-            }, next);
-        },
-
-        function backupZookeeperData(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Creating backup of zookeeper data directory ' +
-                    '(this may take some time)');
-            common.execRemote({
-                cmd: 'cd /zookeeper/zookeeper; ' +
-                    '/opt/local/bin/tar czf zookeeper-' + stamp +
-                    '.tgz version-2',
-                vm: vms[0].uuid,
-                server: vms[0].server_uuid,
-                log: self.log
-            }, function (err, __, stderr) {
+            steps.backupZKData(Object.assign({
+                ctx: ctx
+            }, commonOpts), function backupCb(err, stamp) {
                 if (err) {
                     next(err);
                     return;
                 }
-                if (stderr) {
-                    next(new errors.InternalError({
-                        message: util.format('Backup failed: %s', stderr)
-                    }));
-                    return;
-                }
+                ctx.stamp = stamp;
                 next();
             });
         },
 
-        function enableZkAfterBakup(_, next) {
+        function createBinderInstances(_, next) {
             if (!willCreateInsts) {
                 next();
                 return;
             }
-            self.progress('Enabling zookeeper after data backup');
-            shared.enableRemoteSvc({
-                server: vms[0].server_uuid,
-                zone: vms[0].uuid,
-                fmri: 'zookeeper',
-                log: self.log
-            }, next);
-        },
 
-        function copyZkBackupToWorkDir(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Copying backup of zookeeper data to: %s', wrkDir);
-            var argv = [
-                '/opt/smartdc/bin/sdc-oneachnode',
-                '-j',
-                '-T',
-                '300',
-                '-n',
-                vms[0].server_uuid,
-                '-p',
-                util.format(
-                    '/zones/%s/root/zookeeper/zookeeper/zookeeper-%s.tgz',
-                    vms[0].uuid, stamp
-                ),
-                '--clobber',
-                '-d',
-                wrkDir
-            ];
-
-            common.execFilePlus({
-                argv: argv,
-                log: self.log
-            }, function (execErr, stdout, stderr) {
-                if (execErr) {
-                    return next(execErr);
-                }
-                try {
-                    // Due to the -j option of sdc-oneachnode:
-                    var res = JSON.parse(stdout);
-                    var out = res[0].result.stdout.trim() || null;
-                    var err = res[0].result.stderr.trim() || null;
-                    self.log.debug({
-                        stdout: out,
-                        stderr: err
-                    }, 'sdc-oneachnode copy zk backup to work dir');
-                    return next();
-                } catch (e) {
-                    self.log.error({
-                        err: e,
-                        stdout: stdout,
-                        stderr: stderr
-                    }, 'sdc-oneachnode copy zk backup to work dir');
-                    return next(e);
+            vasync.forEachPipeline({
+                inputs: changes.filter(function (c) {
+                    return (c.type === 'add-instance');
+                }),
+                func: function createBinderInstance(change, nextInst) {
+                    shared.createInstance({
+                        opts: commonOpts,
+                        server: change.inst.server,
+                        img: change.image,
+                        alias: change.inst.alias,
+                        change: change,
+                        metadata: {
+                            ZK_ID: String(change.inst.zk_id)
+                        }
+                    }, nextInst);
                 }
-            });
+            }, next);
         },
 
-        function renameZkBackup(_, next) {
-            if (!willCreateInsts) {
+        function removeBinderInstances(_, next) {
+            if (!willRemoveInsts) {
                 next();
                 return;
             }
-            var fname = path.join(wrkDir,
-                    util.format('zookeeper-%s.tgz', stamp));
-            self.progress('Moving backup of zookeeper data to: %s', fname);
-            fs.rename(path.join(wrkDir, vms[0].server_uuid), fname, next);
-        },
-
-        function createBinderInstances(ctx, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-
             vasync.forEachPipeline({
-                inputs: changes,
-                func: function createBinderInstance(change, next_) {
-                    self.progress('Creating "%s" instance', change.inst.alias);
-                    var instOpts = {
-                        params: {
-                            alias: change.inst.alias
-                        },
-                        metadata: {
-                            ZK_ID: String(change.inst.zk_id)
-                        }
-                    };
-
-                    if (change.inst.server) {
-                        instOpts.params.server_uuid = change.inst.server;
-                    }
-
-                    self.sdcadm.sapi.createInstance(ctx.binderSvc.uuid,
-                        instOpts, function (err, inst_) {
-                        if (err) {
-                            return next_(
-                                new errors.SDCClientError(err, 'sapi'));
-                        }
-                        self.progress('Instance "%s" (%s) created',
-                            inst_.uuid, inst_.params.alias);
-                        return next_();
-                    });
-                }
-            }, function _resCb(pipErr, results) {
-                if (pipErr) {
-                    return next(pipErr);
+                inputs: instancesToDelete,
+                func: function deleteBinderInstance(inst, nextInst) {
+                    self.progress(sprintf(
+                        'Removing "%s" (%s) instance in server %s',
+                        inst.uuid, inst.alias, inst.server_uuid));
+                    self.sdcadm.sapi.deleteInstance(
+                        inst.uuid, function sapiCb(sapiErr) {
+                            if (sapiErr) {
+                                nextInst(new errors.SDCClientError(sapiErr,
+                                    'sapi'));
+                                return;
+                            }
+                            nextInst();
+                        });
                 }
-                return next();
-            });
+            }, next);
         },
 
         function hupHermes(_, next) {
-            if (!willCreateInsts) {
+            if (!willCreateInsts && !willRemoveInsts) {
                 next();
                 return;
             }
-            svcadm.restartHermes({
-                sdcadm: self.sdcadm,
-                log: self.log,
-                progress: self.progress
-            }, next);
+            svcadm.restartHermes(commonOpts, next);
         },
 
         function getBinderInstancesAfterCreation(ctx, next) {
@@ -692,10 +573,11 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 service_uuid: ctx.binderSvc.uuid
             }, function (instErr, insts) {
                 if (instErr) {
-                    return next(instErr);
+                    next(instErr);
+                    return;
                 }
                 ctx.binderInsts = instances = insts;
-                return next();
+                next();
             });
         },
 
@@ -705,490 +587,61 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 state: 'running'
             }, function (vmsErr, vms_) {
                 if (vmsErr) {
-                    return next(vmsErr);
+                    next(vmsErr);
+                    return;
                 }
                 vms_.forEach(function (vm) {
-                    if (oldVms.indexOf(vm.uuid) === -1) {
+                    if (existingVmsUUIDs.indexOf(vm.uuid) === -1) {
                         newVms.push(vm);
                     }
                 });
                 ctx.binderVms = vms = vms_;
-                return next();
-            });
-        },
-
-        function disableZkIntoNewInsts(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Disabling zookeeper into new instances');
-            vasync.forEachParallel({
-                inputs: newVms,
-                func: function _disableZk(vm, nextVm) {
-                    shared.disableRemoteSvc({
-                        server: vm.server_uuid,
-                        zone: vm.uuid,
-                        fmri: 'zookeeper',
-                        log: self.log
-                    }, nextVm);
-                }
-            }, next);
-        },
-        // rm -Rf /zookeeper/zookeeper/version-2 into the new binders
-        function removeZkDataFromNewInsts(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Clearing zookeeper data into new instances');
-            vasync.forEachParallel({
-                inputs: newVms,
-                func: function _removeZkData(vm, nextVm) {
-                    common.execRemote({
-                        cmd: 'rm -Rf /zookeeper/zookeeper/version-2',
-                        vm: vm.uuid,
-                        server: vm.server_uuid,
-                        log: self.log
-                    }, function (err, __, stderr) {
-                        if (err) {
-                            nextVm(err);
-                            return;
-                        }
-                        if (stderr) {
-                            nextVm(new errors.InternalError({
-                                message: stderr
-                            }));
-                            return;
-                        }
-                        nextVm();
-                    });
-                }
-            }, next);
-        },
-        // Copy data from binder0 backup into the binder instances
-        function copyZkDataIntoNewInsts(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Copying zookeeper data into new instances');
-            var fname = path.join(wrkDir,
-                    util.format('zookeeper-%s.tgz', stamp));
-            vasync.forEachParallel({
-                inputs: newVms,
-                func: function _copyZkData(vm, nextVm) {
-                    var argv = [
-                        '/opt/smartdc/bin/sdc-oneachnode',
-                        '-j',
-                        '-T',
-                        '300',
-                        '-n',
-                        vm.server_uuid,
-                        '-g',
-                        /* JSSTYLED */
-                        fname,
-                        '--clobber',
-                        '-d',
-                        util.format('/zones/%s/root/zookeeper/zookeeper',
-                                vm.uuid)
-                    ];
-
-                    common.execFilePlus({
-                        argv: argv,
-                        log: self.log
-                    }, function (execErr, stdout, stderr) {
-                        if (execErr) {
-                            return nextVm(execErr);
-                        }
-                        try {
-                            // Due to the -j option of sdc-oneachnode:
-                            var res = JSON.parse(stdout);
-                            var out = res[0].result.stdout.trim() || null;
-                            var err = res[0].result.stderr.trim() || null;
-                            self.log.debug({
-                                stdout: out,
-                                stderr: err
-                            }, 'sdc-oneachnode copy zk backup to work dir');
-                            return nextVm();
-                        } catch (e) {
-                            self.log.error({
-                                err: e,
-                                stdout: stdout,
-                                stderr: stderr
-                            }, 'sdc-oneachnode copy zk backup to work dir');
-                            return nextVm(e);
-                        }
-                    });
-                }
-            }, next);
-        },
-        // Untar data from binder0 into the new binder instances
-        function untarZkDataIntoNewInsts(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Extracting zookeeper data into new instances ' +
-                    '(may take some time)');
-            vasync.forEachParallel({
-                inputs: newVms,
-                func: function _untarZkData(vm, nextVm) {
-                    common.execRemote({
-                        cmd: 'cd /zookeeper/zookeeper; ' +
-                            '/opt/local/bin/tar xf zookeeper-' +
-                            stamp + '.tgz',
-                        vm: vm.uuid,
-                        server: vm.server_uuid,
-                        log: self.log
-                    }, function (err, __, stderr) {
-                        if (err) {
-                            nextVm(err);
-                            return;
-                        }
-                        if (stderr) {
-                            nextVm(new errors.InternalError({
-                                message: stderr
-                            }));
-                            return;
-                        }
-                        nextVm();
-                    });
-                }
-            }, next);
-        },
-        // enable zookeeper into the new binder instances
-        function enableZkIntoNewInsts(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Enabling zookeeper into new instances');
-            vasync.forEachParallel({
-                inputs: newVms,
-                func: function _enableZk(vm, nextVm) {
-                    shared.enableRemoteSvc({
-                        server: vm.server_uuid,
-                        zone: vm.uuid,
-                        fmri: 'zookeeper',
-                        log: self.sdcadm.log
-                    }, nextVm);
-                }
-            }, next);
-        },
-
-        // Now that we're sure every binder instance has knowledge of previous
-        // ensemble status, we re-configure binder instances in SAPI in order
-        // to make these instances to join the same zookeeper ensemble.
-
-        function prepareClusterPayload(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            vms.forEach(function (vm) {
-                var instance = instances.filter(function (i) {
-                    return (i.uuid === vm.uuid);
-                })[0];
-
-                HA_ZK_JSON.push({
-                    host: vm.nics[0].ip,
-                    port: 2181,
-                    num: Number(instance.metadata.ZK_ID)
+                ctx.binderIps = vms.map(function (vm) {
+                    return (vm.nics[0].ip);
                 });
-            });
-
-            // Set a value for special property "last" for just the final
-            // element of the collection
-            HA_ZK_JSON[HA_ZK_JSON.length - 1].last = true;
-            next();
-        },
-
-        function cfgBinderService(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Updating Binder service config in SAPI');
-            self.sdcadm.sapi.updateApplication(app.uuid, {
-                metadata: {
-                    ZK_SERVERS: HA_ZK_JSON
-                }
-            }, function (upErr) {
-                if (upErr) {
-                    return next(upErr);
-                }
-                return next();
-            });
-        },
-
-        // Set ZK_SERVERS, not ZK_HA_SERVERS
-        function cfgMoraySvc(_, next) {
-            if (!willCreateInsts) {
                 next();
-                return;
-            }
-            self.progress('Updating Moray service config in SAPI');
-            self.sdcadm.sapi.updateService(moraySvc.uuid, {
-                metadata: {
-                    ZK_SERVERS: HA_ZK_JSON
-                }
-            }, function (upErr) {
-                if (upErr) {
-                    return next(upErr);
-                }
-                return next();
             });
         },
 
-        // Set ZK_SERVERS, not ZK_HA_SERVERS
-        function cfgManateeSvc(_, next) {
+        function replaceZkDataIntoNewInsts(ctx, next) {
             if (!willCreateInsts) {
                 next();
                 return;
             }
-            self.progress('Updating Manatee service config in SAPI');
-            self.sdcadm.sapi.updateService(manateeSvc.uuid, {
-                metadata: {
-                    ZK_SERVERS: HA_ZK_JSON
-                }
-            }, function (upErr) {
-                if (upErr) {
-                    return next(upErr);
-                }
-                return next();
-            });
-        },
-
-        // Call config-agent sync for all the binder VMs
-        function callConfigAgentSyncForAllBinders(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Reloading config for all the binder VMs');
             vasync.forEachParallel({
-                inputs: vms,
-                func: function callCfgSync(vm, next_) {
-                    common.callConfigAgentSync({
-                        vm: vm.uuid,
-                        server: vm.server_uuid,
-                        log: self.log
-                    }, next_);
+                inputs: newVms,
+                func: function replaceZkData(vm, nextVm) {
+                    steps.replaceZKData(Object.assign({
+                        vm: vm,
+                        stamp: ctx.stamp
+                    }, commonOpts), nextVm);
                 }
             }, next);
         },
 
-        function waitForZkClusterOk(ctx, next) {
-            ctx.ips = vms.map(function (vm) {
-                return (vm.nics[0].ip);
-            });
 
-            if (!willCreateInsts) {
+        function reconfigureZkCoreCfg(ctx, next) {
+            if (!willCreateInsts && !willRemoveInsts) {
                 next();
                 return;
             }
 
-            self.progress('Waiting for ZK cluster to reach a steady state');
-
-
-            shared.wait4ZkOk({
-                ips: ctx.ips,
-                log: self.sdcadm.log
-            }, next);
-        },
-
-        function checkAllInstancesJoinedZkCluster(ctx, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Waiting for binder instances to join ZK cluster');
-
-            shared.wait4ZkCluster({
-                ips: ctx.ips,
-                log: self.sdcadm.log
-            }, next);
-        },
-
-        // Now that we've added the binder, wouldn't it be the leader always?:
-        function getZkLeaderIP(ctx, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Getting ZK leader IP');
-
-            shared.getZkLeaderIP({
-                ips: ctx.ips,
-                log: self.sdcadm.log
-            }, function (err, ip) {
-                if (err) {
-                    return next(err);
-                }
-                leaderIP = ip;
-                return next();
-            });
-        },
-
-        // Call config-agent sync for all the manatee VMs
-        function callConfigAgentSyncForAllManatees(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Reloading config for all the manatee VMs');
-            vasync.forEachParallel({
-                inputs: manateeVms,
-                func: function callCfgSync(vm, next_) {
-                    common.callConfigAgentSync({
-                        vm: vm.uuid,
-                        server: vm.server_uuid,
-                        log: self.log
-                    }, next_);
-                }
-            }, next);
-        },
-
-        // HUP Manatee (Already waits for manatee shard to
-        // reach the desired status):
-        function disableManatee(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            shared.disableManateeSitter({
-                progress: self.progress,
-                log: self.sdcadm.log,
-                leaderIP: leaderIP,
-                shard: shard,
-                hasManatee21: hasManatee21
-            }, next);
+            steps.updateCoreZkConfig(Object.assign({
+                ctx: ctx
+            }, commonOpts), next);
         },
 
-        function enableManatee(_, next) {
+        function clearDataBackupFromBinderVm(ctx, next) {
             if (!willCreateInsts) {
                 next();
                 return;
             }
-            shared.enableManateeSitter({
+            steps.clearZKBackup({
                 progress: self.progress,
-                log: self.sdcadm.log,
-                leaderIP: leaderIP,
-                shard: shard,
-                hasManatee21: hasManatee21
-            }, next);
-        },
-
-        // Call config-agent sync for all the moray VMs
-        function callConfigAgentSyncForAllMorays(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Reloading config for all the moray VMs');
-            vasync.forEachParallel({
-                inputs: morayVms,
-                func: function callCfgSync(vm, next_) {
-                    common.callConfigAgentSync({
-                        vm: vm.uuid,
-                        server: vm.server_uuid,
-                        log: self.log
-                    }, next_);
-                }
-            }, next);
-        },
-
-        // HUP morays:
-        function restartMorays(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Restarting moray services');
-            vasync.forEachParallel({
-                inputs: morayVms,
-                func: function restartMoray(vm, next_) {
-                    shared.restartRemoteSvc({
-                        server: vm.server_uuid,
-                        zone: vm.uuid,
-                        fmri: '*moray-202*',
-                        log: self.sdcadm.log
-                    }, next_);
-                }
-            }, function (morErr, morRes) {
-                if (morRes) {
-                    return next(morErr);
-                }
-                return next();
-            });
-        },
-
-        function wait4Morays(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Waiting for moray services to be up into' +
-                    ' every moray instance');
-            shared.wait4Morays({
-                vms: morayVms,
-                sdcadm: self.sdcadm
-            }, next);
-        },
-
-        function unfreezeManatee(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Unfreezing manatee shard');
-            common.manateeAdmRemote({
-                server: manateeVms[0].server_uuid,
-                vm: manateeVms[0].uuid,
-                cmd: 'unfreeze',
-                log: self.log
-            }, function (err, __, stder) {
-                if (err) {
-                    next(err);
-                    return;
-                } else if (stder) {
-                    next(new errors.InternalError({
-                        message: stder
-                    }));
-                    return;
-                }
-                next();
-            });
-        },
-
-        function clearDataBackupFromBinderVm(_, next) {
-            if (!willCreateInsts) {
-                next();
-                return;
-            }
-            self.progress('Removing zookeeper data backup from %s',
-                    vms[0].uuid);
-
-            common.execRemote({
-                cmd: 'cd /zookeeper/zookeeper; ' +
-                    'rm zookeeper-' + stamp + '.tgz',
-                vm: vms[0].uuid,
-                server: vms[0].server_uuid,
+                vm: vms[0],
+                stamp: ctx.stamp,
                 log: self.log
-            }, function (err, __, stderr) {
-                if (err) {
-                    next(err);
-                    return;
-                }
-                if (stderr) {
-                    next(new errors.InternalError({
-                        message: stderr
-                    }));
-                    return;
-                }
-                next();
-            });
+            }, next);
         },
 
         function ensureAdminNetworkHasCorrectResolvers(ctx, next) {
@@ -1208,10 +661,11 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 }
 
                 ctx.admin_network_uuid = nets[0].uuid;
-                var changed = (ctx.ips.length !== nets[0].resolvers.length ||
-                                !ctx.ips.every(function checkIp(ip, pos) {
-                                    return (ip === nets[0].resolvers[pos]);
-                                }));
+                var changed = (
+                    ctx.binderIps.length !== nets[0].resolvers.length ||
+                    !ctx.binderIps.every(function checkIp(ip, pos) {
+                        return (ip === nets[0].resolvers[pos]);
+                    }));
 
                 if (!changed) {
                     next();
@@ -1221,10 +675,10 @@ function do_ha_binder(subcmd, opts, args, cb) {
                 self.progress(
                     'Updating admin network resolvers from [%s] to [%s]',
                     nets[0].resolvers.join(', '),
-                    ctx.ips.join(', ')
+                    ctx.binderIps.join(', ')
                 );
                 self.sdcadm.napi.updateNetwork(ctx.admin_network_uuid, {
-                    resolvers: ctx.ips
+                    resolvers: ctx.binderIps
                 }, function (err2) {
                     if (err2) {
                         next(new errors.SDCClientError(err2, 'napi'));
@@ -1237,13 +691,9 @@ function do_ha_binder(subcmd, opts, args, cb) {
 
         function updateCoreVmsResolvers(ctx, next) {
             self.progress('Updating core SDC VMs resolvers');
-            ctx.binderIps = ctx.ips;
-            steps.checkCoreVmInstancesResolvers({
-                sdcadm: self.sdcadm,
-                progress: self.progress,
-                log: self.log,
+            steps.checkCoreVmInstancesResolvers(Object.assign({
                 ctx: ctx
-            }, function (err, resolvers) {
+            }, commonOpts), function checkResolversCb(err, resolvers) {
                 if (err) {
                     next(err);
                     return;
@@ -1256,17 +706,13 @@ function do_ha_binder(subcmd, opts, args, cb) {
                         resolvers[r].expected.join(', '));
                 });
 
-                steps.updateCoreVmsResolvers({
-                    sdcadm: self.sdcadm,
-                    progress: self.progress,
-                    log: self.log,
+                steps.updateCoreVmsResolvers(Object.assign({
                     fixableResolvers: resolvers
-                }, function (updateError) {
-                    next(updateError);
-                });
+                }, commonOpts), next);
             });
         }
 
+
     ]}, function (err) {
         // Add error to history in case the update execution failed:
         if (err) {
@@ -1298,6 +744,17 @@ do_ha_binder.options = [
         type: 'bool',
         help: 'Show this help.'
     },
+    {
+        names: ['allow-delete'],
+        type: 'bool',
+        help: 'Allow replacement/deletion of existing binder instances.'
+    },
+    {
+        names: ['dev-allow-repeat-servers'],
+        type: 'bool',
+        help: 'For development, allow a binder cluster with multiple\n' +
+              'instances on the same server.'
+    },
     {
         names: ['yes', 'y'],
         type: 'bool',
@@ -1306,33 +763,66 @@ do_ha_binder.options = [
     {
         names: ['servers', 's'],
         type: 'arrayOfString',
-        help: 'UUID for the target servers. At least m are required.'
+        hidden: true,
+        help: 'UUID for the target servers. At least 2 are required.'
     },
     {
         names: ['members', 'm'],
         type: 'integer',
-        'default': 2,
+        hidden: true,
         help: 'Number of instances to create (2 or 4). Default: 2'
     }
 
 ];
 
 do_ha_binder.help = (
-    'HA setup for binder/zookeeper services using binder instances.\n' +
-    '\n' +
-    'The zookeeper cluster, known as an ensemble, will use Headnode\'s\n' +
-    'binder as the first member and leader of the cluster.\n' +
+    'Setup the binder service for high availability (HA).\n' +
     '\n' +
-    'Given that the existing binder instance will be included into the\n' +
-    'ensemble, and we need an odd number of machines for better cluster\n' +
-    'reliability, we need to specify an additional number of new instances\n' +
-    'to be created, either 2 or 4, in order to complete a total of 3 or 5\n' +
-    'instances.\n' +
+    'The binder service provides internal DNS to Triton core services.\n' +
+    'It also holds a zookeeper (ZK) cluster used by some Triton core\n' +
+    'services. To best support ZK availability we want an odd number of\n' +
+    'binder instances. One, three, or five instances are supported.\n' +
     '\n' +
     'Usage:\n' +
-    '     {{name}} ha-binder -s SERVER_UUID1 -s SERVER_UUID2\n' +
+    '     {{name}} ha-binder SERVER1 SERVER2 ...\n' +
+    '\n' +
+    '{{options}}' +
+    '\n' +
+    '"SERVER ..." should list one, three, or five setup servers (hostname\n' +
+    'or UUID) on which a binder instance is desired. Note that this\n' +
+    '*includes* existing binder instances, e.g. the "binder0" instance\n' +
+    'typically on the initial headnode.\n' +
+    '\n' +
+    'For backward compatibility, \n' +
+    '`sdcadm post-setup ha-binder -s SERVER2 -s SERVER3` is accepted\n' +
+    '(a) when there is only a single binder on the headnode and \n' +
+    '(b) to mean that two binder instances should be added for a total of\n' +
+    'three instances. The new calling form is preferred because it is\n' +
+    'idempotent.\n' +
+    '\n' +
+    'Examples:\n' +
+    '    # Ensure a 3-instance binder cluster on the given 3 servers.\n' +
+    '    sdcadm post-setup ha-binder headnode SERVER2 SERVER3\n' +
+    '\n' +
+    '    # Deprecated. Same result as preview example.\n' +
+    '    sdcadm post-setup ha-binder -s SERVER2 -s SERVER3\n' +
+    '\n' +
+    'At least one of the existing binder instances must remain unchanged\n' +
+    'during the process. In case the desired configuration does not \n' +
+    'include any of the existing instances, the recommended procedure is\n' +
+    'to complete the removal or replacement of all the desired instances\n' +
+    'in two steps, achieving the replacement of the instance that must\n' +
+    'remain unchanged during the first execution of the command during\n' +
+    'the second execution. For example, say we want to "move" our binder\n' +
+    'instances from servers "headnode", "SERVER1" and "SERVER2" to the\n' +
+    'new servers "SERVER4", "SERVER5" and "new-headnode". We can proceed\n' +
+    'as follows:\n' +
     '\n' +
-    '{{options}}'
+    '    # Replace all the instances but the first one:\n' +
+    '    sdcadm post-setup ha-binder headnode SERVER4 SERVER5 \n' +
+    '    # Replace the first one while keeping the new ones:\n' +
+    '    sdcadm post-setup ha-binder new-headnode SERVER4 SERVER5 \n' +
+    '\n'
 );
 
 
diff --git a/lib/procedures/create-service-instance-v1.js b/lib/procedures/create-service-instance-v1.js
index d28cb99..974d3f5 100644
--- a/lib/procedures/create-service-instance-v1.js
+++ b/lib/procedures/create-service-instance-v1.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright 2017 Joyent, Inc.
+ * Copyright 2018 Joyent, Inc.
  */
 
 var assert = require('assert-plus');
@@ -66,59 +66,60 @@ CreateServiceInstanceV1.prototype.execute = function csiv1Execute(opts, cb) {
             progress: progress,
             log: opts.log
         };
-        var instances = [];
         var alias;
 
         var funcs = [
-            function getSvcInstances(_, next) {
+            function getSvcInstances(ctx, next) {
                 progress('Getting SDC\'s %s instances from SAPI',
                         change.service.name);
                 sdcadm.sapi.listInstances({
                     service_uuid: change.service.uuid
-                }, function (instErr, insts) {
+                }, function sapiListInstsCb(instErr, insts) {
                     if (instErr) {
-                        return next(instErr);
+                        next(instErr);
+                        return;
                     }
                     // It doesn't really matter if we have no instances, the
                     // command could have failed creating the first one, and we
                     // may be trying to re-run from there
-                    instances = insts;
-                    return next();
+                    ctx.instances = insts;
+                    next();
                 });
             },
-            function avoidCloudAPIFirstInstance(_, next) {
-                if (instances.length === 0 &&
+            function avoidCloudAPIFirstInstance(ctx, next) {
+                if (ctx.instances.length === 0 &&
                         change.service.name === 'cloudapi') {
-                    return next(new errors.UsageError(
+                    next(new errors.UsageError(
                         'First CloudAPI instance should be created using ' +
                         '`sdcadm post-setup cloudapi`.'));
+                    return;
                 }
-                return next();
+                next();
             },
-            function fixSapiZeroAlias(_, next) {
+            // See TOOLS-1940 (first sapi instance is created w/o parameters
+            // during headnode initial setup):
+            function fixSapiZeroAlias(ctx, next) {
                 if (change.service.name !== 'sapi') {
                     next();
                     return;
                 }
                 steps.sapiFixInstanceAlias({
                     sdcadm: sdcadm,
-                    instances: instances
+                    instances: ctx.instances
                 }, function fixInstCb(fixInstErr, fixedInsts) {
                     if (fixInstErr) {
                         next(fixInstErr);
                         return;
                     }
-                    instances = fixedInsts;
+                    ctx.instances = fixedInsts;
                     next();
                 });
             },
-            function generateInstanceAlias(_, next) {
-                var n = change.service.name;
-                var nextId = instances.map(function (inst) {
-                    return Number(inst.params.alias.replace(n, ''));
-                }).sort().pop();
-                nextId = isNaN(nextId) ? 0 : nextId + 1;
-                arg.nextId = nextId;
+            // Get the ordinal number corresponding to the next instance so
+            // all the created instances for a given service have consecutive
+            // numbers:
+            function getNextInstOrd(ctx, next) {
+                ctx.nextId = s.getNextInstAliasOrdinal(ctx).nextId;
                 next();
             }
         ];
@@ -140,7 +141,7 @@ CreateServiceInstanceV1.prototype.execute = function csiv1Execute(opts, cb) {
                     next();
                 },
                 function imgadmInstallForInstance(_, next) {
-                    return s.imgadmInstallRemote({
+                    s.imgadmInstallRemote({
                         progress: progress,
                         img: change.image,
                         log: opts.log,
diff --git a/lib/procedures/shared.js b/lib/procedures/shared.js
index f61a6b3..50c479b 100644
--- a/lib/procedures/shared.js
+++ b/lib/procedures/shared.js
@@ -733,18 +733,37 @@ function destroyTmpVM(arg, next) {
 }
 
 function createInstance(arg, next) {
+    assert.object(arg, 'arg');
+    assert.string(arg.alias, 'arg.alias');
+    assert.object(arg.change, 'arg.change');
+    assert.object(arg.change.image, 'arg.change.image');
+    assert.uuid(arg.change.image.uuid, 'arg.change.image.uuid');
+    assert.string(arg.change.image.version, 'arg.change.image.version');
+    assert.uuid(arg.change.server, 'arg.change.server');
+    assert.object(arg.change.service, 'arg.change.service');
+    assert.string(arg.change.service.name, 'arg.change.service.name');
+    assert.string(arg.change.service.type, 'arg.change.service.type');
+    assert.uuid(arg.change.service.uuid, 'arg.change.service.uuid');
+    assert.optionalObject(arg.metadata, 'arg.metadata');
+    assert.object(arg.opts, 'arg.opts');
+    assert.func(arg.opts.progress, 'arg.opts.progress');
+    assert.object(arg.opts.sdcadm, 'arg.opts.sdcadm');
+    assert.func(next, 'next');
+
     var progress = arg.opts.progress;
     var sdcadm = arg.opts.sdcadm;
-    progress('Creating "%s" instance', arg.alias);
+
     var iOpts = {
         params: {
             alias: arg.alias,
             server_uuid: arg.change.server
         },
-        metadata: {}
+        metadata: arg.metadata || {}
     };
 
     var svc = arg.change.service.uuid;
+
+    progress('Creating "%s" instance', arg.alias);
     sdcadm.sapi.createInstance(svc, iOpts, function (err, inst_) {
         if (err) {
             next(new errors.SDCClientError(err, 'sapi'));
@@ -769,6 +788,22 @@ function createInstance(arg, next) {
     });
 }
 
+
+function getNextInstAliasOrdinal(arg) {
+    assert.object(arg, 'arg');
+    assert.object(arg.change, 'arg.change');
+    assert.object(arg.change.service, 'arg.change.service');
+    assert.string(arg.change.service.name, 'arg.change.service.name');
+    assert.object(arg.instances, 'arg.instances');
+    var n = arg.change.service.name;
+    var nextId = arg.instances.map(function instanceOrdinalsFromAliases(inst) {
+        return Number(inst.params.alias.replace(n, ''));
+    }).sort().pop();
+    nextId = isNaN(nextId) ? 0 : nextId + 1;
+    arg.nextId = nextId;
+    return arg;
+}
+
 // Functions operating remotely through sdc-oneachnode:
 
 // Same than imgadmInstall but through sdc-oneachnode
@@ -1201,14 +1236,17 @@ function manateeSitterSvcStatus(opts, callback) {
             return;
         }
 
+        var res, out, parseErr;
         try {
-            // Due to the -j option of sdc-oneachnode:
-            var res = JSON.parse(stdout);
-            var out = res[0].result.stdout.trim() || null;
-            callback(null, out);
+            res = JSON.parse(stdout);
+            out = (Array.isArray(res) &&
+                   res.length &&
+                   res[0].result &&
+                   res[0].result.stdout) ? res[0].result.stdout.trim() : null;
         } catch (e) {
-            callback(e);
+            parseErr = e;
         }
+        callback(parseErr, out);
     });
 }
 
@@ -1241,6 +1279,7 @@ function waitForManatee(opts, callback) {
     assert.string(opts.state, 'opts.state');
     assert.optionalString(opts.leaderIP, 'opts.leaderIP');
     assert.optionalBool(opts.hasManatee21, 'opts.hasManatee21');
+    assert.optionalBool(opts.oneNodeWriteMode, 'opts.oneNodeWriteMode');
     assert.func(callback, 'callback');
 
     opts.hasManatee21 = opts.hasManatee21 || false;
@@ -1255,21 +1294,22 @@ function waitForManatee(opts, callback) {
             return shardPgSt;
         }
         Object.keys(obj.sdc).forEach(function (m) {
-            if ((m === 'primary' || m === 'sync') && !obj.sdc[m].error) {
+            var member = obj.sdc[m];
+            if ((m === 'primary' || m === 'sync') && !member.error) {
                 shardPgSt[m] = {
-                    pg_status: obj.sdc[m].online ? 'ok' : '-',
-                    repl_status: (obj.sdc[m].repl &&
-                        obj.sdc[m].repl.sync_state) ?
-                            obj.sdc[m].repl.sync_state : '-'
+                    pg_status: member.online ? 'ok' : '-',
+                    repl_status: (member.repl &&
+                        member.repl.sync_state) ?
+                            member.repl.sync_state : '-'
                 };
-            } else if (!obj.sdc[m].error) {
+            } else if (!member.error) {
                 if (!shardPgSt[m]) {
                     shardPgSt[m] = [];
                 }
 
-                if (typeof (obj.sdc[m].online) !== 'undefined') {
+                if (typeof (member.online) !== 'undefined') {
                     shardPgSt[m].push({
-                        pg_status: obj.sdc[m].online ? 'ok' : '-'
+                        pg_status: member.online ? 'ok' : '-'
                     });
                 }
             }
@@ -1462,8 +1502,26 @@ function disableManateeSitter(opts, cb) {
     var progress = opts.progress;
     var leaderIP = opts.leaderIP || null;
     var hasManatee21 = opts.hasManatee21 || false;
+    // Do we have a standalone manatee or is part of a shard?:
+    var oneNodeWriteMode = false;
 
     vasync.pipeline({funcs: [
+        function getState(_, next) {
+            getShardState({
+                log: opts.log,
+                server: shard.primary.server,
+                manateeUUID: shard.primary.zoneId,
+                hasManatee21: hasManatee21,
+                leaderIP: leaderIP
+            }, function (err, state) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                oneNodeWriteMode = state.oneNodeWriteMode;
+                next();
+            });
+        },
         function disableAsyncManatee(_, next) {
             if (!shard.async || !shard.async.length) {
                 next();
@@ -1550,7 +1608,8 @@ function disableManateeSitter(opts, cb) {
                 server: shard.primary.server,
                 manateeUUID: shard.primary.zoneId,
                 log: log,
-                hasManatee21: hasManatee21
+                hasManatee21: hasManatee21,
+                oneNodeWriteMode: oneNodeWriteMode
             };
             if (leaderIP) {
                 _opts.leaderIP = leaderIP;
@@ -1772,9 +1831,12 @@ function wait4ZkCluster(opts, callback) {
                 return;
             }
             counter += 1;
-            var notOk = results.successes.filter(function (r) {
-                return (r !== 'leader' && r !== 'follower');
-            });
+
+            var filter = opts.ips.length !== 1 ?
+                function (r) { return (r !== 'leader' && r !== 'follower'); } :
+                function (r) { return (r !== 'standalone'); };
+
+            var notOk = results.successes.filter(filter);
 
             if (notOk.length && counter < limit) {
                 if (counter < limit) {
@@ -1888,7 +1950,12 @@ function getShardState(opts, callback) {
             callback(err);
             return;
         }
-
+        if (stderr) {
+            callback(new errors.InternalError({
+                message: stderr
+            }));
+            return;
+        }
         var manateeShard = JSON.parse(res);
         callback(null, manateeShard);
     });
@@ -1923,16 +1990,17 @@ function wait4Morays(opts, cb) {
                 insts: [inst]
             }, function (err, results) {
                 if (err) {
-                    log.debug({
+                    log.error({
                         err: err
-                    }, 'checkInstSvcs');
+                    }, 'checkInstanceSvcs');
                     next_(err);
                     return;
                 }
                 counter += 1;
                 log.debug({
-                    results: results
-                }, 'checkInstSvcs');
+                    results: results,
+                    attempt: counter
+                }, 'checkInstanceSvcs');
                 var res = results[0];
                 if (res.health_errors && res.health_errors.length) {
                     if (counter < limit) {
@@ -2064,6 +2132,7 @@ module.exports = {
     stopTmpVm: stopTmpVm,
     destroyTmpVM: destroyTmpVM,
     createInstance: createInstance,
+    getNextInstAliasOrdinal: getNextInstAliasOrdinal,
     imgadmInstallRemote: imgadmInstallRemote,
     reprovisionRemote: reprovisionRemote,
     disableVMRegistrarRemote: disableVMRegistrarRemote,
diff --git a/lib/sdcadm.js b/lib/sdcadm.js
index 4565c9c..0730d96 100644
--- a/lib/sdcadm.js
+++ b/lib/sdcadm.js
@@ -26,7 +26,6 @@ var cueball = require('cueball');
 var mkdirp = require('mkdirp');
 var sdcClients = require('sdc-clients');
 var semver = require('semver');
-var sprintf = require('extsprintf').sprintf;
 var UFDS = require('ufds');
 var uuid = require('node-uuid');
 var urclient = require('urclient');
@@ -2222,7 +2221,7 @@ SdcAdm.prototype.genUpdatePlan = function genUpdatePlan(options, cb) {
                     var changeRepr = JSON.stringify({
                         type: ch.type,
                         service: ch.service.name,
-                        instance: ch.inst && ch.instance.instance
+                        instance: ch.instance && ch.instance.instance
                     });
                     next(new errors.UpdateError(format(
                         '%s updates are locked: %s ' +
@@ -2524,13 +2523,7 @@ SdcAdm.prototype.execUpdatePlan = function execUpdatePlan(options, cb) {
             });
         },
         function createWrkDir(_, next) {
-            var stamp = sprintf('%d%02d%02dT%02d%02d%02dZ',
-                start.getUTCFullYear(),
-                start.getUTCMonth() + 1,
-                start.getUTCDate(),
-                start.getUTCHours(),
-                start.getUTCMinutes(),
-                start.getUTCSeconds());
+            var stamp = common.utcTimestamp(start);
             wrkDir = (rollback ?
                     '/var/sdcadm/rollbacks/' : '/var/sdcadm/updates/'
                     ) + stamp;
@@ -3001,13 +2994,7 @@ SdcAdm.prototype.selfUpdate = function selfUpdate(options, cb) {
                 next();
                 return;
             }
-            var stamp = sprintf('%d%02d%02dT%02d%02d%02dZ',
-                start.getUTCFullYear(),
-                start.getUTCMonth() + 1,
-                start.getUTCDate(),
-                start.getUTCHours(),
-                start.getUTCMinutes(),
-                start.getUTCSeconds());
+            var stamp = common.utcTimestamp(start);
             wrkDir = '/var/sdcadm/self-updates/' + stamp;
             mkdirp(wrkDir, function (err) {
                 if (err) {
@@ -3951,6 +3938,12 @@ SdcAdm.prototype.checkHealth = function checkHealth(opts, cb) {
             return;
         }
 
+        // Make sure we remove the properties we'll assign later from an
+        // eventual previous invocation of this function, or those will be
+        // cached forever:
+        delete inst.health_errors;
+        delete inst.healthy;
+
         urConnection.exec({
             script: script,
             server_uuid: inst.server,
@@ -4029,10 +4022,21 @@ SdcAdm.prototype.checkHealth = function checkHealth(opts, cb) {
             return;
         }
 
+        // Make sure we remove the properties we'll assign later from an
+        // eventual previous invocation of this function, or those will be
+        // cached forever:
+        delete inst.health_errors;
+        delete inst.healthy;
+
         common.execFilePlus({
             argv: argv,
             log: self.log
         }, function (err, stdout, stderr) {
+            self.log.debug({
+                err: err,
+                stdout: stdout,
+                stderr: stderr
+            }, 'checkHeadnodeInst');
             var errs = [];
 
             if (err) {
@@ -4075,20 +4079,21 @@ SdcAdm.prototype.checkHealth = function checkHealth(opts, cb) {
             }
             try {
                 headnode = JSON.parse(stdout.trim());
-                if (!opts.insts) {
-                    insts.push({
-                        type: 'global',
-                        instance: headnode.UUID,
-                        alias: 'global',
-                        service: 'global',
-                        hostname: 'headnode',
-                        server: headnode.UUID
-                    });
-                }
             } catch (e) {
                 next(e);
                 return;
             }
+
+            if (!opts.insts) {
+                insts.push({
+                    type: 'global',
+                    instance: headnode.UUID,
+                    alias: 'global',
+                    service: 'global',
+                    hostname: 'headnode',
+                    server: headnode.UUID
+                });
+            }
             next();
         });
     }
diff --git a/lib/steps/index.js b/lib/steps/index.js
index a8f3472..5b6e24c 100644
--- a/lib/steps/index.js
+++ b/lib/steps/index.js
@@ -26,7 +26,8 @@ module.exports = {};
     'update_vm_size',
     'sapi',
     'servers',
-    'binder'
+    'binder',
+    'zookeeper'
 ].forEach(function (modName) {
     var mod = require('./' + modName);
     Object.keys(mod).forEach(function (symbol) {
diff --git a/lib/steps/zookeeper.js b/lib/steps/zookeeper.js
new file mode 100644
index 0000000..3ed5f98
--- /dev/null
+++ b/lib/steps/zookeeper.js
@@ -0,0 +1,790 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2018 Joyent, Inc.
+ */
+
+/*
+ * Zookeeper related steps shared across different sdcadm subcommands
+ */
+var fs = require('fs');
+var path = require('path');
+var util = require('util');
+
+var assert = require('assert-plus');
+var mkdirp = require('mkdirp');
+var vasync = require('vasync');
+
+var common = require('../common');
+var errors = require('../errors');
+var shared = require('../procedures/shared');
+
+/*
+ * Not exported helper functions
+ */
+function execFileAndParseJSONOutput(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.array(opts.argv, 'opts.argv');
+    assert.object(opts.log, 'opts.log');
+    assert.func(cb, 'cb');
+
+    common.execFilePlus({
+        argv: opts.argv,
+        log: opts.log
+    }, function execFilePlusCb(execErr, stdout, stderr) {
+        if (execErr) {
+            cb(execErr);
+            return;
+        }
+        var res, parseErr;
+        try {
+            // Due to the -j option of sdc-oneachnode:
+            res = JSON.parse(stdout);
+
+        } catch (e) {
+            parseErr = e;
+            opts.log.error({
+                err: e,
+                stdout: stdout,
+                stderr: stderr,
+                argv: opts.argv
+            }, 'sdc-oneachnode execFileAndParseJSONOutput');
+        }
+        var out = res[0].result.stdout.trim() || null;
+        var err = res[0].result.stderr.trim() || null;
+        opts.log.debug({
+            stdout: out,
+            stderr: err,
+            argv: opts.argv
+        }, 'sdc-oneachnode execFileAndParseJSONOutput');
+        cb(parseErr);
+    });
+}
+
+
+function execRemoteOnVm(opts, cb) {
+    assert.object(opts, 'opts');
+    assert.string(opts.cmd, 'opts.cmd');
+    assert.uuid(opts.vm_uuid, 'opts.vm_uuid');
+    assert.uuid(opts.server_uuid, 'opts.server_uuid');
+    assert.object(opts.log, 'opts.log');
+    assert.func(cb, 'cb');
+
+    common.execRemote({
+        cmd: opts.cmd,
+        vm: opts.vm_uuid,
+        server: opts.server_uuid,
+        log: opts.log
+    }, function execRemoteCb(err, stdout, stderr) {
+        if (err) {
+            cb(err);
+            return;
+        }
+        if (stderr) {
+            cb(new errors.InternalError({
+                message: stderr
+            }));
+            return;
+        }
+        cb();
+    });
+}
+
+
+/*
+ * Create a backup of Zookeeper's data directory
+ * (/zookeeper/zookeeper/version-2) which can be used to rebuild the status
+ * of the ZK system by replaying the transaction log.
+ *
+ * This can be used by new machines to reach the status the leader is at
+ * at the moment of the backup creation.
+ *
+ * The callback function should have the signature:
+ *      `callback(err, backupDirTimestamp)`
+ */
+function backupZKData(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.func(opts.progress, 'opts.progress');
+    assert.optionalObject(opts.ctx, 'opts.ctx');
+    assert.object(opts.log, 'opts.log');
+    assert.object(opts.sdcadm, 'opts.sdcadm');
+    assert.func(callback, 'callback');
+
+    var sdcadm = opts.sdcadm;
+    var context = opts.ctx || {};
+    var app = sdcadm.sdc;
+
+    vasync.pipeline({arg: context, funcs: [
+        function getBinderSvc(ctx, next) {
+            if (ctx.binderSvc) {
+                next();
+                return;
+            }
+            sdcadm.sapi.listServices({
+                name: 'binder',
+                application_uuid: app.uuid
+            }, function (svcErr, svcs) {
+                if (svcErr) {
+                    next(svcErr);
+                    return;
+                }
+                if (svcs.length) {
+                    ctx.binderSvc = svcs[0];
+                }
+                next();
+            });
+        },
+
+        function getBinderInsts(ctx, next) {
+            if (ctx.binderInsts) {
+                next();
+                return;
+            }
+            sdcadm.sapi.listInstances({
+                service_uuid: ctx.binderSvc.uuid
+            }, function (instErr, insts) {
+                if (instErr) {
+                    next(instErr);
+                    return;
+                }
+                ctx.binderInsts = insts;
+                next();
+            });
+        },
+
+        function getBinderVms(ctx, next) {
+            if (ctx.binderVms && ctx.binderIps) {
+                next();
+                return;
+            }
+            sdcadm.vmapi.listVms({
+                'tag.smartdc_role': 'binder',
+                state: 'running'
+            }, function vmapiCb(vmsErr, vms) {
+                if (vmsErr) {
+                    next(vmsErr);
+                    return;
+                }
+                ctx.binderVms = vms;
+                // Binder instances have only admin Ips:
+                ctx.binderIps = vms.map(function ipFromNic(vm) {
+                    return (vm.nics[0].ip);
+                });
+                next();
+            });
+        },
+        // Sets `ctx.wrkDir` and creates the directory. Also sets `ctx.stamp`.
+        function createWrkDir(ctx, next) {
+            var start = new Date();
+            ctx.stamp = common.utcTimestamp(start);
+            ctx.wrkDir = '/var/sdcadm/ha-binder/' + ctx.stamp;
+            opts.progress('Create work dir: ' + ctx.wrkDir);
+
+            mkdirp(ctx.wrkDir, function (err) {
+                if (err) {
+                    next(new errors.InternalError({
+                        message: 'error creating work dir: ' + ctx.wrkDir,
+                        cause: err
+                    }));
+                    return;
+                }
+                next();
+            });
+        },
+
+        function disableZkForBakup(ctx, next) {
+            ctx._1stVm = ctx.binderVms[0];
+            opts.progress('Disabling zookeeper for data backup');
+            shared.disableRemoteSvc({
+                server: ctx._1stVm.server_uuid,
+                zone: ctx._1stVm.uuid,
+                fmri: 'zookeeper',
+                log: opts.log
+            }, next);
+        },
+
+        function backupZookeeperData(ctx, next) {
+            opts.progress('Creating backup of zookeeper data directory ' +
+                    '(this may take some time)');
+            execRemoteOnVm({
+                cmd: 'cd /zookeeper/zookeeper; ' +
+                    '/opt/local/bin/tar czf zookeeper-' + ctx.stamp +
+                    '.tgz version-2',
+                vm_uuid: ctx._1stVm.uuid,
+                server_uuid: ctx._1stVm.server_uuid,
+                log: opts.log
+            }, next);
+        },
+
+        function enableZkAfterBackup(ctx, next) {
+            opts.progress('Enabling zookeeper after data backup');
+            shared.enableRemoteSvc({
+                server: ctx._1stVm.server_uuid,
+                zone: ctx._1stVm.uuid,
+                fmri: 'zookeeper',
+                log: opts.log
+            }, next);
+        },
+
+        function copyZkBackupToWorkDir(ctx, next) {
+            opts.progress('Copying backup of zookeeper data to: %s',
+                ctx.wrkDir);
+            var argv = [
+                '/opt/smartdc/bin/sdc-oneachnode',
+                '-j',
+                '-T',
+                '300',
+                '-n',
+                ctx._1stVm.server_uuid,
+                '-p',
+                util.format(
+                    '/zones/%s/root/zookeeper/zookeeper/zookeeper-%s.tgz',
+                    ctx.binderVms[0].uuid, ctx.stamp
+                ),
+                '--clobber',
+                '-d',
+                ctx.wrkDir
+            ];
+
+            execFileAndParseJSONOutput({
+                argv: argv,
+                log: opts.log
+            }, next);
+        },
+
+        function renameZkBackup(ctx, next) {
+            ctx.fname = path.join(ctx.wrkDir,
+                    util.format('zookeeper-%s.tgz', ctx.stamp));
+            opts.progress('Moving backup of zookeeper data to: %s', ctx.fname);
+            fs.rename(
+                path.join(ctx.wrkDir, ctx._1stVm.server_uuid),
+                ctx.fname, next);
+        }
+
+    ]}, function pipeCb(err) {
+        callback(err, context.stamp);
+    });
+}
+
+
+/*
+ * Replace binder's VM zookeeper's data directory with the contents of
+ * a previously made ZK's data backup.
+ */
+function replaceZKData(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.func(opts.progress, 'opts.progress');
+    assert.object(opts.vm, 'opts.vm');
+    assert.uuid(opts.vm.uuid, 'opts.vm.uuid');
+    assert.uuid(opts.vm.server_uuid, 'opts.vm.server_uuid');
+    assert.string(opts.stamp, 'opts.stamp');
+    assert.object(opts.log, 'opts.log');
+    assert.func(callback, 'callback');
+
+    var vm = opts.vm;
+    var workingDir = '/var/sdcadm/ha-binder/' + opts.stamp;
+    var context = {
+        stamp: opts.stamp,
+        wrkDir: workingDir,
+        fname: path.join(workingDir,
+                    util.format('zookeeper-%s.tgz', opts.stamp))
+    };
+
+     vasync.pipeline({arg: context, funcs: [
+         function disableZk(_, next) {
+             opts.progress('Disabling zookeeper in ' + vm.uuid);
+             shared.disableRemoteSvc({
+                server: vm.server_uuid,
+                zone: vm.uuid,
+                fmri: 'zookeeper',
+                log: opts.log
+            }, next);
+         },
+
+        // rm -Rf /zookeeper/zookeeper/version-2 from the instance
+        function removeZkDataFromInst(_, next) {
+            opts.progress('Clearing zookeeper data into ' + vm.uuid);
+            execRemoteOnVm({
+                cmd: 'rm -Rf /zookeeper/zookeeper/version-2',
+                vm_uuid: vm.uuid,
+                server_uuid: vm.server_uuid,
+                log: opts.log
+            }, next);
+        },
+
+        // Copy data from provided backup into the binder instance
+        function copyZkDataIntoNewInsts(ctx, next) {
+            opts.progress('Copying zookeeper data into ' + vm.uuid);
+
+            var argv = [
+                '/opt/smartdc/bin/sdc-oneachnode',
+                '-j',
+                '-T',
+                '300',
+                '-n',
+                vm.server_uuid,
+                '-g',
+                /* JSSTYLED */
+                ctx.fname,
+                '--clobber',
+                '-d',
+                util.format('/zones/%s/root/zookeeper/zookeeper',
+                        vm.uuid)
+            ];
+            execFileAndParseJSONOutput({
+                argv: argv,
+                log: opts.log
+            }, next);
+        },
+        // Untar data from backup into the new binder instance
+        function untarZkDataIntoNewInst(ctx, next) {
+            opts.progress('Extracting zookeeper data into instance ' +
+                vm.uuid + ' (may take some time)');
+            execRemoteOnVm({
+                cmd: 'cd /zookeeper/zookeeper; ' +
+                    '/opt/local/bin/tar xf zookeeper-' +
+                    ctx.stamp + '.tgz',
+                vm_uuid: vm.uuid,
+                server_uuid: vm.server_uuid,
+                log: opts.log
+            }, next);
+        },
+        // enable zookeeper into the new binder instances
+        function enableZkIntoNewInsts(_, next) {
+            opts.progress('Enabling zookeeper into instance ' + vm.uuid);
+            shared.enableRemoteSvc({
+                server: vm.server_uuid,
+                zone: vm.uuid,
+                fmri: 'zookeeper',
+                log: opts.log
+            }, next);
+        }
+
+     ]}, function pipeCb(pipeErr) {
+         callback(pipeErr);
+     });
+}
+
+function clearZKBackup(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.func(opts.progress, 'opts.progress');
+    assert.object(opts.vm, 'opts.vm');
+    assert.uuid(opts.vm.uuid, 'opts.vm.uuid');
+    assert.uuid(opts.vm.server_uuid, 'opts.vm.server_uuid');
+    assert.string(opts.stamp, 'opts.stamp');
+    assert.object(opts.log, 'opts.log');
+    assert.func(callback, 'callback');
+
+    var vm = opts.vm;
+    opts.progress('Removing zookeeper data backup from %s',
+            vm.uuid);
+    execRemoteOnVm({
+        cmd: 'rm /zookeeper/zookeeper/zookeeper-' + opts.stamp + '.tgz',
+        vm_uuid: vm.uuid,
+        server_uuid: vm.server_uuid,
+        log: opts.log
+    }, callback);
+}
+
+/*
+ * We usually gather all the information about `sdc` application, binder,
+ * manatee, moray instances before we attempt any configuration changes,
+ * just in case any of our services didn't come up clear.
+ *
+ * Expected callback signature is `function(err, context)` where the
+ * returned `context` object will contain the properties:
+ * - moraySvc (Object)
+ * - manateeSvc (Object)
+ * - morayVms (Array of VM Objects)
+ * - manateeVms (Array of VM Objects)
+ * - shard (Manatee Shard Object including server uuids for every VM)
+ * - hasManatee21 (Boolean)
+ *
+ */
+function getCoreZkConfig(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.object(opts.log, 'opts.log');
+    assert.func(opts.progress, 'opts.progress');
+    assert.object(opts.sdcadm, 'opts.sdcadm');
+    assert.func(callback, 'callback');
+
+    var app = opts.sdcadm.sdc;
+    var context = {};
+
+    vasync.pipeline({arg: context, funcs: [
+        function getMorayService(ctx, next) {
+            opts.progress('Getting SDC\'s moray details from SAPI');
+            opts.sdcadm.sapi.listServices({
+                name: 'moray',
+                application_uuid: app.uuid
+            }, function (svcErr, svcs) {
+                if (svcErr) {
+                    next(svcErr);
+                    return;
+                }
+                if (!svcs.length) {
+                    next(new errors.SDCClientError(new Error(
+                        'No services named "moray"'), 'sapi'));
+                    return;
+                }
+                ctx.moraySvc = svcs[0];
+                next();
+            });
+        },
+
+        function getMorayVms(ctx, next) {
+            opts.progress('Getting SDC\'s moray vms from VMAPI');
+            opts.sdcadm.vmapi.listVms({
+                'tag.smartdc_role': 'moray',
+                state: 'running'
+            }, function (vmsErr, vms) {
+                if (vmsErr) {
+                    next(vmsErr);
+                    return;
+                }
+                ctx.morayVms = vms;
+                next();
+            });
+        },
+
+        function getManateeService(ctx, next) {
+            opts.progress('Getting SDC\'s manatee details from SAPI');
+            opts.sdcadm.sapi.listServices({
+                name: 'manatee',
+                application_uuid: app.uuid
+            }, function (svcErr, svcs) {
+                if (svcErr) {
+                    next(svcErr);
+                    return;
+                }
+                if (!svcs.length) {
+                    next(new errors.SDCClientError(new Error(
+                        'No services named "manatee"'), 'sapi'));
+                    return;
+                }
+                ctx.manateeSvc = svcs[0];
+                next();
+            });
+        },
+
+        function getManateeVms(ctx, next) {
+            opts.progress('Getting SDC\'s manatees vms from VMAPI');
+            opts.sdcadm.vmapi.listVms({
+                'tag.smartdc_role': 'manatee',
+                state: 'running'
+            }, function (vmsErr, vms) {
+                if (vmsErr) {
+                    next(vmsErr);
+                    return;
+                }
+                ctx.manateeVms = vms;
+                next();
+            });
+        },
+
+        function getShard(ctx, next) {
+            opts.progress('Getting manatee shard status');
+            var vm = ctx.manateeVms[0];
+
+            shared.getShardState({
+                server: vm.server_uuid,
+                manateeUUID: vm.uuid,
+                log: opts.log
+            }, function getShardStateCb(err, st) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                ctx.shard = st;
+                // Also set server uuid for each one of the manatees on the
+                // shard to simplify next steps:
+                ctx.manateeVms.forEach(function setShardVmServer(v) {
+                    var primary = ctx.shard.primary;
+                    var sync = ctx.shard.sync;
+                    var async = ctx.shard.async;
+                    if (primary.zoneId === v.uuid) {
+                        ctx.shard.primary.server = v.server_uuid;
+                    } else if (sync && sync.zoneId === v.uuid) {
+                        ctx.shard.sync.server = v.server_uuid;
+                    } else if (async && async.length) {
+                        ctx.shard.async = async.map(function (v2) {
+                            if (v2.zoneId === v.uuid) {
+                                v2.server = v.server_uuid;
+                            }
+                            return (v2);
+                        });
+                    }
+                });
+                next();
+            });
+        },
+
+        // Check manatee-adm version in order to take advantage of latest
+        // available sub-commands if possible:
+        function getManateeVersion(ctx, next) {
+            opts.sdcadm.imgapi.getImage(ctx.manateeVms[0].image_uuid, {
+            }, function getImgCb(err, image) {
+                if (err) {
+                    next(err);
+                } else {
+                    var parts = image.version.split('-');
+                    var curVer = parts[parts.length - 2];
+                    if (curVer >= '20150320T174220Z') {
+                        ctx.hasManatee21 = true;
+                    }
+                    next();
+                }
+            });
+        }
+
+    ]}, function pipeCb(pipeErr) {
+        callback(pipeErr, context);
+    });
+}
+
+/*
+ * Once we've added one or more binder instances, we need to reconfigure
+ * everything from `sdc` application to all the services where ZK_SERVERS
+ * are included, alongside with all those service's instances, including
+ * synchronous calls to config agent everywhere
+ */
+function updateCoreZkConfig(opts, callback) {
+    assert.object(opts, 'opts');
+    assert.object(opts.ctx, 'opts.ctx');
+
+    assert.object(opts.ctx.binderInsts, 'opts.ctx.binderInsts');
+    assert.object(opts.ctx.binderVms, 'opts.ctx.binderVms');
+    assert.object(opts.ctx.binderIps, 'opts.ctx.binderIps');
+    assert.object(opts.ctx.moraySvc, 'opts.ctx.moraySvc');
+    assert.object(opts.ctx.manateeSvc, 'opts.ctx.manateeSvc');
+    assert.object(opts.ctx.manateeVms, 'opts.ctx.manateeVms');
+    assert.bool(opts.ctx.hasManatee21, 'opts.ctx.hasManatee21');
+    assert.object(opts.ctx.morayVms, 'opts.ctx.morayVms');
+
+    assert.object(opts.log, 'opts.log');
+    assert.func(opts.progress, 'opts.progress');
+    assert.object(opts.sdcadm, 'opts.sdcadm');
+    assert.func(callback, 'callback');
+
+    var app = opts.sdcadm.sdc;
+    var context = Object.assign({
+        HA_ZK_JSON: []
+    }, opts.ctx);
+
+    vasync.pipeline({arg: context, funcs: [
+
+        function prepareClusterPayload(ctx, next) {
+            ctx.binderVms.forEach(function jsonFromInst(vm) {
+                var instance = ctx.binderInsts.filter(function (i) {
+                    return (i.uuid === vm.uuid);
+                })[0];
+
+                ctx.HA_ZK_JSON.push({
+                    host: vm.nics[0].ip,
+                    port: 2181,
+                    num: Number(instance.metadata.ZK_ID)
+                });
+            });
+
+            // Set a value for special property "last" for just the final
+            // element of the collection
+            ctx.HA_ZK_JSON[ctx.HA_ZK_JSON.length - 1].last = true;
+            next();
+        },
+
+        function cfgSdcApp(ctx, next) {
+            opts.progress('Updating Binder service config in SAPI');
+            opts.sdcadm.sapi.updateApplication(app.uuid, {
+                metadata: {
+                    ZK_SERVERS: ctx.HA_ZK_JSON
+                }
+            }, next);
+        },
+
+        // Set ZK_SERVERS, not ZK_HA_SERVERS
+        function cfgMoraySvc(ctx, next) {
+            opts.progress('Updating Moray service config in SAPI');
+            opts.sdcadm.sapi.updateService(ctx.moraySvc.uuid, {
+                metadata: {
+                    ZK_SERVERS: ctx.HA_ZK_JSON
+                }
+            }, next);
+        },
+
+        // Set ZK_SERVERS, not ZK_HA_SERVERS
+        function cfgManateeSvc(ctx, next) {
+            opts.progress('Updating Manatee service config in SAPI');
+            opts.sdcadm.sapi.updateService(ctx.manateeSvc.uuid, {
+                metadata: {
+                    ZK_SERVERS: ctx.HA_ZK_JSON
+                }
+            }, next);
+        },
+
+        // Call config-agent sync for all the binder VMs
+        function callConfigAgentSyncForAllBinders(ctx, next) {
+            opts.progress('Reloading config for all the binder VMs');
+            vasync.forEachParallel({
+                inputs: ctx.binderVms,
+                func: function callCfgSync(vm, nextInst) {
+                    common.callConfigAgentSync({
+                        vm: vm.uuid,
+                        server: vm.server_uuid,
+                        log: opts.log
+                    }, nextInst);
+                }
+            }, next);
+        },
+
+        function waitForZkClusterOk(ctx, next) {
+            opts.progress('Waiting for ZK cluster to reach a steady state');
+
+            shared.wait4ZkOk({
+                ips: ctx.binderIps,
+                log: opts.log
+            }, next);
+        },
+
+        function checkAllInstancesJoinedZkCluster(ctx, next) {
+            opts.progress('Waiting for binder instances to join ZK cluster');
+
+            shared.wait4ZkCluster({
+                ips: ctx.binderIps,
+                log: opts.log
+            }, next);
+        },
+
+        function getZkLeaderIP(ctx, next) {
+            opts.progress('Getting ZK leader IP');
+
+            shared.getZkLeaderIP({
+                ips: ctx.binderIps,
+                log: opts.log
+            }, function (err, ip) {
+                if (err) {
+                    next(err);
+                    return;
+                }
+                ctx.leaderIP = ip;
+                next();
+            });
+        },
+
+
+
+        // Call config-agent sync for all the manatee VMs
+        function callConfigAgentSyncForAllManatees(ctx, next) {
+            opts.progress('Reloading config for all the manatee VMs');
+            vasync.forEachParallel({
+                inputs: ctx.manateeVms,
+                func: function callCfgSync(vm, next_) {
+                    common.callConfigAgentSync({
+                        vm: vm.uuid,
+                        server: vm.server_uuid,
+                        log: opts.log
+                    }, next_);
+                }
+            }, next);
+        },
+
+        // HUP Manatee (Already waits for manatee shard to
+        // reach the desired status):
+        function disableManatee(ctx, next) {
+            shared.disableManateeSitter({
+                progress: opts.progress,
+                log: opts.log,
+                leaderIP: ctx.leaderIP,
+                shard: ctx.shard,
+                hasManatee21: ctx.hasManatee21
+            }, next);
+        },
+
+        function enableManatee(ctx, next) {
+            shared.enableManateeSitter({
+                progress: opts.progress,
+                log: opts.log,
+                leaderIP: ctx.leaderIP,
+                shard: ctx.shard,
+                hasManatee21: ctx.hasManatee21
+            }, next);
+        },
+
+        // Call config-agent sync for all the moray VMs
+        function callConfigAgentSyncForAllMorays(ctx, next) {
+            opts.progress('Reloading config for all the moray VMs');
+            vasync.forEachParallel({
+                inputs: ctx.morayVms,
+                func: function callCfgSync(vm, next_) {
+                    common.callConfigAgentSync({
+                        vm: vm.uuid,
+                        server: vm.server_uuid,
+                        log: opts.log
+                    }, next_);
+                }
+            }, next);
+        },
+
+        // HUP morays:
+        function restartMorays(ctx, next) {
+            opts.progress('Restarting moray services');
+            vasync.forEachParallel({
+                inputs: ctx.morayVms,
+                func: function restartMoray(vm, next_) {
+                    shared.restartRemoteSvc({
+                        server: vm.server_uuid,
+                        zone: vm.uuid,
+                        fmri: '*moray-202*',
+                        log: opts.log
+                    }, next_);
+                }
+            }, next);
+        },
+
+        function wait4Morays(ctx, next) {
+            opts.progress('Waiting for moray services to be up into' +
+                    ' every moray instance');
+            shared.wait4Morays({
+                vms: ctx.morayVms,
+                sdcadm: opts.sdcadm
+            }, next);
+        },
+
+        function unfreezeManatee(ctx, next) {
+            opts.progress('Unfreezing manatee shard');
+            common.manateeAdmRemote({
+                server: ctx.manateeVms[0].server_uuid,
+                vm: ctx.manateeVms[0].uuid,
+                cmd: 'unfreeze',
+                log: opts.log
+            }, function (err, _, stder) {
+                if (err) {
+                    next(err);
+                    return;
+                } else if (stder) {
+                    next(new errors.InternalError({
+                        message: stder
+                    }));
+                    return;
+                }
+                next();
+            });
+        }
+
+    ]}, callback);
+}
+
+// --- exports
+
+module.exports = {
+    backupZKData: backupZKData,
+    replaceZKData: replaceZKData,
+    clearZKBackup: clearZKBackup,
+    getCoreZkConfig: getCoreZkConfig,
+    updateCoreZkConfig: updateCoreZkConfig
+};
+
+// vim: set softtabstop=4 shiftwidth=4:
diff --git a/lib/vmadm.js b/lib/vmadm.js
index edb966d..e6bc184 100644
--- a/lib/vmadm.js
+++ b/lib/vmadm.js
@@ -109,10 +109,11 @@ function vmGet(uuid, options, callback) {
         }
         try {
             var vm = JSON.parse(stdout);
-            callback(null, vm);
         } catch (e) {
             callback(e);
+            return;
         }
+        callback(null, vm);
     });
 }
 
diff --git a/man/man1/sdcadm.1.ronn b/man/man1/sdcadm.1.ronn
index c3ea942..f887080 100644
--- a/man/man1/sdcadm.1.ronn
+++ b/man/man1/sdcadm.1.ronn
@@ -391,32 +391,64 @@ into the same network for any CN.
 
 ### sdcadm post-setup ha-binder \[options\]
 
-Create a binder cluster, known as an ensemble, using the headnode's
-binder as the first member and leader of the cluster.
+Setup the binder service for high availability (HA).
 
-Given that the existing binder instance will be included into the
-ensemble, and we need an odd number of machines for better cluster
-reliability, we need to specify an additional number of new instances
-to be created, either 2 or 4, in order to complete a total of 3 or 5
-instances.
+The binder service provides internal DNS to Triton core services.
+It also holds a zookeeper (ZK) cluster used by some Triton core
+services. To best support ZK availability we want an odd number of
+binder instances. One, three, or five instances are supported.
 
-Remember that you need to specify the -s option as many times as
-different servers UUIDs you need to provide:
-
-sdcadm post-setup ha-binder -s SERVER\_UUID1 -s SERVER\_UUID2
+Usage:
+     sdcadm post-setup ha-binder SERVER1 SERVER2 ...
 
+Options:
 
 `-h, --help`
-    Show this help and exit.
+    Show this help.
+
+`--allow-delete`
+    Allow replacement/deletion of existing binder instances.
+
+`--dev-allow-repeat-servers`
+    For development, allow a binder cluster with
+    multiple instances on the same server.
 
 `-y, --yes`
     Answer yes to all confirmations.
 
-`-s ARG, --servers=ARG`
-    UUID for the target servers. At least m are required.
+"SERVER ..." should list one, three, or five setup servers (hostname
+or UUID) on which a binder instance is desired. Note that this
+*includes* existing binder instances, e.g. the "binder0" instance
+typically on the initial headnode.
 
-`-m INT, --members=INT`
-    Number of instances to create (2 or 4). Default: 2
+For backward compatibility,
+`sdcadm post-setup ha-binder -s SERVER2 -s SERVER3` is accepted
+(a) when there is only a single binder on the headnode and
+(b) to mean that two binder instances should be added for a total of
+three instances. The new calling form is preferred because it is
+idempotent.
+
+Examples:
+    # Ensure a 3-instance binder cluster on the given 3 servers.
+    sdcadm post-setup ha-binder headnode SERVER2 SERVER3
+
+    # Deprecated. Same result as preview example.
+    sdcadm post-setup ha-binder -s SERVER2 -s SERVER3
+
+At least one of the existing binder instances must remain unchanged
+during the process. In case the desired configuration does not
+include any of the existing instances, the recommended procedure is
+to complete the removal or replacement of all the desired instances
+in two steps, keeping at least one of the instances during the first
+run of the command. For example, say we want to "move" our binder
+instances from servers "headnode", "SERVER1" and "SERVER2" to the
+new servers "SERVER4", "SERVER5" and "new-headnode". We can proceed
+as follows:
+
+    # Replace all but the first instance:
+    sdcadm post-setup ha-binder headnode SERVER4 SERVER5
+    # Replace the first one while keeping the new instances:
+    sdcadm post-setup ha-binder new-headnode SERVER4 SERVER5
 
 ### sdcadm post-setup ha-manatee \[options\]
 
@@ -1093,4 +1125,4 @@ Enables/disables support for various NFS volumes features.
 
 ## COPYRIGHT
 
-sdcadm Copyright (c) 2017 Joyent Inc., All rights reserved.
+sdcadm Copyright (c) 2018 Joyent Inc., All rights reserved.
diff --git a/package.json b/package.json
index f8011bc..96badd4 100644
--- a/package.json
+++ b/package.json
@@ -1,7 +1,7 @@
 {
   "name": "sdcadm",
   "description": "Administer a SmartDataCenter (SDC) standup",
-  "version": "1.17.3",
+  "version": "1.17.4",
   "author": "Joyent (joyent.com)",
   "private": true,
   "dependencies": {
diff --git a/test/post-setup-ha-binder.test.js b/test/post-setup-ha-binder.test.js
new file mode 100644
index 0000000..404c4b8
--- /dev/null
+++ b/test/post-setup-ha-binder.test.js
@@ -0,0 +1,230 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2018, Joyent, Inc.
+ */
+
+/*
+ * Tests for `sdcadm post-setup ha-binder`
+ */
+
+var util = require('util');
+var format = util.format;
+
+var test = require('tape').test;
+var uuid = require('node-uuid');
+
+var exec = require('child_process').exec;
+var common = require('./common');
+var checkHelp = common.checkHelp;
+var shared = require('./shared');
+
+var haveMultipleServers = false;
+var servers = [];
+
+function getServers(t, cb) {
+    var cmd = 'sdc-cnapi /servers?setup=true|json -H -j';
+    exec(cmd, function (err, stderr, stdout) {
+        t.ifError(err, 'cnapi error');
+        t.equal(stdout, '', 'empty stdout');
+        var out = JSON.parse(stderr);
+        servers = out;
+        if (out.length && out.length > 1) {
+            haveMultipleServers = true;
+        }
+        cb();
+    });
+}
+
+function getInstances(t, cb) {
+    var cmd = 'sdc-sapi /instances?service_uuid=$(sdc-sapi ' +
+        '/services?name=binder|json -Ha uuid)|json -H';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ifError(err, 'Get instances error');
+        t.equal(stderr, '', 'Get instances empty stderr');
+        var insts = JSON.parse(stdout);
+        t.ok(Array.isArray(insts), 'Binder array of instances');
+        t.ok(insts.length, 'Binder instances');
+        cb(insts);
+    });
+}
+
+test('setup', function (t) {
+    getServers(t, function () {
+        getInstances(t, function () {
+            shared.prepare(t, {external_nics: true});
+        });
+    });
+});
+
+test('post-setup help ha-binder', function (t) {
+    checkHelp(t, 'post-setup ha-binder',
+        'Setup the binder service for high availability (HA)');
+});
+
+// `post-setup zookeeper` is deprecated
+test('sdcadm post-setup zookeeper', function (t) {
+    exec('sdcadm post-setup zookeeper', function (err, stdout, stderr) {
+        t.ok(err, 'post-setup zookeeper err');
+        t.ok(stdout, 'post-setup zookeeper stdout');
+        t.ok(stderr.indexOf('deprecated'), 'post-setup zookeeper stderr');
+        t.end();
+    });
+});
+
+// Test backwards compatibility with the old `-s server` way
+test('sdcadm post-setup ha-binder', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder -s headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'Backcompat err');
+        t.ok(stdout.indexOf('deprecated'),
+            'Backcompat stderr');
+        t.ok(stderr.indexOf('Invalid number of binder cluster members'),
+            'Backcompat stderr');
+        t.end();
+    });
+});
+
+test('post-setup ha-binder bogus servers', function (t) {
+    var cmd = format('sdcadm post-setup ha-binder %s %s %s',
+        'headnode', uuid(), uuid());
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'Bogus servers err');
+        t.ok(stdout, 'Bogus server stdout');
+        t.ok(stderr.indexOf('Must provide valid server UUIDs or hostnames'),
+            'Bogus servers stderr');
+        t.end();
+    });
+});
+
+test('post-setup ha-binder invalid number of args', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder headnode headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'invalid number of args err');
+        t.equal('', stdout, 'invalid number of args stdout');
+        t.ok(stderr.indexOf('invalid number of args'),
+            'invalid number of args stderr');
+        t.end();
+    });
+});
+
+test('post-setup ha-binder without --dev-allow-repeat-servers', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder headnode headnode headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'W/o --dev-allow-repeat-servers err');
+        t.ok(stdout, 'W/o --dev-allow-repeat-servers stdout');
+        t.ok(stderr.indexOf('--dev-allow-repeat-servers'),
+            'W/o --dev-allow-repeat-servers stderr');
+        t.end();
+    });
+});
+
+test('post-setup ha-binder with --dev-allow-repeat-servers', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder ' +
+        ' --dev-allow-repeat-servers' +
+        ' --yes' +
+        ' headnode headnode headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ifError(err, 'ha-binder err');
+        t.equal(stderr, '', 'Empty stderr');
+        t.ok(stdout.indexOf('Extracting zookeeper data into instance'),
+            'Extract ZK data');
+        t.ok(stdout.indexOf('Waiting for binder instances to join ZK cluster'),
+            'ZK cluster');
+        t.ok(stdout.indexOf('Creating "binder'), 'Create instances');
+        t.ok(stdout.indexOf('Updating admin network resolvers'),
+            'Update resolvers');
+        getInstances(t, function (insts) {
+            t.ok(insts.length === 3, 'Created two instances');
+            t.end();
+        });
+    });
+});
+
+test('post-setup ha-binder replace all instances', function (t) {
+    if (!haveMultipleServers) {
+        t.end();
+        return;
+    }
+    var aCn = servers.filter(function (s) {
+        return (s.hostname !== 'headnode');
+    })[0].uuid;
+
+    var cmd = 'sdcadm post-setup ha-binder ' +
+        ' --dev-allow-repeat-servers' +
+        ' --allow-delete' +
+        ' --yes' +
+        format(' %s %s %s', aCn, aCn, aCn);
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'Replace all instances err');
+        t.ok(stdout, 'Replace all instances stdout');
+        t.ok(stderr.indexOf('At least one of the existing' +
+            'binder instances must remain'),
+            'Replace all instances stderr');
+        t.end();
+    });
+});
+
+
+test('post-setup ha-binder replace some instances', function (t) {
+    if (!haveMultipleServers) {
+        t.end();
+        return;
+    }
+    var aCn = servers.filter(function (s) {
+        return (s.hostname !== 'headnode');
+    })[0].uuid;
+
+    var cmd = 'sdcadm post-setup ha-binder ' +
+        ' --dev-allow-repeat-servers' +
+        ' --allow-delete' +
+        ' --yes' +
+        format(' headnode headnode %s', aCn);
+    exec(cmd, function (err, stdout, stderr) {
+        t.ifError(err, 'Replace some instances err');
+        t.equal(stderr, '', 'Replace some instances stderr');
+        t.ok(stdout.indexOf('Creating "binder'), 'Create instances');
+        t.ok(stdout.indexOf('Updating admin network resolvers'),
+            'Update resolvers');
+        t.ok(stdout.indexOf('Removing'), 'Remove instance');
+        getInstances(t, function (insts) {
+            t.ok(insts.length === 3, 'Created one instance, removes another');
+            t.end();
+        });
+    });
+});
+
+test('post-setup ha-binder remove w/o --allow-delete', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder ' +
+        ' --yes' +
+        ' headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ok(err, 'W/o --allow-delete err');
+        t.ok(stdout, 'W/o --allow-delete stdout');
+        t.ok(stderr.indexOf('--allow-delete'),
+            'W/o --dev-allow-repeat-servers stderr');
+        t.end();
+    });
+});
+
+
+test('post-setup ha-binder remove HA', function (t) {
+    var cmd = 'sdcadm post-setup ha-binder ' +
+        ' --allow-delete' +
+        ' --yes' +
+        ' headnode';
+    exec(cmd, function (err, stdout, stderr) {
+        t.ifError(err, 'ha-binder err');
+        t.equal(stderr, '', 'Empty stderr');
+        t.ok(stdout.indexOf('Extracting zookeeper data into instance'),
+            'Extract ZK data');
+        getInstances(t, function (insts) {
+            t.ok(insts.length === 1, 'Destroyed two instances');
+            t.end();
+        });
+    });
+});
diff --git a/test/post-setup.test.js b/test/post-setup.test.js
index 92d00fc..08e9b45 100644
--- a/test/post-setup.test.js
+++ b/test/post-setup.test.js
@@ -320,50 +320,6 @@ test('sdcadm post-setup help dev-sample-data', function (t) {
 });
 
 
-test('sdcadm post-setup ha-binder', function (t) {
-    exec('sdcadm post-setup ha-binder', function (err, stdout, stderr) {
-        t.ok(err);
-
-        t.equal(stdout, '');
-        t.notEqual(stderr.indexOf('Must specify 1 servers'), -1);
-
-        t.end();
-    });
-});
-
-
-test('sdcadm post-setup ha-binder --members', function (t) {
-    exec('sdcadm post-setup ha-binder -m 4', function (err, stdout, stderr) {
-        t.ok(err);
-
-        t.equal(stdout, '');
-        t.notEqual(stderr.indexOf('Must specify 3 servers'), -1);
-
-        t.end();
-    });
-});
-
-
-test('sdcadm post-setup ha-binder --servers', function (t) {
-    var serverUuids = '';
-
-    exec('sdcadm post-setup ha-binder -s ' + serverUuids,
-         function (err, stdout, stderr) {
-             console.log(err);
-             console.log(stdout);
-             console.log(stderr);
-        // TODO
-        t.end();
-    });
-});
-
-
-test('sdcadm post-setup help ha-binder', function (t) {
-    checkHelp(t, 'post-setup ha-binder',
-        'HA setup for binder/zookeeper services using binder instances');
-});
-
-
 test('sdcadm post-setup ha-manatee', function (t) {
     exec('sdcadm post-setup ha-manatee', function (err, stdout, stderr) {
         t.ok(err);
-- 
2.21.0

