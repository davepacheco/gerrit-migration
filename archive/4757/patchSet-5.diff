From 74bc4d6289886a15c28c277c6dfb4ec990229809 Mon Sep 17 00:00:00 2001
From: Cody Peter Mello <cody.mello@joyent.com>
Date: Thu, 23 Aug 2018 22:18:43 +0000
Subject: [PATCH] MORAY-474 Update Moray to use node v6 MORAY-491 Update Moray
 to use ESLint 4.x Reviewed by: Alex Wilson <alex.wilson@joyent.com> Reviewed
 by: Trent Mick <trentm@gmail.com> Approved by: Trent Mick <trentm@gmail.com>

---
 .eslintrc              |   5 ++
 Makefile               |   2 +-
 lib/buckets/common.js  |  10 ++--
 lib/buckets/creat.js   |  14 ++---
 lib/buckets/update.js  |  20 ++++---
 lib/objects/common.js  | 116 ++++++++++++++++++++++++-----------------
 lib/objects/find.js    |  11 ++--
 lib/objects/put.js     |   3 +-
 lib/objects/reindex.js |  14 +++--
 lib/objects/update.js  |   2 +-
 lib/pg.js              |   6 ++-
 lib/ping.js            |   1 -
 package.json           |  10 ++--
 13 files changed, 126 insertions(+), 88 deletions(-)

diff --git a/.eslintrc b/.eslintrc
index ccc6f09..33c3a07 100644
--- a/.eslintrc
+++ b/.eslintrc
@@ -15,5 +15,10 @@
         "node": true
     },
     "rules": {
+        "callback-return": "off",
+
+        // Style:
+        "func-style": [ "error", "declaration" ],
+        "multiline-comment-style": [ "error", "starred-block" ]
     }
 }
diff --git a/Makefile b/Makefile
index 36d406c..b179410 100644
--- a/Makefile
+++ b/Makefile
@@ -47,7 +47,7 @@ ifeq ($(shell uname -s),SunOS)
 	# Allow building on a SmartOS image other than sdc-*-multiarch 15.4.1.
 	NODE_PREBUILT_IMAGE	= 18b094b0-eb01-11e5-80c1-175dac7ddf02
 	NODE_PREBUILT_TAG	= zone
-	NODE_PREBUILT_VERSION	:= v0.10.48
+	NODE_PREBUILT_VERSION	:= v6.14.3
 endif
 
 # RELENG-341: no npm cache is making builds unreliable
diff --git a/lib/buckets/common.js b/lib/buckets/common.js
index fe47c4f..9243fb7 100644
--- a/lib/buckets/common.js
+++ b/lib/buckets/common.js
@@ -29,9 +29,10 @@ var TYPES = require('../types').TYPES;
 
 // --- Globals
 
-// Postgres rules:
-// start with a letter, everything else is alphum or '_', and must be
-// <= 63 characters in length
+/*
+ * Postgres rules: a table name must start with a letter, everything else is
+ * alphanumeric or '_'. The name must be <= 63 characters in length.
+ */
 var BUCKET_NAME_RE = /^[a-zA-Z]\w{0,62}$/;
 
 var INDEX_NAME_RE =
@@ -66,8 +67,9 @@ function buildIndexString(schema) {
     var str = '';
     Object.keys(schema).forEach(function (k) {
         str += ',\n        ' + k + ' ' + typeToPg(schema[k].type);
-        if (schema[k].unique)
+        if (schema[k].unique) {
             str += ' UNIQUE';
+        }
     });
 
     return (str);
diff --git a/lib/buckets/creat.js b/lib/buckets/creat.js
index c763765..3febc25 100644
--- a/lib/buckets/creat.js
+++ b/lib/buckets/creat.js
@@ -41,8 +41,10 @@ var PIPELINE = [
 // --- Handlers
 
 function insertConfig(req, cb) {
-    if (req.prev)
-        return (cb());
+    if (req.prev) {
+        cb();
+        return;
+    }
 
     cb = once(cb);
 
@@ -84,8 +86,6 @@ function insertConfig(req, cb) {
         log.debug('insertConfig: done');
         cb();
     });
-
-    return (undefined);
 }
 
 
@@ -199,8 +199,10 @@ function createTable(req, cb) {
 
 
 function createIndexes(req, cb) {
-    // we can skip unique indexes, as those implicitly have a PG index
-    // at create table time
+    /*
+     * we can skip unique indexes, as those implicitly have a PG index
+     * at the time of table creation.
+     */
     common.createIndexes({
         bucket: req.bucket.name,
         log: req.log,
diff --git a/lib/buckets/update.js b/lib/buckets/update.js
index 9b4d603..d4048a2 100644
--- a/lib/buckets/update.js
+++ b/lib/buckets/update.js
@@ -113,9 +113,11 @@ function loadBucket(req, cb) {
         // Needed for reindexing details
         req.raw_bucket = row;
 
-        // Note v=0 is a legacy hack here that you get when you make a
-        // bucket with no version. If you have the version set to zero
-        // in the DB, we go ahead and overwrite regardless.
+        /*
+         * Note v=0 is a legacy hack here that you get when you make a
+         * bucket with no version. If you have the version set to zero
+         * in the DB, we go ahead and overwrite regardless.
+         */
         if (v !== 0 && v >= v2) {
             log.warn({
                 bucket: b.name,
@@ -196,12 +198,14 @@ function calculateDiff(req, cb) {
 }
 
 
-function ensureRowVer(req, cb) {
-    // If a reindex operation has been requested, updated/pending rows will
-    // need a _rver column to track completion.  Since this will be in use as
-    // soon as the bucket record is updated with the reindexing operation, it
-    // _must_ exist beforehand.
 
+/**
+ * If a reindex operation has been requested, updated/pending rows will need a
+ * _rver column to track completion.  Since this will be in use as soon as the
+ * bucket record is updated with the reindexing operation, it _must_ exist
+ * beforehand.
+ */
+function ensureRowVer(req, cb) {
     if (req.opts.no_reindex || !req.bucket.options.version) {
         // skip if bucket is versionless or reindexing excluded
         cb(null);
diff --git a/lib/objects/common.js b/lib/objects/common.js
index 820922e..83e98b1 100644
--- a/lib/objects/common.js
+++ b/lib/objects/common.js
@@ -453,28 +453,34 @@ function compileQuery(b, f, args) {
 
         if (f.initial) {
             _v = _value(b.index, f.attribute, f.initial, f);
-            if (_v.isArray)
+            if (_v.isArray) {
                 throw new NotIndexedError(b.name, f.toString());
-            if (_v.value === undefined)
+            }
+            if (_v.value === undefined) {
                 valid = false;
+            }
             _like_tmp += _v.value + '%';
         }
 
         f.any.forEach(function (any) {
             _v = _value(b.index, f.attribute, any, f);
-            if (_v.isArray)
+            if (_v.isArray) {
                 throw new NotIndexedError(b.name, f.toString());
-            if (_v.value === undefined)
+            }
+            if (_v.value === undefined) {
                 valid = false;
+            }
             _like_tmp += '%' + _v.value + '%';
         });
 
         if (f.final) {
             _v = _value(b.index, f.attribute, f.final, f);
-            if (_v.isArray)
+            if (_v.isArray) {
                 throw new NotIndexedError(b.name, f.toString());
-            if (_v.value === undefined)
+            }
+            if (_v.value === undefined) {
                 valid = false;
+            }
             _like_tmp += '%' + _v.value + '%';
         }
 
@@ -496,13 +502,15 @@ function compileQuery(b, f, args) {
                 ands.push(v);
             }
         });
-        if (ands.length === 0)
+        if (ands.length === 0) {
             throw new NotIndexedError(b.name, f.toString());
+        }
 
         for (i = 0; i < ands.length; i++) {
             clause += ' (' + ands[i] + ') ';
-            if (i < ands.length - 1)
+            if (i < ands.length - 1) {
                 clause += 'AND';
+            }
         }
         break;
 
@@ -510,18 +518,21 @@ function compileQuery(b, f, args) {
         var ors = [];
         f.filters.forEach(function (_f) {
             v = compileQuery(b, _f, args);
-            if (v === '')
+            if (v === '') {
                 throw new NotIndexedError(b.name, f.toString());
+            }
 
             ors.push(v);
         });
-        if (ors.length === 0)
+        if (ors.length === 0) {
             throw new NotIndexedError(b.name, f.toString());
+        }
 
         for (i = 0; i < ors.length; i++) {
             clause += ' (' + ors[i] + ') ';
-            if (i < ors.length - 1)
+            if (i < ors.length - 1) {
                 clause += 'OR';
+            }
         }
         break;
 
@@ -533,15 +544,17 @@ function compileQuery(b, f, args) {
         break;
 
     case 'substring':
-        if (!b.index[f.attribute] && !/^_\w+/.test(f.attribute))
+        if (!b.index[f.attribute] && !/^_\w+/.test(f.attribute)) {
             break;
+        }
 
         _substr('LIKE');
         break;
 
     case 'present':
-        if (b.index[f.attribute])
+        if (b.index[f.attribute]) {
             clause += f.attribute + ' IS NOT NULL';
+        }
         break;
 
     case 'ge':
@@ -989,34 +1002,36 @@ function buildWhereClause(opts, cb) {
     var log = opts.log;
     var o = opts.opts;
     var where = 'WHERE ';
+    var sort = '';
     var args = [];
     var sql;
 
     // Query only against fields with valid indices
     var b = opts.idxBucket;
 
+    function append(item) {
+        if (item.attribute) {
+            if (sort.length > 0) {
+                sort += ', ';
+            }
+            sort += item.attribute;
+            if (item.order) {
+                sort += ' ' + item.order;
+            }
+        }
+    }
+
     try {
         sql = compileQuery(b, f, args);
-        if (sql === '')
+        if (sql === '') {
             throw new InvalidQueryError(f.toString());
+        }
         where += sql;
 
         if (o.sort) {
             var sorts = Array.isArray(o.sort) ? o.sort : [ o.sort ];
 
             if (sorts.length > 0) {
-                var sort = '';
-                var append = function (item) {
-                    if (item.attribute) {
-                        if (sort.length > 0) {
-                            sort += ', ';
-                        }
-                        sort += item.attribute;
-                        if (item.order) {
-                            sort += ' ' + item.order;
-                        }
-                    }
-                };
                 sorts.forEach(function (item) {
                     if (item.attribute === EXTENDED_ID) {
                         /*
@@ -1066,8 +1081,10 @@ function buildWhereClause(opts, cb) {
         } else if (!o.noLimit) {
             where += ' LIMIT ' + 1000;
         }
-        if (o.offset)
+
+        if (o.offset) {
             where += ' OFFSET ' + o.offset;
+        }
 
         opts.where = {
             clause: where,
@@ -1087,8 +1104,9 @@ function cacheKey(b, k) {
     assert.string(b, 'bucket');
 
     var str = '/' + b;
-    if (k)
+    if (k) {
         str += '/' + k;
+    }
 
     return (str);
 }
@@ -1101,16 +1119,15 @@ function checkEtag(req, cb) {
     var k = req.key;
     var old = (req.previous || {})._etag;
 
-    //
-    // So the logic for etag checking below is as follows (assume 'etag' is
-    // caller-specified value):
-    //
-    // - if the etag is 'undefined', no-op, caller doesn't care (common)
-    // - if the etag is 'null', there must be no previous record
-    // - otherwise, the etag has to match the existing record (if there was
-    //   no existing record, that's an error)
-    //
-
+    /*
+     * The logic for etag checking below is as follows (assume 'etag' is
+     * caller-specified value):
+     *
+     * - if the etag is 'undefined', no-op, caller doesn't care (common)
+     * - if the etag is 'null', there must be no previous record
+     * - otherwise, the etag has to match the existing record (if there was
+     *   no existing record, that's an error)
+     */
     if (etag === undefined) {
         log.debug('checkEtag: etag undefined');
     } else if (etag === null) {
@@ -1246,7 +1263,6 @@ function checkExtendedId(req, callback) {
 
             setImmediate(next);
         });
-
     }, function (next) {
         if (!columnExists) {
             setImmediate(next);
@@ -1305,7 +1321,6 @@ function checkExtendedId(req, callback) {
 
             setImmediate(next);
         });
-
     } ], function (err) {
         log.debug({
             bucket: req.bucket.name,
@@ -1441,9 +1456,11 @@ function verifyBucket(req, cb) {
     var rowVer = parseInt(req.previous._rver || '0', 10);
     var bucketVer = parseInt(req.bucket.options.version, 10);
     if (rowVer > bucketVer) {
-        // The row we just fetched has a bucket version higher than what was
-        // retrieved from the bucket cache.  Shoot down the old entry and
-        // refetch so we can continue this action with a correct bucket schema.
+        /*
+         * The row we just fetched has a bucket version higher than what was
+         * retrieved from the bucket cache.  Shoot down the old entry and
+         * refetch so we can continue this action with a correct bucket schema.
+         */
         shootdownBucket(req);
         loadBucket(req, cb);
         return;
@@ -1588,8 +1605,10 @@ function rowToObject(bucket, ignore, row) {
 
 
 function runPostChain(req, cb) {
-    if (req.bucket.post.length === 0)
-        return (cb());
+    if (req.bucket.post.length === 0) {
+        cb();
+        return;
+    }
 
     var cookie = {
         bucket: req.bucket.name,
@@ -1600,7 +1619,7 @@ function runPostChain(req, cb) {
         schema: req.bucket.index,
         value: req.value,
         headers: req.opts.headers || {},
-        update: (req.previous) ? true : false
+        update: !!req.previous
     };
     var log = req.log;
 
@@ -1618,8 +1637,6 @@ function runPostChain(req, cb) {
             cb();
         }
     });
-
-    return (undefined);
 }
 
 
@@ -1650,8 +1667,9 @@ function selectForUpdate(req, cb) {
     });
 
     q.once('end', function (result) {
-        if (row)
+        if (row) {
             req.previous = row;
+        }
 
         log.debug({
             previous: req.previous || null
diff --git a/lib/objects/find.js b/lib/objects/find.js
index bd96019..0888d7d 100644
--- a/lib/objects/find.js
+++ b/lib/objects/find.js
@@ -171,8 +171,9 @@ function getRecords(req, cb) {
                           req.req_id, bucket, req.where.clause);
 
     if (req.opts.sql_only) {
-        if (!req.opts._sql)
+        if (!req.opts._sql) {
             req.opts._sql = {};
+        }
         req.opts._sql.query = sql;
         req.opts._sql.args = req.where.args;
         cb();
@@ -201,9 +202,11 @@ function getRecords(req, cb) {
             row: row
         }, 'getRecords: row found');
 
-        // MANTA-317: we need to check that the object actually matches
-        // the real filter, which requires us to do this janky stub out
-        // of _id and _mtime
+        /*
+         * MANTA-317: we need to check that the object actually matches
+         * the real filter, which requires us to do this janky stub out
+         * of _id and _mtime.
+         */
         var obj;
 
         try {
diff --git a/lib/objects/put.js b/lib/objects/put.js
index bba016e..02bdd2b 100644
--- a/lib/objects/put.js
+++ b/lib/objects/put.js
@@ -75,7 +75,7 @@ function runPreChain(req, cb) {
         schema: req.bucket.index,
         value: req.value,
         headers: req.headers || {},
-        update: (req.previous) ? true : false
+        update: !!req.previous
     };
     var log = req.log;
 
@@ -144,7 +144,6 @@ function getNextId(req, cb) {
         log.debug({id: req.value._txn_snap}, 'getNextId: done');
         cb();
     });
-
 }
 
 
diff --git a/lib/objects/reindex.js b/lib/objects/reindex.js
index 2cdc3a1..c68d7b6 100644
--- a/lib/objects/reindex.js
+++ b/lib/objects/reindex.js
@@ -125,9 +125,11 @@ function processRows(req, cb) {
         });
     }
 
-    // There is no backpressure on rows being returned from the SELECT
-    // statement so heap consumption my be extreme if an unreasonable page size
-    // is chosen.
+    /*
+     * There is no backpressure on rows being returned from the SELECT
+     * statement so heap consumption may be extreme if an unreasonable page
+     * size is chosen.
+     */
     var result = req.pg.query(sql);
     var queue = vasync.queue(indexObject, 1);
 
@@ -185,8 +187,10 @@ function recordStatus(req, cb) {
         });
         q.on('end', function () {
             log.debug('recordStatus: done');
-            // Shoot down the bucketCache entry now that new columns are
-            // potentially available for filter use.
+            /*
+             * Shoot down the bucketCache entry now that new columns are
+             * potentially available for filter use.
+             */
             common.shootdownBucket(req);
             cb(null);
         });
diff --git a/lib/objects/update.js b/lib/objects/update.js
index 9ff7604..f0cdb18 100644
--- a/lib/objects/update.js
+++ b/lib/objects/update.js
@@ -49,7 +49,7 @@ var SUBPIPELINE = PIPELINE.slice(1);
 function updateRows(req, cb) {
     var args;
     var b = req.bucket;
-    var column  = '';
+    var column = '';
     var etag = 'u' + libuuid.create().substr(0, 7);
     var i, k;
     var log = req.log;
diff --git a/lib/pg.js b/lib/pg.js
index 0bca822..79f9b8c 100644
--- a/lib/pg.js
+++ b/lib/pg.js
@@ -128,8 +128,9 @@ function PGClient(options) {
     assert.object(options.pool, 'options.pool');
     assert.number(options.queryTimeout, 'options.queryTimeout');
 
-    if (++CLIENT_ID >= 4294967295) // 2^32 -1
+    if (++CLIENT_ID >= 4294967295) { // 2^32 -1
         CLIENT_ID = 1;
+    }
 
     this.client = options.client;
     this.client.on('error', this._handleClientError.bind(this));
@@ -784,8 +785,9 @@ PGPool.prototype.close = function close(cb) {
     self._deadbeef = true;
 
     self.log.trace({pool: self.pool}, 'close: closed');
-    if (typeof (cb) === 'function')
+    if (typeof (cb) === 'function') {
         cb();
+    }
 
     self.emit('close');
 };
diff --git a/lib/ping.js b/lib/ping.js
index facba05..d1ecf63 100644
--- a/lib/ping.js
+++ b/lib/ping.js
@@ -93,7 +93,6 @@ function ping(options) {
                 });
             });
         });
-
     }
 
     return (_ping);
diff --git a/package.json b/package.json
index cf8f812..4925370 100644
--- a/package.json
+++ b/package.json
@@ -10,7 +10,7 @@
         "artedi": "1.3.0",
         "assert-plus": "1.0.0",
         "bunyan": "1.8.10",
-        "bunyan-syslog": "0.2.2",
+        "bunyan-syslog": "~0.3.2",
         "clone": "0.1.11",
         "crc": "0.2.1",
         "cueball": "~2.7.1",
@@ -24,11 +24,11 @@
         "kang": "1.2.0",
         "macaddr": "0.0.1",
         "moray-filter": "1.0.0",
-        "libuuid": "0.1.3",
+        "libuuid": "0.2.1",
         "lru-cache": "2.5.0",
         "node-manatee": "git+https://github.com/joyent/node-manatee.git#262828a8",
         "moray": "3.1.1",
-        "microtime": "0.5.1",
+        "microtime": "2.1.6",
         "once": "1.3.0",
         "pg": "6.2.4",
         "pg-parse-float": "0.0.1",
@@ -38,8 +38,8 @@
         "verror": "1.9.0"
     },
     "devDependencies": {
-        "eslint": "2.13.1",
-        "eslint-plugin-joyent": "1.3.0"
+        "eslint": "^4.13.1",
+        "eslint-plugin-joyent": "~2.1.0"
     },
     "sdcDependencies": {
         "config-agent": ">=1.2.0"
-- 
2.21.0

