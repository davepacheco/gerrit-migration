commit 3401d76450203a0b2d63db7e783fffa7cec00002
Author: Russell Brown <russell.brown@joyent.com>
Date:   2019-06-27T11:45:07+01:00 (3 months ago)
    
    MANTA-3525 Muppet should handle haproxy config changes without restarting haproxy
    Reviewed by: John Levon <john.levon@joyent.com>

diff --git a/.gitmodules b/.gitmodules
index 61d8a53..1efbbbf 100644
--- a/.gitmodules
+++ b/.gitmodules
@@ -10,10 +10,10 @@
 [submodule "deps/manta-scripts"]
 	path = deps/manta-scripts
 	url = https://github.com/joyent/manta-scripts.git
-[submodule "deps/haproxy-1.5"]
-	path = deps/haproxy-1.5
-	url = https://github.com/joyent/haproxy-1.5.git
-	branch = joyent/v1.5.19
+[submodule "deps/haproxy-1.8"]
+	path = deps/haproxy-1.8
+	url = https://github.com/joyent/haproxy-1.8.git
+	branch = dev-v1.8.20
 [submodule "deps/eng"]
 	path = deps/eng
 	url = https://github.com/joyent/eng.git
diff --git a/README.md b/README.md
index e31fb65..9c62986 100644
--- a/README.md
+++ b/README.md
@@ -5,7 +5,7 @@
 -->
 
 <!--
-    Copyright (c) 2014, Joyent, Inc.
+    Copyright 2019 Joyent, Inc.
 -->
 
 # muppet
@@ -26,17 +26,4 @@ Run `make prepush` before commits; otherwise, follow the
 
 # Testing
 
-## Prerequisites
-
-To properly run the muppet tests, the following package must be installed from
-pkgsrc:
-
-- haproxy
-
-Though the version of haproxy might differ from the running `loadbalancer` zone,
-it is simply used to check that haproxy can properly parse the resulting
-`haproxy.cfg` files generated in the tests.
-
-## Running the Tests
-
-Then to run the tests, simply run `make test`
+Run `make test`. The locally built haproxy is used as part of these tests.
diff --git a/deps/eng b/deps/eng
index 126c0f0..ed10150 160000
--- a/deps/eng
+++ b/deps/eng
@@ -1 +1 @@
-Subproject commit 126c0f032b8bfddd45b14e8ee14e73e9798a013f
+Subproject commit ed10150657b1f3ae4f061c751daf365ed16ca8d5
diff --git a/deps/haproxy-1.5 b/deps/haproxy-1.5
deleted file mode 160000
index 836df3b..0000000
--- a/deps/haproxy-1.5
+++ /dev/null
@@ -1 +0,0 @@
-Subproject commit 836df3bc832e572c42e2618fcb1a10a81d63df3c
diff --git a/deps/haproxy-1.8 b/deps/haproxy-1.8
new file mode 160000
index 0000000..9cf79e3
--- /dev/null
+++ b/deps/haproxy-1.8
@@ -0,0 +1 @@
+Subproject commit 9cf79e3538a33807d0b9f088db15afd46a395627
diff --git a/docs/index.md b/docs/index.md
index 86a7876..62f3105 100644
--- a/docs/index.md
+++ b/docs/index.md
@@ -10,7 +10,7 @@ apisections:
 -->
 
 <!--
-    Copyright (c) 2014, Joyent, Inc.
+    Copyright 2019 Joyent, Inc.
 -->
 
 # tl;dr
@@ -27,9 +27,9 @@ can create a loadbalancer configuration (see below) that fronts your backend
 servers.
 
 In manta at least, all configuration of the load balancer is automatically
-managed by the muppet service, which watches for registrar changes in
-ZooKeeper.  This simply updates the upstream server list of IP addresses
-and restarts the loadbalancer service (not gracefully...).
+managed by the muppet service, which watches for registrar changes in ZooKeeper.
+This updates the upstream server list of IP addresses and refreshes the haproxy
+loadbalancer service.
 
 # Configuration
 
@@ -170,18 +170,18 @@ Run this command:
 
 ## Load Balancer
 
-The loadbalancer used is just [HAProxy](http://haproxy.1wt.eu/), but with a
-[patch from openwrt](https://dev.openwrt.org/) that lets us get the "real"
-client IP address into the `x-forwarded-for` header.  There is an
-`haproxy.cfg.in` file that is templated with a sparse number of `%s`; this
-file is used to generate a new haproxy.cfg each time the topology of online
-loadbalancers changes.
-
-*Important:* Checked into this repo is a "blank" haproxy.cfg - *DO NOT EDIT
-THIS FILE!*.  That file is used as a syntactically correct, but empty
-haproxy.cfg file that we use to bootstrap haproxy _before_ muppet is running.
-Any changes you want to see made to haproxy.cfg must be made in the template
-file, as that's what you really care about.
+The loadbalancer used is [HAProxy](http://www.haproxy.org/), but a [fork
+maintained by Joyent](https://github.com/joyent/haproxy-1.8), with a patch to
+use Event Ports. There is an `haproxy.cfg.in` file that is templated with a
+sparse number of `%s`; this file is used to generate a new haproxy.cfg each time
+the topology of online loadbalancers changes.
+
+*Important:* Checked into this repo is a "blank" haproxy.cfg.default - *DO NOT
+EDIT THIS FILE!*, except in the case you need the default behaviour to change.
+That file is used as a syntactically correct, but empty haproxy.cfg file that we
+use to bootstrap haproxy _before_ muppet is running.  Any changes you want to
+see made to haproxy.cfg must be made in the template file, as that's what you
+really care about.
 
 ## Muppet
 
diff --git a/etc/haproxy.cfg.default b/etc/haproxy.cfg.default
index 531309a..ba26d08 100644
--- a/etc/haproxy.cfg.default
+++ b/etc/haproxy.cfg.default
@@ -1,11 +1,17 @@
 global
+        # have haproxy launch a worker process, SMF monitors the master, part of
+        # seamless config reload (via SMF refresh method)
+        master-worker
+	# maximum of 10 kept-open child processes after reload
+	max-old-workers 10
         log 127.0.0.1 local0
         user nobody
         group nobody
         daemon
         maxconn 65535
         pidfile /var/run/haproxy.pid
-        stats socket /tmp/haproxy mode 0600 level admin
+        # expose-fd listeners also required for seamless config reload
+        stats socket /tmp/haproxy mode 0600 level admin expose-fd listeners
 
 defaults
         balance leastconn
diff --git a/etc/haproxy.cfg.in b/etc/haproxy.cfg.in
index 879c30f..1056359 100644
--- a/etc/haproxy.cfg.in
+++ b/etc/haproxy.cfg.in
@@ -1,4 +1,9 @@
 global
+        # have haproxy launch a worker process, SMF monitors the master, part of
+        # seamless config reload (via SMF refresh method)
+        master-worker
+	# maximum of 10 kept-open child processes after reload
+	max-old-workers 10
         log 127.0.0.1 local0
         user nobody
         group nobody
@@ -6,7 +11,8 @@ global
         maxconn 65535
         pidfile /var/run/haproxy.pid
         log-send-hostname %s
-        stats socket /tmp/haproxy mode 0600 level admin
+        # expose-fd listeners also required for seamless config reload
+        stats socket /tmp/haproxy mode 0600 level admin expose-fd listeners
 
 
 defaults
diff --git a/lib/app.js b/lib/app.js
new file mode 100644
index 0000000..8a95ca6
--- /dev/null
+++ b/lib/app.js
@@ -0,0 +1,205 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019 Joyent, Inc.
+ */
+
+/*jsl:ignore*/
+'use strict';
+/*jsl:end*/
+
+const mod_fs = require('fs');
+const mod_assert = require('assert-plus');
+const mod_forkexec = require('forkexec');
+const mod_net = require('net');
+const mod_util = require('util');
+const mod_zkstream = require('zkstream');
+const mod_vasync = require('vasync');
+const VError = require('verror');
+const FSM = require('mooremachine').FSM;
+
+const lib_lbman = require('./lb_manager');
+const lib_watch = require('./watch');
+
+function domainToPath(domain) {
+    return ('/' + domain.split('.').reverse().join('/'));
+}
+
+const MDATA_TIMEOUT = 30000;
+const SETUP_RETRY_TIMEOUT = 30000;
+
+function AppFSM(cfg) {
+    this.a_log = cfg.log;
+
+    this.a_adminIPs = cfg.adminIPS;
+    this.a_mantaIPs = cfg.mantaIPS;
+    this.a_trustedIP = cfg.trustedIP;
+    this.a_untrustedIPs = [];
+    if (cfg.hasOwnProperty('untrustedIPs'))
+        this.a_untrustedIPs = cfg.untrustedIPs;
+    this.a_zkCfg = cfg.zookeeper;
+    this.a_name = cfg.name;
+    this.a_path = domainToPath(cfg.name);
+    this.a_lastError = null;
+
+    this.a_reloadCmd = cfg.reload;
+
+    FSM.call(this, 'getips');
+}
+mod_util.inherits(AppFSM, FSM);
+
+/*
+ * Uses mdata-get or our configuration JSON to figure out which of our NIC IP
+ * addresses are "untrusted" or "public" -- where we should be listening for
+ * connections.
+ */
+AppFSM.prototype.state_getips = function (S) {
+    var self = this;
+    var log = this.a_log;
+    // Allow hardcoding addresses in the configuration.
+    if (this.a_untrustedIPs.length > 0) {
+        S.gotoState('zksetup');
+        return;
+    }
+
+    const args = [ '/usr/sbin/mdata-get', 'sdc:nics' ];
+    log.info({ cmd: args }, 'Loading NIC information');
+    mod_forkexec.forkExecWait({
+        argv: args
+    }, S.callback(function (err, info) {
+        if (err) {
+            self.a_lastError = new VError(err,
+                'failed to load NIC information');
+            S.gotoState('setuperr');
+            return;
+        }
+
+        const nics = JSON.parse(info.stdout);
+        mod_assert.array(nics, 'nics');
+
+        function _pushIP(ip) {
+            /* If this is an admin, manta, or other trusted IP, skip it. */
+            if ((self.a_adminIPs && self.a_adminIPs.indexOf(ip) !== -1) ||
+                (self.a_mantaIPs && self.a_mantaIPs.indexOf(ip) !== -1) ||
+                ip === self.a_trustedIP)  {
+
+                return;
+            }
+
+            if (!mod_net.isIPv4(ip) && !mod_net.isIPv6(ip)) {
+                log.warn('invalid IP found in NIC information: "%s"', ip);
+                return;
+            }
+
+            self.a_untrustedIPs.push(ip);
+        }
+
+        function _addIPsFromNics(nic) {
+            if (nic.hasOwnProperty('ips')) {
+                nic.ips.forEach(function parseIP(addr) {
+                    _pushIP(addr.split('/')[0]);
+                });
+            } else if (nic.hasOwnProperty('ip')) {
+                _pushIP(nic.ip);
+            } else {
+                log.warn({ nic: nic }, 'NIC has no IP addresses');
+            }
+        }
+
+        nics.forEach(_addIPsFromNics);
+
+        log.info({ ips: self.a_untrustedIPs },
+            'selected IPs for untrusted networks');
+
+        S.gotoState('zksetup');
+    }));
+    S.timeout(MDATA_TIMEOUT, function () {
+        this.a_lastError = new Error('Timeout waiting for mdata-get exec');
+        S.gotoState('setuperror');
+    });
+};
+
+/* Sleeps and restarts the entire setup process. */
+AppFSM.prototype.state_setuperror = function (S) {
+    this.a_log.error(this.a_lastError, 'muppet startup failed: retry in 30sec');
+    S.gotoStateTimeout(SETUP_RETRY_TIMEOUT, 'getips');
+};
+
+AppFSM.prototype.state_zksetup = function (S) {
+    var opts = {
+        servers: [],
+        log: this.a_log,
+        sessionTimeout: this.a_zkCfg.timeout
+    };
+
+    this.a_zkCfg.servers.forEach(function (s) {
+        // Support old zk-plus (host) or new zkstream (address) configs
+        var _host = s.address || s.host;
+        opts.servers.push({ address: _host, port: s.port });
+    });
+
+    this.a_log.debug({
+        servers: opts.servers,
+        timeout: opts.sessionTimeout
+    }, 'Creating ZooKeeper client');
+
+    this.a_zk = new mod_zkstream.Client(opts);
+    this.a_nsf = new lib_watch.HostWatcherFSM({
+        zk: this.a_zk,
+        path: this.a_path,
+        log: this.a_log
+    });
+
+    S.on(this.a_zk, 'session', function () {
+        S.gotoState('watch');
+    });
+};
+
+/*
+ * We enter this state whenever we get a new ZK session, to create a new watcher
+ * and then move to 'running' to resume normal operation.
+ */
+AppFSM.prototype.state_watch = function (S) {
+    this.a_watcher = this.a_zk.watcher(this.a_path);
+    S.gotoState('running');
+};
+
+AppFSM.prototype.state_running = function (S) {
+    var self = this;
+    var log = this.a_log;
+
+    S.on(this.a_watcher, 'childrenChanged', function (kids) {
+        log.debug({ kids: kids }, 'childrenChanged fired');
+        self.a_nsf.childrenChanged(kids);
+    });
+
+    S.on(this.a_nsf, 'hostsChanged', function (hosts) {
+        const opts = {
+            trustedIP: self.a_trustedIP,
+            untrustedIPs: self.a_untrustedIPs,
+            hosts: hosts,
+            log: self.a_log.child({component: 'lb_manager'}),
+            reload: self.a_reloadCmd
+        };
+        log.trace({ hosts: hosts }, 'going to reload lb config');
+        lib_lbman.reload(opts, function (err) {
+            if (err) {
+                log.error(err, 'lb reload failed');
+                return;
+            }
+            log.info({ hosts: hosts }, 'lb config reloaded');
+        });
+    });
+
+    S.on(this.a_zk, 'session', function () {
+        S.gotoState('watch');
+    });
+};
+
+module.exports = {
+    AppFSM: AppFSM
+};
diff --git a/lib/index.js b/lib/index.js
index 16dcc09..82c528c 100644
--- a/lib/index.js
+++ b/lib/index.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 
 const lbm = require('./lb_manager');
@@ -19,5 +19,5 @@ module.exports = {
         return (new Watch(options));
     },
     createZKClient: zkm.createZKClient,
-    restartLB: lbm.restart
+    reloadLB: lbm.reload
 };
diff --git a/lib/lb_manager.js b/lib/lb_manager.js
index f3f855b..26812f6 100644
--- a/lib/lb_manager.js
+++ b/lib/lb_manager.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 
 /*jsl:ignore*/
@@ -21,19 +21,17 @@ const sprintf = require('util').format;
 
 const assert = require('assert-plus');
 const once = require('once');
-const backoff = require('backoff');
 const vasync = require('vasync');
 const jsprim = require('jsprim');
 
-
-
 ///--- Globals
 
 const CFG_FILE = path.resolve(__dirname, '../etc/haproxy.cfg');
 const CFG_FILE_TMP = path.resolve(__dirname, '../etc/haproxy.cfg.tmp');
 const CFG_IN = fs.readFileSync(path.resolve(__dirname, '../etc/haproxy.cfg.in'),
                              'utf8');
-const RESTART = '/usr/sbin/svcadm restart haproxy';
+const HAPROXY_FMRI = 'svc:/manta/haproxy:default';
+const RELOAD = '/usr/sbin/svcadm refresh ' + HAPROXY_FMRI;
 /* JSSTYLED */
 const CLEAR_SERVER_LINE = '        server be%d %s:81 check inter 30s slowstart 10s\n';
 /* JSSTYLED */
@@ -43,12 +41,13 @@ const INSECURE_FRONTEND =
 const INSECURE_BIND_LINE = '        bind %s:80\n';
 
 // Locks for single reset run
-var RESTART_RUNNING = false;
-var RESTART_NEEDS_RUN = false;
+var RELOAD_RUNNING = false;
+var RELOAD_NEEDS_RUN = false;
+
+// Storage for objects we might lose if we block on a reload lock
+var RELOAD_OPTS = {};
+var RELOAD_CB = null;
 
-// Storage for objects we might lose if we block on a restart lock
-var RESTART_OPTS = {};
-var RESTART_CB = null;
 
 /*
  * Generate a haproxy configuration file using the provided parameters
@@ -106,50 +105,56 @@ function writeHaproxyConfig(opts, cb) {
     return (fs.writeFile(configOut, str, 'utf8', cb));
 }
 
-
-function restartHaproxy(opts, cb) {
+/*
+ * Note: is just "fire and forget" of the opts.reload command (default
+ * is `svcadm refresh`). Assumes that the full config validation code
+ * has been run first, i.e. expected to be called as part of the
+ * exported reload/0 function
+ *
+ * reload works by calling refresh which works like this:
+ * - only the master process will take the signal
+ * - it'll keep running, so SMF is happy
+ * - master will start a new worker with the new config, and pass
+ *   along the listening sockets
+ * - a configured maximum number of old instances may hang around for
+ *   already open connections
+ */
+function reloadHaproxy(opts, cb) {
     assert.object(opts.log, 'options.log');
-    assert.optionalString(opts.restart, 'options.restart');
-
-    const _restart = opts.restart || RESTART;
-    opts.log.debug('Restarting haproxy with: %s...', _restart);
-
-    const retry = backoff.call(exec, _restart, cb);
-    retry.failAfter(3);
-    retry.setStrategy(new backoff.ExponentialStrategy({
-        initialDelay: 1000
-    }));
-    retry.on('backoff', function (number, delay, err) {
-        opts.log.debug({
-            attempt: number,
-            delay: delay,
-            err: err
-        }, 'Haproxy restart attempted');
-    });
-    retry.start();
+    assert.optionalString(opts.reload, 'options.reload');
+
+    const _reload = opts.reload || RELOAD;
+    opts.log.debug('Reloading haproxy config with: %s...', _reload);
+
+    exec(_reload, cb);
 }
 
 /*
- * Gets the haproxy executable path that is used in SMF so that
- * we aren't hard-coding the haproxy path in two separate spots
- *
+ * Gets the haproxy executable path from  SMF.
  */
 function getHaproxyExec(opts, cb) {
     assert.object(opts.log, 'options.log');
+    assert.optionalString(opts.haproxyExec, 'opts.haproxyExec');
     assert.func(cb, 'callback');
+
+    if (opts.haproxyExec !== undefined) {
+        cb(null, opts.haproxyExec);
+        return;
+    }
+
     // svcprop returns something like:
     //    /opt/local/sbin/haproxy\ -f\ %{config_file}\ -D
-    execFile('/usr/bin/svcprop', ['-p', 'start/exec', 'haproxy' ],
+    execFile('/usr/bin/svcprop', ['-p', 'start/exec', HAPROXY_FMRI ],
         function (error, stdout, _stderr) {
             var haproxy_exec = null;
             if (error !== null) {
                 opts.log.error(error, 'failed to find haproxy exec path');
                 return (cb(error));
             } else {
-                // svccfg line returned, parse out the haproxy path
-                const m = stdout.match(/[\w/]+haproxy/);
+                // svcprop line returned, parse out the haproxy path
+                const m = stdout.match(/(^.*?\/haproxy)\\{1}/);
                 if (m !== null) {
-                    haproxy_exec = m[0];
+                    haproxy_exec = m[1];
                 } else {
                     opts.log.error('Error finding haproxy exec path in %s',
                                    stdout);
@@ -227,16 +232,16 @@ function checkHaproxyConfig(opts, cb) {
 
 /*
  * Regenerate the configuration file using the provided parameters, and then
- * restart HAProxy so that it picks it up.
+ * reload HAProxy configuration.
  *
  * Options:
  * - trustedIP, an address on the Manta network that is considered preauthorized
  * - untrustedIPs, an array of addresses that untrusted traffic comes in over
  * - hosts, an array of Muskie backends to forward requests to
- * - restart (optional), the command to run to restart HAProxy
+ * - reload (optional), the command to run to reload HAProxy config
  * - log, a Bunyan logger
  */
-function restart(opts, cb) {
+function reload(opts, cb) {
     assert.object(opts, 'options');
     assert.string(opts.trustedIP, 'options.trustedIP');
     assert.arrayOfString(opts.untrustedIPs, 'options.untrustedIPs');
@@ -244,45 +249,45 @@ function restart(opts, cb) {
     assert.object(opts.log, 'options.log');
     assert.func(cb, 'callback');
     // For testing
-    assert.optionalString(opts.restart, 'options.restart');
+    assert.optionalString(opts.reload, 'options.reload');
     assert.optionalString(opts.configFileIn, 'options.configFileIn');
 
     /*
-     * Wrap restart logic in a cheap & simple lock to ensure we are not writing
-     * a new temp config file while renaming the temp config file in a previous
-     * restart cycle. In addition, save the options from the queued restart().
-     * If the most diabolical timing issue happened where multiple restart()'s
-     * got queued, we'd only care about at most two (the current,
-     * and the last one queued).
+     * Wrap config reload logic in a cheap & simple lock to ensure we are not
+     * writing a new temp config file while renaming the temp config file in a
+     * previous cycle. In addition, save the options from the queued reload().
+     * If the most diabolical timing issue happened where multiple reload()'s
+     * got queued, we'd only care about at most two (the current, and the last
+     * one queued).
      */
     /*
-     * TODO: If a third restart() call happened, and a delay
+     * TODO: If a third reload() call happened, and a delay
      * happened to the first and second call, the second call's
      * callback would get lost since we only save/restore the
-     * one queued restart. This will be filed in a separate
+     * one queued reload. This will be filed in a separate
      * issue. This issue however is an extremely unlikely event
      * considering the speed in which we get ZK notifications.
      */
-    if (RESTART_RUNNING) {
-        opts.log.debug('Restart is already running, queueing restart...');
-        opts.log.debug('Hosts we are saving for queued restart: %s',
+    if (RELOAD_RUNNING) {
+        opts.log.debug('Config reload is already running, queueing reload...');
+        opts.log.debug('Hosts we are saving for queued reload: %s',
             opts.hosts);
-        RESTART_OPTS = jsprim.deepCopy(opts);
-        RESTART_CB = jsprim.deepCopy(cb);
-        RESTART_NEEDS_RUN = true;
+        RELOAD_OPTS = jsprim.deepCopy(opts);
+        RELOAD_CB = jsprim.deepCopy(cb);
+        RELOAD_NEEDS_RUN = true;
         return;
     }
-    RESTART_RUNNING = true;
+    RELOAD_RUNNING = true;
 
     cb = once(cb);
 
     /*
      * Kick off the checkConfig -> writeHaproxyConfig ->
-     *   restartHaproxy pipeline
+     *   reloadHaproxy pipeline
      * - Generate a temporary config file with writeHaproxyConfig.
      * - Check the temporary config with checkHaproxyConfig
      * - Rename temporary file to final file once check passes
-     * - Restart haproxy with a known-good config file
+     * - Tell haproxy to reload with a known-good config file
      */
     var tmpOpts = jsprim.deepCopy(opts);
     tmpOpts.configFileOut = CFG_FILE_TMP;
@@ -292,8 +297,8 @@ function restart(opts, cb) {
         checkHaproxyConfig,
         function finalRenameConfig(_, callback) {
             renameHaproxyConfig({log: opts.log}, callback); },
-        function finalRestart(_, callback) {
-            restartHaproxy(opts, callback); }
+        function finalReload(_, callback) {
+            reloadHaproxy(opts, callback); }
     ]}, function (err) {
         if (err) {
             opts.log.error(err, 'Error reconfiguring haproxy');
@@ -303,25 +308,22 @@ function restart(opts, cb) {
         }
 
         // Clear the lock now that we are finished
-        RESTART_RUNNING = false;
-        // Call a restart if one is pending
-        if (RESTART_NEEDS_RUN) {
-            RESTART_NEEDS_RUN = false;
-            opts.log.debug('Calling queued restart, using saved hosts: %s',
-                          RESTART_OPTS.hosts);
-            restart(RESTART_OPTS, RESTART_CB);
+        RELOAD_RUNNING = false;
+        // Call a reload if one is pending
+        if (RELOAD_NEEDS_RUN) {
+            RELOAD_NEEDS_RUN = false;
+            opts.log.debug('Calling queued reload, using saved hosts: %s',
+                          RELOAD_OPTS.hosts);
+            reload(RELOAD_OPTS, RELOAD_CB);
         }
     });
 }
 
-
-
 ///--- Exports
 
 module.exports = {
-    restart: restart,
+    reload: reload,
     // Below only exported for testing
     checkHaproxyConfig: checkHaproxyConfig,
-    writeHaproxyConfig: writeHaproxyConfig,
-    getHaproxyExec: getHaproxyExec
+    writeHaproxyConfig: writeHaproxyConfig
 };
diff --git a/lib/watch.js b/lib/watch.js
index 0085aaf..d31ea90 100644
--- a/lib/watch.js
+++ b/lib/watch.js
@@ -5,298 +5,466 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 
 /*jsl:ignore*/
 'use strict';
 /*jsl:end*/
 
-const EventEmitter = require('events').EventEmitter;
-const util = require('util');
-const assert = require('assert-plus');
-const once = require('once');
-const vasync = require('vasync');
-const verror = require('verror');
-const jsprim = require('jsprim');
+const mod_fs = require('fs');
+const mod_assert = require('assert-plus');
+const mod_forkexec = require('forkexec');
+const mod_net = require('net');
+const mod_util = require('util');
+const mod_zkstream = require('zkstream');
+const mod_vasync = require('vasync');
+const VError = require('verror');
+const FSM = require('mooremachine').FSM;
 
+/*
+ * Timing parameters for our heuristic rules below (see the FSM state diagram
+ * and explanation above HostWatcherFSM).
+ */
+const COLLECTION_TIMEOUT = 15000;   /* ms */
+const HOLD_TIME = 30000;            /* ms */
+const REMOVAL_THROTTLE = 0.2;       /* 0.2 = 20% */
+const RETRY_TIMEOUT = 15000;        /* ms */
+const FETCH_CONCURRENCY = 4;
 
-///--- Globals
+/* Debugging: how many previous diffs to keep in memory */
+const HISTORY_LENGTH = 32;
 
-const sprintf = util.format;
+/*
+ * We add Math.random() * SMEAR to most of the timeouts listed above to "smear"
+ * them out a bit and randomize the load we put on zookeeper. This is meant to
+ * keep lots of muppet processes from hammering it all at once.
+ */
+const SMEAR = 5000;                 /* ms */
 
-///--- Private Functions
 
-// Turns something like manta.machine.joyent.com into com/joyent/machine/manta
-function domainToPath(domain) {
-    return ('/' + domain.split('.').reverse().join('/'));
+function diffSets(list1, list2) {
+    var idx1 = {};
+    var idx2 = {};
+    var out = { added: [], removed: [] };
+    list1.forEach(function (val) {
+        idx1[val] = true;
+    });
+    list2.forEach(function (val) {
+        if (idx1[val] !== true)
+            out.added.push(val);
+        idx2[val] = true;
+    });
+    list1.forEach(function (val) {
+        if (idx2[val] !== true)
+            out.removed.push(val);
+    });
+    return (out);
 }
 
+/*
+ * The HostWatcherFSM manages turning the childrenChanged watch events into
+ * a list of hosts, emitted whenever we should restart haproxy.
+ *
+ * It uses a couple of rules/heuristics to control this list and the timing
+ * of restarts to avoid causing unnecessary churn and outages.
+ *
+ * In particular:
+ *
+ *   - All changes to the backend list are "collected"/spooled for
+ *     COLLECTION_TIMEOUT milliseconds before being applied (this happens
+ *     in FSM state 'collecting'). This has a few goals:
+ *       1. Don't react to short transient glitches where a registrar loses
+ *          its session but immediately re-registers
+ *       2. Only restart once when a whole lot of backends come online at
+ *          the same time
+ *
+ *   - Removals from the backend list are throttled, first by time -- we ignore
+ *     any removal for HOLD_TIME milliseconds and only actually remove it from
+ *     our backends list once that much time has elapsed (plus/minus the
+ *     collection timeout). This is double insurance against transient glitches.
+ *
+ *   - Removals are also throttled by percentage of backend set removed -- if
+ *     a fraction of the current list greater than REMOVAL_THROTTLE are removed
+ *     at once, we only obey up to that fraction in any one restart, and we
+ *     wait HOLD_TIME before looking again. This protects us against DC-wide
+ *     ZK glitches where everything gets cut-off and has to re-register.
+ *
+ *
+ *                  +
+ *                  |
+ *                  |
+ *                  |
+ *   ...            v
+ *   &&
+ *   throttle  +----------+
+ *   or HOLD   |          |
+ *  +--------> |   idle   |
+ *  |          |          |
+ *  |          +-+------+-+
+ *  |            |      |
+ *  |            |      |
+ *  |            |      |
+ *  |       host |      | childrenChanged
+ *  |     expiry |      | && diff >0
+ *  | (HOLD_TIME)|      |
+ *  |            |      |
+ *  |            v      v
+ *  |
+ *  |         +------------+
+ *  |         |            |
+ *  +-------> | collecting |
+ *  | ...     |            |
+ *  | &&      +-----+------+
+ *  | childrenCh.   |
+ *  |               |
+ *  |               | timeout
+ *  |               | (COLLECTION_TIMEOUT)
+ *  |               |
+ *  |               v
+ *  |
+ *  |          +---------+
+ *  |          |         |
+ *  |          |  fetch  | <---------------+ timeout
+ *  |          |         |                 | (RETRY_TIMEOUT)
+ *  |          +--+---+--+                 |
+ *  |             |   |                    | zk 'connect'
+ *  |   got hosts |   | error              |
+ *  |          ok |   |                    |
+ *  |      && ... |   |               +----+----+
+ *  |             |   |               |         |
+ *  +-------------+   +-------------> |  retry  |
+ *                                    |         |
+ *                                    +---------+
+ */
+function HostWatcherFSM(opts) {
+    this.hw_zk = opts.zk;
+    this.hw_path = opts.path;
+    this.hw_log = opts.log;
+
+    this.hw_lastSeen = {};
+    this.hw_lastHosts = [];
+    this.hw_lastKids = [];
+    this.hw_kids = [];
+    this.hw_history = [];
+    this.hw_hostHistory = [];
+    this.hw_nextExpiry = null;
+
+    this.hw_lastError = null;
+
+    FSM.call(this, 'idle');
+}
+mod_util.inherits(HostWatcherFSM, FSM);
 
-///--- API
-function Watch(options) {
-    assert.object(options);
-    assert.string(options.domain);
-    assert.object(options.log);
-    assert.object(options.zk);
+HostWatcherFSM.prototype.childrenChanged = function (kids) {
+    this.emit('childrenChangedAsserted', kids);
+};
 
-    EventEmitter.call(this);
+HostWatcherFSM.prototype._newDiff = function (diff) {
+    this.hw_history.push({ time: new Date(), diff: diff });
+    while (this.hw_history.length > HISTORY_LENGTH)
+        this.hw_history.shift();
+};
 
-    this.hosts = [];
-    this.log = options.log.child({clazz: 'Watch'}, true);
-    this.path = domainToPath(options.domain);
-    this.zk = options.zk;
-}
-util.inherits(Watch, EventEmitter);
+HostWatcherFSM.prototype._newHostDiff = function (diff) {
+    this.hw_hostHistory.push({ time: new Date(), diff: diff });
+    while (this.hw_hostHistory.length > HISTORY_LENGTH)
+        this.hw_hostHistory.shift();
+};
 
-Watch.prototype.start = function start(callback) {
-    callback = once(callback);
+HostWatcherFSM.prototype.state_idle = function (S) {
+    var self = this;
+    var now = Date.now();
+    /*
+     * hw_nextExpiry would have been set last time we finished "fetch", only
+     * if we ran into something that needs to expire (e.g. a HOLD_TIME
+     * or REMOVAL_THROTTLE violation). If we don't run into either of those
+     * it should have been set to null.
+     */
+    if (this.hw_nextExpiry !== null) {
+        var delta = (this.hw_nextExpiry - now);
+        if (delta > 0) {
+            S.timeout(delta, function () {
+                self.hw_log.info('expiry timeout reached (hold time/throttle)');
+                S.gotoState('collecting');
+            });
+        } else {
+            S.gotoState('collecting');
+            return;
+        }
+    }
+    /*
+     * Other than through expiry, we only leave this state if the set of child
+     * nodes in ZK changes.
+     */
+    S.on(this, 'childrenChangedAsserted', function (kids) {
+        var diff = diffSets(self.hw_lastKids, kids);
+        if (diff.added.length > 0 || diff.removed.length > 0) {
+            self.hw_log.info('received change notification from ZK');
+            self._newDiff(diff);
+            self.hw_kids = kids;
+            S.gotoState('collecting');
+        }
+    });
+};
+
+HostWatcherFSM.prototype.state_collecting = function (S) {
+    var self = this;
+    this.hw_nextExpiry = null;
+    var timeout = Math.round(COLLECTION_TIMEOUT + Math.random() * SMEAR);
+    this.hw_log.info('collecting diff for %d sec...',
+        timeout / 1000);
+    /*
+     * Keep collecting any further changes to the child nodes, but don't
+     * transition until COLLECTION_TIMEOUT elapses.
+     */
+    S.on(this, 'childrenChangedAsserted', function (kids) {
+        var diff = diffSets(self.hw_kids, kids);
+        if (diff.added.length > 0 || diff.removed.length > 0) {
+            self._newDiff(diff);
+            self.hw_kids = kids;
+        }
+    });
+    S.gotoStateTimeout(timeout, 'fetch');
+};
 
-    const log = this.log;
-    const zk = this.zk;
+HostWatcherFSM.prototype.state_fetch = function (S) {
     var self = this;
-    var tasks = [];
+    var zk = this.hw_zk;
+    var log = this.hw_log;
 
-    log.debug({
-        path: self.path
-    }, 'start: entered');
+    /* Save the set of kids we're going to fetch now. */
+    var kids = this.hw_kids;
 
     /*
-     * Setup tasks we need to accomplish on start
-     *  mkdirp - for ensuring the path in ZK exists
-     *  watch - for creating the ZK watcher on the above path
-     *  setup - for setting up watchers for hosts being added/removed/changed
-     *          in the above ZK path
+     * If we receive another childrenChanged watch event while processing
+     * this set of children, we should re-run this process again. We use this
+     * 'repeat' variable to indicate this has happened.
      */
-    tasks.push(function mkdirp(_, cb) {
-        cb = once(cb);
-
-        log.debug({
-            path: self.path
-        }, 'mkdirp: ensuring directory exists');
-        const nullBuffer = new Buffer('null', 'ascii');
-        zk.createWithEmptyParents(self.path, nullBuffer, {}, function (err) {
-            if (err && err.code === 'NODE_EXISTS') {
-                log.debug({
-                    path: self.path
-                }, 'mkdirp: directory already exists');
-                cb(null);
-            } else if (err) {
-                cb(err);
-            } else {
-                log.debug({
-                    path: self.path
-                }, 'mkdirp: directory created');
-                cb(null);
-            }
-        });
+    var repeat = false;
+    S.on(this, 'childrenChangedAsserted', function (nkids) {
+        var diff = diffSets(self.hw_lastKids, nkids);
+        if (diff.added.length > 0 || diff.removed.length > 0) {
+            self._newDiff(diff);
+            self.hw_kids = nkids;
+            repeat = true;
+        }
     });
 
-    tasks.push(function watch(_, cb) {
-        cb = once(cb);
+    log.trace('fetching info about hosts...');
 
-        log.debug({
-            path: self.path
-        }, 'watch: creating watcher');
+    var hosts = [];
 
-        self.watcher = zk.watcher(self.path);
-        cb(null);
-    });
+    var opts = {
+        worker: doKid,
+        concurrency: FETCH_CONCURRENCY
+    };
+    this.hw_kidq = mod_vasync.queuev(opts);
+    S.on(this.hw_kidq, 'end', S.callback(function () {
+        if (hosts.length === 0) {
+            log.warn('tried to generate empty backends list, ignoring');
+            S.gotoState('collecting');
+            return;
+        }
 
-    tasks.push(function setup(_, cb) {
-        assert.object(self.watcher);
-        cb = once(cb);
+        var hostDiff = diffSets(self.hw_lastHosts, hosts);
 
-        log.debug({
-            path: self.path
-        }, 'setup: registering hooks');
+        var removed = hostDiff.removed;
 
-        self.watcher.on('error', function onWatchError(watchErr) {
-            log.error({
-                err: watchErr,
-                path: self.path
-            }, 'onWatchError: error from ZooKeeper');
-            self.emit('error', watchErr);
+        var now = Date.now();
+        hosts.forEach(function (h) {
+            self.hw_lastSeen[h] = now;
         });
 
-        self.watcher.on('childrenChanged', function onChildren(children) {
-            log.debug({
-                path: self.path,
-                children: children
-            }, 'onChildrenChanged: watch fired');
+        /*
+         * Sort the removed hosts so that the ones we've seen least recently
+         * (oldest/lowest lastSeen values) are at the front (lowest indices).
+         * That is, we want it in ascending order of lastSeen value.
+         *
+         * If we hit the throttle below we will decide to only actually remove
+         * the first N of these in their sorted order.
+         *
+         * We also take advantage of this sorting when looking at HOLD_TIME
+         * enforcement.
+         */
+        removed = removed.sort(function (a, b) {
+            if (self.hw_lastSeen[a] < self.hw_lastSeen[b])
+                return (-1);
+            if (self.hw_lastSeen[a] > self.hw_lastSeen[b])
+                return (1);
+            /* Sort by name if lastSeen is the same, to keep it consistent */
+            if (a < b)
+                return (-1);
+            if (a > b)
+                return (1);
+            return (0);
+        });
 
+        if (removed.length > 0) {
+            log.info({ removed: removed }, 'hosts have been removed in ZK');
+        }
+
+        var nextExpiry = null;
+
+        var rmThresh = Math.ceil(REMOVAL_THROTTLE * self.hw_lastHosts.length);
+
+        log.trace('checking removal throttle (removing %d, threshold %d)',
+            removed.length, rmThresh);
+
+        if (removed.length > rmThresh) {
+            log.warn('throttling backend removal to %d backends (tried to ' +
+                'remove %d)', rmThresh, removed.length);
             /*
-             * Children are returned as a list of UUID's like:
-             *  children: [
-             *    "26ec0faf-740e-4b55-be1a-XXXX",
-             *    "a6a58d04-0099-4319-83dc-XXXX"
-             *  ]
+             * We want to only remove the first rmThresh entries on the removed
+             * list, so we take the rest of it and push it back into the
+             * 'hosts' list (they were already missing from 'hosts', since this
+             * came from the diff).
              *
-             * This function then fetches the object at the path
-             * corresponding to this entry, determining if it is a
-             * host we care about.
+             * Remember .slice(N) returns the *rest* of the list after chopping
+             * off the first N
+             */
+            var toRestore = removed.slice(rmThresh);
+            toRestore.forEach(function (h) {
+                hosts.push(h);
+            });
+            /* Those first entries are the ones actually removed now. */
+            removed = removed.slice(0, rmThresh);
+            /*
+             * Come back in HOLD_TIME and look again if nothing else happens
+             * to re-process the throttle.
              */
-            function getChild(child, _cb) {
-                const p = self.path + '/' + child;
-                // Get info about host out of ZK
-                zk.get(p, function (err, _obj) {
-                    if (err) {
-                        err.path = p;
-                        _cb(err);
-                        return;
-                    }
-
-                    // Object returned as binary data from get()
-                    var obj = JSON.parse(_obj.toString());
-
-                    if (obj && obj.type === 'host') {
-                        log.debug({
-                            path: self.path,
-                            host: obj
-                        }, 'onChildrenChanged::getChild: host fetched');
-                        _cb(null, obj.host.address);
-                    } else {
-                        /*
-                         * webapi and loadbalancer instances both register
-                         * themselves into the same domain, but as different
-                         * types ("host" and "load_balancer", respectively).
-                         * Here we effectively filter out anything but
-                         * webapi instances.
-                         */
-                        _cb(null);
-                    }
-                });
+            nextExpiry = Math.round(now + HOLD_TIME + Math.random() * SMEAR);
+        }
+
+        /*
+         * Now check for HOLD_TIMEs on individual hosts. The 'removed' array
+         * is sorted so that the most recently seen entries are *last*, so we
+         * work from the end of the list here (calling .pop()).
+         */
+        while (removed.length > 0) {
+            var host = removed.pop();
+            var lastSeen = self.hw_lastSeen[host];
+            var delta = now - lastSeen;
+            if (delta < HOLD_TIME) {
+                log.info('keeping removed host %s around for HOLD_TIME (%d s)',
+                    host, HOLD_TIME / 1000);
+                hosts.push(host);
+                var exp = Math.round(lastSeen + HOLD_TIME +
+                    Math.random() * SMEAR);
+                if (nextExpiry === null || exp < nextExpiry)
+                    nextExpiry = exp;
+            } else {
+                removed.push(host);
+                break;
             }
+        }
+
+        /*
+         * Always set hw_nextExpiry: if we didn't encounter anything that needs
+         * to expire, we want it to go to null so that "idle" doesn't wake up
+         * spuriously.
+         *
+         * Note that if we're encountering errors that prevent us from ever
+         * completing a run through fetch here (e.g. hosts.length is 0), we
+         * might leave this set and keep retrying from "idle" a lot.
+         * That's fine.
+         */
+        self.hw_nextExpiry = nextExpiry;
+
+        hostDiff = diffSets(self.hw_lastHosts, hosts);
+        self._newHostDiff(hostDiff);
+
+        if (hostDiff.added.length !== 0 || hostDiff.removed.length !== 0) {
+            log.info({ diff: hostDiff }, 'making changes to hosts (after ' +
+                'throttle and hold)');
+            self.hw_lastHosts = hosts;
+            setImmediate(function () {
+                self.emit('hostsChanged', hosts);
+            });
+        } else {
+            log.info('no net change to hosts detected, will not restart lb');
+        }
 
+        if (repeat) {
+            S.gotoState('collecting');
+        } else {
+            S.gotoState('idle');
+        }
+    }));
+    kids.forEach(function (kid) {
+        self.hw_kidq.push(kid);
+    });
+    self.hw_kidq.close();
+
+    function doKid(name, cb) {
+        const path = self.hw_path + '/' + name;
+        zk.get(path, S.callback(function (err, json) {
             /*
-             * Process children array in parallel, calling getChild() on each
-             * entry
+             * The one error we can safely ignore here is NO_NODE, it just means
+             * that we raced against another childrenChanged notification as
+             * we entered the 'fetch' state, and one of the nodes went away.
              */
-            const opts = {
-                func: getChild,
-                inputs: children
-            };
-            vasync.forEachParallel(opts, function (err, res) {
-                if (err) {
-                    var emitError = false;
-                    verror.errorForEach(err, function (getChildErr) {
-                        if (getChildErr.name === 'ZKPingTimeoutError' &&
-                            getChildErr.code === 'PING_TIMEOUT') {
-                            /*
-                             * There is no meaningful action to be taken for a
-                             * zookeeper ping timeout. Muppet will be notified
-                             * if the zookeeper session becomes invalid and can
-                             * take action at that point. Log a debug message
-                             * and otherwise ignore it.
-                             */
-                            log.debug({
-                                path: getChildErr.path
-                            }, 'onChildrenChanged: zookeeper ping timeout');
-                        } else if (getChildErr.name === 'ZKError' &&
-                            getChildErr.code === 'NO_NODE') {
-                            /*
-                             * Failed to fetch the information about a host from
-                             * zookeeper. This need not be a fatal error. Log a
-                             * warning and carry on with the set of hosts that
-                             * we have info about.
-                             */
-                            log.warn({
-                                path: getChildErr.path
-                            }, 'onChildrenChanged: get host information ' +
-                                'failed');
-                        } else {
-                            log.error({
-                                path: getChildErr.path,
-                                err: err
-                            }, 'onChildrenChanged: get host information ' +
-                                'failed');
-                            emitError = true;
-                        }
-                    });
-
-                    if (emitError) {
-                        self.emit('error', err);
-                        return;
-                    }
-
-                }
-
-                var hosts = [];
-                /*
-                 * This little snippet just drops
-                 * nulls and duplicates
-                 */
-                res.successes.forEach(function uniqHost(h) {
-                    if (h && (hosts.indexOf(h) < 0)) {
-                        hosts.push(h);
-                    }
-                });
-                hosts.sort();
+            if (err && err.name === 'ZKError' && err.code === 'NO_NODE') {
+                log.debug({ path: path }, 'saw node in childrenChanged but ' +
+                    'was missing at get()');
+                cb();
+                return;
 
+            } else if (err) {
                 /*
-                 * Only emit if the set of webapi instances has
-                 * changed.
+                 * Queues don't really give us a nice way to return an error and
+                 * abort, but the kill() function is close. Note that the 'end'
+                 * handler won't run after kill() so we transition here.
                  */
-                if (!jsprim.deepEqual(hosts, self.hosts)) {
-                    // Log the changes first
-                    log.info({
-                        path: self.path,
-                        current: self.hosts,
-                        new: hosts
-                    }, 'onChildrenChanged: hosts differ, changing');
-                    self.hosts = hosts;
-
-                    // Emit updated hosts list
-                    self.emit('hosts', self.hosts);
-                } else {
-                    log.info({
-                        path: self.path,
-                        current: self.hosts
-                    }, 'onChildrenChanged: got hosts, but no changes');
-                }
-            });
-        });
-        cb(null);
-    });
-
-    // Kick off the mkdirp -> watch -> register pipeline
-    vasync.pipeline({ funcs: tasks }, function (err) {
-        if (err) {
-            log.error({
-                path: self.path,
-                err: err
-            }, 'Watch start: ZK error');
-            if (typeof (callback) === 'function') {
-                callback(err);
-            } else {
-                self.emit('error', err);
+                self.hw_lastError = err;
+                self.hw_kidq.kill();
+                S.gotoState('retry');
+                return;
             }
-        } else {
-            log.debug({
-                path: self.path
-            }, 'start: watching successful');
 
-            if (typeof (callback) === 'function')
-                callback(null);
+            try {
+                var obj = JSON.parse(json.toString('utf-8'));
+            } catch (e) {
+                log.debug({ err: e, path: path }, 'failed parsing JSON in ' +
+                    'ZK node, ignoring');
+                cb();
+                return;
+            }
+            /*
+             * There are non-'host' type objects under the manta name as well,
+             * which belong to load-balancer zones like ourselves.
+             */
+            if (typeof (obj) !== 'object' || obj.type !== 'host') {
+                log.trace({ path: path }, 'not a host node');
+                cb();
+                return;
+            }
+            hosts.push(obj.host.address);
+            cb();
+        }));
+    }
+};
 
-            process.nextTick(function () {
-                self.emit('start');
-            });
+HostWatcherFSM.prototype.state_retry = function (S) {
+    var self = this;
+    this.hw_log.warn(this.hw_lastError, 'error while updating backend list');
+    S.on(this, 'childrenChangedAsserted', function (kids) {
+        var diff = diffSets(self.hw_kids, kids);
+        if (diff.added.length > 0 || diff.removed.length > 0) {
+            self._newDiff(diff);
+            self.hw_kids = kids;
         }
     });
+    if (!this.hw_zk.isConnected()) {
+        S.on(this.hw_zk, 'connect', function () {
+            S.gotoStateTimeout(Math.round(Math.random() * SMEAR), 'fetch');
+        });
+        return;
+    }
+    const timeout = Math.round(RETRY_TIMEOUT + Math.random() * SMEAR);
+    S.gotoStateTimeout(timeout, 'fetch');
 };
 
-Watch.prototype.toString = function toString() {
-    var str = '[object Watch <';
-    str += sprintf('path=%s,', (this.path || 'null'));
-    str += sprintf('hosts=%j', (this.hosts || []));
-    str += '>]';
-    return (str);
-};
-
-
-///--- Exports
-
 module.exports = {
-    Watch: Watch
+    HostWatcherFSM: HostWatcherFSM
 };
diff --git a/lib/zk.js b/lib/zk.js
deleted file mode 100644
index e64bf4c..0000000
--- a/lib/zk.js
+++ /dev/null
@@ -1,44 +0,0 @@
-/*
- * This Source Code Form is subject to the terms of the Mozilla Public
- * License, v. 2.0. If a copy of the MPL was not distributed with this
- * file, You can obtain one at http://mozilla.org/MPL/2.0/.
- */
-
-/*
- * Copyright (c) 2017, Joyent, Inc.
- */
-const assert = require('assert-plus');
-const zkstream = require('zkstream');
-
-function createZKClient(cfg) {
-    assert.object(cfg, 'cfg');
-    assert.object(cfg.log, 'cfg.log');
-    assert.arrayOfObject(cfg.zookeeper.servers, 'cfg.zookeeper.servers');
-    assert.number(cfg.zookeeper.timeout, 'cfg.zookeeper.timeout');
-
-    var opts = {
-        servers: [],
-        log: cfg.log,
-        sessionTimeout: cfg.zookeeper.timeout
-    };
-
-    cfg.zookeeper.servers.forEach(function (s) {
-        // Support old zk-plus (host) or new zkstream (address) configs
-        var _host = s.address || s.host;
-        opts.servers.push({ address: _host, port: s.port });
-    });
-
-    cfg.log.debug({
-        servers: opts.servers,
-        timeout: opts.sessionTimeout
-    }, 'Creating ZooKeeper client');
-
-    return (new zkstream.Client(opts));
-}
-
-
-///--- API
-
-module.exports = {
-    createZKClient: createZKClient
-};
diff --git a/muppet.js b/muppet.js
index 63ac128..7ade2ea 100644
--- a/muppet.js
+++ b/muppet.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 
 /*
@@ -17,80 +17,16 @@
 'use strict';
 /*jsl:end*/
 
-const fs = require('fs');
-const assert = require('assert-plus');
-const backoff = require('backoff');
-const bunyan = require('bunyan');
-const dashdash = require('dashdash');
-const forkexec = require('forkexec');
-const net = require('net');
-const once = require('once');
+const mod_fs = require('fs');
+const mod_assert = require('assert-plus');
+const mod_bunyan = require('bunyan');
+const mod_dashdash = require('dashdash');
+const mod_forkexec = require('forkexec');
+const mod_net = require('net');
 const VError = require('verror');
-const zkstream = require('zkstream');
-const core = require('./lib');
-
-
-///--- Helper functions
-
-function getUntrustedIPs(cfg, callback) {
-    // Allow hardcoding addresses in the configuration.
-    if (cfg.hasOwnProperty('untrustedIPs')) {
-        callback();
-        return;
-    }
-
-    cfg.untrustedIPs = [];
-
-    const args = [ '/usr/sbin/mdata-get', 'sdc:nics' ];
-    cfg.log.info({ cmd: args }, 'Loading NIC information');
-    forkexec.forkExecWait({
-        argv: args
-    }, function (err, info) {
-        if (err) {
-            cfg.log.error(info, 'Failed to load NIC information');
-            setImmediate(callback,
-                new VError(err, 'Fetching untrusted IPs failed'));
-            return;
-        }
-
-        const nics = JSON.parse(info.stdout);
-        assert.array(nics, 'nics');
-
-        cfg.log.info({ nics: nics }, 'Looked up NICs');
-
-        function _pushIP(ip) {
-            /* If this is an admin, manta, or other trusted IP, skip it. */
-            if ((cfg.adminIPS && cfg.adminIPS.indexOf(ip) !== -1) ||
-                (cfg.mantaIPS && cfg.mantaIPS.indexOf(ip) !== -1) ||
-                ip === cfg.trustedIP)  {
-
-                return;
-            }
-
-            if (!net.isIPv4(ip) && !net.isIPv6(ip)) {
-                return;
-            }
-
-            cfg.untrustedIPs.push(ip);
-        }
-
-        function _addIPsFromNics(nic) {
-            if (nic.hasOwnProperty('ips')) {
-                nic.ips.forEach(function parseIP(addr) {
-                    _pushIP(addr.split('/')[0]);
-                });
-            } else if (nic.hasOwnProperty('ip')) {
-                _pushIP(nic.ip);
-            } else {
-                cfg.log.warn({ nic: nic }, 'NIC has no IP addresses');
-            }
-        }
-
-        nics.forEach(_addIPsFromNics);
-        callback();
-    });
-}
 
+const lib_app = require('./lib/app');
+const lib_lbman = require('./lib/lb_manager');
 
 ///--- CLI Functions
 
@@ -114,20 +50,20 @@ function configure() {
         }
     ];
 
-    const parser = new dashdash.Parser({options: cli_options});
-    var log = bunyan.createLogger({
+    const parser = new mod_dashdash.Parser({options: cli_options});
+    var log = mod_bunyan.createLogger({
         level: (process.env.LOG_LEVEL || 'info'),
         name: 'muppet',
         stream: process.stdout,
         serializers: {
-            err: bunyan.stdSerializers.err
+            err: mod_bunyan.stdSerializers.err
         }
     });
 
     var opts;
     try {
         opts = parser.parse(process.argv);
-        assert.object(opts, 'options');
+        mod_assert.object(opts, 'options');
     } catch (e) {
         log.fatal(e, 'invalid options');
         process.exit(1);
@@ -140,7 +76,7 @@ function configure() {
     var cfg;
     try {
         const _f = opts.file || __dirname + '/etc/config.json';
-        cfg = JSON.parse(fs.readFileSync(_f, 'utf8'));
+        cfg = JSON.parse(mod_fs.readFileSync(_f, 'utf8'));
         if (cfg.adminIPS && typeof (cfg.adminIPS) === 'string') {
             cfg.adminIPS = cfg.adminIPS.split(',');
         }
@@ -152,10 +88,10 @@ function configure() {
         process.exit(1);
     }
 
-    assert.string(cfg.name, 'config.name');
-    assert.string(cfg.trustedIP, 'config.trustedIP');
-    assert.object(cfg.zookeeper, 'config.zookeeper');
-    assert.optionalArrayOfString(cfg.untrustedIPs,
+    mod_assert.string(cfg.name, 'config.name');
+    mod_assert.string(cfg.trustedIP, 'config.trustedIP');
+    mod_assert.object(cfg.zookeeper, 'config.zookeeper');
+    mod_assert.optionalArrayOfString(cfg.untrustedIPs,
         'config.untrustedIPs');
 
     if (cfg.logLevel)
@@ -163,11 +99,11 @@ function configure() {
 
     if (opts.verbose) {
         opts.verbose.forEach(function () {
-            log.level(Math.max(bunyan.TRACE, (log.level() - 10)));
+            log.level(Math.max(mod_bunyan.TRACE, (log.level() - 10)));
         });
     }
 
-    if (log.level() <= bunyan.DEBUG)
+    if (log.level() <= mod_bunyan.DEBUG)
         log = log.child({src: true});
 
     cfg.log = log;
@@ -188,150 +124,7 @@ function usage(msg) {
 }
 
 
-
-///--- Internal Functions
-
-function startWatch(opts, cb) {
-    assert.object(opts, 'options');
-    assert.object(opts.config, 'options.config');
-    assert.object(opts.config.log, 'options.config.log');
-    assert.object(opts.zk, 'options.zk');
-    assert.func(cb, 'callback');
-
-    cb = once(cb);
-
-    function _start(_, _cb) {
-        _cb = once(_cb);
-
-        const cfg = opts.config;
-        const watch = new core.createWatch({
-            domain: cfg.name,
-            log: cfg.log,
-            zk: opts.zk
-        });
-        watch.start(function onStart(startErr) {
-            if (startErr) {
-                _cb(startErr);
-                return;
-            }
-
-            // Watcher emits `hosts` on a change to hosts in ZK
-            watch.on('hosts', function onHosts(hosts) {
-                const _opts = {
-                    trustedIP: cfg.trustedIP,
-                    untrustedIPs: cfg.untrustedIPs,
-                    hosts: hosts || [],
-                    log: cfg.log.child({component: 'lb_manager'}),
-                    restart: cfg.restart
-                };
-                core.restartLB(_opts, function (err) {
-                    if (err) {
-                        cfg.log.error({
-                            hosts: hosts,
-                            err: err
-                        }, 'lb restart failed');
-                        return;
-                    }
-
-                    cfg.log.info({
-                        hosts: hosts
-                    }, 'lb restarted');
-                });
-            });
-
-            /*
-             * Watcher directly handles certain classes of zookeeper errors, but
-             * emits an error event for those not directly handled.
-             */
-            watch.on('error', function onError(err) {
-                cfg.log.error({
-                    err: err
-                }, 'zookeeper error');
-            });
-
-            _cb(null, watch);
-        });
-    }
-
-    const retry = backoff.call(_start, {}, cb);
-    retry.failAfter(Infinity);
-    retry.setStrategy(new backoff.ExponentialStrategy());
-
-    retry.on('backoff', function (num, delay, err) {
-        opts.config.log.warn({
-            err: err,
-            num_attempts: num,
-            delay: delay
-        }, 'failed to start ZooKeeper watch');
-    });
-    retry.start();
-}
-
-function watcher(cfg, zk_client) {
-    startWatch({
-        config: cfg,
-        zk: zk_client
-    }, function onStartWatch(err, watch) {
-        if (err) {
-            cfg.log.fatal(err, 'Failed to start watch');
-            process.exit(1);
-        }
-        cfg.log.info('ZooKeeper watch created');
-    });
-}
-
-function zookeeper(cfg) {
-    assert.object(cfg, 'cfg');
-    assert.object(cfg.log, 'cfg.log');
-
-    const zk_client = core.createZKClient(cfg);
-
-    zk_client.on('session', function onSession() {
-        cfg.log.info('ZooKeeper session started');
-        watcher(cfg, zk_client);
-    });
-
-    zk_client.on('connect', function onConnect() {
-        cfg.log.info('ZooKeeper successfully connected');
-    });
-
-    zk_client.on('close', function onClose() {
-        cfg.log.warn('ZooKeeper connection closed');
-    });
-
-    zk_client.on('expire', function onExpire() {
-        cfg.log.warn('ZooKeeper connection expired');
-    });
-
-    /*
-     * zkstream attempts to retry the connection to zookeeper. On retry
-     * exhaustion it will emit a `failed` event.
-     * For this we only log an error, because when ZK comes back up, zkstream
-     * will automatically reconnect and re-arm the watchers (if they existed)
-     */
-    zk_client.on('failed', function onFailed(err) {
-        cfg.log.error(err, 'ZooKeeper: received failed event');
-    });
-}
-
-
 ///--- Mainline
 
-(function main() {
-    var cfg = configure();
-
-    getUntrustedIPs(cfg, function (err) {
-        if (err) {
-            // We failed to load our IPs: abort.
-            cfg.log.fatal(err, 'Failed to look up any IPs');
-            process.exit(1);
-        }
-
-        cfg.log.info({
-            trustedIP: cfg.trustedIP,
-            untrustedIPs: cfg.untrustedIPs
-        }, 'Selected IPs for untrusted networks');
-
-        zookeeper(cfg);
-    });
-})();
+var config = configure();
+var app = new lib_app.AppFSM(config);
diff --git a/package.json b/package.json
index f5d072c..f9522a5 100644
--- a/package.json
+++ b/package.json
@@ -1,32 +1,33 @@
 {
-    "name": "muppet",
-    "description": "Joyent's Load Balancer",
-    "version": "1.1.0",
-    "author": "Joyent (joyent.com)",
-    "private": true,
-    "dependencies": {
-        "assert-plus": "1.0.0",
-        "backoff": "2.3.0",
-        "bunyan": "2.0.2",
-        "dashdash": "1.14.1",
-        "forkexec": "1.1.0",
-        "haproxy-stat": "0.1.0",
-        "jsprim": "1.4.0",
-        "node-uuid": "1.4.1",
-        "once": "1.4.0",
-        "vasync": "2.2.0",
-        "verror": "1.10.0",
-        "zkstream": "0.11.4"
-    },
-    "devDependencies": {
-        "nodeunit": "0.11.2",
-        "diff": "4.0.1"
-    },
-    "scripts": {
-        "start": "node ./muppet.js"
-    },
-    "sdcDependencies": {
-        "config-agent": ">=1.2.0"
-    },
-    "license": "MPL-2.0"
+  "name": "muppet",
+  "description": "Joyent's Load Balancer",
+  "version": "1.1.0",
+  "author": "Joyent (joyent.com)",
+  "private": true,
+  "dependencies": {
+    "assert-plus": "1.0.0",
+    "backoff": "2.3.0",
+    "bunyan": "2.0.2",
+    "dashdash": "1.14.1",
+    "forkexec": "1.1.0",
+    "haproxy-stat": "0.1.0",
+    "jsprim": "1.4.0",
+    "mooremachine": "2.3.0",
+    "node-uuid": "1.4.1",
+    "once": "1.4.0",
+    "vasync": "2.2.0",
+    "verror": "1.10.0",
+    "zkstream": "0.11.8"
+  },
+  "devDependencies": {
+    "nodeunit": "0.11.2",
+    "diff": "4.0.1"
+  },
+  "scripts": {
+    "start": "node ./muppet.js"
+  },
+  "sdcDependencies": {
+    "config-agent": ">=1.2.0"
+  },
+  "license": "MPL-2.0"
 }
diff --git a/smf/manifests/haproxy.xml.in b/smf/manifests/haproxy.xml.in
index 7a98423..0cc7220 100644
--- a/smf/manifests/haproxy.xml.in
+++ b/smf/manifests/haproxy.xml.in
@@ -7,7 +7,7 @@
 -->
 
 <!--
-    Copyright (c) 2014, Joyent, Inc.
+    Copyright 2019 Joyent, Inc.
 -->
 
 <service_bundle type="manifest" name="haproxy">
@@ -51,6 +51,8 @@
 	    </method_context>
 	</exec_method>
 
+        <exec_method name='refresh' type='method' exec='/usr/bin/pkill -USR2 -z $(zonename) -u root haproxy' timeout_seconds='30'/>
+
 	<exec_method type="method"
 		     name="stop"
 		     exec=":kill"
diff --git a/test/config.test.js b/test/config.test.js
index 6d50618..f627831 100644
--- a/test/config.test.js
+++ b/test/config.test.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 var vasync = require('vasync');
 var helper = require('./helper.js');
@@ -27,7 +27,7 @@ var haproxy_empty_error = path.resolve(__dirname, 'haproxy.cfg.empty');
 var haproxy_parse_error = path.resolve(__dirname, 'haproxy.cfg.parse-error');
 var haproxy_no_frontend = path.resolve(__dirname, 'haproxy.cfg.no-frontend');
 
-// Input file to use for writeHaproxyConfig and restart
+// Input file to use for writeHaproxyConfig and reload
 var haproxy_config_in = fs.readFileSync(path.resolve(__dirname,
                                                      'haproxy.cfg.in'),
                                         'utf8');
@@ -37,16 +37,18 @@ var updConfig_out = path.resolve(__dirname, 'haproxy.cfg.out');
 // File for the above to check against
 var updConfig_out_chk = path.resolve(__dirname, 'haproxy.cfg.out-check');
 
-// Files that the successful restart test will write out
+// Files that the successful reload test will write out
 var haproxy_file = path.resolve(__dirname, '../etc/haproxy.cfg');
 var haproxy_file_tmp = path.resolve(__dirname, '../etc/haproxy.cfg.tmp');
 
+var haproxy_exec = path.resolve(__dirname, '../deps/haproxy-1.8/haproxy');
 
 
 ///--- Tests
 
 test('test good config file', function (t) {
     var opts = { log: helper.createLogger(),
+        haproxyExec: haproxy_exec,
         configFileOut: haproxy_good};
     lbm.checkHaproxyConfig(opts, function (err) {
         t.equal(null, err);
@@ -56,6 +58,7 @@ test('test good config file', function (t) {
 
 test('test no-listener config file (should error)', function (t) {
     var opts = { log: helper.createLogger(),
+        haproxyExec: haproxy_exec,
         configFileOut: haproxy_no_listener};
     lbm.checkHaproxyConfig(opts, function (err) {
         t.notEqual(null, err);
@@ -65,6 +68,7 @@ test('test no-listener config file (should error)', function (t) {
 
 test('test empty config file (should error)', function (t) {
     var opts = { log: helper.createLogger(),
+        haproxyExec: haproxy_exec,
         configFileOut: haproxy_empty_error};
     lbm.checkHaproxyConfig(opts, function (err) {
         t.notEqual(null, err);
@@ -74,6 +78,7 @@ test('test empty config file (should error)', function (t) {
 
 test('test parse error config file (should error)', function (t) {
     var opts = { log: helper.createLogger(),
+        haproxyExec: haproxy_exec,
         configFileOut: haproxy_parse_error};
     lbm.checkHaproxyConfig(opts, function (err) {
         t.notEqual(null, err);
@@ -83,6 +88,7 @@ test('test parse error config file (should error)', function (t) {
 
 test('test no-frontend config file (should error)', function (t) {
     var opts = { log: helper.createLogger(),
+        haproxyExec: haproxy_exec,
         configFileOut: haproxy_no_frontend};
     lbm.checkHaproxyConfig(opts, function (err) {
         t.notEqual(null, err);
@@ -90,21 +96,13 @@ test('test no-frontend config file (should error)', function (t) {
     });
 });
 
-test('test get haproxy exec path', function (t) {
-    var opts = { log: helper.createLogger() };
-    lbm.getHaproxyExec(opts, function (err, data) {
-        t.equal(null, err);
-        t.notEqual(null, data);
-        t.done();
-    });
-});
-
 test('test writeHaproxyConfig', function (t) {
     var opts = {
         trustedIP: '127.0.0.1',
         untrustedIPs: ['::1', '255.255.255.255'],
         hosts: ['foo.joyent.us', 'bar.joyent.us'],
         configFileOut: updConfig_out,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
     lbm.writeHaproxyConfig(opts, function (err, data) {
@@ -120,7 +118,9 @@ test('test writeHaproxyConfig', function (t) {
                     t.equal(null, part.value);
                 }
             } else if (part.removed) {
-                if (! part.value.includes('log-send-hostname')) {
+                if ((! part.value.includes('log-send-hostname')) &&
+                    // the input cfg is commented
+                    (! part.value.startsWith('#'))) {
                     t.equal(null, part.value);
                 }
             }
@@ -138,6 +138,7 @@ test('test writeHaproxyConfig bad config (should error)', function (t) {
         hosts: [],
         configFileOut: updConfig_out,
         configFileIn: haproxy_config_in,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
 
@@ -150,24 +151,25 @@ test('test writeHaproxyConfig bad config (should error)', function (t) {
     });
 });
 
-test('test restart', function (t) {
+test('test reload', function (t) {
     var opts = {
         trustedIP: '127.0.0.1',
         untrustedIPs: ['::1', '255.255.255.255'],
         // This must resolve, so pick something public
         hosts: ['google.com'],
-        restart: '/bin/true',
+        reload: '/bin/true',
         configFileIn: haproxy_config_in,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
 
-    lbm.restart(opts, function (err, data) {
+    lbm.reload(opts, function (err, data) {
         t.equal(null, err);
         t.doesNotThrow(function () {
-            // Check if restart created the proper file
+            // Check if reload created the proper file
             // this will throw if the file doesn't exist
             fs.statSync(haproxy_file);
-            // remove files that a successful restart
+            // remove files that a successful reload
             // would have created
             fs.unlinkSync(haproxy_file);
         });
@@ -175,29 +177,31 @@ test('test restart', function (t) {
     });
 });
 
-test('test restart bad config (should error)', function (t) {
+test('test reload bad config (should error)', function (t) {
     var opts = {
         trustedIP: '127.0.0.1',
         untrustedIPs: ['::1', '255.255.255.255'],
         hosts: [],
-        restart: '/bin/true',
+        reload: '/bin/true',
         configFileIn: haproxy_config_in,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
 
-    lbm.restart(opts, function (err, data) {
+    lbm.reload(opts, function (err, data) {
         t.notEqual(null, err);
         t.done();
     });
 });
 
-test('test dueling restarts', function (t) {
+test('test dueling reloads', function (t) {
     var opts = {
         trustedIP: '127.0.0.1',
         untrustedIPs: ['::1', '255.255.255.255'],
         hosts: ['google.com', 'joyent.com'],
-        restart: '/bin/sleep 2',
+        reload: '/bin/sleep 2',
         configFileIn: haproxy_config_in,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
 
@@ -206,19 +210,20 @@ test('test dueling restarts', function (t) {
         untrustedIPs: ['::1', '255.255.255.255'],
         // This must resolve, so pick something public
         hosts: ['google.com'],
-        restart: '/bin/true',
+        reload: '/bin/true',
         configFileIn: haproxy_config_in,
+        haproxyExec: haproxy_exec,
         log: helper.createLogger()
     };
 
-    // Restart twice, calling the functions as fast as possible
+    // Reload twice, calling the functions as fast as possible
     // Using a /bin/sleep call to make sure the first one is still
     // busy for the second call.
-    lbm.restart(opts, function (err, data) {
+    lbm.reload(opts, function (err, data) {
         t.equal(null, err);
     });
 
-    lbm.restart(opts2, function (err, data) {
+    lbm.reload(opts2, function (err, data) {
         t.equal(null, err);
         t.done();
     });
diff --git a/test/helper.js b/test/helper.js
index 23daeb6..da31160 100644
--- a/test/helper.js
+++ b/test/helper.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright 2019 Joyent, Inc.
  */
 
 /*jsl:ignore*/
@@ -16,9 +16,6 @@ const bunyan = require('bunyan');
 const vasync = require('vasync');
 const zkstream = require('zkstream');
 
-const core = require('../lib');
-
-
 
 ///--- Helpers
 
@@ -36,30 +33,6 @@ function createLogger(name, stream) {
 }
 
 
-function createZkClient(callback) {
-        const host = process.env.ZK_HOST || 'localhost';
-        var log = createLogger();
-        const port = process.env.ZK_PORT || 2181;
-
-        core.createZKClient({
-                log: log,
-                servers: [ {
-                        address: host,
-                        port: port
-                } ],
-                timeout: 100
-        }, function (_err, zk) {
-            zk.on('failed', function (err) {
-                callback(err);
-            });
-            zk.on('session', function () {
-                callback(null, zk);
-            });
-        });
-}
-
-
-
 ///--- Exports
 
 module.exports = {
@@ -103,7 +76,6 @@ module.exports = {
                 };
         },
 
-        createLogger: createLogger,
-        createZkClient: createZkClient
+        createLogger: createLogger
 
 };
diff --git a/tools/mk/Makefile.haproxy.defs b/tools/mk/Makefile.haproxy.defs
index 83a2dfb..095b0fa 100644
--- a/tools/mk/Makefile.haproxy.defs
+++ b/tools/mk/Makefile.haproxy.defs
@@ -6,7 +6,7 @@
 #
 
 #
-# Copyright (c) 2017, Joyent, Inc.
+# Copyright 2019 Joyent, Inc.
 #
 
 #
@@ -20,7 +20,7 @@ HAPROXY_INSTALL ?= $(BUILD)/haproxy
 DISTCLEAN_FILES	+= $(HAPROXY_INSTALL)
 
 HAPROXY_EXEC	= $(HAPROXY_INSTALL)/sbin/haproxy
-HAPROXY_SRC	:= deps/haproxy-1.5
+HAPROXY_SRC	:= deps/haproxy-1.8
 
 # Ensure these use absolute paths to the executables to allow running
 # from a dir other than the project top.
diff --git a/tools/mk/Makefile.haproxy.targ b/tools/mk/Makefile.haproxy.targ
index 1e1615b..e8a24fc 100644
--- a/tools/mk/Makefile.haproxy.targ
+++ b/tools/mk/Makefile.haproxy.targ
@@ -5,10 +5,6 @@
 # file, You can obtain one at http://mozilla.org/MPL/2.0/.
 #
 
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
 #
 # Makefile.haproxy.targ: building and shipping a private haproxy
 #
diff --git a/tools/service_bundle.dtd.1 b/tools/service_bundle.dtd.1
deleted file mode 100644
index e5c2380..0000000
--- a/tools/service_bundle.dtd.1
+++ /dev/null
@@ -1,1091 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
- Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.
-
- CDDL HEADER START
-
- The contents of this file are subject to the terms of the
- Common Development and Distribution License (the "License").
- You may not use this file except in compliance with the License.
-
- You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
- or http://www.opensolaris.org/os/licensing.
- See the License for the specific language governing permissions
- and limitations under the License.
-
- When distributing Covered Code, include this CDDL HEADER in each
- file and include the License file at usr/src/OPENSOLARIS.LICENSE.
- If applicable, add the following below this CDDL HEADER, with the
- fields enclosed by brackets "[]" replaced with your own identifying
- information: Portions Copyright [yyyy] [name of copyright owner]
-
- CDDL HEADER END
--->
-
-<!--
-  Service description DTD
-
-    Most attributes are string values (or an individual string from a
-    restricted set), but attributes with a specific type requirement are
-    noted in the comment describing the element.
--->
-
-<!--
-  XInclude support
-
-    A series of service bundles may be composed via the xi:include tag.
-    smf(5) tools enforce that all bundles be of the same type.
--->
-
-<!--
-     These entities are used for the property, propval and property_group
-     elements, that require type attributes for manifest, while for profiles
-     the type attributes are only implied.
--->
-
-<!ENTITY % profile "IGNORE">
-<!ENTITY % manifest "INCLUDE">
-
-<!ELEMENT xi:include
-  (xi:fallback)
-  >
-<!ATTLIST xi:include
-  href CDATA #REQUIRED
-  parse (xml|text) "xml"
-  encoding CDATA #IMPLIED
-  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
-  >
-
-<!ELEMENT xi:fallback
-  ANY
-  >
-<!ATTLIST xi:fallback
-  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
-  >
-
-<!--
-  stability
-
-    This element associates an SMI stability level with the parent
-    element.  See attributes(5) for an explanation of interface
-    stability levels.
-
-    Its attribute is
-
-	value	The stability level of the parent element.
--->
-
-<!ELEMENT stability EMPTY>
-
-<!ATTLIST stability
-	value		( Standard | Stable | Evolving | Unstable |
-			External | Obsolete ) #REQUIRED >
-
-<!-- Property value lists -->
-
-<!--
-  value_node
-
-    This element represents a single value within any of the typed
-    property value lists.
-
-    Its attribute is
-
-	value	The value for this node in the list.
--->
-
-<!ELEMENT value_node EMPTY>
-
-<!ATTLIST value_node
-	value CDATA #REQUIRED>
-
-<!--
-  count_list
-  integer_list
-  opaque_list
-  host_list
-  hostname_list
-  net_address_list
-  net_address_v4_list
-  net_address_v6_list
-  time_list
-  astring_list
-  ustring_list
-  boolean_list
-  fmri_list
-  uri_list
-
-    These elements represent the typed lists of values for a property.
-    Each contains one or more value_node elements representing each
-    value on the list.
-
-    None of these elements has attributes.
--->
-
-<!ELEMENT count_list
-	( value_node+ )>
-
-<!ATTLIST count_list>
-
-<!ELEMENT integer_list
-	( value_node+ )>
-
-<!ATTLIST integer_list>
-
-<!ELEMENT opaque_list
-	( value_node+ )>
-
-<!ATTLIST opaque_list>
-
-<!ELEMENT host_list
-	( value_node+ )>
-
-<!ATTLIST host_list>
-
-<!ELEMENT hostname_list
-	( value_node+ )>
-
-<!ATTLIST hostname_list>
-
-<!ELEMENT net_address_list
-	( value_node+ )>
-
-<!ATTLIST net_address_list>
-
-<!ELEMENT net_address_v4_list
-	( value_node+ )>
-
-<!ATTLIST net_address_v4_list>
-
-<!ELEMENT net_address_v6_list
-	( value_node+ )>
-
-<!ATTLIST net_address_v6_list>
-
-<!ELEMENT time_list
-	( value_node+ )>
-
-<!ATTLIST time_list>
-
-<!ELEMENT astring_list
-	( value_node+ )>
-
-<!ATTLIST astring_list>
-
-<!ELEMENT ustring_list
-	( value_node+ )>
-
-<!ATTLIST ustring_list>
-
-<!ELEMENT boolean_list
-	( value_node+ )>
-
-<!ATTLIST boolean_list>
-
-<!ELEMENT fmri_list
-	( value_node+ )>
-
-<!ATTLIST fmri_list>
-
-<!ELEMENT uri_list
-	( value_node+ )>
-
-<!ATTLIST uri_list>
-
-<!-- Properties and property groups -->
-
-<!--
-   property
-
-     This element is for a singly or multiply valued property within a
-     property group.  It contains an appropriate value list element,
-     which is expected to be consistent with the type attribute.
-
-     Its attributes are
-
-	name	The name of this property.
-
-	type	The data type for this property.
-
-	override These values should replace values already in the
-		repository.
--->
-
-<![%profile;[
-<!ELEMENT property
-	( count_list | integer_list | opaque_list | host_list | hostname_list |
-	net_address_list | net_address_v4_list | net_address_v6_list |
-	time_list | astring_list | ustring_list | boolean_list | fmri_list |
-	uri_list )? >
-
-<!ATTLIST property
-	name		CDATA #REQUIRED
-	type		( count | integer | opaque | host | hostname |
-			net_address | net_address_v4 | net_address_v6 | time |
-			astring | ustring | boolean | fmri | uri ) #IMPLIED
-	override	( true | false ) "false" >
-]]>
-	
-<![%manifest;[
-<!ELEMENT property
-	( count_list | integer_list | opaque_list | host_list | hostname_list |
-	net_address_list | net_address_v4_list | net_address_v6_list |
-	time_list | astring_list | ustring_list | boolean_list | fmri_list |
-	uri_list )? >
-
-<!ATTLIST property
-	name		CDATA #REQUIRED
-	type		( count | integer | opaque | host | hostname |
-			net_address | net_address_v4 | net_address_v6 | time |
-			astring | ustring | boolean | fmri | uri ) #REQUIRED
-	override	( true | false ) "false" >
-]]>
-
-<!--
-   propval
-
-     This element is for a singly valued property within a property
-     group.  List-valued properties must use the property element above.
-
-     Its attributes are
-
-	name	The name of this property.
-
-	type	The data type for this property.
-
-	value	The value for this property.  Must match type
-		restriction of type attribute.
-
-	override This value should replace any values already in the
-		repository.
--->
-
-<![%profile;[
-<!ELEMENT propval EMPTY>
-
-<!ATTLIST propval
-	name		CDATA #REQUIRED
-	type		( count | integer | opaque | host | hostname |
-			net_address | net_address_v4 | net_address_v6 | time |
-			astring | ustring | boolean | fmri | uri ) #IMPLIED
-	value		CDATA #REQUIRED
-	override	( true | false ) "false" >
-]]>
-
-<![%manifest;[
-<!ELEMENT propval EMPTY>
-
-<!ATTLIST propval
-	name		CDATA #REQUIRED
-	type		( count | integer | opaque | host | hostname |
-			net_address | net_address_v4 | net_address_v6 | time |
-			astring | ustring | boolean | fmri | uri ) #REQUIRED
-	value		CDATA #REQUIRED
-	override	( true | false ) "false" >
-]]>
-
-<!--
-  property_group
-
-    This element is for a set of related properties on a service or
-    instance.  It contains an optional stability element, as well as
-    zero or more property-containing elements.
-
-    Its attributes are
-
-	name	The name of this property group.
-
-	type	A category for this property group.  Groups of type
-		"framework", "implementation" or "template" are primarily
-		of interest to the service management facility, while
-		groups of type "application" are expected to be only of
-		interest to the service to which this group is attached.
-		Other types may be introduced using the service symbol
-		namespace conventions.
-
-	delete	If in the repository, this property group should be removed.
--->
-
-<![%profile;[
-<!ELEMENT property_group
-	( stability?, ( propval | property )* )>
-
-<!ATTLIST property_group
-	name		CDATA #REQUIRED
-	type		CDATA #IMPLIED
-	delete		( true | false ) "false" >
-]]>
-
-<![%manifest;[
-<!ELEMENT property_group
-	( stability?, ( propval | property )* )>
-
-<!ATTLIST property_group
-	name		CDATA #REQUIRED
-	type		CDATA #REQUIRED
-	delete		( true | false ) "false" >
-]]>
-
-<!--
-  service_fmri
-
-    This element defines a reference to a service FMRI (for either a
-    service or an instance).
-
-    Its attribute is
-
-	value	The FMRI.
--->
-
-<!ELEMENT service_fmri EMPTY>
-
-<!ATTLIST service_fmri
-	value		CDATA #REQUIRED>
-
-<!-- Dependencies -->
-
-<!--
-  dependency
-
-    This element identifies a group of FMRIs upon which the service is
-    in some sense dependent.  Its interpretation is left to the
-    restarter to which a particular service instance is delegated.  It
-    contains a group of service FMRIs, as well as a block of properties.
-
-    Its attributes are
-
-	name	The name of this dependency.
-
-	grouping The relationship between the various FMRIs grouped
-		here; "require_all" of the FMRIs to be online, "require_any"
-		of the FMRIs to be online, or "exclude_all" of the FMRIs
-		from being online or in maintenance for the dependency to
-		be satisfied.  "optional_all" dependencies are satisfied
-		when all of the FMRIs are either online or unable to come
-		online (because they are disabled, misconfigured, or one
-		of their dependencies is unable to come online).
-
-	restart_on The type of events from the FMRIs that the service should
-		be restarted for.  "error" restarts the service if the
-		dependency is restarted due to hardware fault.  "restart"
-		restarts the service if the dependency is restarted for
-		any reason, including hardware fault.  "refresh" restarts
-		the service if the dependency is refreshed or restarted for
-		any reason.  "none" will never restart the service due to
-		dependency state changes.
-
-	type	The type of dependency: on another service ('service'), on
-		a filesystem path ('path'), or another dependency type.
-
-	delete	This dependency should be deleted.
--->
-
-<!ELEMENT dependency
-	( service_fmri*, stability?, ( propval | property )* ) >
-
-<!ATTLIST dependency
-	name		CDATA #REQUIRED
-	grouping	( require_all | require_any | exclude_all |
-			optional_all ) #REQUIRED
-	restart_on	( error | restart | refresh | none ) #REQUIRED
-	type		CDATA #REQUIRED
-	delete		( true | false ) "false" >
-
-<!-- Dependents -->
-
-<!--
-  dependent
-
-    This element identifies a service which should depend on this service.  It
-    corresponds to a dependency in the named service.  The grouping and type
-    attributes of that dependency are implied to be "require_all" and
-    "service", respectively.
-
-    Its attributes are
-
-	name	The name of the dependency property group to create in the
-		dependent entity.
-
-	grouping The grouping relationship of the dependency property
-		group to create in the dependent entity.  See "grouping"
-		attribute on the dependency element.
-
-	restart_on The type of events from this service that the named service
-		should be restarted for.
-
-	delete	True if this dependent should be deleted.
-
-	override Whether to replace an existing dependent of the same name.
-
--->
-
-<!ELEMENT dependent
-	( service_fmri, stability?, ( propval | property )* ) >
-
-<!ATTLIST dependent
-	name		CDATA #REQUIRED
-	grouping	( require_all | require_any | exclude_all |
-			optional_all) #REQUIRED
-	restart_on	( error | restart | refresh | none) #REQUIRED
-	delete		( true | false ) "false"
-	override	( true | false ) "false" >
-
-<!-- Method execution context, security profile, and credential definitions -->
-
-<!--
-  envvar
-
-    An environment variable. It has two attributes:
-
-	name	The name of the environment variable.
-	value	The value of the environment variable.
--->
-
-<!ELEMENT envvar EMPTY>
-
-<!ATTLIST envvar
-	name		CDATA #REQUIRED
-	value		CDATA #REQUIRED >
-
-<!--
-  method_environment
-
-    This element defines the environment for a method. It has no
-    attributes, and one or more envvar child elements.
--->
-
-<!ELEMENT method_environment (envvar+) >
-
-<!ATTLIST method_environment>
-
-<!--
-  method_profile
-
-    This element indicates which exec_attr(5) profile applies to the
-    method context being defined.
-
-    Its attribute is
-
-	name	The name of the profile.
--->
-
-<!ELEMENT method_profile EMPTY>
-
-<!ATTLIST method_profile
-	name		CDATA #REQUIRED >
-
-<!--
-  method_credential
-
-    This element specifies credential attributes for the execution
-    method to use.
-
-    Its attributes are
-
-	user	The user ID, in numeric or text form.
-
-	group	The group ID, in numeric or text form.  If absent or
-		":default", the group associated with the user in the
-		passwd database.
-
-	supp_groups Supplementary group IDs to be associated with the
-		method, separated by commas or spaces.  If absent or
-		":default", initgroups(3C) will be used.
-
-	privileges An optional string specifying the privilege set.
-
-	limit_privileges An optional string specifying the limit
-		privilege set.
--->
-
-<!ELEMENT method_credential EMPTY>
-
-<!ATTLIST method_credential
-	user		CDATA #REQUIRED
-	group		CDATA #IMPLIED
-	supp_groups	CDATA #IMPLIED
-	privileges	CDATA #IMPLIED
-	limit_privileges CDATA #IMPLIED >
-
-<!--
-  method_context
-
-    This element combines credential and resource management attributes
-    for execution methods.  It may contain a method_environment, or
-    a method_profile or method_credential element.
-
-    Its attributes are
-
-	working_directory The home directory to launch the method from.
-		":default" can be used as a token to indicate use of the
-		user specified by the credential or profile specified.
-
-	project	The project ID, in numeric or text form.  ":default" can
-		be used as a token to indicate use of the project
-		identified by getdefaultproj(3PROJECT) for the non-root
-		user specified by the credential or profile specified.
-		If the user is root, ":default" designates the project
-		the restarter is running in.
-
-	resource_pool The resource pool name to launch the method on.
-		":default" can be used as a token to indicate use of the
-		pool specified in the project(4) entry given in the
-		"project" attribute above.
--->
-<!ELEMENT method_context
-	( (method_profile | method_credential)?, method_environment? ) >
-
-<!ATTLIST method_context
-	working_directory	CDATA #IMPLIED
-	project			CDATA #IMPLIED
-	resource_pool		CDATA #IMPLIED >
-
-<!-- Restarter delegation, methods, and monitors -->
-
-<!--
-  exec_method
-
-    This element describes one of the methods used by the designated
-    restarter to act on the service instance.  Its interpretation is
-    left to the restarter to which a particular service instance is
-    delegated.  It contains a set of attributes, an optional method
-    context, and an optional stability element for the optional
-    properties that can be included.
-
-    Its attributes are
-
-	type	The type of method, either "method" or "monitor".
-
-	name	Name of this execution method.  The method names are
-		usually a defined interface of the restarter to which an
-		instance of this service is delegated.
-
-	exec	The string identifying the action to take.  For
-		svc.startd(1M), this is a string suitable to pass to
-		exec(2).
-
-	timeout_seconds [integer] Duration, in seconds, to wait for this
-		method to complete.  A '0' or '-1' denotes an infinite
-		timeout.
-
-	delete	If in the repository, the property group for this method
-		should be removed.
--->
-
-<!ELEMENT exec_method
-	( method_context?, stability?, ( propval | property )* ) >
-
-<!ATTLIST exec_method
-	type		( method | monitor ) #REQUIRED
-	name		CDATA #REQUIRED
-	exec		CDATA #REQUIRED
-	timeout_seconds	CDATA #REQUIRED
-	delete		( true | false ) "false" >
-
-<!--
-  restarter
-
-    A flag element identifying the restarter to which this service or
-    service instance is delegated.  Contains the FMRI naming the
-    delegated restarter.
-
-    This element has no attributes.
--->
-
-<!ELEMENT restarter
-	( service_fmri ) >
-
-<!ATTLIST restarter>
-
-<!--
-  Templates
--->
-
-<!--
-  doc_link
-
-    The doc_link relates a resource described by the given URI to the
-    service described by the containing template.  The resource is
-    expected to be a documentation or elucidatory reference of some
-    kind.
-
-    Its attributes are
-
-      name      A label for this resource.
-
-      uri       A URI to the resource.
--->
-
-<!ELEMENT doc_link EMPTY>
-
-<!ATTLIST doc_link
-	name		CDATA #REQUIRED
-	uri		CDATA #REQUIRED >
-
-<!--
-  manpage
-
-    The manpage element connects the reference manual page to the
-    template's service.
-
-    Its attributes are
-
-      title     The manual page title.
-
-      section   The manual page's section.
-
-      manpath   The MANPATH environment variable, as described in man(1)
-                that is required to reach the named manual page
--->
-
-<!ELEMENT manpage EMPTY>
-
-<!ATTLIST manpage
-	title		CDATA #REQUIRED
-	section		CDATA #REQUIRED
-	manpath		CDATA ":default" >
-
-<!--
-  documentation
-
-    The documentation element groups an arbitrary number of doc_link
-    and manpage references.
-
-    It has no attributes.
--->
-
-<!ELEMENT documentation
-	( doc_link | manpage )* >
-
-<!ATTLIST documentation>
-
-<!--
-  loctext
-
-    The loctext element is a container for localized text.
-
-    Its sole attribute is
-
-	xml:lang The name of the locale, in the form accepted by LC_ALL,
-		etc.  See locale(5).
--->
-<!ELEMENT loctext
-        (#PCDATA) >
-
-<!ATTLIST loctext
-        xml:lang	CDATA #REQUIRED >
-
-<!--
-  description
-
-    The description holds a set of potentially longer, localized strings that
-    consist of a short description of the service.
-
-    The description has no attributes.
--->
-<!ELEMENT description
-        ( loctext+ ) >
-
-<!ATTLIST description>
-
-<!--
-  common_name
-
-    The common_name holds a set of short, localized strings that
-    represent a well-known name for the service in the given locale.
-
-    The common_name has no attributes.
--->
-<!ELEMENT common_name
-        ( loctext+ ) >
-
-<!ATTLIST common_name>
-
-<!--
-  units
-
-    The units a numerical property is expressed in.
--->
-
-<!ELEMENT units
-	( loctext+ ) >
-
-<!ATTLIST units>
-
-<!--
-  visibility
-
-    Expresses how a property is typically accessed.  This isn't
-    intended as access control, but as an indicator as to how a
-    property is used.
-
-    Its attributes are:
-
-      value     'hidden', 'readonly', or 'readwrite' indicating that
-		the property should be hidden from the user, shown but
-		read-only, or modifiable.
--->
-
-<!ELEMENT visibility EMPTY>
-
-<!ATTLIST visibility
-	value	( hidden | readonly | readwrite ) #REQUIRED >
-
-<!--
-  value
-
-    Describes a legal value for a property value, and optionally contains a
-    human-readable name and description for the specified property
-    value.
-
-    Its attributes are:
-
-      name	A string representation of the value.
--->
-
-<!ELEMENT value
-	( common_name?, description? ) >
-
-<!ATTLIST value
-	name	CDATA #REQUIRED >
-
-<!--
-  values
-
-    Human-readable names and descriptions for valid values of a property.
--->
-
-<!ELEMENT values
-	(value+) >
-
-<!ATTLIST values>
-
-<!--
-  cardinality
-
-    Places a constraint on the number of values the property can take
-    on.
-
-    Its attributes are:
-	min	minimum number of values
-	max	maximum number of values
-
-    Both attributes are optional.  If min is not specified, it defaults to
-    0.  If max is not specified it indicates an unlimited number of values.
-    If neither is specified this indicates 0 or more values.
--->
-
-<!ELEMENT cardinality EMPTY>
-
-<!ATTLIST cardinality
-	min	CDATA "0"
-	max	CDATA "18446744073709551615">
-
-<!--
-  internal_separators
-
-    Indicates the separators used within a property's value used to
-    separate the actual values.  Used in situations where multiple
-    values are packed into a single property value instead of using a
-    multi-valued property.
--->
-
-<!ELEMENT internal_separators
-	(#PCDATA) >
-
-<!ATTLIST internal_separators>
-
-<!--
-  range
-
-    Indicates a range of possible integer values.
-
-    Its attributes are:
-
-      min	The minimum value of the range (inclusive).
-      max	The maximum value of the range (inclusive).
--->
-
-<!ELEMENT range EMPTY>
-
-<!ATTLIST range
-	min	CDATA #REQUIRED
-	max	CDATA #REQUIRED >
-
-<!--
-  constraints
-
-    Provides a set of constraints on the values a property can take on.
--->
-
-<!ELEMENT constraints
-	( value*, range* ) >
-<!ATTLIST constraints>
-
-<!--
-  include_values
-
-    Includes an entire set of values in the choices block.
-
-    Its attributes are:
-
-	type    Either "constraints" or "values", indicating an
-		inclusion of all values allowed by the property's
-		constraints or all values for which there are
-		human-readable names and descriptions, respectively.
--->
-
-<!ELEMENT include_values EMPTY>
-
-<!ATTLIST include_values
-	type	( constraints | values ) #REQUIRED >
-
-<!--
-  choices
-
-    Provides a set of common choices for the values a property can take
-    on.  Useful in those cases where the possibilities are unenumerable
-    or merely inconveniently legion, and a manageable subset is desired
-    for presentation in a user interface.
--->
-
-<!ELEMENT choices
-	( value*, range*, include_values* ) >
-
-<!ATTLIST choices>
-
-<!--
-  prop_pattern
-
-
-    The prop_pattern describes one property of the enclosing property group
-    pattern.
-
-    Its attributes are:
-
-	name    The property's name.
-	type    The property's type.
-	required
-		If the property group is present, this property is required.
-
-	type can be omitted if required is false.
--->
-
-<!ELEMENT prop_pattern
-	( common_name?, description?, units?, visibility?, cardinality?,
-	  internal_separators?, values?, constraints?, choices? ) >
-
-<!ATTLIST prop_pattern
-	name		CDATA	#REQUIRED
-	type		( count | integer | opaque | host | hostname |
-			net_address | net_address_v4 | net_address_v6 | time |
-			astring | ustring | boolean | fmri | uri ) #IMPLIED
-	required	( true | false )	"false" >
-
-<!--
-  pg_pattern
-
-    The pg_pattern describes one property group.
-    Depending on the element's attributes, these descriptions may apply
-    to just the enclosing service/instance, instances of the enclosing
-    service, delegates of the service (assuming it is a restarter), or
-    all services.
-
-    Its attributes are:
-
-	name    The property group's name.  If not specified, it
-		matches all property groups with the specified type.
-	type    The property group's type.  If not specified, it
-		matches all property groups with the specified name.
-	required
-		If the property group is required.
-	target	The scope of the pattern, which may be all, delegate,
-		instance, or this.  'all' is reserved for framework use
-		and applies the template to all services on the system.
-		'delegate' is reserved for restarters, and means the
-		template applies to all services which use the restarter.
-		'this' would refer to the defining service or instance.
-		'instance' can only be used in a service's template block,
-		and means the definition applies to all instances of this
-		service.
-
--->
-
-<!ELEMENT pg_pattern
-	( common_name?, description?, prop_pattern* ) >
-
-<!ATTLIST pg_pattern
-	name		CDATA	""
-	type		CDATA	""
-	required	( true | false )	"false"
-	target		( this | instance | delegate | all )	"this" >
-
-<!--
-  template
-
-    The template contains a collection of metadata about the service.
-    It contains a localizable string that serves as a common,
-    human-readable name for the service.  (This name should be less than
-    60 characters in a single byte locale.)  The template may optionally
-    contain a longer localizable description of the service, a
-    collection of links to documentation, either in the form of manual
-    pages or in the form of URI specifications to external documentation
-    sources (such as docs.sun.com).
-
-    The template has no attributes.
--->
-<!ELEMENT template
-        ( common_name, description?, documentation?, pg_pattern* ) >
-
-<!ATTLIST template>
-
-<!-- Notification Parameters -->
-
-<!ELEMENT paramval EMPTY>
-
-<!ATTLIST paramval
-	name		CDATA #REQUIRED
-	value		CDATA #REQUIRED>
-
-<!ELEMENT parameter
-	( value_node* )>
-
-<!ATTLIST parameter
-	name		CDATA #REQUIRED>
-
-<!ELEMENT event EMPTY>
-
-<!ATTLIST event
-	value		CDATA #REQUIRED>
-
-<!ELEMENT type
-	( ( parameter | paramval )* )>
-
-<!ATTLIST type
-	name		CDATA #REQUIRED
-	active		( true | false ) "true" >
-
-<!--
-  notification parameters
-
-    This element sets the notification parameters for Software Events and
-    Fault Management problem lifecycle events.
--->
-
-<!ELEMENT notification_parameters
-	( event, type+ )>
-
-<!ATTLIST notification_parameters>
-
-<!-- Services and instances -->
-
-<!--
-  create_default_instance
-
-    A flag element indicating that an otherwise empty default instance
-    of this service (named "default") should be created at install, with
-    its enabled property set as given.
-
-    Its attribute is
-
-	enabled	[boolean] The initial value for the enabled state of
-		this instance.
--->
-
-<!ELEMENT create_default_instance EMPTY >
-
-<!ATTLIST create_default_instance
-	enabled		( true | false ) #REQUIRED >
-
-<!--
-  single_instance
-
-    A flag element stating that this service can only have a single
-    instance on a particular system.
--->
-
-<!ELEMENT single_instance EMPTY>
-
-<!ATTLIST single_instance>
-
-<!--
-  instance
-
-    The service instance is the object representing a software component
-    that will run on the system if enabled.  It contains an enabled
-    element, a set of dependencies on other services, potentially
-    customized methods or configuration data, an optional method
-    context, and a pointer to its restarter.  (If no restarter is
-    specified, the master restarter, svc.startd(1M), is assumed to be
-    responsible for the service.)
-
-    Its attributes are
-
-	name	The canonical name for this instance of the service.
-
-	enabled	[boolean] The initial value for the enabled state of
-		this instance.
--->
-
-<!ELEMENT instance
-	( restarter?, dependency*, dependent*, method_context?,
-	exec_method*, notification_parameters*, property_group*,
-	template? ) >
-
-<!ATTLIST instance
-	name		CDATA #REQUIRED
-	enabled		( true | false ) #REQUIRED >
-
-<!--
-  service
-
-    The service contains the set of instances defined by default for
-    this service, an optional method execution context, any default
-    methods, the template, and various restrictions or advice applicable
-    at installation.  The method execution context and template elements
-    are required for service_bundle documents with type "manifest", but
-    are optional for "profile" or "archive" documents.
-
-    Its attributes are
-
-	name	The canonical name for the service.
-
-	version	[integer] The integer version for this service.
-
-	type	Whether this service is a simple service, a delegated
-		restarter, or a milestone (a synthetic service that
-		collects a group of dependencies).
--->
-
-<!ELEMENT service
-	( create_default_instance?, single_instance?, restarter?,
-	dependency*, dependent*, method_context?, exec_method*,
-	notification_parameters*, property_group*, instance*,
-	stability?, template? ) >
-
-<!ATTLIST service
-	name		CDATA #REQUIRED
-	version		CDATA #REQUIRED
-	type		( service | restarter | milestone ) #REQUIRED >
-
-<!--
-  service_bundle
-
-    The bundle possesses two attributes:
-
-	type	How this file is to be understood by the framework (or
-		used in a non-framework compliant way). Standard types
-		are 'archive', 'manifest', and 'profile'.
-	
-	name	A name for the bundle.  Manifests should be named after
-		the package which delivered them; profiles should be
-		named after the "feature set nickname" they intend to
-		enable.
--->
-
-<!ELEMENT service_bundle
-	( service_bundle* | service* | xi:include* )>
-
-<!ATTLIST service_bundle
-	type		CDATA #REQUIRED
-	name		CDATA #REQUIRED>
