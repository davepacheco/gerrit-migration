commit 104def44c4eeabccace997a00b34c2f10f2b5ab3 (refs/changes/37/3137/1)
Author: Ryan Zezeski <rpz@joyent.com>
Date:   2017-12-22T17:07:22-07:00 (1 year, 10 months ago)
    
    OS-5326 SRS ring polling disable for VLANs

diff --git a/usr/src/uts/common/inet/ip/ip6_input.c b/usr/src/uts/common/inet/ip/ip6_input.c
index c7c241f944..5bd8693c8b 100644
--- a/usr/src/uts/common/inet/ip/ip6_input.c
+++ b/usr/src/uts/common/inet/ip/ip6_input.c
@@ -143,11 +143,8 @@ static void	ip_input_multicast_v6(ire_t *, mblk_t *, ip6_t *,
  * The ill will always be valid if this function is called directly from
  * the driver.
  *
- * If ip_input_v6() is called from GLDv3:
- *
- *   - This must be a non-VLAN IP stream.
- *   - 'mp' is either an untagged or a special priority-tagged packet.
- *   - Any VLAN tag that was in the MAC header has been stripped.
+ * If this chain is part of a VLAN stream then the VLAN tag is stripped
+ * from the MAC header before delivering the chain to this function.
  *
  * If the IP header in packet is not 32-bit aligned, every message in the
  * chain will be aligned before further operations. This is required on SPARC
diff --git a/usr/src/uts/common/inet/ip/ip_input.c b/usr/src/uts/common/inet/ip/ip_input.c
index 6aa70b014a..78d93ef2b0 100644
--- a/usr/src/uts/common/inet/ip/ip_input.c
+++ b/usr/src/uts/common/inet/ip/ip_input.c
@@ -146,11 +146,8 @@ static void	ip_input_multicast_v4(ire_t *, mblk_t *, ipha_t *,
  * The ill will always be valid if this function is called directly from
  * the driver.
  *
- * If ip_input() is called from GLDv3:
- *
- *   - This must be a non-VLAN IP stream.
- *   - 'mp' is either an untagged or a special priority-tagged packet.
- *   - Any VLAN tag that was in the MAC header has been stripped.
+ * If this chain is part of a VLAN stream then the VLAN tag is stripped
+ * from the MAC header before delivering the chain to this function.
  *
  * If the IP header in packet is not 32-bit aligned, every message in the
  * chain will be aligned before further operations. This is required on SPARC
diff --git a/usr/src/uts/common/io/dld/dld_proto.c b/usr/src/uts/common/io/dld/dld_proto.c
index 661d8b2f4f..fa87d1e458 100644
--- a/usr/src/uts/common/io/dld/dld_proto.c
+++ b/usr/src/uts/common/io/dld/dld_proto.c
@@ -1409,24 +1409,22 @@ dld_capab_direct(dld_str_t *dsp, void *data, uint_t flags)
 }
 
 /*
- * dld_capab_poll_enable()
+ * This function is misnamed. All polling and fanouts are run out of
+ * the the lower MAC in the case of VNICs and the MAC in case of NICs.
+ * The availability of Rx rings and promiscous mode is taken care of
+ * between the soft ring set (mac_srs), the Rx ring, and the SW
+ * classifier. Fanout, if necessary, is done by the soft rings that
+ * are part of the SRS. By default the SRS divvies up the packets
+ * based on protocol: TCP, UDP, or Other (OTH).
  *
- * This function is misnamed. All polling  and fanouts are run out of the
- * lower mac (in case of VNIC and the only mac in case of NICs). The
- * availability of Rx ring and promiscous mode is all taken care between
- * the soft ring set (mac_srs), the Rx ring, and S/W classifier. Any
- * fanout necessary is done by the soft rings that are part of the
- * mac_srs (by default mac_srs sends the packets up via a TCP and
- * non TCP soft ring).
- *
- * The mac_srs (or its associated soft rings) always store the ill_rx_ring
+ * The SRS (or its associated soft rings) always store the ill_rx_ring
  * (the cookie returned when they registered with IP during plumb) as their
  * 2nd argument which is passed up as mac_resource_handle_t. The upcall
  * function and 1st argument is what the caller registered when they
  * called mac_rx_classify_flow_add() to register the flow. For VNIC,
  * the function is vnic_rx and argument is vnic_t. For regular NIC
  * case, it mac_rx_default and mac_handle_t. As explained above, the
- * mac_srs (or its soft ring) will add the ill_rx_ring (mac_resource_handle_t)
+ * SRS (or its soft ring) will add the ill_rx_ring (mac_resource_handle_t)
  * from its stored 2nd argument.
  */
 static int
@@ -1439,11 +1437,11 @@ dld_capab_poll_enable(dld_str_t *dsp, dld_capab_poll_t *poll)
 		return (ENOTSUP);
 
 	/*
-	 * Enable client polling if and only if DLS bypass is possible.
-	 * Special cases like VLANs need DLS processing in the Rx data path.
-	 * In such a case we can neither allow the client (IP) to directly
-	 * poll the softring (since DLS processing hasn't been done) nor can
-	 * we allow DLS bypass.
+	 * Enable client polling if and only if DLS bypass is
+	 * possible. Some traffic requires DLS processing in the Rx
+	 * data path. In such a case we can neither allow the client
+	 * (IP) to directly poll the soft ring (since DLS processing
+	 * hasn't been done) nor can we allow DLS bypass.
 	 */
 	if (!mac_rx_bypass_set(dsp->ds_mch, dsp->ds_rx, dsp->ds_rx_arg))
 		return (ENOTSUP);
diff --git a/usr/src/uts/common/io/dls/dls.c b/usr/src/uts/common/io/dls/dls.c
index 0f8dbcb57a..f91f116e44 100644
--- a/usr/src/uts/common/io/dls/dls.c
+++ b/usr/src/uts/common/io/dls/dls.c
@@ -25,7 +25,7 @@
  */
 
 /*
- * Copyright 2016 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  */
 
 /*
@@ -171,16 +171,16 @@ dls_bind(dld_str_t *dsp, uint32_t sap)
 	/*
 	 * The MAC layer does the VLAN demultiplexing and will only pass up
 	 * untagged packets to non-promiscuous primary MAC clients. In order to
-	 * support the binding to the VLAN SAP which is required by DLPI, dls
+	 * support binding to the VLAN SAP, which is required by DLPI, DLS
 	 * needs to get a copy of all tagged packets when the client binds to
 	 * the VLAN SAP. We do this by registering a separate promiscuous
-	 * callback for each dls client binding to that SAP.
+	 * callback for each DLS client binding to that SAP.
 	 *
 	 * Note: even though there are two promiscuous handles in dld_str_t,
 	 * ds_mph is for the regular promiscuous mode, ds_vlan_mph is the handle
-	 * to receive VLAN pkt when promiscuous mode is not on. Only one of
-	 * them can be non-NULL at the same time, to avoid receiving dup copies
-	 * of pkts.
+	 * to receive VLAN traffic when promiscuous mode is not on. Only one of
+	 * them can be non-NULL at the same time, to avoid receiving duplicate
+	 * copies of packets.
 	 */
 	if (sap == ETHERTYPE_VLAN && dsp->ds_promisc == 0) {
 		int err;
@@ -709,8 +709,8 @@ dls_mac_active_set(dls_link_t *dlp)
 		/* request the primary MAC address */
 		if ((err = mac_unicast_add(dlp->dl_mch, NULL,
 		    MAC_UNICAST_PRIMARY | MAC_UNICAST_TAG_DISABLE |
-		    MAC_UNICAST_DISABLE_TX_VID_CHECK, &dlp->dl_mah, 0,
-		    &diag)) != 0) {
+		    MAC_UNICAST_DISABLE_TX_VID_CHECK, &dlp->dl_mah,
+		    VLAN_ID_NONE, &diag)) != 0) {
 			return (err);
 		}
 
diff --git a/usr/src/uts/common/io/dls/dls_link.c b/usr/src/uts/common/io/dls/dls_link.c
index 6c318b9752..9cf4d88f55 100644
--- a/usr/src/uts/common/io/dls/dls_link.c
+++ b/usr/src/uts/common/io/dls/dls_link.c
@@ -380,7 +380,16 @@ i_dls_link_rx(void *arg, mac_resource_handle_t mrh, mblk_t *mp,
 
 		vid = VLAN_ID(mhi.mhi_tci);
 
+		/*
+		 * When using a GLDv3 device and the client has only
+		 * one VLAN associated with it (which is the case for
+		 * any client that isn't sun4v vsw) then the VLAN tag
+		 * is stripped from the chain before passing it to
+		 * this function; and thus mhi_istagged will always be
+		 * false. See mac_rx_deliver().
+		 */
 		if (mhi.mhi_istagged) {
+
 			/*
 			 * If it is tagged traffic, send it upstream to
 			 * all dld_str_t which are attached to the physical
diff --git a/usr/src/uts/common/io/ixgbe/core/ixgbe_common.c b/usr/src/uts/common/io/ixgbe/core/ixgbe_common.c
index eb98709d14..44c511f1bd 100644
--- a/usr/src/uts/common/io/ixgbe/core/ixgbe_common.c
+++ b/usr/src/uts/common/io/ixgbe/core/ixgbe_common.c
@@ -2885,7 +2885,11 @@ static s32 ixgbe_negotiate_fc(struct ixgbe_hw *hw, u32 adv_reg, u32 lp_reg,
 		DEBUGOUT("Flow Control = RX PAUSE frames only.\n");
 	} else {
 		hw->fc.current_mode = ixgbe_fc_none;
-		DEBUGOUT("Flow Control = NONE.\n");
+		/*
+		 * RPZ Commented out to stop annoying logs. Will
+		 * reenable after testing is complete.
+		 */
+		/* DEBUGOUT("Flow Control = NONE.\n"); */
 	}
 	return IXGBE_SUCCESS;
 }
diff --git a/usr/src/uts/common/io/ixgbe/core/ixgbe_type.h b/usr/src/uts/common/io/ixgbe/core/ixgbe_type.h
index 45e8a7d029..ca47f96bf4 100644
--- a/usr/src/uts/common/io/ixgbe/core/ixgbe_type.h
+++ b/usr/src/uts/common/io/ixgbe/core/ixgbe_type.h
@@ -1669,6 +1669,7 @@ enum {
 #define IXGBE_VT_CTL_POOL_MASK		(0x3F << IXGBE_VT_CTL_POOL_SHIFT)
 
 /* VMOLR bitmasks */
+#define IXGBE_VMOLR_VPE		0x00800000 /* VLAN promisc */
 #define IXGBE_VMOLR_AUPE	0x01000000 /* accept untagged packets */
 #define IXGBE_VMOLR_ROMPE	0x02000000 /* accept packets in MTA tbl */
 #define IXGBE_VMOLR_ROPE	0x04000000 /* accept packets in UC tbl */
diff --git a/usr/src/uts/common/io/ixgbe/ixgbe_debug.c b/usr/src/uts/common/io/ixgbe/ixgbe_debug.c
index 1430817445..fc1658f15d 100644
--- a/usr/src/uts/common/io/ixgbe/ixgbe_debug.c
+++ b/usr/src/uts/common/io/ixgbe/ixgbe_debug.c
@@ -31,6 +31,8 @@
 #ifdef IXGBE_DEBUG
 extern ddi_device_acc_attr_t ixgbe_regs_acc_attr;
 
+static void ixgbe_dump_regs(void *);
+
 /*
  * Dump interrupt-related registers & structures
  */
@@ -43,6 +45,8 @@ ixgbe_dump_interrupt(void *adapter, char *tag)
 	uint32_t ivar, reg, hw_index;
 	int i, j;
 
+	ixgbe_dump_regs(adapter);
+
 	/*
 	 * interrupt control registers
 	 */
@@ -423,7 +427,7 @@ ixgbe_pci_dump(void *arg)
 /*
  * Dump registers
  */
-void
+static void
 ixgbe_dump_regs(void *adapter)
 {
 	ixgbe_t *ixgbe = (ixgbe_t *)adapter;
diff --git a/usr/src/uts/common/io/ixgbe/ixgbe_debug.h b/usr/src/uts/common/io/ixgbe/ixgbe_debug.h
index be5f1a00d1..3cb38fa308 100644
--- a/usr/src/uts/common/io/ixgbe/ixgbe_debug.h
+++ b/usr/src/uts/common/io/ixgbe/ixgbe_debug.h
@@ -39,9 +39,9 @@ extern "C" {
 #endif
 
 
-#ifdef DEBUG
+/* #ifdef DEBUG */
 #define	IXGBE_DEBUG
-#endif
+/* #endif */
 
 #ifdef IXGBE_DEBUG
 
diff --git a/usr/src/uts/common/io/ixgbe/ixgbe_main.c b/usr/src/uts/common/io/ixgbe/ixgbe_main.c
index 3ca88e4696..8a60531286 100644
--- a/usr/src/uts/common/io/ixgbe/ixgbe_main.c
+++ b/usr/src/uts/common/io/ixgbe/ixgbe_main.c
@@ -25,7 +25,7 @@
 
 /*
  * Copyright (c) 2008, 2010, Oracle and/or its affiliates. All rights reserved.
- * Copyright 2017, Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  * Copyright 2012 Nexenta Systems, Inc. All rights reserved.
  * Copyright (c) 2013 Saso Kiselkov. All rights reserved.
  * Copyright (c) 2013 OSN Online Service Nuernberg GmbH. All rights reserved.
@@ -34,6 +34,11 @@
 
 #include "ixgbe_sw.h"
 
+/*
+ * RPZ: Included for debugging print out until I finish testing.
+ */
+#include "ixgbe_debug.h"
+
 static char ixgbe_ident[] = "Intel 10Gb Ethernet";
 
 /*
@@ -67,6 +72,7 @@ static void ixgbe_setup_vmdq(ixgbe_t *);
 static void ixgbe_setup_vmdq_rss(ixgbe_t *);
 static void ixgbe_setup_rss_table(ixgbe_t *);
 static void ixgbe_init_unicst(ixgbe_t *);
+static void ixgbe_init_vlan(ixgbe_t *);
 static int ixgbe_unicst_find(ixgbe_t *, const uint8_t *);
 static void ixgbe_setup_multicst(ixgbe_t *);
 static void ixgbe_get_hw_state(ixgbe_t *);
@@ -113,6 +119,8 @@ static void ixgbe_intr_other_work(ixgbe_t *, uint32_t);
 static void ixgbe_get_driver_control(struct ixgbe_hw *);
 static int ixgbe_addmac(void *, const uint8_t *);
 static int ixgbe_remmac(void *, const uint8_t *);
+static int ixgbe_addvlan(mac_group_driver_t, uint16_t);
+static int ixgbe_remvlan(mac_group_driver_t, uint16_t);
 static void ixgbe_release_driver_control(struct ixgbe_hw *);
 
 static int ixgbe_attach(dev_info_t *, ddi_attach_cmd_t);
@@ -131,6 +139,8 @@ static int ixgbe_fm_error_cb(dev_info_t *dip, ddi_fm_error_t *err,
 static void ixgbe_fm_init(ixgbe_t *);
 static void ixgbe_fm_fini(ixgbe_t *);
 
+static int ixgbe_rpz_report(mac_group_driver_t, mac_report_t *);
+
 char *ixgbe_priv_props[] = {
 	"_tx_copy_thresh",
 	"_tx_recycle_thresh",
@@ -1454,6 +1464,7 @@ ixgbe_init(ixgbe_t *ixgbe)
 		goto init_fail;
 	}
 
+
 	/*
 	 * Read identifying information and place in devinfo.
 	 */
@@ -2518,6 +2529,13 @@ ixgbe_setup_rx(ixgbe_t *ixgbe)
 		break;
 	}
 
+	/*
+	 * Initialize VLAN SW and HW state if VLAN filtering is
+	 * enabled.
+	 */
+	if (ixgbe->vlft_enabled)
+		ixgbe_init_vlan(ixgbe);
+
 	/*
 	 * Enable the receive unit.  This must be done after filter
 	 * control is set in FCTRL. On 82598, we disable the descriptor monitor.
@@ -2831,7 +2849,7 @@ static void
 ixgbe_setup_vmdq(ixgbe_t *ixgbe)
 {
 	struct ixgbe_hw *hw = &ixgbe->hw;
-	uint32_t vmdctl, i, vtctl;
+	uint32_t vmdctl, i, vtctl, vlnctl;
 
 	/*
 	 * Setup the VMDq Control register, enable VMDq based on
@@ -2869,6 +2887,16 @@ ixgbe_setup_vmdq(ixgbe_t *ixgbe)
 		vtctl = IXGBE_VT_CTL_VT_ENABLE | IXGBE_VT_CTL_REPLEN;
 		IXGBE_WRITE_REG(hw, IXGBE_VT_CTL, vtctl);
 
+		/*
+		 * Setup VLNCTRL for VLAN filtering but do not enable
+		 * CFI filtering.
+		 */
+		vlnctl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+		vlnctl &=  IXGBE_VLNCTRL_VET;
+		vlnctl |= IXGBE_VLNCTRL_VFE;
+		IXGBE_WRITE_REG(hw, IXGBE_VLNCTRL, vlnctl);
+		ixgbe->vlft_enabled = B_TRUE;
+
 		/*
 		 * Enable receiving packets to all VFs
 		 */
@@ -2889,7 +2917,7 @@ ixgbe_setup_vmdq_rss(ixgbe_t *ixgbe)
 {
 	struct ixgbe_hw *hw = &ixgbe->hw;
 	uint32_t i, mrqc;
-	uint32_t vtctl, vmdctl;
+	uint32_t vtctl, vmdctl, vlnctl;
 
 	/*
 	 * Initialize RETA/ERETA table
@@ -2974,6 +3002,16 @@ ixgbe_setup_vmdq_rss(ixgbe_t *ixgbe)
 		vtctl = IXGBE_VT_CTL_VT_ENABLE | IXGBE_VT_CTL_REPLEN;
 		IXGBE_WRITE_REG(hw, IXGBE_VT_CTL, vtctl);
 
+		/*
+		 * Setup VLNCTRL for VLAN filtering but do not enable
+		 * CFI filtering.
+		 */
+		vlnctl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+		vlnctl &=  IXGBE_VLNCTRL_VET;
+		vlnctl |= IXGBE_VLNCTRL_VFE;
+		IXGBE_WRITE_REG(hw, IXGBE_VLNCTRL, vlnctl);
+		ixgbe->vlft_enabled = B_TRUE;
+
 		/*
 		 * Enable receiving packets to all VFs
 		 */
@@ -3144,6 +3182,67 @@ ixgbe_unicst_find(ixgbe_t *ixgbe, const uint8_t *mac_addr)
 	return (-1);
 }
 
+/*
+ * Initialize the VLAN SW and HW state both on initial start and
+ * restore the HW state to match the SW state during restart.
+ *
+ * It is assumed that num_rx_groups does not change across resets.
+ * Otherwise, the number of SW groups and HW groups would not match
+ * and breakage may ensue.
+ */
+void
+ixgbe_init_vlan(ixgbe_t *ixgbe)
+{
+	int ret;
+	uint_t slot, i;
+	ixgbe_vlft_t *vlft;
+
+	/*
+	 * If this device is stating for the first time then zero out
+	 * the SW state. The HW state was already cleared by the
+	 * common code.
+	 */
+	if (!ixgbe->vlft_init) {
+		ixgbe->vlft_total = MAX_NUM_VLAN_FILTERS;
+		ixgbe->vlft_avail = ixgbe->vlft_total;
+		for (i = 0; i < ixgbe->vlft_total; i++) {
+			bitset_init(&ixgbe->vlan_filt[i].vlft_groups);
+			bitset_resize(&ixgbe->vlan_filt[i].vlft_groups,
+			    ixgbe->num_rx_groups);
+		}
+
+		ixgbe->vlft_init = B_TRUE;
+		return;
+	}
+
+	ASSERT(ixgbe->vlft_init);
+
+	/*
+	 * Restore VLAN filters from the software state.
+	 */
+	for (slot = 0; slot < ixgbe->vlft_total; slot++) {
+		vlft = &ixgbe->vlan_filt[slot];
+		if (vlft->vlft_set == 1) {
+			for (i = 0; i < ixgbe->num_rx_groups; i++) {
+				if (bitset_in_set(&vlft->vlft_groups, i) != 0) {
+					ret = ixgbe_set_vfta(&ixgbe->hw,
+					    vlft->vlft_vid, i, B_TRUE);
+					/*
+					 * In order for this software
+					 * state to exist the hardware
+					 * must have accepted it at
+					 * some point -- therefore it
+					 * should still accept it on a
+					 * chip reset.
+					 */
+					VERIFY(ret == IXGBE_SUCCESS);
+				}
+			}
+		}
+	}
+
+}
+
 /*
  * ixgbe_multicst_add - Add a multicst address.
  */
@@ -6154,6 +6253,7 @@ ixgbe_fill_group(void *arg, mac_ring_type_t rtype, const int index,
     mac_group_info_t *infop, mac_group_handle_t gh)
 {
 	ixgbe_t *ixgbe = (ixgbe_t *)arg;
+	struct ixgbe_hw *hw = &ixgbe->hw;
 
 	switch (rtype) {
 	case MAC_RING_TYPE_RX: {
@@ -6167,6 +6267,21 @@ ixgbe_fill_group(void *arg, mac_ring_type_t rtype, const int index,
 		infop->mgi_stop = NULL;
 		infop->mgi_addmac = ixgbe_addmac;
 		infop->mgi_remmac = ixgbe_remmac;
+
+		if ((ixgbe->classify_mode == IXGBE_CLASSIFY_VMDQ ||
+		    ixgbe->classify_mode == IXGBE_CLASSIFY_VMDQ_RSS) &&
+		    (hw->mac.type == ixgbe_mac_82599EB ||
+		    hw->mac.type == ixgbe_mac_X540 ||
+		    hw->mac.type == ixgbe_mac_X550 ||
+		    hw->mac.type == ixgbe_mac_X550EM_x)) {
+			infop->mgi_addvlan = ixgbe_addvlan;
+			infop->mgi_remvlan = ixgbe_remvlan;
+		} else {
+			infop->mgi_addvlan = NULL;
+			infop->mgi_remvlan = NULL;
+		}
+
+		infop->mgi_report = ixgbe_rpz_report;
 		infop->mgi_count = (ixgbe->num_rx_rings / ixgbe->num_rx_groups);
 
 		break;
@@ -6266,6 +6381,220 @@ ixgbe_rx_ring_intr_disable(mac_intr_handle_t intrh)
 	return (0);
 }
 
+/*
+ * Add a VLAN ID filter to the Rx group.
+ *
+ * If there is a chip reset and the VLAN filter state is sparse then
+ * after the reset the HW and SW state will be equivalent but the
+ * slots won't match -- SW will still be sparse but HW will be packed.
+ * This doesn't affect the correct operation of the SW or HW, but it
+ * might confuse when comparing the two states during debugging.
+ */
+static int
+ixgbe_addvlan(mac_group_driver_t gdriver, uint16_t vid)
+{
+	ixgbe_rx_group_t	*rx_group = (ixgbe_rx_group_t *)gdriver;
+	ixgbe_t			*ixgbe = rx_group->ixgbe;
+	struct ixgbe_hw		*hw = &ixgbe->hw;
+	ixgbe_vlft_t		*vlft;
+	int			slot, ret;
+	u32			vlnctl;
+	u32                     vml2flt;
+
+	mutex_enter(&ixgbe->gen_lock);
+
+	if (ixgbe->ixgbe_state & IXGBE_SUSPENDED) {
+		mutex_exit(&ixgbe->gen_lock);
+		return (ECANCELED);
+	}
+
+	/*
+	 * Let's be completely sure VLAN filtering is enabled.
+	 */
+	VERIFY(ixgbe->vlft_enabled == B_TRUE);
+	vlnctl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+	VERIFY((vlnctl & IXGBE_VLNCTRL_VFE) != 0);
+
+	/*
+	 * VLAN filtering is enabled but we want to receive untagged
+	 * traffic on this group -- set the AUPE bit on the group and
+	 * leave the VLAN tables alone.
+	 */
+	if (vid == MAC_VLAN_UNTAGGED) {
+		vml2flt = IXGBE_READ_REG(hw, IXGBE_VMOLR(rx_group->index));
+		vml2flt |= IXGBE_VMOLR_AUPE;
+		IXGBE_WRITE_REG(hw, IXGBE_VMOLR(rx_group->index), vml2flt);
+		mutex_exit(&ixgbe->gen_lock);
+		return (0);
+	}
+
+	/*
+	 * Slot 0 is reserved for VID 0. Thus we can always add a
+	 * group to VID 0.
+	 */
+	if (vid == 0) {
+		vlft = &ixgbe->vlan_filt[0];
+		ret = ixgbe_set_vfta(hw, vid, rx_group->index, B_TRUE);
+		if (ret == IXGBE_SUCCESS) {
+			bitset_add(&vlft->vlft_groups, rx_group->index);
+			vlft->vlft_set = 1;
+			VERIFY(vlft->vlft_vid == 0);
+		}
+
+		if (ret == IXGBE_ERR_PARAM)
+			ret = EINVAL;
+
+		mutex_exit(&ixgbe->gen_lock);
+		return (ret);
+	}
+
+	/*
+	 * Search all slots for an existing filter on the VID. If no
+	 * filter exists then save the index of the first available
+	 * slot. Start at slot 1 because slot 0 is always VID 0.
+	 */
+	slot = -1;
+	for (uint_t i = 1; i < ixgbe->vlft_total; i++) {
+		vlft = &ixgbe->vlan_filt[i];
+		if (vid == vlft->vlft_vid && vlft->vlft_set == 1) {
+			ret = ixgbe_set_vfta(hw, vid, rx_group->index, B_TRUE);
+			if (ret == IXGBE_SUCCESS)
+				bitset_add(&vlft->vlft_groups, rx_group->index);
+
+			if (ret == IXGBE_ERR_PARAM)
+				ret = EINVAL;
+
+			mutex_exit(&ixgbe->gen_lock);
+			return (ret);
+		}
+
+		if (vlft->vlft_set != 1 && slot == -1)
+			slot = i;
+	}
+
+	/*
+	 * There is no existing filter. Create one and mark the slot
+	 * as active.
+	 */
+	if (slot != -1) {
+		VERIFY(slot < ixgbe->vlft_total);
+		vlft = &ixgbe->vlan_filt[slot];
+		ret = ixgbe_set_vfta(hw, vid, rx_group->index, B_TRUE);
+		if (ret == IXGBE_SUCCESS) {
+			bitset_add(&vlft->vlft_groups, rx_group->index);
+			vlft->vlft_vid = vid;
+			vlft->vlft_set = 1;
+			ixgbe->vlft_avail--;
+		}
+
+		if (ret == IXGBE_ERR_PARAM)
+			ret = EINVAL;
+
+		mutex_exit(&ixgbe->gen_lock);
+		return (ret);
+	}
+
+	/*
+	 * Either the VLAN filter doesn't already exist or we are out
+	 * of empty slots to palce a filter. In either case, we can't
+	 * get HW classification for this VLAN. However, we can enable
+	 * VLAN promsic mode and still receie packets on this group
+	 * using SW classifiction. This is preferable to moving the
+	 * client to the default group. We still return ENOSPC to the
+	 * consumer to indicate the lack of full HW classifiction.
+	 */
+	VERIFY(slot == -1);
+	vml2flt = IXGBE_READ_REG(hw, IXGBE_VMOLR(rx_group->index));
+	vml2flt |= IXGBE_VMOLR_VPE;
+	IXGBE_WRITE_REG(hw, IXGBE_VMOLR(rx_group->index), vml2flt);
+	mutex_exit(&ixgbe->gen_lock);
+	return (ENOSPC);
+}
+
+/*
+ * Remove the VLAN ID filter from the Rx group.
+ */
+static int
+ixgbe_remvlan(mac_group_driver_t gdriver, uint16_t vid)
+{
+	ixgbe_rx_group_t	*rx_group = (ixgbe_rx_group_t *)gdriver;
+	ixgbe_t			*ixgbe = rx_group->ixgbe;
+	struct ixgbe_hw		*hw = &ixgbe->hw;
+	ixgbe_vlft_t		*vlft;
+	uint_t			i;
+	int			ret;
+	u32                     vml2flt;
+
+	mutex_enter(&ixgbe->gen_lock);
+
+	if (ixgbe->ixgbe_state & IXGBE_SUSPENDED) {
+		mutex_exit(&ixgbe->gen_lock);
+		return (ECANCELED);
+	}
+
+	/*
+	 * VLAN filtering is enabled but we want to stop receiving
+	 * untagged traffic on this group -- clear the AUPE bit on the
+	 * group and leave the VLAN tables alone.
+	 */
+	if (vid == MAC_VLAN_UNTAGGED) {
+		vml2flt = IXGBE_READ_REG(hw, IXGBE_VMOLR(rx_group->index));
+		vml2flt &= ~IXGBE_VMOLR_AUPE;
+		IXGBE_WRITE_REG(hw, IXGBE_VMOLR(rx_group->index), vml2flt);
+		mutex_exit(&ixgbe->gen_lock);
+		return (0);
+	}
+
+	if (vid == VLAN_ID_NONE) {
+		vlft = &ixgbe->vlan_filt[VLAN_ID_NONE];
+		if (bitset_in_set(&vlft->vlft_groups, rx_group->index) == 0) {
+			mutex_exit(&ixgbe->gen_lock);
+			return (EINVAL);
+		} else {
+			ret = ixgbe_set_vfta(hw, vid, rx_group->index, B_FALSE);
+			if (ret != IXGBE_SUCCESS) {
+				mutex_exit(&ixgbe->gen_lock);
+				return (ret);
+			}
+			bitset_del(&vlft->vlft_groups, vid);
+		}
+
+		mutex_exit(&ixgbe->gen_lock);
+		return (IXGBE_SUCCESS);
+	}
+
+	for (i = 1; i < ixgbe->vlft_total; i++) {
+		vlft = &ixgbe->vlan_filt[i];
+		if (vlft->vlft_vid == vid && vlft->vlft_set == 1)
+			break;
+	}
+
+	if (i > ixgbe->vlft_total) {
+		mutex_exit(&ixgbe->gen_lock);
+		return (EINVAL);
+	}
+
+	ret = ixgbe_set_vfta(hw, vid, rx_group->index, B_FALSE);
+	if (ret != IXGBE_SUCCESS) {
+		mutex_exit(&ixgbe->gen_lock);
+		return (ret);
+	}
+
+	/*
+	 * The slot isn't available until there are no groups
+	 * interested in the VLAN.
+	 */
+	bitset_del(&vlft->vlft_groups, rx_group->index);
+	if (bitset_is_null(&vlft->vlft_groups) == 1) {
+		vlft->vlft_set = 0;
+		vlft->vlft_vid = 0;
+		ixgbe->vlft_avail++;
+	}
+
+	mutex_exit(&ixgbe->gen_lock);
+	return (IXGBE_SUCCESS);
+}
+
 /*
  * Add a mac address.
  */
@@ -6364,3 +6693,100 @@ ixgbe_remmac(void *arg, const uint8_t *mac_addr)
 
 	return (0);
 }
+
+/*
+ * Report:
+ *
+ * RAH/RAL
+ * MPSAR
+ * VFTA
+ * VFRE
+ * VLVF
+ * VLVFB
+ * VML2FLT
+ *
+ * This function reads the raw bytes of the various registers and
+ * fills out a report structure passed in by the consumer. The
+ * consumer can then use these bytes to build a human readable report
+ * for debugging purposes.
+ */
+static int
+ixgbe_rpz_report(mac_group_driver_t gdriver, mac_report_t *rp)
+{
+	ixgbe_rx_group_t *rx_group = (ixgbe_rx_group_t *)gdriver;
+	ixgbe_t *ixgbe = rx_group->ixgbe;
+	struct ixgbe_hw *hw = &ixgbe->hw;
+	uint_t i;
+
+	u32 rar_entries = hw->mac.num_rar_entries;
+
+	ixgbe_dump_interrupt(ixgbe, "rpz");
+
+	mutex_enter(&ixgbe->gen_lock);
+
+	rp->vlnctrl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+
+	rp->rar_entries = rar_entries;
+
+	/*
+	 * MAC address spans across RAL/RAH.
+	 */
+	for (i = 0; i < rar_entries; i++) {
+		/* ral/rah are u32 */
+		rp->ral[i] = IXGBE_READ_REG(hw, IXGBE_RAL(i));
+		rp->rah[i] = IXGBE_READ_REG(hw, IXGBE_RAH(i));
+	}
+
+	/*
+	 * MPSAR_LO is for pools 0-31, HI for 32-63
+	 */
+	for (i = 0; i < hw->mac.num_rar_entries; i++) {
+		rp->mpsar_lo[i] = IXGBE_READ_REG(hw, IXGBE_MPSAR_LO(i));
+		rp->mpsar_hi[i] = IXGBE_READ_REG(hw, IXGBE_MPSAR_HI(i));
+	}
+
+	/*
+	 * The VFTA is made up of 128 32-bit values which represent
+	 * the 4096 VIDs.
+	 */
+	for (i = 0; i < 128; i++) {
+		rp->vfta[i] = IXGBE_READ_REG(hw, IXGBE_VFTA(i));
+	}
+
+	/*
+	 * The VFRE is the VF Rx Enable. A bit per group.
+	 */
+	rp->vfre[0] = IXGBE_READ_REG(hw, IXGBE_VFRE(0));
+	rp->vfre[1] = IXGBE_READ_REG(hw, IXGBE_VFRE(1));
+
+	/*
+	 * Each VLVF slot (64 of them) holds a VID. When an incoming
+	 * packet's VID matches a VID in one of these slots then when
+	 * use the VLVFB value for the pool switching. The 0 slot is
+	 * always reserved for VID 0.
+	 */
+	for (i = 0; i < IXGBE_VLVF_ENTRIES; i++) {
+		rp->vlvf[i] = IXGBE_READ_REG(hw, IXGBE_VLVF(i));
+	}
+
+	/*
+	 * Each VLVF slot (64 of them) has a corresponding two byte
+	 * VLVFB slot; e.g.
+	 *
+	 *   VLVF[0] = VLVFB[0] | VLVFB[1]
+	 *   VLVF[1] = VLVFB[2] | VLVFB[3]
+	 */
+	for (i = 0; i < IXGBE_VLVF_ENTRIES; i++) {
+		rp->vlvfb[i * 2] = IXGBE_READ_REG(hw, IXGBE_VLVFB(i * 2));
+		rp->vlvfb[(i * 2) + 1] = IXGBE_READ_REG(hw,
+		    IXGBE_VLVFB((i * 2) + 1));
+	}
+
+	for (i = 0; i < 64; i++) {
+		rp->vml2flt[i] = IXGBE_READ_REG(hw, IXGBE_VMOLR(i));
+	}
+
+	mutex_exit(&ixgbe->gen_lock);
+
+	return (0);
+}
diff --git a/usr/src/uts/common/io/ixgbe/ixgbe_sw.h b/usr/src/uts/common/io/ixgbe/ixgbe_sw.h
index 12184751e4..2dbce03c9f 100644
--- a/usr/src/uts/common/io/ixgbe/ixgbe_sw.h
+++ b/usr/src/uts/common/io/ixgbe/ixgbe_sw.h
@@ -91,6 +91,8 @@ extern "C" {
 
 #define	MAX_NUM_UNICAST_ADDRESSES 	0x80
 #define	MAX_NUM_MULTICAST_ADDRESSES 	0x1000
+#define	MAX_NUM_VLAN_FILTERS		0x40
+
 #define	IXGBE_INTR_NONE			0
 #define	IXGBE_INTR_MSIX			1
 #define	IXGBE_INTR_MSI			2
@@ -387,6 +389,24 @@ typedef union ixgbe_ether_addr {
 	} mac;
 } ixgbe_ether_addr_t;
 
+/*
+ * TODO: should I remove the vlft prefix to make it consistent with the
+ * other structures?
+ */
+typedef struct ixgbe_vlft {
+	/*
+	 * The group index only applies when virtualization is on the
+	 * scene and we want to switch the incoming VLAN frame to a
+	 * specific group. The 82598 controller doesn't support this
+	 * feature and instead only the VLAN filtering applies.
+	 *
+	 * TODO: replace vlft_set with bitmap_is_null()?
+	 */
+	uint8_t		vlft_set; /* Is this entry active? */
+	bitset_t	vlft_groups; /* Groups paraticipating in this VLAN. */
+	uint16_t	vlft_vid;     /* The VLAN ID. */
+} ixgbe_vlft_t;
+
 typedef enum {
 	USE_NONE,
 	USE_COPY,
@@ -589,6 +609,7 @@ typedef struct ixgbe_rx_ring {
 
 	struct ixgbe		*ixgbe;		/* Pointer to ixgbe struct */
 } ixgbe_rx_ring_t;
+
 /*
  * Software Receive Ring Group
  */
@@ -715,6 +736,12 @@ typedef struct ixgbe {
 	uint32_t		mcast_count;
 	struct ether_addr	mcast_table[MAX_NUM_MULTICAST_ADDRESSES];
 
+	boolean_t		vlft_enabled; /* VLAN filtering enabled? */
+	boolean_t		vlft_init;    /* VLAN filtering initialized? */
+	uint16_t		vlft_avail;   /* Num VLAN filters avail */
+	uint16_t		vlft_total;   /* Total VLAN filters provided */
+	ixgbe_vlft_t		vlan_filt[MAX_NUM_VLAN_FILTERS];
+
 	ulong_t			sys_page_size;
 
 	boolean_t		link_check_complete;
diff --git a/usr/src/uts/common/io/mac/mac.c b/usr/src/uts/common/io/mac/mac.c
index 1fcc38fb54..304f872e5c 100644
--- a/usr/src/uts/common/io/mac/mac.c
+++ b/usr/src/uts/common/io/mac/mac.c
@@ -460,7 +460,7 @@ mac_init(void)
 	mac_logging_interval = 20;
 	mac_flow_log_enable = B_FALSE;
 	mac_link_log_enable = B_FALSE;
-	mac_logging_timer = 0;
+	mac_logging_timer = NULL;
 
 	/* Register to be notified of noteworthy pools events */
 	mac_pool_event_reg.pec_func =  mac_pool_event_cb;
@@ -1115,9 +1115,10 @@ mac_start(mac_handle_t mh)
 
 		if ((defgrp = MAC_DEFAULT_RX_GROUP(mip)) != NULL) {
 			/*
-			 * Start the default ring, since it will be needed
-			 * to receive broadcast and multicast traffic for
-			 * both primary and non-primary MAC clients.
+			 * Start the default group wich is responsible
+			 * for receiving broadcast and multicast
+			 * traffic for both primary and non-primary
+			 * MAC clients.
 			 */
 			ASSERT(defgrp->mrg_state == MAC_GROUP_STATE_REGISTERED);
 			err = mac_start_group_and_rings(defgrp);
@@ -1144,13 +1145,13 @@ mac_stop(mac_handle_t mh)
 	mac_impl_t	*mip = (mac_impl_t *)mh;
 	mac_group_t	*grp;
 
-	ASSERT(mip->mi_stop != NULL);
+	VERIFY(mip->mi_stop != NULL);
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
 
 	/*
 	 * Check whether the device is still needed.
 	 */
-	ASSERT(mip->mi_active != 0);
+	VERIFY(mip->mi_active != 0);
 	if (--mip->mi_active == 0) {
 		if ((grp = MAC_DEFAULT_RX_GROUP(mip)) != NULL) {
 			/*
@@ -1166,8 +1167,8 @@ mac_stop(mac_handle_t mh)
 			 * (since mac_bcast_add doesn't register itself
 			 * as a client) and group is in SHARED state.
 			 */
-			ASSERT(grp->mrg_state == MAC_GROUP_STATE_SHARED);
-			ASSERT(MAC_GROUP_NO_CLIENT(grp) &&
+			VERIFY(grp->mrg_state == MAC_GROUP_STATE_SHARED);
+			VERIFY(MAC_GROUP_NO_CLIENT(grp) &&
 			    mip->mi_nactiveclients == 0);
 			mac_stop_group_and_rings(grp);
 			mac_set_group_state(grp, MAC_GROUP_STATE_REGISTERED);
@@ -1729,6 +1730,19 @@ mac_hwgroup_remmac(mac_group_handle_t gh, const uint8_t *addr)
 	return (mac_group_remmac(group, addr));
 }
 
+/*
+ * Is all traffic on the group HW classified?
+ */
+boolean_t
+mac_group_hw_classified(mac_group_t *group)
+{
+	mac_client_impl_t *client = MAC_GROUP_ONLY_CLIENT(group);
+
+	return (group->mrg_state == MAC_GROUP_STATE_RESERVED &&
+	    client != NULL &&
+	    client->mci_unicast->ma_type == MAC_ADDRESS_TYPE_FULL_CLASSIFY);
+}
+
 /*
  * Set the RX group to be shared/reserved. Note that the group must be
  * started/stopped outside of this function.
@@ -2416,7 +2430,6 @@ mac_disable(mac_handle_t mh)
 /*
  * Called when the MAC instance has a non empty flow table, to de-multiplex
  * incoming packets to the right flow.
- * The MAC's rw lock is assumed held as a READER.
  */
 /* ARGSUSED */
 static mblk_t *
@@ -2427,14 +2440,14 @@ mac_rx_classify(mac_impl_t *mip, mac_resource_handle_t mrh, mblk_t *mp)
 	int		err;
 
 	/*
-	 * If the mac is a port of an aggregation, pass FLOW_IGNORE_VLAN
+	 * If the MAC is a port of an aggregation, pass FLOW_IGNORE_VLAN
 	 * to mac_flow_lookup() so that the VLAN packets can be successfully
 	 * passed to the non-VLAN aggregation flows.
 	 *
 	 * Note that there is possibly a race between this and
 	 * mac_unicast_remove/add() and VLAN packets could be incorrectly
-	 * classified to non-VLAN flows of non-aggregation mac clients. These
-	 * VLAN packets will be then filtered out by the mac module.
+	 * classified to non-VLAN flows of non-aggregation MAC clients. These
+	 * VLAN packets will be then filtered out by the MAC module.
 	 */
 	if ((mip->mi_state_flags & MIS_EXCLUSIVE) != 0)
 		flags |= FLOW_IGNORE_VLAN;
@@ -4077,11 +4090,12 @@ mac_init_rings(mac_impl_t *mip, mac_ring_type_t rtype)
 
 
 		/*
-		 * Driver must register group->mgi_addmac/remmac() for rx groups
-		 * to support multiple MAC addresses.
+		 * The driver must register some form of hardware MAC
+		 * filter in order for Rx groups to support multiple
+		 * MAC addresses.
 		 */
 		if (rtype == MAC_RING_TYPE_RX &&
-		    ((group_info.mgi_addmac == NULL) ||
+		    (group_info.mgi_addmac == NULL ||
 		    (group_info.mgi_remmac == NULL))) {
 			err = EINVAL;
 			goto bail;
@@ -4129,8 +4143,9 @@ mac_init_rings(mac_impl_t *mip, mac_ring_type_t rtype)
 
 		/* Update this group's status */
 		mac_set_group_state(group, MAC_GROUP_STATE_REGISTERED);
-	} else
+	} else {
 		group->mrg_rings = NULL;
+	}
 
 	ASSERT(ring_left == 0);
 
@@ -4319,6 +4334,30 @@ mac_free_rings(mac_impl_t *mip, mac_ring_type_t rtype)
 	kmem_free(groups, sizeof (mac_group_t) * (group_count + 1));
 }
 
+/*
+ * Associate the VLAN filter to the receive group.
+ */
+int
+mac_group_addvlan(mac_group_t *group, uint16_t vlan)
+{
+	VERIFY(group->mrg_type == MAC_RING_TYPE_RX);
+	VERIFY(group->mrg_info.mgi_addvlan != NULL);
+
+	return (group->mrg_info.mgi_addvlan(group->mrg_info.mgi_driver, vlan));
+}
+
+/*
+ * Dissociate the VLAN from the receive group.
+ */
+int
+mac_group_remvlan(mac_group_t *group, uint16_t vlan)
+{
+	VERIFY(group->mrg_type == MAC_RING_TYPE_RX);
+	VERIFY(group->mrg_info.mgi_remvlan != NULL);
+
+	return (group->mrg_info.mgi_remvlan(group->mrg_info.mgi_driver, vlan));
+}
+
 /*
  * Associate a MAC address with a receive group.
  *
@@ -4335,8 +4374,8 @@ mac_free_rings(mac_impl_t *mip, mac_ring_type_t rtype)
 int
 mac_group_addmac(mac_group_t *group, const uint8_t *addr)
 {
-	ASSERT(group->mrg_type == MAC_RING_TYPE_RX);
-	ASSERT(group->mrg_info.mgi_addmac != NULL);
+	VERIFY(group->mrg_type == MAC_RING_TYPE_RX);
+	VERIFY(group->mrg_info.mgi_addmac != NULL);
 
 	return (group->mrg_info.mgi_addmac(group->mrg_info.mgi_driver, addr));
 }
@@ -4347,8 +4386,8 @@ mac_group_addmac(mac_group_t *group, const uint8_t *addr)
 int
 mac_group_remmac(mac_group_t *group, const uint8_t *addr)
 {
-	ASSERT(group->mrg_type == MAC_RING_TYPE_RX);
-	ASSERT(group->mrg_info.mgi_remmac != NULL);
+	VERIFY(group->mrg_type == MAC_RING_TYPE_RX);
+	VERIFY(group->mrg_info.mgi_remmac != NULL);
 
 	return (group->mrg_info.mgi_remmac(group->mrg_info.mgi_driver, addr));
 }
@@ -4523,28 +4562,19 @@ i_mac_group_add_ring(mac_group_t *group, mac_ring_t *ring, int index)
 	switch (ring->mr_type) {
 	case MAC_RING_TYPE_RX:
 		/*
-		 * Setup SRS on top of the new ring if the group is
-		 * reserved for someones exclusive use.
+		 * Setup an SRS on top of the new ring if the group is
+		 * fully HW classified.
 		 */
-		if (group->mrg_state == MAC_GROUP_STATE_RESERVED) {
-			mac_client_impl_t *mcip;
-
-			mcip = MAC_GROUP_ONLY_CLIENT(group);
-			/*
-			 * Even though this group is reserved we migth still
-			 * have multiple clients, i.e a VLAN shares the
-			 * group with the primary mac client.
-			 */
-			if (mcip != NULL) {
-				flent = mcip->mci_flent;
-				ASSERT(flent->fe_rx_srs_cnt > 0);
-				mac_rx_srs_group_setup(mcip, flent, SRST_LINK);
-				mac_fanout_setup(mcip, flent,
-				    MCIP_RESOURCE_PROPS(mcip), mac_rx_deliver,
-				    mcip, NULL, NULL);
-			} else {
-				ring->mr_classify_type = MAC_SW_CLASSIFIER;
-			}
+		if (mac_group_hw_classified(group)) {
+			mac_client_impl_t *mcip =  MAC_GROUP_ONLY_CLIENT(group);
+			VERIFY(mcip != NULL);
+			flent = mcip->mci_flent;
+			VERIFY(flent->fe_rx_srs_cnt > 0);
+			mac_rx_srs_group_setup(mcip, flent, SRST_LINK);
+			mac_fanout_setup(mcip, flent, MCIP_RESOURCE_PROPS(mcip),
+			    mac_rx_deliver, mcip, NULL, NULL);
+		} else {
+			ring->mr_classify_type = MAC_SW_CLASSIFIER;
 		}
 		break;
 	case MAC_RING_TYPE_TX:
@@ -4570,7 +4600,7 @@ i_mac_group_add_ring(mac_group_t *group, mac_ring_t *ring, int index)
 
 			mcip = mgcp->mgc_client;
 			flent = mcip->mci_flent;
-			is_aggr = (mcip->mci_state_flags & MCIS_IS_AGGR);
+			is_aggr = (mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT);
 			mac_srs = MCIP_TX_SRS(mcip);
 			tx = &mac_srs->srs_tx;
 			mac_tx_client_quiesce((mac_client_handle_t)mcip);
@@ -4714,7 +4744,7 @@ i_mac_group_rem_ring(mac_group_t *group, mac_ring_t *ring,
 
 			mcip = MAC_GROUP_ONLY_CLIENT(group);
 			ASSERT(mcip != NULL);
-			ASSERT(mcip->mci_state_flags & MCIS_IS_AGGR);
+			ASSERT(mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT);
 			mac_srs = MCIP_TX_SRS(mcip);
 			ASSERT(mac_srs->srs_tx.st_mode == SRS_TX_AGGR ||
 			    mac_srs->srs_tx.st_mode == SRS_TX_BW_AGGR);
@@ -4922,12 +4952,12 @@ mac_free_macaddr(mac_address_t *map)
 	mac_impl_t *mip = map->ma_mip;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
-	ASSERT(mip->mi_addresses != NULL);
-
-	map = mac_find_macaddr(mip, map->ma_addr);
+	VERIFY(mip->mi_addresses != NULL);
 
-	ASSERT(map != NULL);
-	ASSERT(map->ma_nusers == 0);
+	VERIFY(map == mac_find_macaddr(mip, map->ma_addr));
+	VERIFY(map != NULL);
+	VERIFY(map->ma_nusers == 0);
+	VERIFY(map->ma_vlans == NULL);
 
 	if (map == mip->mi_addresses) {
 		mip->mi_addresses = map->ma_next;
@@ -4943,132 +4973,275 @@ mac_free_macaddr(mac_address_t *map)
 	kmem_free(map, sizeof (mac_address_t));
 }
 
+static mac_vlan_t *
+mac_find_vlan(mac_address_t *map, uint16_t vid)
+{
+	mac_vlan_t *mvp;
+	vid = MAC_VLAN_UNTAGGED_VID(vid);
+
+	for (mvp = map->ma_vlans; mvp != NULL; mvp = mvp->mv_next)
+		if (mvp->mv_vid == vid)
+			return (mvp);
+
+	return (NULL);
+}
+
+static mac_vlan_t *
+mac_add_vlan(mac_address_t *map, uint16_t vid)
+{
+	mac_vlan_t *mvp;
+
+	/*
+	 * We should never add the same {addr, VID} tuple more
+	 * than once, but let's be sure.
+	 */
+	for (mvp = map->ma_vlans; mvp != NULL; mvp = mvp->mv_next)
+		VERIFY(mvp->mv_vid != MAC_VLAN_UNTAGGED_VID(vid));
+
+	/* Add the VLAN to the head of the VLAN list. */
+	mvp = kmem_zalloc(sizeof (mac_vlan_t), KM_SLEEP);
+	mvp->mv_vid = MAC_VLAN_UNTAGGED_VID(vid);
+	mvp->mv_next = map->ma_vlans;
+	map->ma_vlans = mvp;
+
+	return (mvp);
+}
+
+static void
+mac_rem_vlan(mac_address_t *map, mac_vlan_t *mvp)
+{
+	mac_vlan_t *pre;
+
+	if (map->ma_vlans == mvp) {
+		map->ma_vlans = mvp->mv_next;
+	} else {
+		pre = map->ma_vlans;
+		while (pre->mv_next != mvp)
+			pre = pre->mv_next;
+		pre->mv_next = mvp->mv_next;
+	}
+
+	kmem_free(mvp, sizeof (mac_vlan_t));
+}
+
 /*
- * Add a MAC address reference for a client. If the desired MAC address
- * exists, add a reference to it. Otherwise, add the new address by adding
- * it to a reserved group or setting promiscuous mode. Won't try different
- * group is the group is non-NULL, so the caller must explictly share
- * default group when needed.
- *
- * Note, the primary MAC address is initialized at registration time, so
- * to add it to default group only need to activate it if its reference
- * count is still zero. Also, some drivers may not have advertised RINGS
- * capability.
+ * Create a new mac_address_t if this is the first use of the address
+ * or add a VID to an existing address. In either case, the
+ * mac_address_t acts as a list of {addr, VID} tuples where each tuple
+ * shares the same addr. If group is non-NULL then attempt to program
+ * the MAC's HW filters for this group. Otherwise, if group is NULL,
+ * then the MAC has no rings and there is nothing to program.
  */
 int
-mac_add_macaddr(mac_impl_t *mip, mac_group_t *group, uint8_t *mac_addr,
-    boolean_t use_hw)
+mac_add_macaddr_vlan(mac_impl_t *mip, mac_group_t *group, uint8_t *addr,
+    uint16_t vid, uint_t flags)
 {
-	mac_address_t *map;
-	int err = 0;
-	boolean_t allocated_map = B_FALSE;
+	mac_address_t	*map;
+	mac_vlan_t	*mvp;
+	int		err = 0;
+	boolean_t	allocated_map = B_FALSE;
+	int		err2;
+	boolean_t	use_hw = (flags & MAC_GROUP_UNICAST_HW) != 0;
+	boolean_t	hw_mac;
+	boolean_t	hw_vlan;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
 
-	map = mac_find_macaddr(mip, mac_addr);
+	map = mac_find_macaddr(mip, addr);
 
 	/*
-	 * If the new MAC address has not been added. Allocate a new one
-	 * and set it up.
+	 * If this is the first use of this MAC address then allocate
+	 * and initialize a new structure.
 	 */
 	if (map == NULL) {
 		map = kmem_zalloc(sizeof (mac_address_t), KM_SLEEP);
 		map->ma_len = mip->mi_type->mt_addr_length;
-		bcopy(mac_addr, map->ma_addr, map->ma_len);
+		bcopy(addr, map->ma_addr, map->ma_len);
 		map->ma_nusers = 0;
 		map->ma_group = group;
 		map->ma_mip = mip;
 
-		/* add the new MAC address to the head of the address list */
+		/* Add the new MAC address to the head of the address list. */
 		map->ma_next = mip->mi_addresses;
 		mip->mi_addresses = map;
 
 		allocated_map = B_TRUE;
 	}
 
-	ASSERT(map->ma_group == NULL || map->ma_group == group);
+	VERIFY(map->ma_group == NULL || map->ma_group == group);
 	if (map->ma_group == NULL)
 		map->ma_group = group;
 
+	mvp = mac_add_vlan(map, vid);
+
+	/*
+	 * Set the VLAN HW filter if:
+	 *
+	 * o the MAC's VLAN HW filter is enabled, and
+	 * o the address does not currently rely on promisc mode.
+	 *
+	 * This is called even when the client specifies an untagged
+	 * address (VLAN_ID_NONE) because some MAC providers require
+	 * setting additional bits to accept untagged traffic when
+	 * VLAN HW filtering is enabled.
+	 */
+	if (group != NULL && group->mrg_info.mgi_addvlan != NULL &&
+	    map->ma_type != MAC_ADDRESS_TYPE_PROMISC) {
+		err = mac_group_addvlan(group, mvp->mv_vid);
+		hw_vlan = (err == 0);
+
+		/*
+		 * Either we had a VLAN filter slot or we didn't. Any
+		 * other error results in failure.
+		 */
+		if (err != 0 && err != ENOSPC)
+			goto bail;
+
+		/*
+		 * If this is not the first VLAN to be added to this
+		 * address and we are out of VLAN HW filters then mark
+		 * the address as only partially classified.
+		 */
+		if (map->ma_nusers > 0 && err == ENOSPC)
+			map->ma_type = MAC_ADDRESS_TYPE_PART_CLASSIFY;
+	}
+
+	VERIFY(map->ma_nusers >= 0);
+
 	/*
-	 * If the MAC address is already in use, simply account for the
-	 * new client.
+	 * If this MAC address already has a HW filter then simply
+	 * increment the counter.
 	 */
 	if (map->ma_nusers++ > 0)
 		return (0);
 
+	/*
+	 * All logic from here on out is executed during initial
+	 * creation only.
+	 */
+	VERIFY(map->ma_nusers == 1);
+
 	/*
 	 * Activate this MAC address by adding it to the reserved group.
 	 */
 	if (group != NULL) {
-		err = mac_group_addmac(group, (const uint8_t *)mac_addr);
-		if (err == 0) {
-			map->ma_type = MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED;
+		/* ECANCELED, ENOSPC */
+		err = mac_group_addmac(group, (const uint8_t *)addr);
+
+		if (err == ECANCELED) {
+			map->ma_nusers--;
+			goto bail;
+		}
+
+		hw_mac = (err == 0);
+	}
+
+	/*
+	 * Consider the type HW classified if all available HW filters
+	 * we successful.
+	 */
+	if (group != NULL && group->mrg_info.mgi_addvlan != NULL) {
+		if (hw_vlan && hw_mac) {
+			map->ma_type = MAC_ADDRESS_TYPE_FULL_CLASSIFY;
+			return (0);
+		} else if (!hw_vlan && hw_mac) {
+			map->ma_type = MAC_ADDRESS_TYPE_PART_CLASSIFY;
+			return (0);
+		}
+	} else if (group != NULL) {
+		if (hw_mac) {
+			map->ma_type = MAC_ADDRESS_TYPE_FULL_CLASSIFY;
 			return (0);
 		}
 	}
 
 	/*
 	 * The MAC address addition failed. If the client requires a
-	 * hardware classified MAC address, fail the operation.
+	 * hardware classified MAC address, fail the operation. This
+	 * feature is only used by sun4v vsw.
 	 */
-	if (use_hw) {
+	if (use_hw && !hw_mac) {
 		err = ENOSPC;
+		map->ma_nusers--;
 		goto bail;
 	}
 
 	/*
-	 * Try promiscuous mode.
-	 *
-	 * For drivers that don't advertise RINGS capability, do
-	 * nothing for the primary address.
+	 * If we reach this point then either the MAC doesn't have
+	 * RINGS capability or we are out of MAC address HW filters.
+	 * In any case we must put the MAC into promiscuous mode.
+	 */
+	VERIFY(group == NULL || !hw_mac);
+
+	/*
+	 * The one exception is the factory MAC address. A non-RINGS
+	 * driver filters the factory address by default. We only need
+	 * to set promsic mode for a non-factory address.
 	 */
 	if ((group == NULL) &&
 	    (bcmp(map->ma_addr, mip->mi_addr, map->ma_len) == 0)) {
-		map->ma_type = MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED;
+		map->ma_type = MAC_ADDRESS_TYPE_FULL_CLASSIFY;
 		return (0);
 	}
 
 	/*
-	 * Enable promiscuous mode in order to receive traffic
-	 * to the new MAC address.
+	 * Enable promiscuous mode in order to receive traffic to the
+	 * new MAC address. All existing HW filters still send their
+	 * traffic to their respective group/SRSes. But with promisc
+	 * enabled all unknown traffic is delivered to the default
+	 * group where it is SW classified via mac_rx_classify().
 	 */
 	if ((err = i_mac_promisc_set(mip, B_TRUE)) == 0) {
-		map->ma_type = MAC_ADDRESS_TYPE_UNICAST_PROMISC;
+		map->ma_type = MAC_ADDRESS_TYPE_PROMISC;
 		return (0);
 	}
 
-	/*
-	 * Free the MAC address that could not be added. Don't free
-	 * a pre-existing address, it could have been the entry
-	 * for the primary MAC address which was pre-allocated by
-	 * mac_init_macaddr(), and which must remain on the list.
-	 */
 bail:
-	map->ma_nusers--;
+	if (hw_vlan) {
+		err2 = mac_group_remvlan(group, mvp->mv_vid);
+		VERIFY(err2 == 0 || err2 == ECANCELED);
+	}
+
+	mac_rem_vlan(map, mvp);
+
 	if (allocated_map)
 		mac_free_macaddr(map);
+
 	return (err);
 }
 
-/*
- * Remove a reference to a MAC address. This may cause to remove the MAC
- * address from an associated group or to turn off promiscuous mode.
- * The caller needs to handle the failure properly.
- */
 int
-mac_remove_macaddr(mac_address_t *map)
+mac_remove_macaddr_vlan(mac_address_t *map, uint16_t vid)
 {
-	mac_impl_t *mip = map->ma_mip;
-	int err = 0;
+	mac_vlan_t	*mvp;
+	mac_address_t	*tmap;
+	mac_impl_t	*mip = map->ma_mip;
+	mac_group_t	*group = map->ma_group;
+	int		err = 0;
+	boolean_t	all_hw = B_TRUE;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
+	VERIFY(map == mac_find_macaddr(mip, map->ma_addr));
+	mvp = mac_find_vlan(map, vid);
+	VERIFY(mvp != NULL);
+
+	if (group != NULL &&
+	    map->ma_type == MAC_ADDRESS_TYPE_FULL_CLASSIFY &&
+	    group->mrg_info.mgi_remvlan != NULL &&
+	    ((err = mac_group_remvlan(group, mvp->mv_vid)) != 0))
+		return (err);
 
-	ASSERT(map == mac_find_macaddr(mip, map->ma_addr));
+	mac_rem_vlan(map, mvp);
 
 	/*
 	 * If it's not the last client using this MAC address, only update
 	 * the MAC clients count.
+	 *
+	 * XXX There could be transition from PART -> FULL, but it's
+	 * not strictly a bug to not include that logic since no other
+	 * part of the system can really act this type of change (i.e.
+	 * by moving the client from the default group to a reserved
+	 * group).
 	 */
 	if (--map->ma_nusers > 0)
 		return (0);
@@ -5079,28 +5252,61 @@ mac_remove_macaddr(mac_address_t *map)
 	 * if it was enabled for the MAC address.
 	 */
 	switch (map->ma_type) {
-	case MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED:
+	case MAC_ADDRESS_TYPE_FULL_CLASSIFY:
 		/*
 		 * Don't free the preset primary address for drivers that
 		 * don't advertise RINGS capability.
 		 */
-		if (map->ma_group == NULL)
+		if (group == NULL)
 			return (0);
 
-		err = mac_group_remmac(map->ma_group, map->ma_addr);
-		if (err == 0)
-			map->ma_group = NULL;
+		if ((err = mac_group_remmac(group, map->ma_addr)) != 0) {
+			mvp = mac_add_vlan(map, vid);
+
+			/*
+			 * If we fail to remove the MAC address HW
+			 * filter but then also fail to re-add the
+			 * VLAN HW filter then we are in a busted
+			 * state and should just crash.
+			 */
+			if (group->mrg_info.mgi_addvlan != NULL &&
+			    map->ma_type == MAC_ADDRESS_TYPE_FULL_CLASSIFY)
+				VERIFY0(mac_group_addvlan(group, mvp->mv_vid));
+
+			return (err);
+		}
+
+		map->ma_group = NULL;
+		break;
+	case MAC_ADDRESS_TYPE_PART_CLASSIFY:
+		/*
+		 * Don't free the preset primary address for drivers that
+		 * don't advertise RINGS capability.
+		 */
+		if (group == NULL)
+			return (0);
+
+		if((err = mac_group_remmac(group, map->ma_addr)) != 0)
+			return (err);
+
+		map->ma_group = NULL;
 		break;
-	case MAC_ADDRESS_TYPE_UNICAST_PROMISC:
-		err = i_mac_promisc_set(mip, B_FALSE);
+	case MAC_ADDRESS_TYPE_PROMISC:
+		for (tmap = mip->mi_addresses; tmap != NULL;
+		     tmap = tmap->ma_next)
+			all_hw = (tmap->ma_type != MAC_ADDRESS_TYPE_PROMISC);
+
+		/*
+		 * If all MAC addresses have HW classification then
+		 * disable global promsic on the MAC.
+		 */
+		if (all_hw)
+			err = i_mac_promisc_set(mip, B_FALSE);
 		break;
 	default:
-		ASSERT(B_FALSE);
+		VERIFY(B_FALSE);
 	}
 
-	if (err != 0)
-		return (err);
-
 	/*
 	 * We created MAC address for the primary one at registration, so we
 	 * won't free it here. mac_fini_macaddr() will take care of it.
@@ -5122,10 +5328,11 @@ mac_update_macaddr(mac_address_t *map, uint8_t *mac_addr)
 	int err = 0;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
-	ASSERT(mac_find_macaddr(mip, mac_addr) == NULL);
+	VERIFY(mac_find_macaddr(mip, mac_addr) == NULL);
 
 	switch (map->ma_type) {
-	case MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED:
+	case MAC_ADDRESS_TYPE_FULL_CLASSIFY:
+	case MAC_ADDRESS_TYPE_PART_CLASSIFY:
 		/*
 		 * Update the primary address for drivers that are not
 		 * RINGS capable.
@@ -5163,7 +5370,7 @@ mac_update_macaddr(mac_address_t *map, uint8_t *mac_addr)
 			(void) mac_group_addmac(map->ma_group, map->ma_addr);
 
 		break;
-	case MAC_ADDRESS_TYPE_UNICAST_PROMISC:
+	case MAC_ADDRESS_TYPE_PROMISC:
 		/*
 		 * Need to do nothing more if in promiscuous mode.
 		 */
@@ -5229,7 +5436,7 @@ mac_init_macaddr(mac_impl_t *mip)
 	 * primary address must work after registration.
 	 */
 	if (mip->mi_rx_groups == NULL)
-		map->ma_type = MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED;
+		map->ma_type = MAC_ADDRESS_TYPE_FULL_CLASSIFY;
 
 	map->ma_mip = mip;
 
@@ -5252,8 +5459,8 @@ mac_fini_macaddr(mac_impl_t *mip)
 	 * If mi_addresses is initialized, there should be exactly one
 	 * entry left on the list with no users.
 	 */
-	ASSERT(map->ma_nusers == 0);
-	ASSERT(map->ma_next == NULL);
+	VERIFY(map->ma_nusers == 0);
+	VERIFY(map->ma_next == NULL);
 
 	kmem_free(map, sizeof (mac_address_t));
 	mip->mi_addresses = NULL;
@@ -5815,7 +6022,7 @@ mac_stop_logusage(mac_logtype_t type)
 	mod_hash_walk(i_mac_impl_hash, i_mac_fastpath_walker, &estate);
 
 	(void) untimeout(mac_logging_timer);
-	mac_logging_timer = 0;
+	mac_logging_timer = NULL;
 
 	/* Write log entries for each mac_impl in the list */
 	i_mac_log_info(&net_log_list, &lstate);
@@ -6298,7 +6505,6 @@ mac_group_add_client(mac_group_t *grp, mac_client_impl_t *mcip)
 	mgcp->mgc_client = mcip;
 	mgcp->mgc_next = grp->mrg_clients;
 	grp->mrg_clients = mgcp;
-
 }
 
 void
@@ -6312,15 +6518,13 @@ mac_group_remove_client(mac_group_t *grp, mac_client_impl_t *mcip)
 			break;
 	}
 
-	ASSERT(mgcp != NULL);
+	VERIFY(mgcp != NULL);
 
 	*pprev = mgcp->mgc_next;
 	kmem_free(mgcp, sizeof (mac_grp_client_t));
 }
 
 /*
- * mac_reserve_rx_group()
- *
  * Finds an available group and exclusively reserves it for a client.
  * The group is chosen to suit the flow's resource controls (bandwidth and
  * fanout requirements) and the address type.
@@ -6354,18 +6558,20 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 	isprimary = mcip->mci_flent->fe_type & FLOW_PRIMARY_MAC;
 
 	/*
-	 * Check if a group already has this mac address (case of VLANs)
+	 * Check if a group already has this MAC address (case of VLANs)
 	 * unless we are moving this MAC client from one group to another.
 	 */
 	if (!move && (map = mac_find_macaddr(mip, mac_addr)) != NULL) {
 		if (map->ma_group != NULL)
 			return (map->ma_group);
 	}
+
 	if (mip->mi_rx_groups == NULL || mip->mi_rx_group_count == 0)
 		return (NULL);
+
 	/*
-	 * If exclusive open, return NULL which will enable the
-	 * caller to use the default group.
+	 * If this client is requesting exclusive MAC access then
+	 * return NULL to ensure the client uses the default group.
 	 */
 	if (mcip->mci_state_flags & MCIS_EXCLUSIVE)
 		return (NULL);
@@ -6375,6 +6581,7 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 	    mip->mi_rx_group_type == MAC_GROUP_TYPE_DYNAMIC) {
 		mrp->mrp_nrxrings = 1;
 	}
+
 	/*
 	 * For static grouping we allow only specifying rings=0 and
 	 * unspecified
@@ -6448,17 +6655,15 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 		 */
 		if (grp->mrg_state >= MAC_GROUP_STATE_RESERVED) {
 			/*
-			 * If the primary/donor group is not the default
-			 * group, don't bother looking for a candidate group.
-			 * If we don't have enough rings we will check
-			 * if the primary group can be vacated.
+			 * If the donor group is not the default
+			 * group, don't bother looking for a candidate
+			 * group. If we don't have enough rings we
+			 * will check if the primary group can be
+			 * vacated.
 			 */
 			if (candidate_grp == NULL &&
 			    donorgrp == MAC_DEFAULT_RX_GROUP(mip)) {
-				ASSERT(!MAC_GROUP_NO_CLIENT(grp));
-				gclient = MAC_GROUP_ONLY_CLIENT(grp);
-				if (gclient == NULL)
-					gclient = mac_get_grp_primary(grp);
+				gclient = grp->mrg_clients->mgc_client;
 				ASSERT(gclient != NULL);
 				gmrp = MCIP_RESOURCE_PROPS(gclient);
 				if (gclient->mci_share == NULL &&
@@ -6528,6 +6733,7 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 		 */
 		mac_stop_group(grp);
 	}
+
 	/* We didn't find an exclusive group for this MAC client */
 	if (i >= mip->mi_rx_group_count) {
 
@@ -6535,12 +6741,12 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 			return (NULL);
 
 		/*
-		 * If we found a candidate group then we switch the
-		 * MAC client from the candidate_group to the default
-		 * group and give the group to this MAC client. If
-		 * we didn't find a candidate_group, check if the
-		 * primary is in its own group and if it can make way
-		 * for this MAC client.
+		 * If we found a candidate group then move the
+		 * existing MAC client from the candidate_group to the
+		 * default group and give the candidate_group to the
+		 * new MAC client. If we didn't find a candidate
+		 * group, then check if the primary is in its own
+		 * group and if it can make way for this MAC client.
 		 */
 		if (candidate_grp == NULL &&
 		    donorgrp != MAC_DEFAULT_RX_GROUP(mip) &&
@@ -6551,15 +6757,15 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 			boolean_t	prim_grp = B_FALSE;
 
 			/*
-			 * Switch the MAC client from the candidate group
-			 * to the default group.. If this group was the
-			 * donor group, then after the switch we need
-			 * to update the donor group too.
+			 * Switch the existing MAC client from the
+			 * candidate group to the default group. If
+			 * the candidate group is the donor group,
+			 * then after the switch we need to update the
+			 * donor group too.
 			 */
 			grp = candidate_grp;
-			gclient = MAC_GROUP_ONLY_CLIENT(grp);
-			if (gclient == NULL)
-				gclient = mac_get_grp_primary(grp);
+			gclient = grp->mrg_clients->mgc_client;
+			ASSERT(gclient != NULL);
 			if (grp == mip->mi_rx_donor_grp)
 				prim_grp = B_TRUE;
 			if (mac_rx_switch_group(gclient, grp,
@@ -6572,7 +6778,6 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 				donorgrp = MAC_DEFAULT_RX_GROUP(mip);
 			}
 
-
 			/*
 			 * Now give this group with the required rings
 			 * to this MAC client.
@@ -6620,10 +6825,10 @@ mac_reserve_rx_group(mac_client_impl_t *mcip, uint8_t *mac_addr, boolean_t move)
 /*
  * mac_rx_release_group()
  *
- * This is called when there are no clients left for the group.
- * The group is stopped and marked MAC_GROUP_STATE_REGISTERED,
- * and if it is a non default group, the shares are removed and
- * all rings are assigned back to default group.
+ * Release the group when it has no remaining clients. The group is
+ * stopped and its shares are removed and all rings are assigned back
+ * to default group. This should never be called against the default
+ * group.
  */
 void
 mac_release_rx_group(mac_client_impl_t *mcip, mac_group_t *group)
@@ -6631,7 +6836,8 @@ mac_release_rx_group(mac_client_impl_t *mcip, mac_group_t *group)
 	mac_impl_t		*mip = mcip->mci_mip;
 	mac_ring_t		*ring;
 
-	ASSERT(group != MAC_DEFAULT_RX_GROUP(mip));
+	VERIFY(group != MAC_DEFAULT_RX_GROUP(mip));
+	VERIFY(MAC_GROUP_NO_CLIENT(group));
 
 	if (mip->mi_rx_donor_grp == group)
 		mip->mi_rx_donor_grp = MAC_DEFAULT_RX_GROUP(mip);
@@ -6683,44 +6889,90 @@ mac_release_rx_group(mac_client_impl_t *mcip, mac_group_t *group)
 }
 
 /*
- * When we move the primary's mac address between groups, we need to also
- * take all the clients sharing the same mac address along with it (VLANs)
- * We remove the mac address for such clients from the group after quiescing
- * them. When we add the mac address we restart the client. Note that
- * the primary's mac address is removed from the group after all the
- * other clients sharing the address are removed. Similarly, the primary's
- * mac address is added before all the other client's mac address are
- * added. While grp is the group where the clients reside, tgrp is
- * the group where the addresses have to be added.
+ *
+ * Move all clients sharing the same MAC address (maddr) as the client
+ * mcip. This scenario should only occur when VLANs are on the scene.
+ *
+ * 1. One or more VLANs share the MAC address of the primary client;
+ *    VLANs created via dladm create-vlan.
+ *
+ * 2. Two or more VLAN VNICs (or one untagged client along with one or
+ *    more VLAN clients) share the same MAC address which is not the
+ *    primary MAC address. These are clients created via dladm
+ *    create-vnic.
+ *
+ * This function is used to move all clients, except for mcip, from
+ * the source group (grp) to the target group (tgrp). The move is done
+ * over two calls in conjunction with logic found in
+ * mac_rx_move_macaddr().
  */
 static void
-mac_rx_move_macaddr_prim(mac_client_impl_t *mcip, mac_group_t *grp,
+mac_rx_move_macaddr_multi(mac_client_impl_t *mcip, mac_group_t *grp,
     mac_group_t *tgrp, uint8_t *maddr, boolean_t add)
 {
 	mac_impl_t		*mip = mcip->mci_mip;
 	mac_grp_client_t	*mgcp = grp->mrg_clients;
 	mac_client_impl_t	*gmcip;
-	boolean_t		prim;
+	uint16_t		vid = VLAN_ID_NONE;
+	flow_desc_t		fdesc;
+	mac_unicast_impl_t	*muip;
+	uint_t			flags = 0;
+
+	flags &= (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0 ?
+	    MAC_GROUP_UNICAST_HW : 0;
 
-	prim = (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0;
+	VERIFY(maddr != NULL);
 
 	/*
 	 * If the clients are in a non-default group, we just have to
-	 * walk the group's client list. If it is in the default group
-	 * (which will be shared by other clients as well, we need to
-	 * check if the unicast address matches mcip's unicast.
+	 * walk the group's client list. If they are in the default
+	 * group, which is shared with other clients as well, we need
+	 * to check if the unicast address matches mcip's unicast.
 	 */
 	while (mgcp != NULL) {
 		gmcip = mgcp->mgc_client;
+		mac_flow_get_desc(gmcip->mci_flent, &fdesc);
+
 		if (gmcip != mcip &&
 		    (grp != MAC_DEFAULT_RX_GROUP(mip) ||
-		    mcip->mci_unicast == gmcip->mci_unicast)) {
+		    bcmp(maddr, fdesc.fd_dst_mac, fdesc.fd_mac_len) == 0)) {
+			VERIFY0(bcmp(maddr, fdesc.fd_dst_mac,
+			    fdesc.fd_mac_len));
+
 			if (!add) {
 				mac_rx_client_quiesce(
 				    (mac_client_handle_t)gmcip);
-				(void) mac_remove_macaddr(mcip->mci_unicast);
+				vid = i_mac_flow_vid(gmcip->mci_flent);
+				VERIFY0(mac_remove_macaddr_vlan(
+					    gmcip->mci_unicast, vid));
+				gmcip->mci_unicast = NULL;
+				rw_enter(&gmcip->mci_rw_lock, RW_WRITER);
+				for (muip = gmcip->mci_unicast_list;
+				     muip != NULL; muip = muip->mui_next)
+					muip->mui_map = NULL;
+				rw_exit(&gmcip->mci_rw_lock);
 			} else {
-				(void) mac_add_macaddr(mip, tgrp, maddr, prim);
+				/*
+				 * The only time there should be more
+				 * than one flow entry is if sun4v vsw
+				 * is in play; and we don't support HW
+				 * VLAN classifiction in that case.
+				 */
+				if (gmcip->mci_nflents == 1)
+					vid = i_mac_flow_vid(gmcip->mci_flent);
+
+				VERIFY0(mac_add_macaddr_vlan(mip, tgrp, maddr,
+					vid, flags));
+				gmcip->mci_unicast =
+				    mac_find_macaddr(mip, maddr);
+
+				VERIFY(gmcip->mci_unicast != NULL);
+				rw_enter(&gmcip->mci_rw_lock, RW_WRITER);
+				for (muip = gmcip->mci_unicast_list;
+				     muip != NULL; muip = muip->mui_next)
+					muip->mui_map = gmcip->mci_unicast;
+				rw_exit(&gmcip->mci_rw_lock);
+
 				mac_rx_client_restart(
 				    (mac_client_handle_t)gmcip);
 			}
@@ -6729,7 +6981,6 @@ mac_rx_move_macaddr_prim(mac_client_impl_t *mcip, mac_group_t *grp,
 	}
 }
 
-
 /*
  * Move the MAC address from fgrp to tgrp. If this is the primary client,
  * we need to take any VLANs etc. together too.
@@ -6741,56 +6992,95 @@ mac_rx_move_macaddr(mac_client_impl_t *mcip, mac_group_t *fgrp,
 	mac_impl_t		*mip = mcip->mci_mip;
 	uint8_t			maddr[MAXMACADDRLEN];
 	int			err = 0;
-	boolean_t		prim;
 	boolean_t		multiclnt = B_FALSE;
+	uint16_t		vid;
+	mac_unicast_impl_t	*muip;
+	uint_t			flags = 0;
 
 	mac_rx_client_quiesce((mac_client_handle_t)mcip);
-	ASSERT(mcip->mci_unicast != NULL);
+	VERIFY(mcip->mci_unicast != NULL);
 	bcopy(mcip->mci_unicast->ma_addr, maddr, mcip->mci_unicast->ma_len);
 
-	prim = (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0;
-	if (mcip->mci_unicast->ma_nusers > 1) {
-		mac_rx_move_macaddr_prim(mcip, fgrp, NULL, maddr, B_FALSE);
+	/*
+	 * Does the client require MAC address hardware classifiction?
+	 */
+	flags &= (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0 ?
+	    MAC_GROUP_UNICAST_HW : 0;
+	vid = i_mac_flow_vid(mcip->mci_flent);
+
+	/*
+	 * If multiple clients share them same MAC address then first
+	 * move all the clients besides mcip.
+	 */
+	if (mac_check_macaddr_shared(mcip->mci_unicast)) {
+		mac_rx_move_macaddr_multi(mcip, fgrp, NULL, maddr, B_FALSE);
 		multiclnt = B_TRUE;
 	}
-	ASSERT(mcip->mci_unicast->ma_nusers == 1);
-	err = mac_remove_macaddr(mcip->mci_unicast);
+
+	/*
+	 * At this point only one client should have a
+	 * reference to the MAC address. Remove the MAC addr from the
+	 * group.
+	 */
+	VERIFY(!mac_check_macaddr_shared(mcip->mci_unicast));
+	err = mac_remove_macaddr_vlan(mcip->mci_unicast, vid);
+
 	if (err != 0) {
 		mac_rx_client_restart((mac_client_handle_t)mcip);
 		if (multiclnt) {
-			mac_rx_move_macaddr_prim(mcip, fgrp, fgrp, maddr,
+			mac_rx_move_macaddr_multi(mcip, fgrp, fgrp, maddr,
 			    B_TRUE);
 		}
 		return (err);
 	}
+
+	/*
+	 * If this isn't the primary MAC address then the
+	 * mac_address_t has been freed by the last call to
+	 * mac_remove_macaddr_vlan(). In any case, NULL the reference
+	 * to avoid a dangling pointer.
+	 */
+	mcip->mci_unicast = NULL;
+	rw_enter(&mcip->mci_rw_lock, RW_WRITER);
+	for (muip = mcip->mci_unicast_list; muip != NULL; muip = muip->mui_next)
+		muip->mui_map = NULL;
+	rw_exit(&mcip->mci_rw_lock);
+
 	/*
-	 * Program the H/W Classifier first, if this fails we need
-	 * not proceed with the other stuff.
+	 * Program the H/W Classifier first, if this fails we need not
+	 * proceed with the other stuff.
 	 */
-	if ((err = mac_add_macaddr(mip, tgrp, maddr, prim)) != 0) {
+	if ((err = mac_add_macaddr_vlan(mip, tgrp, maddr, vid, flags)) != 0) {
 		/* Revert back the H/W Classifier */
-		if ((err = mac_add_macaddr(mip, fgrp, maddr, prim)) != 0) {
-			/*
-			 * This should not fail now since it worked earlier,
-			 * should we panic?
-			 */
+		err = mac_add_macaddr_vlan(mip, fgrp, maddr, vid, flags);
+		if (err != 0) {
 			cmn_err(CE_WARN,
 			    "mac_rx_switch_group: switching %p back"
 			    " to group %p failed!!", (void *)mcip,
 			    (void *)fgrp);
 		}
+
 		mac_rx_client_restart((mac_client_handle_t)mcip);
 		if (multiclnt) {
-			mac_rx_move_macaddr_prim(mcip, fgrp, fgrp, maddr,
+			mac_rx_move_macaddr_multi(mcip, fgrp, fgrp, maddr,
 			    B_TRUE);
 		}
+
 		return (err);
 	}
+
+	/*
+	 * Get a reference to the new mac_address_t and update the
+	 * client's reference. Then restart the client and add the
+	 * other clients of this MAC addr (if they exsit).
+	 */
 	mcip->mci_unicast = mac_find_macaddr(mip, maddr);
+
 	mac_rx_client_restart((mac_client_handle_t)mcip);
 	if (multiclnt)
-		mac_rx_move_macaddr_prim(mcip, fgrp, tgrp, maddr, B_TRUE);
-	return (err);
+		mac_rx_move_macaddr_multi(mcip, fgrp, tgrp, maddr, B_TRUE);
+
+	return (0);
 }
 
 /*
@@ -6811,19 +7101,34 @@ mac_rx_switch_group(mac_client_impl_t *mcip, mac_group_t *fgrp,
 	mac_impl_t		*mip = mcip->mci_mip;
 	mac_grp_client_t	*mgcp;
 
-	ASSERT(fgrp == mcip->mci_flent->fe_rx_ring_group);
+	VERIFY(fgrp == mcip->mci_flent->fe_rx_ring_group);
 
 	if ((err = mac_rx_move_macaddr(mcip, fgrp, tgrp)) != 0)
 		return (err);
 
 	/*
-	 * The group might be reserved, but SRSs may not be set up, e.g.
-	 * primary and its vlans using a reserved group.
+	 * If the group is marked as reserved and in use by a single
+	 * client then there is an SRS to teardown.
 	 */
 	if (fgrp->mrg_state == MAC_GROUP_STATE_RESERVED &&
 	    MAC_GROUP_ONLY_CLIENT(fgrp) != NULL) {
 		mac_rx_srs_group_teardown(mcip->mci_flent, B_TRUE);
 	}
+
+	/*
+	 * If we are moving the client from a non-default group then
+	 * we know that any additional clients on this group all
+	 * shared the same MAC address. Since we moved the MAC address
+	 * filter we need to move these clients too.
+	 *
+	 * If we are moving the client from the default group and its
+	 * MAC address has VLAN clients then we must move those
+	 * clients as well.
+	 *
+	 * In both cases the idea is the same: we moved the MAC
+	 * address filter to the tgrp, so we must move all clients
+	 * using that MAC address to tgrp as well.
+	 */
 	if (fgrp != MAC_DEFAULT_RX_GROUP(mip)) {
 		mgcp = fgrp->mrg_clients;
 		while (mgcp != NULL) {
@@ -6834,20 +7139,21 @@ mac_rx_switch_group(mac_client_impl_t *mcip, mac_group_t *fgrp,
 			gmcip->mci_flent->fe_rx_ring_group = tgrp;
 		}
 		mac_release_rx_group(mcip, fgrp);
-		ASSERT(MAC_GROUP_NO_CLIENT(fgrp));
+		VERIFY(MAC_GROUP_NO_CLIENT(fgrp));
 		mac_set_group_state(fgrp, MAC_GROUP_STATE_REGISTERED);
 	} else {
 		mac_group_remove_client(fgrp, mcip);
 		mac_group_add_client(tgrp, mcip);
 		mcip->mci_flent->fe_rx_ring_group = tgrp;
+
 		/*
 		 * If there are other clients (VLANs) sharing this address
-		 * we should be here only for the primary.
+		 * then move them too.
 		 */
-		if (mcip->mci_unicast->ma_nusers > 1) {
+		if (mac_check_macaddr_shared(mcip->mci_unicast)) {
 			/*
 			 * We need to move all the clients that are using
-			 * this h/w address.
+			 * this MAC address.
 			 */
 			mgcp = fgrp->mrg_clients;
 			while (mgcp != NULL) {
@@ -6861,22 +7167,26 @@ mac_rx_switch_group(mac_client_impl_t *mcip, mac_group_t *fgrp,
 				}
 			}
 		}
+
 		/*
-		 * The default group will still take the multicast,
-		 * broadcast traffic etc., so it won't go to
+		 * The default group still handles multicast and
+		 * broadcast traffic; it won't transition to
 		 * MAC_GROUP_STATE_REGISTERED.
 		 */
 		if (fgrp->mrg_state == MAC_GROUP_STATE_RESERVED)
 			mac_rx_group_unmark(fgrp, MR_CONDEMNED);
 		mac_set_group_state(fgrp, MAC_GROUP_STATE_SHARED);
 	}
+
 	next_state = mac_group_next_state(tgrp, &group_only_mcip,
 	    MAC_DEFAULT_RX_GROUP(mip), B_TRUE);
 	mac_set_group_state(tgrp, next_state);
+
 	/*
-	 * If the destination group is reserved, setup the SRSs etc.
+	 * If the destination group is fully HW classfied then setup
+	 * the SRSes. Otherwise make sure to use SW classification.
 	 */
-	if (tgrp->mrg_state == MAC_GROUP_STATE_RESERVED) {
+	if (mac_group_hw_classified(tgrp)) {
 		mac_rx_srs_group_setup(mcip, mcip->mci_flent, SRST_LINK);
 		mac_fanout_setup(mcip, mcip->mci_flent,
 		    MCIP_RESOURCE_PROPS(mcip), mac_rx_deliver, mcip, NULL,
@@ -6885,6 +7195,7 @@ mac_rx_switch_group(mac_client_impl_t *mcip, mac_group_t *fgrp,
 	} else {
 		mac_rx_switch_grp_to_sw(tgrp);
 	}
+
 	return (0);
 }
 
@@ -6915,6 +7226,7 @@ mac_reserve_tx_group(mac_client_impl_t *mcip, boolean_t move)
 	boolean_t		isprimary;
 
 	isprimary = mcip->mci_flent->fe_type & FLOW_PRIMARY_MAC;
+
 	/*
 	 * When we come here for a VLAN on the primary (dladm create-vlan),
 	 * we need to pair it along with the primary (to keep it consistent
@@ -6995,9 +7307,8 @@ mac_reserve_tx_group(mac_client_impl_t *mcip, boolean_t move)
 			 */
 			if (grp->mrg_state == MAC_GROUP_STATE_RESERVED &&
 			    candidate_grp == NULL) {
-				gclient = MAC_GROUP_ONLY_CLIENT(grp);
-				if (gclient == NULL)
-					gclient = mac_get_grp_primary(grp);
+				gclient = grp->mrg_clients->mgc_client;
+				ASSERT(gclient != NULL);
 				gmrp = MCIP_RESOURCE_PROPS(gclient);
 				if (gclient->mci_share == NULL &&
 				    (gmrp->mrp_mask & MRP_TX_RINGS) == 0 &&
@@ -7038,9 +7349,8 @@ mac_reserve_tx_group(mac_client_impl_t *mcip, boolean_t move)
 			 * to the default group.
 			 */
 			grp = candidate_grp;
-			gclient = MAC_GROUP_ONLY_CLIENT(grp);
-			if (gclient == NULL)
-				gclient = mac_get_grp_primary(grp);
+			gclient = grp->mrg_clients->mgc_client;
+			ASSERT(gclient != NULL);
 			mac_tx_client_quiesce((mac_client_handle_t)gclient);
 			mac_tx_switch_group(gclient, grp, defgrp);
 			mac_tx_client_restart((mac_client_handle_t)gclient);
@@ -7208,7 +7518,7 @@ mac_tx_switch_group(mac_client_impl_t *mcip, mac_group_t *fgrp,
 		 */
 		mac_group_remove_client(fgrp, mcip);
 		mac_tx_dismantle_soft_rings(fgrp, flent);
-		if (mcip->mci_unicast->ma_nusers > 1) {
+		if (mac_check_macaddr_shared(mcip->mci_unicast)) {
 			mgcp = fgrp->mrg_clients;
 			while (mgcp != NULL) {
 				gmcip = mgcp->mgc_client;
@@ -7454,7 +7764,7 @@ mac_no_active(mac_handle_t mh)
  * changes and update the mac_resource_props_t for the VLAN's client.
  * We need to do this since we don't support setting these properties
  * on the primary's VLAN clients, but the VLAN clients have to
- * follow the primary w.r.t the rings property;
+ * follow the primary w.r.t the rings property.
  */
 void
 mac_set_prim_vlan_rings(mac_impl_t  *mip, mac_resource_props_t *mrp)
@@ -7525,9 +7835,11 @@ mac_group_ring_modify(mac_client_impl_t *mcip, mac_group_t *group,
 	 * the specified number of rings.
 	 */
 	if (rx_group) {
+		VERIFY(mip->mi_rx_group_type == MAC_GROUP_TYPE_DYNAMIC);
 		ringcnt = (mrp->mrp_mask & MRP_RXRINGS_UNSPEC) ? 1:
 		    mrp->mrp_nrxrings;
 	} else {
+		VERIFY(mip->mi_tx_group_type == MAC_GROUP_TYPE_DYNAMIC);
 		ringcnt = (mrp->mrp_mask & MRP_TXRINGS_UNSPEC) ? 1:
 		    mrp->mrp_ntxrings;
 	}
@@ -7603,9 +7915,7 @@ mac_group_ring_modify(mac_client_impl_t *mcip, mac_group_t *group,
 				    MAC_GROUP_STATE_RESERVED) {
 					continue;
 				}
-				mcip = MAC_GROUP_ONLY_CLIENT(tgrp);
-				if (mcip == NULL)
-					mcip = mac_get_grp_primary(tgrp);
+				mcip = tgrp->mrg_clients->mgc_client;
 				ASSERT(mcip != NULL);
 				mrp = MCIP_RESOURCE_PROPS(mcip);
 				if ((mrp->mrp_mask & MRP_RX_RINGS) != 0)
@@ -7624,9 +7934,8 @@ mac_group_ring_modify(mac_client_impl_t *mcip, mac_group_t *group,
 				    MAC_GROUP_STATE_RESERVED) {
 					continue;
 				}
-				mcip = MAC_GROUP_ONLY_CLIENT(tgrp);
-				if (mcip == NULL)
-					mcip = mac_get_grp_primary(tgrp);
+				mcip = tgrp->mrg_clients->mgc_client;
+				ASSERT(mcip != NULL);
 				mrp = MCIP_RESOURCE_PROPS(mcip);
 				if ((mrp->mrp_mask & MRP_TX_RINGS) != 0)
 					continue;
@@ -7899,10 +8208,10 @@ mac_pool_event_cb(pool_event_t what, poolid_t id, void *arg)
  * Set effective rings property. This could be called from datapath_setup/
  * datapath_teardown or set-linkprop.
  * If the group is reserved we just go ahead and set the effective rings.
- * Additionally, for TX this could mean the default  group has lost/gained
+ * Additionally, for TX this could mean the default group has lost/gained
  * some rings, so if the default group is reserved, we need to adjust the
  * effective rings for the default group clients. For RX, if we are working
- * with the non-default group, we just need * to reset the effective props
+ * with the non-default group, we just need to reset the effective props
  * for the default group clients.
  */
 void
diff --git a/usr/src/uts/common/io/mac/mac_client.c b/usr/src/uts/common/io/mac/mac_client.c
index 491bdee43a..a7de2ca75c 100644
--- a/usr/src/uts/common/io/mac/mac_client.c
+++ b/usr/src/uts/common/io/mac/mac_client.c
@@ -21,7 +21,7 @@
 
 /*
  * Copyright (c) 2008, 2010, Oracle and/or its affiliates. All rights reserved.
- * Copyright 2015, Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  * Copyright 2017 RackTop Systems.
  */
 
@@ -865,9 +865,12 @@ mac_unicast_update_client_flow(mac_client_impl_t *mcip)
 	mac_protect_update_mac_token(mcip);
 
 	/*
-	 * A MAC client could have one MAC address but multiple
-	 * VLANs. In that case update the flow entries corresponding
-	 * to all VLANs of the MAC client.
+	 * When there are multiple VLANs sharing the same MAC address
+	 * each gets its own MAC client, except when running on sun4v
+	 * vsw. In that case the mci_flent_list is used to place
+	 * multiple VLAN flows on one MAC client. If we ever get rid
+	 * of vsw then this code can go. But until then, we need to
+	 * update all flow entries.
 	 */
 	for (flent = mcip->mci_flent_list; flent != NULL;
 	    flent = flent->fe_client_next) {
@@ -1025,13 +1028,13 @@ mac_unicast_primary_set(mac_handle_t mh, const uint8_t *addr)
 		return (0);
 	}
 
-	if (mac_find_macaddr(mip, (uint8_t *)addr) != 0) {
+	if (mac_find_macaddr(mip, (uint8_t *)addr) != NULL) {
 		i_mac_perim_exit(mip);
 		return (EBUSY);
 	}
 
 	map = mac_find_macaddr(mip, mip->mi_addr);
-	ASSERT(map != NULL);
+	VERIFY(map != NULL);
 
 	/*
 	 * Update the MAC address.
@@ -1040,12 +1043,13 @@ mac_unicast_primary_set(mac_handle_t mh, const uint8_t *addr)
 		mac_capab_aggr_t aggr_cap;
 
 		/*
-		 * If the mac is an aggregation, other than the unicast
+		 * If the MAC is an aggregation, other than the unicast
 		 * addresses programming, aggr must be informed about this
-		 * primary unicst address change to change its mac address
+		 * primary unicst address change to change its MAC address
 		 * policy to be user-specified.
 		 */
-		ASSERT(map->ma_type == MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED);
+		ASSERT(map->ma_type == MAC_ADDRESS_TYPE_FULL_CLASSIFY ||
+		    map->ma_type == MAC_ADDRESS_TYPE_PART_CLASSIFY);
 		VERIFY(i_mac_capab_get(mh, MAC_CAPAB_AGGR, &aggr_cap));
 		err = aggr_cap.mca_unicst(mip->mi_driver, addr);
 		if (err == 0)
@@ -1374,7 +1378,7 @@ mac_client_open(mac_handle_t mh, mac_client_handle_t *mchp, char *name,
 		mcip->mci_state_flags |= MCIS_IS_AGGR_PORT;
 
 	if (mip->mi_state_flags & MIS_IS_AGGR)
-		mcip->mci_state_flags |= MCIS_IS_AGGR;
+		mcip->mci_state_flags |= MCIS_IS_AGGR_CLIENT;
 
 	if ((flags & MAC_OPEN_FLAGS_USE_DATALINK_NAME) != 0) {
 		datalink_id_t	linkid;
@@ -1539,7 +1543,8 @@ mac_client_close(mac_client_handle_t mch, uint16_t flags)
 }
 
 /*
- * Set the rx bypass receive callback.
+ * Set the Rx bypass receive callback and return B_TRUE. Return
+ * B_FALSE if it's not possible to enable bypass.
  */
 boolean_t
 mac_rx_bypass_set(mac_client_handle_t mch, mac_direct_rx_t rx_fn, void *arg1)
@@ -1550,11 +1555,11 @@ mac_rx_bypass_set(mac_client_handle_t mch, mac_direct_rx_t rx_fn, void *arg1)
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
 
 	/*
-	 * If the mac_client is a VLAN, we should not do DLS bypass and
-	 * instead let the packets come up via mac_rx_deliver so the vlan
-	 * header can be stripped.
+	 * If the client has more than one VLAN then process packets
+	 * through DLS. This should happen only when sun4v vsw is on
+	 * the scene.
 	 */
-	if (mcip->mci_nvids > 0)
+	if (mcip->mci_nvids > 1)
 		return (B_FALSE);
 
 	/*
@@ -1612,7 +1617,7 @@ mac_rx_set(mac_client_handle_t mch, mac_rx_t rx_fn, void *arg)
 	 * make sure any secondary macs on the vnic are updated as well.
 	 */
 	if (umip != NULL) {
-		ASSERT((umip->mi_state_flags & MIS_IS_VNIC) != 0);
+		VERIFY((umip->mi_state_flags & MIS_IS_VNIC) != 0);
 		mac_vnic_secondary_update(umip);
 	}
 }
@@ -2166,10 +2171,10 @@ mac_unicast_flow_create(mac_client_impl_t *mcip, uint8_t *mac_addr,
 		flent_flags = FLOW_VNIC_MAC;
 
 	/*
-	 * For the first flow we use the mac client's name - mci_name, for
-	 * subsequent ones we just create a name with the vid. This is
+	 * For the first flow we use the MAC client's name - mci_name, for
+	 * subsequent ones we just create a name with the VID. This is
 	 * so that we can add these flows to the same flow table. This is
-	 * fine as the flow name (except for the one with the mac client's
+	 * fine as the flow name (except for the one with the MAC client's
 	 * name) is not visible. When the first flow is removed, we just replace
 	 * its fdesc with another from the list, so we will still retain the
 	 * flent with the MAC client's flow name.
@@ -2326,7 +2331,8 @@ mac_client_datapath_setup(mac_client_impl_t *mcip, uint16_t vid,
 		/*
 		 * The unicast MAC address must have been added successfully.
 		 */
-		ASSERT(mcip->mci_unicast != NULL);
+		VERIFY(mcip->mci_unicast != NULL);
+
 		/*
 		 * Push down the sub-flows that were defined on this link
 		 * hitherto. The flows are added to the active flow table
@@ -2336,15 +2342,25 @@ mac_client_datapath_setup(mac_client_impl_t *mcip, uint16_t vid,
 	} else {
 		mac_address_t *map = mcip->mci_unicast;
 
-		ASSERT(!no_unicast);
+		VERIFY(!no_unicast);
+		VERIFY(vid != VLAN_ID_NONE);
 		/*
 		 * A unicast flow already exists for that MAC client,
-		 * this flow must be the same mac address but with
-		 * different VID. It has been checked by mac_addr_in_use().
+		 * this flow must be the same MAC address but with a
+		 * different VID. It has been checked by
+		 * mac_addr_in_use().
+		 *
+		 * We will use the SRS etc. from the initial
+		 * mci_flent. We don't need to create a kstat for
+		 * this, as except for the fdesc, everything will be
+		 * used from the first flent.
 		 *
-		 * We will use the SRS etc. from the mci_flent. Note that
-		 * We don't need to create kstat for this as except for
-		 * the fdesc, everything will be used from in the 1st flent.
+		 * The only time we should see multiple flents on the
+		 * same MAC client is on the sun4v vsw. If we removed
+		 * that code we should be able to remove the entire
+		 * notion of multiple flents on a MAC client (this
+		 * doesn't affect sub/user flows because they have
+		 * their own list unrelated to mci_flent_list).
 		 */
 
 		if (bcmp(mac_addr, map->ma_addr, map->ma_len) != 0) {
@@ -2475,8 +2491,13 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 	boolean_t		is_vnic_primary =
 	    (flags & MAC_UNICAST_VNIC_PRIMARY);
 
-	/* when VID is non-zero, the underlying MAC can not be VNIC */
-	ASSERT(!((mip->mi_state_flags & MIS_IS_VNIC) && (vid != 0)));
+	/*
+	 * When the VID is non-zero the underlying MAC cannot be a
+	 * VNIC. I.e., dladm create-vlan cannot take a VNIC as
+	 * argument, only the primary MAC client.
+	 */
+	VERIFY(!((mip->mi_state_flags & MIS_IS_VNIC) &&
+	    (vid != VLAN_ID_NONE)));
 
 	/*
 	 * Can't unicast add if the client asked only for minimal datapath
@@ -2489,18 +2510,19 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 	 * Check for an attempted use of the current Port VLAN ID, if enabled.
 	 * No client may use it.
 	 */
-	if (mip->mi_pvid != 0 && vid == mip->mi_pvid)
+	if (mip->mi_pvid != VLAN_ID_NONE && vid == mip->mi_pvid)
 		return (EBUSY);
 
 	/*
 	 * Check whether it's the primary client and flag it.
 	 */
-	if (!(mcip->mci_state_flags & MCIS_IS_VNIC) && is_primary && vid == 0)
+	if (!(mcip->mci_state_flags & MCIS_IS_VNIC) && is_primary &&
+	    vid == VLAN_ID_NONE)
 		mcip->mci_flags |= MAC_CLIENT_FLAGS_PRIMARY;
 
 	/*
 	 * is_vnic_primary is true when we come here as a VLAN VNIC
-	 * which uses the primary mac client's address but with a non-zero
+	 * which uses the primary MAC client's address but with a non-zero
 	 * VID. In this case the MAC address is not specified by an upper
 	 * MAC client.
 	 */
@@ -2518,7 +2540,7 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 		 * doesn't attempt to free the original entry that
 		 * was allocated by the VNIC driver.
 		 */
-		ASSERT(mcip->mci_unicast != NULL);
+		VERIFY(mcip->mci_unicast != NULL);
 
 		/* Check for VLAN flags, if present */
 		if ((flags & MAC_UNICAST_TAG_DISABLE) != 0)
@@ -2552,7 +2574,7 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 		/*
 		 * Create a handle for vid 0.
 		 */
-		ASSERT(vid == 0);
+		VERIFY(vid == VLAN_ID_NONE);
 		muip = kmem_zalloc(sizeof (mac_unicast_impl_t), KM_SLEEP);
 		muip->mui_vid = vid;
 		*mah = (mac_unicast_handle_t)muip;
@@ -2572,7 +2594,9 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 	}
 
 	/*
-	 * If this is a VNIC/VLAN, disable softmac fast-path.
+	 * If this is a VNIC/VLAN, disable softmac fast-path. This is
+	 * only relevant to legacy devices which use softmac to
+	 * interface with GLDv3.
 	 */
 	if (mcip->mci_state_flags & MCIS_IS_VNIC) {
 		err = mac_fastpath_disable((mac_handle_t)mip);
@@ -2620,9 +2644,11 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 		(void) mac_client_set_resources(mch, mrp);
 	} else if (mcip->mci_state_flags & MCIS_IS_VNIC) {
 		/*
-		 * This is a primary VLAN client, we don't support
-		 * specifying rings property for this as it inherits the
-		 * rings property from its MAC.
+		 * This is a VLAN client sharing the address of the
+		 * primary MAC client; i.e., one created via dladm
+		 * create-vlan. We don't support specifying ring
+		 * properties for this type of client as it inherits
+		 * these from the primary MAC client.
 		 */
 		if (is_vnic_primary) {
 			mac_resource_props_t	*vmrp;
@@ -2681,7 +2707,7 @@ i_mac_unicast_add(mac_client_handle_t mch, uint8_t *mac_addr, uint16_t flags,
 
 	/*
 	 * Set the flags here so that if this is a passive client, we
-	 * can return  and set it when we call mac_client_datapath_setup
+	 * can return and set it when we call mac_client_datapath_setup
 	 * when this becomes the active client. If we defer to using these
 	 * flags to mac_client_datapath_setup, then for a passive client,
 	 * we'd have to store the flags somewhere (probably fe_flags)
@@ -2984,14 +3010,14 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 	i_mac_perim_enter(mip);
 	if (mcip->mci_flags & MAC_CLIENT_FLAGS_VNIC_PRIMARY) {
 		/*
-		 * Called made by the upper MAC client of a VNIC.
+		 * Call made by the upper MAC client of a VNIC.
 		 * There's nothing much to do, the unicast address will
 		 * be removed by the VNIC driver when the VNIC is deleted,
 		 * but let's ensure that all our transmit is done before
 		 * the client does a mac_client_stop lest it trigger an
 		 * assert in the driver.
 		 */
-		ASSERT(muip->mui_vid == 0);
+		VERIFY(muip->mui_vid == VLAN_ID_NONE);
 
 		mac_tx_client_flush(mcip);
 
@@ -3023,7 +3049,7 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 		return (0);
 	}
 
-	ASSERT(muip != NULL);
+	VERIFY(muip != NULL);
 
 	/*
 	 * We are removing a passive client, we haven't setup the datapath
@@ -3031,8 +3057,8 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 	 */
 	if ((mcip->mci_flags & MAC_CLIENT_FLAGS_PASSIVE_PRIMARY) != 0) {
 
-		ASSERT((mcip->mci_flent->fe_flags & FE_MC_NO_DATAPATH) != 0);
-		ASSERT(mcip->mci_p_unicast_list == muip);
+		VERIFY((mcip->mci_flent->fe_flags & FE_MC_NO_DATAPATH) != 0);
+		VERIFY(mcip->mci_p_unicast_list == muip);
 
 		mcip->mci_flags &= ~MAC_CLIENT_FLAGS_PASSIVE_PRIMARY;
 
@@ -3055,6 +3081,7 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 		i_mac_perim_exit(mip);
 		return (0);
 	}
+
 	/*
 	 * Remove the VID from the list of client's VIDs.
 	 */
@@ -3064,7 +3091,7 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 	} else {
 		while ((pre->mui_next != NULL) && (pre->mui_next != muip))
 			pre = pre->mui_next;
-		ASSERT(pre->mui_next == muip);
+		VERIFY(pre->mui_next == muip);
 		rw_enter(&mcip->mci_rw_lock, RW_WRITER);
 		pre->mui_next = muip->mui_next;
 		rw_exit(&mcip->mci_rw_lock);
@@ -3081,7 +3108,7 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 		 * flows.
 		 */
 		flent = mac_client_get_flow(mcip, muip);
-		ASSERT(flent != NULL);
+		VERIFY(flent != NULL);
 
 		/*
 		 * The first one is disappearing, need to make sure
@@ -3108,7 +3135,8 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 		}
 
 		FLOW_FINAL_REFRELE(flent);
-		ASSERT(!(mcip->mci_state_flags & MCIS_EXCLUSIVE));
+		VERIFY(!(mcip->mci_state_flags & MCIS_EXCLUSIVE));
+
 		/*
 		 * Enable fastpath if this is a VNIC or a VLAN.
 		 */
@@ -3122,7 +3150,8 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 	mui_vid = muip->mui_vid;
 	mac_client_datapath_teardown(mch, muip, flent);
 
-	if ((mcip->mci_flags & MAC_CLIENT_FLAGS_PRIMARY) && mui_vid == 0) {
+	if ((mcip->mci_flags & MAC_CLIENT_FLAGS_PRIMARY) &&
+	    mui_vid == VLAN_ID_NONE) {
 		mcip->mci_flags &= ~MAC_CLIENT_FLAGS_PRIMARY;
 	} else {
 		i_mac_perim_exit(mip);
@@ -3147,7 +3176,7 @@ mac_unicast_remove(mac_client_handle_t mch, mac_unicast_handle_t mah)
 		 */
 		mac_get_resources((mac_handle_t)mip, mrp);
 		(void) mac_client_set_resources(mch, mrp);
-		ASSERT(mcip->mci_p_unicast_list != NULL);
+		VERIFY(mcip->mci_p_unicast_list != NULL);
 		muip = mcip->mci_p_unicast_list;
 		mcip->mci_p_unicast_list = NULL;
 		if (mac_client_datapath_setup(mcip, VLAN_ID_NONE,
@@ -3812,12 +3841,12 @@ mac_client_poll_enable(mac_client_handle_t mch)
 	int			i;
 
 	flent = mcip->mci_flent;
-	ASSERT(flent != NULL);
+	VERIFY(flent != NULL);
 
 	mcip->mci_state_flags |= MCIS_CLIENT_POLL_CAPABLE;
 	for (i = 0; i < flent->fe_rx_srs_cnt; i++) {
 		mac_srs = (mac_soft_ring_set_t *)flent->fe_rx_srs[i];
-		ASSERT(mac_srs->srs_mcip == mcip);
+		VERIFY(mac_srs->srs_mcip == mcip);
 		mac_srs_client_poll_enable(mcip, mac_srs);
 	}
 }
diff --git a/usr/src/uts/common/io/mac/mac_datapath_setup.c b/usr/src/uts/common/io/mac/mac_datapath_setup.c
index de7dd0b716..4fa383b4eb 100644
--- a/usr/src/uts/common/io/mac/mac_datapath_setup.c
+++ b/usr/src/uts/common/io/mac/mac_datapath_setup.c
@@ -24,6 +24,7 @@
  */
 
 #include <sys/types.h>
+#include <sys/bitmap.h>
 #include <sys/callb.h>
 #include <sys/cpupart.h>
 #include <sys/pool.h>
@@ -370,7 +371,7 @@ mac_srs_client_poll_enable(mac_client_impl_t *mcip,
 	mac_rx_fifo_t		mrf;
 	mac_soft_ring_t		*softring;
 
-	ASSERT(mac_srs->srs_mcip == mcip);
+	VERIFY(mac_srs->srs_mcip == mcip);
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mcip->mci_mip));
 
 	if (!(mcip->mci_state_flags & MCIS_CLIENT_POLL_CAPABLE))
@@ -1197,7 +1198,7 @@ mac_srs_fanout_list_alloc(mac_soft_ring_set_t *mac_srs)
 		mac_srs->srs_tx_soft_rings = (mac_soft_ring_t **)
 		    kmem_zalloc(sizeof (mac_soft_ring_t *) *
 		    MAX_RINGS_PER_GROUP, KM_SLEEP);
-		if (mcip->mci_state_flags & MCIS_IS_AGGR) {
+		if (mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT) {
 			mac_srs_tx_t *tx = &mac_srs->srs_tx;
 
 			tx->st_soft_rings = (mac_soft_ring_t **)
@@ -1606,13 +1607,13 @@ mac_srs_update_bwlimit(flow_entry_t *flent, mac_resource_props_t *mrp)
 
 /*
  * When the first sub-flow is added to a link, we disable polling on the
- * link and also modify the entry point to mac_rx_srs_subflow_process.
+ * link and also modify the entry point to mac_rx_srs_subflow_process().
  * (polling is disabled because with the subflow added, accounting
  * for polling needs additional logic, it is assumed that when a subflow is
  * added, we can take some hit as a result of disabling polling rather than
  * adding more complexity - if this becomes a perf. issue we need to
  * re-rvaluate this logic).  When the last subflow is removed, we turn back
- * polling and also reset the entry point to mac_rx_srs_process.
+ * polling and also reset the entry point to mac_rx_srs_process().
  *
  * In the future if there are multiple SRS, we can simply
  * take one and give it to the flow rather than disabling polling and
@@ -1657,7 +1658,7 @@ mac_client_update_classifier(mac_client_impl_t *mcip, boolean_t enable)
 	 * Change the S/W classifier so that we can land in the
 	 * correct processing function with correct argument.
 	 * If all subflows have been removed we can revert to
-	 * mac_rx_srsprocess, else we need mac_rx_srs_subflow_process.
+	 * mac_rx_srs_process(), else we need mac_rx_srs_subflow_process().
 	 */
 	mutex_enter(&flent->fe_lock);
 	flent->fe_cb_fn = (flow_fn_t)rx_func;
@@ -2198,7 +2199,7 @@ mac_srs_create(mac_client_impl_t *mcip, flow_entry_t *flent, uint32_t srs_type,
 	 *    find nothing plus we have an existing backlog
 	 *    (sr_poll_pkt_cnt > 0), we stay in polling mode but don't poll
 	 *    the H/W for packets anymore (let the polling thread go to sleep).
-	 * 5) Once the backlog is relived (packets are processed) we reenable
+	 * 5) Once the backlog is relieved (packets are processed) we reenable
 	 *    polling (by signalling the poll thread) only when the backlog
 	 *    dips below sr_poll_thres.
 	 * 6) sr_hiwat is used exclusively when we are not polling capable
@@ -2276,8 +2277,8 @@ mac_srs_create(mac_client_impl_t *mcip, flow_entry_t *flent, uint32_t srs_type,
 		/*
 		 * Some drivers require serialization and don't send
 		 * packet chains in interrupt context. For such
-		 * drivers, we should always queue in soft ring
-		 * so that we get a chance to switch into a polling
+		 * drivers, we should always queue in the soft ring
+		 * so that we get a chance to switch into polling
 		 * mode under backlog.
 		 */
 		ring_info = mac_hwring_getinfo((mac_ring_handle_t)ring);
@@ -2384,9 +2385,11 @@ mac_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 }
 
 /*
- * Set up the RX SRSs. If the S/W SRS is not set, set  it up, if there
- * is a group associated with this MAC client, set up SRSs for individual
- * h/w rings.
+ * Set up the RX SRSes. If there is no group associated with the
+ * client then only setup SW classification. If the client has
+ * exlusive (MAC_GROUP_STATE_RESERVED) use of the group then create an
+ * SRS for each HW ring. If the client is sharing a group then make
+ * sure to teardown the HW SRSes.
  */
 void
 mac_rx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
@@ -2397,13 +2400,17 @@ mac_rx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 	mac_ring_t 		*ring;
 	uint32_t		fanout_type;
 	mac_group_t		*rx_group = flent->fe_rx_ring_group;
+	uint16_t		vid;
+	boolean_t		is_vlan, no_unicast;
 
 	fanout_type = mac_find_fanout(flent, link_type);
+	no_unicast = mcip->mci_state_flags & MCIS_NO_UNICAST_ADDR;
+	vid = i_mac_flow_vid(flent);
+	is_vlan = (vid != VLAN_ID_NONE);
 
-	/* Create the SRS for S/W classification if none exists */
+	/* Create the SRS for SW classification if none exists */
 	if (flent->fe_rx_srs[0] == NULL) {
-		ASSERT(flent->fe_rx_srs_cnt == 0);
-		/* Setup the Rx SRS */
+		VERIFY(flent->fe_rx_srs_cnt == 0);
 		mac_srs = mac_srs_create(mcip, flent, fanout_type | link_type,
 		    mac_rx_deliver, mcip, NULL, NULL);
 		mutex_enter(&flent->fe_lock);
@@ -2415,10 +2422,10 @@ mac_rx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 
 	if (rx_group == NULL)
 		return;
+
 	/*
-	 * fanout for default SRS is done when default SRS are created
-	 * above. As each ring is added to the group, we setup the
-	 * SRS and fanout to it.
+	 * If the group is marked RESERVED then setup an SRS and
+	 * fanout for each HW ring.
 	 */
 	switch (rx_group->mrg_state) {
 	case MAC_GROUP_STATE_RESERVED:
@@ -2433,20 +2440,29 @@ mac_rx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 					(void) mac_start_ring(ring);
 
 				/*
-				 * Since the group is exclusively ours create
-				 * an SRS for this ring to allow the
-				 * individual SRS to dynamically poll the
-				 * ring. Do this only if the  client is not
-				 * a VLAN MAC client, since for VLAN we do
-				 * s/w classification for the VID check, and
-				 * if it has a unicast address.
+				 * If a client has no unicast address
+				 * then we don't create any HW ring SRSes.
 				 */
-				if ((mcip->mci_state_flags &
-				    MCIS_NO_UNICAST_ADDR) ||
-				    i_mac_flow_vid(mcip->mci_flent) !=
-				    VLAN_ID_NONE) {
+				if (no_unicast)
 					break;
-				}
+
+				/*
+				 * If the client's address is not
+				 * fully HW classified then don't
+				 * create any HW ring SRSes.
+				 */
+				if (mcip->mci_unicast->ma_type !=
+				    MAC_ADDRESS_TYPE_FULL_CLASSIFY)
+					break;
+
+				/*
+				 * When a client has exclusive use of
+				 * a group, and that group's traffic
+				 * is fully HW classified, we create
+				 * an SRS for each HW ring in order to
+				 * make use of dynamic polling of said
+				 * HW rings.
+				 */
 				mac_srs = mac_srs_create(mcip, flent,
 				    fanout_type | link_type,
 				    mac_rx_deliver, mcip, NULL, ring);
@@ -2462,14 +2478,9 @@ mac_rx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 		break;
 	case MAC_GROUP_STATE_SHARED:
 		/*
-		 * Set all rings of this group to software classified.
-		 *
-		 * If the group is current RESERVED, the existing mac
-		 * client (the only client on this group) is using
-		 * this group exclusively.  In that case we need to
-		 * disable polling on the rings of the group (if it
-		 * was enabled), and free the SRS associated with the
-		 * rings.
+		 * When a group is shared by multiple clients we must
+		 * use SW classifiction to ensure packets are
+		 * delivered to the correct client.
 		 */
 		mac_rx_switch_grp_to_sw(rx_group);
 		break;
@@ -2522,10 +2533,11 @@ mac_tx_srs_group_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 }
 
 /*
- * Remove all the RX SRSs. If we want to remove only the SRSs associated
- * with h/w rings, leave the S/W SRS alone. This is used when we want to
- * move the MAC client from one group to another, so we need to teardown
- * on the h/w SRSs.
+ * Teardown all the Rx SRSs. Unless hwonly is set, then only teardown
+ * the Rx HW SRSs and leave the SW SRS alone. The hwonly flag is set
+ * when we wish to move a MAC client from one group to another. In
+ * that case we need to release the current HW SRSs but keep the SW
+ * SRS for continued traffic classifiction.
  */
 void
 mac_rx_srs_group_teardown(flow_entry_t *flent, boolean_t hwonly)
@@ -2543,8 +2555,14 @@ mac_rx_srs_group_teardown(flow_entry_t *flent, boolean_t hwonly)
 		flent->fe_rx_srs[i] = NULL;
 		flent->fe_rx_srs_cnt--;
 	}
-	ASSERT(!hwonly || flent->fe_rx_srs_cnt == 1);
-	ASSERT(hwonly || flent->fe_rx_srs_cnt == 0);
+
+	/*
+	 * If we are only tearing down the HW SRSs then there must be
+	 * 1 SRS left for SW classifiction. Otherwise we are tearing
+	 * down both HW and SW and there should be no SRSs left.
+	 */
+	VERIFY(!hwonly || flent->fe_rx_srs_cnt == 1);
+	VERIFY(hwonly || flent->fe_rx_srs_cnt == 0);
 }
 
 /*
@@ -2611,6 +2629,7 @@ mac_tx_srs_group_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
  *
  * Non-default		0		N.A.			REGISTERED
  * Non-default		1		N.A.			RESERVED
+ * Non-default		> 1		N.A.			SHARED
  *
  * Default		0		N.A.			SHARED
  * Default		1		1			RESERVED
@@ -2846,6 +2865,107 @@ mac_group_next_state(mac_group_t *grp, mac_client_impl_t **group_only_mcip,
  * even if this is the only client in the default group, we will
  * leave group as shared).
  */
+
+/*
+ * uts/common/os/printf.c
+ */
+static void
+mac_rpz_report(mac_group_t *rgroup)
+{
+	uint16_t		vid;
+	mac_report_t		rp;
+
+	bzero(&rp, sizeof (rp));
+	rgroup->mrg_info.mgi_report(rgroup->mrg_info.mgi_driver, &rp);
+
+	printf("VLNCTRL: 0x%x\n", rp.vlnctrl);
+	printf("rar_entries: %u\n", rp.rar_entries);
+
+	for (uint_t i = 0; i < rp.rar_entries; i++) {
+		uint8_t mac[6];
+		int en = (0x80000000 & rp.rah[i]) != 0;
+
+		/*
+		 * Reverse ixgbe_set_rar_generic()
+		 */
+		mac[0] = rp.ral[i];
+		mac[1] = rp.ral[i] >> 8;
+		mac[2] = rp.ral[i] >> 16;
+		mac[3] = rp.ral[i] >> 24;
+		mac[4] = rp.rah[i];
+		mac[5] = rp.rah[i] >> 8;
+
+		printf("RAR %u (en: %d): %x:%x:%x:%x:%x:%x", i, en,
+		    mac[0], mac[1], mac[2], mac[3], mac[4], mac[5]);
+
+		/*
+		 * Print num of each group enabled for this
+		 * RAR. For unicast addrs there should only be
+		 * one group enabled.
+		 */
+		for (uint_t j = 0; j < 32; j++) {
+			if (BT_TEST(&(rp.mpsar_lo[i]), j))
+				printf("    MPSAR[%u]: group %u\n", i, j);
+
+			if (BT_TEST(&(rp.mpsar_hi[i]), j))
+				printf("    MPSAR[%u]: group %u\n", i, j + 32);
+		}
+	}
+
+	for (uint_t n = 0; n < 128; n++) {
+		for (uint_t i = 0; i < 32; i++) {
+			if (BT_TEST(&(rp.vfta[n]), i))
+				printf("VFTA VID: %u\n", (32 * n) + i);
+		}
+	}
+
+	for (uint_t n = 0; n < 2; n++) {
+		for (uint_t i = 0; i < 32; i++) {
+			if (BT_TEST(&(rp.vfre[n]), i))
+				printf("VFRE %d ENABLED\n", (32 * n) + i);
+			else
+				printf("VFRE %d DISABLED\n", (32 * n) + i);
+		}
+	}
+
+	/*
+	 * There are 64 VLVF entries.
+	 */
+	for (uint_t i = 0; i < 64; i++) {
+		vid = 0x7FF & rp.vlvf[i];
+		int en = (0x80000000 & rp.vlvf[i]) != 0;
+
+		printf("VLVF[%u] en: %d vid: %u\n", i, en, vid);
+
+		/*
+		 * For each of the 64 VLVF entries there may
+		 * be a bit set in the VLVFB for one of the 64
+		 * groups.
+		 */
+		for (uint_t j = 0; j < 32; j++) {
+			if (en && BT_TEST(&(rp.vlvfb[2*i]), j))
+				printf("    VLVFB group: %u\n", j);
+
+			if (en && BT_TEST(&(rp.vlvfb[(2*i) + 1]), j))
+				printf("    VLVFB group: %u\n", j + 32);
+		}
+	}
+
+	for (uint_t i = 0; i < 64; i++) {
+		uint upe = (0x400000 & rp.vml2flt[i]) != 0;
+		uint vpe = (0x800000 & rp.vml2flt[i]) != 0;
+		uint aupe = (0x1000000 & rp.vml2flt[i]) != 0;
+		uint rompe = (0x2000000 & rp.vml2flt[i]) != 0;
+		uint rope = (0x4000000 & rp.vml2flt[i]) != 0;
+		uint bam = (0x8000000 & rp.vml2flt[i]) != 0;
+		uint mpe = (0x10000000 & rp.vml2flt[i]) != 0;
+
+		printf("VML2FLT[%u] UPE %u VPE %u AUPE %u ROMPE %u ROPE %u"
+		    " BAM %u MPE %u\n", i, upe, vpe, aupe, rompe, rope, bam,
+		    mpe);
+	}
+}
+
 int
 mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
     uint32_t link_type)
@@ -2857,6 +2977,7 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 	mac_group_t		*default_tgroup;
 	int			err;
 	uint8_t 		*mac_addr;
+	uint16_t		vid;
 	mac_group_state_t	next_state;
 	mac_client_impl_t	*group_only_mcip;
 	mac_resource_props_t	*mrp = MCIP_RESOURCE_PROPS(mcip);
@@ -2868,6 +2989,8 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 	boolean_t		no_unicast;
 	boolean_t		isprimary = flent->fe_type & FLOW_PRIMARY_MAC;
 	mac_client_impl_t	*reloc_pmcip = NULL;
+	boolean_t		hw_vlan = B_FALSE;
+	uint_t			flags = 0;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
 
@@ -2899,15 +3022,29 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 		    (mrp->mrp_mask & MRP_TXRINGS_UNSPEC));
 
 		/*
-		 * By default we have given the primary all the rings
-		 * i.e. the default group. Let's see if the primary
-		 * needs to be relocated so that the addition of this
-		 * client doesn't impact the primary's performance,
-		 * i.e. if the primary is in the default group and
-		 * we add this client, the primary will lose polling.
-		 * We do this only for NICs supporting dynamic ring
-		 * grouping and only when this is the first client
-		 * after the primary (i.e. nactiveclients is 2)
+		 * All the rings initially belong to the default group
+		 * when the MAC uses dynamic gropuing. In this case
+		 * the primary will use the default group when it is
+		 * the only client. When the second client is added we
+		 * query if the primary client may be relocated to a
+		 * new group dedicated to it. We do this because all
+		 * multicast and broadcast traffic is delivered to the
+		 * default group. When the primary client is the sole
+		 * client this is fine, but the moment a second client
+		 * is added the primary client will loose the ability
+		 * to poll this group because it has to share the
+		 * group with the broadcast and multicast traffic of
+		 * another client. If the primary client is relocated
+		 * to its own dedicated group then it continues to
+		 * receive fully classified traffic to the group and
+		 * may take advantage of squeue polling.
+		 *
+		 * This only applies to dynamic polling because it has
+		 * the ability to put all rings in one group. If the
+		 * MAC group type is static then we'll always have a
+		 * static number of groups available and the primary
+		 * will begin life with its own group separate from
+		 * the default group.
 		 */
 		if (!isprimary && mip->mi_nactiveclients == 2 &&
 		    (group_only_mcip = mac_primary_client_handle(mip)) !=
@@ -2928,6 +3065,7 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 		} else if (rgroup == NULL) {
 			rgroup = default_rgroup;
 		}
+
 		/*
 		 * Check to see if we can get an exclusive group for
 		 * this mac client. If no groups are available, use
@@ -2961,12 +3099,14 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 			}
 			flent->fe_rx_ring_group = rgroup;
 			/*
-			 * Add the client to the group. This could cause
-			 * either this group to move to the shared state or
-			 * cause the default group to move to the shared state.
-			 * The actions on this group are done here, while the
-			 * actions on the default group are postponed to
-			 * the end of this function.
+			 * Add the client to the group and update the
+			 * group's state. If rgroup != default_group
+			 * then the rgroup will have a RESERVED state
+			 * iff there is only one client. But no matter
+			 * what, the default_group will enter the
+			 * SHARED state since it has to receive all
+			 * broadcast and multicast traffic. This case
+			 * is handled later in the function.
 			 */
 			mac_group_add_client(rgroup, mcip);
 			next_state = mac_group_next_state(rgroup,
@@ -2991,28 +3131,39 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 			    &group_only_mcip, default_tgroup, B_FALSE);
 			tgroup->mrg_state = next_state;
 		}
-		/*
-		 * Setup the Rx and Tx SRSes. If we got a pristine group
-		 * exclusively above, mac_srs_group_setup would simply create
-		 * the required SRSes. If we ended up sharing a previously
-		 * reserved group, mac_srs_group_setup would also dismantle the
-		 * SRSes of the previously exclusive group
-		 */
-		mac_srs_group_setup(mcip, flent, link_type);
 
 		/* We are setting up minimal datapath only */
-		if (no_unicast)
+		if (no_unicast) {
+			mac_srs_group_setup(mcip, flent, link_type);
 			break;
-		/* Program the S/W Classifer */
+		}
+
+		/* Program software classification. */
 		if ((err = mac_flow_add(mip->mi_flow_tab, flent)) != 0)
 			goto setup_failed;
 
-		/* Program the H/W Classifier */
-		if ((err = mac_add_macaddr(mip, rgroup, mac_addr,
-		    (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0)) != 0)
+		/* Program hardware classification. */
+		vid = i_mac_flow_vid(flent);
+		flags &= (mcip->mci_state_flags & MCIS_UNICAST_HW) != 0 ?
+		    MAC_GROUP_UNICAST_HW : 0;
+		err = mac_add_macaddr_vlan(mip, rgroup, mac_addr, vid, flags);
+
+		if (err != 0)
 			goto setup_failed;
+
 		mcip->mci_unicast = mac_find_macaddr(mip, mac_addr);
-		ASSERT(mcip->mci_unicast != NULL);
+		VERIFY(mcip->mci_unicast != NULL);
+
+		/*
+		 * Setup the Rx and Tx SRSes. If have an exclusive
+		 * group with full HW classification then
+		 * mac_srs_group_setup() creates the required SRSes
+		 * for the HW rings. If we have a shared group,
+		 * mac_srs_group_setup() dismantles the HW SRSes of
+		 * the previously exclusive group.
+		 */
+		mac_srs_group_setup(mcip, flent, link_type);
+
 		/* (Re)init the v6 token & local addr used by link protection */
 		mac_protect_update_mac_token(mcip);
 		break;
@@ -3056,18 +3207,44 @@ mac_datapath_setup(mac_client_impl_t *mcip, flow_entry_t *flent,
 			ASSERT(default_rgroup->mrg_state ==
 			    MAC_GROUP_STATE_SHARED);
 		}
+
 		/*
-		 * If we get an exclusive group for a VLAN MAC client we
-		 * need to take the s/w path to make the additional check for
-		 * the vid. Disable polling and set it to s/w classification.
-		 * Similarly for clients that don't have a unicast address.
+		 * If the address (MAC addr + VID) filtering isn't
+		 * fully hardware classified then make sure to switch
+		 * to software classifiction. Switching to SW
+		 * classification prevents the upstream squeue from
+		 * polling the SRS but the SRS can still poll the NIC
+		 * rings.
+		 *
+		 * We also switch to SW classification for those
+		 * clients that don't have a unicast address.
+		 *
+		 * XXX This isn't enough when VLAN filtering is
+		 * enabled. The ixgbe NIC will never deliver traffic
+		 * to this rgroup because it ran out of VLAN filters.
+		 * Instead the traffic will arrive on the default
+		 * group, so this client should be moved to the
+		 * default group. The reason this didn't matter before
+		 * is because all ixgbe parts always reserved enough
+		 * MAC address HW filters to cover all the groups, so
+		 * if you had a group you were guarenteed a MAC
+		 * address HW filter. This is not the case with VLAN
+		 * filters.
 		 */
-		if (rgroup->mrg_state == MAC_GROUP_STATE_RESERVED &&
-		    (i_mac_flow_vid(flent) != VLAN_ID_NONE || no_unicast)) {
+		if ((mcip->mci_unicast->ma_type !=
+		    MAC_ADDRESS_TYPE_FULL_CLASSIFY) || no_unicast) {
 			mac_rx_switch_grp_to_sw(rgroup);
 		}
 	}
 	mac_set_rings_effective(mcip);
+
+	/*
+	 * RPZ: Included for debugging until I finish testing.
+	 */
+	if (rgroup != NULL && rgroup->mrg_info.mgi_report != NULL) {
+		mac_rpz_report(rgroup);
+	}
+
 	return (0);
 
 setup_failed:
@@ -3092,6 +3269,8 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 	boolean_t		check_default_group = B_FALSE;
 	mac_group_state_t	next_state;
 	mac_resource_props_t	*mrp = MCIP_RESOURCE_PROPS(mcip);
+	int			err;
+	uint16_t		vid;
 
 	ASSERT(MAC_PERIM_HELD((mac_handle_t)mip));
 
@@ -3104,16 +3283,22 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 	case SRST_LINK:
 		/* Stop sending packets */
 		mac_tx_client_block(mcip);
+		group = flent->fe_rx_ring_group;
+		vid = i_mac_flow_vid(flent);
 
-		/* Stop the packets coming from the H/W */
+		/*
+		 * Stop the packet flow from the hardware by disabling
+		 * any hardware filters assigned to this client.
+		 */
 		if (mcip->mci_unicast != NULL) {
-			int err;
-			err = mac_remove_macaddr(mcip->mci_unicast);
+			err = mac_remove_macaddr_vlan(mcip->mci_unicast, vid);
+
 			if (err != 0) {
-				cmn_err(CE_WARN, "%s: failed to remove a MAC"
-				    " address because of error 0x%x",
+				cmn_err(CE_WARN, "%s: failed to remove a MAC HW"
+				    " filters because of error 0x%x",
 				    mip->mi_name, err);
 			}
+
 			mcip->mci_unicast = NULL;
 		}
 
@@ -3134,19 +3319,18 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 		 * left who can use it exclusively. Also, if we
 		 * were the last client, release the group.
 		 */
-		group = flent->fe_rx_ring_group;
 		default_group = MAC_DEFAULT_RX_GROUP(mip);
 		if (group != NULL) {
 			mac_group_remove_client(group, mcip);
 			next_state = mac_group_next_state(group,
 			    &grp_only_mcip, default_group, B_TRUE);
-			if (next_state == MAC_GROUP_STATE_RESERVED) {
+			mac_set_group_state(group, next_state);
+
+			if (mac_group_hw_classified(group)) {
 				/*
 				 * Only one client left on this RX group.
 				 */
-				ASSERT(grp_only_mcip != NULL);
-				mac_set_group_state(group,
-				    MAC_GROUP_STATE_RESERVED);
+				VERIFY(grp_only_mcip != NULL);
 				group_only_flent = grp_only_mcip->mci_flent;
 
 				/*
@@ -3169,7 +3353,7 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 				 * to see if the primary client can get
 				 * exclusive access to the default group.
 				 */
-				ASSERT(group != MAC_DEFAULT_RX_GROUP(mip));
+				VERIFY(group != MAC_DEFAULT_RX_GROUP(mip));
 				if (mrp->mrp_mask & MRP_RX_RINGS) {
 					MAC_RX_GRP_RELEASED(mip);
 					if (mip->mi_rx_group_type ==
@@ -3179,13 +3363,8 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 					}
 				}
 				mac_release_rx_group(mcip, group);
-				mac_set_group_state(group,
-				    MAC_GROUP_STATE_REGISTERED);
 				check_default_group = B_TRUE;
-			} else {
-				ASSERT(next_state == MAC_GROUP_STATE_SHARED);
-				mac_set_group_state(group,
-				    MAC_GROUP_STATE_SHARED);
+			} else if (next_state == MAC_GROUP_STATE_SHARED) {
 				mac_rx_group_unmark(group, MR_CONDEMNED);
 			}
 			flent->fe_rx_ring_group = NULL;
@@ -3272,14 +3451,13 @@ mac_datapath_teardown(mac_client_impl_t *mcip, flow_entry_t *flent,
 	 */
 	if (check_default_group) {
 		default_group = MAC_DEFAULT_RX_GROUP(mip);
-		ASSERT(default_group->mrg_state == MAC_GROUP_STATE_SHARED);
+		VERIFY(default_group->mrg_state == MAC_GROUP_STATE_SHARED);
 		next_state = mac_group_next_state(default_group,
 		    &grp_only_mcip, default_group, B_TRUE);
-		if (next_state == MAC_GROUP_STATE_RESERVED) {
-			ASSERT(grp_only_mcip != NULL &&
+		mac_set_group_state(default_group, next_state);
+		if (mac_group_hw_classified(default_group)) {
+			VERIFY(grp_only_mcip != NULL &&
 			    mip->mi_nactiveclients == 1);
-			mac_set_group_state(default_group,
-			    MAC_GROUP_STATE_RESERVED);
 			mac_rx_srs_group_setup(grp_only_mcip,
 			    grp_only_mcip->mci_flent, SRST_LINK);
 			mac_fanout_setup(grp_only_mcip,
@@ -3801,7 +3979,7 @@ mac_tx_srs_del_ring(mac_soft_ring_set_t *mac_srs, mac_ring_t *tx_ring)
 	 * is also stored in st_soft_rings[] array. That entry should
 	 * be removed.
 	 */
-	if (mcip->mci_state_flags & MCIS_IS_AGGR) {
+	if (mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT) {
 		mac_srs_tx_t *tx = &mac_srs->srs_tx;
 
 		ASSERT(tx->st_soft_rings[tx_ring->mr_index] == remove_sring);
@@ -3830,7 +4008,7 @@ mac_tx_srs_setup(mac_client_impl_t *mcip, flow_entry_t *flent)
 	boolean_t		is_aggr;
 	uint_t			ring_info = 0;
 
-	is_aggr = (mcip->mci_state_flags & MCIS_IS_AGGR) != 0;
+	is_aggr = (mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT) != 0;
 	grp = flent->fe_tx_ring_group;
 	if (grp == NULL) {
 		ring = (mac_ring_t *)mip->mi_default_tx_ring;
diff --git a/usr/src/uts/common/io/mac/mac_flow.c b/usr/src/uts/common/io/mac/mac_flow.c
index aa4985fe4c..885bd4a0ec 100644
--- a/usr/src/uts/common/io/mac/mac_flow.c
+++ b/usr/src/uts/common/io/mac/mac_flow.c
@@ -54,7 +54,8 @@ typedef struct flow_stats_s {
 } flow_stats_t;
 
 
-/* global flow table, will be a per exclusive-zone table later */
+/* global flow table, will be a per exclusive-zone table later
+ */
 static mod_hash_t	*flow_hash;
 static krwlock_t	flow_tab_lock;
 
@@ -1710,7 +1711,8 @@ flow_ether_hash_fe(flow_tab_t *ft, flow_entry_t *flent)
 {
 	flow_desc_t	*fd = &flent->fe_flow_desc;
 
-	ASSERT((fd->fd_mask & FLOW_LINK_VID) != 0 || fd->fd_vid == 0);
+	ASSERT((fd->fd_mask & FLOW_LINK_VID) != 0 ||
+	    fd->fd_vid == VLAN_ID_NONE);
 	return (HASH_ETHER_VID(fd->fd_dst_mac, fd->fd_vid, ft->ft_size));
 }
 
@@ -1766,7 +1768,7 @@ flow_l2_accept_fe(flow_tab_t *ft, flow_entry_t *flent)
 		if (ft->ft_mip->mi_info.mi_nativemedia != DL_ETHER)
 			return (EINVAL);
 
-		if (fd->fd_vid == 0)
+		if (fd->fd_vid == VLAN_ID_NONE)
 			return (EINVAL);
 
 	}
@@ -1782,7 +1784,8 @@ flow_l2_hash_fe(flow_tab_t *ft, flow_entry_t *flent)
 {
 	flow_desc_t	*fd = &flent->fe_flow_desc;
 
-	ASSERT((fd->fd_mask & FLOW_LINK_VID) == 0 && fd->fd_vid == 0);
+	ASSERT((fd->fd_mask & FLOW_LINK_VID) == 0 &&
+	    fd->fd_vid == VLAN_ID_NONE);
 	return (flow_l2_addrhash(fd->fd_dst_mac,
 	    ft->ft_mip->mi_type->mt_addr_length, ft->ft_size));
 }
diff --git a/usr/src/uts/common/io/mac/mac_provider.c b/usr/src/uts/common/io/mac/mac_provider.c
index 8ed5910835..40ab719619 100644
--- a/usr/src/uts/common/io/mac/mac_provider.c
+++ b/usr/src/uts/common/io/mac/mac_provider.c
@@ -21,7 +21,7 @@
 
 /*
  * Copyright (c) 2008, 2010, Oracle and/or its affiliates. All rights reserved.
- * Copyright 2015, Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  * Copyright 2017 OmniTI Computer Consulting, Inc. All rights reserved.
  */
 
@@ -57,6 +57,7 @@
 #include <sys/sdt.h>
 #include <sys/pattr.h>
 #include <sys/strsun.h>
+#include <sys/vlan.h>
 
 /*
  * MAC Provider Interface.
diff --git a/usr/src/uts/common/io/mac/mac_sched.c b/usr/src/uts/common/io/mac/mac_sched.c
index 948594f849..10bbac5d96 100644
--- a/usr/src/uts/common/io/mac/mac_sched.c
+++ b/usr/src/uts/common/io/mac/mac_sched.c
@@ -300,9 +300,8 @@
  *
  * Otherwise, all fanout is performed by software. MAC divides incoming frames
  * into one of three buckets -- IPv4 TCP traffic, IPv4 UDP traffic, and
- * everything else. Note, VLAN tagged traffic is considered other, regardless of
- * the interior EtherType. Regardless of the type of fanout, these three
- * categories or buckets are always used.
+ * everything else. Regardless of the type of fanout, these three categories
+ * or buckets are always used.
  *
  * The difference between protocol level fanout and full software ring protocol
  * fanout is the number of software rings that end up getting created. The
@@ -1475,16 +1474,15 @@ enum pkt_type {
 #define	PORTS_SIZE 4
 
 /*
- * mac_rx_srs_proto_fanout
- *
- * This routine delivers packets destined to an SRS into one of the
+ * This routine delivers packets destined for an SRS into one of the
  * protocol soft rings.
  *
- * Given a chain of packets we need to split it up into multiple sub chains
- * destined into TCP, UDP or OTH soft ring. Instead of entering
- * the soft ring one packet at a time, we want to enter it in the form of a
- * chain otherwise we get this start/stop behaviour where the worker thread
- * goes to sleep and then next packets comes in forcing it to wake up etc.
+ * Given a chain of packets we need to split it up into multiple sub
+ * chains: TCP, UDP or OTH soft ring. Instead of entering the soft
+ * ring one packet at a time, we want to enter it in the form of a
+ * chain otherwise we get this start/stop behaviour where the worker
+ * thread goes to sleep and then next packet comes in forcing it to
+ * wake up.
  */
 static void
 mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
@@ -1512,6 +1510,7 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 	is_ether = (mcip->mci_mip->mi_info.mi_nativemedia == DL_ETHER);
 	bw_ctl = ((mac_srs->srs_type & SRST_BW_CONTROL) != 0);
 
+
 	/*
 	 * If we don't have a Rx ring, S/W classification would have done
 	 * its job and its a packet meant for us. If we were polling on
@@ -1523,9 +1522,9 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 	    mac_srs->srs_ring->mr_classify_type == MAC_HW_CLASSIFIER;
 
 	/*
-	 * Special clients (eg. VLAN, non ether, etc) need DLS
-	 * processing in the Rx path. SRST_DLS_BYPASS will be clear for
-	 * such SRSs. Another way of disabling bypass is to set the
+	 * Some clients, such as non Ethernet, need DLS processing in
+	 * the Rx path. Such clients clear the SRST_DLS_BYPASS flag.
+	 * DLS bypass may also be disabled via the
 	 * MCIS_RX_BYPASS_DISABLE flag.
 	 */
 	dls_bypass = ((mac_srs->srs_type & SRST_DLS_BYPASS) != 0) &&
@@ -1537,10 +1536,11 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 	bzero(sz, MAX_SR_TYPES * sizeof (size_t));
 
 	/*
-	 * We got a chain from SRS that we need to send to the soft rings.
-	 * Since squeues for TCP & IPv4 sap poll their soft rings (for
-	 * performance reasons), we need to separate out v4_tcp, v4_udp
-	 * and the rest goes in other.
+	 * We have a chain from SRS that we need to split across the
+	 * softrings. The squeues for the TCP and IPv4 SAPs use their
+	 * own softrings to allow polling from the squeue. The rest of
+	 * the packets are delivered on the OTH softring which cannot
+	 * be polled.
 	 */
 	while (head != NULL) {
 		mp = head;
@@ -1568,9 +1568,14 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 				evhp = (struct ether_vlan_header *)mp->b_rptr;
 				sap = ntohs(evhp->ether_type);
 				hdrsize = sizeof (struct ether_vlan_header);
+
 				/*
-				 * Check if the VID of the packet, if any,
-				 * belongs to this client.
+				 * Check if the VID of the packet, if
+				 * any, belongs to this client.
+				 * Technically, if this packet came up
+				 * via a HW classified ring then we
+				 * don't need to perform this check.
+				 * Perhaps a future optimization.
 				 */
 				if (!mac_client_check_flow_vid(mcip,
 				    VLAN_ID(ntohs(evhp->ether_tci)))) {
@@ -1610,7 +1615,6 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 			 */
 			if (hw_classified && mcip->mci_promisc_list != NULL) {
 				mac_address_t		*map;
-
 				rw_enter(&mcip->mci_rw_lock, RW_READER);
 				map = mcip->mci_unicast;
 				if (bcmp(dstaddr, map->ma_addr,
@@ -1620,6 +1624,7 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 			} else if (is_unicast) {
 				type = UNDEF;
 			}
+
 		}
 
 		/*
@@ -1635,7 +1640,6 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 		 * performance and may bypass DLS. All other cases go through
 		 * the 'OTH' type path without DLS bypass.
 		 */
-
 		ipha = (ipha_t *)(mp->b_rptr + hdrsize);
 		if ((type != OTH) && MBLK_RX_FANOUT_SLOWPATH(mp, ipha))
 			type = OTH;
@@ -1647,11 +1651,13 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 		}
 
 		ASSERT(type == UNDEF);
+
 		/*
-		 * We look for at least 4 bytes past the IP header to get
-		 * the port information. If we get an IP fragment, we don't
-		 * have the port information, and we use just the protocol
-		 * information.
+		 * Determine the type from the IP protocol value. If
+		 * classified as TCP or UDP then update the read
+		 * pointer to the beginning of the IP header.
+		 * Otherwise leave the message as is for further
+		 * processing by DLS.
 		 */
 		switch (ipha->ipha_protocol) {
 		case IPPROTO_TCP:
@@ -1695,11 +1701,10 @@ mac_rx_srs_proto_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 int	fanout_unaligned = 0;
 
 /*
- * mac_rx_srs_long_fanout
- *
- * The fanout routine for VLANs, and for anything else that isn't performing
- * explicit dls bypass.  Returns -1 on an error (drop the packet due to a
- * malformed packet), 0 on success, with values written in *indx and *type.
+ * The fanout routine for any clients with DLS bypass disabled or for
+ * traffic classified as "other". Returns -1 on an error (drop the
+ * packet due to a malformed packet), 0 on success, with values
+ * written in *indx and *type.
  */
 static int
 mac_rx_srs_long_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *mp,
@@ -1862,16 +1867,15 @@ src_dst_based_fanout:
 }
 
 /*
- * mac_rx_srs_fanout
- *
- * This routine delivers packets destined to an SRS into a soft ring member
+ * This routine delivers packets destined for an SRS into a soft ring member
  * of the set.
  *
- * Given a chain of packets we need to split it up into multiple sub chains
- * destined for one of the TCP, UDP or OTH soft rings. Instead of entering
- * the soft ring one packet at a time, we want to enter it in the form of a
- * chain otherwise we get this start/stop behaviour where the worker thread
- * goes to sleep and then next packets comes in forcing it to wake up etc.
+ * Given a chain of packets we need to split it up into multiple sub
+ * chains: TCP, UDP or OTH soft ring. Instead of entering the soft
+ * ring one packet at a time, we want to enter it in the form of a
+ * chain otherwise we get this start/stop behaviour where the worker
+ * thread goes to sleep and then next packet comes in forcing it to
+ * wake up.
  *
  * Note:
  * Since we know what is the maximum fanout possible, we create a 2D array
@@ -1932,10 +1936,11 @@ mac_rx_srs_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 	    mac_srs->srs_ring->mr_classify_type == MAC_HW_CLASSIFIER;
 
 	/*
-	 * Special clients (eg. VLAN, non ether, etc) need DLS
-	 * processing in the Rx path. SRST_DLS_BYPASS will be clear for
-	 * such SRSs. Another way of disabling bypass is to set the
-	 * MCIS_RX_BYPASS_DISABLE flag.
+	 * Some clients, such as non Ethernet, need DLS processing in
+	 * the Rx path. Such clients clear the SRST_DLS_BYPASS flag.
+	 * DLS bypass may also be disabled via the
+	 * MCIS_RX_BYPASS_DISABLE flag, but this is only consumed by
+	 * sun4v vsw currently.
 	 */
 	dls_bypass = ((mac_srs->srs_type & SRST_DLS_BYPASS) != 0) &&
 	    ((mcip->mci_state_flags & MCIS_RX_BYPASS_DISABLE) == 0);
@@ -1957,7 +1962,7 @@ mac_rx_srs_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 
 	/*
 	 * We got a chain from SRS that we need to send to the soft rings.
-	 * Since squeues for TCP & IPv4 sap poll their soft rings (for
+	 * Since squeues for TCP & IPv4 SAP poll their soft rings (for
 	 * performance reasons), we need to separate out v4_tcp, v4_udp
 	 * and the rest goes in other.
 	 */
@@ -1987,9 +1992,14 @@ mac_rx_srs_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 				evhp = (struct ether_vlan_header *)mp->b_rptr;
 				sap = ntohs(evhp->ether_type);
 				hdrsize = sizeof (struct ether_vlan_header);
+
 				/*
-				 * Check if the VID of the packet, if any,
-				 * belongs to this client.
+				 * Check if the VID of the packet, if
+				 * any, belongs to this client.
+				 * Technically, if this packet came up
+				 * via a HW classified ring then we
+				 * don't need to perform this check.
+				 * Perhaps a future optimization.
 				 */
 				if (!mac_client_check_flow_vid(mcip,
 				    VLAN_ID(ntohs(evhp->ether_tci)))) {
@@ -2029,7 +2039,6 @@ mac_rx_srs_fanout(mac_soft_ring_set_t *mac_srs, mblk_t *head)
 			continue;
 		}
 
-
 		/*
 		 * If we are using the default Rx ring where H/W or S/W
 		 * classification has not happened, we need to verify if
@@ -2618,7 +2627,6 @@ again:
 
 	mac_srs->srs_state |= (SRS_PROC|proc_type);
 
-
 	/*
 	 * mcip is NULL for broadcast and multicast flows. The promisc
 	 * callbacks for broadcast and multicast packets are delivered from
@@ -2638,10 +2646,8 @@ again:
 	}
 
 	/*
-	 * Check if SRS itself is doing the processing
-	 * This direct path does not apply when subflows are present. In this
-	 * case, packets need to be dispatched to a soft ring according to the
-	 * flow's bandwidth and other resources contraints.
+	 * Check if SRS itself is doing the processing. This direct
+	 * path applies only when subflows are present.
 	 */
 	if (mac_srs->srs_type & SRST_NO_SOFT_RINGS) {
 		mac_direct_rx_t		proc;
@@ -4655,6 +4661,9 @@ mac_rx_deliver(void *arg1, mac_resource_handle_t mrh, mblk_t *mp_chain,
 		 * the packet to the promiscuous listeners of the
 		 * client, since they expect to see the whole
 		 * frame including the VLAN headers.
+		 *
+		 * The MCIS_STRIP_DISABLE is only issued when sun4v
+		 * vsw is in play.
 		 */
 		mp_chain = mac_strip_vlan_tag_chain(mp_chain);
 	}
@@ -4663,13 +4672,11 @@ mac_rx_deliver(void *arg1, mac_resource_handle_t mrh, mblk_t *mp_chain,
 }
 
 /*
- * mac_rx_soft_ring_process
- *
- * process a chain for a given soft ring. The number of packets queued
- * in the SRS and its associated soft rings (including this one) is
- * very small (tracked by srs_poll_pkt_cnt), then allow the entering
- * thread (interrupt or poll thread) to do inline processing. This
- * helps keep the latency down under low load.
+ * Process a chain for a given soft ring. If the number of packets
+ * queued in the SRS and its associated soft rings (including this
+ * one) is very small (tracked by srs_poll_pkt_cnt) then allow the
+ * entering thread (interrupt or poll thread) to process the chain
+ * inline. This is meant to reduce latency under low load.
  *
  * The proc and arg for each mblk is already stored in the mblk in
  * appropriate places.
@@ -4728,13 +4735,13 @@ mac_rx_soft_ring_process(mac_client_impl_t *mcip, mac_soft_ring_t *ringp,
 
 			ASSERT(MUTEX_NOT_HELD(&ringp->s_ring_lock));
 			/*
-			 * If we have a soft ring set which is doing
-			 * bandwidth control, we need to decrement
-			 * srs_size and count so it the SRS can have a
-			 * accurate idea of what is the real data
-			 * queued between SRS and its soft rings. We
-			 * decrement the counters only when the packet
-			 * gets processed by both SRS and the soft ring.
+			 * If we have an SRS performing bandwidth
+			 * control then we need to decrement the size
+			 * and count so the SRS has an accurate count
+			 * of the data queued between the SRS and its
+			 * soft rings. We decrement the counters only
+			 * when the packet is processed by both the
+			 * SRS and the soft ring.
 			 */
 			mutex_enter(&mac_srs->srs_lock);
 			MAC_UPDATE_SRS_COUNT_LOCKED(mac_srs, cnt);
@@ -4750,8 +4757,8 @@ mac_rx_soft_ring_process(mac_client_impl_t *mcip, mac_soft_ring_t *ringp,
 			if ((ringp->s_ring_first == NULL) ||
 			    (ringp->s_ring_state & S_RING_BLANK)) {
 				/*
-				 * We processed inline our packet and
-				 * nothing new has arrived or our
+				 * We processed a single packet inline
+				 * and nothing new has arrived or our
 				 * receiver doesn't want to receive
 				 * any packets. We are done.
 				 */
diff --git a/usr/src/uts/common/io/mac/mac_soft_ring.c b/usr/src/uts/common/io/mac/mac_soft_ring.c
index 2e056c8a2e..82dcc7b3f6 100644
--- a/usr/src/uts/common/io/mac/mac_soft_ring.c
+++ b/usr/src/uts/common/io/mac/mac_soft_ring.c
@@ -207,7 +207,7 @@ mac_soft_ring_create(int id, clock_t wait, uint16_t type,
 		ringp->s_ring_tx_hiwat =
 		    (mac_tx_soft_ring_hiwat > mac_tx_soft_ring_max_q_cnt) ?
 		    mac_tx_soft_ring_max_q_cnt : mac_tx_soft_ring_hiwat;
-		if (mcip->mci_state_flags & MCIS_IS_AGGR) {
+		if (mcip->mci_state_flags & MCIS_IS_AGGR_CLIENT) {
 			mac_srs_tx_t *tx = &mac_srs->srs_tx;
 
 			ASSERT(tx->st_soft_rings[
@@ -339,15 +339,11 @@ mac_soft_ring_fire(void *arg)
 }
 
 /*
- * mac_rx_soft_ring_drain
- *
- * Called when worker thread model (ST_RING_WORKER_ONLY) of processing
- * incoming packets is used. s_ring_first contain the queued packets.
- * s_ring_rx_func contains the upper level (client) routine where the
- * packets are destined and s_ring_rx_arg1/s_ring_rx_arg2 are the
- * cookie meant for the client.
+ * Drain the softring pointed to by ringp. s_ring_first points to the
+ * queued packet chain. s_ring_rx_func points to the client's Rx
+ * routine. s_ring_rx_{arg1,arg2} are opaque values specific to the
+ * client.
  */
-/* ARGSUSED */
 static void
 mac_rx_soft_ring_drain(mac_soft_ring_t *ringp)
 {
@@ -392,13 +388,12 @@ mac_rx_soft_ring_drain(mac_soft_ring_t *ringp)
 		(*proc)(arg1, arg2, mp, NULL);
 
 		/*
-		 * If we have a soft ring set which is doing
-		 * bandwidth control, we need to decrement its
-		 * srs_size so it can have a accurate idea of
-		 * what is the real data queued between SRS and
-		 * its soft rings. We decrement the size for a
-		 * packet only when it gets processed by both
-		 * SRS and the soft ring.
+		 * If we have an SRS performing bandwidth control then
+		 * we need to decrement the size and count so the SRS
+		 * has an accurate count of the data queued between
+		 * the SRS and its soft rings. We decrement the
+		 * counters only when the packet is processed by both
+		 * the SRS and the soft ring.
 		 */
 		mutex_enter(&mac_srs->srs_lock);
 		MAC_UPDATE_SRS_COUNT_LOCKED(mac_srs, cnt);
@@ -414,12 +409,10 @@ mac_rx_soft_ring_drain(mac_soft_ring_t *ringp)
 }
 
 /*
- * mac_soft_ring_worker
- *
  * The soft ring worker routine to process any queued packets. In
- * normal case, the worker thread is bound to a CPU. It the soft
- * ring is dealing with TCP packets, then the worker thread will
- * be bound to the same CPU as the TCP squeue.
+ * normal case, the worker thread is bound to a CPU. If the soft ring
+ * handles TCP packets then the worker thread is bound to the same CPU
+ * as the TCP squeue.
  */
 static void
 mac_soft_ring_worker(mac_soft_ring_t *ringp)
@@ -604,7 +597,7 @@ mac_soft_ring_dls_bypass(void *arg, mac_direct_rx_t rx_func, void *rx_arg1)
 	mac_soft_ring_t		*softring = arg;
 	mac_soft_ring_set_t	*srs;
 
-	ASSERT(rx_func != NULL);
+	VERIFY(rx_func != NULL);
 
 	mutex_enter(&softring->s_ring_lock);
 	softring->s_ring_rx_func = rx_func;
diff --git a/usr/src/uts/common/io/vnic/vnic_dev.c b/usr/src/uts/common/io/vnic/vnic_dev.c
index 3cb7e7660a..2d59df92d9 100644
--- a/usr/src/uts/common/io/vnic/vnic_dev.c
+++ b/usr/src/uts/common/io/vnic/vnic_dev.c
@@ -354,7 +354,7 @@ vnic_dev_create(datalink_id_t vnic_id, datalink_id_t linkid,
 
 	rw_enter(&vnic_lock, RW_WRITER);
 
-	/* does a VNIC with the same id already exist? */
+	/* Does a VNIC with the same id already exist? */
 	err = mod_hash_find(vnic_hash, VNIC_HASH_KEY(vnic_id),
 	    (mod_hash_val_t *)&vnic);
 	if (err == 0) {
diff --git a/usr/src/uts/common/mapfiles/kernel.mapfile b/usr/src/uts/common/mapfiles/kernel.mapfile
index 6bddb3c7ef..d4a23f64a4 100644
--- a/usr/src/uts/common/mapfiles/kernel.mapfile
+++ b/usr/src/uts/common/mapfiles/kernel.mapfile
@@ -10,7 +10,7 @@
 #
 
 #
-# Copyright 2016 Joyent, Inc.
+# Copyright 2017 Joyent, Inc.
 #
 
 #
@@ -36,6 +36,16 @@ $mapfile_version 2
 
 SYMBOL_SCOPE {
     global:
+	#
+	# bitset.h
+	#
+	bitset_is_null			{ FLAGS = EXTERN };
+	bitset_add			{ FLAGS = EXTERN };
+	bitset_del			{ FLAGS = EXTERN };
+	bitset_in_set			{ FLAGS = EXTERN };
+	bitset_init			{ FLAGS = EXTERN };
+	bitset_resize			{ FLAGS = EXTERN };
+
 	bt_getlowbit			{ FLAGS = EXTERN };
 	servicing_interrupt		{ FLAGS = EXTERN };
 };
diff --git a/usr/src/uts/common/sys/mac_client_impl.h b/usr/src/uts/common/sys/mac_client_impl.h
index 173d15fbb3..bc42c09941 100644
--- a/usr/src/uts/common/sys/mac_client_impl.h
+++ b/usr/src/uts/common/sys/mac_client_impl.h
@@ -24,7 +24,7 @@
  * Copyright (c) 2012, Joyent, Inc.  All rights reserved.
  */
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  */
 
 #ifndef	_SYS_MAC_CLIENT_IMPL_H
@@ -57,7 +57,7 @@ typedef struct mac_unicast_impl_s {			/* Protected by */
 	uint16_t			mui_vid;	/* SL */
 } mac_unicast_impl_t;
 
-#define	MAC_CLIENT_FLAGS_PRIMARY		0X0001
+#define	MAC_CLIENT_FLAGS_PRIMARY		0x0001
 #define	MAC_CLIENT_FLAGS_VNIC_PRIMARY		0x0002
 #define	MAC_CLIENT_FLAGS_MULTI_PRIMARY		0x0004
 #define	MAC_CLIENT_FLAGS_PASSIVE_PRIMARY	0x0008
@@ -132,12 +132,17 @@ struct mac_client_impl_s {			/* Protected by */
 	uint32_t		mci_flags;		/* SL */
 	krwlock_t		mci_rw_lock;
 	mac_unicast_impl_t	*mci_unicast_list;	/* mci_rw_lock */
+
 	/*
 	 * The mac_client_impl_t may be shared by multiple clients, i.e
 	 * multiple VLANs sharing the same MAC client. In this case the
-	 * address/vid tubles differ and are each associated with their
+	 * address/vid tuples differ and are each associated with their
 	 * own flow entry, but the rest underlying components SRS, etc,
 	 * are common.
+	 *
+	 * I believe this is only needed to support sun4v vsw. There
+	 * are several places in MAC we could simplify the code if we
+	 * removed sun4v support.
 	 */
 	flow_entry_t		*mci_flent_list;	/* mci_rw_lock */
 	uint_t			mci_nflents;		/* mci_rw_lock */
@@ -314,6 +319,74 @@ extern	int	mac_tx_percpu_cnt;
 	(((mcip)->mci_state_flags & MCIS_TAG_DISABLE) == 0 &&		\
 	(mcip)->mci_nvids == 1)						\
 
+/*
+ * MAC Client Implementation State (mci_state_flags)
+ *
+ * MCIS_IS_VNIC
+ *
+ *	The client is a VNIC.
+ *
+ * MCIS_EXCLUSIVE
+ *
+ *	The client has exclusive control over the MAC, such that it is
+ *	the sole client of the MAC.
+ *
+ * MCIS_TAG_DISABLE
+ *
+ *	MAC will not add VLAN tags to outgoing traffic. If this flag
+ *	is set it is up to the client to add the correct VLAN tag.
+ *
+ * MCIS_STRIP_DISABLE
+ *
+ *	MAC will not strip the VLAN tags on incoming traffic before
+ *	passing it to mci_rx_fn. This only applies to non-bypass
+ *	traffic.
+ *
+ * MCIS_IS_AGGR_PORT
+ *
+ *	The client represents a port on an aggr.
+ *
+ * MCIS_CLIENT_POLL_CAPABLE
+ *
+ *	The client is capable of polling the Rx TCP/UDP softrings.
+ *
+ * MCIS_DESC_LOGGED
+ *
+ *	This flag is set when the client's link info has been logged
+ *	by the mac_log_linkinfo() timer. This ensures that the
+ *	client's link info is only logged once.
+ *
+ * MCIS_SHARE_BOUND
+ *
+ *	This client has an HIO share bound to it???
+ *
+ * MCIS_DISABLE_TX_VID_CHECK
+ *
+ *	The client will not check the VID on Tx traffic.
+ *
+ * MCIS_USE_DATALINK_NAME
+ *
+ *	The client is using the same name as its underlying MAC. This
+ *	happens when dlmgmtd is unreachable during client creation.
+ *
+ * MCIS_UNICAST_HW
+ *
+ *	The client requires MAC address hardware classification. This
+ *	is only used by sun4v vsw.
+ *
+ * MCIS_IS_AGGR_CLIENT
+ *
+ *	The client sits atop an aggr.
+ *
+ * MCIS_RX_BYPASS_DISABLE
+ *
+ *	Do not allow the client to enable DLS bypass.
+ *
+ * MCIS_NO_UNICAST_ADDR
+ *
+ *	This client has no MAC unicast addresss associated with it.
+ *
+ */
 /* MCI state flags */
 #define	MCIS_IS_VNIC			0x0001
 #define	MCIS_EXCLUSIVE			0x0002
@@ -326,7 +399,7 @@ extern	int	mac_tx_percpu_cnt;
 #define	MCIS_DISABLE_TX_VID_CHECK	0x0100
 #define	MCIS_USE_DATALINK_NAME		0x0200
 #define	MCIS_UNICAST_HW			0x0400
-#define	MCIS_IS_AGGR			0x0800
+#define	MCIS_IS_AGGR_CLIENT		0x0800
 #define	MCIS_RX_BYPASS_DISABLE		0x1000
 #define	MCIS_NO_UNICAST_ADDR		0x2000
 
diff --git a/usr/src/uts/common/sys/mac_impl.h b/usr/src/uts/common/sys/mac_impl.h
index d98b8e435e..e9a696a511 100644
--- a/usr/src/uts/common/sys/mac_impl.h
+++ b/usr/src/uts/common/sys/mac_impl.h
@@ -255,8 +255,8 @@ struct mac_ring_s {
 }
 
 /*
- * Per mac client flow information associated with a RX group.
- * The entire structure is SL protected.
+ * Used to attach MAC clients to an Rx group. The members are SL
+ * protected.
  */
 typedef struct mac_grp_client {
 	struct mac_grp_client		*mgc_next;
@@ -270,15 +270,17 @@ typedef struct mac_grp_client {
 	((g)->mrg_clients->mgc_next == NULL)) ?		\
 	(g)->mrg_clients->mgc_client : NULL)
 
+#define	MAC_GROUP_UNICAST_HW	0x001
+
 /*
  * Common ring group data structure for ring control and management.
- * The entire structure is SL protected
+ * The entire structure is SL protected.
  */
 struct mac_group_s {
 	int			mrg_index;	/* index in the list */
 	mac_ring_type_t		mrg_type;	/* ring type */
 	mac_group_state_t	mrg_state;	/* state of the group */
-	mac_group_t		*mrg_next;	/* next ring in the chain */
+	mac_group_t		*mrg_next;	/* next group in the chain */
 	mac_handle_t		mrg_mh;		/* reference to MAC */
 	mac_ring_t		*mrg_rings;	/* grouped rings */
 	uint_t			mrg_cur_count;	/* actual size of group */
@@ -360,17 +362,23 @@ typedef struct mac_mcast_addrs_s {
 } mac_mcast_addrs_t;
 
 typedef enum {
-	MAC_ADDRESS_TYPE_UNICAST_CLASSIFIED = 1,	/* hardware steering */
-	MAC_ADDRESS_TYPE_UNICAST_PROMISC		/* promiscuous mode */
+	MAC_ADDRESS_TYPE_FULL_CLASSIFY = 1,	/* full HW classify */
+	MAC_ADDRESS_TYPE_PART_CLASSIFY,		/* partial HW classify */
+	MAC_ADDRESS_TYPE_PROMISC		/* promiscuous mode */
 } mac_address_type_t;
 
+typedef struct mac_vlan_s {
+	struct mac_vlan_s	*mv_next;
+	uint16_t		mv_vid;
+} mac_vlan_t;
+
 typedef struct mac_address_s {
 	mac_address_type_t	ma_type;		/* address type */
-	int			ma_nusers;		/* number of users */
-							/* of that address */
+	int			ma_nusers;		/* num users of addr */
 	struct mac_address_s	*ma_next;		/* next address */
 	uint8_t			ma_addr[MAXMACADDRLEN];	/* address value */
 	size_t			ma_len;			/* address length */
+	mac_vlan_t		*ma_vlans;		/* VLANs on this addr */
 	mac_group_t		*ma_group;		/* asscociated group */
 	mac_impl_t		*ma_mip;		/* MAC handle */
 } mac_address_t;
@@ -487,7 +495,7 @@ struct mac_impl_s {
 	mac_capab_led_t		mi_led;
 
 	/*
-	 * MAC address list. SL protected.
+	 * MAC address and VLAN lists. SL protected.
 	 */
 	mac_address_t		*mi_addresses;
 
@@ -760,6 +768,8 @@ extern void mac_client_bcast_refresh(mac_client_impl_t *, mac_multicst_t,
  */
 extern int mac_group_addmac(mac_group_t *, const uint8_t *);
 extern int mac_group_remmac(mac_group_t *, const uint8_t *);
+extern int mac_group_addvlan(mac_group_t *, uint16_t);
+extern int mac_group_remvlan(mac_group_t *, uint16_t);
 extern int mac_rx_group_add_flow(mac_client_impl_t *, flow_entry_t *,
     mac_group_t *);
 extern mblk_t *mac_hwring_tx(mac_ring_handle_t, mblk_t *);
@@ -780,6 +790,7 @@ extern void mac_rx_switch_grp_to_sw(mac_group_t *);
  * MAC address functions are used internally by MAC layer.
  */
 extern mac_address_t *mac_find_macaddr(mac_impl_t *, uint8_t *);
+extern mac_address_t *mac_find_macaddr_vlan(mac_impl_t *, uint8_t *, uint16_t);
 extern boolean_t mac_check_macaddr_shared(mac_address_t *);
 extern int mac_update_macaddr(mac_address_t *, uint8_t *);
 extern void mac_freshen_macaddr(mac_address_t *, uint8_t *);
@@ -864,9 +875,11 @@ extern int mac_start_group(mac_group_t *);
 extern void mac_stop_group(mac_group_t *);
 extern int mac_start_ring(mac_ring_t *);
 extern void mac_stop_ring(mac_ring_t *);
-extern int mac_add_macaddr(mac_impl_t *, mac_group_t *, uint8_t *, boolean_t);
-extern int mac_remove_macaddr(mac_address_t *);
+extern int mac_add_macaddr_vlan(mac_impl_t *, mac_group_t *, uint8_t *,
+    uint16_t, uint_t);
+extern int mac_remove_macaddr_vlan(mac_address_t *, uint16_t);
 
+extern boolean_t mac_group_hw_classified(mac_group_t *);
 extern void mac_set_group_state(mac_group_t *, mac_group_state_t);
 extern void mac_group_add_client(mac_group_t *, mac_client_impl_t *);
 extern void mac_group_remove_client(mac_group_t *, mac_client_impl_t *);
diff --git a/usr/src/uts/common/sys/mac_provider.h b/usr/src/uts/common/sys/mac_provider.h
index 5d94a0d7d8..9eabac5ccc 100644
--- a/usr/src/uts/common/sys/mac_provider.h
+++ b/usr/src/uts/common/sys/mac_provider.h
@@ -281,6 +281,16 @@ typedef enum {
 	MAC_RING_TYPE_TX	/* Transmit ring */
 } mac_ring_type_t;
 
+/*
+ * While VLAN_ID_NONE (VID 0) represents untagged links in userspace
+ * and MAC, it's a valid VID for priority tagging in the provider.
+ * This value represents untagged in the provider so that VID 0 may
+ * be used by the provider.
+ */
+#define	MAC_VLAN_UNTAGGED		UINT16_MAX
+#define	MAC_VLAN_UNTAGGED_VID(vid)	\
+	(((vid) == VLAN_ID_NONE) ? MAC_VLAN_UNTAGGED : (vid))
+
 /*
  * Grouping type of a ring group
  *
@@ -355,10 +365,61 @@ typedef struct mac_ring_info_s {
 #define	mri_tx			mrfunion.send
 #define	mri_poll		mrfunion.poll
 
+typedef struct mac_report {
+
+	/*
+	 * Actual number of RAR slots.
+	 */
+	uint_t rar_entries;
+
+	uint32_t vlnctrl;
+
+	/*
+	 * There are two 32-bit regs per RAR.
+	 */
+	uint32_t ral[128];
+	uint32_t rah[128];
+
+	/*
+	 * Two 32-bit MPSAR regs for each RAR (Rx Address Register).
+	 * For now I'm hardcoding the RARs to 128.
+	 */
+	uint32_t mpsar_lo[128];
+	uint32_t mpsar_hi[128];
+
+	/*
+	 * 128 * 32 = 4096 (bit per VLAN)
+	 */
+	uint32_t vfta[128];
+
+	/*
+	 * There are 64 groups max, thus 64 bits.
+	 */
+	uint32_t vfre[2];
+
+	/*
+	 * 64 VLVF slots
+	 */
+	uint32_t vlvf[64];
+
+	/*
+	 * Two 32-bit slots in VLVFB per VLVF slot
+	 */
+	uint32_t vlvfb[128];
+
+	/*
+	 * 64 VM Inexact L2 filtering registers (IXGBE_VMOLR in the
+	 * code), one per group.
+	 */
+	uint32_t vml2flt[64];
+} mac_report_t;
+
 /*
  * #defines for mri_flags. The flags are temporary flags that are provided
  * only to workaround issues in specific drivers, and they will be
  * removed in the future.
+ *
+ * These are consumed only by sun4v and neptune (nxge).
  */
 #define	MAC_RING_TX_SERIALIZE		0x1
 #define	MAC_RING_RX_ENQUEUE		0x2
@@ -367,6 +428,9 @@ typedef	int	(*mac_group_start_t)(mac_group_driver_t);
 typedef	void	(*mac_group_stop_t)(mac_group_driver_t);
 typedef	int	(*mac_add_mac_addr_t)(void *, const uint8_t *);
 typedef	int	(*mac_rem_mac_addr_t)(void *, const uint8_t *);
+typedef int	(*mac_add_vlan_filter_t)(mac_group_driver_t, uint16_t);
+typedef int	(*mac_rem_vlan_filter_t)(mac_group_driver_t, uint16_t);
+typedef int	(*mac_get_report_t)(mac_group_driver_t, mac_report_t *);
 
 struct mac_group_info_s {
 	mac_group_driver_t	mgi_driver;	/* Driver reference */
@@ -375,9 +439,13 @@ struct mac_group_info_s {
 	uint_t			mgi_count;	/* Count of rings */
 	mac_intr_t		mgi_intr;	/* Optional per-group intr */
 
-	/* Only used for rx groups */
+	/* Only used for Rx groups */
 	mac_add_mac_addr_t	mgi_addmac;	/* Add a MAC address */
 	mac_rem_mac_addr_t	mgi_remmac;	/* Remove a MAC address */
+	mac_add_vlan_filter_t	mgi_addvlan;	/* Add a VLAN filter */
+	mac_rem_vlan_filter_t	mgi_remvlan;	/* Remove a VLAN filter */
+
+	mac_get_report_t	mgi_report; /* Generate a report. */
 };
 
 /*
diff --git a/usr/src/uts/intel/ixgbe/Makefile b/usr/src/uts/intel/ixgbe/Makefile
index 26d0e670f2..6548b636fb 100644
--- a/usr/src/uts/intel/ixgbe/Makefile
+++ b/usr/src/uts/intel/ixgbe/Makefile
@@ -68,9 +68,9 @@ LINT_TARGET	= $(MODULE).lint
 INSTALL_TARGET	= $(BINARY) $(ROOTMODULE) $(ROOT_CONFFILE)
 
 #
-# Driver depends on MAC
+# Driver depends on MAC and on bitset from genunix.
 #
-LDFLAGS		+= -dy -N misc/mac
+LDFLAGS		+= -dy -N misc/mac -N kernel/genunix
 MAPFILES	+= ddi mac random kernel
 
 #
