commit fe4a6bc7fecb0de0a5e1101c0a12369f1bae1911
Author: Mohamed Khalfella <mohamed.khalfella@joyent.com>
Date:   2019-04-14T00:21:05+00:00 (6 months ago)
    
    MANTA-3678 storage metering could use some more memory

diff --git a/assets/bin/storage-reduce1 b/assets/bin/storage-reduce1
index 9bbbab5..ac1264a 100755
--- a/assets/bin/storage-reduce1
+++ b/assets/bin/storage-reduce1
@@ -15,17 +15,13 @@ dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 NODE=$dir/../build/node/bin/node
 
 #
-# This phase of the job constructs a large in-memory object aggregating all of
-# the input data.  For very large input sizes, this object can exhaust the
-# default node heap limit.  We increase the "old space" cap to allow for the
-# aggregation of a larger quantity of objects per reducer process.
-#
-# Note that this is something of a stop-gap: a 32-bit node process likely
-# cannot continue to be grown much, if at all, beyond this size.  In the
-# future, the aggregation of input records should be tracked using a mechanism
-# that can easily spill to disk; e.g., by using a SQLite or other disk-based
-# database.
+# Every task in this phase produces a summary of accounts' usage. To
+# consider snaplinks, each task stores processed objects in a sqlite
+# database table to be queried later on as we process new objects.
+# This way, we guarantee that each stored object is accounted for
+# once, regardless of the number of snaplinks pointing to that object.
 #
+
 $ZCAT \
-| $NODE --max_old_space_size=1300 $dir/../lib/storage-reduce1.js \
+| $NODE $dir/../lib/storage-reduce1.js \
 | msplit -j -n $NUM_REDUCERS -f owner,namespace
diff --git a/assets/lib/storage-reduce1.js b/assets/lib/storage-reduce1.js
index 3a521e3..411b7e9 100755
--- a/assets/lib/storage-reduce1.js
+++ b/assets/lib/storage-reduce1.js
@@ -6,7 +6,13 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2019, Joyent, Inc.
+ */
+
+/*
+ * This is the phase that does the real accounting of customers' usage in manta.
+ * It receives the a stream of JSON objects representing objects and directories
+ * stored in manta, and produces a summary usage record for each user.
  */
 
 /* BEGIN JSSTYLED */
@@ -65,18 +71,31 @@
  *                      namespace: 0,
  *                      ...
  *              },
- *              "objects": {
- *                      objectId: {
- *                              namespace: 0, // count of # keys in this
- *                                            // namespace for this objectId
- *                              ...
- *                              _size: 0
- *                      },
+ *              "objs": {
+ *                      namespace: 0,
+ *                      ...
+ *              },
+ *              "keys": {
+ *                      namespace: 0,
+ *                      ...
+ *              },
+ *              "bytes": {
+ *                      namespace: 0,
  *                      ...
- *              }
+ *              },
  *      },
  *      ...
  * }
+ *
+ * SQLite table structure
+ *
+ * ------------------------------------
+ * |  OWNER_UUID   |    OBJECT_UUID   |
+ * ------------------------------------
+ * |               |                  |
+ * ------------------------------------
+ * |               |                  |
+ * ------------------------------------
  */
 
 /*
@@ -93,11 +112,19 @@
 
 /* END JSSTYLED */
 
-var mod_carrier = require('carrier');
+var lstream = require('lstream');
+var stream = require('stream');
+var fs = require('fs');
+var sqlite3 = require('sqlite3');
 var Big = require('big.js');
-var ERROR = false;
+
+
+var sstmt = null;	// This is a prepared select statement
+var istmt = null;	// A prepared insert statement
+
 var MIN_SIZE = +process.env['MIN_SIZE'] || 131072;
 
+
 var LOG = require('bunyan').createLogger({
         name: 'storage-reduce1.js',
         stream: process.stderr,
@@ -105,92 +132,108 @@ var LOG = require('bunyan').createLogger({
 });
 
 var NAMESPACES = (process.env.NAMESPACES).split(' ');
+var DBFILE = +process.env['DBFILE'] || '/var/tmp/objects.db';
+
+function fatal(message)
+{
+        LOG.fatal(message);
+        process.exit(1);
+}
 
-function count(record, aggr) {
+function processLine(record, aggr, db, done) {
         var owner = record.owner;
         var type = record.type;
         var namespace;
+        var n;
+
         try {
                 namespace = record.key.split('/')[2]; // /:uuid/:namespace/...
-        } catch (e) {
-                LOG.error(e, 'error getting namespace: ' + record.key);
-                ERROR = true;
+        } catch (_e) {
+                fatal('Error getting namespace: ' + record.key);
                 return;
         }
 
-        aggr[owner] = aggr[owner] || {
-                dirs: {},
-                objects: {}
-        };
+        // Create an owner record if we haven't see this account before
+        if (!aggr[owner]) {
+                aggr[owner] = {
+                    dirs: {},
+                    objs: {},
+                    keys: {},
+                    bytes: {}
+                };
+
+                for (n in NAMESPACES) {
+                        aggr[owner].dirs[NAMESPACES[n]] = 0;
+                        aggr[owner].objs[NAMESPACES[n]] = 0;
+                        aggr[owner].keys[NAMESPACES[n]] = 0;
+                        aggr[owner].bytes[NAMESPACES[n]] = new Big(0);
+                }
+        }
 
-        aggr[owner].dirs[namespace] = aggr[owner].dirs[namespace] || 0;
+         // Ignore objects and directories in other namespaces
+        if (!(aggr[owner].bytes[namespace])) {
+                done();
+                return;
+        }
 
         if (type === 'directory') {
                 aggr[owner].dirs[namespace]++;
+                done();
+                return;
         } else if (type === 'object') {
-                var index = aggr[owner].objects;
-                var n;
+                var objectId, size;
                 try {
-                        var objectId = record.objectId;
-                        var size = Math.max(record.contentLength, MIN_SIZE) *
+                        objectId = record.objectId;
+                        size = Math.max(record.contentLength, MIN_SIZE) *
                             record.sharks.length;
                 } catch (e) {
-                        console.warn(e);
+                        fatal('Error processing object record\n' +
+                            record + '\n' + e);
                         return;
                 }
 
-                if (!index[objectId]) {
-                        index[objectId] = {};
-                        for (n in NAMESPACES) {
-                                index[objectId][NAMESPACES[n]] = 0;
+                // Add the owner, objectId to sqlite table
+                istmt.run([owner, objectId], function (er) {
+                        if (er) {
+                                /*
+                                 * It is ok if we failed to insert the
+                                 * object record because it already
+                                 * exists. In this case, we increment
+                                 * the number of keys and return.
+                                 */
+                                if (er.code === 'SQLITE_CONSTRAINT') {
+                                        aggr[owner].keys[namespace]++;
+                                        done();
+                                } else {
+                                        fatal('sqlite3 error: ' + er);
+                                }
+                                return;
                         }
-                }
 
-                index[objectId][namespace]++;
-                index[objectId]._size = size;
+                        aggr[owner].keys[namespace]++;
+                        aggr[owner].objs[namespace]++;
+                        aggr[owner].bytes[namespace] =
+                            aggr[owner].bytes[namespace].plus(size);
+                        done();
+                });
+
         } else {
-                LOG.error(record, 'unrecognized object type: ' + type);
-                ERROR = true;
+                fatal('unrecognized object type: ' + type + '\n' + record);
         }
 }
 
 function printResults(aggr) {
-        var n, dirs;
+        var n, bytes;
         Object.keys(aggr).forEach(function (owner) {
-                var keys = {};
-                var bytes = {};
-                var objects = {};
-
                 for (n in NAMESPACES) {
-                        keys[NAMESPACES[n]] = 0;
-                        bytes[NAMESPACES[n]] = new Big(0);
-                        objects[NAMESPACES[n]] = 0;
-                }
-
-                Object.keys(aggr[owner].objects).forEach(function (object) {
-                        var counted = false;
-                        var objCounts = aggr[owner].objects[object];
-                        for (n in NAMESPACES) {
-                                if (!counted && objCounts[NAMESPACES[n]] > 0) {
-                                        counted = true;
-                                        var size = objCounts._size;
-                                        bytes[NAMESPACES[n]] =
-                                                bytes[NAMESPACES[n]].plus(size);
-                                        objects[NAMESPACES[n]]++;
-                                }
-                                keys[NAMESPACES[n]] += objCounts[NAMESPACES[n]];
-                        }
-                });
-
-                for (n in NAMESPACES) {
-                        dirs = aggr[owner].dirs[NAMESPACES[n]] || 0;
+                        bytes = aggr[owner].bytes[NAMESPACES[n]].toString();
                         console.log(JSON.stringify({
                                 owner: owner,
                                 namespace: NAMESPACES[n],
-                                directories: dirs,
-                                keys: keys[NAMESPACES[n]],
-                                objects: objects[NAMESPACES[n]],
-                                bytes: bytes[NAMESPACES[n]].toString()
+                                directories: aggr[owner].dirs[NAMESPACES[n]],
+                                keys: aggr[owner].keys[NAMESPACES[n]],
+                                objects: aggr[owner].objs[NAMESPACES[n]],
+                                bytes: bytes
                         }));
                 }
         });
@@ -198,39 +241,82 @@ function printResults(aggr) {
 
 
 function main() {
-        var carry = mod_carrier.carry(process.openStdin());
 
         var aggr = {};
         var lineCount = 0;
-        carry.on('line', function onLine(line) {
+
+        try {
+                fs.unlinkSync(DBFILE);
+        } catch (e) {
+        }
+
+        function sqlite3_execute(sqdb, cmd, args) {
+                sqdb.run(cmd, args, function (error) {
+                        if (error) {
+                                fatal('sqlite3: error executing '
+                                    + '"' + cmd + '"\n' + error);
+                        }
+                });
+        }
+
+        function sqlite3_prepare_stmt(sqdb, stmt, args) {
+                return (sqdb.prepare(stmt, args, function (error) {
+                        if (error) {
+                                fatal('sqlite3: error executing ' +
+                                    '"' + stmt + '"\n' + error);
+                        }
+                }));
+        }
+
+        var db = new sqlite3.cached.Database(DBFILE);
+        db.serialize(function () {
+                // We are trading safety for performance
+                sqlite3_execute(db, 'PRAGMA synchronous = OFF', []);
+                sqlite3_execute(db, 'PRAGMA journal_mode = OFF', []);
+                sqlite3_execute(db, 'PRAGMA locking_mode = EXCLUSIVE', []);
+                // 1.5 GB of cache.
+                sqlite3_execute(db, 'PRAGMA cache_size = 393216', []);
+                // This will create an index on (owner_uuid, object_uuid)
+                sqlite3_execute(db, 'CREATE TABLE objects ' +
+                    '(owner_uuid TEXT, object_uuid TEXT, ' +
+                    'PRIMARY KEY (owner_uuid, object_uuid))', []);
+
+                sstmt = sqlite3_prepare_stmt(db,
+                    'SELECT * FROM objects ' +
+                    'WHERE owner_uuid = ? and object_uuid = ?', []);
+                istmt = sqlite3_prepare_stmt(db,
+                    'INSERT INTO objects VALUES (?, ?)', []);
+
+                sqlite3_execute(db, 'BEGIN TRANSACTION', []);
+        });
+
+
+        var transform = new stream.Transform({ objectMode: true });
+
+        transform._transform = function (line, _encoding, done) {
                 lineCount++;
                 try {
                         var record = JSON.parse(line);
                 } catch (e) {
-                        LOG.error(e, 'Error on line ' + lineCount);
-                        ERROR = true;
+                        fatal('Error parsing line: ' + lineCount +
+                            '\n"' + line + '"\n' + e);
                         return;
                 }
 
                 if (!record.owner || !record.type) {
-                        LOG.error(line, 'Missing owner or type field on line ' +
-                                lineCount);
-                        ERROR = true;
-                        return;
+                        fatal('Missing owner or type field on line: ' +
+                                lineCount + '\n' + record);
                 }
+                processLine(record, aggr, db, done);
+        };
 
-                count(record, aggr);
-        });
+        // Print the output when done
+        transform._flush =  printResults.bind(null, aggr);
+
+        process.stdin.pipe(new lstream()).pipe(transform);
 
-        carry.on('end', function onEnd() {
-                printResults(aggr);
-        });
 }
 
 if (require.main === module) {
-        process.on('exit', function onExit() {
-                process.exit(ERROR);
-        });
-
         main();
 }
diff --git a/package.json b/package.json
index 99bc45a..27107fd 100644
--- a/package.json
+++ b/package.json
@@ -24,6 +24,7 @@
                 "screener": "0.0.5",
                 "lstream": "0.0.4",
                 "uuid": "3.3.2",
+                "sqlite3": "3.1.9",
                 "vasync": "1.3.3"
         },
         "devDependencies": {
