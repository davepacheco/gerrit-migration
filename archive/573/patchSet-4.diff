From 8c18c45418dee59162ac65e355ec73efaf885d86 Mon Sep 17 00:00:00 2001
From: Patrick Mooney <pmooney@pfmooney.com>
Date: Mon, 19 Sep 2016 19:38:38 +0000
Subject: [PATCH] OS-5667 lxbrand move sched_*affinity syscalls in-kernel
 Reviewed by: Jerry Jelinek <jerry.jelinek@joyent.com> Approved by: Jerry
 Jelinek <jerry.jelinek@joyent.com>

---
 usr/src/lib/brand/lx/lx_brand/common/clone.c  |  15 -
 .../lib/brand/lx/lx_brand/common/lx_brand.c   |   8 +-
 usr/src/lib/brand/lx/lx_brand/common/sched.c  | 148 +--------
 .../lib/brand/lx/lx_brand/sys/lx_syscall.h    |   2 -
 usr/src/lib/brand/lx/testing/ltp_skiplist     |   2 -
 usr/src/uts/common/brand/lx/os/lx_brand.c     |  12 -
 usr/src/uts/common/brand/lx/os/lx_misc.c      |  12 +-
 usr/src/uts/common/brand/lx/os/lx_syscall.c   |   8 +-
 usr/src/uts/common/brand/lx/sys/lx_brand.h    |   7 +-
 usr/src/uts/common/brand/lx/sys/lx_misc.h     |   2 +
 usr/src/uts/common/brand/lx/sys/lx_syscalls.h |   2 +
 .../uts/common/brand/lx/syscall/lx_sched.c    | 298 ++++++++++++++----
 12 files changed, 268 insertions(+), 248 deletions(-)

diff --git a/usr/src/lib/brand/lx/lx_brand/common/clone.c b/usr/src/lib/brand/lx/lx_brand/common/clone.c
index 404808e4da..586c042a83 100644
--- a/usr/src/lib/brand/lx/lx_brand/common/clone.c
+++ b/usr/src/lib/brand/lx/lx_brand/common/clone.c
@@ -93,7 +93,6 @@ struct clone_state {
 	struct lx_desc	*c_ldtinfo;	/* thread-specific segment */
 	void		*c_ctidp;
 	ucontext_t	c_uc;		/* original register state/sigmask */
-	lx_affmask_t	c_affmask;	/* CPU affinity mask */
 	volatile int	*c_clone_res;	/* pid/error returned to cloner */
 	int		c_ptrace_event;	/* ptrace(2) event for child stop */
 	void		*c_ntv_stk;	/* native stack for this thread */
@@ -205,14 +204,6 @@ clone_start(void *arg)
 		return (NULL);
 	}
 
-	if (lx_sched_setaffinity(0, sizeof (cs->c_affmask),
-	    (uintptr_t)&cs->c_affmask) != 0) {
-		*(cs->c_clone_res) = -errno;
-
-		lx_err_fatal("Unable to set affinity mask in child thread: %s",
-		    strerror(errno));
-	}
-
 	/*
 	 * Initialize the thread specific data for this thread.
 	 */
@@ -635,12 +626,6 @@ lx_clone(uintptr_t p1, uintptr_t p2, uintptr_t p3, uintptr_t p4, uintptr_t p5)
 		return (-ENOMEM);
 	}
 
-	if (lx_sched_getaffinity(0, sizeof (cs->c_affmask),
-	    (uintptr_t)&cs->c_affmask) == -1) {
-		lx_err_fatal("Unable to get affinity mask for parent "
-		    "thread: %s", strerror(errno));
-	}
-
 	clone_res = 0;
 
 	/*
diff --git a/usr/src/lib/brand/lx/lx_brand/common/lx_brand.c b/usr/src/lib/brand/lx/lx_brand/common/lx_brand.c
index 2e0390fe4e..d98b73941e 100644
--- a/usr/src/lib/brand/lx/lx_brand/common/lx_brand.c
+++ b/usr/src/lib/brand/lx/lx_brand/common/lx_brand.c
@@ -1214,8 +1214,8 @@ static lx_syscall_handler_t lx_handlers[] = {
 	NULL,				/* 200: tkill */
 	NULL,				/* 201: time */
 	NULL,				/* 202: futex */
-	lx_sched_setaffinity,		/* 203: sched_setaffinity */
-	lx_sched_getaffinity,		/* 204: sched_getaffinity */
+	NULL,				/* 203: sched_setaffinity */
+	NULL,				/* 204: sched_getaffinity */
 	NULL,				/* 205: set_thread_area */
 	lx_io_setup,			/* 206: io_setup */
 	lx_io_destroy,			/* 207: io_destroy */
@@ -1583,8 +1583,8 @@ static lx_syscall_handler_t lx_handlers[] = {
 	NULL,				/* 238: tkill */
 	lx_sendfile64,			/* 239: sendfile64 */
 	NULL,				/* 240: futex */
-	lx_sched_setaffinity,		/* 241: sched_setaffinity */
-	lx_sched_getaffinity,		/* 242: sched_getaffinity */
+	NULL,				/* 241: sched_setaffinity */
+	NULL,				/* 242: sched_getaffinity */
 	NULL,				/* 243: set_thread_area */
 	NULL,				/* 244: get_thread_area */
 	lx_io_setup,			/* 245: io_setup */
diff --git a/usr/src/lib/brand/lx/lx_brand/common/sched.c b/usr/src/lib/brand/lx/lx_brand/common/sched.c
index 97d4625824..80b7660985 100644
--- a/usr/src/lib/brand/lx/lx_brand/common/sched.c
+++ b/usr/src/lib/brand/lx/lx_brand/common/sched.c
@@ -22,7 +22,7 @@
 /*
  * Copyright 2006 Sun Microsystems, Inc.  All rights reserved.
  * Use is subject to license terms.
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2016 Joyent, Inc.
  */
 
 #include <sys/types.h>
@@ -196,152 +196,6 @@ stol_sparam(int policy, struct sched_param *sp, struct lx_sched_param *lsp)
 	    ? -errno : 0);
 }
 
-#define	BITINDEX(ind)	(ind / (sizeof (uint_t) * 8))
-#define	BITSHIFT(ind)	(1 << (ind % (sizeof (uint_t) * 8)))
-
-/* ARGSUSED */
-long
-lx_sched_getaffinity(uintptr_t pid, uintptr_t len, uintptr_t maskp)
-{
-	int	sz;
-	uint_t	*lmask, *zmask;
-	int	i;
-
-	sz = syscall(SYS_brand, B_GET_AFFINITY_MASK, pid, len, maskp);
-	if (sz == -1)
-		return (-errno);
-
-	/*
-	 * If the target LWP hasn't ever had an affinity mask set, the kernel
-	 * will return a mask of all 0's. If that is the case we must build a
-	 * default mask that has all valid bits turned on.
-	 */
-	lmask = SAFE_ALLOCA(sz);
-	zmask = SAFE_ALLOCA(sz);
-	if (lmask == NULL || zmask == NULL)
-		return (-ENOMEM);
-
-	bzero(zmask, sz);
-
-	if (uucopy((void *)maskp, lmask, sz) != 0)
-		return (-EFAULT);
-
-	if (bcmp(lmask, zmask, sz) != 0)
-		return (sz);
-
-	for (i = 0; i < sz * 8; i++) {
-		if (p_online(i, P_STATUS) != -1) {
-			lmask[BITINDEX(i)] |= BITSHIFT(i);
-		}
-	}
-
-	if (uucopy(lmask, (void *)maskp, sz) != 0)
-		return (-EFAULT);
-
-	return (sz);
-}
-
-/* ARGSUSED */
-long
-lx_sched_setaffinity(uintptr_t pid, uintptr_t len, uintptr_t maskp)
-{
-	int		ret;
-	int		sz;
-	int		i;
-	int		found;
-	uint_t		*lmask;
-	pid_t		s_pid;
-	lwpid_t		s_tid;
-	processorid_t	cpuid = NULL;
-
-	if ((pid_t)pid < 0)
-		return (-EINVAL);
-
-	if (lx_lpid_to_spair(pid, &s_pid, &s_tid) < 0)
-		return (-ESRCH);
-
-	/*
-	 * We only support setting affinity masks for threads in
-	 * the calling process.
-	 */
-	if (s_pid != getpid())
-		return (-EPERM);
-
-	/*
-	 * First, get the minimum bitmask size from the kernel.
-	 */
-	sz = syscall(SYS_brand, B_GET_AFFINITY_MASK, 0, 0, 0);
-	if (sz == -1)
-		return (-errno);
-
-	lmask = SAFE_ALLOCA(sz);
-	if (lmask == NULL)
-		return (-ENOMEM);
-
-	if (uucopy((void *)maskp, lmask, sz) != 0)
-		return (-EFAULT);
-
-	/*
-	 * Make sure the mask contains at least one processor that is
-	 * physically on the system. Reduce the user's mask to the set of
-	 * physically present CPUs. Keep track of how many valid
-	 * bits are set in the user's mask.
-	 */
-
-	for (found = 0, i = 0; i < sz * 8; i++) {
-		if (p_online(i, P_STATUS) == -1) {
-			/*
-			 * This CPU doesn't exist, so clear this bit from
-			 * the user's mask.
-			 */
-			lmask[BITINDEX(i)] &= ~BITSHIFT(i);
-			continue;
-		}
-
-		if ((lmask[BITINDEX(i)] & BITSHIFT(i)) == BITSHIFT(i)) {
-			found++;
-			cpuid = i;
-		}
-	}
-
-	if (found == 0) {
-		lx_debug("\tlx_sched_setaffinity: mask has no present CPUs\n");
-		return (-EINVAL);
-	}
-
-	/*
-	 * If only one bit is set, bind the thread to that procesor;
-	 * otherwise, clear the binding.
-	 */
-	if (found == 1) {
-		lx_debug("\tlx_sched_setaffinity: binding thread %d to cpu%d\n",
-		    s_tid, cpuid);
-		if (processor_bind(P_LWPID, s_tid, cpuid, NULL) != 0)
-			/*
-			 * It could be that the requested processor is offline,
-			 * so we'll just abandon our good-natured attempt to
-			 * bind to it.
-			 */
-			lx_debug("couldn't bind LWP %d to cpu %d: %s\n", s_tid,
-			    cpuid, strerror(errno));
-	} else {
-		lx_debug("\tlx_sched_setaffinity: clearing thr %d binding\n",
-		    s_tid);
-		if (processor_bind(P_LWPID, s_tid, PBIND_NONE, NULL) != 0) {
-			lx_debug("couldn't clear CPU binding for LWP %d: %s\n",
-			    s_tid, strerror(errno));
-		}
-	}
-
-	/*
-	 * Finally, ask the kernel to make a note of our current (though fairly
-	 * meaningless) affinity mask.
-	 */
-	ret = syscall(SYS_brand, B_SET_AFFINITY_MASK, pid, sz, lmask);
-
-	return ((ret == 0) ? 0 : -errno);
-}
-
 long
 lx_sched_getparam(uintptr_t pid, uintptr_t param)
 {
diff --git a/usr/src/lib/brand/lx/lx_brand/sys/lx_syscall.h b/usr/src/lib/brand/lx/lx_brand/sys/lx_syscall.h
index ed6f4c2bc4..1f255a8c58 100644
--- a/usr/src/lib/brand/lx/lx_brand/sys/lx_syscall.h
+++ b/usr/src/lib/brand/lx/lx_brand/sys/lx_syscall.h
@@ -162,8 +162,6 @@ extern long lx_setpriority(uintptr_t, uintptr_t, uintptr_t);
 
 extern long lx_ptrace(uintptr_t, uintptr_t, uintptr_t, uintptr_t);
 
-extern long lx_sched_getaffinity(uintptr_t, uintptr_t, uintptr_t);
-extern long lx_sched_setaffinity(uintptr_t, uintptr_t, uintptr_t);
 extern long lx_sched_getparam(uintptr_t, uintptr_t);
 extern long lx_sched_setparam(uintptr_t, uintptr_t);
 extern long lx_sched_rr_get_interval(uintptr_t pid, uintptr_t);
diff --git a/usr/src/lib/brand/lx/testing/ltp_skiplist b/usr/src/lib/brand/lx/testing/ltp_skiplist
index e2dccf2ffa..e98654f4e9 100644
--- a/usr/src/lib/brand/lx/testing/ltp_skiplist
+++ b/usr/src/lib/brand/lx/testing/ltp_skiplist
@@ -75,8 +75,6 @@ sched_getparam01
 sched_getparam02
 sched_setscheduler01
 sched_setscheduler03	# OS-5524
-sched_setaffinity01
-sched_getaffinity01
 sched_setparam02
 sched_setparam03
 setfsuid04
diff --git a/usr/src/uts/common/brand/lx/os/lx_brand.c b/usr/src/uts/common/brand/lx/os/lx_brand.c
index 8b2c5d39c4..c615a50f43 100644
--- a/usr/src/uts/common/brand/lx/os/lx_brand.c
+++ b/usr/src/uts/common/brand/lx/os/lx_brand.c
@@ -1524,18 +1524,6 @@ lx_brandsys(int cmd, int64_t *rval, uintptr_t arg1, uintptr_t arg2,
 		return (0);
 	}
 
-	case B_SET_AFFINITY_MASK:
-	case B_GET_AFFINITY_MASK:
-		/*
-		 * Retrieve or store the CPU affinity mask for the
-		 * requested linux pid.
-		 *
-		 * arg1 is a linux PID (0 means curthread).
-		 * arg2 is the size of the given mask.
-		 * arg3 is the address of the affinity mask.
-		 */
-		return (lx_sched_affinity(cmd, arg1, arg2, arg3, rval));
-
 	case B_PTRACE_STOP_FOR_OPT:
 		return (lx_ptrace_stop_for_option((int)arg1, arg2 == 0 ?
 		    B_FALSE : B_TRUE, (ulong_t)arg3, arg4));
diff --git a/usr/src/uts/common/brand/lx/os/lx_misc.c b/usr/src/uts/common/brand/lx/os/lx_misc.c
index 01fbfca382..bc6d0a1c00 100644
--- a/usr/src/uts/common/brand/lx/os/lx_misc.c
+++ b/usr/src/uts/common/brand/lx/os/lx_misc.c
@@ -344,6 +344,7 @@ lx_lwpdata_alloc(proc_t *p)
 {
 	lx_lwp_data_t *lwpd;
 	struct lx_pid *lpidp;
+	cpuset_t *affmask;
 	pid_t newpid = 0;
 	struct pid *pidp = NULL;
 
@@ -364,10 +365,13 @@ lx_lwpdata_alloc(proc_t *p)
 
 	lwpd = kmem_zalloc(sizeof (struct lx_lwp_data), KM_SLEEP);
 	lpidp = kmem_zalloc(sizeof (struct lx_pid), KM_SLEEP);
+	affmask = cpuset_alloc(KM_SLEEP);
 
 	lpidp->l_pid = newpid;
 	lpidp->l_pidp = pidp;
 	lwpd->br_lpid = lpidp;
+	lwpd->br_affinitymask = affmask;
+
 	return (lwpd);
 }
 
@@ -382,7 +386,9 @@ lx_lwpdata_free(void *lwpbd)
 	lx_lwp_data_t *lwpd = (lx_lwp_data_t *)lwpbd;
 	VERIFY(lwpd != NULL);
 	VERIFY(lwpd->br_lpid != NULL);
+	VERIFY(lwpd->br_affinitymask != NULL);
 
+	cpuset_free(lwpd->br_affinitymask);
 	if (lwpd->br_lpid->l_pidp != NULL) {
 		(void) pid_rele(lwpd->br_lpid->l_pidp);
 	}
@@ -409,10 +415,7 @@ lx_initlwp(klwp_t *lwp, void *lwpbd)
 	lwpd->br_set_ctidp = NULL;
 	lwpd->br_signal = 0;
 	lwpd->br_stack_mode = LX_STACK_MODE_PREINIT;
-	/*
-	 * lwpd->br_affinitymask was zeroed by kmem_zalloc()
-	 * as was lwpd->br_scall_args and lwpd->br_args_size.
-	 */
+	cpuset_all(lwpd->br_affinitymask);
 
 	/*
 	 * The first thread in a process has ppid set to the parent
@@ -548,6 +551,7 @@ lx_forklwp(klwp_t *srclwp, klwp_t *dstlwp)
 	 */
 	dst->br_lwp_flags = src->br_lwp_flags & BR_CPU_BOUND;
 	dst->br_scall_args = NULL;
+	lx_affinity_forklwp(srclwp, dstlwp);
 
 	/*
 	 * Flag so child doesn't ptrace-stop on syscall exit.
diff --git a/usr/src/uts/common/brand/lx/os/lx_syscall.c b/usr/src/uts/common/brand/lx/os/lx_syscall.c
index 86715607ab..bfd77c029f 100644
--- a/usr/src/uts/common/brand/lx/os/lx_syscall.c
+++ b/usr/src/uts/common/brand/lx/os/lx_syscall.c
@@ -760,8 +760,8 @@ lx_sysent_t lx_sysent32[] = {
 	{"tkill",	lx_tkill,		0,		2}, /* 238 */
 	{"sendfile64",	NULL,			0,		4}, /* 239 */
 	{"futex",	lx_futex,		LX_SYS_EBPARG6,	6}, /* 240 */
-	{"sched_setaffinity", NULL, 		0,		3}, /* 241 */
-	{"sched_getaffinity", NULL, 		0,		3}, /* 242 */
+	{"sched_setaffinity", lx_sched_setaffinity,	0,	3}, /* 241 */
+	{"sched_getaffinity", lx_sched_getaffinity,	0,	3}, /* 242 */
 	{"set_thread_area", lx_set_thread_area,	0,		1}, /* 243 */
 	{"get_thread_area", lx_get_thread_area,	0,		1}, /* 244 */
 	{"io_setup",	lx_io_setup,		0,		2}, /* 245 */
@@ -1093,8 +1093,8 @@ lx_sysent_t lx_sysent64[] = {
 	{"tkill",	lx_tkill,		0,		2}, /* 200 */
 	{"time",	lx_time,		0,		1}, /* 201 */
 	{"futex",	lx_futex,		0,		6}, /* 202 */
-	{"sched_setaffinity", NULL,		0,		3}, /* 203 */
-	{"sched_getaffinity", NULL,		0,		3}, /* 204 */
+	{"sched_setaffinity", lx_sched_setaffinity,	0,	3}, /* 203 */
+	{"sched_getaffinity", lx_sched_getaffinity,	0,	3}, /* 204 */
 	{"set_thread_area", lx_set_thread_area, 0,		1}, /* 205 */
 	{"io_setup",	lx_io_setup,		0,		2}, /* 206 */
 	{"io_destroy",	NULL,			0,		1}, /* 207 */
diff --git a/usr/src/uts/common/brand/lx/sys/lx_brand.h b/usr/src/uts/common/brand/lx/sys/lx_brand.h
index 44ea80070d..4082b36091 100644
--- a/usr/src/uts/common/brand/lx/sys/lx_brand.h
+++ b/usr/src/uts/common/brand/lx/sys/lx_brand.h
@@ -38,6 +38,7 @@
 #include <sys/vfs.h>
 #include <sys/sunddi.h>
 #include <sys/sunldi.h>
+#include <sys/cpuvar.h>
 #endif
 
 #ifdef	__cplusplus
@@ -90,8 +91,8 @@ extern "C" {
 #define	B_GET_CURRENT_CONTEXT	129
 #define	B_EMULATION_DONE	130
 /* formerly B_PTRACE_KERNEL	131 */
-#define	B_SET_AFFINITY_MASK	132
-#define	B_GET_AFFINITY_MASK	133
+/* formerly B_SET_AFFINITY_MASK	132 */
+/* formerly B_GET_AFFINITY_MASK	133 */
 #define	B_PTRACE_CLONE_BEGIN	134
 #define	B_PTRACE_STOP_FOR_OPT	135
 #define	B_UNSUPPORTED		136
@@ -456,7 +457,7 @@ struct lx_lwp_data {
 					/* clone()'ed child terminates */
 	int	br_exitwhy;		/* reason for thread (process) exit */
 	int	br_exitwhat;		/* exit code / killing signal */
-	lx_affmask_t br_affinitymask;	/* bitmask of CPU sched affinities */
+	cpuset_t *br_affinitymask;	/* bitmask of CPU sched affinities */
 	struct user_desc br_tls[LX_TLSNUM];
 			/* descriptors used by libc for TLS */
 	ulong_t	br_lx_fsbase;		/* lx fsbase for 64-bit thread ptr */
diff --git a/usr/src/uts/common/brand/lx/sys/lx_misc.h b/usr/src/uts/common/brand/lx/sys/lx_misc.h
index 3c6c45b0fc..af073c3f5f 100644
--- a/usr/src/uts/common/brand/lx/sys/lx_misc.h
+++ b/usr/src/uts/common/brand/lx/sys/lx_misc.h
@@ -37,6 +37,8 @@ extern void lx_initlwp(klwp_t *, void *);
 extern void lx_initlwp_post(klwp_t *);
 extern void lx_forklwp(klwp_t *, klwp_t *);
 
+extern void lx_affinity_forklwp(klwp_t *, klwp_t *);
+
 extern void lx_set_gdt(int, user_desc_t *);
 extern void lx_clear_gdt(int);
 
diff --git a/usr/src/uts/common/brand/lx/sys/lx_syscalls.h b/usr/src/uts/common/brand/lx/sys/lx_syscalls.h
index 0d4a74c900..34b2c6153c 100644
--- a/usr/src/uts/common/brand/lx/sys/lx_syscalls.h
+++ b/usr/src/uts/common/brand/lx/sys/lx_syscalls.h
@@ -175,9 +175,11 @@ extern long lx_recvmsg();
 extern long lx_recvfrom();
 extern long lx_rename();
 extern long lx_renameat();
+extern long lx_sched_getaffinity();
 extern long lx_sched_getparam();
 extern long lx_sched_getscheduler();
 extern long lx_sched_rr_get_interval();
+extern long lx_sched_setaffinity();
 extern long lx_sched_setparam();
 extern long lx_sched_setscheduler();
 extern long lx_sched_yield();
diff --git a/usr/src/uts/common/brand/lx/syscall/lx_sched.c b/usr/src/uts/common/brand/lx/syscall/lx_sched.c
index 0def559e29..14d2eda4ea 100644
--- a/usr/src/uts/common/brand/lx/syscall/lx_sched.c
+++ b/usr/src/uts/common/brand/lx/syscall/lx_sched.c
@@ -23,7 +23,7 @@
  * Use is subject to license terms.
  */
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2016 Joyent, Inc.
  */
 
 #include <sys/types.h>
@@ -37,10 +37,14 @@
 #include <sys/brand.h>
 #include <sys/lx_sched.h>
 #include <sys/lx_brand.h>
+#include <sys/sysmacros.h>
+#include <sys/policy.h>
 
 extern int yield();
 extern long priocntl_common(int, procset_t *, int, caddr_t, caddr_t, uio_seg_t);
 
+#define	BITS_PER_BYTE	8
+
 long
 lx_sched_yield(void)
 {
@@ -49,93 +53,277 @@ lx_sched_yield(void)
 	return (0);
 }
 
-int
-lx_sched_affinity(int cmd, uintptr_t pid, int len, uintptr_t maskp,
-    int64_t *rval)
+static void
+ltos_cpuset(lx_affmask_t *lmask, cpuset_t *smask)
+{
+	ASSERT(NCPU <= LX_NCPU);
+
+	cpuset_zero(smask);
+	for (int i = 0; i < NCPU; i++) {
+		if (BT_TEST(*lmask, i)) {
+			cpuset_add(smask, i);
+		}
+	}
+}
+
+static void
+stol_cpuset(cpuset_t *smask, lx_affmask_t *lmask)
+{
+	ASSERT(NCPU <= LX_NCPU);
+
+	bzero(lmask, sizeof (*lmask));
+	for (int i = 0; i < NCPU; i++) {
+		if (cpu_in_set(smask, i)) {
+			BT_SET(*lmask, i);
+		}
+	}
+}
+
+/*
+ * Find and lock a process for lx_sched_* operations.
+ * Sets 'pp' and 'tp' on success, with P_PR_LOCK set (but p_lock not held).
+ */
+static int
+lx_sched_pidlock(l_pid_t pid, proc_t **pp, kthread_t **tp, boolean_t is_write)
 {
 	pid_t		s_pid;
 	id_t		s_tid;
-	kthread_t	*t = curthread;
-	lx_lwp_data_t	*lx_lwp;
+	proc_t		*p;
+	kthread_t	*t = NULL;
+	int		err = 0;
+	lwpdir_t	*ld;
 
-	if (cmd != B_GET_AFFINITY_MASK && cmd != B_SET_AFFINITY_MASK)
-		return (set_errno(EINVAL));
+	if (pid < 0) {
+		return (EINVAL);
+	}
+	if (pid == 0) {
+		p = curproc;
+		mutex_enter(&p->p_lock);
+		sprlock_proc(p);
+		mutex_exit(&p->p_lock);
 
-	/*
-	 * The caller wants to know how large the mask should be.
-	 */
-	if (cmd == B_GET_AFFINITY_MASK && len == 0) {
-		*rval = sizeof (lx_affmask_t);
+		*tp = curthread;
+		*pp = p;
 		return (0);
 	}
 
+	if (lx_lpid_to_spair((pid_t)pid, &s_pid, &s_tid) < 0) {
+		return (ESRCH);
+	}
+	mutex_enter(&pidlock);
+	if ((p = prfind(s_pid)) == NULL) {
+		mutex_exit(&pidlock);
+		return (ESRCH);
+	}
+	mutex_enter(&p->p_lock);
+	mutex_exit(&pidlock);
+
+	err = sprtrylock_proc(p);
+	if (err < 0) {
+		mutex_exit(&p->p_lock);
+		return (ESRCH);
+	} else if (err > 0) {
+		sprwaitlock_proc(p);
+		err = 0;
+	}
+
+	ld = lwp_hash_lookup(p, s_tid);
+	if (ld != NULL) {
+		t = ld->ld_entry->le_thread;
+	} else {
+		sprunlock(p);
+		return (ESRCH);
+	}
+
+	mutex_exit(&p->p_lock);
+	if (is_write) {
+		cred_t *cr = CRED();
+
+		/*
+		 * To perform a sched_setaffinity on a thread outside of the
+		 * current process, either the euid/egid of the target must
+		 * match, or the calling process must hold CAP_SYS_NICE.
+		 * (PRIV_PROC_PRIOUP maps to CAP_SYS_NICE)
+		 */
+		err = 0;
+		if (secpolicy_raisepriority(cr) != 0) {
+			err = 0;
+			mutex_enter(&p->p_crlock);
+			if (crgetuid(cr) != crgetuid(p->p_cred) ||
+			    crgetgid(cr) != crgetgid(p->p_cred)) {
+				err = EPERM;
+			}
+			mutex_exit(&p->p_crlock);
+			if (err != 0) {
+				mutex_enter(&p->p_lock);
+				sprunlock(p);
+				return (err);
+			}
+		}
+	}
+	*pp = p;
+	*tp = t;
+	return (0);
+}
+
+long
+lx_sched_getaffinity(l_pid_t pid, unsigned int len, void *maskp)
+{
+	proc_t		*p;
+	kthread_t	*tp = NULL;
+	lx_lwp_data_t	*lwpd;
+	int		err;
+	unsigned int	pmin, pmax;
+	lx_affmask_t	lmask;
+	cpuset_t	*smask;
+
 	/*
-	 * Otherwise, ensure they have a large enough mask.
+	 * The ulong_t boundary requirement is to match Linux's behavior.
 	 */
-	if (cmd == B_GET_AFFINITY_MASK && len < sizeof (lx_affmask_t)) {
-		*rval = -1;
+	if ((len & (sizeof (ulong_t) - 1)) != 0) {
 		return (set_errno(EINVAL));
 	}
 
-	if (pid == 0) {
-		s_pid = curproc->p_pid;
-		s_tid = curthread->t_tid;
-	} else if (lx_lpid_to_spair((pid_t)pid, &s_pid, &s_tid) == -1) {
-		return (set_errno(ESRCH));
+	smask = cpuset_alloc(KM_SLEEP);
+	if ((err = lx_sched_pidlock(pid, &p, &tp, B_FALSE)) != 0) {
+		cpuset_free(smask);
+		return (set_errno(err));
 	}
 
+	mutex_enter(&cpu_lock);
+	mutex_enter(&p->p_lock);
 	/*
-	 * For now, we only support manipulating threads in the
-	 * same process.
+	 * Grab the existing affinity mask and constrain it by the current set
+	 * of active CPUs (which may have changed since it was assigned.
 	 */
-	if (curproc->p_pid != s_pid)
-		return (set_errno(EPERM));
+	lwpd = ttolxlwp(tp);
+	cpuset_or(smask, lwpd->br_affinitymask);
+	cpuset_and(smask, &cpu_active_set);
+	sprunlock(p);
+	mutex_exit(&cpu_lock);
+
+	cpuset_bounds(smask, &pmin, &pmax);
+	stol_cpuset(smask, &lmask);
+	cpuset_free(smask);
 
 	/*
-	 * We must hold the process lock so that the thread list
-	 * doesn't change while we're looking at it. We'll hold
-	 * the lock until we no longer reference the
-	 * corresponding lwp.
+	 * It is out of convenience that this check is performed so late.  If
+	 * the need arises, it could be altered to be done earlier in order to
+	 * match Linux error ordering.
 	 */
+	if (pmax >= (len * BITS_PER_BYTE)) {
+		return (set_errno(EINVAL));
+	}
 
-	mutex_enter(&curproc->p_lock);
+	len = MIN(len, sizeof (lx_affmask_t));
+	if (copyout(&lmask, maskp, len) != 0) {
+		return (set_errno(EFAULT));
+	}
+	return (len);
+}
 
-	do {
-		if (t->t_tid == s_tid)
-			break;
-		t = t->t_forw;
-	} while (t != curthread);
+long
+lx_sched_setaffinity(l_pid_t pid, unsigned int len, void *maskp)
+{
+	proc_t		*p;
+	kthread_t	*tp = NULL;
+	lx_lwp_data_t	*lwpd;
+	int		err;
+	unsigned int	pmin, pmax;
+	lx_affmask_t	lmask;
+	cpuset_t	*smask;
+
+	if (pid < 0) {
+		return (set_errno(EINVAL));
+	}
+
+	if (len < sizeof (lmask)) {
+		bzero(&lmask, sizeof (lmask));
+	} else if (len > sizeof (lmask)) {
+		len = sizeof (lmask);
+	}
+	if (copyin(maskp, &lmask, len) != 0) {
+		return (set_errno(EFAULT));
+	}
+	smask = cpuset_alloc(KM_SLEEP);
+	ltos_cpuset(&lmask, smask);
+	if ((err = lx_sched_pidlock(pid, &p, &tp, B_TRUE)) != 0) {
+		cpuset_free(smask);
+		return (set_errno(err));
+	}
 
 	/*
-	 * If the given PID is in the current thread's process,
-	 * then we _must_ find it in the process's thread list.
+	 * Constrain the mask to currently active CPUs.
 	 */
-	ASSERT(t->t_tid == s_tid);
-
-	lx_lwp = t->t_lwp->lwp_brand;
+	mutex_enter(&cpu_lock);
+	mutex_enter(&p->p_lock);
+	lwpd = ttolxlwp(tp);
+
+	cpuset_and(smask, &cpu_active_set);
+	if (cpuset_isnull(smask)) {
+		err = EINVAL;
+		goto out;
+	}
+	if (cpuset_isequal(lwpd->br_affinitymask, smask)) {
+		err = 0;
+		goto out;
+	}
 
-	if (cmd == B_SET_AFFINITY_MASK) {
-		if (copyin_nowatch((void *)maskp, &lx_lwp->br_affinitymask,
-		    sizeof (lx_affmask_t)) != 0) {
-			mutex_exit(&curproc->p_lock);
-			return (set_errno(EFAULT));
+	/*
+	 * If one (and only one) CPU is selected in the affinity mask, bind the
+	 * thread to that CPU.
+	 */
+	cpuset_bounds(smask, &pmin, &pmax);
+	VERIFY(pmin != CPUSET_NOTINSET);
+	if (pmin == pmax) {
+		processorid_t obind;
+
+		(void) cpu_bind_thread(tp, pmin, &obind, &err);
+		if (err != 0) {
+			goto out;
 		}
-
-		*rval = 0;
 	} else {
-		if (copyout_nowatch(&lx_lwp->br_affinitymask, (void *)maskp,
-		    sizeof (lx_affmask_t)) != 0) {
-			mutex_exit(&curproc->p_lock);
-			return (set_errno(EFAULT));
+		/*
+		 * If the thread transitions away from a single-CPU mask, it
+		 * should be unbound from that processor.
+		 */
+		cpuset_bounds(lwpd->br_affinitymask, &pmin, &pmax);
+		if (pmin == pmax) {
+			processorid_t obind;
+			(void) cpu_bind_thread(tp, PBIND_NONE, &obind, &err);
 		}
-
-		*rval = sizeof (lx_affmask_t);
 	}
-
-	mutex_exit(&curproc->p_lock);
+	cpuset_zero(lwpd->br_affinitymask);
+	cpuset_or(lwpd->br_affinitymask, smask);
+	err = 0;
+
+out:
+	mutex_exit(&cpu_lock);
+	sprunlock(p);
+	cpuset_free(smask);
+	if (err != 0) {
+		return (set_errno(err));
+	}
 	return (0);
 }
 
+void
+lx_affinity_forklwp(klwp_t *srclwp, klwp_t *dstlwp)
+{
+	proc_t *pp = lwptoproc(srclwp);
+	lx_lwp_data_t *slwpd = lwptolxlwp(srclwp);
+	lx_lwp_data_t *dlwpd = lwptolxlwp(dstlwp);
+
+	/*
+	 * Copy over the affinity mask.  This could be enhanced in the future
+	 * to perform single-CPU binding like sched_setaffinity.
+	 */
+	mutex_enter(&pp->p_lock);
+	cpuset_zero(dlwpd->br_affinitymask);
+	cpuset_or(dlwpd->br_affinitymask, slwpd->br_affinitymask);
+	mutex_exit(&pp->p_lock);
+}
+
 long
 lx_sched_setscheduler(l_pid_t pid, int policy, struct lx_sched_param *param)
 {
-- 
2.21.0

