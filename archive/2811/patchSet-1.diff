From ec2ec1db378810bd80cc6f84538435dba3bc9d4f Mon Sep 17 00:00:00 2001
From: Vishal Kulkarni <vishal@chelsio.com>
Date: Tue, 10 Oct 2017 17:38:30 +0000
Subject: [PATCH] OS-6408 Chelsio T6 perf improvements

---
 usr/src/uts/common/Makefile.files            |   2 +-
 usr/src/uts/common/io/cxgbe/cxgbe/cxgbe.c    |   2 +-
 usr/src/uts/common/io/cxgbe/t4nex/adapter.h  |  55 +++
 usr/src/uts/common/io/cxgbe/t4nex/t4_lro.c   | 479 +++++++++++++++++++
 usr/src/uts/common/io/cxgbe/t4nex/t4_nexus.c |  29 +-
 usr/src/uts/common/io/cxgbe/t4nex/t4_sge.c   |  93 +++-
 6 files changed, 632 insertions(+), 28 deletions(-)
 create mode 100644 usr/src/uts/common/io/cxgbe/t4nex/t4_lro.c

diff --git a/usr/src/uts/common/Makefile.files b/usr/src/uts/common/Makefile.files
index 8220f91f03..f3dfefb670 100644
--- a/usr/src/uts/common/Makefile.files
+++ b/usr/src/uts/common/Makefile.files
@@ -1998,7 +1998,7 @@ CH_COM_OBJS =	ch_mac.o ch_subr.o cspi.o espi.o ixf1010.o mc3.o mc4.o mc5.o \
 #
 CXGBE_FW_OBJS  =	t4_fw.o t4_cfg.o t5_cfg.o t5_fw.o t6_cfg.o t6_fw.o
 CXGBE_COM_OBJS =	t4_hw.o
-CXGBE_NEX_OBJS =	t4_nexus.o t4_sge.o t4_mac.o t4_ioctl.o shared.o \
+CXGBE_NEX_OBJS =	t4_nexus.o t4_sge.o t4_mac.o t4_ioctl.o shared.o t4_lro.o\
 			t4_l2t.o osdep.o
 
 #
diff --git a/usr/src/uts/common/io/cxgbe/cxgbe/cxgbe.c b/usr/src/uts/common/io/cxgbe/cxgbe/cxgbe.c
index 585635cd35..926bd56d1f 100644
--- a/usr/src/uts/common/io/cxgbe/cxgbe/cxgbe.c
+++ b/usr/src/uts/common/io/cxgbe/cxgbe/cxgbe.c
@@ -74,7 +74,7 @@ struct dev_ops cxgbe_dev_ops = {
 
 static struct modldrv modldrv = {
 	.drv_modops =		&mod_driverops,
-	.drv_linkinfo =		"Chelsio T4/T5 NIC " DRV_VERSION,
+	.drv_linkinfo =		"Chelsio T4/T5/T6 NIC " DRV_VERSION,
 	.drv_dev_ops =		&cxgbe_dev_ops
 };
 
diff --git a/usr/src/uts/common/io/cxgbe/t4nex/adapter.h b/usr/src/uts/common/io/cxgbe/t4nex/adapter.h
index cf6fd497fd..5092f016cb 100644
--- a/usr/src/uts/common/io/cxgbe/t4nex/adapter.h
+++ b/usr/src/uts/common/io/cxgbe/t4nex/adapter.h
@@ -134,6 +134,43 @@ struct port_info {
 	kstat_t *ksp_info;
 };
 
+struct mbl_list {
+	mblk_t *head;
+	mblk_t **tail;
+};
+
+struct lro_entry {
+	struct lro_entry *next;
+	mblk_t *m_head;
+	mblk_t *m_tail;
+	struct ip *ip;
+	in_addr_t source_ip;
+	in_addr_t dest_ip;
+	uint16_t source_port;
+	uint16_t dest_port;
+	uint16_t eh_type;
+	uint16_t append_cnt;
+	uint32_t len;
+	uint32_t data_csum;
+	uint32_t next_seq;
+	uint32_t ack_seq;
+	uint32_t tsval;
+	uint32_t tsecr;
+	uint16_t window;
+	uint16_t timestamp;
+	struct timeval mtime;
+};
+
+struct lro_ctrl {
+	int lro_queued;
+	int lro_flushed;
+	int lro_bad_csum;
+	int lro_cnt;
+
+	struct lro_entry *lro_active;
+	struct lro_entry *lro_free;
+};
+
 struct fl_sdesc {
 	struct rxbuf *rxb;
 };
@@ -163,6 +200,7 @@ enum {
 	IQ_ALLOCATED	= (1 << 0),	/* firmware resources allocated */
 	IQ_INTR		= (1 << 1),	/* iq takes direct interrupt */
 	IQ_HAS_FL	= (1 << 2),	/* iq has fl */
+	IQ_LRO_ENABLED  = (1 << 3),
 
 	/* iq state */
 	IQS_DISABLED	= 0,
@@ -348,11 +386,18 @@ struct sge_rxq {
 	mac_ring_handle_t ring_handle;
 	uint64_t ring_gen_num;
 
+
+	struct lro_ctrl lro;
+
 	/* stats for common events first */
 
 	uint64_t rxcsum;	/* # of times hardware assisted with checksum */
 	uint64_t rxpkts;	/* # of ethernet packets */
 	uint64_t rxbytes;	/* # of ethernet bytes */
+	uint64_t lroqueued;	/* # of LRO queued */
+	uint64_t lroflushed;	/* # of LRO flushes */
+	uint64_t lrobadcsum;	/* # of LRO bad checksums */
+ 
 
 	/* stats for not-that-common events */
 
@@ -878,4 +923,14 @@ int t4_addmac(void *arg, const uint8_t *ucaddr);
 int t4_ioctl(struct adapter *sc, int cmd, void *data, int mode);
 
 struct l2t_data *t4_init_l2t(struct adapter *sc);
+
+/* t4_lro.c */
+int t4_lro_init(struct lro_ctrl *);
+void t4_lro_free(struct lro_ctrl *);
+void t4_mbl_append(struct mbl_list *, mblk_t *);
+void t4_lro_flush(struct sge_rxq *, struct lro_ctrl *, struct lro_entry *,
+		  struct mbl_list *);
+int t4_lro_rx(struct sge_rxq *, struct lro_ctrl *, mblk_t *, uint32_t,
+		struct mbl_list *);
+
 #endif /* __CXGBE_ADAPTER_H */
diff --git a/usr/src/uts/common/io/cxgbe/t4nex/t4_lro.c b/usr/src/uts/common/io/cxgbe/t4nex/t4_lro.c
new file mode 100644
index 0000000000..e928da3399
--- /dev/null
+++ b/usr/src/uts/common/io/cxgbe/t4nex/t4_lro.c
@@ -0,0 +1,479 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source. A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * This file is part of the Chelsio T4 support code.
+ *
+ * Copyright (C) 2010-2017 Chelsio Communications.  All rights reserved.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the LICENSE file included in this
+ * release for licensing terms and conditions.
+ */
+
+
+#include <sys/ddi.h>
+#include <sys/sunddi.h>
+#include <sys/sunndi.h>
+#include <sys/pattr.h>
+#include <sys/stream.h>
+#include <sys/strsun.h>
+#include <inet/ip.h>
+#include <inet/tcp.h>
+
+#include "version.h"
+#include "common/common.h"
+
+#define LRO_ENTRIES	64 /* # of LRO entries per RX queue. */
+#define IP_OFFMASK	0x1fff
+#define TCPOPT_TIMESTAMP	8
+#define TCPOLEN_TIMESTAMP	10
+#define TCPOLEN_TSTAMP_APPA	12
+#define ETHERNET_HEADER_SIZE	14
+
+#if defined(__GNUC__)
+#define likely(x)       __builtin_expect((x), 1)
+#define unlikely(x)     __builtin_expect((x), 0)
+#else
+#define likely(x)       (x)
+#define unlikely(x)     (x)
+#endif /* defined(__GNUC__) */
+
+int
+t4_lro_init(struct lro_ctrl *lc)
+{
+	struct lro_entry *le = NULL;
+	int i;
+
+	memset(lc, 0, sizeof(struct lro_ctrl));
+
+	for (i = 0; i < LRO_ENTRIES; i++) {
+		le = kmem_zalloc(sizeof(*le), KM_SLEEP);
+		if (le == NULL) {
+			if (i == 0)
+				return (ENOMEM);
+			break;
+		}
+		lc->lro_cnt = i + 1;
+		le->next = lc->lro_free;
+		lc->lro_free = le;
+	}
+	return (0);
+}
+
+void
+t4_lro_free(struct lro_ctrl *lc)
+{
+	struct lro_entry *le;
+
+	while (lc->lro_free) {
+		le = lc->lro_free;
+		lc->lro_free = le->next;
+		kmem_free(le, sizeof(*le));
+	}
+}
+
+#define ADDCARRY(x)  (x > 65535 ? x -= 65535 : x)
+#define REDUCE32 do {\
+	q_util.q = sum;\
+	sum = q_util.s[0] + q_util.s[1] + q_util.s[2] + q_util.s[3];\
+} while (0)
+
+#define REDUCE16 do {\
+	q_util.q = sum;\
+	l_util.l = q_util.s[0] + q_util.s[1] + q_util.s[2] + q_util.s[3];\
+	sum = l_util.s[0] + l_util.s[1];\
+	ADDCARRY(sum);\
+} while (0)
+
+union l_util {
+	uint16_t s[2];
+	uint32_t l;
+};
+
+union q_util {
+	uint16_t s[4];
+	uint32_t l[2];
+	uint64_t q;
+};
+
+uint64_t
+t4_in_cksumdata(const void *buf, int len)
+{
+	const uint32_t *lw = (const uint32_t *) buf;
+	uint64_t sum = 0;
+	union q_util q_util;
+	sum = (uint64_t) lw[0] + lw[1] + lw[2] + lw[3] + lw[4];
+	REDUCE32;
+	return sum;
+}
+
+uint
+t4_in_cksum_hdr(const struct ip *ip)
+{
+	uint64_t sum = t4_in_cksumdata(ip, sizeof(struct ip));
+	union q_util q_util;
+	union l_util l_util;
+	REDUCE16;
+	return (~sum & 0xffff);
+}
+
+ushort
+t4_in_addword(ushort a, ushort b)
+{
+	uint64_t sum = a + b;
+
+	ADDCARRY(sum);
+	return (sum);
+}
+
+ushort
+t4_in_pseudo(uint32_t a, uint32_t b, uint32_t c)
+{
+	uint64_t sum;
+	union q_util q_util;
+	union l_util l_util;
+
+	sum = (uint64_t) a + b + c;
+	REDUCE16;
+	return (sum);
+}
+
+uint16_t
+t4_lro_csum_th(struct tcphdr *l4)
+{
+	uint32_t ch;
+	uint16_t *p, l;
+
+	ch = l4->th_sum = 0x0000;
+	l = l4->th_off;
+	p = (uint16_t *)l4;
+	while (l > 0) {
+		ch += *p;
+		p++;
+		ch += *p;
+		p++;
+		l--;
+	}
+	while (ch > 0xffff)
+		ch = (ch >> 16) + (ch & 0xffff);
+
+	return (ch & 0xffff);
+}
+
+uint16_t
+t4_lro_rx_csum_fixup(struct lro_entry *le, void *l3hdr, struct tcphdr *l4,
+		     uint16_t tcp_data_len, uint16_t csum)
+{
+	uint32_t c;
+	uint16_t cs;
+	struct ip *ip;
+
+	c = csum;
+
+	if (le->eh_type == htons(ETHERTYPE_IP)) {
+		/* Remove length from checksum. */
+		ip = (struct ip *)l3hdr;
+		if (le->append_cnt == 0)
+			cs = ip->ip_len;
+		else {
+			cs = t4_in_addword(ntohs(ip->ip_len) - sizeof(*ip),
+					IPPROTO_TCP);
+			cs = t4_in_pseudo(ip->ip_src.s_addr, ip->ip_dst.s_addr,
+					htons(cs));
+		}
+	} else
+		cs = 0;
+	cs = ~cs;
+	c += cs;
+
+	/* Remove TCP header csum. */
+	cs = ~t4_lro_csum_th(l4);
+	c += cs;
+	while (c > 0xffff)
+		c = (c >> 16) + (c & 0xffff);
+
+	return (c & 0xffff);
+}
+
+void
+t4_mbl_append(struct mbl_list *mbl, mblk_t *mp)
+{
+	*(mbl->tail) = mp;
+	mbl->tail = &mp->b_next;
+	mp->b_next = NULL;
+}
+
+void
+t4_lro_flush(struct sge_rxq *rxq, struct lro_ctrl *lc, struct lro_entry *le,
+	     struct mbl_list *mbl)
+{
+	struct port_info *pi = rxq->port;
+	struct tcphdr *l4;
+	struct ether_header *l2;
+	struct ip *ip;
+	uint32_t cl;
+	uint32_t *ts;
+	uint16_t c;
+	uint16_t p_len;
+
+	if (le->append_cnt > 0) {
+		p_len = htons(le->len);
+		l2 = (struct ether_header *)(void *)le->m_head->b_rptr;
+		if (le->eh_type == htons(ETHERTYPE_IP)) {
+			ip = (struct ip *)(void *)(l2 + 1);
+
+			c = ~ip->ip_sum;
+			cl = c;
+			c = ~ip->ip_len;
+			cl += c + p_len;
+			while (cl > 0xffff)
+				cl = (cl >> 16) + (cl & 0xffff);
+			c = cl;
+			ip->ip_sum = ~c;
+			ip->ip_len = p_len;
+			l4 = (struct tcphdr *)(ip + 1);
+			le->len += ETHERNET_HEADER_SIZE;
+		} else
+			l4 = NULL;
+
+		l4->th_ack = le->ack_seq;
+		l4->th_win = le->window;
+
+		if (le->timestamp != 0) {
+			ts = (uint32_t *)(l4 + 1);
+			ts[1] = htonl(le->tsval);
+			ts[2] = le->tsecr;
+		}
+
+		le->data_csum += p_len;
+		le->data_csum += t4_lro_csum_th(l4);
+		while (le->data_csum > 0xffff)
+			le->data_csum = (le->data_csum >> 16) +
+					(le->data_csum & 0xffff);
+		l4->th_sum = (le->data_csum & 0xffff);
+		l4->th_sum = ~l4->th_sum;
+	}
+
+	mac_hcksum_set(le->m_head, 0, 0, 0,
+			0, HCK_IPV4_HDRCKSUM_OK | HCK_FULLCKSUM_OK);
+
+	if (mbl != NULL)
+		t4_mbl_append(mbl, le->m_head);
+	else
+		t4_mac_rx(pi, rxq, le->m_head);
+
+	lc->lro_queued += le->append_cnt + 1;
+	lc->lro_flushed++;
+	bzero(le, sizeof(*le));
+	le->next = lc->lro_free;
+	lc->lro_free = le;
+}
+
+int
+t4_lro_rx(struct sge_rxq *rxq, struct lro_ctrl *lc, mblk_t *m, uint32_t csum,
+	  struct mbl_list *mbl)
+{
+	struct lro_entry *le, *curr;
+	struct port_info *pi = rxq->port;
+	struct ether_header *l2;
+	struct tcphdr *l4;
+	struct ip *ip;
+	void *l3hdr = NULL;
+	uint32_t *ts_ptr;
+	tcp_seq seq;
+	int error, ip_len, l;
+	uint16_t eh_type, tcp_data_len, tcp_hdr_len;
+	uint32_t tmp_csum;
+	uint32_t csum_flags = 0;
+	int opt_bytes, trim;
+	int tot_len = MBLKL(m);
+	int ret = 0;
+	mblk_t *m_tail;
+
+	l2 = (struct ether_header *)(void *)m->b_rptr;
+	if (l2->ether_type != htons(ETHERTYPE_IP))
+		return (EINVAL);
+
+	l3hdr = ip = (struct ip *)(void *)(l2 + 1);
+
+	if ((ip->ip_p != IPPROTO_TCP) ||
+	    ((ip->ip_hl << 2) != sizeof(*ip)) ||
+	    (ip->ip_off & htons(IP_MF|IP_OFFMASK))) {
+		ret = EINVAL;
+		goto err;
+	}
+
+	/* Dont calculate csum if HW has already done it */
+	mac_hcksum_get(m, NULL, NULL, NULL, NULL, &csum_flags);
+
+	if (!csum_flags & HCK_IPV4_HDRCKSUM_OK) {
+		tmp_csum = t4_in_cksum_hdr(ip);
+		if (unlikely(tmp_csum  != 0)) {
+			lc->lro_bad_csum++;
+			return (EINVAL);
+		}
+	}
+
+	ip_len = ntohs(ip->ip_len);
+	tcp_data_len = ip_len - sizeof(*ip);
+
+	/*get l4 header */
+	l4 = (struct tcphdr *)(ip + 1);
+
+	if ((l4->th_flags & ~(TH_ACK | TH_PUSH)) != 0)
+		return (EINVAL);
+
+	l = (l4->th_off << 2);
+	tcp_data_len -= l;
+	l -= sizeof(*l4);
+	ts_ptr = (uint32_t *)(l4 + 1);
+	if (l != 0 && (unlikely(l != TCPOLEN_TSTAMP_APPA) ||
+	   (*ts_ptr != ntohl(TCPOPT_NOP<<24|TCPOPT_NOP<<16|
+	   TCPOPT_TIMESTAMP<<8|TCPOLEN_TIMESTAMP))))
+		return (EINVAL);
+
+	trim = tot_len - (ip_len + ETHERNET_HEADER_SIZE);
+	if (trim != 0) {
+		if (trim < 0)
+			return (EINVAL);
+		adjmsg(m, -trim);
+	}
+
+	m_tail = m;
+	while (m_tail->b_next)
+		m_tail = m_tail->b_next;
+
+	if (csum == 0x0000)
+		csum = l4->th_sum;
+
+	seq = ntohl(l4->th_seq);
+
+	for (le = lc->lro_active; le != NULL; le = le->next) {
+		if (le->eh_type != l2->ether_type ||
+		    le->source_port != l4->th_sport ||
+		    le->dest_port != l4->th_dport)
+			continue;
+
+		if (le->source_ip != ip->ip_src.s_addr ||
+		    le->dest_ip != ip->ip_dst.s_addr)
+			continue;
+
+		if (le->len > (65535 - tcp_data_len)) {
+			if (lc->lro_active == le) {
+				lc->lro_active = le->next;
+			} else {
+				curr = lc->lro_active;
+				while (curr->next != le)
+					curr = curr->next;
+				curr->next = le->next;
+			}
+			t4_lro_flush(rxq, lc, le, mbl);
+			break;
+		}
+
+		if (unlikely(seq != le->next_seq ||
+		   (tcp_data_len == 0 && le->ack_seq == l4->th_ack))) {
+			if (lc->lro_active == le) {
+				lc->lro_active = le->next;
+			} else {
+				curr = lc->lro_active;
+				while (curr->next != le)
+					curr = curr->next;
+				curr->next = le->next;
+			}
+			t4_lro_flush(rxq, lc, le, mbl);
+			return (EINVAL);
+		}
+
+		if (l != 0) {
+			uint32_t tsval = ntohl(*(ts_ptr + 1));
+			if (unlikely(le->tsval > tsval ||
+			    *(ts_ptr + 2) == 0))
+				return (EINVAL);
+			le->tsval = tsval;
+			le->tsecr = *(ts_ptr + 2);
+		}
+
+		le->next_seq += tcp_data_len;
+		le->ack_seq = l4->th_ack;
+		le->window = l4->th_win;
+		le->append_cnt++;
+
+		le->data_csum += t4_lro_rx_csum_fixup(le, l3hdr, l4,
+				 tcp_data_len, ~csum);
+
+		if (tcp_data_len == 0) {
+			freeb(m);
+			return (0);
+		}
+
+		le->len += tcp_data_len;
+
+		adjmsg(m, (tot_len - tcp_data_len));
+		le->m_tail->b_cont = m;
+		le->m_tail = m_tail;
+
+		if (le->len > (65535 - pi->mtu) ||
+		   (le->append_cnt + 1) == LRO_ENTRIES) {
+			if (lc->lro_active == le) {
+				lc->lro_active = le->next;
+			} else {
+				curr = lc->lro_active;
+				while (curr->next != le)
+					curr = curr->next;
+				curr->next = le->next;
+			}
+			t4_lro_flush(rxq, lc, le, mbl);
+		}
+
+		return (0);
+	}
+
+	if (lc->lro_free == NULL)
+		return (ENOMEM);
+
+	le = lc->lro_free;
+	lc->lro_free = le->next;
+	le->next = lc->lro_active;
+	lc->lro_active = le;
+
+	le->ip = ip;
+	le->source_ip = ip->ip_src.s_addr;
+	le->dest_ip = ip->ip_dst.s_addr;
+	le->eh_type = l2->ether_type;
+	le->len = tot_len - ETHERNET_HEADER_SIZE;
+	le->source_port = l4->th_sport;
+	le->dest_port = l4->th_dport;
+	le->next_seq = seq + tcp_data_len;
+	le->ack_seq = l4->th_ack;
+	le->window = l4->th_win;
+
+	if (l != 0) {
+		le->timestamp = 1;
+		le->tsval = ntohl(*(ts_ptr + 1));
+		le->tsecr = *(ts_ptr + 2);
+	}
+
+	ASSERT(le->data_csum == 0);
+
+	le->data_csum = t4_lro_rx_csum_fixup(le, l3hdr, l4, tcp_data_len,
+					     ~csum);
+	l4->th_sum = csum;
+
+	le->m_head = m;
+	le->m_tail = m_tail;
+
+err:
+	return ret;
+}
+
diff --git a/usr/src/uts/common/io/cxgbe/t4nex/t4_nexus.c b/usr/src/uts/common/io/cxgbe/t4nex/t4_nexus.c
index 5607385283..ff2b193dc6 100644
--- a/usr/src/uts/common/io/cxgbe/t4nex/t4_nexus.c
+++ b/usr/src/uts/common/io/cxgbe/t4nex/t4_nexus.c
@@ -108,7 +108,7 @@ struct dev_ops t4_dev_ops = {
 
 static struct modldrv modldrv = {
 	.drv_modops =		&mod_driverops,
-	.drv_linkinfo =		"Chelsio T4 nexus " DRV_VERSION,
+	.drv_linkinfo =		"Chelsio T4/T5/T6 nexus " DRV_VERSION,
 	.drv_dev_ops =		&t4_dev_ops
 };
 
@@ -512,22 +512,27 @@ t4_devo_attach(dev_info_t *dip, ddi_attach_cmd_t cmd)
 
 		if (is_100G_port(pi)) {
 			n100g++;
+			cxgb_printf(dip, CE_NOTE, "Port-%d : 100G", i);
 			pi->tmr_idx = prp->tmr_idx_10g;
 			pi->pktc_idx = prp->pktc_idx_10g;
 		} else if (is_40G_port(pi)) {
 			n40g++;
 			pi->tmr_idx = prp->tmr_idx_10g;
+			cxgb_printf(dip, CE_NOTE, "Port-%d : 40G", i);
 			pi->pktc_idx = prp->pktc_idx_10g;
 		} else if (is_25G_port(pi)) {
 			n25g++;
 			pi->tmr_idx = prp->tmr_idx_10g;
+			cxgb_printf(dip, CE_NOTE, "Port-%d : 25G", i);
 			pi->pktc_idx = prp->pktc_idx_10g;
 		} else if (is_10G_port(pi)) {
 			n10g++;
+			cxgb_printf(dip, CE_NOTE, "Port-%d : 10G", i);
 			pi->tmr_idx = prp->tmr_idx_10g;
 			pi->pktc_idx = prp->pktc_idx_10g;
 		} else {
 			n1g++;
+			cxgb_printf(dip, CE_NOTE, "Port-%d : 1G", i);
 			pi->tmr_idx = prp->tmr_idx_1g;
 			pi->pktc_idx = prp->pktc_idx_1g;
 		}
@@ -752,37 +757,35 @@ ofld_queues:
 
 	if (n100g) {
 		cxgb_printf(dip, CE_NOTE,
-		    "%dx100G (%d rxq, %d txq total) %d %s.",
-		    n100g, rqidx, tqidx, sc->intr_count,
+		    "(%d rxq, %d txq total) %d %s.",
+		    rqidx, tqidx, sc->intr_count,
 		    sc->intr_type == DDI_INTR_TYPE_MSIX ? "MSI-X interrupts" :
 		    sc->intr_type == DDI_INTR_TYPE_MSI ? "MSI interrupts" :
 		    "fixed interrupt");
 	} else if (n40g) {
 		cxgb_printf(dip, CE_NOTE,
-		    "%dx40G (%d rxq, %d txq total) %d %s.",
-		    n40g, rqidx, tqidx, sc->intr_count,
+		    "(%d rxq, %d txq total) %d %s.",
+		    rqidx, tqidx, sc->intr_count,
 		    sc->intr_type == DDI_INTR_TYPE_MSIX ? "MSI-X interrupts" :
 		    sc->intr_type == DDI_INTR_TYPE_MSI ? "MSI interrupts" :
 		    "fixed interrupt");
 	} else if (n25g) {
 		cxgb_printf(dip, CE_NOTE,
-		    "%dx25G (%d rxq, %d txq total) %d %s.",
-		    n25g, rqidx, tqidx, sc->intr_count,
+		    "(%d rxq, %d txq total) %d %s.",
+		    rqidx, tqidx, sc->intr_count,
 		    sc->intr_type == DDI_INTR_TYPE_MSIX ? "MSI-X interrupts" :
 		    sc->intr_type == DDI_INTR_TYPE_MSI ? "MSI interrupts" :
 		    "fixed interrupt");
 	} else if (n10g && n1g) {
 		cxgb_printf(dip, CE_NOTE,
-		    "%dx10G %dx1G (%d rxq, %d txq total) %d %s.",
-		    n10g, n1g, rqidx, tqidx, sc->intr_count,
+		    "%dx1G (%d rxq, %d txq total) %d %s.",
+		    n1g, rqidx, tqidx, sc->intr_count,
 		    sc->intr_type == DDI_INTR_TYPE_MSIX ? "MSI-X interrupts" :
 		    sc->intr_type == DDI_INTR_TYPE_MSI ? "MSI interrupts" :
 		    "fixed interrupt");
 	} else {
 		cxgb_printf(dip, CE_NOTE,
-		    "%dx%sG (%d rxq, %d txq per port) %d %s.",
-		    n10g ? n10g : n1g,
-		    n10g ? "10" : "1",
+		    "(%d rxq, %d txq per port) %d %s.",
 		    n10g ? iaq.nrxq10g : iaq.nrxq1g,
 		    n10g ? iaq.ntxq10g : iaq.ntxq1g,
 		    sc->intr_count,
@@ -2322,7 +2325,7 @@ setup_kstats(struct adapter *sc)
 	KS_CINIT(pci_vendor_id);
 	KS_CINIT(pci_device_id);
 
-	KS_U_SET(chip_ver, sc->params.chip);
+	KS_U_SET(chip_ver, CHELSIO_CHIP_RELEASE(sc->params.chip));
 	KS_C_SET(fw_vers, "%d.%d.%d.%d",
 	    G_FW_HDR_FW_VER_MAJOR(sc->params.fw_vers),
 	    G_FW_HDR_FW_VER_MINOR(sc->params.fw_vers),
diff --git a/usr/src/uts/common/io/cxgbe/t4nex/t4_sge.c b/usr/src/uts/common/io/cxgbe/t4nex/t4_sge.c
index 6f68670bc9..a7d699a8db 100644
--- a/usr/src/uts/common/io/cxgbe/t4nex/t4_sge.c
+++ b/usr/src/uts/common/io/cxgbe/t4nex/t4_sge.c
@@ -494,6 +494,7 @@ t4_setup_port_queues(struct port_info *pi)
 #endif
 		   ) {
 			rxq->iq.flags |= IQ_INTR;
+			rxq->iq.flags |= IQ_LRO_ENABLED;
 			rc = alloc_rxq(pi, rxq, intr_idx, i);
 			if (rc != 0)
 				goto done;
@@ -746,13 +747,15 @@ t4_ring_rx(struct sge_rxq *rxq, int budget)
 	int ndescs = 0, fl_bufs_used = 0;
 	int rsp_type;
 	uint32_t lq;
-	mblk_t *mblk_head = NULL, **mblk_tail, *m;
+	struct mbl_list mbl = {0};
+	mblk_t *m;
 	struct cpl_rx_pkt *cpl;
 	uint32_t received_bytes = 0, pkt_len = 0;
 	bool csum_ok;
 	uint16_t err_vec;
 
-	mblk_tail = &mblk_head;
+	mbl.head = NULL;
+	mbl.tail = &mbl.head;
 
 	while (is_new_response(iq, &ctrl)) {
 
@@ -802,9 +805,13 @@ t4_ring_rx(struct sge_rxq *rxq, int budget)
 				rxq->rxbytes += pkt_len;
 				received_bytes += pkt_len;
 
-				*mblk_tail = m;
-				mblk_tail = &m->b_next;
-
+				if (cpl->l2info & cpu_to_be32(F_RXF_LRO) &&
+				    iq->flags & IQ_LRO_ENABLED && t4_lro_rx(rxq,
+				    &rxq->lro, m, 0, &mbl) == 0) {
+					/* LRO'd */
+				} else
+					t4_mbl_append(&mbl, m);
+ 
 				break;
 			}
 
@@ -829,7 +836,18 @@ t4_ring_rx(struct sge_rxq *rxq, int budget)
 	}
 
 done:
+	if (iq->flags & IQ_LRO_ENABLED) {
+		struct lro_ctrl *lc = &rxq->lro;
+		struct lro_entry *le;
+
+		while (lc->lro_active) {
+			le = lc->lro_active;
+			lc->lro_active = le->next;
+			t4_lro_flush(rxq, lc, le, &mbl);
+		}
+	}
 
+ 
 	t4_write_reg(sc, MYPF_REG(A_SGE_PF_GTS),
 		     V_CIDXINC(ndescs) | V_INGRESSQID(iq->cntxt_id) |
 		     V_SEINTARM(V_QINTR_TIMER_IDX(X_TIMERREG_UPDATE_CIDX)));
@@ -843,7 +861,7 @@ done:
 		if (starved)
 			add_fl_to_sfl(sc, fl);
 	}
-	return (mblk_head);
+	return (mbl.head);
 }
 
 /*
@@ -964,6 +982,17 @@ service_iq(struct sge_iq *iq, int budget)
 			STAILQ_INSERT_TAIL(&iql, q, link);
 	}
 
+	if (iq->flags & IQ_LRO_ENABLED) {
+		struct lro_ctrl *lc = &rxq->lro;
+		struct lro_entry *le;
+
+		while (lc->lro_active) {
+			le = lc->lro_active;
+			lc->lro_active = le->next;
+			t4_lro_flush(rxq, lc, le, NULL);
+		}
+	}
+
 	t4_write_reg(sc, MYPF_REG(A_SGE_PF_GTS), V_CIDXINC(ndescs) |
 	    V_INGRESSQID((u32)iq->cntxt_id) | V_SEINTARM(iq->intr_next));
 
@@ -1579,6 +1608,10 @@ alloc_rxq(struct port_info *pi, struct sge_rxq *rxq, int intr_idx, int i)
 	if (rc != 0)
 		return (rc);
 
+	rc = t4_lro_init(&rxq->lro);
+	if (rc != 0)
+		return (rc);
+
 	rxq->ksp = setup_rxq_kstats(pi, rxq, i);
 
 	return (rc);
@@ -3273,14 +3306,20 @@ t4_eth_rx(struct sge_iq *iq, const struct rss_header *rss, mblk_t *m)
 		rxq->rxcsum++;
 	}
 
-	/* Add to the chain that we'll send up */
-	if (chain.head != NULL)
-		chain.tail->b_next = m;
-	else
-		chain.head = m;
-	chain.tail = m;
+	if (cpl->l2info & cpu_to_be32(F_RXF_LRO) &&
+	    iq->flags & IQ_LRO_ENABLED &&
+	    t4_lro_rx(rxq, &rxq->lro, m, 0, NULL) == 0) {
+		/* LRO'd */
+	} else {
+		/* Add to the chain that we'll send up */
+		if (chain.head)
+			chain.tail->b_next = m;
+		else
+			chain.head = m;
+		chain.tail = m;
 
-	t4_mac_rx(rxq->port, rxq, chain.head);
+		t4_mac_rx(rxq->port, rxq, chain.head);
+	}
 
 	rxq->rxpkts++;
 	rxq->rxbytes  += be16_to_cpu(cpl->len);
@@ -3600,6 +3639,11 @@ struct rxq_kstats {
 	kstat_named_t rxpkts;
 	kstat_named_t rxbytes;
 	kstat_named_t nomem;
+
+	/* LRO Stats */
+	kstat_named_t lroqueued;
+	kstat_named_t lroflushed;
+	kstat_named_t lrobadcsum;
 };
 
 static kstat_t *
@@ -3629,6 +3673,11 @@ setup_rxq_kstats(struct port_info *pi, struct sge_rxq *rxq, int idx)
 	KS_UINIT(rxbytes);
 	KS_UINIT(nomem);
 
+	/* LRO Stats */
+	KS_UINIT(lroqueued);
+	KS_UINIT(lroflushed);
+	KS_UINIT(lrobadcsum);
+
 	ksp->ks_update = update_rxq_kstats;
 	ksp->ks_private = (void *)rxq;
 	kstat_install(ksp);
@@ -3650,6 +3699,24 @@ update_rxq_kstats(kstat_t *ksp, int rw)
 	KS_U_FROM(rxbytes, rxq);
 	KS_U_FROM(nomem, rxq);
 
+	/* LRO Stats */
+	rxq->lroqueued = rxq->lro.lro_queued;
+	rxq->lroflushed = rxq->lro.lro_flushed;
+	rxq->lrobadcsum = rxq->lro.lro_bad_csum;
+
+	KS_U_FROM(lroqueued, rxq);
+	KS_U_FROM(lroflushed, rxq);
+	KS_U_FROM(lrobadcsum, rxq);
+
+	/* LRO Stats */
+	rxq->lro.lro_queued = 0;
+	rxq->lro.lro_flushed = 0;
+	rxq->lro.lro_bad_csum = 0;
+
+	rxq->lroqueued = 0;
+	rxq->lroflushed = 0;
+	rxq->lrobadcsum = 0;
+
 	return (0);
 }
 
-- 
2.21.0

