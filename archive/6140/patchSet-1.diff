commit 4446ecf1f2634315b0bac605ace5dda9878495e7
Author: Robert Bogart <robert.bogart@joyent.com>
Date:   2019-04-19T23:15:14+00:00 (6 months ago)
    
    MANTA-4136 garbage-collector redundantly buffers manta_fastdelete_queue records

diff --git a/lib/delete_record_transformer.js b/lib/delete_record_transformer.js
index 3d08549..5379a60 100644
--- a/lib/delete_record_transformer.js
+++ b/lib/delete_record_transformer.js
@@ -183,13 +183,15 @@ _process_record(record, done)
 	}
 
 	/*
-	 * In the MorayDeleteRecordCleaner, Moray#batch may fail a potentially
-	 * large group of delete operations if one of those operations is to
-	 * delete a key that doesn't exist in the delete queue. For this reason,
-	 * we must make sure that no component of the garbage-collector attempts
-	 * requests deletion of the same key twice. This shared status object
-	 * determines whether the MakoInstructionUploader has already requested
-	 * that a record for some key be removed.
+	 * The DeleteRecordTransformer emits a separate instruction for each
+	 * storage node the object referred to by the record's key is stored on.
+	 * Since the metadata record occupies a single row in the metadata tier,
+	 * we use this bit of state to ensure that the key is included in only
+	 * one batch delete.
+	 *
+	 * A Moray batch delete could fail a potentially large number of
+	 * requests if any given delete transaction fails, so not doing this
+	 * opens the collector up to potentially wasting a lot of work.
 	 */
 	var cleaned_state = {
 		cleaned: false
@@ -256,6 +258,7 @@ _flush(storage_ids, done)
 
 	self.mt_mako_flush_in_progress = true;
 
+
 	var flush_done = function (err) {
 		if (!err) {
 			self.mt_last_flush = Date.now();
@@ -281,6 +284,11 @@ _flush(storage_ids, done)
 				return;
 			}
 
+			self.mt_log.info({
+				storage_id: storage_id,
+				lines: lines.length
+			}, 'Begin flushing records for mako consumption.');
+
 			/*
 			 * It is unfortunate and inefficient that we have to
 			 * micromanage GC like this, but it has been observed
diff --git a/lib/moray_delete_record_reader.js b/lib/moray_delete_record_reader.js
index 445725b..5eacfe6 100644
--- a/lib/moray_delete_record_reader.js
+++ b/lib/moray_delete_record_reader.js
@@ -287,7 +287,7 @@ state_running(S)
 	}
 
 	var req = self._find_objects();
-	var record_keys = [];
+	var num_seen = 0;
 
 	var paused_in_flight = false;
 	var shutdown_in_flight = false;
@@ -321,7 +321,9 @@ state_running(S)
 
 		if (self._is_allowed_creator(creator)) {
 			self.mr_listener.emit('record', record);
-			record_keys.push(record.key);
+			self.mr_log.info({ record: record.key },
+			    'Received key.');
+			num_seen++;
 		}
 	});
 
@@ -339,7 +341,7 @@ state_running(S)
 	});
 
 	req.on('end', function () {
-		if (record_keys.length === 0) {
+		if (num_seen === 0) {
 			/*
 			 * Back off exponentially each time we consecutively
 			 * receive 0 delete records. The queue is not
@@ -360,16 +362,21 @@ state_running(S)
 			self.mr_log.info({
 				bucket: self.mr_bucket,
 				shard: self.mr_shard,
-				num: record_keys.length,
-				keys: record_keys
+				num: num_seen
 			}, 'Received records.');
 
+			/*
+			 * Collector received records.  Reset any exponentiated
+			 * backoff that may have accumulated from one or more
+			 * consecutive times that the collector saw 0 records
+			 * from the Moray client's call to `findObjects()'.
+			 */
 			self._reset_empty_backoff();
 
 			if (self.mr_ctx.ctx_metrics_manager) {
 				self._get_collector().getCollector(
 					'gc_delete_records_read').observe(
-					record_keys.length, {
+					num_seen, {
 					bucket: self.mr_bucket,
 					shard: self.mr_shard
 				});
@@ -382,7 +389,7 @@ state_running(S)
 		 */
 		self.mr_err_timeout = 1000;
 
-		self.mr_prev_records_received = record_keys.length;
+		self.mr_prev_records_received = num_seen;
 
 		if (check_cancelled()) {
 			return;
