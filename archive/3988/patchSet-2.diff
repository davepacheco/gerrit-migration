From f5fdde8a189ed57140e78155f1d7b638fbb0a088 Mon Sep 17 00:00:00 2001
From: "Joshua M. Clulow" <jmc@joyent.com>
Date: Thu, 24 May 2018 20:41:25 +0000
Subject: [PATCH] MANTA-3721 reshard support for Moray extended identifiers
 Reviewed by: Kelly McLaughlin <kelly.mclaughlin@joyent.com> Approved by: Alex
 Wilson <alex.wilson@joyent.com>

---
 lib/phase_delete_data.js | 167 ++++++++++++++++++++++++++++++++++++---
 1 file changed, 158 insertions(+), 9 deletions(-)

diff --git a/lib/phase_delete_data.js b/lib/phase_delete_data.js
index c02672e..71a8764 100644
--- a/lib/phase_delete_data.js
+++ b/lib/phase_delete_data.js
@@ -425,7 +425,6 @@ delete_ghost_data(ctl, vnode_data, delete_from_shard, ghost_shard, status,
 		 * We want to delete the data in small batches, as there may be
 		 * millions of rows for any particular vnode and we do not
 		 * want to inhibit production traffic.
-		 * XXX This should be tuneable.
 		 */
 		var again = function () {
 			if (ctl.pausing(done)) {
@@ -567,6 +566,124 @@ delete_ghost_data(ctl, vnode_data, delete_from_shard, ghost_shard, status,
 	});
 }
 
+/*
+ * Each object in a Moray bucket has an integer "_id" property which we can use
+ * when assembling a limited set of rows to remove from the table.  In some
+ * deployments, the original "_id" column was limited to 32-bit values.  A
+ * second 64-bit column ("_idx") was added; the "_id" property value may appear
+ * in either one of these columns for any particular row.
+ *
+ * Determine whether this particular table has the "_idx" extended identifier
+ * column.
+ */
+function
+check_extended_id(ctl, pg_set, table, callback)
+{
+	mod_assert.object(ctl, 'ctl');
+	mod_assert.arrayOfObject(pg_set, 'pg_set');
+	mod_assert.string(table, 'table');
+	mod_assert.func(callback, 'callback');
+
+	var column_exists = false;
+	var index_ready = false;
+	var pg = pg_set[0];
+
+	mod_vasync.waterfall([ function (next) {
+		/*
+		 * Check to see if the table for this bucket has the "_idx"
+		 * column.  If this column is present, the "_id" property of
+		 * objects in this bucket is virtual: the actual ID value might
+		 * be in either the "_id" column or the "_idx" column.
+		 */
+		var q = [
+			'SELECT',
+			'    TRUE as exists',
+			'FROM',
+			'    pg_catalog.pg_attribute pga',
+			'WHERE',
+			'    pga.attrelid = \'' + table + '\'::regclass AND',
+			'    pga.attname = \'_idx\' AND',
+			'    NOT pga.attisdropped'
+		].join(' ');
+		pg.query({ text: q }, function (err, res) {
+			if (err) {
+				next(new VE(err, 'checking for "_idx" column'));
+				return;
+			}
+
+			mod_assert.number(res.rowCount, 'rowCount');
+			if (res.rowCount !== 1) {
+				next();
+				return;
+			}
+
+			mod_assert.strictEqual(res.rows[0].exists, true,
+			    'exists');
+			column_exists = true;
+			next();
+		});
+
+	}, function (next) {
+		if (!column_exists) {
+			setImmediate(next);
+			return;
+		}
+
+		/*
+		 * Check to see if the index for the "_idx" column exists and
+		 * is able to be used by queries.
+		 */
+		var q = [
+			'SELECT',
+			'    pgc.relname AS table_name,',
+			'    pgc.oid AS table_oid,',
+			'    pgci.relname AS index_name,',
+			'    pgi.indexrelid AS index_oid,',
+			'    pgi.indisvalid AS index_valid',
+			'FROM',
+			'    pg_catalog.pg_class pgc INNER JOIN',
+			'    pg_catalog.pg_index pgi ON',
+			'        pgc.oid = pgi.indrelid INNER JOIN',
+			'    pg_catalog.pg_class pgci ON',
+			'        pgi.indexrelid = pgci.oid',
+			'WHERE',
+			'    pgc.relname = \'' + table + '\' AND',
+			'    pgci.relname = \'' + table + '__idx_idx\''
+		].join(' ');
+		pg.query({ text: q }, function (err, res) {
+			if (err) {
+				next(new VE(err, 'checking for "_idx" index'));
+				return;
+			}
+
+			mod_assert.number(res.rowCount, 'rowCount');
+			if (res.rowCount !== 1) {
+				next();
+				return;
+			}
+
+			mod_assert.strictEqual(res.rows[0].index_name,
+			    table + '__idx_idx', 'expected index');
+			mod_assert.bool(res.rows[0].index_valid, 'index_valid');
+			index_ready = res.rows[0].index_valid;
+			next();
+		});
+
+	} ], function (err) {
+		if (err) {
+			callback(new VE(err, 'checking for extended ' +
+			    'identifier column (table "%s")', table));
+			return;
+		}
+
+		/*
+		 * If the "_idx" column exists and is correctly indexed, we
+		 * will use it in queries.
+		 */
+		callback(null, !!(column_exists && index_ready));
+	});
+}
+
 function
 delete_one_table(ctl, pg_set, table, vnodes, status, callback)
 {
@@ -582,6 +699,7 @@ delete_one_table(ctl, pg_set, table, vnodes, status, callback)
 
 	var total_rows = 0;
 	var datapoints = [];
+	var extended_id;
 
 	/*
 	 * Keep a running total of rows deleted for this table, and attempt
@@ -717,17 +835,39 @@ delete_one_table(ctl, pg_set, table, vnodes, status, callback)
 
 		status.prop('delete batch size', '' + delete_batch_size);
 		status.prop('delete pause (ms)', '' + delete_pause_ms);
+		status.prop('moray extended id?', extended_id ? 'yes' : 'no');
 
+		/*
+		 * Delete a limited quantity of rows in this batch.  As
+		 * PostgreSQL does not support a LIMIT clause on a DELETE
+		 * statement, we first assemble the list of rows in a subquery.
+		 * We use the Common Table Expression (CTE) feature so that we
+		 * can refer to up to two columns from the subquery separately.
+		 */
+		mod_assert.bool(extended_id, 'extended_id');
 		var q = [
-			'DELETE FROM', table, 'WHERE _id IN (SELECT _id FROM',
-			table, 'WHERE _vnode = $1 LIMIT $2) AND _vnode = $1'
-		].join(' ');
+			'WITH row_set AS (SELECT',
+			extended_id ? '_id, _idx' : '_id',
+			'FROM', table, 'WHERE _vnode = $1 LIMIT $2)',
+			'DELETE FROM', table, 'WHERE',
+			'(_id IN (SELECT _id FROM row_set WHERE _id',
+			'IS NOT NULL)',
+		];
+		if (extended_id) {
+			q.push('OR _idx IN (SELECT _idx FROM row_set WHERE',
+			    '_idx IS NOT NULL)');
+		}
+		q.push(') AND _vnode = $1');
+
+		q = q.join(' ');
+
 		var p = [ vq.vq_vnode, delete_batch_size ];
 
 		dot.dot_status.update('vnode %10d: deleted %d rows (#%d)',
 		    vq.vq_vnode, vq.vq_count, vq.vq_ordinal);
 
-		ctl.log.info('checking table %s vnode %d', table,
+		ctl.log.info({ extended_id: extended_id },
+		    'checking table %s vnode %d', table,
 		    vq.vq_vnode);
 		var start = process.hrtime();
 		dot.dot_pg.query({ text: q, values: p }, function (err, res) {
@@ -776,14 +916,23 @@ delete_one_table(ctl, pg_set, table, vnodes, status, callback)
 
 	};
 
-	mod_vasync.forEachParallel({ inputs: dots, func: worker },
-	    function (err) {
+	check_extended_id(ctl, pg_set, table, function (err, _extended_id) {
 		if (err) {
 			callback(err);
 			return;
 		}
 
-		callback();
+		extended_id = _extended_id;
+
+		mod_vasync.forEachParallel({ inputs: dots, func: worker },
+		    function (err) {
+			if (err) {
+				callback(err);
+				return;
+			}
+
+			callback();
+		});
 	});
 }
 
@@ -819,7 +968,7 @@ check_one_vnode(ctl, pg, tables, vnode, status, callback)
 		var tr = track[table];
 
 		var q = [
-			'SELECT COUNT(x._id) AS found_rows FROM (SELECT _id',
+			'SELECT COUNT(x._key) AS found_rows FROM (SELECT _key',
 			'FROM', table, 'WHERE _vnode = $1 LIMIT 1) x',
 		].join(' ');
 		var p = [ vnode ];
-- 
2.21.0

