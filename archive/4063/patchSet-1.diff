commit e590ce9666c23ed5b64ebb9ef4c98ff16e06b2e5 (refs/changes/63/4063/1)
Author: Robert Mustacchi <rm@joyent.com>
Date:   2018-05-31T20:48:44+00:00 (1 year, 4 months ago)
    
    OS-6992 Want hypervisor API for FPU management

diff --git a/usr/src/uts/i86pc/Makefile.files b/usr/src/uts/i86pc/Makefile.files
index 7fc3cfec14..2473039fac 100644
--- a/usr/src/uts/i86pc/Makefile.files
+++ b/usr/src/uts/i86pc/Makefile.files
@@ -64,6 +64,7 @@ CORE_OBJS +=			\
 	hardclk.o		\
 	hat_i86.o		\
 	hat_kdi.o		\
+	hma_fpu.o		\
 	hment.o			\
 	hold_page.o		\
 	hrtimers.o		\
diff --git a/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c b/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
index 59e811ed20..399da1f139 100644
--- a/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
+++ b/usr/src/uts/i86pc/io/vmm/vmm_sol_glue.c
@@ -51,6 +51,7 @@
 #include <sys/id_space.h>
 #include <sys/psm_defs.h>
 #include <sys/smp_impldefs.h>
+#include <sys/hma.h>
 
 #include <sys/x86_archext.h>
 
@@ -464,171 +465,78 @@ vmm_cpuid_init(void)
 	cpu_exthigh = regs[0];
 }
 
-struct savefpu {
-	fpu_ctx_t	fsa_fp_ctx;
-};
-
-static vmem_t *fpu_save_area_arena;
-
-static void
-fpu_save_area_init(void)
-{
-	fpu_save_area_arena = vmem_create("fpu_save_area",
-	    NULL, 0, XSAVE_AREA_ALIGN,
-	    segkmem_alloc, segkmem_free, heap_arena, 0, VM_BESTFIT | VM_SLEEP);
-}
-
-static void
-fpu_save_area_cleanup(void)
-{
-	vmem_destroy(fpu_save_area_arena);
-}
-
+/*
+ * FreeBSD uses the struct savefpu for managing the FPU state. That is mimicked
+ * by our hypervisor multiplexor framework structure.
+ */
 struct savefpu *
 fpu_save_area_alloc(void)
 {
-	struct savefpu *fsa = vmem_alloc(fpu_save_area_arena,
-	    sizeof (struct savefpu), VM_SLEEP);
-
-	bzero(fsa, sizeof (struct savefpu));
-	fsa->fsa_fp_ctx.fpu_regs.kfpu_u.kfpu_generic =
-	    kmem_cache_alloc(fpsave_cachep, KM_SLEEP);
-
-	return (fsa);
+	return ((struct savefpu *)hma_fpu_alloc(KM_SLEEP));
 }
 
 void
 fpu_save_area_free(struct savefpu *fsa)
 {
-	kmem_cache_free(fpsave_cachep,
-	    fsa->fsa_fp_ctx.fpu_regs.kfpu_u.kfpu_generic);
-	vmem_free(fpu_save_area_arena, fsa, sizeof (struct savefpu));
+	hma_fpu_t *fpu = (hma_fpu_t *)fsa;
+	hma_fpu_free(fpu);
 }
 
 void
 fpu_save_area_reset(struct savefpu *fsa)
 {
-	extern const struct fxsave_state sse_initial;
-	extern const struct xsave_state avx_initial;
-	struct fpu_ctx *fp;
-	struct fxsave_state *fx;
-	struct xsave_state *xs;
-
-	fp = &fsa->fsa_fp_ctx;
-
-	fp->fpu_regs.kfpu_status = 0;
-	fp->fpu_regs.kfpu_xstatus = 0;
-
-	switch (fp_save_mech) {
-	case FP_FXSAVE:
-		fx = fp->fpu_regs.kfpu_u.kfpu_fx;
-		bcopy(&sse_initial, fx, sizeof (*fx));
-		break;
-	case FP_XSAVE:
-		fp->fpu_xsave_mask = (XFEATURE_ENABLED_X87 |
-		    XFEATURE_ENABLED_SSE | XFEATURE_ENABLED_AVX);
-		xs = fp->fpu_regs.kfpu_u.kfpu_xs;
-		bcopy(&avx_initial, xs, sizeof (*xs));
-		break;
-	default:
-		panic("Invalid fp_save_mech");
-		/*NOTREACHED*/
-	}
+	hma_fpu_t *fpu = (hma_fpu_t *)fsa;
+	hma_fpu_reset(fpu, (XFEATURE_ENABLED_X87 | XFEATURE_ENABLED_SSE |
+	    XFEATURE_ENABLED_AVX));
 }
 
+/*
+ * This glue function is supposed to save the host's FPU state. This is always
+ * paired in the general bhyve code with a call to fpusave. Therefore, we treat
+ * this as a nop and do all the work in fpusave(), which will have the context
+ * argument that we want anyways.
+ */
 void
 fpuexit(kthread_t *td)
 {
-	fp_save(&curthread->t_lwp->lwp_pcb.pcb_fpu);
-}
-
-static __inline void
-vmm_fxrstor(struct fxsave_state *addr)
-{
-	__asm __volatile("fxrstor %0" : : "m" (*(addr)));
-}
-
-static __inline void
-vmm_fxsave(struct fxsave_state *addr)
-{
-	__asm __volatile("fxsave %0" : "=m" (*(addr)));
-}
-
-static __inline void
-vmm_xrstor(struct xsave_state *addr, uint64_t mask)
-{
-	uint32_t low, hi;
-
-	low = mask;
-	hi = mask >> 32;
-	__asm __volatile("xrstor %0" : : "m" (*addr), "a" (low), "d" (hi));
-}
-
-static __inline void
-vmm_xsave(struct xsave_state *addr, uint64_t mask)
-{
-	uint32_t low, hi;
-
-	low = mask;
-	hi = mask >> 32;
-	__asm __volatile("xsave %0" : "=m" (*addr) : "a" (low), "d" (hi) :
-	    "memory");
 }
 
+/*
+ * This glue function is supposed to restore the guest's FPU state from the save
+ * area back to the host. In FreeBSD, it is assumed that the host state has
+ * already been saved by a call to fpuexit(); however, we do both here.
+ */
 void
 fpurestore(void *arg)
 {
-	struct savefpu *fsa = (struct savefpu *)arg;
-	struct fpu_ctx *fp;
-
-	fp = &fsa->fsa_fp_ctx;
-
-	switch (fp_save_mech) {
-	case FP_FXSAVE:
-		vmm_fxrstor(fp->fpu_regs.kfpu_u.kfpu_fx);
-		break;
-	case FP_XSAVE:
-		vmm_xrstor(fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
-		break;
-	default:
-		panic("Invalid fp_save_mech");
-		/*NOTREACHED*/
-	}
+	hma_fpu_t *fpu = arg;
+
+	hma_fpu_start_guest(fpu);
 }
 
+/*
+ * This glue function is supposed to save the guest's FPU state. The host's FPU
+ * state is not expected to be restored necessarily due to the use of FPU
+ * emulation through CR0.TS. However, we can and do restore it here.
+ */
 void
 fpusave(void *arg)
 {
-	struct savefpu *fsa = (struct savefpu *)arg;
-	struct fpu_ctx *fp;
-
-	fp = &fsa->fsa_fp_ctx;
-
-	switch (fp_save_mech) {
-	case FP_FXSAVE:
-		vmm_fxsave(fp->fpu_regs.kfpu_u.kfpu_fx);
-		break;
-	case FP_XSAVE:
-		vmm_xsave(fp->fpu_regs.kfpu_u.kfpu_xs, fp->fpu_xsave_mask);
-		break;
-	default:
-		panic("Invalid fp_save_mech");
-		/*NOTREACHED*/
-	}
+	hma_fpu_t *fpu = arg;
+
+	hma_fpu_stop_guest(fpu);
 }
 
 void
 vmm_sol_glue_init(void)
 {
 	vmm_cpuid_init();
-	fpu_save_area_init();
 	unr_idx = 0;
 }
 
 void
 vmm_sol_glue_cleanup(void)
 {
-	fpu_save_area_cleanup();
 }
 
 
diff --git a/usr/src/uts/i86pc/os/hma_fpu.c b/usr/src/uts/i86pc/os/hma_fpu.c
new file mode 100644
index 0000000000..6c436b654f
--- /dev/null
+++ b/usr/src/uts/i86pc/os/hma_fpu.c
@@ -0,0 +1,229 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc. 
+ */
+
+/*
+ * This implements the hypervisor multiplexor FPU API. Its purpose is to make it
+ * easy to switch between the host and guest hypervisor while hiding all the
+ * details about CR0.TS and how to save the host's state as required.
+ */
+
+#include <sys/pcb.h>
+#include <sys/kmem.h>
+#include <sys/debug.h>
+#include <sys/cmn_err.h>
+#include <sys/ddi.h>
+#include <sys/sunddi.h>
+#include <sys/hma.h>
+#include <sys/x86_archext.h>
+#include <sys/archsystm.h>
+
+extern const struct fxsave_state sse_initial;
+extern const struct xsave_state avx_initial;
+
+struct hma_fpu {
+	fpu_ctx_t	hf_kfpu;
+	kthread_t	*hf_curthread;
+	boolean_t	hf_inguest;
+};
+
+int
+hma_fpu_reset(hma_fpu_t *fpu, uint64_t xbv)
+{
+	struct xsave_state *xs;
+
+	ASSERT0(fpu->hf_inguest);
+
+	switch (fp_save_mech) {
+	case FP_FXSAVE:
+		bcopy(&sse_initial, fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_fx,
+		    sizeof (struct fxsave_state));
+		fpu->hf_kfpu.fpu_xsave_mask = 0;
+		break;
+	case FP_XSAVE:
+		/*
+		 * Check if any bits are set in the xbv value that aren't a part
+		 * of our normal set of requested values. If so, we must fail
+		 * this as there may be host related work required for us to be
+		 * able to properly use these.
+		 */
+		if ((xbv & ~(get_xcr(XFEATURE_ENABLED_MASK) &
+		    XFEATURE_FP_ALL)) != 0) {
+			return (EINVAL);
+		}
+
+		/*
+		 * Rezero everything in the xsave case as we may have data in
+		 * the structure that's not part of the initial value (which
+		 * only really deals with a small portion of the xsave state.
+		 */
+		xs = fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_xs;
+		bzero(xs, cpuid_get_xsave_size());
+		bcopy(&avx_initial, xs, sizeof (*xs));
+		xs->xs_xstate_bv = xbv;
+		fpu->hf_kfpu.fpu_xsave_mask = xbv;
+		break;
+	default:
+		panic("Invalid fp_save_mech");
+	}
+
+	fpu->hf_kfpu.fpu_flags = FPU_EN | FPU_VALID;
+
+	return (0);
+}
+
+void
+hma_fpu_free(hma_fpu_t *fpu)
+{
+	if (fpu == NULL)
+		return;
+	if (fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic != NULL) {
+		kmem_cache_free(fpsave_cachep, fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic);
+		fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic = NULL;
+	}
+
+	kmem_free(fpu, sizeof (*fpu));
+}
+
+hma_fpu_t *
+hma_fpu_alloc(int kmflag)
+{
+	hma_fpu_t *fpu;
+
+	fpu = kmem_zalloc(sizeof (hma_fpu_t), kmflag);
+	if (fpu == NULL)
+		return (NULL);
+
+	fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic = kmem_cache_alloc(fpsave_cachep, kmflag);
+	if (fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic == NULL) {
+		kmem_free(fpu, sizeof (hma_fpu_t));
+		return (NULL);
+	}
+	fpu->hf_inguest = B_FALSE;
+
+	/*
+	 * Make sure the entire structure is zero.
+	 */
+	switch (fp_save_mech) {
+	case FP_FXSAVE:
+		bzero(fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic,
+		    sizeof (struct fxsave_state));
+	case FP_XSAVE:
+		bzero(fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_generic,
+		    cpuid_get_xsave_size());
+		break;
+	default:
+		panic("Invalid fp_save_mech");
+	}
+
+	return (fpu);
+}
+
+void
+hma_fpu_start_guest(hma_fpu_t *fpu)
+{
+	/*
+	 * Note, we don't check / assert whether or not t_prempt is true because
+	 * there are contexts where this is safe to call (from a context op)
+	 * where t_preempt may not be set.
+	 */
+	ASSERT3S(fpu->hf_inguest, ==, B_FALSE);
+	ASSERT3P(fpu->hf_curthread, ==, NULL);
+	ASSERT3P(curthread->t_lwp, !=, NULL);
+	ASSERT3U(fpu->hf_kfpu.fpu_flags & FPU_EN, !=, 0);
+	ASSERT3U(fpu->hf_kfpu.fpu_flags & FPU_VALID, !=, 0);
+
+	fpu->hf_inguest = B_TRUE;
+	fpu->hf_curthread = curthread;
+
+
+	fp_save(&curthread->t_lwp->lwp_pcb.pcb_fpu);
+	fp_restore(&fpu->hf_kfpu);
+	fpu->hf_kfpu.fpu_flags &= ~FPU_VALID;
+}
+
+void
+hma_fpu_stop_guest(hma_fpu_t *fpu)
+{
+	ASSERT3S(fpu->hf_inguest, ==, B_TRUE);
+	ASSERT3P(fpu->hf_curthread, !=, NULL);
+	ASSERT3P(fpu->hf_curthread, ==, curthread);
+	ASSERT3U(fpu->hf_kfpu.fpu_flags & FPU_EN, !=, 0);
+	ASSERT3U(fpu->hf_kfpu.fpu_flags & FPU_VALID, ==, 0);
+
+	/*
+	 * Note, we can't use fp_save because it assumes that we're saving to
+	 * the thread's PCB and not somewhere else. Because this is a different
+	 * FPU context, we instead have to do this ourselves.
+	 */
+	switch (fp_save_mech) {
+	case FP_FXSAVE:
+		fpxsave(fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_fx);
+		break;
+	case FP_XSAVE:
+		xsavep(fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_xs,
+		    fpu->hf_kfpu.fpu_xsave_mask);
+		break;
+	default:
+		panic("Invalid fp_save_mech");
+		/*NOTREACHED*/
+	}
+	fpu->hf_kfpu.fpu_flags |= FPU_VALID;
+
+	fp_restore(&curthread->t_lwp->lwp_pcb.pcb_fpu);
+
+	fpu->hf_inguest = B_FALSE;
+	fpu->hf_curthread = NULL;
+}
+
+void
+hma_fpu_get_fxsave_state(const hma_fpu_t *fpu, struct fxsave_state *fx)
+{
+	const struct fxsave_state *guest;
+
+	ASSERT3S(fpu->hf_inguest, ==, B_FALSE);
+
+	guest = fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_fx;
+	bcopy(guest, fx, sizeof (*fx));
+}
+
+int
+hma_fpu_set_fxsave_state(hma_fpu_t *fpu, const struct fxsave_state *fx)
+{
+	struct fxsave_state *gfx;
+	struct xsave_state *gxs;
+	ASSERT3S(fpu->hf_inguest, ==, B_FALSE);
+
+	/*
+	 * XXX Come back and check the fxsave state and see if there's anything
+	 * that we should be checking. This may be a lot worse for xsave.
+	 */
+	switch (fp_save_mech) {
+	case FP_FXSAVE:
+		gfx = fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_fx;
+		bcopy(fx, gfx, sizeof (*fx));
+		break;
+	case FP_XSAVE:
+		gxs = fpu->hf_kfpu.fpu_regs.kfpu_u.kfpu_xs;
+		bzero(gxs, cpuid_get_xsave_size());
+		bcopy(fx, &gxs->xs_fxsave, sizeof (*fx));
+		gxs->xs_xstate_bv = XFEATURE_LEGACY_FP | XFEATURE_SSE;
+		break;
+	default:
+		panic("Invalid fp_save_mech");
+		/* NOTREACHED */
+	}
+
+	return (0);
+}
