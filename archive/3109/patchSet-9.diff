From c3ca7ae4e92ead914880cc6ced05ee89ffcfbf2d Mon Sep 17 00:00:00 2001
From: Kelly McLaughlin <kelly.mclaughlin@joyent.com>
Date: Tue, 15 May 2018 14:59:59 -0600
Subject: [PATCH] MANTA-3488 poseidon should be able to write when Manta is
 otherwise full for users Reviewed by: Jordan Hendricks
 <jordan.hendricks@joyent.com> Reviewed by: Jared Morrow <jm@joyent.com>

---
 bin/mpicker                    |  35 ++-
 lib/obj.js                     |   3 +-
 lib/picker.js                  | 452 ++++++++++++++++++++-------------
 main.js                        | 104 ++++++--
 sapi_manifests/muskie/template |   3 +-
 5 files changed, 389 insertions(+), 208 deletions(-)

diff --git a/bin/mpicker b/bin/mpicker
index d7dca66..8f5234f 100755
--- a/bin/mpicker
+++ b/bin/mpicker
@@ -30,7 +30,7 @@ var sprintf = mod_util.format;
 var VError = mod_verror.VError;
 var muskie_errors = require('../lib/errors');
 
-
+var consts = require('../lib/constants');
 
 ///-- Globals
 
@@ -41,9 +41,11 @@ var LOG = mod_bunyan.createLogger({
     stream: process.stderr
 });
 
-// Some default values to use when creating the picker.
-var DEF_MAX_PERCENT_UTIL = 90;
-var DEF_MAX_STREAMING_SIZE_MB = 5120;
+///--- Constants
+
+const DEF_MAX_STREAMING_SIZE_MB = 5120;
+const DEF_MAX_PERCENT_UTIL = 90;
+const DEF_MAX_OPERATOR_PERCENT_UTIL = 92;
 
 /*
  * Common options for all submcommands.
@@ -177,9 +179,11 @@ MPicker.prototype.do_poll = function do_poll(subcmd, opts, args, cb) {
     p_opts = {
         log: LOG,
         defaultMaxStreamingSizeMB: cfg.defaultMaxStreamingSizeMB ||
-            DEF_MAX_STREAMING_SIZE_MB,
+            consts.DEF_MAX_STREAMING_SIZE_MB,
         maxUtilizationPct: cfg.storage.maxUtilizationPct ||
-            DEF_MAX_PERCENT_UTIL,
+            consts.DEF_MAX_PERCENT_UTIL,
+        maxOperatorUtilizationPct: cfg.storage.maxOperatorUtilizationPct ||
+            consts.DEF_MAX_PERCENT_UTIL,
         multiDC: cfg.storage.multiDC,
         moray: cfg.storage.moray,
         lag: cfg.storage.lag
@@ -268,7 +272,9 @@ MPicker.prototype.do_poll = function do_poll(subcmd, opts, args, cb) {
      * from its polling, so we can listen for this to see the poll response.
      */
     iteration = 0;
-    p.on('topology', function onTopology(db) {
+    p.on('topology', function onTopology(sharkMaps) {
+        var db = opts.operator ? sharkMaps[1] : sharkMaps[0];
+
         if (opts.all) {
             console.log(JSON.stringify(db, null, 4));
         } else if (opts.json) {
@@ -313,6 +319,12 @@ MPicker.prototype.do_poll.options = commonOptions.concat([
         type: 'bool',
         help: 'Omit header row from tabular output',
         default: false
+    },
+    {
+        names: [ 'operator', 'o' ],
+        type: 'bool',
+        help: 'Display information based on operator utilization threshold',
+        default: false
     }
 ]);
 
@@ -496,15 +508,18 @@ MPicker.prototype.do_choose = function do_choose(subcmd, opts, args, cb) {
         function runChoose(_, vcb) {
             p_opts = {
                 log: LOG,
-                defaultMaxStreamingSizeMB: DEF_MAX_STREAMING_SIZE_MB,
-                maxUtilizationPct: DEF_MAX_PERCENT_UTIL,
+                defaultMaxStreamingSizeMB: consts.DEF_MAX_STREAMING_SIZE_MB,
+                maxUtilizationPct: consts.DEF_MAX_PERCENT_UTIL,
+                maxOperatorUtilizationPct: consts.DEF_MAX_OPERATOR_PERCENT_UTIL,
                 multiDC: user_dcs.length > 1,
                 standalone: true
             };
 
             p = mod_picker.createClient(p_opts);
 
-            p.setRecordsDb(user_db, function () {
+            setImmediate(function () {
+                mod_picker.sortAndStoreDcs.call(p, user_db, user_db);
+
                 var chooseOpts = {
                     replicas: replicas,
                     size: sizeBytes
diff --git a/lib/obj.js b/lib/obj.js
index af04a2b..d867dfe 100644
--- a/lib/obj.js
+++ b/lib/obj.js
@@ -307,7 +307,8 @@ function findSharks(req, res, next) {
     var opts = {
         replicas: req._copies,
         requestId: req.getId(),
-        size: req._size
+        size: req._size,
+        isOperator: req.caller.account.isOperator
     };
 
     log.debug(opts, 'findSharks: entered');
diff --git a/lib/picker.js b/lib/picker.js
index 4e8bcfa..9a83581 100644
--- a/lib/picker.js
+++ b/lib/picker.js
@@ -56,10 +56,8 @@ var moray = require('moray');
 var once = require('once');
 
 var objCommon = require('./obj');
-
 var VError = require('verror');
 
-
 require('./errors');
 
 
@@ -68,12 +66,23 @@ require('./errors');
 var sprintf = util.format;
 
 
-
 ///--- Private Functions
 
+/*
+ * Used to encode more detailed information about storage selection errors.
+ * Providing an error cause allows us to expose more detailed information in
+ * logging about why the picker was unable to choose a storage set.
+ */
+function PickerError(msg) {
+    VError.call(this, {
+        name: 'PickerError'
+    }, msg);
+}
+util.inherits(PickerError, VError);
+
 // Refreshes the local cache from moray
 
-var fetch = function fetch_moray(opts, cb) {
+var fetch = function fetchMoray(opts, cb) {
     assert.object(opts, 'options');
     assert.number(opts.lag, 'options.lag');
     assert.object(opts.moray, 'options.moray');
@@ -135,132 +144,172 @@ var fetch = function fetch_moray(opts, cb) {
 };
 
 
-var _cached_stub_data;
-function fetch_stub(opts, cb) {
-    cb = once(cb);
+/**
+ * A comparison function used to order storage zones based on available space.
+ *
+ * @param {object} a               - a storage zone object
+ * @param {integer} a.availableMB  - free space in MB on the storage zone
+ * @param {object} b               - a storage zone object
+ * @param {integer} b.availableMB  - free space in MB on the storage zone
+ * @throws {TypeError} on bad input.
+ */
+function storageZoneComparator(a, b) {
+    assert.object(a, 'a');
+    assert.object(b, 'b');
+    assert.number(a.availableMB, 'a.availableMB');
+    assert.number(b.availableMB, 'b.availableMB');
+
+    if (a.availableMB < b.availableMB) {
+        return (-1);
+    } else if (a.availableMB > b.availableMB) {
+        return (1);
+    }
 
-    var fs = require('fs');
-    var path = require('path');
+    return (0);
+}
 
-    var fname = process.env.UNIT_TEST_STUB_NAME || 'picker.stub.json';
-    var file = path.join(__dirname, '..', 'test', fname);
-    var _opts = {
-        encoding: 'utf8'
-    };
 
-    if (_cached_stub_data) {
-        process.nextTick(function () {
-            cb(null, _cached_stub_data);
-        });
-    } else {
-        fs.readFile(file, _opts, function (err, data) {
-            if (err) {
-                cb(err);
-                return;
-            }
+/**
+ * A function to sort the storage zones available for normal requests and those
+ * available only for operator requests within each datacenter by available
+ * storage.
+ *
+ * @param {object} dcObj   - an object mapping datacenters to their associated
+ *                           storage zones
+ * @param {object} opDcObj - an object mapping datacenters to their associated
+ *                           storage zones
+ * @throws {TypeError} on bad input.
+ */
+function sortAndStoreDcs(dcObj, opDcObj) {
+    assert.object(dcObj, 'dcObj');
+    assert.object(opDcObj, 'opDcObj');
+
+    var dcCount = 0;
+    var operatorDcCount = 0;
+    var dcs = Object.keys(dcObj);
+    var operatorDcs = Object.keys(opDcObj);
+
+    dcs.forEach(function dcSortAndCount(k) {
+        dcObj[k].sort(storageZoneComparator);
+        dcCount++;
+    });
 
-            var values;
-            try {
-                values = JSON.parse(data).filter(function (obj) {
-                    return (obj.value.percentUsed < opts.utilization);
-                }).map(function (obj) {
-                    return (obj.value);
-                });
-            } catch (e) {
-                cb(e);
-                return;
-            }
+    operatorDcs.forEach(function opDcSortAndCount(k) {
+        opDcObj[k].sort(storageZoneComparator);
+        operatorDcCount++;
+    });
 
-            _cached_stub_data = values;
-            cb(null, values);
-        });
+    if (dcCount > 0) {
+        this.datacenters = dcs;
+    } else {
+        this.log.warn('Picker.sortAndStoreDcs: could not find any minnow ' +
+                      'instances');
+        this.datacenters = [];
+    }
+
+    if (operatorDcCount > 0) {
+        this.operatorDatacenters = operatorDcs;
+    } else {
+        this.log.warn('Picker.sortAndStoreDcs: could not find any minnow ' +
+            'instances for operator requests');
+        this.operatorDatacenters = [];
     }
+
+    this.dcSharkMap = dcObj;
+    this.operatorDcSharkMap = opDcObj;
+    this.emit('topology', [this.dcSharkMap, this.operatorDcSharkMap]);
+
+    this.log.trace('Picker.sortAndStoreDcs: done');
 }
 
-/*
- * Used to encode more detailed information about storage selection errors.
- * Providing an error cause allows us to expose more detailed information in
- * logging about why the picker was unable to choose a storage set.
+/**
+ * Callback function invoked to process the storage zone query results from
+ * moray. The results are sorted based on the datacenter of each storage zone.
+ * This function requires that "this" be bound to an instance of Picker.
  */
-function PickerError(msg) {
-    VError.call(this, {
-        name: 'PickerError'
-    }, msg);
+function handleStorageResults(err, storageZoneResults) {
+    clearTimeout(this._storageTimer);
+    this._storageTimer =
+        setTimeout(pollStorage.bind(this), this.storageInterval);
+
+    if (err) {
+        /*
+         * Most errors here would be operational errors, including cases
+         * where we cannot reach Moray or Moray cannot reach PostgreSQL or
+         * the like.  In these cases, we want to log an error (which will
+         * likely fire an alarm), but do nothing else.  We'll retry again on
+         * our normal interval.  We'll only run into trouble if this doesn't
+         * succeed for long enough that minnow records expire, and in that
+         * case there's nothing we can really do about it anyway.
+         *
+         * It's conceivable that we hit a persistent error here like Moray
+         * being unable to parse our query.  That's essentially a programmer
+         * error in that we'd never expect this to happen in a functioning
+         * system.  It's not easy to identify these errors, and there
+         * wouldn't be much we could do to handle them anyway, so we treat
+         * all errors the same way: log (which fires the alarm) and wait for
+         * a retry.
+         */
+        this.log.error(err, 'Picker.handleStorageResults: unexpected error ' +
+            '(will retry)');
+        return;
+    }
+
+    var dcObj = {};
+    var opDcObj = {};
+
+    function sortByDatacenter(maxUtilization, v) {
+        if (!opDcObj[v.datacenter]) {
+            opDcObj[v.datacenter] = [];
+        }
+
+        opDcObj[v.datacenter].push(v);
+
+        /*
+         * Moray is queried for the sharks whose utilization is less than or
+         * equal to the maximum utilization percentage at which operator writes
+         * are still accepted. Find the set of sharks whose utilization is less
+         * than or equal to the utilization threshold for all requests.
+         */
+        if (v.percentUsed <= maxUtilization) {
+            if (!dcObj[v.datacenter]) {
+                dcObj[v.datacenter] = [];
+            }
+
+            dcObj[v.datacenter].push(v);
+        }
+    }
+
+    storageZoneResults.forEach(sortByDatacenter.bind(this, this.utilization));
+
+    /*
+     * We just defer to the next tick so we're not tying
+     * up the event loop to sort a lot if the list is large
+     */
+    setImmediate(sortAndStoreDcs.bind(this, dcObj, opDcObj));
 }
-util.inherits(PickerError, VError);
 
 
-// "this" must be bound to an instance of Picker. This simply
-// manages timers and calls `fetch`, above.
-function poll() {
+/**
+ * Function to manage the process of periodically querying Moray for available
+ * storage zones under the maximum utilization threshold. This function
+ * requires that "this" be bound to an instance of Picker. This period is
+ * determined by the value of storageInterval established when the Picker
+ * instance is created.
+ */
+function pollStorage() {
     assert.object(this.client, 'no client connected');
     assert.ok(!this.standalone, 'polling not available in standalone mode');
 
     var opts = {
         lag: this.lag,
         moray: this.client,
-        utilization: this.utilization
+        utilization: this.operatorUtilization
     };
-    var self = this;
-
-    function reschedule() {
-        clearTimeout(self._timer);
-        self._timer = setTimeout(poll.bind(self), self.interval);
-    }
-
-    self.log.trace('Picker.poll: entered');
-    clearTimeout(self._timer);
-    fetch(opts, function (err, values) {
-        reschedule();
-
-        if (err) {
-            /*
-             * Most errors here would be operational errors, including cases
-             * where we cannot reach Moray or Moray cannot reach PostgreSQL or
-             * the like.  In these cases, we want to log an error (which will
-             * likely fire an alarm), but do nothing else.  We'll retry again on
-             * our normal interval.  We'll only run into trouble if this doesn't
-             * succeed for long enough that minnow records expire, and in that
-             * case there's nothing we can really do about it anyway.
-             *
-             * It's conceivable that we hit a persistent error here like Moray
-             * being unable to parse our query.  That's essentially a programmer
-             * error in that we'd never expect this to happen in a functioning
-             * system.  It's not easy to identify these errors, and there
-             * wouldn't be much we could do to handle them anyway, so we treat
-             * all errors the same way: log (which fires the alarm) and wait for
-             * a retry.
-             */
-            self.log.error(err, 'Picker.poll: unexpected error (will retry)');
-            return;
-        }
 
-        var obj = {};
-        values.forEach(function (v) {
-            if (!obj[v.datacenter])
-                obj[v.datacenter] = [];
-            obj[v.datacenter].push(v);
-        });
-
-       /*
-        * In general, we don't want to replace a non-empty set of sharks
-        * with an empty one.  We make an exception at startup: provided
-        * the query to Moray did not result in any errors, we accept one
-        * empty result set.  This enables us to service requests that will
-        * not ask the Picker for a storage node, while remaining confident
-        * that once storage nodes become available, we'll know about them.
-        */
-        if (Object.keys(obj).length > 0 || self.firstTopology) {
-                self.firstTopology = false;
-                self.setRecordsDb(obj, function () {
-                    self.emit('topology', self.db);
-                    self.log.trace('Picker.poll: done');
-                });
-        } else {
-            self.log.warn('Picker.poll: could not find any minnow ' +
-                    'instances');
-        }
-    });
+    this.log.trace('Picker.pollStorage: entered');
+    clearTimeout(this._storageTimer);
+    fetch(opts, handleStorageResults.bind(this));
 }
 
 
@@ -288,13 +337,13 @@ function shuffle(array) {
 }
 
 
-// Modified binary-search. we're looking for the point in the set where all
-// servers have >= the desired space.  Logically you would then do
-//
-// set.slice(lower_bound(set, 100));
-//
-// But that creates a copy - but really the return value of this to $end is
-// what the picker logic can then look at
+/**
+ * Modified binary-search. We're looking for the point in the set at which all
+ * servers have at least the requested amount of space.  Logically you would
+ * then do set.slice(lower_bound(set, 100));
+ * But that creates a copy - but really the return value of this to $end is
+ * what the picker logic can then look at
+ */
 function lower_bound(set, size, low, high) {
     assert.arrayOfObject(set, 'set');
     assert.number(size, 'size');
@@ -319,17 +368,16 @@ function lower_bound(set, size, low, high) {
 }
 
 
-
 ///--- API
 
 /**
  * Creates an instance of picker, and an underlying moray client.
  *
  * You can pass in all the usual moray-client options, and additionally pass in
- * an `interval` field, which indicates how often to go poll Moray for minnow
- * updates.  The default is 30s.  Additionally, you can pass in a `lag` field,
- * which indicates how much "staleness" to allow in Moray records. The default
- * for `lag` is 60s.
+ * an `storageInterval` field, which indicates how often to go poll Moray
+ * for minnow updates.  The default is 30s.  Additionally, you can pass in a
+ * `lag` field, which indicates how much "staleness" to allow in Moray records.
+ *  The default for `lag` is 60s.
  */
 function Picker(opts) {
     assert.object(opts, 'options');
@@ -339,22 +387,35 @@ function Picker(opts) {
     assert.number(opts.maxUtilizationPct, 'options.maxUtilizationPct');
     assert.optionalObject(opts.moray, 'options.moray');
     assert.optionalBool(opts.multiDC, 'options.multiDC');
-    assert.optionalNumber(opts.interval, 'options.interval');
+    assert.optionalNumber(opts.storageInterval, 'options.storageInterval');
     assert.optionalNumber(opts.lag, 'options.lag');
     assert.optionalBool(opts.standalone, 'options.standalone');
 
     EventEmitter.call(this);
 
-    this.db = null;
+    /*
+     * The dcSharkMap is an object that maps datacenter names to an array of
+     * sharks sorted by available storage capacity that are all at or below the
+     * storage utilization threshold for normal manta requests.
+     */
+    this.dcSharkMap = null;
+    /*
+     * The operatorDcSharkMap is an object that maps datacenter names to an
+     * array of sharks sorted by available storage capacity that are all at or
+     * below the storage utilization threshold for operator manta requests.
+     */
+    this.operatorDcSharkMap = null;
     this.datacenters = null;
+    this.operatorDatacenters = null;
     this.dcIndex = -1;
-    this.interval = parseInt(opts.interval || 30000, 10);
+    this.storageInterval = parseInt(opts.storageInterval || 30000, 10);
     this.lag = parseInt(opts.lag || (60 * 60 * 1000), 10);
     this.log = opts.log.child({component: 'picker'}, true);
     this.multiDC = opts.multiDC === undefined ? true : opts.multiDC;
     this.url = opts.url;
     this.defMaxSizeMB = opts.defaultMaxStreamingSizeMB;
     this.utilization = opts.maxUtilizationPct;
+    this.operatorUtilization = opts.maxOperatorUtilizationPct;
 
     this.client = null;
 
@@ -369,8 +430,7 @@ function Picker(opts) {
         morayOptions.log = opts.log;
 
         this.client = moray.createClient(morayOptions);
-        this.client.once('connect', poll.bind(this));
-        this.firstTopology = true;
+        this.client.once('connect', pollStorage.bind(this));
         this.once('topology', this.emit.bind(this, 'connect'));
     }
 }
@@ -378,7 +438,7 @@ util.inherits(Picker, EventEmitter);
 
 
 Picker.prototype.close = function close() {
-    clearTimeout(this._timer);
+    clearTimeout(this._storageTimer);
     if (this.client)
         this.client.close();
 };
@@ -391,6 +451,7 @@ Picker.prototype.close = function close() {
  *                   - {number} size => req.getContentLength()
  *                   - {string} requestId => req.getId()
  *                   - {number} replicas => req.header('x-durability-level')
+ *                   - {boolean} isOperator => req.caller.account.isOperator
  * @param {funtion} callback => f(err, [sharkClient])
  */
 Picker.prototype.choose = function choose(opts, cb) {
@@ -398,6 +459,7 @@ Picker.prototype.choose = function choose(opts, cb) {
     assert.optionalObject(opts.log, 'options.log');
     assert.optionalNumber(opts.replicas, 'options.replicas');
     assert.optionalNumber(opts.size, 'options.size');
+    assert.optionalBool(opts.isOperator, 'options.isOperator');
     assert.func(cb, 'callback');
 
     cb = once(cb);
@@ -423,17 +485,26 @@ Picker.prototype.choose = function choose(opts, cb) {
      * enough space, we exclude them from the possible set of DCs to choose
      * from.
      */
-    this.datacenters.forEach(function filterDatacenters(dc) {
-        var l = lower_bound(self.db[dc], size);
+    function filterDatacenters(sharkMap, dc) {
+        var l = lower_bound(sharkMap[dc], size);
         if (l !== -1) {
             dcs.push(dc);
             offsets.push(l);
         }
-    });
-    dcs = shuffle(dcs);
+    }
+
+    var filterFun;
+
+    if (opts.isOperator) {
+        filterFun = filterDatacenters.bind(this, this.operatorDcSharkMap);
+        this.operatorDatacenters.forEach(filterFun);
+    } else {
+        filterFun = filterDatacenters.bind(this, this.dcSharkMap);
+        this.datacenters.forEach(filterFun);
+    }
 
     var chooseStats = {
-        db: self.db,
+        db: opts.isOperator ? self.operatorDcSharkMap : self.dcSharkMap,
         dcsInUse: dcs,
         offsets: offsets
     };
@@ -457,6 +528,8 @@ Picker.prototype.choose = function choose(opts, cb) {
         return;
     }
 
+    dcs = shuffle(dcs);
+
     /*
      * Pick a random shark from the next DC in the round robin ordering.  If it
      * hasn't yet been used for a set, return the shark.
@@ -471,7 +544,13 @@ Picker.prototype.choose = function choose(opts, cb) {
             self.dcIndex = 0;
 
         var ndx = self.dcIndex;
-        var dc = self.db[dcs[ndx]];
+        var dc;
+        if (opts.isOperator) {
+            dc = self.operatorDcSharkMap[dcs[ndx]];
+        } else {
+            dc = self.dcSharkMap[dcs[ndx]];
+        }
+
         var s = random(offsets[ndx], dc.length - 1);
 
         if (seen.indexOf(dc[s].manta_storage_id) === -1) {
@@ -529,13 +608,19 @@ Picker.prototype.choose = function choose(opts, cb) {
             cb(err, null, chooseStats);
             return;
         } else if (tuple && this.multiDC && replicas > 1) {
-            var _dcs = tuple.map(function (s) {
+            function mapFun(s) {
                 return (s.datacenter);
-            }).reduce(function (last, now) {
-                if (last.indexOf(now) === -1)
+            }
+
+            function reduceFun(last, now) {
+                if (last.indexOf(now) === -1) {
                     last.push(now);
+                }
+
                 return (last);
-            }, []);
+            }
+
+            var _dcs = tuple.map(mapFun).reduce(reduceFun, []);
 
             if (_dcs.length < 2) {
                 err_msg = 'insufficient number of DCs selected';
@@ -558,47 +643,11 @@ Picker.prototype.choose = function choose(opts, cb) {
 };
 
 
-/*
- * Given an input set of Moray records, sort them and set necessary properties
- * on the Picker object.
- */
-Picker.prototype.setRecordsDb = function setRecordsDb(db, cb) {
-    assert.object(db, 'db');
-    assert.func(cb, 'cb');
-
-    var self = this;
-
-    var dcs = Object.keys(db);
-
-   /*
-    * We defer to the end of the event loop, so that it's not tied up
-    * sorting if the list is large.
-    */
-    setImmediate(function () {
-        dcs.forEach(function (k) {
-            db[k].sort(function (a, b) {
-                if (a.availableMB < b.availableMB) {
-                    return (-1);
-                }
-                if (a.availableMB > b.availableMB) {
-                    return (1);
-                }
-
-                return (0);
-            });
-        });
-
-        self.db = db;
-        self.datacenters = dcs;
-        cb();
-    });
-};
-
-
 Picker.prototype.toString = function toString() {
     var str = '[object Picker <';
     str += 'datacenters=' + this.datacenters.length + ', ';
-    str += 'interval=' + this.interval + ', ';
+    str += 'operatorDatacenters=' + this.operatorDatacenters.length + ', ';
+    str += 'storageInterval=' + this.storageInterval + ', ';
     str += 'lag=' + this.lag + ', ';
     str += 'moray=' + this.client.toString();
     str += '>]';
@@ -611,10 +660,11 @@ Picker.prototype.toString = function toString() {
 ///--- Exports
 
 module.exports = {
-
     createClient: function createClient(options) {
         return (new Picker(options));
-    }
+    },
+
+    sortAndStoreDcs: sortAndStoreDcs
 
 };
 
@@ -622,6 +672,50 @@ module.exports = {
 
 ///--- Tests
 
+var _cached_stub_data;
+function fetch_stub(opts, cb) {
+    cb = once(cb);
+
+    var fs = require('fs');
+    var path = require('path');
+
+    var fname = process.env.UNIT_TEST_STUB_NAME || 'picker.stub.json';
+    var file = path.join(__dirname, '..', 'test', fname);
+    var _opts = {
+        encoding: 'utf8'
+    };
+
+    if (_cached_stub_data) {
+        process.nextTick(function () {
+            cb(null, _cached_stub_data);
+        });
+    } else {
+        fs.readFile(file, _opts, function (err, data) {
+            if (err) {
+                cb(err);
+                return;
+            }
+
+            var values;
+            try {
+                values = JSON.parse(data).filter(function (obj) {
+                    return (obj.value.percentUsed < opts.utilization);
+                }).map(function (obj) {
+                    return (obj.value);
+                });
+            } catch (e) {
+                cb(e);
+                return;
+            }
+
+            _cached_stub_data = values;
+            cb(null, values);
+        });
+    }
+}
+
+
+
 function test(N) {
     var picker = new Picker({
         log: require('bunyan').createLogger({
@@ -629,7 +723,7 @@ function test(N) {
             name: 'picker_test',
             stream: process.stdout
         }),
-        interval: 10,
+        storageInterval: 10,
         multiDC: true,
         url: 'tcp://10.99.99.44:2020'
     });
diff --git a/main.js b/main.js
index 2ad6ef4..4677e36 100644
--- a/main.js
+++ b/main.js
@@ -36,6 +36,11 @@ var vasync = require('vasync');
 var app = require('./lib');
 var uploadsCommon = require('./lib/uploads/common');
 
+///--- Constants
+
+const DEF_MAX_STREAMING_SIZE_MB = 51200;
+const DEF_MAX_PERCENT_UTIL = 90;
+const DEF_MAX_OPERATOR_PERCENT_UTIL = 92;
 
 ///--- Internal Functions
 
@@ -93,6 +98,47 @@ function parseOptions() {
     return (opts);
 }
 
+/**
+ * Verify the type of a numeric configuration property and set a default value
+ * if the property is not defined. If the value for the specified configuration
+ * property is not of type Number the process exits. Additionally the caller may
+ * supply a predicate that is used to evaluate the value given for the property.
+ * The process exits if the value does not conform to the predicate if it is
+ * supplied.
+ *
+ * @param {String} property: Required. The name of the configuration property.
+ * @param {Number} dfault: Required. A default value.
+ * @param {Object} config: Required. The configuration object.
+ * @param {Object} log: Required. A logging object.
+ * @param {Function} predicate: Optional. A function from Number to Boolean.
+ */
+function setNumericConfigProperty(property, dfault, config, log, predicate) {
+    assert.string(property, 'property');
+    assert.number(dfault, 'default property value');
+    assert.object(config, 'config');
+    assert.object(log, 'log');
+    assert.optionalFunc(predicate, 'predicate');
+
+    if (config.hasOwnProperty(property)) {
+        var cfgVal = config[property];
+
+        /*
+         * Ensure the configuration value for the property is of type
+         * Number. Also apply a property-specific predicate to the value if
+         * provided by the caller. If the value does not conform then the
+         * process exits.
+         */
+        if (typeof (cfgVal) !== 'number') {
+            log.fatal('invalid "' + cfgVal + '" value');
+            process.exit(1);
+        } else if (predicate && !predicate(cfgVal)) {
+            log.fatal('invalid "' + cfgVal + '" value');
+            process.exit(1);
+        }
+    } else {
+        config[property] = dfault;
+    }
+}
 
 /**
  * Configure the application based on the configuration file data and the
@@ -141,22 +187,9 @@ function configure(appName, opts, dtProbes) {
      * we assume a default value.  An operator may override this value by using
      * the "MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB" SAPI property.
      */
-    if (cfg.storage.hasOwnProperty('defaultMaxStreamingSizeMB')) {
-        var v = cfg.storage.defaultMaxStreamingSizeMB;
-
-        /*
-         * The structure of the configuration template is such that the value
-         * is a valid Number or not present at all.  Any other case would have
-         * already caused a JSON parse failure at an earlier point in this
-         * function.
-         */
-        if (typeof (v) !== 'number' || v < 1) {
-            cfg.log.fatal('invalid "defaultMaxStreamingSizeMB" value');
-            process.exit(1);
-        }
-    } else {
-        cfg.storage.defaultMaxStreamingSizeMB = 51200;
-    }
+    setNumericConfigProperty('defaultMaxStreamingSizeMB',
+        DEF_MAX_STREAMING_SIZE_MB, cfg.storage, cfg.log,
+        function (x) { return (x >= 1); });
 
     if (!cfg.hasOwnProperty('multipartUpload')) {
         cfg.multipartUpload = {};
@@ -178,6 +211,42 @@ function configure(appName, opts, dtProbes) {
         cfg.multipartUpload.prefixDirLen = uploadsCommon.DEF_PREFIX_LEN;
     }
 
+    setNumericConfigProperty('maxUtilizationPct',
+        DEF_MAX_PERCENT_UTIL, cfg.storage, cfg.log,
+        function (x) { return (x > 0 && x <= 100); });
+    setNumericConfigProperty('maxOperatorUtilizationPct',
+        DEF_MAX_OPERATOR_PERCENT_UTIL, cfg.storage, cfg.log,
+        function (x) { return (x > 0 && x <= 100); });
+
+    /*
+     * If the configuration is invalid such that the maximum utilization for
+     * normal request is greater than the maximum utilization for operator
+     * requests then log a warning and use the greater of the default maximum
+     * operator utilization or the maximum utilization for normal requests.
+     */
+    if (cfg.storage.maxUtilizationPct > cfg.storage.maxOperatorUtilizationPct) {
+        if (DEF_MAX_OPERATOR_PERCENT_UTIL > cfg.storage.maxUtilizationPct) {
+            cfg.log.warn('invalid configuration: "maxUtilizationPct" value (' +
+                cfg.storage.maxUtilizationPct + ') should not exceed the ' +
+                'value for maxOperatorUtilizationPct (' +
+                cfg.storage.maxOperatorUtilizationPct + '). Using the default' +
+                ' operator utilization value of ' +
+                DEF_MAX_OPERATOR_PERCENT_UTIL + ' as the value for ' +
+                'maxOperatorUtilizationPct.');
+            cfg.storage.maxOperatorUtilizationPct =
+                DEF_MAX_OPERATOR_PERCENT_UTIL;
+        } else {
+            cfg.log.warn('invalid configuration: "maxUtilizationPct" value (' +
+                cfg.storage.maxUtilizationPct + ') should not exceed the ' +
+                'value for maxOperatorUtilizationPct (' +
+                cfg.storage.maxOperatorUtilizationPct + '). Using ' +
+                cfg.storage.maxUtilizationPct + ' as the value for ' +
+                'maxOperatorUtilizationPct.');
+            cfg.storage.maxOperatorUtilizationPct =
+                cfg.storage.maxUtilizationPct;
+        }
+    }
+
     cfg.collector = artedi.createCollector({
         labels: {
             datacenter: cfg.datacenter,
@@ -393,7 +462,8 @@ function createPickerClient(cfg, log, onConnect) {
         log: log.child({component: 'picker'}, true),
         multiDC: cfg.multiDC,
         defaultMaxStreamingSizeMB: cfg.defaultMaxStreamingSizeMB,
-        maxUtilizationPct: cfg.maxUtilizationPct || 90
+        maxUtilizationPct: cfg.maxUtilizationPct,
+        maxOperatorUtilizationPct: cfg.maxOperatorUtilizationPct
     };
 
     var client = app.picker.createClient(opts);
diff --git a/sapi_manifests/muskie/template b/sapi_manifests/muskie/template
index b5f07df..43083bb 100644
--- a/sapi_manifests/muskie/template
+++ b/sapi_manifests/muskie/template
@@ -200,7 +200,8 @@
     "lag": 60000,
     "multiDC": {{MUSKIE_MULTI_DC}}{{#MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}},
     "defaultMaxStreamingSizeMB": {{MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}}{{/MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}}{{#MUSKIE_MAX_UTILIZATION_PCT}},
-    "maxUtilizationPct": {{MUSKIE_MAX_UTILIZATION_PCT}}{{/MUSKIE_MAX_UTILIZATION_PCT}},
+    "maxUtilizationPct": {{MUSKIE_MAX_UTILIZATION_PCT}}{{/MUSKIE_MAX_UTILIZATION_PCT}}{{#MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}},
+    "maxOperatorUtilizationPct": {{MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}}{{/MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}},
     "moray": {
         "srvDomain": "{{STORAGE_MORAY_SHARD}}",
         "cueballOptions": {
-- 
2.21.0

