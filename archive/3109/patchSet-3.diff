commit a1d48fe82acd83fa401f203f01ee1b69f414b9b5 (refs/changes/09/3109/3)
Author: Kelly McLaughlin <kelly.mclaughlin@joyent.com>
Date:   2017-12-19T12:43:31-07:00 (1 year, 10 months ago)
    
    MANTA-3488 poseidon should be able to write when Manta is otherwise full for users

diff --git a/lib/obj.js b/lib/obj.js
index 59993b3..2794aef 100644
--- a/lib/obj.js
+++ b/lib/obj.js
@@ -306,7 +306,8 @@ function findSharks(req, res, next) {
     var opts = {
         replicas: req._copies,
         requestId: req.getId(),
-        size: req._size
+        size: req._size,
+        isOperator: req.caller.account.isOperator
     };
 
     log.debug(opts, 'findSharks: entered');
diff --git a/lib/picker.js b/lib/picker.js
index 101a7b2..48d248e 100644
--- a/lib/picker.js
+++ b/lib/picker.js
@@ -56,7 +56,6 @@ var moray = require('moray');
 var assert = require('assert-plus');
 var once = require('once');
 
-
 require('./errors');
 
 
@@ -65,12 +64,11 @@ require('./errors');
 var sprintf = util.format;
 
 
-
 ///--- Private Functions
 
 // Refreshes the local cache from moray
 
-var fetch = function fetch_moray(opts, cb) {
+var fetch = function fetchMoray(opts, cb) {
     assert.object(opts, 'options');
     assert.number(opts.lag, 'options.lag');
     assert.object(opts.moray, 'options.moray');
@@ -132,137 +130,169 @@ var fetch = function fetch_moray(opts, cb) {
 };
 
 
-var _cached_stub_data;
-function fetch_stub(opts, cb) {
-    cb = once(cb);
+/**
+ * A comparision function used to order storage zones based on available space.
+ *
+ * @param {object} a               - a storage zone object
+ * @param {integer} a.availableMB  - free space in MB on the storage zone
+ * @param {object} b               - a storage zone object
+ * @param {integer} b.availableMB  - free space in MB on the storage zone
+ * @throws {TypeError} on bad input.
+ */
+function storageZoneComparator(a, b) {
+    assert.object(a, 'a');
+    assert.object(b, 'b');
+    assert.number(a.availableMB, 'a.availableMB');
+    assert.number(b.availableMB, 'b.availableMB');
+
+    if (a.availableMB < b.availableMB) {
+        return (-1);
+    } else if (a.availableMB > b.availableMB) {
+        return (1);
+    }
 
-    var fs = require('fs');
-    var path = require('path');
+    return (0);
+}
 
-    var fname = process.env.UNIT_TEST_STUB_NAME || 'picker.stub.json';
-    var file = path.join(__dirname, '..', 'test', fname);
-    var _opts = {
-        encoding: 'utf8'
-    };
 
-    if (_cached_stub_data) {
-        process.nextTick(function () {
-            cb(null, _cached_stub_data);
-        });
-    } else {
-        fs.readFile(file, _opts, function (err, data) {
-            if (err) {
-                cb(err);
-                return;
-            }
+/**
+ * A function to sort the storage zones available for normal requests and those
+ * available only for operator requests within each datacenter by available
+ * storage.
+ *
+ * @param {object} dcObj   - an object mapping a datacenter to an array of
+ *                           storage zones
+ * @param {object} opDcObj - an object mapping a datacenter to an array of
+ *                           storage zones
+ * @throws {TypeError} on bad input.
+ */
+function sortAndStoreDcs(dcObj, opDcObj) {
+    assert.object(dcObj, 'dcObj');
+    assert.object(opDcObj, 'opDcObj');
+
+    var dcCount = 0;
+    var operatorDcCount = 0;
+    var dcs = Object.keys(dcObj);
+    var operatorDcs = Object.keys(opDcObj);
+
+    dcs.forEach(function dcSortAndCount(k) {
+        dcObj[k].sort(storageZoneComparator);
+        dcCount++;
+    });
 
-            var values;
-            try {
-                values = JSON.parse(data).filter(function (obj) {
-                    return (obj.value.percentUsed < opts.utilization);
-                }).map(function (obj) {
-                    return (obj.value);
-                });
-            } catch (e) {
-                cb(e);
-                return;
-            }
+    operatorDcs.forEach(function opDcSortAndCount(k) {
+        opDcObj[k].sort(storageZoneComparator);
+        operatorDcCount++;
+    });
 
-            _cached_stub_data = values;
-            cb(null, values);
-        });
+    if (dcCount > 0) {
+        this.datacenters = dcs;
+    } else {
+        this.log.warn('Picker.pollStorage: could not find any minnow ' +
+                      'instances');
+        this.datacenters = [];
     }
-}
 
+    if (operatorDcCount > 0) {
+        this.operatorDatacenters = operatorDcs;
+    } else {
+        this.log.warn('Picker.pollStorage: could not find any minnow ' +
+                      'instances for operator requests');
+        this.operatorDatacenters = [];
+    }
 
+    this.db = opDcObj;
+    this.emit('topology', this.db);
+
+    this.log.trace('Picker.pollStorage: done');
+}
 
-// "this" must be bound to an instance of Picker. This simply
-// manages timers and calls `fetch`, above.
-function poll() {
-    var opts = {
-        lag: this.lag,
-        moray: this.client,
-        utilization: this.utilization
-    };
-    var self = this;
 
-    function reschedule() {
-        clearTimeout(self._timer);
-        self._timer = setTimeout(poll.bind(self), self.interval);
+/**
+ * Callback function invoked to process the storage zone query results from
+ * moray. The results are sorted based on the datacenter of each storage zone.
+ * This function requires that "this" be bound to an instance of Picker.
+ */
+function handleStorageResults(err, storageZoneResults) {
+    clearTimeout(this._storageTimer);
+    this._storageTimer =
+        setTimeout(pollStorage.bind(this), this.storageInterval);
+
+    if (err) {
+        /*
+         * Most errors here would be operational errors, including cases
+         * where we cannot reach Moray or Moray cannot reach PostgreSQL or
+         * the like.  In these cases, we want to log an error (which will
+         * likely fire an alarm), but do nothing else.  We'll retry again on
+         * our normal interval.  We'll only run into trouble if this doesn't
+         * succeed for long enough that minnow records expire, and in that
+         * case there's nothing we can really do about it anyway.
+         *
+         * It's conceivable that we hit a persistent error here like Moray
+         * being unable to parse our query.  That's essentially a programmer
+         * error in that we'd never expect this to happen in a functioning
+         * system.  It's not easy to identify these errors, and there
+         * wouldn't be much we could do to handle them anyway, so we treat
+         * all errors the same way: log (which fires the alarm) and wait for
+         * a retry.
+         */
+        this.log.error(err, 'Picker.pollStorage: unexpected error (will ' +
+                       'retry)');
+        return;
     }
 
-    self.log.trace('Picker.poll: entered');
-    clearTimeout(self._timer);
-    fetch(opts, function (err, values) {
-        reschedule();
-
-        if (err) {
-            /*
-             * Most errors here would be operational errors, including cases
-             * where we cannot reach Moray or Moray cannot reach PostgreSQL or
-             * the like.  In these cases, we want to log an error (which will
-             * likely fire an alarm), but do nothing else.  We'll retry again on
-             * our normal interval.  We'll only run into trouble if this doesn't
-             * succeed for long enough that minnow records expire, and in that
-             * case there's nothing we can really do about it anyway.
-             *
-             * It's conceivable that we hit a persistent error here like Moray
-             * being unable to parse our query.  That's essentially a programmer
-             * error in that we'd never expect this to happen in a functioning
-             * system.  It's not easy to identify these errors, and there
-             * wouldn't be much we could do to handle them anyway, so we treat
-             * all errors the same way: log (which fires the alarm) and wait for
-             * a retry.
-             */
-            self.log.error(err, 'Picker.poll: unexpected error (will retry)');
-            return;
+    var dcObj = {};
+    var opDcObj = {};
+
+    function sortByDatacenter(maxUtilization, v) {
+        if (!opDcObj[v.datacenter]) {
+            opDcObj[v.datacenter] = [];
         }
 
-        var obj = {};
-        values.forEach(function (v) {
-            if (!obj[v.datacenter])
-                obj[v.datacenter] = [];
-            obj[v.datacenter].push(v);
-        });
+        opDcObj[v.datacenter].push(v);
 
-        // We just defer to the next tick so we're not tying
-        // up the event loop to sort a lot if the list is large
-        process.nextTick(function () {
-            var count = 0;
-            var dcs = Object.keys(obj);
-
-            dcs.forEach(function (k) {
-                obj[k].sort(function (a, b) {
-                    if (a.availableMB < b.availableMB)
-                        return (-1);
-                    if (a.availableMB > b.availableMB)
-                        return (1);
-                    return (0);
-                });
-                count++;
-            });
-
-            /*
-             * In general, we don't want to replace a non-empty set of sharks
-             * with an empty one.  We make an exception at startup: provided
-             * the query to Moray did not result in any errors, we accept one
-             * empty result set.  This enables us to service requests that will
-             * not ask the Picker for a storage node, while remaining confident
-             * that once storage nodes become available, we'll know about them.
-             */
-            if (count > 0 || self.firstTopology) {
-                self.firstTopology = false;
-                self.datacenters = dcs;
-                self.db = obj;
-                self.emit('topology', self.db);
-            } else {
-                self.log.warn('Picker.poll: could not find any minnow ' +
-                    'instances');
+        /*
+         * Moray is queried for the sharks whose utilization is less than or
+         * equal to the maximum utilization percentage at which operator writes
+         * are still accepted. Find the set of sharks whose utilization is less
+         * than or equal to the utilization threshold for all requests.
+         */
+        if (v.percentUsed < maxUtilization) {
+            if (!dcObj[v.datacenter]) {
+                dcObj[v.datacenter] = [];
             }
 
-            self.log.trace('Picker.poll: done');
-        });
-    });
+            dcObj[v.datacenter].push(v);
+        }
+    }
+
+    storageZoneResults.forEach(sortByDatacenter.bind(this, this.utilization));
+
+    /*
+     * We just defer to the next tick so we're not tying
+     * up the event loop to sort a lot if the list is large
+     */
+    process.nextTick(sortAndStoreDcs.bind(this, dcObj, opDcObj));
+}
+
+
+/**
+ * Function to manage the process of periodically querying moray for available
+ * storage zones under the maximum utilization threshold. This function
+ * requires that "this" be bound to an instance of Picker. This period is
+ * determined by the value of storageInterval established when the Picker
+ * instance is created.
+ */
+function pollStorage() {
+    var opts = {
+        lag: this.lag,
+        moray: this.client,
+        utilization: this.operatorUtilization
+    };
+
+    this.log.trace('Picker.pollStorage: entered');
+    clearTimeout(this._storageTimer);
+    fetch(opts, handleStorageResults.bind(this));
 }
 
 
@@ -290,13 +320,13 @@ function shuffle(array) {
 }
 
 
-// Modified binary-search. we're looking for the point in the set where all
-// servers have >= the desired space.  Logically you would then do
-//
-// set.slice(lower_bound(set, 100));
-//
-// But that creates a copy - but really the return value of this to $end is
-// what the picker logic can then look at
+/**
+ * Modified binary-search. we're looking for the point in the set where all
+ * servers have >= the desired space.  Logically you would then do
+ * set.slice(lower_bound(set, 100));
+ * But that creates a copy - but really the return value of this to $end is
+ * what the picker logic can then look at
+ */
 function lower_bound(set, size, low, high) {
     assert.arrayOfObject(set, 'set');
     assert.number(size);
@@ -320,23 +350,22 @@ function lower_bound(set, size, low, high) {
 }
 
 
-
 ///--- API
 
 /**
  * Creates an instance of picker, and an underlying moray client.
  *
  * You can pass in all the usual moray-client options, and additionally pass in
- * an `interval` field, which indicates how often to go poll Moray for minnow
- * updates.  The default is 30s.  Additionally, you can pass in a `lag` field,
- * which indicates how much "staleness" to allow in Moray records. The default
- * for `lag` is 60s.
+ * an `storageInterval` field, which indicates how often to go poll Moray
+ * for minnow updates.  The default is 30s.  Additionally, you can pass in a
+ * `lag` field, which indicates how much "staleness" to allow in Moray records.
+ *  The default for `lag` is 60s.
  */
 function Picker(opts) {
     assert.object(opts, 'options');
     assert.object(opts, 'options.moray');
     assert.optionalBool(opts.multiDC, 'options.multiDC');
-    assert.optionalNumber(opts.interval, 'options.interval');
+    assert.optionalNumber(opts.storageInterval, 'options.storageInterval');
     assert.optionalNumber(opts.lag, 'options.lag');
     assert.number(opts.defaultMaxStreamingSizeMB,
         'options.defaultMaxStreamingSizeMB');
@@ -351,24 +380,23 @@ function Picker(opts) {
     this.client = moray.createClient(morayOptions);
     this.db = null;
     this.dcIndex = -1;
-    this.interval = parseInt(opts.interval || 30000, 10);
+    this.storageInterval = parseInt(opts.storageInterval || 30000, 10);
     this.lag = parseInt(opts.lag || (60 * 60 * 1000), 10);
     this.log = opts.log.child({component: 'picker'}, true);
     this.multiDC = opts.multiDC === undefined ? true : opts.multiDC;
     this.url = opts.url;
     this.defMaxSizeMB = opts.defaultMaxStreamingSizeMB;
     this.utilization = opts.maxUtilizationPct;
+    this.operatorUtilization = opts.maxOperatorUtilizationPct;
 
-    this.client.once('connect', poll.bind(this));
-
-    this.firstTopology = true;
+    this.client.once('connect', pollStorage.bind(this));
     this.once('topology', this.emit.bind(this, 'connect'));
 }
 util.inherits(Picker, EventEmitter);
 
 
 Picker.prototype.close = function close() {
-    clearTimeout(this._timer);
+    clearTimeout(this._storageTimer);
     if (this.client)
         this.client.close();
 };
@@ -381,6 +409,7 @@ Picker.prototype.close = function close() {
  *                   - {number} size => req.getContentLength()
  *                   - {string} requestId => req.getId()
  *                   - {number} replicas => req.header('x-durability-level')
+ *                   - {boolean} isOperator => req.caller.account.isOperator
  * @param {funtion} callback => f(err, [sharkClient])
  */
 Picker.prototype.choose = function choose(opts, cb) {
@@ -388,6 +417,7 @@ Picker.prototype.choose = function choose(opts, cb) {
     assert.optionalObject(opts.log, 'options.log');
     assert.optionalNumber(opts.replicas, 'options.replicas');
     assert.optionalNumber(opts.size, 'options.size');
+    assert.optionalBool(opts.isOperator, 'options.isOperator');
     assert.func(cb, 'callback');
 
     cb = once(cb);
@@ -406,14 +436,19 @@ Picker.prototype.choose = function choose(opts, cb) {
         defMaxSizeMB: this.defMaxSizeMB
     }, 'Picker.choose: entered');
 
-    this.datacenters.forEach(function filterDatacenters(dc) {
+    function filterDatacenters(dc) {
         var l = lower_bound(self.db[dc], size);
         if (l !== -1) {
             dcs.push(dc);
             offsets.push(l);
         }
-    });
-    dcs = shuffle(dcs);
+    }
+
+    if (opts.isOperator) {
+        this.operatorDatacenters.forEach(filterDatacenters);
+    } else {
+        this.datacenters.forEach(filterDatacenters);
+    }
 
     if ((replicas > 1 && this.multiDC && dcs.length < 2) ||
         !dcs.length ||
@@ -425,6 +460,8 @@ Picker.prototype.choose = function choose(opts, cb) {
         return;
     }
 
+    dcs = shuffle(dcs);
+
     function host() {
         if (++self.dcIndex >= dcs.length)
             self.dcIndex = 0;
@@ -482,13 +519,19 @@ Picker.prototype.choose = function choose(opts, cb) {
             cb(new NotEnoughSpaceError(size));
             return;
         } else if (tuple && this.multiDC && replicas > 1) {
-            var _dcs = tuple.map(function (s) {
+            function mapFun(s) {
                 return (s.datacenter);
-            }).reduce(function (last, now) {
-                if (last.indexOf(now) === -1)
+            }
+
+            function reduceFun(last, now) {
+                if (last.indexOf(now) === -1) {
                     last.push(now);
+                }
+
                 return (last);
-            }, []);
+            }
+
+            var _dcs = tuple.map(mapFun).reduce(reduceFun, []);
 
             if (_dcs.length < 2) {
                 cb(new NotEnoughSpaceError(size));
@@ -512,7 +555,8 @@ Picker.prototype.choose = function choose(opts, cb) {
 Picker.prototype.toString = function toString() {
     var str = '[object Picker <';
     str += 'datacenters=' + this.datacenters.length + ', ';
-    str += 'interval=' + this.interval + ', ';
+    str += 'operatorDatacenters=' + this.operatorDatacenters.length + ', ';
+    str += 'storageInterval=' + this.storageInterval + ', ';
     str += 'lag=' + this.lag + ', ';
     str += 'moray=' + this.client.toString();
     str += '>]';
@@ -536,6 +580,50 @@ module.exports = {
 
 ///--- Tests
 
+var _cached_stub_data;
+function fetch_stub(opts, cb) {
+    cb = once(cb);
+
+    var fs = require('fs');
+    var path = require('path');
+
+    var fname = process.env.UNIT_TEST_STUB_NAME || 'picker.stub.json';
+    var file = path.join(__dirname, '..', 'test', fname);
+    var _opts = {
+        encoding: 'utf8'
+    };
+
+    if (_cached_stub_data) {
+        process.nextTick(function () {
+            cb(null, _cached_stub_data);
+        });
+    } else {
+        fs.readFile(file, _opts, function (err, data) {
+            if (err) {
+                cb(err);
+                return;
+            }
+
+            var values;
+            try {
+                values = JSON.parse(data).filter(function (obj) {
+                    return (obj.value.percentUsed < opts.utilization);
+                }).map(function (obj) {
+                    return (obj.value);
+                });
+            } catch (e) {
+                cb(e);
+                return;
+            }
+
+            _cached_stub_data = values;
+            cb(null, values);
+        });
+    }
+}
+
+
+
 function test(N) {
     var picker = new Picker({
         log: require('bunyan').createLogger({
@@ -543,7 +631,7 @@ function test(N) {
             name: 'picker_test',
             stream: process.stdout
         }),
-        interval: 10,
+        storageInterval: 10,
         multiDC: true,
         url: 'tcp://10.99.99.44:2020'
     });
diff --git a/main.js b/main.js
index 2ad6ef4..f60bf1f 100644
--- a/main.js
+++ b/main.js
@@ -178,6 +178,46 @@ function configure(appName, opts, dtProbes) {
         cfg.multipartUpload.prefixDirLen = uploadsCommon.DEF_PREFIX_LEN;
     }
 
+    if (cfg.storage.hasOwnProperty('maxUtilizationPct')) {
+        var mu = cfg.storage.maxUtilizationPct;
+
+        /*
+         * The structure of the configuration template is such that the value
+         * is a valid Number or not present at all.  Any other case would have
+         * already caused a JSON parse failure at an earlier point in this
+         * function.
+         */
+        if (typeof (mu) !== 'number' || mu < 1) {
+            cfg.log.fatal('invalid "maxUtilizationPct" value');
+            process.exit(1);
+        }
+    } else {
+        cfg.storage.maxUtilizationPct = 90;
+    }
+
+    if (cfg.storage.hasOwnProperty('maxOperatorUtilizationPct')) {
+        var mou = cfg.storage.maxOperatorUtilizationPct;
+
+        /*
+         * The structure of the configuration template is such that the value
+         * is a valid Number or not present at all.  Any other case would have
+         * already caused a JSON parse failure at an earlier point in this
+         * function.
+         */
+        if (typeof (mou) !== 'number' || mou < 1) {
+            cfg.log.fatal('invalid "maxOperatorUtilizationPct" value');
+            process.exit(1);
+        }
+    } else {
+        cfg.storage.maxOperatorUtilizationPct = 92;
+    }
+
+    if (cfg.storage.maxUtilizationPct > cfg.storage.maxOperatorUtilizationPct) {
+        cfg.log.fatal('invalid configuration "maxUtilizationPct" value must ' +
+                  'not exceed the value for maxOperatorUtilizationPct.');
+        process.exit(1);
+    }
+
     cfg.collector = artedi.createCollector({
         labels: {
             datacenter: cfg.datacenter,
@@ -393,7 +433,8 @@ function createPickerClient(cfg, log, onConnect) {
         log: log.child({component: 'picker'}, true),
         multiDC: cfg.multiDC,
         defaultMaxStreamingSizeMB: cfg.defaultMaxStreamingSizeMB,
-        maxUtilizationPct: cfg.maxUtilizationPct || 90
+        maxUtilizationPct: cfg.maxUtilizationPct,
+        maxOperatorUtilizationPct: cfg.maxOperatorUtilizationPct
     };
 
     var client = app.picker.createClient(opts);
diff --git a/sapi_manifests/muskie/template b/sapi_manifests/muskie/template
index 56ec6d4..c839913 100644
--- a/sapi_manifests/muskie/template
+++ b/sapi_manifests/muskie/template
@@ -183,7 +183,8 @@
     "lag": 60000,
     "multiDC": {{MUSKIE_MULTI_DC}}{{#MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}},
     "defaultMaxStreamingSizeMB": {{MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}}{{/MUSKIE_DEFAULT_MAX_STREAMING_SIZE_MB}}{{#MUSKIE_MAX_UTILIZATION_PCT}},
-    "maxUtilizationPct": {{MUSKIE_MAX_UTILIZATION_PCT}}{{/MUSKIE_MAX_UTILIZATION_PCT}},
+    "maxUtilizationPct": {{MUSKIE_MAX_UTILIZATION_PCT}}{{/MUSKIE_MAX_UTILIZATION_PCT}}{{#MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}},
+    "maxOperatorUtilizationPct": {{MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}}{{/MUSKIE_MAX_OPERATOR_UTILIZATION_PCT}},
     "moray": {
         "srvDomain": "{{STORAGE_MORAY_SHARD}}",
         "cueballOptions": {
