commit ca89347953e2d28c28dd07d0b3c3b7567151e9b0 (refs/changes/20/1920/5)
Author: Trent Mick <trentm@gmail.com>
Date:   2017-06-02T11:22:45-07:00 (2 years, 4 months ago)
    
    HEAD-2361 support multi-level incremental core images for sdc-headnode build and headnode setup
    Reviewed by: Julien Gilli <julien.gilli@joyent.com>
    Approved by: Trent Mick <trentm@gmail.com>

diff --git a/README.md b/README.md
index 77317f0d..8d14cd08 100644
--- a/README.md
+++ b/README.md
@@ -122,48 +122,8 @@ In the example above,
 
 #### Build Artefacts
 
-Three classes of build artefact may be described in the build specification
-file: images, zones and files.
-
-##### Images
-
-Images, defined in the `"images"` key of the build specification file, refer to
-specific image dataset streams (and their associated manifests) as published in
-an IMGAPI service.  These artefacts are generally base images on which the
-incremental dataset streams for core SDC zone datasets (specified in `"zones"`)
-are based.
-
-For example, the `sdc-multiarch` image (version `13.3.1`) has UUID
-`"b4bdc598-8939-11e3-bea4-8341f6861379"`.  Its inclusion in the build is
-specified with the following in `build.spec`:
-
-```
-{
-    ...
-    "images": {
-        "multiarch-13.3.1": {
-            "imgapi": "https://updates.joyent.com",
-            "name": "sdc-multiarch",
-            "version": "13.3.1",
-            "uuid": "b4bdc598-8939-11e3-bea4-8341f6861379"
-        },
-        ...
-    },
-    ...
-}
-```
-
-The `"uuid"` is the primary key used to locate the image in the IMGAPI service,
-at the URL `"imgapi"`.  The `"name"` and `"version"` keys are checked against
-the metadata retrieved in the manifest for this image.
-
-The key used to name the object describing the image, i.e. `"multiarch-13.3.1"`
-above, is used to name the symbolic link in the `cache/` directory that
-later build steps will use to find the downloaded file.  The image definition
-above will result in the creation of two symlinks:
-
-- `cache/image.multiarch-13.3.1.imgmanifest`
-- `cache/image.multiarch-13.3.1.zfs.gz`
+Two classes of build artefact may be described in the build specification
+file: zones and files.
 
 ##### Zones
 
@@ -241,15 +201,28 @@ directory, using the original filename of the image, e.g. for `manatee`:
 - `sdc-manatee-zfs-release-20150514-20150514T135531Z-g58e19ad.imgmanifest`
 - `sdc-manatee-zfs-release-20150514-20150514T135531Z-g58e19ad.zfs.gz`
 
-Note that the filename includes the MG job name and branch.  A symbolic link
+Note that the filename includes the MG job name and branch. A symbolic link
 will also be created to the downloaded files using the short name we specified,
 i.e.
 
 - `zone.manatee.imgmanifest`
-- `zone.manatee.zfs.gz`
+- `zone.manatee.imgfile`
+
+
+In addition, any origin images of the zone image will also be downloaded and
+placed in the `cache/` directory, e.g.:
+
+- 04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f.imgmanifest
+- 04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f.imgfile
+
+Likewise, a symbolic link will be created to the download origin image files:
+
+- image.04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f.imgmanifest
+- image.04a48d7d-6bb5-4e83-8c3b-e60a99e0f48f.imgfile
+
+These symlinks are used by subsequent build phases to locate the downloaded
+build artefact.
 
-This symlink is used by subsequent build phases to locate the downloaded build
-artefact.
 
 ##### Files
 
diff --git a/bin/build-tar-image b/bin/build-tar-image
index d7e50bc0..245fba70 100755
--- a/bin/build-tar-image
+++ b/bin/build-tar-image
@@ -6,9 +6,15 @@
 #
 
 #
-# Copyright 2017 Joyent, Inc.
+# Copyright (c) 2017, Joyent, Inc.
 #
 
+if [[ -n "$TRACE" ]]; then
+    # BASHSTYLED
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+
 ROOT=$(cd $(dirname $0)/../; pwd)
 
 . "${ROOT}/buildtools/lib/error_handler.sh"
@@ -374,36 +380,6 @@ function cleanup_logs
     fi
 }
 
-function cleanup_bit
-{
-    local bits_pattern="^$1"
-
-    local bits_dir="${ROOT}/cache"
-    local kept=0
-    local keep_bits=
-    keep_bits=$(build_spec keep-bits)
-
-    if [[ -n ${keep_bits} && ${keep_bits} -gt 0 ]]; then
-        [[ -n ${TRACE} ]] \
-            && echo "CLEANUP_BIT CALLED FOR: '${bits_pattern}'" >&2
-
-        local bit=
-        for bit in $(ls -1t ${bits_dir} | grep "${bits_pattern}"); do
-            if [[ ! -f ${bits_dir}/${bit} ]]; then
-                # skip non-file
-                continue;
-            fi
-            if [[ ${kept} -lt ${keep_bits} ]]; then
-                [[ -n ${TRACE} ]] && echo "KEEPING: ${bit}" >&2
-                kept=$((${kept} + 1))
-            else
-                echo "DELETING: ${bit}" >&2
-                rm ${bits_dir}/${bit} >&2
-            fi
-        done
-    fi
-}
-
 function get_bit
 {
     local name
@@ -555,66 +531,32 @@ function test_bzip2
     fi
 }
 
-function copy_datasets
+#
+# Test the given compressed file.
+# Usage:
+#   test_compression FILE-PATH COMPRESSION-TYPE
+# where COMPRESSION-TYPE is one of 'bzip2', 'gzip', or none per
+# <https://images.joyent.com/docs/#manifest-files>.
+#
+function test_compression
 {
-    local dataset
-    local name
-    local version
-    local file_image
-    local comp_ext
-    local target_name
-    local target_vers
-    local target_base
-
-    mkdir -p "${STAGE}/datasets"
-    mkdir -p "${ROOT}/datasets"
-
-    DATASET_LIST=$(${BUILDSPEC} -a images)
-
-    for name in ${DATASET_LIST}; do
-        printf '==> Copying dataset "%s" to "datasets/"\n' "${name}"
-
-        #
-        # Locate image manifest file:
-        #
-        file_manifest="$(get_bit "image.${name}.imgmanifest")"
-
-        #
-        # Locate compressed image stream file:
-        #
-        comp_ext=
-        file_image="${CACHE}/image.${name}.zfs"
-        if [[ -f "${file_image}.gz" ]]; then
-            comp_ext='gz'
-            file_image="${CACHE}/$(readlink "${file_image}.${comp_ext}")"
-            file_image="$(get_bit "image.${name}.zfs.${comp_ext}")"
-            test_gzip "${file_image}"
-        elif [[ -f "${file_image}.bz2" ]]; then
-            comp_ext='bz2'
-            file_image="$(get_bit "image.${name}.zfs.${comp_ext}")"
-            test_bzip2 "${file_image}"
-        else
-            fatal "Could not find dataset image file!"
-        fi
-
-        #
-        # Copy files:
-        #
-        target_name=$(${BUILDSPEC} "images|${name}|name")
-        target_version=$(${BUILDSPEC} "images|${name}|version")
-        target_base="${target_name}-${target_version}"
-
-        printf '  ==> copy "%s"\n' "${target_base}.imgmanifest"
-        ln "${file_manifest}" "${STAGE}/datasets/${target_base}.imgmanifest"
-
-        printf '  ==> copy "%s"\n' "${target_base}.zfs.${comp_ext}"
-        ln "${file_image}" "${STAGE}/datasets/${target_base}.zfs.${comp_ext}"
-
-        #
-        # Write metadata:
-        #
-        echo "${target_base}" >> "${STAGE}/datasets/img_dependencies"
-    done
+    if [[ -z ${NO_COMPRESS_CHECK} ]]; then
+        case "${2}" in
+        gzip)
+            printf '  ==> test gzip compression "%s"\n' "$(basename "${1}")"
+            gzip -t "${1}" || fatal "gzip file ${1} is corrupt; aborting"
+            ;;
+        bzip2)
+            printf '  ==> test bzip2 compression "%s"\n' "$(basename "${1}")"
+            bzip2 -t "${1}" || fatal "bzip2 file ${1} is corrupt; aborting"
+            ;;
+        none)
+            ;;
+        *)
+            fatal "invalid compression type: '$2'"
+            ;;
+        esac
+    fi
 }
 
 function copy_core_zone_image
@@ -622,23 +564,54 @@ function copy_core_zone_image
     local name=$1
     local file_manifest
     local file_image
-    local x
     local service
     local image_uuid
+    local origin_uuid
+    local origin_manifest
+    local origin_file
+
+    mkdir -p "${STAGE}/images"
 
     #
     # Locate image manifest and compressed stream file:
     #
     file_manifest="$(get_bit "zone.${name}.imgmanifest")"
-    file_image="$(get_bit "zone.${name}.zfs.gz")"
+    file_image="$(get_bit "zone.${name}.imgfile")"
     test_gzip "${file_image}"
+    image_uuid="$(${JSON} -f "${file_manifest}" uuid)"
 
     #
     # Copy files:
     #
-    for x in ${file_manifest} ${file_image}; do
-        printf '  ==> copy "%s"\n' "$(basename "${x}")"
-        ln "${x}" "${STAGE}/datasets/$(basename "${x}")"
+    echo "  ==> copy 'images/${image_uuid}.imgmanifest'"
+    ln "${file_manifest}" "${STAGE}/images/${image_uuid}.imgmanifest"
+    echo "  ==> copy 'images/${image_uuid}.imgfile'"
+    ln "${file_image}" "${STAGE}/images/${image_uuid}.imgfile"
+
+    #
+    # Copy image ancestry (origin images):
+    #
+    origin_uuid="$(${JSON} -f "${file_manifest}" origin)"
+    while true; do
+        if [[ -z "${origin_uuid}" ]]; then
+            break
+        fi
+        if [[ -f "${STAGE}/images/${origin_uuid}.imgmanifest" ]]; then
+            # Already have it in "images/".
+            break
+        fi
+
+        origin_manifest="$(get_bit "image.${origin_uuid}.imgmanifest")"
+        origin_file="$(get_bit "image.${origin_uuid}.imgfile")"
+        test_compression "${origin_file}" \
+            "$(${JSON} -f "${origin_manifest}" files.0.compression)"
+
+        echo "  ==> copy origin 'images/${origin_uuid}.imgmanifest'"
+        ln "${origin_manifest}" "${STAGE}/images/${origin_uuid}.imgmanifest"
+        echo "  ==> copy origin 'images/${origin_uuid}.imgfile'"
+        ln "${origin_file}" "${STAGE}/images/${origin_uuid}.imgfile"
+
+        origin_uuid="$(${JSON} -f "${origin_manifest}" origin)"
     done
 
     #
@@ -655,18 +628,17 @@ function copy_core_zone_image
     #
     service="${STAGE}/services/${name}/service.json"
     if [[ -f ${service} ]]; then
-        image_uuid="$(${JSON} -f "${file_manifest}" uuid)"
         sed -i'.tmp' -e "s|IMAGE_UUID|${image_uuid}|" "${service}"
         rm -f "${service}.tmp"
     fi
+
     #
-    # The full dataset name is written to this file so that headnode
+    # The image uuid is written to this file so that headnode
     # setup may locate it.  The USB key filesystem is mounted for
-    # setup using pcfs(7FS) with the "foldcase" option, so the filename
-    # is written here in lowercase.  (See also: mount_pcfs(1M)).
+    # setup using pcfs(7FS) with the "foldcase" option, so beware that the
+    # filename must be lowercase. (See also: mount_pcfs(1M)).
     #
-    echo $(basename "${file_manifest}") | tr '[:upper:]' '[:lower:]' \
-      > "${STAGE}/zones/${name}/dataset"
+    echo "${image_uuid}" > "${STAGE}/zones/${name}/image"
 }
 
 function copy_zones
@@ -677,11 +649,10 @@ function copy_zones
 
     zone_list="$(${BUILDSPEC} -a zones)"
 
-    mkdir -p "${STAGE}/datasets"
     mkdir -p "${STAGE}/zones"
 
     for zone in ${zone_list}; do
-        printf '==> Copying zone "%s" to "zones/"\n' "${zone}"
+        echo "==> Copying zone '${zone}'"
 
         #
         # We use the "-L" flag to copy to ensure that the _target_
@@ -748,7 +719,6 @@ copy_platform
 copy_sdcadm
 copy_agentsshar
 copy_sapi_config
-copy_datasets
 copy_zones
 copy_tools
 copy_config
diff --git a/build.spec b/build.spec
index 874966cc..c15c7707 100644
--- a/build.spec
+++ b/build.spec
@@ -109,38 +109,5 @@
       "alt_manta_base": "joyent-manta-base-path",
       "file": { "base": "firmware-tools", "ext": "tgz" }
     }
-  },
-
-  "images": {
-    "smartos-1.6.3": {
-      "imgapi": "https://updates.joyent.com",
-      "name": "sdc-smartos",
-      "version": "1.6.3",
-      "uuid": "fd2cc906-8938-11e3-beab-4359c665ac99"
-    },
-    "multiarch-13.3.1": {
-      "imgapi": "https://updates.joyent.com",
-      "name": "sdc-multiarch",
-      "version": "13.3.1",
-      "uuid": "b4bdc598-8939-11e3-bea4-8341f6861379"
-    },
-    "base64-13.3.1": {
-      "imgapi": "https://updates.joyent.com",
-      "name": "sdc-base64",
-      "version": "13.3.1",
-      "uuid": "aeb4e3e0-8937-11e3-b0bd-637363a89e49"
-    },
-    "base-14.2.0": {
-      "imgapi": "https://updates.joyent.com",
-      "name": "sdc-base",
-      "version": "14.2.0",
-      "uuid": "de411e86-548d-11e4-a4b7-3bb60478632a"
-    },
-    "sdc-minimal-multiarch-lts-15.4.1": {
-      "imgapi": "https://updates.joyent.com",
-      "name": "sdc-minimal-multiarch-lts",
-      "version": "15.4.1",
-      "uuid": "18b094b0-eb01-11e5-80c1-175dac7ddf02"
-    }
   }
 }
diff --git a/buildtools/novus/cmd/downloader.js b/buildtools/novus/cmd/downloader.js
index 9ea7e6c8..7e7c8683 100644
--- a/buildtools/novus/cmd/downloader.js
+++ b/buildtools/novus/cmd/downloader.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  */
 
 var mod_fs = require('fs');
@@ -164,11 +164,16 @@ bit_enum_assert(be, next)
 	mod_assert.func(next, 'next');
 }
 
+/*
+ * Gather the bits for this zone image. However, do *not* append them to
+ * `be.be_out`. Instead they are returned via the `next` callback:
+ * `next(null, out)`.
+ */
 function
-bit_enum_zone(be, next)
-{
+bit_enum_zone(be, next) {
 	bit_enum_assert(be, next);
 
+	var bits;
 	var name = be.be_name;
 	var zone_spec = function (key, optional) {
 		return (be.be_spec.get('zones|' + name + '|' + key, optional));
@@ -186,24 +191,56 @@ bit_enum_zone(be, next)
 		base_path = be.be_spec.get(alt_base_var);
 	}
 
-	var basen;
-
 	switch (source) {
 	case 'manta':
-		basen = jobname + '-zfs';
-		lib_bits_from_manta(be.be_out, {
+		bits = [];
+		lib_bits_from_manta(bits, {
 			bfm_manta: be.be_manta,
 			bfm_prefix: 'zone.' + name,
 			bfm_jobname: jobname,
 			bfm_branch: branch,
 			bfm_files: [
-				{ name: name + '_manifest',
-				    base: basen, ext: 'imgmanifest' },
-				{ name: name + '_image',
-				    base: basen, ext: 'zfs.gz' }
+				{
+					name: name + '_imgmanifest',
+					base: jobname + '-zfs',
+					ext: 'imgmanifest',
+					get_bit_json: true
+				},
+				{
+					name: name + '_imgfile',
+					base: jobname + '-zfs',
+					ext: 'zfs.gz',
+					symlink_ext: 'imgfile'
+				}
 			],
 			bfm_base_path: base_path
-		}, next);
+		}, function on_manta_bits(err) {
+			if (err) {
+				next(err);
+				return;
+			}
+
+			/*
+			 * Append `bits` to `be.be_out` and gather any
+			 * origin images.
+			 */
+			var img;
+			bits.forEach(function push_bit(bit) {
+				be.be_out.push(bit);
+				if (bit.bit_name === name + '_imgmanifest') {
+					img = bit.bit_json;
+				}
+			});
+			mod_assert.object(img, 'img manifest');
+
+			if (img.origin) {
+				lib_common.origin_bits_from_updates(be.be_out, {
+					obfu_origin_uuid: img.origin
+				}, next);
+			} else {
+				next();
+			}
+		});
 		return;
 
 	case 'imgapi':
@@ -211,7 +248,7 @@ bit_enum_zone(be, next)
 			bfi_prefix: 'zone.' + name,
 			bfi_imgapi: 'https://updates.joyent.com',
 			bfi_uuid: zone_spec('uuid'),
-			bfi_channel: zone_spec('channel'),
+			bfi_channel: zone_spec('channel', true),
 			bfi_name: jobname
 		}, next);
 		return;
@@ -219,53 +256,58 @@ bit_enum_zone(be, next)
 	case 'bits-dir':
 		mod_assert.string(process.env.BITS_DIR, '$BITS_DIR');
 
-		basen = jobname + '-zfs';
-		lib_bits_from_dir(be.be_out, {
+		bits = [];
+		lib_bits_from_dir(bits, {
 			bfd_dir: mod_path.join(process.env.BITS_DIR,
 			    jobname),
 			bfd_prefix: 'zone.' + name,
 			bfd_jobname: jobname,
 			bfd_branch: branch,
 			bfd_files: [
-				{ name: name + '_manifest',
-				    base: basen, ext: 'imgmanifest' },
-				{ name: name + '_image',
-				    base: basen, ext: 'zfs.gz' }
+				{
+					name: name + '_imgmanifest',
+					base: jobname + '-zfs',
+					ext: 'imgmanifest',
+					get_bit_json: true
+				},
+				{
+					name: name + '_imgfile',
+					base: jobname + '-zfs',
+					ext: 'zfs.gz',
+					symlink_ext: 'imgfile'
+				}
 			]
-		}, next);
-		return;
-
-	default:
-		next(new VError('unsupported "zone" source "%s"', source));
-		return;
-	}
-}
-
-function
-bit_enum_image(be, next)
-{
-	bit_enum_assert(be, next);
-
-	var name = be.be_name;
-	var image_spec = function (key, optional) {
-		return (be.be_spec.get('images|' + name + '|' + key, optional));
-	};
-
-	var source = image_spec('source', true) || 'imgapi';
+		}, function on_dir_bits(err) {
+			if (err) {
+				next(err);
+				return;
+			}
 
-	switch (source) {
-	case 'imgapi':
-		lib_bits_from_image(be.be_out, {
-			bfi_prefix: 'image.' + name,
-			bfi_imgapi: image_spec('imgapi'),
-			bfi_uuid: image_spec('uuid'),
-			bfi_version: image_spec('version'),
-			bfi_name: image_spec('name')
-		}, next);
+			/*
+			 * Append `bits` to `be.be_out` and gather any
+			 * origin images.
+			 */
+			var img;
+			bits.forEach(function push_bit(bit) {
+				be.be_out.push(bit);
+				if (bit.bit_name === name + '_imgmanifest') {
+					img = bit.bit_json;
+				}
+			});
+			mod_assert.object(img, 'img manifest');
+
+			if (img.origin) {
+				lib_common.origin_bits_from_updates(be.be_out, {
+					obfu_origin_uuid: img.origin
+				}, next);
+			} else {
+				next();
+			}
+		});
 		return;
 
 	default:
-		next(new VError('unsupported "image" source "%s"', source));
+		next(new VError('unsupported "zone" source "%s"', source));
 		return;
 	}
 }
@@ -401,8 +443,7 @@ process_artefacts(pa, callback)
 	mod_vasync.forEachParallel({
 		inputs: [
 			{ type: 'zones', func: bit_enum_zone },
-			{ type: 'files', func: bit_enum_file },
-			{ type: 'images', func: bit_enum_image }
+			{ type: 'files', func: bit_enum_file }
 		],
 		func: process_artefact_type
 	}, function (err) {
diff --git a/buildtools/novus/lib/bits_from/dir.js b/buildtools/novus/lib/bits_from/dir.js
index 1b37142e..538748fa 100755
--- a/buildtools/novus/lib/bits_from/dir.js
+++ b/buildtools/novus/lib/bits_from/dir.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var mod_path = require('path');
@@ -38,8 +38,7 @@ bits_from_dir(out, bfd, next)
 			return;
 		}
 
-		mod_assert.arrayOfObject(bfd.bfd_files,
-		    'bfd_files');
+		mod_assert.arrayOfObject(bfd.bfd_files, 'bfd_files');
 
 		for (var i = 0; i < bfd.bfd_files.length; i++) {
 			var mf = bfd.bfd_files[i];
@@ -48,10 +47,11 @@ bits_from_dir(out, bfd, next)
 			mod_assert.string(mf.mf_path, 'path');
 			mod_assert.string(mf.mf_name, 'name');
 			mod_assert.string(mf.mf_ext, 'ext');
+			mod_assert.optionalObject(mf.mf_bit_json, 'bit_json');
 
 			var bn = mod_path.basename(mf.mf_path);
 
-			out.push({
+			var bit = {
 				bit_type: 'file',
 				bit_name: mf.mf_name,
 				bit_local_file: lib_common.cache_path(bn),
@@ -61,7 +61,11 @@ bits_from_dir(out, bfd, next)
 					'.',
 					mf.mf_ext
 				].join('')
-			});
+			};
+			if (mf.mf_bit_json) {
+				bit.bit_json = mf.mf_bit_json;
+			}
+			out.push(bit);
 		}
 
 		next();
@@ -102,6 +106,8 @@ bfd_find_build_files(bfd, next)
 		mod_assert.string(f.base, 'f.base');
 		mod_assert.string(f.ext, 'f.ext');
 		mod_assert.string(f.name, 'f.name');
+		mod_assert.optionalString(f.symlink_ext, 'f.symlink_ext');
+		mod_assert.optionalBool(f.get_bit_json, 'f.get_bit_json');
 
 		patterns.push({
 			p_re: new RegExp([
@@ -116,7 +122,9 @@ bfd_find_build_files(bfd, next)
 			p_ents: [],
 			p_base: f.base,
 			p_ext: f.ext,
-			p_name: f.name
+			p_symlink_ext: f.symlink_ext,
+			p_name: f.name,
+			p_get_bit_json: f.get_bit_json
 		});
 	}
 
@@ -164,9 +172,10 @@ bfd_find_build_files(bfd, next)
 
 			if (p.p_ents.length < 1) {
 				next(new VError('pattern "%s" in dir ' +
-				    '"%s" matched %d entries, ' +
-				    'expected >= 1', bfd.bfd_dir,
-				    p.p_re.toString(), p.p_ents.length));
+				    '"%s" matched %d entries, expected >= 1',
+				    p.p_re.toString(),
+				    bfd.bfd_dir,
+				    p.p_ents.length));
 				return;
 			}
 
@@ -190,11 +199,25 @@ bfd_find_build_files(bfd, next)
 				return;
 			}
 
-			files.push({
+			var mf = {
 				mf_name: p.p_name,
 				mf_path: p.p_ents[p.p_ents.length - 1],
-				mf_ext: p.p_ext
-			});
+				mf_ext: p.p_symlink_ext || p.p_ext
+			};
+
+			if (p.p_get_bit_json) {
+				var data = mod_fs.readFileSync(mf.mf_path,
+				    {encoding: 'utf8'});
+				try {
+					mf.mf_bit_json = JSON.parse(data);
+				} catch (parse_err) {
+					next(new VError(parse_err,
+					    '"%s" is not JSON', mf.mf_path));
+					return;
+				}
+			}
+
+			files.push(mf);
 		}
 
 		bfd.bfd_files = files;
diff --git a/buildtools/novus/lib/bits_from/image.js b/buildtools/novus/lib/bits_from/image.js
index 3abf5274..ca49c356 100755
--- a/buildtools/novus/lib/bits_from/image.js
+++ b/buildtools/novus/lib/bits_from/image.js
@@ -44,7 +44,8 @@ bits_from_image(out, bfi, next)
 	].join('/');
 	var query = (bfi.bfi_channel ? '?channel=' + bfi.bfi_channel : '');
 
-	lib_common.get_json_via_http(url + query, function (err, img) {
+	lib_common.get_json_via_http(url + query, {},
+	    function on_img(err, img) {
 		if (err) {
 			next(new VError(err, 'could not get image "%s"',
 			    uuid));
@@ -95,10 +96,7 @@ bits_from_image(out, bfi, next)
 				'.imgmanifest'
 			].join('')),
 			bit_json: img,
-			bit_make_symlink: [
-				bfi.bfi_prefix,
-				'.imgmanifest'
-			].join('')
+			bit_make_symlink: bfi.bfi_prefix + '.imgmanifest'
 		});
 
 		/*
@@ -118,16 +116,22 @@ bits_from_image(out, bfi, next)
 			bit_hash_type: 'sha1',
 			bit_hash: fil.sha1,
 			bit_size: fil.size,
-			bit_make_symlink: [
-				bfi.bfi_prefix,
-				'.zfs.',
-				fil.compression === 'bzip2' ? 'bz2' : 'gz'
-			].join('')
+			bit_make_symlink: bfi.bfi_prefix + '.imgfile'
 		});
 
-		next();
+		/*
+		 * Walk the ancestry (origin chain) for this image and create
+		 * download requests from updates.joyent.com (if not already
+		 * in `out`).
+		 */
+		if (img.origin) {
+			lib_common.origin_bits_from_updates(out, {
+				obfu_origin_uuid: img.origin
+			}, next);
+		} else {
+			next();
+		}
 	});
-
 }
 
 module.exports = bits_from_image;
diff --git a/buildtools/novus/lib/bits_from/manta.js b/buildtools/novus/lib/bits_from/manta.js
index fd7a2190..c954c6bf 100755
--- a/buildtools/novus/lib/bits_from/manta.js
+++ b/buildtools/novus/lib/bits_from/manta.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  */
 
 var mod_path = require('path');
@@ -50,6 +50,7 @@ bits_from_manta(out, bfm, next)
 			mod_assert.string(mf.mf_path, 'path');
 			mod_assert.string(mf.mf_name, 'name');
 			mod_assert.string(mf.mf_ext, 'ext');
+			mod_assert.optionalObject(mf.mf_bit_json, 'bit_json');
 
 			var bn = mod_path.basename(mf.mf_path);
 			var hash = bfm.bfm_manta_hashes[bn];
@@ -60,7 +61,7 @@ bits_from_manta(out, bfm, next)
 				return;
 			}
 
-			out.push({
+			var bit = {
 				bit_type: 'manta',
 				bit_name: mf.mf_name,
 				bit_local_file: lib_common.cache_path(bn),
@@ -72,7 +73,11 @@ bits_from_manta(out, bfm, next)
 					'.',
 					mf.mf_ext
 				].join('')
-			});
+			};
+			if (mf.mf_bit_json) {
+				bit.bit_json = mf.mf_bit_json;
+			}
+			out.push(bit);
 		}
 
 		next();
@@ -114,6 +119,8 @@ bfm_find_build_files(bfm, next)
 		mod_assert.string(f.base, 'f.base');
 		mod_assert.string(f.ext, 'f.ext');
 		mod_assert.string(f.name, 'f.name');
+		mod_assert.optionalString(f.symlink_ext, 'f.symlink_ext');
+		mod_assert.optionalBool(f.get_bit_json, 'f.get_bit_json');
 
 		patterns.push({
 			p_re: new RegExp([
@@ -129,7 +136,9 @@ bfm_find_build_files(bfm, next)
 			p_ent: null,
 			p_base: f.base,
 			p_ext: f.ext,
-			p_name: f.name
+			p_symlink_ext: f.symlink_ext,
+			p_name: f.name,
+			p_get_bit_json: Boolean(f.get_bit_json)
 		});
 	}
 
@@ -147,6 +156,51 @@ bfm_find_build_files(bfm, next)
 		}
 	};
 
+	var mf_from_pattern = function (p, next_p)
+	{
+		mod_assert.object(p, 'pattern');
+		mod_assert.func(next_p, 'next_p');
+
+		if (p.p_count !== 1) {
+			next_p(new VError('pattern "%s" matched %d entries, ' +
+			    'expected 1', p.p_re.toString(), p.p_count));
+			return;
+		}
+
+		var mf = {
+			mf_name: p.p_name,
+			mf_path: p.p_ent,
+			mf_ext: p.p_symlink_ext || p.p_ext,
+		};
+
+		/*
+		 * If requested, download and parse the Manta file as JSON.
+		 */
+		if (!p.p_get_bit_json) {
+			next_p(null, mf);
+		} else {
+			lib_common.get_manta_file(bfm.bfm_manta, p.p_ent,
+			    function got_manta_file(err, data) {
+				if (err) {
+					next_p(err);
+					return;
+				} else if (data === false) {
+					next_p(new VError('"%s" not found',
+					    p.p_ent));
+					return;
+				}
+				try {
+					mf.mf_bit_json = JSON.parse(data);
+				} catch (parse_err) {
+					next_p(new VError(parse_err,
+					    '"%s" is not JSON', p.p_ent));
+					return;
+				}
+				next_p(null, mf);
+			});
+		}
+	};
+
 	/*
 	 * Walk the build artefact directory for this build run:
 	 */
@@ -164,34 +218,26 @@ bfm_find_build_files(bfm, next)
 		});
 
 		res.once('end', function () {
-			var files = [];
-
-			for (var i = 0; i < patterns.length; i++) {
-				var p = patterns[i];
-
-				if (p.p_count !== 1) {
-					next(new VError('pattern "%s" in dir ' +
-					    '"%s" matched %d entries, ' +
-					    'expected 1', bfm.bfm_manta_dir,
-					    p.p_re.toString(), p.p_count));
+			mod_vasync.forEachParallel({
+				inputs: patterns,
+				func: mf_from_pattern
+			}, function checked_patterns(err, results) {
+				if (err) {
+					next(new VError(err, 'could not ' +
+					    'find matching Manta files in ' +
+					    'dir "%s"', bfm.bfm_manta_dir));
 					return;
 				}
 
-				files.push({
-					mf_name: p.p_name,
-					mf_path: p.p_ent,
-					mf_ext: p.p_ext
-				});
-			}
+				/*
+				 * Store the full Manta path(s) of the build
+				 * object for subsequent tasks:
+				 */
+				bfm.bfm_manta_files = results.successes;
 
-			/*
-			 * Store the full Manta path(s) of the build object
-			 * for subsequent tasks:
-			 */
-			bfm.bfm_manta_files = files;
+				next();
+			});
 
-			next();
-			return;
 		});
 	});
 }
diff --git a/buildtools/novus/lib/common.js b/buildtools/novus/lib/common.js
index 18c979ac..5fe374df 100755
--- a/buildtools/novus/lib/common.js
+++ b/buildtools/novus/lib/common.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright 2017 Joyent, Inc.
  */
 
 var mod_path = require('path');
@@ -29,13 +29,15 @@ delta_ms(hrt_epoch)
 }
 
 function
-get_via_http(url_str, callback)
+get_via_http(url_str, headers, callback)
 {
 	mod_assert.string(url_str, 'url_str');
+	mod_assert.object(headers, 'headers');
 	mod_assert.func(callback, 'callback');
 
 	var opts = mod_url.parse(url_str);
 	var mod_proto = (opts.protocol === 'https:') ? mod_https : mod_http;
+	opts.headers = headers;
 
 	var req = mod_proto.request(opts, function (res) {
 		if (res.statusCode !== 200) {
@@ -55,9 +57,9 @@ get_via_http(url_str, callback)
 }
 
 function
-get_json_via_http(url_str, callback)
+get_json_via_http(url_str, headers, callback)
 {
-	get_via_http(url_str, function (err, res) {
+	get_via_http(url_str, headers, function (err, res) {
 		if (err) {
 			callback(err);
 			return;
@@ -129,11 +131,114 @@ root_path(path)
 	    path)));
 }
 
+
+/*
+ * Append "bit_enum" objects (see downloader.js "bit_enum_*" functions) to
+ * `out`: one for each image in the given `obfu_origin_uuid`'s ancestry.
+ */
+function
+origin_bits_from_updates(out, obfu, next)
+{
+	mod_assert.arrayOfObject(out, 'out');
+	mod_assert.object(obfu, 'obfu');
+	mod_assert.string(obfu.obfu_origin_uuid, 'obfu.obfu_origin_uuid');
+	mod_assert.func(next, 'next');
+
+	var origin_uuid = obfu.obfu_origin_uuid;
+	var url = 'https://updates.joyent.com/images/' + origin_uuid;
+	var query = '?channel=*';
+
+	get_json_via_http(url + query, {
+		'Accept-Version': '~2' // Need IMGAPI v2 to get "channels".
+	}, function on_img(err, img) {
+		if (err) {
+			next(new VError(err, 'could not get image "%s"',
+			    origin_uuid));
+			return;
+		}
+
+		mod_assert.arrayOfString(img.channels, 'img.channels');
+		var channel = img.channels[0];
+		delete img.channels; // Don't want "channels" field for USB key.
+
+		/*
+		 * This image must have exactly one file:
+		 */
+		if (!img.files || img.files.length !== 1) {
+			next(new VError(
+			    'invalid image "%s": other than 1 file',
+			    origin_uuid));
+			return;
+		}
+
+		/*
+		 * Many images can share this origin. If this is already in
+		 * our download list, then we are done.
+		 */
+		var bit_name = origin_uuid + '_imgmanifest';
+		var have_it = out.some(function (rec) {
+			return rec.bit_name === bit_name;
+		});
+		if (have_it) {
+			next();
+			return;
+		}
+
+		var fil = img.files[0];
+		mod_assert.string(fil.sha1, 'file.sha1');
+		mod_assert.number(fil.size, 'file.size');
+		mod_assert.string(fil.compression, 'file.compression');
+
+		/*
+		 * Create a synthetic "download" request that will write the
+		 * manifest object we just loaded to the appropriate cache
+		 * file.
+		 */
+		out.push({
+			bit_type: 'json',
+			bit_name: origin_uuid + '_imgmanifest',
+			bit_local_file: cache_path(
+			    origin_uuid + '.imgmanifest'),
+			bit_json: img,
+			bit_make_symlink: 'image.' + origin_uuid +
+			    '.imgmanifest'
+		});
+
+		/*
+		 * Create a download request for the image file:
+		 */
+		out.push({
+			bit_type: 'http',
+			bit_name: origin_uuid + '_imgfile',
+			bit_local_file: cache_path(origin_uuid + '.imgfile'),
+			bit_url: url + '/file?channel=' + channel,
+			bit_hash_type: 'sha1',
+			bit_hash: fil.sha1,
+			bit_size: fil.size,
+			bit_make_symlink: 'image.' + origin_uuid + '.imgfile'
+		});
+
+		/*
+		 * Walk the ancestry (origin chain) for this image and create
+		 * download requests for them (if not already in `out`).
+		 */
+		if (img.origin) {
+			origin_bits_from_updates(out, {
+				obfu_origin_uuid: img.origin
+			}, next);
+		} else {
+			next();
+		}
+	});
+}
+
+
 module.exports = {
 	root_path: root_path,
 	cache_path: cache_path,
 	get_via_http: get_via_http,
 	get_json_via_http: get_json_via_http,
 	get_manta_file: get_manta_file,
-	delta_ms: delta_ms
+	delta_ms: delta_ms,
+	origin_bits_from_updates: origin_bits_from_updates
 };
diff --git a/buildtools/novus/lib/work/download_file.js b/buildtools/novus/lib/work/download_file.js
index a46a698c..5dd8de2e 100644
--- a/buildtools/novus/lib/work/download_file.js
+++ b/buildtools/novus/lib/work/download_file.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright 2015 Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 var mod_crypto = require('crypto');
@@ -154,7 +154,7 @@ dfop_download_file_http(arg, next)
 	arg.bar.add(dfop.dfop_bit.bit_name, dfop.dfop_expected_size);
 
 	var start = Date.now();
-	lib_common.get_via_http(dfop.dfop_url, function (err, res) {
+	lib_common.get_via_http(dfop.dfop_url, {}, function (err, res) {
 		if (err) {
 			next(err);
 			return;
diff --git a/scripts/build-payload.js b/scripts/build-payload.js
index 58d10ad9..bb94a0d7 100755
--- a/scripts/build-payload.js
+++ b/scripts/build-payload.js
@@ -6,7 +6,7 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2017, Joyent, Inc.
  */
 
 /**
@@ -21,11 +21,16 @@ var execFile = cp.execFile;
 var fs = require('fs');
 
 // Globals
+
+/* JSSTYLED */
+var UUID_RE = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
+
 var zone = process.argv[2];
 var passed_uuid = process.argv[3];
 var config;
 var obj = {};
 
+
 async.series([
     function ensureArgs(cb) {
         if (!zone) {
@@ -78,35 +83,29 @@ async.series([
     },
     function setImageUuid(cb) {
         if (!obj.hasOwnProperty('image_uuid')) {
-            // find out which dataset we should use for these zones
-            return fs.readFile('/usbkey/zones/' + zone + '/dataset',
-                               function readDataset(err, data) {
+            var image_path = '/usbkey/zones/' + zone + '/image';
+            fs.readFile(image_path, {
+                encoding: 'utf8'
+            }, function readImage(err, data) {
                 if (err) {
-                    return cb(new Error('Unable to find dataset name: ' +
-                              err.message));
+                    cb(new Error('Unable to read "' + image_path + '": ' +
+                        err.message));
+                    return;
                 }
-                var image_file_name = data.toString().split('\n')[0];
-                return fs.readFile('/usbkey/datasets/' + image_file_name,
-                                   function readImgmanifest(_err, _data) {
-                    if (_err) {
-                        return cb(new Error('unable to load imgmanifest: ' +
-                                  _err.message));
-                    }
-
-                    try {
-                        var imgmanifest = JSON.parse(_data.toString());
-                    } catch (e) {
-                        return cb(new Error('exception loading imgmanifest for '
-                            + zone + ': ' + e.message));
-                    }
-
-                    obj.image_uuid = imgmanifest.uuid;
-                    return cb();
-                });
+
+                var image_uuid = data.split('\n')[0].trim();
+                if (!UUID_RE.test(image_uuid)) {
+                    cb(new Error('first line of "' + image_path +
+                        '" is not a UUID: "' + image_uuid + '"'));
+                    return;
+                }
+
+                obj.image_uuid = image_uuid;
+                cb();
             });
         } else {
             // obj already has image_uuid so we'll use that.
-            return cb();
+            cb();
         }
     },
     function setPackageValues(cb) {
diff --git a/scripts/headnode.sh b/scripts/headnode.sh
index 0c881a83..196860f0 100755
--- a/scripts/headnode.sh
+++ b/scripts/headnode.sh
@@ -479,31 +479,6 @@ function create_zone {
     # This just moves us to the beginning of the line (once)
     cr_once
 
-    # If zone has specified dataset_uuid, we need to ensure that's imported.
-    if [[ -f ${USB_COPY}/zones/${zone}/dataset ]]; then
-        # PCFS casing. sigh.
-        ds_name=$(cat ${USB_COPY}/zones/${zone}/dataset)
-        [[ -z ${ds_name} ]] && \
-            fatal "No dataset specified in ${USB_COPY}/zones/${zone}/dataset"
-        ds_manifest=$(ls ${USB_COPY}/datasets/${ds_name})
-        [[ -z ${ds_manifest} ]] && fatal "No manifest found at ${ds_manifest}"
-        ds_basename=$(echo "${ds_name}" | sed -e "s/\.zfs\.imgmanifest$//" \
-            -e "s/\.dsmanifest$//" -e "s/\.imgmanifest$//")
-        ds_filename=$(ls ${USB_COPY}/datasets/${ds_basename}.zfs+(.bz2|.gz) \
-                      | head -1)
-        [[ -z ${ds_filename} ]] && fatal "No filename found for ${ds_name}"
-        ds_uuid=$(json uuid < ${ds_manifest})
-        [[ -z ${ds_uuid} ]] && fatal "No uuid found for ${ds_name}"
-
-        # imgadm exits non-zero when the dataset is already imported, we need to
-        # work around that.
-        if [[ ! -d /zones/${ds_uuid} ]]; then
-            printf_log "%-58s" "importing: $(echo ${ds_name} | cut -d'.' -f1) "
-            imgadm install -m ${ds_manifest} -f ${ds_filename}
-            printf_timer "done (%ss)\n" >&${CONSOLE_FD}
-        fi
-    fi
-
     if [[ ${restore} == 0 ]]; then
         printf_log "%-58s" "creating zone ${existing_uuid}${zone}... "
     else
@@ -772,17 +747,25 @@ function adopt_agents()
 # to secondary headnodes without re-bootstrapping core services.
 if setup_state_not_seen "setup_complete" \
         && setup_state_not_seen "sdczones_created"; then
-    # If the zone image is incremental, you'll need to manually setup the import
-    # here for the origin dataset for now. The way to do this is add the name
-    # and uuid to build.spec's datasets.
-    if [[ -f /usbkey/datasets/img_dependencies ]]; then
-        for name in $(cat /usbkey/datasets/img_dependencies); do
-            imgadm install -f \
-                "$(ls -1 /usbkey/datasets/${name}.zfs.{gz,bz2} 2>/dev/null \
-                    | head -1)" \
-                -m /usbkey/datasets/${name}.imgmanifest
-        done
-    fi
+
+    # Import all the USB key images into the zpool -- in ancestry order.
+    cat /usbkey/images/*.imgmanifest \
+        | json -e 'this.origin = this.origin || this.uuid' -ga origin uuid \
+        | tsort \
+        | while read img_uuid; do
+
+        # Checking /zones/$img_uuid is a little faster than using exit
+        # status 3 from `imgadm get $img_uuid` to see if the image is already
+        # installed in the zpool.
+        if [[ ! -d /zones/${img_uuid} ]]; then
+            img_namever=$(json -f /usbkey/images/$img_uuid.imgmanifest \
+                -a -d@ name version)
+            printf_log "%-58s" "importing image ${img_namever:0:37}... "
+            imgadm install -m /usbkey/images/$img_uuid.imgmanifest \
+                -f /usbkey/images/$img_uuid.imgfile
+            printf_timer "done (%ss)\n"
+        fi
+    done
 
     # These are here in the order they'll be brought up.
     create_zone assets
@@ -852,85 +835,34 @@ EOF
 fi
 
 
-# Import the images used for SDC services into IMGAPI.
+# Import all the USB key images into IMGAPI.
 function import_smartdc_service_images {
+    local img_uuid
+    local img_manifest
+    local img_file
 
-    # If the zone image is incremental, you'll need to manually setup the import
-    # here for the origin dataset for now. The way to do this is add the name
-    # and uuid to build.spec's datasets.
-    if [[ -f /usbkey/datasets/img_dependencies ]]; then
-        for name in $(cat /usbkey/datasets/img_dependencies); do
-            local retries=0
-            local max_retries=6
-            local bail=true
-            while [[ ${retries} -lt ${max_retries} ]]; do
-                if [[ -f /usbkey/datasets/${name}.zfs.gz ]]; then
-                    file="/usbkey/datasets/${name}.zfs.gz"
-                elif [[ -f /usbkey/datasets/${name}.zfs.bz2 ]]; then
-                    file="/usbkey/datasets/${name}.zfs.bz2"
-                fi
-                manifest="/usbkey/datasets/${name}.imgmanifest"
-                # Unlike with sdc-imgapi, we know that any failure will exit
-                # non-zero. There is one failure that we do not care about and
-                # it is the (ImageUuidAlreadyExists) failure.
-                if ! err=$(/opt/smartdc/bin/sdc-imgadm \
-                    import  --skip-owner-check -f $file  -m $manifest \
-                    2>&1 | awk '{print $3;}'); then
-
-                        if [[ ${err} == "(ImageUuidAlreadyExists):" ]]; then
-                            bail=false
-                            break;
-                        fi
-                else
-                        bail=false
-                        break;
-                fi
-                retries=`expr $retries + 1`;
-            done
-            if [[ ${bail} == "true" ]]; then
-                fatal "Unable to import image file ${file}" \
-                    " after ${retries} tries."
-            fi
-        done
-    fi
+    # The `tsort` is a "total order" sort to ensure origin images are imported
+    # first.
+    cat /usbkey/images/*.imgmanifest \
+        | json -e 'this.origin = this.origin || this.uuid' -ga origin uuid \
+        | tsort \
+        | while read img_uuid; do
 
-    for manifest in $(ls -1 ${USB_COPY}/datasets/*.imgmanifest); do
-        local is_smartdc_service
-        is_smartdc_service=$(cat $manifest | json tags.smartdc_service)
-        if [[ "$is_smartdc_service" != "true" ]]; then
-            # /usbkey/datasets often has non-core images. Don't import those
-            # here. This includes any additional datasets included in
-            # build.spec#datasets.
-            continue
-        fi
-        local uuid
-        uuid=$(cat ${manifest} | json uuid)
+        img_manifest=/usbkey/images/$img_uuid.imgmanifest
+        img_file=/usbkey/images/$img_uuid.imgfile
 
         # We'll retry up to 3 times on errors reaching IMGAPI.
         local ok=false
         local retries=0
         while [[ ${ok} == "false" && ${retries} -lt 3 ]]; do
             local status
-            status=$(/opt/smartdc/bin/sdc-imgapi /images/${uuid} \
+            status=$(/opt/smartdc/bin/sdc-imgapi /images/${img_uuid} \
                 | head -1 | awk '{print $2}')
             if [[ "${status}" == "404" ]]; then
-                # The core images all have .zfs.imgmanifest extensions.
-
-                local file_basename
-                file_basename=$(echo "${manifest}" \
-                    | sed -e "s/\.zfs\.imgmanifest$//" \
-                        -e "s/\.dsmanifest$//" -e "s/\.imgmanifest$//")
-                local file
-                file=$(ls -1 ${file_basename}.zfs+(.bz2|.gz) | head -1)
-
-                if [[ -z ${file} ]]; then
-                    # BASHSTYLED
-                    fatal "Unable to find file for ${manifest} in: $(ls -l /usbkey/datasets)"
-                fi
+                echo "Importing Triton image ${img_uuid} into IMGAPI:"
+                echo "    manifest: ${img_manifest}"
+                echo "    file:     ${img_file}"
 
-                # BASHSTYLED
-                echo "Importing SDC service image ${uuid} (${manifest}, ${file}) into IMGAPI."
-                [[ -f ${file} ]] || fatal "Image file ${file} not found."
                 # Skip the check that "owner" exists in UFDS during setup
                 # b/c if this is not the DC with the UFDS master, then the
                 # admin user will not have been replicated yet.
@@ -939,8 +871,8 @@ function import_smartdc_service_images {
                 # We have to retry the sdc-imgadm command here as well.
                 while [[ ${imgadm_retries} -lt 6 ]]; do
                     if ! err=$(/opt/smartdc/bin/sdc-imgadm \
-                        import --skip-owner-check -m ${manifest} -f ${file} \
-                        2>&1 | awk '{print $3;}'); then
+                        import --skip-owner-check -m ${img_manifest} \
+                        -f ${img_file} 2>&1 | awk '{print $3;}'); then
                             if [[ ${err} == "(ImageUuidAlreadyExists):" ]]; then
                                 bail=false
                                 break;
@@ -952,21 +884,21 @@ function import_smartdc_service_images {
                     fi
                 done
                 if [[ ${bail} == "true" ]]; then
-                    fatal "Unable to import image file ${file}" \
+                    fatal "Unable to import image file ${img_file}" \
                         " after ${retries} tries."
                 fi
                 ok=true
             elif [[ "${status}" == "200" ]]; then
                 # exists
-            # BASHSTYLED
-                echo "Skipping import of SDC service image ${uuid}: already in IMGAPI."
+                echo "Skipping import of Triton image ${img_uuid}: " \
+                    "already in IMGAPI."
                 ok=true
             else
                 retries=$((${retries} + 1))
             fi
         done
         if [[ ${ok} != "true" ]]; then
-            fatal "Unable to import image ${uuid} after ${retries} tries."
+            fatal "Unable to import image ${img_uuid} after ${retries} tries."
         fi
     done
 }
diff --git a/scripts/setup_manta_zone.sh b/scripts/setup_manta_zone.sh
index 08bf517c..aa87926a 100755
--- a/scripts/setup_manta_zone.sh
+++ b/scripts/setup_manta_zone.sh
@@ -6,7 +6,7 @@
 #
 
 #
-# Copyright (c) 2014, Joyent, Inc.
+# Copyright (c) 2017, Joyent, Inc.
 #
 
 #
@@ -16,6 +16,9 @@
 # BASHSTYLED
 export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
 set -o xtrace
+set -o errexit
+set -o pipefail
+
 
 PATH=/opt/smartdc/bin:$PATH
 
@@ -36,7 +39,7 @@ function add_external_nic {
     local tmpfile=/tmp/update_nics.$$.json
 
     local num_nics
-    num_nics=$(sdc-vmapi /vms/${zone_uuid} | json -H nics.length);
+    num_nics=$(sdc-vmapi /vms/${zone_uuid} | json -H nics.length)
     if [[ ${num_nics} == 2 ]]; then
         return  # External NIC already present
     fi
@@ -54,34 +57,55 @@ function add_external_nic {
     }" > ${tmpfile}
 
     sdc-vmapi /vms/${zone_uuid}?action=add_nics -X POST \
-        -d @${tmpfile}
-    [[ $? -eq 0 ]] || fatal "failed to add external NIC"
-
-    # The add_nics job takes about 20 seconds.
-    sleep 30
+        -d @${tmpfile} | sdc-waitforjob
 
     rm -f ${tmpffile}
 }
 
 
 function import_manta_image {
-    local manifest
-    manifest=$(ls -r1 /usbkey/datasets/manta-d*imgmanifest | head -n 1)
-    local file
-    file=$(ls -r1 /usbkey/datasets/manta-d*gz | head -n 1)
-    local uuid
-    uuid=$(json -f ${manifest} uuid)
-
-    echo $(basename ${manifest}) > /usbkey/zones/manta/dataset
-
-    # If image already exists, don't import again.
-    sdc-imgadm get ${uuid} >/dev/null
-    if [[ $? -eq 0 ]]; then
-        return
+    local image_uuid
+    local service_uuid
+    local status
+    local image_manifest
+    local image_file
+
+    image_uuid=$(sdc-sapi /services?name=manta | json -H 0.params.image_uuid)
+    if [[ -z "$image_uuid" ]]; then
+        fatal "the 'manta' SAPI service does not have a params.image_uuid set"
     fi
 
-    sdc-imgadm import -m ${manifest} -f ${file}
-    [[ $? -eq 0 ]] || fatal "failed to import image"
+    service_uuid=$(sdc-sapi /services?name=manta | json -Ha uuid)
+
+    status=$(sdc-imgapi /images/${image_uuid} | head -1 | awk '{print $2}')
+    if [[ "${status}" == "404" ]]; then
+        # IMGAPI doesn't have the image imported. Let's try to get it from
+        # the USB key.
+        # - In the new world, this is at "/usbkey/images/UUID.imgmanifest".
+        image_manifest="/usbkey/images/$image_uuid.imgmanifest"
+        image_file="/usbkey/images/$image_uuid.imgfile"
+
+        # - In the old world, it is at
+        #   "/usbkey/datasets/manta-deployment-*.imgmanifest".
+        if [[ ! -f $image_manifest ]]; then
+            image_manifest=$(ls -r1 \
+                /usbkey/datasets/manta-deployment-*.imgmanifest 2>/dev/null \
+                || true | head -n 1)
+            image_file=$(ls -r1 \
+                /usbkey/datasets/manta-deployment-*.gz 2>/dev/null \
+                || true | head -n 1)
+            if [[ ! -f "$image_manifest" ]]; then
+                fatal "could not find manta-deployment image $image_uuid in" \
+                    "/usbkey/images or /usbkey/datasets"
+            elif [[ "$($JSON -f $image_manifest uuid)" != "$image_uuid" ]]; then
+                fatal "latest /usbkey/datasets/manta-deployment-*" \
+                    "($image_manifest) image is not the same UUID as the SAPI" \
+                    "'manta' service params.image_uuid ($image_uuid)"
+            fi
+        fi
+
+        sdc-imgadm import -m ${image_manifest} -f ${image_file}
+    fi
 }
 
 
@@ -102,15 +126,12 @@ function deploy_manta_zone {
             \"server_uuid\": \"${server_uuid}\"
         }
     }" | sapiadm provision
-
-    [[ $? -eq 0 ]] || fatal "failed to provision manta zone"
 }
 
 
 function enable_firewall {
     local zone_uuid=$1
     vmadm update ${zone_uuid} firewall_enabled=true
-    [[ $? -eq 0 ]] || fatal "failed to enable firewall for the manta zone"
 }
 
 
@@ -214,7 +235,7 @@ EOF
             fi
 
             echo "creating symlink \"$target\" for \"$manpage\""
-            ln -s "$manpage" "$target"
+            ln -fs "$manpage" "$target"
         done
     fi
 }
@@ -222,9 +243,9 @@ EOF
 
 # Mainline
 
-manta_uuid=$(vmadm lookup -1 alias=${ZONE_ALIAS})
+manta_uuid=$(vmadm lookup -1 alias=${ZONE_ALIAS} || true)
 if [[ -n ${manta_uuid} ]]; then
-    echo "Manta zone already present."
+    echo "Manta zone already present: $manta_uuid ($ZONE_ALIAS)"
     copy_manta_tools ${manta_uuid}
     exit
 fi
