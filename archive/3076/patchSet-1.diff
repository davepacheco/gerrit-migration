commit e01adc597e117dc9b36ed8f0a16bb9db0ed1afd6 (refs/changes/76/3076/1)
Author: Jerry Jelinek <jerry.jelinek@joyent.com>
Date:   2017-12-08T20:08:54+00:00 (1 year, 10 months ago)
    
    OS-6484 page invalidation under low memory takes too long

diff --git a/usr/src/uts/common/os/kstat_fr.c b/usr/src/uts/common/os/kstat_fr.c
index 1171376ba5..b09b2d3558 100644
--- a/usr/src/uts/common/os/kstat_fr.c
+++ b/usr/src/uts/common/os/kstat_fr.c
@@ -198,7 +198,9 @@ struct {
 	kstat_named_t pagesfree;
 	kstat_named_t pageslocked;
 	kstat_named_t pagestotal;
+	kstat_named_t lowmemscan;
 	kstat_named_t zonecapscan;
+	kstat_named_t nthrottle;
 } system_pages_kstat = {
 	{ "physmem",		KSTAT_DATA_ULONG },
 	{ "nalloc",		KSTAT_DATA_ULONG },
@@ -220,7 +222,9 @@ struct {
 	{ "pagesfree", 		KSTAT_DATA_ULONG },
 	{ "pageslocked", 	KSTAT_DATA_ULONG },
 	{ "pagestotal",		KSTAT_DATA_ULONG },
+	{ "low_mem_scan",	KSTAT_DATA_ULONG },
 	{ "zone_cap_scan",	KSTAT_DATA_ULONG },
+	{ "n_throttle",		KSTAT_DATA_ULONG },
 };
 
 static int header_kstat_update(kstat_t *, int);
@@ -914,7 +918,9 @@ system_pages_kstat_update(kstat_t *ksp, int rw)
 	system_pages_kstat.pageslocked.value.ul	= (ulong_t)(availrmem_initial -
 	    availrmem);
 	system_pages_kstat.pagestotal.value.ul	= (ulong_t)total_pages;
+	system_pages_kstat.lowmemscan.value.ul	= (ulong_t)low_mem_scan;
 	system_pages_kstat.zonecapscan.value.ul	= (ulong_t)zone_cap_scan;
+	system_pages_kstat.nthrottle.value.ul	= (ulong_t)n_throttle;
 	/*
 	 * pp_kernel represents total pages used by the kernel since the
 	 * startup. This formula takes into account the boottime kernel
diff --git a/usr/src/uts/common/os/mem_config.c b/usr/src/uts/common/os/mem_config.c
index 3571747e9c..6be46fa422 100644
--- a/usr/src/uts/common/os/mem_config.c
+++ b/usr/src/uts/common/os/mem_config.c
@@ -21,6 +21,7 @@
 /*
  * Copyright 2010 Sun Microsystems, Inc.  All rights reserved.
  * Use is subject to license terms.
+ * Copyright 2017 Joyent, Inc.
  */
 
 #include <sys/types.h>
@@ -1638,7 +1639,7 @@ delthr_get_freemem(struct mem_handle *mhp)
 		 * Put pressure on pageout.
 		 */
 		page_needfree(free_get);
-		cv_signal(&proc_pageout->p_cv);
+		WAKE_PAGEOUT_SCANNER();
 
 		mutex_enter(&mhp->mh_mutex);
 		(void) cv_reltimedwait(&mhp->mh_cv, &mhp->mh_mutex,
diff --git a/usr/src/uts/common/os/vm_pageout.c b/usr/src/uts/common/os/vm_pageout.c
index 85fed26b7c..76dfae1a19 100644
--- a/usr/src/uts/common/os/vm_pageout.c
+++ b/usr/src/uts/common/os/vm_pageout.c
@@ -101,8 +101,13 @@ pgcnt_t	deficit;
 pgcnt_t	nscan;
 pgcnt_t	desscan;
 
+/* kstats */
+uint64_t low_mem_scan;
 uint64_t zone_cap_scan;
+uint64_t n_throttle;
+
 clock_t	zone_pageout_ticks;	/* tunable to change zone pagescan ticks */
+uint_t pageout_reset_cnt = 64;	/* tunable for pageout_scanner hand reset */
 
 /*
  * Values for min_pageout_ticks, max_pageout_ticks and pageout_ticks
@@ -137,18 +142,24 @@ clock_t	zone_pageout_ticks;	/* tunable to change zone pagescan ticks */
  *     Computed each time around by schedpaging().
  *     Varies between min_pageout_ticks .. max_pageout_ticks,
  *     depending on memory pressure or zones over their cap.
- *
- * pageout_lbolt:
- *     Timestamp of the last time pageout_scanner woke up and started
- *     (or resumed) scanning for not recently referenced pages.
  */
 
 static clock_t	min_pageout_ticks;
 static clock_t	max_pageout_ticks;
 static clock_t	pageout_ticks;
-static clock_t	pageout_lbolt;
 
-static uint_t	reset_hands;
+#define	MAX_PSCAN_REGIONS	8
+static boolean_t reset_hands[MAX_PSCAN_REGIONS];
+
+/*
+ * Constants for breaking the page "clock" into scan regions.
+ */
+#define	ONE_GB		0x40000000
+#define	PG_64GB		(btop(64LL * ONE_GB))
+
+static uint_t	n_pscan_regions;
+static pgcnt_t	pscan_region_sz;
+
 
 #define	PAGES_POLL_MASK	1023
 
@@ -185,8 +196,6 @@ static pgcnt_t	pageout_sample_pages = 0;
 static hrrate_t	pageout_rate = 0;
 static pgcnt_t	pageout_new_spread = 0;
 
-static clock_t	pageout_cycle_ticks;
-static hrtime_t	sample_start, sample_end;
 static hrtime_t	pageout_sample_etime = 0;
 
 /* True if page scanner is first starting up */
@@ -232,10 +241,12 @@ static boolean_t zones_over = B_FALSE;
 /*
  * Set up the paging constants for the page scanner clock-hand algorithm.
  * Called at startup after the system is initialized and the amount of memory
- * and number of paging devices is known. Called again once PAGE_SCAN_STARTUP
- * is true after the scanner has collected enough samples.
+ * and number of paging devices is known (recalc will be 0). Called again once
+ * PAGE_SCAN_STARTUP is true after the scanner has collected enough samples
+ * (recalc will be 1).
  *
- * Will also be called after a memory dynamic reconfiguration operation.
+ * Will also be called after a memory dynamic reconfiguration operation and
+ * recalc will be 1 in those cases too.
  *
  * lotsfree is 1/64 of memory, but at least 512K (ha!).
  * desfree is 1/2 of lotsfree.
@@ -244,6 +255,8 @@ static boolean_t zones_over = B_FALSE;
 void
 setupclock(int recalc)
 {
+	uint_t i;
+	pgcnt_t sz, tmp;
 
 	static spgcnt_t init_lfree, init_dfree, init_mfree;
 	static spgcnt_t init_tfree, init_preserve, init_mpgio;
@@ -494,29 +507,97 @@ setupclock(int recalc)
 	if (handspreadpages >= looppages)
 		handspreadpages = looppages - 1;
 
+	if (recalc == 0) {
+		/* Setup basic values at initialization */
+		pscan_region_sz = total_pages;
+		n_pscan_regions = 1;
+		reset_hands[0] = B_TRUE;
+		return;
+	}
+
+	/*
+	 * Recalculating
+	 *
+	 * Setup the number of regions (and scanner threads) that we're
+	 * going to break the memory "clock" into. We also want to ensure that
+	 * the regions don't overlap and that they are not touching.
+	 */
+	if (total_pages < PG_64GB) {
+		sz = tmp = total_pages;
+	} else {
+		sz = tmp = PG_64GB;
+	}
+	if (sz < handspreadpages) {
+		/*
+		 * The region is smaller than the seperation between the front
+		 * and back hands; use double handspreadpages.
+		 */
+		sz = tmp = handspreadpages << 1;
+		if (sz > total_pages)
+			sz = total_pages;
+	}
+	pscan_region_sz = sz;
+
+	for (i = 1; tmp < total_pages; i++) {
+		tmp += PG_64GB;
+	}
+
+	/*
+	 * Each thread will have its own entry in the reset_hands array, so we
+	 * don't need any locking in pageout_scanner to check the thread's
+	 * reset_hands entry.
+	 *
+	 * We use a pre-allocated fixed size reset_hands array and upper limit
+	 * on the number of pagescan regions for the following reason.
+	 *
+	 * We create a fixed number of additional scanner threads in
+	 * pageout_scanner itself after we've finished PAGE_SCAN_STARTUP.
+	 * However, once the initial set of scanner threads has been created,
+	 * there could be any number of async pageout_scanner threads running
+	 * (and checking the reset_hands array) while we're making adjustments
+	 * after a DR, and we don't want to serialize those threads on a mutex
+	 * just to check the existence of reset_hands itself.
+	 */
+	if (i > MAX_PSCAN_REGIONS)
+		i = MAX_PSCAN_REGIONS;
+
+	/*
+	 * We setup the number of regions initially (to 1), and then again
+	 * after we've finished PAGE_SCAN_STARTUP, but after that we do not
+	 * change the number of regions again after a DR. Only the region
+	 * size might change. Theoretically the memory size could go down
+	 * (which could cause an issue with the number of scanner threads and
+	 * the region size), but in reality we do not support memory DR removal
+	 * on any machine we care about.
+	 */
+	if (n_pscan_regions == 1)
+		n_pscan_regions = i;
+
 	/*
-	 * If we have been called to recalculate the parameters,
-	 * set a flag to re-evaluate the clock hand pointers.
+	 * Set the flags to re-evaluate the clock hand pointers.
 	 */
-	if (recalc)
-		reset_hands = 1;
+	for (i = 0; i < n_pscan_regions; i++) {
+		reset_hands[i] = B_TRUE;
+	}
 }
 
 /*
  * Pageout scheduling.
  *
  * Schedpaging controls the rate at which the page out daemon runs by
- * setting the global variables nscan and desscan RATETOSCHEDPAGING
- * times a second.  Nscan records the number of pages pageout has examined
- * in its current pass; schedpaging resets this value to zero each time
- * it runs.  Desscan records the number of pages pageout should examine
- * in its next pass; schedpaging sets this value based on the amount of
- * currently available memory.
+ * setting the global variables pageout_ticks and desscan RATETOSCHEDPAGING
+ * times a second. The pageout_ticks variable controls the percent of one
+ * CPU that each page scanner thread should consume (see min_percent_cpu
+ * and max_percent_cpu descriptions). The desscan variable records the number
+ * of pages pageout should examine in its next pass; schedpaging sets this
+ * value based on the amount of currently available memory. In addtition, the
+ * nscan variable records the number of pages pageout has examined in its
+ * current pass; schedpaging resets this value to zero each time it runs.
  */
 
 #define	RATETOSCHEDPAGING	4		/* times/second */
 
-/* held while pageout_scanner or schedpaging running */
+/* held while pageout_scanner or schedpaging are modifying shared data */
 static kmutex_t	pageout_mutex;
 
 /*
@@ -530,7 +611,7 @@ static kcondvar_t push_cv;
 
 static int async_list_size = 256;	/* number of async request structs */
 
-static void pageout_scanner(void);
+static void pageout_scanner(void *);
 
 /*
  * If a page is being shared more than "po_share" times
@@ -559,100 +640,101 @@ schedpaging(void *arg)
 	if (kcage_on && (kcage_freemem < kcage_desfree || kcage_needfree))
 		kcage_cageout_wakeup();
 
-	if (mutex_tryenter(&pageout_mutex)) {
-		/* pageout_scanner() is not currently running */
-		nscan = 0;
-		vavail = freemem - deficit;
-		if (pageout_new_spread != 0)
-			vavail -= needfree;
-		if (vavail < 0)
-			vavail = 0;
-		if (vavail > lotsfree)
-			vavail = lotsfree;
+	(void) atomic_swap_ulong(&nscan, 0);
+	vavail = freemem - deficit;
+	if (pageout_new_spread != 0)
+		vavail -= needfree;
+	if (vavail < 0)
+		vavail = 0;
+	if (vavail > lotsfree)
+		vavail = lotsfree;
 
+	/*
+	 * Fix for 1161438 (CRS SPR# 73922).  All variables
+	 * in the original calculation for desscan were 32 bit signed
+	 * ints.  As freemem approaches 0x0 on a system with 1 Gig or
+	 * more of memory, the calculation can overflow.  When this
+	 * happens, desscan becomes negative and pageout_scanner()
+	 * stops paging out.
+	 */
+	if ((needfree) && (pageout_new_spread == 0)) {
 		/*
-		 * Fix for 1161438 (CRS SPR# 73922).  All variables
-		 * in the original calculation for desscan were 32 bit signed
-		 * ints.  As freemem approaches 0x0 on a system with 1 Gig or
-		 * more of memory, the calculation can overflow.  When this
-		 * happens, desscan becomes negative and pageout_scanner()
-		 * stops paging out.
+		 * If we've not yet collected enough samples to
+		 * calculate a spread, kick into high gear anytime
+		 * needfree is non-zero. Note that desscan will not be
+		 * the limiting factor for systems with larger memory;
+		 * the %CPU will limit the scan. That will also be
+		 * maxed out below.
 		 */
-		if ((needfree) && (pageout_new_spread == 0)) {
-			/*
-			 * If we've not yet collected enough samples to
-			 * calculate a spread, kick into high gear anytime
-			 * needfree is non-zero. Note that desscan will not be
-			 * the limiting factor for systems with larger memory;
-			 * the %CPU will limit the scan. That will also be
-			 * maxed out below.
-			 */
-			desscan = fastscan / RATETOSCHEDPAGING;
-		} else {
-			/*
-			 * Once we've calculated a spread based on system
-			 * memory and usage, just treat needfree as another
-			 * form of deficit.
-			 */
-			spgcnt_t faststmp, slowstmp, result;
-
-			slowstmp = slowscan * vavail;
-			faststmp = fastscan * (lotsfree - vavail);
-			result = (slowstmp + faststmp) /
-			    nz(lotsfree) / RATETOSCHEDPAGING;
-			desscan = (pgcnt_t)result;
-		}
-
+		desscan = fastscan / RATETOSCHEDPAGING;
+	} else {
 		/*
-		 * If we've not yet collected enough samples to calculate a
-		 * spread, also kick %CPU to the max.
+		 * Once we've calculated a spread based on system
+		 * memory and usage, just treat needfree as another
+		 * form of deficit.
 		 */
-		if (pageout_new_spread == 0) {
-			pageout_ticks = max_pageout_ticks;
-		} else {
-			pageout_ticks = min_pageout_ticks +
-			    (lotsfree - vavail) *
-			    (max_pageout_ticks - min_pageout_ticks) /
-			    nz(lotsfree);
-		}
-		zones_over = B_FALSE;
+		spgcnt_t faststmp, slowstmp, result;
 
-		if (freemem < lotsfree + needfree || PAGE_SCAN_STARTUP) {
-			DTRACE_PROBE(schedpage__wake__low);
-			cv_signal(&proc_pageout->p_cv);
+		slowstmp = slowscan * vavail;
+		faststmp = fastscan * (lotsfree - vavail);
+		result = (slowstmp + faststmp) /
+		    nz(lotsfree) / RATETOSCHEDPAGING;
+		desscan = (pgcnt_t)result;
+	}
 
-		} else if (zone_num_over_cap > 0) {
-			/* One or more zones are over their cap. */
+	/*
+	 * If we've not yet collected enough samples to calculate a
+	 * spread, also kick %CPU to the max.
+	 */
+	if (pageout_new_spread == 0) {
+		pageout_ticks = max_pageout_ticks;
+	} else {
+		pageout_ticks = min_pageout_ticks +
+		    (lotsfree - vavail) *
+		    (max_pageout_ticks - min_pageout_ticks) /
+		    nz(lotsfree);
+	}
+	zones_over = B_FALSE;
 
-			/* No page limit */
-			desscan = total_pages;
+	if (freemem < lotsfree + needfree || PAGE_SCAN_STARTUP) {
+		if (!PAGE_SCAN_STARTUP)
+			low_mem_scan++;
+		DTRACE_PROBE(schedpage__wake__low);
+		WAKE_PAGEOUT_SCANNER();
 
-			/*
-			 * Increase the scanning CPU% to the max. This implies
-			 * 80% of one CPU/sec if the scanner can run each
-			 * opportunity. Can also be tuned via setting
-			 * zone_pageout_ticks in /etc/system or with mdb.
-			 */
-			pageout_ticks = (zone_pageout_ticks != 0) ?
-			    zone_pageout_ticks : max_pageout_ticks;
+	} else if (zone_num_over_cap > 0) {
+		/* One or more zones are over their cap. */
 
-			zones_over = B_TRUE;
-			zone_cap_scan++;
+		/* No page limit */
+		desscan = total_pages;
 
-			DTRACE_PROBE(schedpage__wake__zone);
-			cv_signal(&proc_pageout->p_cv);
+		/*
+		 * Increase the scanning CPU% to the max. This implies
+		 * 80% of one CPU/sec if the scanner can run each
+		 * opportunity. Can also be tuned via setting
+		 * zone_pageout_ticks in /etc/system or with mdb.
+		 */
+		pageout_ticks = (zone_pageout_ticks != 0) ?
+		    zone_pageout_ticks : max_pageout_ticks;
 
-		} else {
-			/*
-			 * There are enough free pages, no need to
-			 * kick the scanner thread.  And next time
-			 * around, keep more of the `highly shared'
-			 * pages.
-			 */
-			cv_signal_pageout();
-			if (po_share > MIN_PO_SHARE) {
-				po_share >>= 1;
-			}
+		zones_over = B_TRUE;
+		zone_cap_scan++;
+
+		DTRACE_PROBE(schedpage__wake__zone);
+		WAKE_PAGEOUT_SCANNER();
+
+	} else {
+		/*
+		 * There are enough free pages, no need to
+		 * kick the scanner thread.  And next time
+		 * around, keep more of the `highly shared'
+		 * pages.
+		 */
+		cv_signal_pageout();
+
+		mutex_enter(&pageout_mutex);
+		if (po_share > MIN_PO_SHARE) {
+			po_share >>= 1;
 		}
 		mutex_exit(&pageout_mutex);
 	}
@@ -691,20 +773,27 @@ int dopageout = 1;	/* /etc/system tunable to disable page reclamation */
  * been referenced in the time since the front hand passed. If modified, they
  * are first written to their backing store before being freed.
  *
+ * In order to make page invalidation more responsive on machines with larger
+ * memory, multiple pageout_scanner threads may be created. In this case, the
+ * threads are evenly distributed around the the memory "clock face" so that
+ * memory can be reclaimed more quickly (that is, there can be large regions in
+ * which no pages can be reclaimed by a single thread, leading to lag which
+ * causes undesirable behavior such as htable stealing).
+ *
  * As long as there are at least lotsfree pages, or no zones over their cap,
- * then this process is not run. When the scanner is running for case (a),
- * all pages are considered for pageout. For case (b), only pages belonging to
- * a zone over its cap will be considered for pageout.
+ * then pageout_scanner threads are not run. When pageout_scanner threads are
+ * running for case (a), all pages are considered for pageout. For case (b),
+ * only pages belonging to a zone over its cap will be considered for pageout.
  *
- * There are 2 threads that act on behalf of the pageout process.
- * One thread scans pages (pageout_scanner) and frees them up if
+ * There are multiple threads that act on behalf of the pageout process.
+ * A set of threads scans pages (pageout_scanner) and frees them up if
  * they don't require any VOP_PUTPAGE operation. If a page must be
  * written back to its backing store, the request is put on a list
  * and the other (pageout) thread is signaled. The pageout thread
  * grabs VOP_PUTPAGE requests from the list, and processes them.
  * Some filesystems may require resources for the VOP_PUTPAGE
  * operations (like memory) and hence can block the pageout
- * thread, but the scanner thread can still operate. There is still
+ * thread, but the pageout_scanner threads can still operate. There is still
  * no guarantee that memory deadlocks cannot occur.
  *
  * The pageout_scanner parameters are determined in schedpaging().
@@ -745,9 +834,9 @@ pageout()
 
 	pageout_pri = curthread->t_pri;
 
-	/* Create the pageout scanner thread. */
-	(void) lwp_kernel_create(proc_pageout, pageout_scanner, NULL, TS_RUN,
-	    pageout_pri - 1);
+	/* Create the (first) pageout scanner thread. */
+	(void) lwp_kernel_create(proc_pageout, pageout_scanner, (void *) 0,
+	    TS_RUN, pageout_pri - 1);
 
 	/*
 	 * kick off pageout scheduler.
@@ -802,32 +891,24 @@ pageout()
  * Kernel thread that scans pages looking for ones to free
  */
 static void
-pageout_scanner(void)
+pageout_scanner(void *a)
 {
 	struct page *fronthand, *backhand;
-	uint_t count;
+	uint_t count, iter = 0;
 	callb_cpr_t cprinfo;
-	pgcnt_t	nscan_limit;
+	pgcnt_t	nscan_cnt, nscan_limit;
 	pgcnt_t	pcount;
+	uint_t inst = (uint_t)(uintptr_t)a;
+	hrtime_t sample_start, sample_end;
+	clock_t pageout_lbolt;
+	kmutex_t pscan_mutex;
 
-	CALLB_CPR_INIT(&cprinfo, &pageout_mutex, callb_generic_cpr, "poscan");
-	mutex_enter(&pageout_mutex);
+	VERIFY(inst < MAX_PSCAN_REGIONS);
 
-	/*
-	 * The restart case does not attempt to point the hands at roughly
-	 * the right point on the assumption that after one circuit things
-	 * will have settled down - and restarts shouldn't be that often.
-	 */
+	mutex_init(&pscan_mutex, NULL, MUTEX_DEFAULT, NULL);
 
-	/*
-	 * Set the two clock hands to be separated by a reasonable amount,
-	 * but no more than 360 degrees apart.
-	 */
-	backhand = page_first();
-	if (handspreadpages >= total_pages)
-		fronthand = page_nextn(backhand, total_pages - 1);
-	else
-		fronthand = page_nextn(backhand, handspreadpages);
+	CALLB_CPR_INIT(&cprinfo, &pscan_mutex, callb_generic_cpr, "poscan");
+	mutex_enter(&pscan_mutex);
 
 	min_pageout_ticks = MAX(1,
 	    ((hz * min_percent_cpu) / 100) / RATETOSCHEDPAGING);
@@ -838,22 +919,44 @@ loop:
 	cv_signal_pageout();
 
 	CALLB_CPR_SAFE_BEGIN(&cprinfo);
-	cv_wait(&proc_pageout->p_cv, &pageout_mutex);
-	CALLB_CPR_SAFE_END(&cprinfo, &pageout_mutex);
+	cv_wait(&proc_pageout->p_cv, &pscan_mutex);
+	CALLB_CPR_SAFE_END(&cprinfo, &pscan_mutex);
 
 	if (!dopageout)
 		goto loop;
 
-	if (reset_hands) {
-		reset_hands = 0;
+	if (reset_hands[inst]) {
+		struct page *first;
+		pgcnt_t offset = total_pages / n_pscan_regions;
+
+		reset_hands[inst] = B_FALSE;
 
-		backhand = page_first();
-		if (handspreadpages >= total_pages)
+		/*
+		 * The restart case does not attempt to point the hands at
+		 * roughly at their original resumption point on the assumption
+		 * that after one circuit things will have settled down - and
+		 * restarts shouldn't be that often.
+		 *
+		 * Set the two clock hands to be separated by a reasonable
+		 * amount, but no more than 360 degrees apart.
+		 *
+		 * If inst == 0, backhand starts at first page, otherwise
+		 * it is (inst * offset) around the memory "clock face" so that
+		 * we spread out each scanner instance evenly.
+		 */
+		first = page_first();
+		backhand = page_nextn(first, offset * inst);
+		if (handspreadpages >= total_pages) {
 			fronthand = page_nextn(backhand, total_pages - 1);
-		else
+		} else {
 			fronthand = page_nextn(backhand, handspreadpages);
+		}
 	}
 
+	/*
+	 * This CPU kstat is only incremented here and we're obviously on this
+	 * CPU, so no lock.
+	 */
 	CPU_STATS_ADDQ(CPU, vm, pgrrun, 1);
 	count = 0;
 
@@ -862,13 +965,15 @@ loop:
 	    tnf_ulong, pages_free, freemem, tnf_ulong, pages_needed, needfree);
 
 	pcount = 0;
+	nscan_cnt = 0;
 	if (PAGE_SCAN_STARTUP) {
 		nscan_limit = total_pages;
 	} else {
 		nscan_limit = desscan;
 	}
 
-	DTRACE_PROBE1(pageout__start, pgcnt_t, nscan_limit);
+	DTRACE_PROBE4(pageout__start, pgcnt_t, nscan_limit, uint_t, inst,
+	    page_t *, backhand, page_t *, fronthand);
 
 	pageout_lbolt = ddi_get_lbolt();
 	sample_start = gethrtime();
@@ -880,13 +985,13 @@ loop:
 	 * 2) there is not enough free memory
 	 * 3) during page scan startup when determining sample data
 	 */
-	while (nscan < nscan_limit &&
+	while (nscan_cnt < nscan_limit &&
 	    (zones_over ||
 	    freemem < lotsfree + needfree ||
 	    PAGE_SCAN_STARTUP)) {
 		int rvfront, rvback;
 
-		DTRACE_PROBE1(pageout__loop, pgcnt_t, pcount);
+		DTRACE_PROBE2(pageout__loop, pgcnt_t, pcount, uint_t, inst);
 
 		/*
 		 * Check to see if we have exceeded our %CPU budget
@@ -894,6 +999,8 @@ loop:
 		 * just every once in a while.
 		 */
 		if ((pcount & PAGES_POLL_MASK) == PAGES_POLL_MASK) {
+			clock_t pageout_cycle_ticks;
+
 			pageout_cycle_ticks = ddi_get_lbolt() - pageout_lbolt;
 			if (pageout_cycle_ticks >= pageout_ticks) {
 				/*
@@ -901,9 +1008,9 @@ loop:
 				 * loop when scanning zones or sampling.
 				 */
 				if (!zones_over) {
-					++pageout_timeouts;
+					atomic_inc_64(&pageout_timeouts);
 				}
-				DTRACE_PROBE(pageout__timeout);
+				DTRACE_PROBE1(pageout__timeout, uint_t, inst);
 				break;
 			}
 		}
@@ -920,7 +1027,8 @@ loop:
 		++pcount;
 
 		/*
-		 * protected by pageout_mutex instead of cpu_stat_lock
+		 * This CPU kstat is only incremented here and we're obviously
+		 * on this CPU, so no lock.
 		 */
 		CPU_STATS_ADDQ(CPU, vm, scan, 1);
 
@@ -928,7 +1036,7 @@ loop:
 		 * Don't include ineligible pages in the number scanned.
 		 */
 		if (rvfront != -1 || rvback != -1)
-			nscan++;
+			nscan_cnt++;
 
 		backhand = page_next(backhand);
 
@@ -938,10 +1046,18 @@ loop:
 		 */
 
 		if ((fronthand = page_next(fronthand)) == page_first())	{
-			DTRACE_PROBE(pageout__wrap__front);
+			DTRACE_PROBE1(pageout__wrap__front, uint_t, inst);
 
 			/*
-			 * protected by pageout_mutex instead of cpu_stat_lock
+			 * Every 64 wraps we reposition our hands within our
+			 * region to prevent creep into another thread.
+			 */
+			if ((++iter % pageout_reset_cnt) == 0)
+				reset_hands[inst] = B_TRUE;
+
+			/*
+			 * This CPU kstat is only incremented here and we're
+			 * obviously on this CPU, so no lock.
 			 */
 			CPU_STATS_ADDQ(CPU, vm, rev, 1);
 
@@ -962,46 +1078,72 @@ loop:
 				 * pages, skip fewer of them.  Otherwise,
 				 * give up till the next clock tick.
 				 */
+				mutex_enter(&pageout_mutex);
 				if (po_share < MAX_PO_SHARE) {
 					po_share <<= 1;
+					mutex_exit(&pageout_mutex);
 				} else {
 					/*
 					 * Really a "goto loop", but if someone
 					 * is tracing or TNF_PROBE_ing, hit
 					 * those probes first.
 					 */
+					mutex_exit(&pageout_mutex);
 					break;
 				}
 			}
 		}
 	}
 
+	atomic_add_long(&nscan, nscan_cnt);
+
 	sample_end = gethrtime();
 
-	DTRACE_PROBE2(pageout__loop__end, pgcnt_t, pcount, uint_t, count);
+	DTRACE_PROBE3(pageout__loop__end, pgcnt_t, nscan_cnt, pgcnt_t, pcount,
+	    uint_t, inst);
 
 	/* Kernel probe */
 	TNF_PROBE_2(pageout_scan_end, "vm pagedaemon", /* CSTYLED */,
-	    tnf_ulong, pages_scanned, nscan, tnf_ulong, pages_free, freemem);
+	    tnf_ulong, pages_scanned, nscan_cnt, tnf_ulong, pages_free,
+	    freemem);
 
 	/*
 	 * The following two blocks are only relevant when the scanner is
 	 * first started up. After the scanner runs for a while, neither of
 	 * the conditions will ever be true again.
+	 *
+	 * The global variables used below are only modified by this thread and
+	 * only during initial scanning when there is a single page scanner
+	 * thread running. Thus, we don't use any locking.
 	 */
 	if (PAGE_SCAN_STARTUP) {
+		VERIFY(inst == 0);
 		pageout_sample_pages += pcount;
 		pageout_sample_etime += sample_end - sample_start;
 		++pageout_sample_cnt;
 
 	} else if (pageout_new_spread == 0) {
+		uint_t i;
+
 		/*
 		 * We have run enough samples, set the spread.
 		 */
+		VERIFY(inst == 0);
 		pageout_rate = (hrrate_t)pageout_sample_pages *
 		    (hrrate_t)(NANOSEC) / pageout_sample_etime;
 		pageout_new_spread = pageout_rate / 10;
 		setupclock(1);
+
+		/*
+		 * Create any additional necessary pageout scanner threads.
+		 * The first thread was already started in pageout() at startup
+		 * and has now completed initializing the various pageout_*
+		 * globals.
+		 */
+		for (i = 1; i < n_pscan_regions; i++) {
+			(void) lwp_kernel_create(proc_pageout, pageout_scanner,
+			    (void *)(uintptr_t)i, TS_RUN, curthread->t_pri);
+		}
 	}
 
 	goto loop;
diff --git a/usr/src/uts/common/sys/vm.h b/usr/src/uts/common/sys/vm.h
index a8ca2ad377..0f7dfa9fd0 100644
--- a/usr/src/uts/common/sys/vm.h
+++ b/usr/src/uts/common/sys/vm.h
@@ -20,6 +20,7 @@
  */
 /*
  * Copyright (c) 1983, 2010, Oracle and/or its affiliates. All rights reserved.
+ * Copyright 2017 Joyent, Inc.
  */
 
 /*	Copyright (c) 1983, 1984, 1985, 1986, 1987, 1988, 1989 AT&T	*/
@@ -57,6 +58,8 @@ int	queue_io_request(struct vnode *, u_offset_t);
 extern	kmutex_t	memavail_lock;
 extern	kcondvar_t	memavail_cv;
 
+#define	WAKE_PAGEOUT_SCANNER()	cv_broadcast(&proc_pageout->p_cv)
+
 #endif	/* defined(_KERNEL) */
 
 #ifdef	__cplusplus
diff --git a/usr/src/uts/common/sys/vmsystm.h b/usr/src/uts/common/sys/vmsystm.h
index 3f908e01fc..2292310bda 100644
--- a/usr/src/uts/common/sys/vmsystm.h
+++ b/usr/src/uts/common/sys/vmsystm.h
@@ -61,7 +61,9 @@ extern pgcnt_t	desscan;	/* desired pages scanned per second */
 extern pgcnt_t	slowscan;
 extern pgcnt_t	fastscan;
 extern pgcnt_t	pushes;		/* number of pages pushed to swap device */
-extern uint64_t	zone_cap_scan;	/* num times page scan due to zone cap */;
+extern uint64_t	low_mem_scan;	/* num times page scan due to low memory */
+extern uint64_t	zone_cap_scan;	/* num times page scan due to zone cap */
+extern uint64_t	n_throttle;	/* num times page create throttled */
 
 /* writable copies of tunables */
 extern pgcnt_t	maxpgio;	/* max paging i/o per sec before start swaps */
diff --git a/usr/src/uts/common/vm/vm_page.c b/usr/src/uts/common/vm/vm_page.c
index 78d1cb1a58..f8c5d8f6d9 100644
--- a/usr/src/uts/common/vm/vm_page.c
+++ b/usr/src/uts/common/vm/vm_page.c
@@ -22,6 +22,7 @@
  * Copyright (c) 1986, 2010, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2015, Josef 'Jeff' Sipek <jeffpc@josefsipek.net>
  * Copyright (c) 2015, 2016 by Delphix. All rights reserved.
+ * Copyright 2017 Joyent, Inc.
  */
 
 /*	Copyright (c) 1983, 1984, 1985, 1986, 1987, 1988, 1989  AT&T	*/
@@ -1460,6 +1461,8 @@ page_create_throttle(pgcnt_t npages, int flags)
 	uint_t	i;
 	pgcnt_t tf;	/* effective value of throttlefree */
 
+	atomic_inc_64(&n_throttle);
+
 	/*
 	 * Normal priority allocations.
 	 */
@@ -1492,7 +1495,7 @@ page_create_throttle(pgcnt_t npages, int flags)
 	tf = throttlefree -
 	    ((flags & PG_PUSHPAGE) ? pageout_reserve : 0);
 
-	cv_signal(&proc_pageout->p_cv);
+	WAKE_PAGEOUT_SCANNER();
 
 	for (;;) {
 		fm = 0;
@@ -1579,7 +1582,7 @@ checkagain:
 	}
 
 	ASSERT(proc_pageout != NULL);
-	cv_signal(&proc_pageout->p_cv);
+	WAKE_PAGEOUT_SCANNER();
 
 	TRACE_2(TR_FAC_VM, TR_PAGE_CREATE_SLEEP_START,
 	    "page_create_sleep_start: freemem %ld needfree %ld",
@@ -2226,7 +2229,7 @@ page_create_va_large(vnode_t *vp, u_offset_t off, size_t bytes, uint_t flags,
 	if (nscan < desscan && freemem < minfree) {
 		TRACE_1(TR_FAC_VM, TR_PAGEOUT_CV_SIGNAL,
 		    "pageout_cv_signal:freemem %ld", freemem);
-		cv_signal(&proc_pageout->p_cv);
+		WAKE_PAGEOUT_SCANNER();
 	}
 
 	pp = rootpp;
@@ -2355,7 +2358,7 @@ page_create_va(vnode_t *vp, u_offset_t off, size_t bytes, uint_t flags,
 	if (nscan < desscan && freemem < minfree) {
 		TRACE_1(TR_FAC_VM, TR_PAGEOUT_CV_SIGNAL,
 		    "pageout_cv_signal:freemem %ld", freemem);
-		cv_signal(&proc_pageout->p_cv);
+		WAKE_PAGEOUT_SCANNER();
 	}
 
 	/*
diff --git a/usr/src/uts/i86pc/vm/vm_machdep.c b/usr/src/uts/i86pc/vm/vm_machdep.c
index 152a717ad0..ac01006aa4 100644
--- a/usr/src/uts/i86pc/vm/vm_machdep.c
+++ b/usr/src/uts/i86pc/vm/vm_machdep.c
@@ -3495,7 +3495,7 @@ page_create_io(
 	if (nscan < desscan && freemem < minfree) {
 		TRACE_1(TR_FAC_VM, TR_PAGEOUT_CV_SIGNAL,
 		    "pageout_cv_signal:freemem %ld", freemem);
-		cv_signal(&proc_pageout->p_cv);
+		WAKE_PAGEOUT_SCANNER();
 	}
 
 	if (flags & PG_PHYSCONTIG) {
