commit c143b0cc3bdfa66bcdc634953e3d4dcc331f9cf2 (refs/changes/12/5212/2)
Author: Mohamed Khalfella <mohamed.khalfella@joyent.com>
Date:   2018-12-10T18:01:25+00:00 (10 months ago)
    
    MANTA-4019 Want the storage job to process moray dumps in parallel and compress intermediate objects

diff --git a/assets/bin/storage-map b/assets/bin/storage-map
index eecdc4c..7da2553 100755
--- a/assets/bin/storage-map
+++ b/assets/bin/storage-map
@@ -1,11 +1,9 @@
 #!/bin/bash
-# Copyright (c) 2013, Joyent, Inc. All rights reserved.
+# Copyright (c) 2018, Joyent, Inc. All rights reserved.
 
 set -o pipefail
 
 dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 NODE=$dir/../build/node/bin/node
 
-$ZCAT \
-| $NODE $dir/../lib/storage-map.js \
-| msplit -j -n $NUM_REDUCERS -f owner,type,objectId
+$ZCAT | $NODE $dir/../lib/storage-map.js -n $NUM_REDUCERS
diff --git a/assets/bin/storage-reduce1 b/assets/bin/storage-reduce1
index 51076a7..e146a8a 100755
--- a/assets/bin/storage-reduce1
+++ b/assets/bin/storage-reduce1
@@ -1,30 +1,10 @@
 #!/bin/bash
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright 2017 Joyent, Inc.
-#
+# Copyright (c) 2018, Joyent, Inc. All rights reserved.
 
 set -o pipefail
 
 dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 NODE=$dir/../build/node/bin/node
 
-#
-# This phase of the job constructs a large in-memory object aggregating all of
-# the input data.  For very large input sizes, this object can exhaust the
-# default node heap limit.  We increase the "old space" cap to allow for the
-# aggregation of a larger quantity of objects per reducer process.
-#
-# Note that this is something of a stop-gap: a 32-bit node process likely
-# cannot continue to be grown much, if at all, beyond this size.  In the
-# future, the aggregation of input records should be tracked using a mechanism
-# that can easily spill to disk; e.g., by using a SQLite or other disk-based
-# database.
-#
-$NODE --max_old_space_size=1300 $dir/../lib/storage-reduce1.js \
-| msplit -j -n $NUM_REDUCERS -f owner,namespace
+$ZCAT \
+| $NODE $dir/../lib/storage-reduce1.js -n $NUM_REDUCERS -s owner,type,objectId
diff --git a/assets/bin/storage-reduce2 b/assets/bin/storage-reduce2
index c566039..d9892e8 100755
--- a/assets/bin/storage-reduce2
+++ b/assets/bin/storage-reduce2
@@ -1,10 +1,31 @@
 #!/bin/bash
-# Copyright (c) 2013, Joyent, Inc. All rights reserved.
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright 2018 Joyent, Inc.
+#
 
 set -o pipefail
 
 dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 NODE=$dir/../build/node/bin/node
 
-$NODE $dir/../lib/sum-columns.js \
-| msplit -j -n $NUM_REDUCERS -f owner
+#
+# This phase of the job constructs a large in-memory object aggregating all of
+# the input data.  For very large input sizes, this object can exhaust the
+# default node heap limit.  We increase the "old space" cap to allow for the
+# aggregation of a larger quantity of objects per reducer process.
+#
+# Note that this is something of a stop-gap: a 32-bit node process likely
+# cannot continue to be grown much, if at all, beyond this size.  In the
+# future, the aggregation of input records should be tracked using a mechanism
+# that can easily spill to disk; e.g., by using a SQLite or other disk-based
+# database.
+#
+$ZCAT \
+|$NODE --max_old_space_size=1300 $dir/../lib/storage-reduce2.js \
+| msplit -j -n $NUM_REDUCERS -f owner,namespace
diff --git a/assets/bin/storage-reduce3 b/assets/bin/storage-reduce3
index 7ba991f..c566039 100755
--- a/assets/bin/storage-reduce3
+++ b/assets/bin/storage-reduce3
@@ -6,4 +6,5 @@ set -o pipefail
 dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 NODE=$dir/../build/node/bin/node
 
-$NODE $dir/../lib/storage-reduce3.js | $NODE $dir/../lib/deliver-usage.js
+$NODE $dir/../lib/sum-columns.js \
+| msplit -j -n $NUM_REDUCERS -f owner
diff --git a/assets/bin/storage-reduce4 b/assets/bin/storage-reduce4
new file mode 100755
index 0000000..1885739
--- /dev/null
+++ b/assets/bin/storage-reduce4
@@ -0,0 +1,9 @@
+#!/bin/bash
+# Copyright (c) 2013, Joyent, Inc. All rights reserved.
+
+set -o pipefail
+
+dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
+NODE=$dir/../build/node/bin/node
+
+$NODE $dir/../lib/storage-reduce4.js | $NODE $dir/../lib/deliver-usage.js
diff --git a/assets/lib/muploader.js b/assets/lib/muploader.js
new file mode 100644
index 0000000..4bd6c41
--- /dev/null
+++ b/assets/lib/muploader.js
@@ -0,0 +1,148 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+
+
+/*
+ * The number of concurrent upstream connections should be less than the maximum
+ * number that Manta allows from a single task before queueing them.  This is
+ * part of Marlin's configuration, but it's not exposed to user tasks, so we
+ * hardcode the default number here.  A better approach would be to have the
+ * server issue a 429 "Too Many Requests" response (instead of queueing them)
+ * and have the client back off when this happens.
+ */
+var msConcurrency = 25;
+
+/*
+ * Configure maxSockets based on our desired concurrency.  We have to do this
+ * here, before pulling in "restify-clients" (via "manta"), because
+ * "restify-clients" reads these from the top-level.
+ */
+var http = require('http');
+http.globalAgent.maxSockets = msConcurrency;
+
+var manta = require('manta');
+var vasync = require('vasync');
+var retry = require('retry');
+var path = require('path');
+var fs = require('fs');
+
+function MUploader(log) {
+        this._log = log;
+}
+
+function createMantaDirectory(client, dir, cb) {
+        client.mkdirp(dir, function (err) {
+                if (err && err.name != 'DirectoryExistsError') {
+                        cb(err);
+                }
+                cb();
+        });
+}
+
+function doUploadReducerStream(args, cb) {
+        var options = {
+                size: args.size,
+                headers:  {
+                        'x-manta-stream': 'stdout',
+                        'x-manta-reducer': args.idx
+                }
+        };
+
+        var client = args.client;
+        var objectName = args.objectName;
+        var istream = args.istream;
+
+        client.put(objectName, istream, options, function (err) {
+                cb(err);
+        });
+}
+
+function doUploadReducerFile(args, cb) {
+        var client = args.client;
+        var dir = path.dirname(args.objectName);
+        var fileName = args.fileName;
+
+        createMantaDirectory(client, dir, function (er) {
+                if (er) {
+                        cb(er);
+                        return;
+                }
+
+                fs.stat(fileName, function (err, stat) {
+                        if (err) {
+                                cb(err);
+                                return;
+                        }
+                        args.size = stat.size;
+                        var istream = fs.createReadStream(fileName);
+
+                        istream.on('error', function (error) {
+                                cb(error);
+                        });
+                        istream.on('open', function () {
+                                args.istream = istream;
+                                doUploadReducerStream(args, cb);
+                        });
+                });
+        });
+}
+
+function uploadReducerFile(args, cb) {
+
+        var operation = retry.operation({
+                'retries': 2,
+                'factor': 2,
+                'minTimeout': 1000,
+                'maxTimeout': 3000
+        });
+
+        operation.attempt(function (_currentAttempt) {
+                doUploadReducerFile(args, function (err) {
+                        if (operation.retry(err)) {
+                                return;
+                        }
+                        cb(err ? operation.mainError() : null);
+                });
+        });
+}
+
+MUploader.prototype.uploadReducerFiles = function (fileNames, objectNames, cb) {
+        var client = manta.createBinClient({
+                'log': this._log
+        });
+
+        var queue = vasync.queuev({
+            'concurrency': msConcurrency,
+            'worker': function (args, qcb) {
+                uploadReducerFile(args, function (err) {
+                        if (err) {
+                                cb(err);
+                                queue.kill();
+                                return;
+                        }
+                        qcb();
+                });
+            }
+        });
+
+        fileNames.forEach(function (fileName, idx) {
+                queue.push({
+                        idx: idx,
+                        fileName: fileName,
+                        objectName: objectNames[idx],
+                        client: client
+                });
+        });
+
+        queue.drain = cb;
+};
+
+module.exports = MUploader;
diff --git a/assets/lib/storage-map.js b/assets/lib/storage-map.js
old mode 100755
new mode 100644
index e501af8..f8fc2df
--- a/assets/lib/storage-map.js
+++ b/assets/lib/storage-map.js
@@ -1,4 +1,3 @@
-#!/usr/node/bin/node
 /*
  * This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
@@ -6,105 +5,145 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
-var mod_carrier = require('carrier');
-var lookupPath = process.env['LOOKUP_FILE'] || '../etc/lookup.json';
-var lookup = require(lookupPath); // maps uuid->login
-var ERROR = false;
-var COUNT_UNAPPROVED_USERS = process.env['COUNT_UNAPPROVED_USERS'] === 'true';
-
-var LOG = require('bunyan').createLogger({
-        name: 'storage-map.js',
-        stream: process.stderr,
-        level: process.env['LOG_LEVEL'] || 'info'
-});
-
-function validSchema(obj) {
-        var fields =
-                ['key', 'owner', 'type'];
-        for (var i = 0; i < fields.length; i++) {
-                if (!obj[fields[i]]) {
-                        return (false);
-                }
-        }
-        return (true);
+var bunyan = require('bunyan');
+var es = require('event-stream');
+var uuid = require('node-uuid');
+var path = require('path');
+var getopt = require('posix-getopt');
+var stream = require('stream');
+
+var ZSplitter = require('./zsplitter');
+var MUploader = require('./muploader');
+
+var process_line;
+
+// Writes the line to the next reducer
+function processLine(zs, line, nReducers, cb) {
+        zs.writeToReducer(line, zs.cur++, cb);
+        zs.cur %= nReducers;
 }
 
+// Writes the first line to all the reducers. We do so because the first
+// line contains a header information the next phase expects to find.
+function processFirstLine(zs, line, nReducers, cb) {
 
-function main() {
-        var carry = mod_carrier.carry(process.openStdin());
-        var index;
-        var lineCount = 0;
-
-        function onLine(line) {
-                lineCount++;
-                try {
-                        var record = JSON.parse(line);
-                } catch (e) {
-                        LOG.error(e, 'Error on line ' + lineCount);
-                        ERROR = true;
-                        return;
-                }
+        process_line = processLine;
 
-                if (!record.entry || !record.entry[index]) {
-                        LOG.error(line, 'unrecognized line ' + lineCount);
-                        ERROR = true;
-                        return;
-                }
+        var r = 0;
+        es.readArray(zs.getFileNames())
+            .pipe(es.map(function (_fileName, callback) {
+                        zs.writeToReducer(line, r++, callback);
+                })).on('end', cb);
+}
 
-                try {
-                        var value = JSON.parse(record.entry[index]);
-                        if (!validSchema(value)) {
-                                LOG.error(line, 'invalid line ' + lineCount);
-                                ERROR = true;
-                                return;
-                        }
-                } catch (e) {
-                        LOG.error(e, 'Error on line ' + lineCount);
-                        ERROR = true;
+function processStdin(zs, nReducers) {
+        var r = 0;
+
+        // We use this transform stream to apply backpressure.
+        var transform = new stream.Transform({ objectMode: true });
+        process_line = processFirstLine;
+
+        transform._transform = function (chunk, encoding, done) {
+                process_line(zs, chunk + '\n', nReducers, done);
+        };
+
+        transform._flush = function (done) {
+                // When done, end all the reducer streams.
+                es.readArray(zs.getFileNames())
+                    .pipe(es.map(function (_fileName, callback) {
+                                zs.end(r++, callback);
+                        })).on('end', done);
+        };
+
+        process.stdin.pipe(es.split()).pipe(transform);
+}
+
+
+function fatal(message)
+{
+        console.error('storage-map: ' + message);
+        process.exit(1);
+}
+
+function uploadFiles(mu, fileNames, objectNames) {
+        mu.uploadReducerFiles(fileNames, objectNames, function (err) {
+                if (err) {
+                        fatal('Error uploading the files' + err.toString());
                         return;
                 }
+                process.exit(0); //done.
+        });
+}
 
-                if (!COUNT_UNAPPROVED_USERS) {
-                        if (!lookup[value.owner]) {
-                                LOG.error(record, 'No login found for UUID ' +
-                                        value.owner);
-                                ERROR = true;
-                                return;
+function main() {
+        var parser;
+        var option;
+
+        var opts = {};
+        opts.dryRun = false;
+        opts.nReducers = 0;
+
+
+        parser = new getopt.BasicParser('dn:', process.argv);
+
+        while ((option = parser.getopt()) !== undefined) {
+                switch (option.option) {
+                case 'd':
+                        opts.dryRun = true;
+                        break;
+                case 'n':
+                        opts.nReducers = parseInt(option.optarg, 10);
+                        if (isNaN(opts.nReducers) || opts.nReducers < 1) {
+                                fatal('invalid number of reducers ' +
+                                    option.optarg);
                         }
+                        break;
 
-                        if (!lookup[value.owner].approved) {
-                                LOG.warn(record, value.owner +
-                                        ' not approved for provisioning. ' +
-                                        'Skipping...');
-                                return;
-                        }
+                default:
+                        /* error message already emitted by getopt */
+                        fatal('Invalid option');
+                        break;
                 }
+        }
 
-                console.log(JSON.stringify(value));
+        if (!opts.nReducers) {
+                fatal('number of reducers must be specified.');
         }
 
-        carry.once('line', function firstLine(line) {
-                lineCount++;
-                try {
-                        index = JSON.parse(line).keys.indexOf('_value');
-                } catch (e) {
-                        LOG.fatal(e, line, 'error parsing schema');
-                        ERROR = true;
-                        return;
-                }
-                carry.on('line', onLine);
-        });
+        if (!process.env['MANTA_OUTPUT_BASE']) {
+                fatal('MANTA_OUTPUT_BASE not set');
+        }
 
-}
 
-if (require.main === module) {
+        var objectPrefix = process.env['MANTA_OUTPUT_BASE'] + uuid.v4() + '.';
+        var n;
+        var objectNames = [];
+        for (n = 0; n < opts.nReducers; n++) {
+                objectNames.push(objectPrefix + n);
+        }
 
-        process.on('exit', function onExit() {
-                process.exit(ERROR);
+        var log = new bunyan({ 'name': 'storage-map',
+            'level': 'fatal',
+            'stream': process.stderr
         });
 
-        main();
+        var zs = new ZSplitter('/var/tmp', opts.nReducers,
+            {gzip: true, log: log});
+        var mu = new MUploader(log);
+
+        zs.cur = 0;
+
+        zs.on('open', processStdin.bind(zs, zs, opts.nReducers));
+        zs.on('error', function (err) {
+                fatal(err.toString());
+        });
+        zs.on('close', function () {
+                if (!opts.dryRun)
+                        uploadFiles(mu, zs.getFileNames(), objectNames);
+        });
 }
+
+main();
diff --git a/assets/lib/storage-reduce1.js b/assets/lib/storage-reduce1.js
old mode 100755
new mode 100644
index 3a521e3..9204fa4
--- a/assets/lib/storage-reduce1.js
+++ b/assets/lib/storage-reduce1.js
@@ -6,231 +6,223 @@
  */
 
 /*
- * Copyright (c) 2014, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
-/* BEGIN JSSTYLED */
-/*
- * sample object record:
- * {
- *   "dirname": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/logs/postgresql/2012/11/12/18",
- *   "key": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/logs/postgresql/2012/11/12/18/49366a2c.log.bz2",
- *   "headers": {},
- *   "mtime": 1352746869592,
- *   "owner": "cc56f978-00a7-4908-8d20-9580a3f60a6e",
- *   "type": "object",
- *   "contentLength": 84939,
- *   "contentMD5": "iSdRMW7Irsw1UwYoRDFmIA==",
- *   "contentType": "application/x-bzip2",
- *   "etag": "5fcc0345-1044-4b67-b7e8-98ee692001bc",
- *   "objectId": "5fcc0345-1044-4b67-b7e8-98ee692001bc",
- *   "sharks": [
- *     {
- *       "availableMB": 20477,
- *       "percentUsed": 1,
- *       "datacenter": "bh1-kvm1",
- *       "server_uuid": "44454c4c-4700-1034-804a-c7c04f354d31",
- *       "zone_uuid": "ef8b166a-ac3e-4d59-bb73-a65e2b17ba44",
- *       "url": "http://ef8b166a-ac3e-4d59-bb73-a65e2b17ba44.stor.bh1-kvm1.joyent.us"
- *     },
- *     {
- *       "availableMB": 20477,
- *       "percentUsed": 1,
- *       "datacenter": "bh1-kvm1",
- *       "server_uuid": "44454c4c-4700-1034-804a-c7c04f354d31",
- *       "zone_uuid": "59fb8bd3-67a7-4da2-bb68-287e2db01ec1",
- *       "url": "http://59fb8bd3-67a7-4da2-bb68-287e2db01ec1.stor.bh1-kvm1.joyent.us"
- *     }
- *   ]
- * }
- */
-
-/*
- * sample directory record:
- * {
- *   "dirname": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/manatee_backups/1.moray.bh1-kvm1.joyent.us",
- *   "key": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/manatee_backups/1.moray.bh1-kvm1.joyent.us/2012-11-13-02-00-03",
- *   "headers": {},
- *   "mtime": 1352772004269,
- *   "owner": "cc56f978-00a7-4908-8d20-9580a3f60a6e",
- *   "type": "directory"
- * }
- */
+var stream = require('stream');
+var getopt = require('posix-getopt');
+var es = require('event-stream');
+var uuid = require('node-uuid');
 
-/*
- * aggr format:
- * {
- *      owner: {
- *              "dirs": {
- *                      namespace: 0,
- *                      ...
- *              },
- *              "objects": {
- *                      objectId: {
- *                              namespace: 0, // count of # keys in this
- *                                            // namespace for this objectId
- *                              ...
- *                              _size: 0
- *                      },
- *                      ...
- *              }
- *      },
- *      ...
- * }
- */
-
-/*
- * output format:
- * {
- *      "owner": owner,
- *      "namespace": namespace,
- *      "directories": directories,
- *      "keys": keys,
- *      "objects": objects,
- *      "bytes": bytes
- * }
- */
+var ZSplitter = require('./zsplitter');
+var MUploader = require('./muploader');
 
-/* END JSSTYLED */
+var lookupPath = process.env['LOOKUP_FILE'] || '../etc/lookup.json';
+var lookup = require(lookupPath); // maps uuid->login
+var COUNT_UNAPPROVED_USERS = process.env['COUNT_UNAPPROVED_USERS'] === 'true';
 
-var mod_carrier = require('carrier');
-var Big = require('big.js');
-var ERROR = false;
-var MIN_SIZE = +process.env['MIN_SIZE'] || 131072;
-
-var LOG = require('bunyan').createLogger({
+var log = require('bunyan').createLogger({
         name: 'storage-reduce1.js',
         stream: process.stderr,
         level: process.env['LOG_LEVEL'] || 'info'
 });
 
-var NAMESPACES = (process.env.NAMESPACES).split(' ');
 
-function count(record, aggr) {
-        var owner = record.owner;
-        var type = record.type;
-        var namespace;
+var index;
+var lineCount = 0;
+var process_line;
+
+function validSchema(obj) {
+        var fields = ['key', 'owner', 'type'];
+
+        for (var i = 0; i < fields.length; i++) {
+                if (!obj[fields[i]]) {
+                        return (false);
+                }
+        }
+        return (true);
+}
+
+function fatal(message)
+{
+        console.error('storage-reduce1: ' + message);
+        process.exit(1);
+}
+
+function processLine(zs, line, opts, cb) {
+        lineCount++;
         try {
-                namespace = record.key.split('/')[2]; // /:uuid/:namespace/...
+                var record = JSON.parse(line);
         } catch (e) {
-                LOG.error(e, 'error getting namespace: ' + record.key);
-                ERROR = true;
+                fatal('Error on line: ' + lineCount);
+        }
+
+        if (record.name === 'manta' && Array.isArray(record.keys)) {
+                /* This is a header record. It is safe to skip it */
+                cb();
                 return;
         }
 
-        aggr[owner] = aggr[owner] || {
-                dirs: {},
-                objects: {}
-        };
+        if (!record.entry || !record.entry[index]) {
+                fatal('Unrecognized line: ' + lineCount);
+        }
 
-        aggr[owner].dirs[namespace] = aggr[owner].dirs[namespace] || 0;
-
-        if (type === 'directory') {
-                aggr[owner].dirs[namespace]++;
-        } else if (type === 'object') {
-                var index = aggr[owner].objects;
-                var n;
-                try {
-                        var objectId = record.objectId;
-                        var size = Math.max(record.contentLength, MIN_SIZE) *
-                            record.sharks.length;
-                } catch (e) {
-                        console.warn(e);
-                        return;
+        try {
+                var value = JSON.parse(record.entry[index]);
+                if (!validSchema(value)) {
+                        fatal('Invalid line: ' + lineCount);
                 }
+        } catch (e) {
+                fatal('Error on line: ' + lineCount);
+        }
 
-                if (!index[objectId]) {
-                        index[objectId] = {};
-                        for (n in NAMESPACES) {
-                                index[objectId][NAMESPACES[n]] = 0;
-                        }
+        if (!COUNT_UNAPPROVED_USERS) {
+                if (!lookup[value.owner]) {
+                        fatal('No login found for UUID: ' + value.owner);
                 }
 
-                index[objectId][namespace]++;
-                index[objectId]._size = size;
-        } else {
-                LOG.error(record, 'unrecognized object type: ' + type);
-                ERROR = true;
+                if (!lookup[value.owner].approved) {
+                        log.warn(record, value.owner +
+                            ' not approved for provisioning. ' +
+                            'Skipping...');
+                                cb();
+                                return;
+                }
         }
-}
 
-function printResults(aggr) {
-        var n, dirs;
-        Object.keys(aggr).forEach(function (owner) {
-                var keys = {};
-                var bytes = {};
-                var objects = {};
-
-                for (n in NAMESPACES) {
-                        keys[NAMESPACES[n]] = 0;
-                        bytes[NAMESPACES[n]] = new Big(0);
-                        objects[NAMESPACES[n]] = 0;
-                }
+        if (opts.stdout) {
+                console.log(JSON.stringify(value));
+                cb();
+                return;
+        }
 
-                Object.keys(aggr[owner].objects).forEach(function (object) {
-                        var counted = false;
-                        var objCounts = aggr[owner].objects[object];
-                        for (n in NAMESPACES) {
-                                if (!counted && objCounts[NAMESPACES[n]] > 0) {
-                                        counted = true;
-                                        var size = objCounts._size;
-                                        bytes[NAMESPACES[n]] =
-                                                bytes[NAMESPACES[n]].plus(size);
-                                        objects[NAMESPACES[n]]++;
-                                }
-                                keys[NAMESPACES[n]] += objCounts[NAMESPACES[n]];
-                        }
-                });
-
-                for (n in NAMESPACES) {
-                        dirs = aggr[owner].dirs[NAMESPACES[n]] || 0;
-                        console.log(JSON.stringify({
-                                owner: owner,
-                                namespace: NAMESPACES[n],
-                                directories: dirs,
-                                keys: keys[NAMESPACES[n]],
-                                objects: objects[NAMESPACES[n]],
-                                bytes: bytes[NAMESPACES[n]].toString()
-                        }));
-                }
+        var splitKey = '';
+        opts.splitKeys.forEach(function (key) {
+                splitKey = splitKey + value[key];
         });
+
+        zs.write(JSON.stringify(value) + '\n', splitKey, cb);
 }
 
+function processFirstLine(zs, line, opts, cb) {
 
-function main() {
-        var carry = mod_carrier.carry(process.openStdin());
-
-        var aggr = {};
-        var lineCount = 0;
-        carry.on('line', function onLine(line) {
-                lineCount++;
-                try {
-                        var record = JSON.parse(line);
-                } catch (e) {
-                        LOG.error(e, 'Error on line ' + lineCount);
-                        ERROR = true;
-                        return;
-                }
+        process_line = processLine;
+        lineCount++;
+        try {
+                index = JSON.parse(line).keys.indexOf('_value');
+        } catch (e) {
+                fatal('Error parsing schema');
+        }
+        cb();
+}
+
+function processStdin(zs, opts) {
 
-                if (!record.owner || !record.type) {
-                        LOG.error(line, 'Missing owner or type field on line ' +
-                                lineCount);
-                        ERROR = true;
+        var transform = new stream.Transform({ objectMode: true });
+        process_line = processFirstLine;
+
+        transform._transform = function (chunk, encoding, done) {
+                // Skip empty lines
+                if (chunk.length === 0) {
+                        done();
                         return;
                 }
+                process_line(zs, chunk + '\n', opts, done);
+        };
 
-                count(record, aggr);
-        });
+        var r = 0;
+        transform._flush = function (done) {
+                es.readArray(zs.getFileNames())
+                    .pipe(es.map(function (_fileName, callback) {
+                        zs.end(r++, callback);
+                })).on('end', done);
+        };
 
-        carry.on('end', function onEnd() {
-                printResults(aggr);
+        process.stdin.pipe(es.split()).pipe(transform);
+}
+
+function uploadFiles(mu, fileNames, objectNames) {
+        mu.uploadReducerFiles(fileNames, objectNames, function (err) {
+                if (err) {
+                        fatal('Error uploading the files' + err.toString());
+                        return;
+                }
+                process.exit(0);
         });
 }
 
-if (require.main === module) {
-        process.on('exit', function onExit() {
-                process.exit(ERROR);
+function main() {
+
+        var opts = {
+                stdout: false,
+                nReducers: 0,
+                splitKeys: ['']
+        };
+
+        var parser = new getopt.BasicParser('cn:s:', process.argv);
+
+        var option;
+        while ((option = parser.getopt()) !== undefined) {
+                switch (option.option) {
+                case 'c':
+                        opts.stdout = true;
+                        break;
+                case 'n':
+                        opts.nReducers = parseInt(option.optarg, 10);
+                        if (isNaN(opts.nReducers) || opts.nReducers < 1) {
+                                fatal('invalid number of reducers ' +
+                                    option.optarg);
+                        }
+                        break;
+                case 's':
+                        opts.splitKeys = option.optarg.split(',');
+                        break;
+                default:
+                        fatal('Invalid option: ' + option.option);
+                        break;
+                }
+        }
+
+        if (!opts.nReducers && !opts.stdout) {
+                fatal('Either output to stdout of number' +
+                    ' of reducers need to be specified');
+        }
+
+        if (!process.env['MANTA_OUTPUT_BASE'] && !opts.stdout) {
+                fatal('Either output to stdout or MANTA_OUTPUT_BASE ' +
+                    'Needs to be set');
+
+        }
+
+        if (opts.nReducers > 1 && opts.splitKeys.length == 1 &&
+            opts.splitKeys[0] === '') {
+                fatal('Please specifiy one of more split keys when ' +
+                    'the number of reducers is more than one');
+        }
+
+        var zs = new ZSplitter('/var/tmp', opts.nReducers,
+            {gzip: true, log: log});
+
+        zs.cur = 0;
+        zs.on('open', processStdin.bind(zs, zs, opts));
+        zs.on('error', function (err) {
+                fatal(err.toString());
         });
 
-        main();
+        zs.on('close', function () {
+                if (!opts.stdout) {
+                        var n;
+                        var mu = new MUploader(log);
+                        var objectPrefix = process.env['MANTA_OUTPUT_BASE'] +
+                            uuid.v4() + '.';
+                        var objectNames = [];
+                        for (n = 0; n < opts.nReducers; n++) {
+                                objectNames.push(objectPrefix + n);
+                        }
+
+                        uploadFiles(mu, zs.getFileNames(), objectNames);
+                }
+        });
 }
+
+main();
diff --git a/assets/lib/storage-reduce2.js b/assets/lib/storage-reduce2.js
new file mode 100755
index 0000000..3a521e3
--- /dev/null
+++ b/assets/lib/storage-reduce2.js
@@ -0,0 +1,236 @@
+#!/usr/node/bin/node
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2014, Joyent, Inc.
+ */
+
+/* BEGIN JSSTYLED */
+/*
+ * sample object record:
+ * {
+ *   "dirname": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/logs/postgresql/2012/11/12/18",
+ *   "key": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/logs/postgresql/2012/11/12/18/49366a2c.log.bz2",
+ *   "headers": {},
+ *   "mtime": 1352746869592,
+ *   "owner": "cc56f978-00a7-4908-8d20-9580a3f60a6e",
+ *   "type": "object",
+ *   "contentLength": 84939,
+ *   "contentMD5": "iSdRMW7Irsw1UwYoRDFmIA==",
+ *   "contentType": "application/x-bzip2",
+ *   "etag": "5fcc0345-1044-4b67-b7e8-98ee692001bc",
+ *   "objectId": "5fcc0345-1044-4b67-b7e8-98ee692001bc",
+ *   "sharks": [
+ *     {
+ *       "availableMB": 20477,
+ *       "percentUsed": 1,
+ *       "datacenter": "bh1-kvm1",
+ *       "server_uuid": "44454c4c-4700-1034-804a-c7c04f354d31",
+ *       "zone_uuid": "ef8b166a-ac3e-4d59-bb73-a65e2b17ba44",
+ *       "url": "http://ef8b166a-ac3e-4d59-bb73-a65e2b17ba44.stor.bh1-kvm1.joyent.us"
+ *     },
+ *     {
+ *       "availableMB": 20477,
+ *       "percentUsed": 1,
+ *       "datacenter": "bh1-kvm1",
+ *       "server_uuid": "44454c4c-4700-1034-804a-c7c04f354d31",
+ *       "zone_uuid": "59fb8bd3-67a7-4da2-bb68-287e2db01ec1",
+ *       "url": "http://59fb8bd3-67a7-4da2-bb68-287e2db01ec1.stor.bh1-kvm1.joyent.us"
+ *     }
+ *   ]
+ * }
+ */
+
+/*
+ * sample directory record:
+ * {
+ *   "dirname": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/manatee_backups/1.moray.bh1-kvm1.joyent.us",
+ *   "key": "/cc56f978-00a7-4908-8d20-9580a3f60a6e/stor/manatee_backups/1.moray.bh1-kvm1.joyent.us/2012-11-13-02-00-03",
+ *   "headers": {},
+ *   "mtime": 1352772004269,
+ *   "owner": "cc56f978-00a7-4908-8d20-9580a3f60a6e",
+ *   "type": "directory"
+ * }
+ */
+
+/*
+ * aggr format:
+ * {
+ *      owner: {
+ *              "dirs": {
+ *                      namespace: 0,
+ *                      ...
+ *              },
+ *              "objects": {
+ *                      objectId: {
+ *                              namespace: 0, // count of # keys in this
+ *                                            // namespace for this objectId
+ *                              ...
+ *                              _size: 0
+ *                      },
+ *                      ...
+ *              }
+ *      },
+ *      ...
+ * }
+ */
+
+/*
+ * output format:
+ * {
+ *      "owner": owner,
+ *      "namespace": namespace,
+ *      "directories": directories,
+ *      "keys": keys,
+ *      "objects": objects,
+ *      "bytes": bytes
+ * }
+ */
+
+/* END JSSTYLED */
+
+var mod_carrier = require('carrier');
+var Big = require('big.js');
+var ERROR = false;
+var MIN_SIZE = +process.env['MIN_SIZE'] || 131072;
+
+var LOG = require('bunyan').createLogger({
+        name: 'storage-reduce1.js',
+        stream: process.stderr,
+        level: process.env['LOG_LEVEL'] || 'info'
+});
+
+var NAMESPACES = (process.env.NAMESPACES).split(' ');
+
+function count(record, aggr) {
+        var owner = record.owner;
+        var type = record.type;
+        var namespace;
+        try {
+                namespace = record.key.split('/')[2]; // /:uuid/:namespace/...
+        } catch (e) {
+                LOG.error(e, 'error getting namespace: ' + record.key);
+                ERROR = true;
+                return;
+        }
+
+        aggr[owner] = aggr[owner] || {
+                dirs: {},
+                objects: {}
+        };
+
+        aggr[owner].dirs[namespace] = aggr[owner].dirs[namespace] || 0;
+
+        if (type === 'directory') {
+                aggr[owner].dirs[namespace]++;
+        } else if (type === 'object') {
+                var index = aggr[owner].objects;
+                var n;
+                try {
+                        var objectId = record.objectId;
+                        var size = Math.max(record.contentLength, MIN_SIZE) *
+                            record.sharks.length;
+                } catch (e) {
+                        console.warn(e);
+                        return;
+                }
+
+                if (!index[objectId]) {
+                        index[objectId] = {};
+                        for (n in NAMESPACES) {
+                                index[objectId][NAMESPACES[n]] = 0;
+                        }
+                }
+
+                index[objectId][namespace]++;
+                index[objectId]._size = size;
+        } else {
+                LOG.error(record, 'unrecognized object type: ' + type);
+                ERROR = true;
+        }
+}
+
+function printResults(aggr) {
+        var n, dirs;
+        Object.keys(aggr).forEach(function (owner) {
+                var keys = {};
+                var bytes = {};
+                var objects = {};
+
+                for (n in NAMESPACES) {
+                        keys[NAMESPACES[n]] = 0;
+                        bytes[NAMESPACES[n]] = new Big(0);
+                        objects[NAMESPACES[n]] = 0;
+                }
+
+                Object.keys(aggr[owner].objects).forEach(function (object) {
+                        var counted = false;
+                        var objCounts = aggr[owner].objects[object];
+                        for (n in NAMESPACES) {
+                                if (!counted && objCounts[NAMESPACES[n]] > 0) {
+                                        counted = true;
+                                        var size = objCounts._size;
+                                        bytes[NAMESPACES[n]] =
+                                                bytes[NAMESPACES[n]].plus(size);
+                                        objects[NAMESPACES[n]]++;
+                                }
+                                keys[NAMESPACES[n]] += objCounts[NAMESPACES[n]];
+                        }
+                });
+
+                for (n in NAMESPACES) {
+                        dirs = aggr[owner].dirs[NAMESPACES[n]] || 0;
+                        console.log(JSON.stringify({
+                                owner: owner,
+                                namespace: NAMESPACES[n],
+                                directories: dirs,
+                                keys: keys[NAMESPACES[n]],
+                                objects: objects[NAMESPACES[n]],
+                                bytes: bytes[NAMESPACES[n]].toString()
+                        }));
+                }
+        });
+}
+
+
+function main() {
+        var carry = mod_carrier.carry(process.openStdin());
+
+        var aggr = {};
+        var lineCount = 0;
+        carry.on('line', function onLine(line) {
+                lineCount++;
+                try {
+                        var record = JSON.parse(line);
+                } catch (e) {
+                        LOG.error(e, 'Error on line ' + lineCount);
+                        ERROR = true;
+                        return;
+                }
+
+                if (!record.owner || !record.type) {
+                        LOG.error(line, 'Missing owner or type field on line ' +
+                                lineCount);
+                        ERROR = true;
+                        return;
+                }
+
+                count(record, aggr);
+        });
+
+        carry.on('end', function onEnd() {
+                printResults(aggr);
+        });
+}
+
+if (require.main === module) {
+        process.on('exit', function onExit() {
+                process.exit(ERROR);
+        });
+
+        main();
+}
diff --git a/assets/lib/storage-reduce3.js b/assets/lib/storage-reduce4.js
similarity index 100%
rename from assets/lib/storage-reduce3.js
rename to assets/lib/storage-reduce4.js
diff --git a/assets/lib/zsplitter.js b/assets/lib/zsplitter.js
new file mode 100644
index 0000000..16c9e1b
--- /dev/null
+++ b/assets/lib/zsplitter.js
@@ -0,0 +1,187 @@
+#!/usr/node/bin/node
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ */
+
+var assert = require('assert-plus');
+var crypto = require('crypto');
+var fs = require('fs');
+var util = require('util');
+var EventEmitter = require('events').EventEmitter;
+var zlib = require('zlib');
+
+var MAX_BUFFER_SIZE = 128 * 1024; //128 KB
+
+function ZSplitter(dir, nFiles, opts) {
+        assert.string(dir, 'dir');
+        assert.number(nFiles, 'nFiles');
+        assert.object(opts, 'opts');
+        assert.object(opts.log, 'opts.log');
+        assert.optionalBool(opts.gzip, 'opts.gzip');
+
+        this._nFiles = nFiles;
+        this._gzip = (opts.gzip === true);
+
+        //Check the number of files to be a positive integer.
+        if (nFiles <= 0 || nFiles % 1 != 0) {
+                opts.log.error('Invalid number of files: ' + nFiles);
+                return;
+        }
+
+        var stat;
+        if (!(stat = fs.statSync(dir)) || !stat.isDirectory()) {
+                opts.log.error('Invalid output directory path: ' + dir);
+                return;
+        }
+
+        //Emit all errors we get from gzip and file streams
+        var onError = function (err) {
+                this.emit('error', err);
+        }.bind(this);
+
+        var n;
+        this._fileNames = [];           //Temorary fileNames
+        this._fileStreams = [];         // FileStreams
+        this._fileOutStreams = [];      // Gzip or fileStreams
+
+        this._nReadyStreams = 0;
+        this._nClosedStreams = 0;
+
+        for (n = 0; n < nFiles; n++) {
+                var fileName = dir + '/part' + n;
+                var fileStream = fs.createWriteStream(fileName);
+                fileStream.on('error', onError);
+
+                fileStream.on('open', function () {
+                        // Emit 'open' when all the underlying
+                        // files are open. This tells the user
+                        // We are ready to receive writes.
+                        if (++this._nReadyStreams == nFiles) {
+                                this.emit('open');
+                        }
+                }.bind(this));
+
+                fileStream.on('close', function () {
+                        // Emit close when all the outputfiles
+                        // are closed. Only then, the user can
+                        // use the split files.
+                        if (++this._nClosedStreams == nFiles) {
+                                this.emit('close');
+                        }
+                }.bind(this));
+
+                var fileOutStream = fileStream;
+
+                // If compression is enabled, create a Gzip stream
+                // and pipe it into the fileStream.
+                if (this._gzip) {
+                        fileOutStream = zlib.createGzip();
+                        fileOutStream.on('error', onError);
+                        fileOutStream.pipe(fileStream);
+                }
+
+                fileOutStream.idx = n;
+                fileOutStream.buffer = '';
+                fileOutStream.bufferLength = 0;
+
+                this._fileNames.push(fileName);
+                this._fileStreams.push(fileStream);
+                this._fileOutStreams.push(fileOutStream);
+        }
+}
+
+util.inherits(ZSplitter, EventEmitter);
+
+// Writes 'data' to a reducer based on 'splitKey' hash value.
+ZSplitter.prototype.write = function (data, splitKey, cb) {
+        assert.string(data);
+        assert.string(splitKey);
+        assert.func(cb);
+
+        var digest = crypto.createHash('md5').update(splitKey).digest('hex');
+        var fileNumber = parseInt(digest.substr(0, 8), 16) % this._nFiles;
+
+        this.writeToReducer(data, fileNumber, cb);
+};
+
+// Writes 'data' to the reducer specified by 'fileNumber'
+ZSplitter.prototype.writeToReducer = function (data, fileNumber, cb) {
+        assert.string(data);
+        assert.number(fileNumber);
+        assert.func(cb);
+
+        if (fileNumber >= this._nFiles) {
+                cb(new Error('fileNumber is out of range: ' + fileNumber));
+                return;
+        }
+
+        var out = this._fileOutStreams[fileNumber];
+
+        // Buffer the data if there is a room for it.
+        if (out.bufferLength < MAX_BUFFER_SIZE) {
+                out.buffer += data;
+                out.bufferLength += data.length;
+                cb();
+                return;
+        }
+
+        // If there is no room to buffer the data
+        // and the stream is ready to receive writes,
+        // then write both the buffer content and the
+        // new data.
+        if (out.writable) {
+                out.write(out.buffer + data);
+                out.buffer = '';
+                out.bufferLength = 0;
+                cb();
+                return;
+        }
+
+        // Otherwise, wait for the stream to drain
+        // before writing the all the data;
+        out.once('drain', function () {
+                out.write(out.buffer + data);
+                out.buffer = '';
+                out.bufferLength = 0;
+                cb();
+        });
+};
+
+
+ZSplitter.prototype.end = function (fileNumber, cb) {
+        assert.number(fileNumber);
+        assert.func(cb);
+
+        if (fileNumber >= this._nFiles) {
+                cb(new Error('fileNumber is out of range:' + fileNumber));
+                return;
+        }
+
+        var out = this._fileOutStreams[fileNumber];
+
+        if (out.bufferLength > 0) {
+                if (out.writable) {
+                        out.end(out.buffer);
+                        return;
+                }
+
+                out.once('drain', function () {
+                        out.end(out.buffer);
+                });
+        }
+        out.end();
+        cb();
+};
+
+// XXX: Should retrun a copy of the array?
+ZSplitter.prototype.getFileNames = function () {
+        return (this._fileNames);
+};
+
+module.exports = ZSplitter;
diff --git a/package.json b/package.json
index 8cc2e00..dd483ea 100644
--- a/package.json
+++ b/package.json
@@ -11,16 +11,19 @@
                 "backoff": "1.2.0",
                 "bunyan": "0.21.1",
                 "carrier": "0.1.10",
+                "event-stream": "4.0.1",
                 "ipaddr.js": "0.1.1",
                 "jsprim": "0.5.0",
-                "libmanta": "git+ssh://git@github.com:joyent/node-libmanta.git#master",
-                "marlin": "git+ssh://git@github.com:joyent/manta-marlin.git#master",
-                "manta": "git+ssh://git@github.com:joyent/node-manta.git#master",
-                "manta-compute-bin": "git+ssh://git@github.com:joyent/manta-compute-bin.git#master",
+                "libmanta": "git+https://github.com/joyent/node-libmanta.git#master",
+                "marlin": "git+https://github.com/joyent/manta-marlin.git#master",
+                "manta": "git+https://github.com/joyent/node-manta.git#master",
+                "manta-compute-bin": "git+https://github.com/joyent/manta-compute-bin.git#master",
                 "once": "1.1.1",
                 "readable-stream": "0.3.1",
                 "posix-getopt": "1.0.0",
+                "retry": "0.12.0",
                 "screener": "0.0.5",
+                "node-uuid": "1.4.8",
                 "vasync": "1.3.3"
         },
         "devDependencies": {
diff --git a/zsplitter.js b/zsplitter.js
new file mode 100644
index 0000000..3dbdf70
--- /dev/null
+++ b/zsplitter.js
@@ -0,0 +1,144 @@
+var assert = require('assert-plus');
+var fs = require('fs');
+var util = require('util');
+var EventEmitter = require('events').EventEmitter;
+var zlib = require('zlib');
+
+var MAX_BUFFER_SIZE = 128 * 1024;
+
+function ZSplitter(dir, nFiles, opts) {
+	assert.string(dir, 'dir');
+	assert.number(nFiles, 'nFiles');
+	assert.object(opts, 'opts');
+	assert.object(opts.log, 'opts.log');
+	assert.optionalBool(opts.gzip, 'opts.gzip');
+
+	this._nFiles = nFiles;
+	this._gzip = (opts.gzip == true);
+
+	if (nFiles <= 0 || nFiles % 1 != 0) {
+		opts.log.error('Invalid number of files: ' + nFiles);
+		return (null);
+	}
+
+	var stat;
+	if (!(stat = fs.statSync(dir)) || !stat.isDirectory()) {
+		opts.log.error('Invalid output directory path: ' + dir);
+		return null;
+	}
+
+	var onError = function(err) {
+		this.emit('error', err);
+	}.bind(this);
+
+	var n;
+	this._fileNames = [];
+	this._fileStreams = [];
+	this._fileOutStreams = [];
+
+	this._nReadyStreams = 0;
+	this._nClosedStreams = 0;
+
+	for (n = 0; n < nFiles; n++) {
+		var fileName = dir + '/part' + n;
+		var fileStream = fs.createWriteStream(fileName);
+		fileStream.on('error', onError);
+
+		fileStream.on('open', function() {
+			if (++this._nReadyStreams == nFiles) {
+				this.emit('open');
+			}
+		}.bind(this));
+
+		fileStream.on('close', function() {
+			if(++this._nClosedStreams == nFiles) {
+				this.emit('close');
+			}
+		}.bind(this));
+
+		var fileOutStream = fileStream;
+
+		if (this._gzip) {
+			fileOutStream = zlib.createGzip();
+			fileOutStream.on('error', onError);
+			fileOutStream.pipe(fileStream);
+		}
+
+		fileOutStream.idx = n;
+		fileOutStream.buffer = '';
+		fileOutStream.bufferLength = 0;
+
+		this._fileNames.push(fileName);
+		this._fileStreams.push(fileStream);
+		this._fileOutStreams.push(fileOutStream);
+	}
+}
+
+util.inherits(ZSplitter, EventEmitter);
+
+ZSplitter.prototype.write = function(data, fileNumber, cb) {
+	assert.string(data);
+	assert.number(fileNumber);
+	assert.func(cb);
+
+	if (fileNumber >= this._nFiles) {
+		cb(new Error('fileNumber is out of range: ' + fileNumber));
+		return;
+	}
+	var out = this._fileOutStreams[fileNumber];
+
+	if (out.bufferLength < MAX_BUFFER_SIZE) {
+		out.buffer += data;
+		out.bufferLength += data.length;
+		cb();
+		return;
+	}
+
+	if (out.writable) {
+		out.write(out.buffer + data);
+		out.buffer = '';
+		out.bufferLength = 0;
+		cb();
+		return;
+	}
+
+	out.once('drain', function() {
+		out.write(out.buffer + data);
+		out.buffer = '';
+		out.bufferLength = 0;
+		cb();
+	});
+};
+
+
+ZSplitter.prototype.end = function(fileNumber, cb) {
+	assert.number(fileNumber);
+	assert.func(cb);
+
+	// @TODO: Return an error
+	if (fileNumber >= this._nFiles) {
+		cb(new Error('fileNumber is out of range:' + fileNumber));
+		return;
+	}
+
+	var out = this._fileOutStreams[fileNumber];
+
+	if (out.bufferLength > 0) {
+		if (out.writable) {
+			out.end(out.buffer);
+			return;
+		}
+
+		out.once('drain', function() {
+			out.end(out.buffer);
+		});
+	}
+
+	cb();
+};
+
+ZSplitter.prototype.getFileNames = function() {
+	return this._fileNames;
+};
+
+module.exports = ZSplitter;
