From 09786209c63a36ac44c6cfb3648400914e4babe7 Mon Sep 17 00:00:00 2001
From: Jerry Jelinek <jerry.jelinek@joyent.com>
Date: Mon, 20 Mar 2017 17:12:41 +0000
Subject: [PATCH] OS-5873 Need NFS client lockd support: fcntl F_SETLK returns
 ENOLCK in LX zone

---
 manifest                                      |    1 +
 usr/src/lib/brand/lx/Makefile                 |    4 +-
 .../lib/brand/lx/lx_brand/common/mount_nfs.c  |   65 +-
 usr/src/lib/brand/lx/lx_lockd/Makefile        |   58 +
 usr/src/lib/brand/lx/lx_lockd/lockd.c         |  551 ++++++
 usr/src/lib/brand/lx/lx_lockd/nfs_tbind.c     | 1721 +++++++++++++++++
 usr/src/lib/brand/lx/zone/platform.xml        |    1 +
 7 files changed, 2396 insertions(+), 5 deletions(-)
 create mode 100644 usr/src/lib/brand/lx/lx_lockd/Makefile
 create mode 100644 usr/src/lib/brand/lx/lx_lockd/lockd.c
 create mode 100644 usr/src/lib/brand/lx/lx_lockd/nfs_tbind.c

diff --git a/manifest b/manifest
index d305358150..8c19996873 100644
--- a/manifest
+++ b/manifest
@@ -5087,6 +5087,7 @@ f usr/lib/brand/lx/lx_boot_zone_busybox 0755 root root
 f usr/lib/brand/lx/lx_boot_zone_ubuntu 0755 root root
 f usr/lib/brand/lx/lxinit 0755 root root
 f usr/lib/brand/lx/lx_librtld_db.so.1 0755 root root
+f usr/lib/brand/lx/lx_lockd 0755 root root
 f usr/lib/brand/lx/lx_support 0755 root root
 f usr/lib/brand/lx/lx_vdso.so.1 0755 root root
 f usr/lib/brand/lx/platform.xml 0444 root root
diff --git a/usr/src/lib/brand/lx/Makefile b/usr/src/lib/brand/lx/Makefile
index 7e01b43dba..bdf0c9f441 100644
--- a/usr/src/lib/brand/lx/Makefile
+++ b/usr/src/lib/brand/lx/Makefile
@@ -22,7 +22,7 @@
 #
 # Copyright 2006 Sun Microsystems, Inc.  All rights reserved.
 # Use is subject to license terms.
-# Copyright 2016 Joyent, Inc.
+# Copyright 2017 Joyent, Inc.
 #
 
 default: all
@@ -32,7 +32,7 @@ include Makefile.lx
 # Build everything in parallel; use .WAIT for dependencies
 .PARALLEL:
 
-SUBDIRS=	librtld_db lx_support lx_init lx_brand netfiles \
+SUBDIRS=	librtld_db lx_support lx_init lx_lockd lx_brand netfiles \
 		zone lx_vdso testing .WAIT
 MSGSUBDIRS=	lx_brand lx_support zone
 
diff --git a/usr/src/lib/brand/lx/lx_brand/common/mount_nfs.c b/usr/src/lib/brand/lx/lx_brand/common/mount_nfs.c
index 6c50482628..0483791057 100644
--- a/usr/src/lib/brand/lx/lx_brand/common/mount_nfs.c
+++ b/usr/src/lib/brand/lx/lx_brand/common/mount_nfs.c
@@ -238,6 +238,7 @@ typedef struct nfs_mnt_data {
 	char		*nmd_fstype;
 	seconfig_t	nmd_nfs_sec;
 	int		nmd_sec_opt;	/* any security option ? */
+	int		nmd_nolock_opt;	/* 'nolock' specified */
 	rpcvers_t	nmd_mnt_vers;
 	rpcvers_t	nmd_nfsvers;
 } nfs_mnt_data_t;
@@ -753,6 +754,53 @@ badopt:
 	return (-EINVAL);
 }
 
+/*
+ * Make a simple effort to determine if lockd is already running. If it doesn't
+ * appear to be, try to start one. lockd itself will ensure that there is only
+ * one instance running and it should remain running for the life of the zone.
+ */
+static void
+start_lockd()
+{
+	int fd;
+
+	if ((fd = open("/native/tmp/lxlockd", O_RDONLY)) != -1) {
+		int len, pid;
+		char buf[80];
+
+		len = read(fd, buf, sizeof (buf));
+		(void) close(fd);
+
+		if (len >= 0) {
+			buf[len] = '\0';
+
+			/* Simple check that lockd is still there */
+			if (convert_int(&pid, buf) == 0) {
+				struct stat sb;
+
+				(void) snprintf(buf, sizeof (buf), "/proc/%d",
+				    pid);
+				if (stat(buf, &sb) == 0)
+					return;
+			}
+		}
+	}
+
+	/*
+	 * We actually need to start a lockd. We don't fail the mount if the
+	 * fork/exec fails for some reason, since most apps never use locking
+	 * over NFS.
+	 */
+	if (fork() == 0) {
+		/* child */
+		(void) execl("/native/usr/lib/brand/lx/lx_lockd", "lx_lockd",
+		    NULL);
+		exit(1);
+	}
+
+	/* parent/error */
+}
+
 static int
 make_secure(struct nfs_args *args, nfs_mnt_data_t *nmdp)
 {
@@ -1233,7 +1281,7 @@ get_nfs_kv(char *vs, char **kp, char **vp)
  *	mountvers=3,mountproto=tcp,mountport=63484
  */
 static int
-convert_nfs_arg_str(char *srcp, char *mntopts)
+convert_nfs_arg_str(char *srcp, char *mntopts, nfs_mnt_data_t *nmdp)
 {
 	char *key, *val, *p;
 	char tmpbuf[MAX_MNTOPT_STR];
@@ -1310,6 +1358,13 @@ convert_nfs_arg_str(char *srcp, char *mntopts)
 				if (r != 0)
 					return (r);
 				no_sec = B_FALSE;
+			} else if (strcmp(key, "nolock") == 0) {
+				int r;
+				nmdp->nmd_nolock_opt = 1;
+				r = append_opt(mntopts, MAX_MNTOPT_STR, key,
+				    val);
+				if (r != 0)
+					return (r);
 			} else {
 				int r;
 
@@ -1378,7 +1433,7 @@ lx_nfs_mount(char *srcp, char *mntp, char *fst, int lx_flags, char *opts)
 	 * looked up. This also converts the opts string so that we'll be
 	 * dealing with illumos options after this.
 	 */
-	if ((r = convert_nfs_arg_str(srcp, opts)) < 0) {
+	if ((r = convert_nfs_arg_str(srcp, opts, nmdp)) < 0) {
 		return (r);
 	}
 
@@ -1460,8 +1515,12 @@ lx_nfs_mount(char *srcp, char *mntp, char *fst, int lx_flags, char *opts)
 
 	r = mount(srcp, mntp, il_flags, nmdp->nmd_fstype, argp, sizeof (*argp),
 	    opts, MAX_MNTOPT_STR);
-	if (r != 0)
+	if (r != 0) {
 		r = -errno;
+	} else if (nmdp->nmd_nolock_opt == 0) {
+		start_lockd();
+	}
+
 out:
 	if (nconf != NULL)
 		freenetconfigent(nconf);
diff --git a/usr/src/lib/brand/lx/lx_lockd/Makefile b/usr/src/lib/brand/lx/lx_lockd/Makefile
new file mode 100644
index 0000000000..f448107e6b
--- /dev/null
+++ b/usr/src/lib/brand/lx/lx_lockd/Makefile
@@ -0,0 +1,58 @@
+#
+# This file and its contents are supplied under the terms of the
+# Common Development and Distribution License ("CDDL"), version 1.0.
+# You may only use this file in accordance with the terms of version
+# 1.0 of the CDDL.
+#
+# A full copy of the text of the CDDL should have accompanied this
+# source.  A copy of the CDDL is also available via the Internet at
+# http://www.illumos.org/license/CDDL.
+
+#
+# Copyright 2017 Joyent, Inc.
+#
+
+PROG =	lx_lockd
+
+PROG_OBJS = lockd.o nfs_tbind.o
+UTIL_OBJS = thrpool.o
+
+OBJS =	$(PROG_OBJS) $(UTIL_OBJS)
+SRCS =	$(PROG_OBJS:%.o=%.c)
+
+all:		$(PROG)
+
+include ../Makefile.lx
+include $(SRC)/cmd/Makefile.cmd
+
+# override the install directory
+ROOTBIN =	$(ROOTBRANDDIR)
+CLOBBERFILES =	$(OBJS) $(ROOTPROG)
+
+CPPFLAGS +=	-I$(SRC)/cmd/fs.d/nfs/lib
+C99MODE =	$(C99_ENABLE)
+LDLIBS +=	-lnsl -lsocket
+
+.KEEP_STATE:
+
+install: all $(ROOTPROG)
+
+clean:
+	$(RM) $(PROG) $(OBJS)
+
+lint:
+	$(LINT.c) -erroff=E_SEC_PRINTF_VAR_FMT $(SRCS) $(LDLIBS)
+
+$(PROG): $(OBJS)
+	$(LINK.c) -o $@ $(OBJS) $(LDLIBS)
+	$(POST_PROCESS)
+
+%.o: %.c
+	$(COMPILE.c) $<
+	$(POST_PROCESS_O)
+
+%.o: $(SRC)/cmd/fs.d/nfs/lib/%.c
+	$(COMPILE.c) $<
+	$(POST_PROCESS_O)
+
+include $(SRC)/cmd/Makefile.targ
diff --git a/usr/src/lib/brand/lx/lx_lockd/lockd.c b/usr/src/lib/brand/lx/lx_lockd/lockd.c
new file mode 100644
index 0000000000..7054181ec6
--- /dev/null
+++ b/usr/src/lib/brand/lx/lx_lockd/lockd.c
@@ -0,0 +1,551 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+
+/*
+ * Copyright (c) 1989, 2010, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2012 by Delphix. All rights reserved.
+ * Copyright 2014 Nexenta Systems, Inc.  All rights reserved.
+ * Copyright 2017 Joyent, Inc.
+ */
+
+/*	Copyright (c) 1984, 1986, 1987, 1988, 1989 AT&T		*/
+/*	  All Rights Reserved  	*/
+
+/*
+ * University Copyright- Copyright (c) 1982, 1986, 1988
+ * The Regents of the University of California
+ * All Rights Reserved
+ *
+ * University Acknowledgment- Portions of this document are derived from
+ * software developed by the University of California, Berkeley, and its
+ * contributors.
+ */
+
+/* LINTLIBRARY */
+/* PROTOLIB1 */
+
+/*
+ * lx-brand NFS lockd (NLM) server.
+ *
+ * This code is derived from the native lockd. The original history starts
+ * from:
+ *    copied from usr/src/cmd/fs.d/nfs/nfsd/nfsd.c and then s:NFS:NLM: applied
+ *
+ * On Linux 'lockd' is implemented entirely inside the kernel, whereas our
+ * native lockd support is a combination of user-level and kernel code.
+ * Unfortunately, the native lockd is unable to run in lx for several reasons:
+ * - tightly bound to SMF
+ * - interacts with various native libnsl configuration files
+ * - expects to register with a native rpcbind using /dev/ticlts
+ * Thus, this code is derived from the native lockd, but modified to address
+ * these issues and run inside an lx-branded zone. Because the Linux lockd
+ * lives entirely in the kernel, our lockd must be started automatically if
+ * it is needed. This is done by the NFS mount code when it determines that
+ * a lockd is not already running. Our code ensures that there is only a
+ * single instance of the lockd running, in the case that there is a race with
+ * two NFS mounts occuring in parallel.
+ *
+ * lockd is required for both NFSv3 and v4 locking. Although v4 locking is
+ * part of the v4 protocol, the kernel support to allow NFS locking is enabled
+ * by the lockd when it starts. For v3, there must be a lockd registered with
+ * rpcbind or the server side will fail the lock. This is because the server
+ * side expects to make callbacks to the client. We must successfully register
+ * with the Linux rpcbind or the nfs syscall to enable the kernel side of
+ * locking will fail. For the v3 case, the user-level Linux mount helper cmd
+ * already checks for the presence of rpcbind. It fails if rpcbind is not
+ * running and the mount does not include the "nolock" option. For v4 the use
+ * of rpcbind appears unnecessary, since locking is built-in to the protocol,
+ * but it still required by our kernel NFS locking code.
+ *
+ * As with the native lockd, the kernel locking code makes upcalls to our lockd
+ * over /dev/ticotsord, so that device must be present inside an lx zone.
+ *
+ * Because this process tries to mimic the Linux kernel lockd, there is no
+ * stdin/out/err and we block all signals, unless we're running in debug mode.
+ */
+
+#include <sys/param.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <tiuser.h>
+#include <rpc/rpc.h>
+#include <errno.h>
+#include <thread.h>
+#include <sys/time.h>
+#include <sys/file.h>
+#include <nfs/nfs.h>
+#include <nfs/nfssys.h>
+#include <stdio.h>
+#include <stdio_ext.h>
+#include <stdlib.h>
+#include <signal.h>
+#include <netconfig.h>
+#include <netdir.h>
+#include <string.h>
+#include <unistd.h>
+#include <stropts.h>
+#include <sys/tihdr.h>
+#include <poll.h>
+#include <priv_utils.h>
+#include <sys/tiuser.h>
+#include <netinet/tcp.h>
+#include <deflt.h>
+#include <rpcsvc/nlm_prot.h>
+#include <ctype.h>
+#include <strings.h>
+#include <sys/varargs.h>
+#include "nfs_tbind.h"
+#include "thrpool.h"
+
+/* Option defaults.  See nfssys.h */
+struct lm_svc_args lmargs = {
+	.version = LM_SVC_CUR_VERS,
+	/* fd, n_fmly, n_proto, n_rdev (below) */
+	.debug = 0,
+	.timout = 5 * 60,
+	.grace = 90, /* How long to wait for clients to re-establish locks. */
+	.retransmittimeout = 5
+};
+int max_servers = 256;
+
+#define	RET_OK		0	/* return code for no error */
+#define	RET_ERR		33	/* return code for error(s) */
+
+#define	SYSLOG_BLEN	256
+
+/*
+ * The defintion of DEFAULT_MAXPID is only in kernel and varies with a debug
+ * build, but we just want a sanity check on the lock entry.
+ */
+#define	KERN_MAXPID	999999
+
+#define	NLM_LOCK_FILE	"/native/tmp/lxlockd"
+
+int nlmsvc(int fd, struct netbuf addrmask, struct netconfig *nconf);
+
+static int nlmsvcpool(int max_servers);
+static void usage(void);
+static void shutdown_lockd(void);
+
+extern int _nfssys(int, void *);
+extern void nlm_do_one(char *, int (*)(int, struct netbuf, struct netconfig *));
+extern void nlm_unreg(char *);
+
+/*
+ * We want to bind to these TLI providers, and in this order,
+ * because the kernel NLM needs the loopback first for its
+ * initialization. (It uses it to talk to statd.)
+ */
+static  NETSELDECL(defaultproviders)[] = {
+	"/dev/ticotsord",
+	"/dev/tcp",
+	"/dev/udp",
+	"/dev/tcp6",
+	"/dev/udp6",
+	NULL
+};
+
+/*
+ * The following are all globals used by routines in nfs_tbind.c.
+ */
+size_t	end_listen_fds;		/* used by conn_close_oldest() */
+size_t	num_fds = 0;		/* used by multiple routines */
+int	listen_backlog = 32;	/* used by bind_to_{provider,proto}() */
+				/* used by cots_listen_event() */
+int	max_conns_allowed = -1;	/* used by cots_listen_event() */
+
+void
+lx_syslog(char *fmt, ...)
+{
+	int fd, l;
+	struct sockaddr_un snd_addr;
+	char buf[SYSLOG_BLEN], fb[SYSLOG_BLEN], *bp, *fp, *ep;
+	va_list ap;
+
+	/* First we replace %m in fmt string with error string into fb. */
+	ep = fb + sizeof (fb);
+	fb[SYSLOG_BLEN - 1] = '\0';
+	for (bp = fb, fp = fmt; bp < ep && (*bp = *fp) != '\0'; bp++, fp++) {
+		if (*fp == '%' && *(fp + 1) == 'm') {
+			(void) strlcpy(bp, strerror(errno), ep - bp);
+			bp += strlen(bp);
+			fp += 2;
+		}
+	}
+
+	va_start(ap, fmt);
+	(void) snprintf(buf, sizeof (buf), "  rpc.lockd[%d]: ", getpid());
+	l = strlen(buf);
+	bp = &buf[l];
+	(void) vsnprintf(bp, sizeof (buf) - l, fb, ap);
+	va_end(ap);
+
+	if ((fd = socket(AF_UNIX, SOCK_DGRAM, 0)) == -1)
+		return;
+
+	bzero(&snd_addr, sizeof (snd_addr));
+	strcpy(snd_addr.sun_path, "/dev/log");
+	snd_addr.sun_family = AF_LOCAL;
+	l = strlen(snd_addr.sun_path) + sizeof (snd_addr.sun_family);
+
+	if (connect(fd, (struct sockaddr *)&snd_addr, l) == 0) {
+		l = strlen(buf);
+		(void) send(fd, buf, l, 0);
+	}
+
+	close(fd);
+}
+
+/*
+ * Return -1 if we cannot setup the lock for any reason, or if we detect that
+ * another lockd is already running. This will lead to this lockd instance
+ * exiting.
+ */
+static int
+create_daemon_lock()
+{
+	int fd, len, r = -1;
+	struct flock lock;
+	char line[64];
+
+	if ((fd = open(NLM_LOCK_FILE, O_RDWR | O_CREAT, 0644)) < 0)
+		return (-1);
+
+	lock.l_type = F_WRLCK;
+	lock.l_whence = SEEK_SET;
+	lock.l_start = (off_t)0;
+	lock.l_len = (off_t)0;
+
+	/* If another lockd is already setting up, quit. */
+	if (fcntl(fd, F_SETLK, &lock) == -1)
+		goto done;
+
+	if ((len = read(fd, line, sizeof (line))) >= 0) {
+		long lval;
+		char *s;
+		struct stat sb;
+
+		line[len] = '\0';
+
+		/* Simple check that lockd is still there */
+		if (!isdigit(line[0]))
+			goto overwrite;
+
+		lval = strtol(line, &s, 10);
+		if (*s != '\n' || lval > KERN_MAXPID)
+			goto overwrite;
+
+		(void) snprintf(line, sizeof (line), "/proc/%ld", lval);
+		if (stat(line, &sb) == 0) {
+			/* the current holder is still there */
+			goto done;
+		}
+	}
+
+overwrite:
+	(void) snprintf(line, sizeof (line), "%d\n", getpid());
+	len = strlen(line);
+	if (lseek(fd, 0, SEEK_SET) == 0 && write(fd, line, len) == len)
+		r = 0;
+
+done:
+	(void) close(fd);
+	return (r);
+}
+
+static void
+daemonize(void)
+{
+	sigset_t set;
+	pid_t pid;
+
+	(void) sigfillset(&set);
+	(void) sigprocmask(SIG_BLOCK, &set, NULL);
+
+	closefrom(STDIN_FILENO);
+
+	if ((pid = fork()) == -1)
+		exit(1);
+
+	if (pid != 0)
+		exit(0);
+
+	/* child */
+	(void) setsid();
+}
+
+static void
+shutdown_lockd(void)
+{
+	NETSELPDECL(providerp);
+
+	lx_syslog("Stopping");
+
+	/* unregister from rpcbind */
+	for (providerp = defaultproviders; *providerp != NULL; providerp++) {
+		char *provider = *providerp;
+		nlm_unreg(provider);
+	}
+	(void) unlink(NLM_LOCK_FILE);
+	(void) _nfssys(KILL_LOCKMGR, NULL);
+}
+
+/* When debugging, ensure cleanup */
+static void
+sigint_handler(void)
+{
+	shutdown_lockd();
+	exit(0);
+}
+
+int
+main(int ac, char *av[])
+{
+	NETSELPDECL(providerp);
+	int i, c, val;
+
+	if (geteuid() != 0) {
+		exit(1);
+	}
+
+	/* Initializations that require more privileges than we need to run. */
+	if (__init_daemon_priv(PU_RESETGROUPS | PU_CLEARLIMITSET, 1, 1,
+	    PRIV_SYS_NFS, NULL) == -1) {
+		exit(1);
+	}
+
+	(void) enable_extended_FILE_stdio(-1, -1);
+
+	while ((c = getopt(ac, av, "c:d:g:l:t:")) != EOF)
+		switch (c) {
+		case 'c': /* max_connections */
+			if ((val = atoi(optarg)) <= 0)
+				goto badval;
+			max_conns_allowed = val;
+			break;
+
+		case 'd': /* debug */
+			lmargs.debug = atoi(optarg);
+			break;
+
+		case 'g': /* grace_period */
+			if ((val = atoi(optarg)) <= 0)
+				goto badval;
+			lmargs.grace = val;
+			break;
+
+		case 'l': /* listen_backlog */
+			if ((val = atoi(optarg)) <= 0)
+				goto badval;
+			listen_backlog = val;
+			break;
+
+		case 't': /* retrans_timeout */
+			if ((val = atoi(optarg)) <= 0)
+				goto badval;
+			lmargs.retransmittimeout = val;
+			break;
+
+		badval:
+			if (lmargs.debug) {
+				fprintf(stderr, "Invalid -%c option value", c);
+			}
+			/* FALLTHROUGH */
+		default:
+			if (lmargs.debug) {
+				usage();
+			}
+			exit(1);
+		}
+
+	/* If there is one more argument, it is the number of servers. */
+	if (optind < ac) {
+		val = atoi(av[optind]);
+		if (val <= 0) {
+			if (lmargs.debug) {
+				fprintf(stderr, "Invalid max_servers argument");
+				usage();
+			}
+			exit(1);
+		}
+		max_servers = val;
+		optind++;
+	}
+	/* If there are two or more arguments, then this is a usage error. */
+	if (optind != ac) {
+		if (lmargs.debug) {
+			usage();
+		}
+		exit(1);
+	}
+
+	if (lmargs.debug) {
+		printf("lx_lockd: debug=%d, conn_idle_timout=%d, "
+		    "grace_period=%d, listen_backlog=%d, "
+		    "max_connections=%d, max_servers=%d, "
+		    "retrans_timeout=%d\n",
+		    lmargs.debug, lmargs.timout, lmargs.grace, listen_backlog,
+		    max_conns_allowed, max_servers, lmargs.retransmittimeout);
+	}
+
+	/* Set current dir to server root */
+	if (chdir("/") < 0) {
+		lx_syslog("chdir: %m");
+		exit(1);
+	}
+
+	/* Daemonize, if not debugging. */
+	if (lmargs.debug == 0) {
+		daemonize();
+	} else {
+		struct sigaction act;
+
+		act.sa_handler = sigint_handler;
+		act.sa_flags = 0;
+		(void) sigaction(SIGINT, &act, NULL);
+	}
+
+	if (create_daemon_lock() < 0)
+		exit(0);
+
+	lx_syslog("Starting");
+
+	/* Install atexit handler. */
+	(void) atexit(shutdown_lockd);
+
+	/* Unregister any previous versions. */
+	for (i = NLM_VERS; i < NLM4_VERS; i++) {
+		svc_unreg(NLM_PROG, i);
+	}
+
+	/* Set up kernel RPC thread pool for the NLM server. */
+	if (nlmsvcpool(max_servers)) {
+		lx_syslog("Can't set up kernel NLM service: %m. Exiting");
+		exit(1);
+	}
+
+	/* Set up blocked thread to do LWP creation on behalf of the kernel. */
+	if (svcwait(NLM_SVCPOOL_ID)) {
+		lx_syslog("Can't set up NLM pool creator: %m. Exiting");
+		exit(1);
+	}
+
+	for (providerp = defaultproviders; *providerp != NULL; providerp++) {
+		char *provider = *providerp;
+		nlm_do_one(provider, nlmsvc);
+	}
+
+	if (num_fds == 0) {
+		lx_syslog("Could not start NLM service for any protocol. "
+		    "Exiting");
+		exit(1);
+	}
+
+	end_listen_fds = num_fds;
+
+	/*
+	 * lockd is up and running as far as we are concerned.
+	 *
+	 * Get rid of unneeded privileges.
+	 */
+	__fini_daemon_priv(PRIV_PROC_FORK, PRIV_PROC_EXEC, PRIV_PROC_SESSION,
+	    PRIV_FILE_LINK_ANY, PRIV_PROC_INFO, (char *)NULL);
+
+	/* Poll for non-data control events on the transport descriptors. */
+	poll_for_action();
+
+	/* If we get here, something failed in poll_for_action(). */
+	return (1);
+}
+
+static int
+nlmsvcpool(int maxservers)
+{
+	struct svcpool_args npa;
+
+	npa.id = NLM_SVCPOOL_ID;
+	npa.maxthreads = maxservers;
+	npa.redline = 0;
+	npa.qsize = 0;
+	npa.timeout = 0;
+	npa.stksize = 0;
+	npa.max_same_xprt = 0;
+	return (_nfssys(SVCPOOL_CREATE, &npa));
+}
+
+static int
+ncfmly_to_lmfmly(const char *ncfmly)
+{
+	if (0 == strcmp(ncfmly, NC_INET))
+		return (LM_INET);
+	if (0 == strcmp(ncfmly, NC_INET6))
+		return (LM_INET6);
+	if (0 == strcmp(ncfmly, NC_LOOPBACK))
+		return (LM_LOOPBACK);
+	return (-1);
+}
+
+static int
+nctype_to_lmprot(uint_t semantics)
+{
+	switch (semantics) {
+	case NC_TPI_CLTS:
+		return (LM_UDP);
+	case NC_TPI_COTS_ORD:
+		return (LM_TCP);
+	}
+	return (-1);
+}
+
+static dev_t
+ncdev_to_rdev(const char *ncdev)
+{
+	struct stat st;
+
+	if (stat(ncdev, &st) < 0)
+		return (NODEV);
+	return (st.st_rdev);
+}
+
+/*
+ * Establish NLM service thread.
+ */
+int
+nlmsvc(int fd, struct netbuf addrmask, struct netconfig *nconf)
+{
+	struct lm_svc_args lma;
+
+	lma = lmargs; /* init by struct copy */
+
+	/*
+	 * The kernel code needs to reconstruct a complete
+	 * knetconfig from n_fmly, n_proto.  We use these
+	 * two fields to convey the family and semantics.
+	 */
+	lma.fd = fd;
+	lma.n_fmly = ncfmly_to_lmfmly(nconf->nc_protofmly);
+	lma.n_proto = nctype_to_lmprot(nconf->nc_semantics);
+	lma.n_rdev = ncdev_to_rdev(nconf->nc_device);
+
+	return (_nfssys(LM_SVC, &lma));
+}
+
+static void
+usage(void)
+{
+	(void) fprintf(stderr, "usage: lx_lockd [options] [max_servers]\n");
+	(void) fprintf(stderr, "\t-c max_connections\n");
+	(void) fprintf(stderr, "\t-d debug_level\n");
+	(void) fprintf(stderr, "\t-g grace_period\n");
+	(void) fprintf(stderr, "\t-l listen_backlog\n");
+	(void) fprintf(stderr, "\t-t retransmit_timeout\n");
+}
diff --git a/usr/src/lib/brand/lx/lx_lockd/nfs_tbind.c b/usr/src/lib/brand/lx/lx_lockd/nfs_tbind.c
new file mode 100644
index 0000000000..b524573d9b
--- /dev/null
+++ b/usr/src/lib/brand/lx/lx_lockd/nfs_tbind.c
@@ -0,0 +1,1721 @@
+/*
+ * This file and its contents are supplied under the terms of the
+ * Common Development and Distribution License ("CDDL"), version 1.0.
+ * You may only use this file in accordance with the terms of version
+ * 1.0 of the CDDL.
+ *
+ * A full copy of the text of the CDDL should have accompanied this
+ * source.  A copy of the CDDL is also available via the Internet at
+ * http://www.illumos.org/license/CDDL.
+ */
+
+/*
+ * Copyright (c) 1983, 1984, 1985, 1986, 1987, 1988, 1989 AT&T
+ * All Rights Reserved
+ *
+ * Portions of this source code were derived from Berkeley
+ * 4.3 BSD under license from the Regents of the University of
+ * California.
+ */
+
+/*
+ * Copyright (c) 1996, 2010, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2012 by Delphix. All rights reserved.
+ * Copyright 2014 Nexenta Systems, Inc.  All rights reserved.
+ * Copyright 2014 Gary Mills
+ * Copyright 2017 Joyent, Inc.
+ */
+
+/*
+ * Derived from usr/src/cmd/fs.d/nfs/lib/nfs_tbind.c, but modified to work
+ * within an lx-branded zone and to only support the lx lockd.
+ */
+
+#include <tiuser.h>
+#include <fcntl.h>
+#include <netconfig.h>
+#include <stropts.h>
+#include <errno.h>
+#include <rpc/rpc.h>
+#include <sys/time.h>
+#include <sys/resource.h>
+#include <signal.h>
+#include <netdir.h>
+#include <unistd.h>
+#include <string.h>
+#include <netinet/tcp.h>
+#include <malloc.h>
+#include <stdlib.h>
+#include "nfs_tbind.h"
+#include <sys/socket.h>
+#include <rpcsvc/nlm_prot.h>
+#include <rpc/pmap_prot.h>
+
+/*
+ * Determine valid semantics for most applications.
+ */
+#define	OK_TPI_TYPE(_nconf) \
+	(_nconf->nc_semantics == NC_TPI_CLTS || \
+	_nconf->nc_semantics == NC_TPI_COTS || \
+	_nconf->nc_semantics == NC_TPI_COTS_ORD)
+
+#define	BE32_TO_U32(a) \
+	((((ulong_t)((uchar_t *)a)[0] & 0xFF) << (ulong_t)24) | \
+	(((ulong_t)((uchar_t *)a)[1] & 0xFF) << (ulong_t)16) | \
+	(((ulong_t)((uchar_t *)a)[2] & 0xFF) << (ulong_t)8)  | \
+	((ulong_t)((uchar_t *)a)[3] & 0xFF))
+
+/*
+ * Number of elements to add to the poll array on each allocation.
+ */
+#define	POLL_ARRAY_INC_SIZE	64
+
+/*
+ * Number of file descriptors by which the process soft limit may be
+ * increased on each call to nofile_increase(0).
+ */
+#define	NOFILE_INC_SIZE	64
+
+/*
+ * Default TCP send and receive buffer size of NFS server.
+ */
+#define	NFSD_TCP_BUFSZ	(1024*1024)
+
+struct conn_ind {
+	struct conn_ind *conn_next;
+	struct conn_ind *conn_prev;
+	struct t_call   *conn_call;
+};
+
+struct conn_entry {
+	bool_t			closing;
+	struct netconfig	nc;
+};
+
+/*
+ * Built-in netconfig table.
+ */
+#define	N_NETCONF_ENTS	5
+static struct netconfig nca[N_NETCONF_ENTS] = {
+	{"udp6", NC_TPI_CLTS,     1, "inet6", "udp", "/dev/udp6", 0, NULL},
+	{"tcp6", NC_TPI_COTS_ORD, 1, "inet6", "tcp", "/dev/tcp6", 0, NULL},
+	{"udp",  NC_TPI_CLTS,     1, "inet",  "udp", "/dev/udp", 0, NULL},
+	{"tcp",  NC_TPI_COTS_ORD, 1, "inet",  "tcp", "/dev/tcp", 0, NULL},
+	{"ticotsord", NC_TPI_COTS_ORD, 1, "loopback", "-", "/dev/ticotsord", 0,
+	    NULL}
+};
+
+static const char nullstring[] = "\000";
+
+static int	nofile_increase(int);
+static int	reuseaddr(int);
+static int	recvucred(int);
+static void	add_to_poll_list(int, struct netconfig *);
+static int	bind_to_provider(char *, struct netbuf **, struct netconfig **);
+static void	conn_close_oldest(void);
+static boolean_t conn_get(int, struct netconfig *, struct conn_ind **);
+static void	cots_listen_event(int, int);
+static int	discon_get(int, struct netconfig *, struct conn_ind **);
+static int	do_poll_clts_action(int, int);
+static int	do_poll_cots_action(int, int);
+static void	remove_from_poll_list(int);
+static int	set_addrmask(int, struct netconfig *, struct netbuf *);
+static int	is_listen_fd_index(int);
+
+static struct pollfd *poll_array;
+static struct conn_entry *conn_polled;
+static int	num_conns;		/* Current number of connections */
+static int	setopt(int fd, int level, int name, int value);
+static int	get_opt(int fd, int level, int name);
+static void	nfslib_set_sockbuf(int fd);
+
+static struct timeval tottimeout = { 60, 0 };
+static struct timeval rpcbtime = { 15, 0 };
+static boolean_t have_rpcbind = B_FALSE;
+
+extern int nlmsvc(int, struct netbuf, struct netconfig *);
+extern void lx_syslog(char *, ...);
+extern bool_t xdr_wrapstring(XDR *, char **);
+extern bool_t xdr_rpcb(XDR *, RPCB *);
+
+#define	LX_PMAP_VERS	4
+
+/*
+ * Set a mapping between program, version and address.
+ * Calls the lx-zone's rpcbind service to do the mapping.
+ */
+static boolean_t
+lx_rpcb_set(const rpcvers_t version, const struct netconfig *nconf,
+    const struct netbuf *address)
+{
+	CLIENT *client;
+	bool_t rslt = FALSE;
+	RPCB parms;
+	char uidbuf[32];
+
+	client = clnt_create_timed("localhost", PMAPPROG, LX_PMAP_VERS,
+	    "datagram_v", &rpcbtime);
+	if (client == NULL)
+		return (B_FALSE);
+
+	parms.r_addr = taddr2uaddr((struct netconfig *)nconf,
+	    (struct netbuf *)address); /* convert to universal */
+	if (!parms.r_addr) {
+		rpc_createerr.cf_stat = RPC_N2AXLATEFAILURE;
+		return (B_FALSE);
+	}
+	parms.r_prog = NLM_PROG;
+	parms.r_vers = version;
+	parms.r_netid = nconf->nc_netid;
+	/*
+	 * Though uid is not being used directly, we still send it for
+	 * completeness.  For non-unix platforms, perhaps some other
+	 * string or an empty string can be sent.
+	 */
+	(void) sprintf(uidbuf, "%d", (int)geteuid());
+	parms.r_owner = uidbuf;
+
+	CLNT_CALL(client, RPCBPROC_SET, (xdrproc_t)xdr_rpcb, (char *)&parms,
+	    (xdrproc_t)xdr_bool, (char *)&rslt, tottimeout);
+
+	CLNT_DESTROY(client);
+	free(parms.r_addr);
+	return (B_TRUE);
+}
+
+/*
+ * Remove the mapping between program, version and netbuf address.
+ * Calls the rpcbind service to do the un-mapping.
+ */
+static void
+lx_rpcb_unset(const rpcvers_t version, char *nc_netid)
+{
+	CLIENT *client;
+	bool_t rslt;
+	RPCB parms;
+	char uidbuf[32];
+
+	if (!have_rpcbind)
+		return;
+
+	client = clnt_create_timed("localhost", PMAPPROG, LX_PMAP_VERS,
+	    "datagram_v", &rpcbtime);
+	if (client == NULL)
+		return;
+
+	parms.r_prog = NLM_PROG;
+	parms.r_vers = version;
+	parms.r_netid = nc_netid;
+	parms.r_addr = (char *)&nullstring[0];
+	(void) sprintf(uidbuf, "%d", (int)geteuid());
+	parms.r_owner = uidbuf;
+
+	CLNT_CALL(client, RPCBPROC_UNSET, (xdrproc_t)xdr_rpcb, (char *)&parms,
+	    (xdrproc_t)xdr_bool, (char *)&rslt, tottimeout);
+
+	CLNT_DESTROY(client);
+}
+
+/*
+ * Called to create and prepare a transport descriptor for in-kernel
+ * RPC service.
+ * Returns -1 on failure and a valid descriptor on success.
+ */
+static int
+lx_nfslib_transport_open(struct netconfig *nconf)
+{
+	int fd;
+	struct strioctl	strioc;
+
+	if ((nconf == (struct netconfig *)NULL) ||
+	    (nconf->nc_device == (char *)NULL)) {
+		lx_syslog("no netconfig device");
+		return (-1);
+	}
+
+	/*
+	 * Open the transport device.
+	 */
+	fd = t_open(nconf->nc_device, O_RDWR, (struct t_info *)NULL);
+	if (fd == -1) {
+		if (t_errno == TSYSERR && errno == EMFILE &&
+		    (nofile_increase(0) == 0)) {
+			/* Try again with a higher NOFILE limit. */
+			fd = t_open(nconf->nc_device, O_RDWR,
+			    (struct t_info *)NULL);
+		}
+		if (fd == -1) {
+			lx_syslog("t_open %s failed:  t_errno %d, %m",
+			    nconf->nc_device, t_errno);
+			return (-1);
+		}
+	}
+
+	/*
+	 * Pop timod because the RPC module must be as close as possible
+	 * to the transport.
+	 */
+	if (ioctl(fd, I_POP, 0) < 0) {
+		lx_syslog("I_POP of timod failed: %m");
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	/*
+	 * Common code for CLTS and COTS transports
+	 */
+	if (ioctl(fd, I_PUSH, "rpcmod") < 0) {
+		lx_syslog("I_PUSH of rpcmod failed: %m");
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	strioc.ic_cmd = RPC_SERVER;
+	strioc.ic_dp = (char *)0;
+	strioc.ic_len = 0;
+	strioc.ic_timout = -1;
+
+	/* Tell rpcmod to act like a server stream. */
+	if (ioctl(fd, I_STR, &strioc) < 0) {
+		lx_syslog("rpcmod set-up ioctl failed: %m");
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	/*
+	 * Re-push timod so that we will still be doing TLI
+	 * operations on the descriptor.
+	 */
+	if (ioctl(fd, I_PUSH, "timod") < 0) {
+		lx_syslog("I_PUSH of timod failed: %m");
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	/*
+	 * Enable options of returning the ip's for udp.
+	 */
+	if (strcmp(nconf->nc_netid, "udp6") == 0) {
+		(void) __rpc_tli_set_options(fd, IPPROTO_IPV6,
+		    IPV6_RECVPKTINFO, 1);
+	} else if (strcmp(nconf->nc_netid, "udp") == 0) {
+		(void) __rpc_tli_set_options(fd, IPPROTO_IP, IP_RECVDSTADDR, 1);
+	}
+
+	return (fd);
+}
+
+static int
+nofile_increase(int limit)
+{
+	struct rlimit rl;
+
+	if (getrlimit(RLIMIT_NOFILE, &rl) == -1) {
+		lx_syslog("getrlimit of NOFILE failed: %m");
+		return (-1);
+	}
+
+	if (limit > 0)
+		rl.rlim_cur = limit;
+	else
+		rl.rlim_cur += NOFILE_INC_SIZE;
+
+	if (rl.rlim_cur > rl.rlim_max &&
+	    rl.rlim_max != RLIM_INFINITY)
+		rl.rlim_max = rl.rlim_cur;
+
+	if (setrlimit(RLIMIT_NOFILE, &rl) == -1) {
+		lx_syslog("setrlimit of NOFILE to %d failed: %m",
+		    rl.rlim_cur);
+		return (-1);
+	}
+
+	return (0);
+}
+
+static void
+nfslib_set_sockbuf(int fd)
+{
+	int curval, val;
+
+	val = NFSD_TCP_BUFSZ;
+
+	curval = get_opt(fd, SOL_SOCKET, SO_SNDBUF);
+	if ((curval != -1) && (curval < val)) {
+		if (setopt(fd, SOL_SOCKET, SO_SNDBUF, val) < 0) {
+			lx_syslog("couldn't set SO_SNDBUF to %d - t_errno = %d",
+			    val, t_errno);
+			lx_syslog("Check and increase system-wide tcp_max_buf");
+		}
+	}
+
+	curval = get_opt(fd, SOL_SOCKET, SO_RCVBUF);
+	if ((curval != -1) && (curval < val)) {
+		if (setopt(fd, SOL_SOCKET, SO_RCVBUF, val) < 0) {
+			lx_syslog("couldn't set SO_RCVBUF to %d - t_errno = %d",
+			    val, t_errno);
+			lx_syslog("Check and increase system-wide tcp_max_buf");
+		}
+	}
+}
+
+static int
+lx_nfslib_bindit(struct netconfig *nconf, struct netbuf **addr, int backlog)
+{
+	int fd;
+	struct t_bind *ntb;
+	struct t_bind tb;
+	struct nd_addrlist *addrlist;
+	struct t_optmgmt req, resp;
+	struct opthdr *opt;
+	char reqbuf[128];
+	struct nd_hostserv hs;
+
+	if ((fd = lx_nfslib_transport_open(nconf)) == -1) {
+		lx_syslog("cannot establish transport service over %s",
+		    nconf->nc_device);
+		return (-1);
+	}
+
+	addrlist = (struct nd_addrlist *)NULL;
+
+	/*
+	 * This is the well-defined 'lockd' port from /etc/services. We can
+	 * pass down the NLM port number to lx_nfslib_bindit and that resolves
+	 * properly in the native *getby* calling paths.
+	 */
+	hs.h_serv = "4045";
+	hs.h_host = HOST_SELF;
+
+	/*
+	 * The following block is based on _netdir_getbyname in
+	 * usr/src/lib/nametoaddr/straddr/common/straddr.c. This is what would
+	 * be used by __classic_netdir_getbyname for the loopback.
+	 */
+	if (strcmp(nconf->nc_netid, "ticotsord") == 0) {
+		struct nd_addrlist *ap;
+		struct netbuf *netbufp;
+		char *fulladdr = "localhost.4045";
+
+		if ((ap = malloc(sizeof (struct nd_addrlist))) == NULL) {
+			(void) t_close(fd);
+			return (-1);
+		}
+
+		ap->n_cnt = 1;
+		if ((ap->n_addrs = malloc(sizeof (struct netbuf))) == NULL) {
+			free(ap);
+			(void) t_close(fd);
+			return (-1);
+		}
+
+		netbufp = ap->n_addrs;
+
+		/* Don't include the terminating NULL character in the length */
+		netbufp->len = netbufp->maxlen = (int)strlen(fulladdr);
+		if ((netbufp->buf = strdup(fulladdr)) == NULL) {
+			free(netbufp);
+			free(ap);
+			(void) t_close(fd);
+			return (-1);
+		}
+		addrlist = ap;
+
+	} else if (netdir_getbyname(nconf, &hs, &addrlist) != 0) {
+		lx_syslog("Cannot get address for transport %s",
+		    nconf->nc_netid);
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	if (strcmp(nconf->nc_proto, "tcp") == 0) {
+		/*
+		 * If we're running over TCP, then set the
+		 * SO_REUSEADDR option so that we can bind
+		 * to our preferred address even if previously
+		 * left connections exist in FIN_WAIT states.
+		 * This is somewhat bogus, but otherwise you have
+		 * to wait 2 minutes to restart after killing it.
+		 */
+		if (reuseaddr(fd) == -1) {
+			lx_syslog("couldn't set SO_REUSEADDR option on "
+			    "transport");
+		}
+	} else if (strcmp(nconf->nc_proto, "udp") == 0) {
+		/*
+		 * In order to run MLP on UDP, we need to handle creds.
+		 */
+		if (recvucred(fd) == -1) {
+			lx_syslog("couldn't set SO_RECVUCRED option on "
+			    "transport");
+		}
+	}
+
+	if (nconf->nc_semantics == NC_TPI_CLTS)
+		tb.qlen = 0;
+	else
+		tb.qlen = backlog;
+
+	/* LINTED pointer alignment */
+	ntb = (struct t_bind *)t_alloc(fd, T_BIND, T_ALL);
+	if (ntb == (struct t_bind *)NULL) {
+		lx_syslog("t_alloc failed:  t_errno %d, %m", t_errno);
+		(void) t_close(fd);
+		netdir_free((void *)addrlist, ND_ADDRLIST);
+		return (-1);
+	}
+
+	if (addrlist)
+		tb.addr = *(addrlist->n_addrs);		/* structure copy */
+
+	if (t_bind(fd, &tb, ntb) == -1) {
+		lx_syslog("t_bind failed:  t_errno %d, %m", t_errno);
+		(void) t_free((char *)ntb, T_BIND);
+		netdir_free((void *)addrlist, ND_ADDRLIST);
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	/* make sure we bound to the right address */
+	if (tb.addr.len != ntb->addr.len ||
+	    memcmp(tb.addr.buf, ntb->addr.buf, tb.addr.len) != 0) {
+		lx_syslog("t_bind to wrong address");
+		(void) t_free((char *)ntb, T_BIND);
+		netdir_free((void *)addrlist, ND_ADDRLIST);
+		(void) t_close(fd);
+		return (-1);
+	}
+
+	*addr = &ntb->addr;
+	netdir_free((void *)addrlist, ND_ADDRLIST);
+
+	if (strcmp(nconf->nc_proto, "tcp") == 0) {
+		/*
+		 * Disable the Nagle algorithm on TCP connections.
+		 * Connections accepted from this listener will
+		 * inherit the listener options.
+		 */
+
+		/* LINTED pointer alignment */
+		opt = (struct opthdr *)reqbuf;
+		opt->level = IPPROTO_TCP;
+		opt->name = TCP_NODELAY;
+		opt->len = sizeof (int);
+
+		/* LINTED pointer alignment */
+		*(int *)((char *)opt + sizeof (*opt)) = 1;
+
+		req.flags = T_NEGOTIATE;
+		req.opt.len = sizeof (*opt) + opt->len;
+		req.opt.buf = (char *)opt;
+		resp.flags = 0;
+		resp.opt.buf = reqbuf;
+		resp.opt.maxlen = sizeof (reqbuf);
+
+		if (t_optmgmt(fd, &req, &resp) < 0 ||
+		    resp.flags != T_SUCCESS) {
+			lx_syslog("couldn't set NODELAY option for proto %s: "
+			    "t_errno = %d, %m", nconf->nc_proto, t_errno);
+		}
+
+		nfslib_set_sockbuf(fd);
+	}
+
+	return (fd);
+}
+
+static int
+get_opt(int fd, int level, int name)
+{
+	struct t_optmgmt req, res;
+	struct {
+		struct opthdr opt;
+		int value;
+	} reqbuf;
+
+	reqbuf.opt.level = level;
+	reqbuf.opt.name = name;
+	reqbuf.opt.len = sizeof (int);
+	reqbuf.value = 0;
+
+	req.flags = T_CURRENT;
+	req.opt.len = sizeof (reqbuf);
+	req.opt.buf = (char *)&reqbuf;
+
+	res.flags = 0;
+	res.opt.buf = (char *)&reqbuf;
+	res.opt.maxlen = sizeof (reqbuf);
+
+	if (t_optmgmt(fd, &req, &res) < 0 || res.flags != T_SUCCESS) {
+		t_error("t_optmgmt");
+		return (-1);
+	}
+	return (reqbuf.value);
+}
+
+static int
+setopt(int fd, int level, int name, int value)
+{
+	struct t_optmgmt req, resp;
+	struct {
+		struct opthdr opt;
+		int value;
+	} reqbuf;
+
+	reqbuf.opt.level = level;
+	reqbuf.opt.name = name;
+	reqbuf.opt.len = sizeof (int);
+
+	reqbuf.value = value;
+
+	req.flags = T_NEGOTIATE;
+	req.opt.len = sizeof (reqbuf);
+	req.opt.buf = (char *)&reqbuf;
+
+	resp.flags = 0;
+	resp.opt.buf = (char *)&reqbuf;
+	resp.opt.maxlen = sizeof (reqbuf);
+
+	if (t_optmgmt(fd, &req, &resp) < 0 || resp.flags != T_SUCCESS) {
+		t_error("t_optmgmt");
+		return (-1);
+	}
+	return (0);
+}
+
+static int
+reuseaddr(int fd)
+{
+	return (setopt(fd, SOL_SOCKET, SO_REUSEADDR, 1));
+}
+
+static int
+recvucred(int fd)
+{
+	return (setopt(fd, SOL_SOCKET, SO_RECVUCRED, 1));
+}
+
+void
+nfslib_log_tli_error(char *tli_name, int fd, struct netconfig *nconf)
+{
+	int error;
+
+	/*
+	 * Save the error code across lx_syslog(), just in case lx_syslog()
+	 * gets its own error and, therefore, overwrites errno.
+	 */
+	error = errno;
+	if (t_errno == TSYSERR) {
+		lx_syslog("%s(file descriptor %d/transport %s) %m",
+		    tli_name, fd, nconf->nc_proto);
+	} else {
+		lx_syslog("%s(file descriptor %d/transport %s) TLI error %d",
+		    tli_name, fd, nconf->nc_proto, t_errno);
+	}
+	errno = error;
+}
+
+/*
+ * Called to set up NLM service over a particular transport.
+ */
+void
+nlm_do_one(char *provider, int (*svc)(int, struct netbuf, struct netconfig *))
+{
+	int sock;
+	struct netbuf *retaddr;
+	struct netconfig *retnconf;
+	struct netbuf addrmask;
+	int vers;
+	int err;
+
+	sock = bind_to_provider(provider, &retaddr, &retnconf);
+	if (sock == -1) {
+		lx_syslog("Cannot establish NLM service over %s: "
+		    "transport setup problem.", provider);
+		return;
+	}
+
+	if (set_addrmask(sock, retnconf, &addrmask) < 0) {
+		lx_syslog("Cannot set address mask for %s",
+		    retnconf->nc_netid);
+		return;
+	}
+
+	/* Register all versions of the NLM with rpcbind. */
+	if (strcmp(provider, "/dev/ticotsord") != 0) {
+		for (vers = NLM_VERS; vers <= NLM4_VERS; vers++) {
+			lx_rpcb_unset(vers, retnconf->nc_netid);
+			have_rpcbind = lx_rpcb_set(vers, retnconf, retaddr);
+			if (!have_rpcbind) {
+				/*
+				 * No rpcbind running. The kernel NFS locking
+				 * code depends on connecting to rpcbind for
+				 * the _nfssys() call to enable locking to
+				 * succeed. Bail out now.
+				 */
+				lx_syslog("rpcbind is not running, but is "
+				    "required for NFS locking");
+				exit(1);
+			}
+		}
+	}
+
+	/*
+	 * Register services with CLTS semantics right now.
+	 * Note: services with COTS/COTS_ORD semantics will be
+	 * registered later from cots_listen_event function.
+	 */
+	if (retnconf->nc_semantics == NC_TPI_CLTS) {
+		/* svc() doesn't block, it returns success or failure. */
+		err = (*svc)(sock, addrmask, retnconf);
+		if (err < 0) {
+			lx_syslog("Cannot establish NLM service over "
+			    "<file desc. %d, protocol %s> : %m. Exiting",
+			    sock, retnconf->nc_proto);
+			exit(1);
+		}
+	}
+	free(addrmask.buf);
+
+	/*
+	 * We successfully set up the server over this transport.
+	 * Add this descriptor to the one being polled on.
+	 */
+	add_to_poll_list(sock, retnconf);
+}
+
+void
+nlm_unreg(char *provider)
+{
+	struct netconfig *retnconf;
+	int vers;
+
+	if (bind_to_provider(provider, NULL, &retnconf) == -1)
+		return;
+
+	/* Unregister all versions of the program. */
+	for (vers = NLM_VERS; vers <= NLM4_VERS; vers++) {
+		lx_rpcb_unset(vers, retnconf->nc_netid);
+	}
+}
+
+/*
+ * poll on the open transport descriptors for events and errors.
+ */
+void
+poll_for_action(void)
+{
+	int nfds;
+	int i;
+
+	/*
+	 * Keep polling until all transports have been closed. When this
+	 * happens, we return.
+	 */
+	while ((int)num_fds > 0) {
+		nfds = poll(poll_array, num_fds, INFTIM);
+		switch (nfds) {
+		case 0:
+			continue;
+
+		case -1:
+			/*
+			 * Some errors from poll could be
+			 * due to temporary conditions, and we try to
+			 * be robust in the face of them. Other
+			 * errors (should never happen in theory)
+			 * are fatal (eg. EINVAL, EFAULT).
+			 */
+			switch (errno) {
+			case EINTR:
+				continue;
+
+			case EAGAIN:
+			case ENOMEM:
+				(void) sleep(10);
+				continue;
+
+			default:
+				lx_syslog("poll failed: %m. Exiting");
+				exit(1);
+			}
+		default:
+			break;
+		}
+
+		/*
+		 * Go through the poll list looking for events.
+		 */
+		for (i = 0; i < num_fds && nfds > 0; i++) {
+			if (poll_array[i].revents) {
+				nfds--;
+				/*
+				 * We have a message, so try to read it.
+				 * Record the error return in errno,
+				 * so that lx_syslog("...%m")
+				 * dumps the corresponding error string.
+				 */
+				if (conn_polled[i].nc.nc_semantics ==
+				    NC_TPI_CLTS) {
+					errno = do_poll_clts_action(
+					    poll_array[i].fd, i);
+				} else {
+					errno = do_poll_cots_action(
+					    poll_array[i].fd, i);
+				}
+
+				if (errno == 0)
+					continue;
+				/*
+				 * Most returned error codes mean that there is
+				 * fatal condition which we can only deal with
+				 * by closing the transport.
+				 */
+				if (errno != EAGAIN && errno != ENOMEM) {
+					lx_syslog("Error (%m) reading "
+					    "descriptor %d/transport %s. "
+					    "Closing it.", poll_array[i].fd,
+					    conn_polled[i].nc.nc_proto);
+					(void) t_close(poll_array[i].fd);
+					remove_from_poll_list(poll_array[i].fd);
+
+				} else if (errno == ENOMEM)
+					(void) sleep(5);
+			}
+		}
+	}
+
+	lx_syslog("All transports have been closed with errors. Exiting.");
+}
+
+/*
+ * Allocate poll/transport array entries for this descriptor.
+ */
+static void
+add_to_poll_list(int fd, struct netconfig *nconf)
+{
+	static int poll_array_size = 0;
+
+	/*
+	 * If the arrays are full, allocate new ones.
+	 */
+	if (num_fds == poll_array_size) {
+		struct pollfd *tpa;
+		struct conn_entry *tnp = NULL;
+
+		if (poll_array_size != 0) {
+			tpa = poll_array;
+			tnp = conn_polled;
+		} else
+			tpa = (struct pollfd *)0;
+
+		poll_array_size += POLL_ARRAY_INC_SIZE;
+		/*
+		 * Allocate new arrays.
+		 */
+		poll_array = (struct pollfd *)
+		    malloc(poll_array_size * sizeof (struct pollfd) + 256);
+		conn_polled = (struct conn_entry *)
+		    malloc(poll_array_size * sizeof (struct conn_entry) + 256);
+		if (poll_array == (struct pollfd *)NULL ||
+		    conn_polled == (struct conn_entry *)NULL) {
+			lx_syslog("malloc failed for poll array");
+			exit(1);
+		}
+
+		/*
+		 * Copy the data of the old ones into new arrays, and
+		 * free the old ones.
+		 */
+		if (tpa) {
+			(void) memcpy((void *)poll_array, (void *)tpa,
+			    num_fds * sizeof (struct pollfd));
+			(void) memcpy((void *)conn_polled, (void *)tnp,
+			    num_fds * sizeof (struct conn_entry));
+			free((void *)tpa);
+			free((void *)tnp);
+		}
+	}
+
+	/*
+	 * Set the descriptor and event list. All possible events are
+	 * polled for.
+	 */
+	poll_array[num_fds].fd = fd;
+	poll_array[num_fds].events = POLLIN|POLLRDNORM|POLLRDBAND|POLLPRI;
+
+	/*
+	 * Copy the transport data over too.
+	 */
+	conn_polled[num_fds].nc = *nconf;
+	conn_polled[num_fds].closing = 0;
+
+	/*
+	 * Set the descriptor to non-blocking. Avoids a race
+	 * between data arriving on the stream and then having it
+	 * flushed before we can read it.
+	 */
+	if (fcntl(fd, F_SETFL, O_NONBLOCK) == -1) {
+		lx_syslog("fcntl(file desc. %d/transport %s, F_SETFL, "
+		    "O_NONBLOCK): %m. Exiting", num_fds, nconf->nc_proto);
+		exit(1);
+	}
+
+	/*
+	 * Count this descriptor.
+	 */
+	++num_fds;
+}
+
+static void
+remove_from_poll_list(int fd)
+{
+	int i;
+	int num_to_copy;
+
+	for (i = 0; i < num_fds; i++) {
+		if (poll_array[i].fd == fd) {
+			--num_fds;
+			num_to_copy = num_fds - i;
+			(void) memcpy((void *)&poll_array[i],
+			    (void *)&poll_array[i+1],
+			    num_to_copy * sizeof (struct pollfd));
+			(void) memset((void *)&poll_array[num_fds], 0,
+			    sizeof (struct pollfd));
+			(void) memcpy((void *)&conn_polled[i],
+			    (void *)&conn_polled[i+1],
+			    num_to_copy * sizeof (struct conn_entry));
+			(void) memset((void *)&conn_polled[num_fds], 0,
+			    sizeof (struct conn_entry));
+			return;
+		}
+	}
+	lx_syslog("attempt to remove nonexistent fd from poll list");
+}
+
+/*
+ * Called to read and interpret the event on a connectionless descriptor.
+ * Returns 0 if successful, or a UNIX error code if failure.
+ */
+static int
+do_poll_clts_action(int fd, int conn_index)
+{
+	int error;
+	int ret;
+	int flags;
+	struct netconfig *nconf = &conn_polled[conn_index].nc;
+	static struct t_unitdata *unitdata = NULL;
+	static struct t_uderr *uderr = NULL;
+	static int oldfd = -1;
+	struct nd_hostservlist *host = NULL;
+	struct strbuf ctl[1], data[1];
+	/*
+	 * We just need to have some space to consume the
+	 * message in the event we can't use the TLI interface to do the
+	 * job.
+	 *
+	 * We flush the message using getmsg(). For the control part
+	 * we allocate enough for any TPI header plus 32 bytes for address
+	 * and options. For the data part, there is nothing magic about
+	 * the size of the array, but 256 bytes is probably better than
+	 * 1 byte, and we don't expect any data portion anyway.
+	 *
+	 * If the array sizes are too small, we handle this because getmsg()
+	 * (called to consume the message) will return MOREDATA|MORECTL.
+	 * Thus we just call getmsg() until it's read the message.
+	 */
+	char ctlbuf[sizeof (union T_primitives) + 32];
+	char databuf[256];
+
+	/*
+	 * If this is the same descriptor as the last time
+	 * do_poll_clts_action was called, we can save some
+	 * de-allocation and allocation.
+	 */
+	if (oldfd != fd) {
+		oldfd = fd;
+
+		if (unitdata) {
+			(void) t_free((char *)unitdata, T_UNITDATA);
+			unitdata = NULL;
+		}
+		if (uderr) {
+			(void) t_free((char *)uderr, T_UDERROR);
+			uderr = NULL;
+		}
+	}
+
+	/*
+	 * Allocate a unitdata structure for receiving the event.
+	 */
+	if (unitdata == NULL) {
+		/* LINTED pointer alignment */
+		unitdata = (struct t_unitdata *)t_alloc(fd, T_UNITDATA, T_ALL);
+		if (unitdata == NULL) {
+			if (t_errno == TSYSERR) {
+				/*
+				 * Save the error code across lx_syslog(), just
+				 * in case lx_syslog() gets its own error and
+				 * therefore overwrites errno.
+				 */
+				error = errno;
+				lx_syslog("t_alloc(file descriptor "
+				    "%d/transport %s, T_UNITDATA) failed: %m",
+				    fd, nconf->nc_proto);
+				return (error);
+			}
+			lx_syslog("t_alloc(file descriptor %d/transport %s, "
+			    "T_UNITDATA) failed TLI error %d",
+			    fd, nconf->nc_proto, t_errno);
+			goto flush_it;
+		}
+	}
+
+try_again:
+	flags = 0;
+
+	/*
+	 * The idea is we wait for T_UNITDATA_IND's. Of course,
+	 * we don't get any, because rpcmod filters them out.
+	 * However, we need to call t_rcvudata() to let TLI
+	 * tell us we have a T_UDERROR_IND.
+	 *
+	 * algorithm is:
+	 * 	t_rcvudata(), expecting TLOOK.
+	 * 	t_look(), expecting T_UDERR.
+	 * 	t_rcvuderr(), expecting success (0).
+	 * 	expand destination address into ASCII,
+	 *	and dump it.
+	 */
+
+	ret = t_rcvudata(fd, unitdata, &flags);
+	if (ret == 0 || t_errno == TBUFOVFLW) {
+		lx_syslog("t_rcvudata(file descriptor %d/transport %s) got "
+		    "unexpected data, %d bytes",
+		    fd, nconf->nc_proto, unitdata->udata.len);
+
+		/*
+		 * Even though we don't expect any data, in case we do,
+		 * keep reading until there is no more.
+		 */
+		if (flags & T_MORE)
+			goto try_again;
+
+		return (0);
+	}
+
+	switch (t_errno) {
+	case TNODATA:
+		return (0);
+	case TSYSERR:
+		/*
+		 * System errors are returned to caller. Save the error code
+		 * across lx_syslog(), just in case lx_syslog() gets its own
+		 * error and therefore overwrites errno.
+		 */
+		error = errno;
+		lx_syslog("t_rcvudata(file descriptor %d/transport %s) %m",
+		    fd, nconf->nc_proto);
+		return (error);
+	case TLOOK:
+		break;
+	default:
+		lx_syslog("t_rcvudata(file descriptor %d/transport %s) TLI "
+		    "error %d", fd, nconf->nc_proto, t_errno);
+		goto flush_it;
+	}
+
+	ret = t_look(fd);
+	switch (ret) {
+	case 0:
+		return (0);
+	case -1:
+		/*
+		 * System errors are returned to caller.
+		 */
+		if (t_errno == TSYSERR) {
+			/*
+			 * Save the error code across lx_syslog(), just in case
+			 * lx_syslog() gets its own error and therefore
+			 * overwrites errno.
+			 */
+			error = errno;
+			lx_syslog("t_look(file descriptor %d/transport %s) %m",
+			    fd, nconf->nc_proto);
+			return (error);
+		}
+		lx_syslog("t_look(file descriptor %d/transport %s) TLI "
+		    "error %d", fd, nconf->nc_proto, t_errno);
+		goto flush_it;
+	case T_UDERR:
+		break;
+	default:
+		lx_syslog("t_look(file descriptor %d/transport %s) returned "
+		    "%d not T_UDERR (%d)", fd, nconf->nc_proto, ret, T_UDERR);
+	}
+
+	if (uderr == NULL) {
+		/* LINTED pointer alignment */
+		uderr = (struct t_uderr *)t_alloc(fd, T_UDERROR, T_ALL);
+		if (uderr == NULL) {
+			if (t_errno == TSYSERR) {
+				/*
+				 * Save the error code across lx_syslog(), just
+				 * in case lx_syslog() gets its own error
+				 * and therefore overwrites errno.
+				 */
+				error = errno;
+				lx_syslog("t_alloc(file descriptor %d/"
+				    "transport %s, T_UDERROR) failed: %m",
+				    fd, nconf->nc_proto);
+				return (error);
+			}
+			lx_syslog("t_alloc(file descriptor %d/transport %s, "
+			    "T_UDERROR) failed TLI error: %d",
+			    fd, nconf->nc_proto, t_errno);
+			goto flush_it;
+		}
+	}
+
+	ret = t_rcvuderr(fd, uderr);
+	if (ret == 0) {
+
+		/*
+		 * Save the datagram error in errno, so that the
+		 * %m argument to lx_syslog picks up the error string.
+		 */
+		errno = uderr->error;
+
+		/*
+		 * Log the datagram error, then log the host that
+		 * probably triggerred. Cannot log both in the
+		 * same transaction because of packet size limitations
+		 * in /dev/log.
+		 */
+		lx_syslog("NFS response over <file descriptor %d/transport %s> "
+		    "generated error: %m", fd, nconf->nc_proto);
+
+		/*
+		 * Try to map the client's address back to a
+		 * name.
+		 */
+		ret = netdir_getbyaddr(nconf, &host, &uderr->addr);
+		if (ret != -1 && host && host->h_cnt > 0 && host->h_hostservs) {
+			lx_syslog("Bad NFS response was sent to client with "
+			    "host name: %s; service port: %s",
+			    host->h_hostservs->h_host,
+			    host->h_hostservs->h_serv);
+		} else {
+			int i, j;
+			char *buf;
+			char *hex = "0123456789abcdef";
+
+			/*
+			 * Mapping failed, print the whole thing in ASCII hex.
+			 */
+			buf = (char *)malloc(uderr->addr.len * 2 + 1);
+			for (i = 0, j = 0; i < uderr->addr.len; i++, j += 2) {
+				buf[j] = hex[((uderr->addr.buf[i]) >> 4) & 0xf];
+				buf[j+1] = hex[uderr->addr.buf[i] & 0xf];
+			}
+			buf[j] = '\0';
+			lx_syslog("Bad NFS response was sent to client with "
+			    "transport address: 0x%s", buf);
+			free((void *)buf);
+		}
+
+		if (ret == 0 && host != NULL)
+			netdir_free((void *)host, ND_HOSTSERVLIST);
+		return (0);
+	}
+
+	switch (t_errno) {
+	case TNOUDERR:
+		goto flush_it;
+	case TSYSERR:
+		/*
+		 * System errors are returned to caller. Save the error code
+		 * across lx_syslog(), just in case lx_syslog() gets its own
+		 * error and therefore overwrites errno.
+		 */
+		error = errno;
+		lx_syslog("t_rcvuderr(file descriptor %d/transport %s) %m",
+		    fd, nconf->nc_proto);
+		return (error);
+	default:
+		lx_syslog("t_rcvuderr(file descriptor %d/transport %s) TLI "
+		    "error %d", fd, nconf->nc_proto, t_errno);
+		goto flush_it;
+	}
+
+flush_it:
+	/*
+	 * If we get here, then we could not cope with whatever message
+	 * we attempted to read, so flush it. If we did read a message,
+	 * and one isn't present, that is all right, because fd is in
+	 * nonblocking mode.
+	 */
+	lx_syslog("Flushing one input message from <file descriptor "
+	    "%d/transport %s>", fd, nconf->nc_proto);
+
+	/*
+	 * Read and discard the message. Do this this until there is
+	 * no more control/data in the message or until we get an error.
+	 */
+	do {
+		ctl->maxlen = sizeof (ctlbuf);
+		ctl->buf = ctlbuf;
+		data->maxlen = sizeof (databuf);
+		data->buf = databuf;
+		flags = 0;
+		ret = getmsg(fd, ctl, data, &flags);
+		if (ret == -1)
+			return (errno);
+	} while (ret != 0);
+
+	return (0);
+}
+
+static void
+conn_close_oldest(void)
+{
+	int fd;
+	int i1;
+
+	/*
+	 * Find the oldest connection that is not already in the
+	 * process of shutting down.
+	 */
+	for (i1 = end_listen_fds; /* no conditional expression */; i1++) {
+		if (i1 >= num_fds)
+			return;
+		if (conn_polled[i1].closing == 0)
+			break;
+	}
+	lx_syslog("too many connections (%d), releasing oldest (%d)",
+	    num_conns, poll_array[i1].fd);
+	fd = poll_array[i1].fd;
+	if (conn_polled[i1].nc.nc_semantics == NC_TPI_COTS) {
+		/*
+		 * For politeness, send a T_DISCON_REQ to the transport
+		 * provider.  We close the stream anyway.
+		 */
+		(void) t_snddis(fd, (struct t_call *)0);
+		num_conns--;
+		remove_from_poll_list(fd);
+		(void) t_close(fd);
+	} else {
+		/*
+		 * For orderly release, we do not close the stream
+		 * until the T_ORDREL_IND arrives to complete
+		 * the handshake.
+		 */
+		if (t_sndrel(fd) == 0)
+			conn_polled[i1].closing = 1;
+	}
+}
+
+static boolean_t
+conn_get(int fd, struct netconfig *nconf, struct conn_ind **connp)
+{
+	struct conn_ind	*conn;
+	struct conn_ind	*next_conn;
+
+	conn = (struct conn_ind *)malloc(sizeof (*conn));
+	if (conn == NULL) {
+		lx_syslog("malloc for listen indication failed");
+		return (FALSE);
+	}
+
+	/* LINTED pointer alignment */
+	conn->conn_call = (struct t_call *)t_alloc(fd, T_CALL, T_ALL);
+	if (conn->conn_call == NULL) {
+		free((char *)conn);
+		nfslib_log_tli_error("t_alloc", fd, nconf);
+		return (FALSE);
+	}
+
+	if (t_listen(fd, conn->conn_call) == -1) {
+		nfslib_log_tli_error("t_listen", fd, nconf);
+		(void) t_free((char *)conn->conn_call, T_CALL);
+		free((char *)conn);
+		return (FALSE);
+	}
+
+	if (conn->conn_call->udata.len > 0) {
+		lx_syslog("rejecting inbound connection(%s) with %d bytes of "
+		    "connect data", nconf->nc_proto,
+		    conn->conn_call->udata.len);
+
+		conn->conn_call->udata.len = 0;
+		(void) t_snddis(fd, conn->conn_call);
+		(void) t_free((char *)conn->conn_call, T_CALL);
+		free((char *)conn);
+		return (FALSE);
+	}
+
+	if ((next_conn = *connp) != NULL) {
+		next_conn->conn_prev->conn_next = conn;
+		conn->conn_next = next_conn;
+		conn->conn_prev = next_conn->conn_prev;
+		next_conn->conn_prev = conn;
+	} else {
+		conn->conn_next = conn;
+		conn->conn_prev = conn;
+		*connp = conn;
+	}
+	return (TRUE);
+}
+
+static int
+discon_get(int fd, struct netconfig *nconf, struct conn_ind **connp)
+{
+	struct conn_ind	*conn;
+	struct t_discon	discon;
+
+	discon.udata.buf = (char *)0;
+	discon.udata.maxlen = 0;
+	if (t_rcvdis(fd, &discon) == -1) {
+		nfslib_log_tli_error("t_rcvdis", fd, nconf);
+		return (-1);
+	}
+
+	conn = *connp;
+	if (conn == NULL)
+		return (0);
+
+	do {
+		if (conn->conn_call->sequence == discon.sequence) {
+			if (conn->conn_next == conn)
+				*connp = (struct conn_ind *)0;
+			else {
+				if (conn == *connp) {
+					*connp = conn->conn_next;
+				}
+				conn->conn_next->conn_prev = conn->conn_prev;
+				conn->conn_prev->conn_next = conn->conn_next;
+			}
+			free((char *)conn);
+			break;
+		}
+		conn = conn->conn_next;
+	} while (conn != *connp);
+
+	return (0);
+}
+
+static void
+cots_listen_event(int fd, int conn_index)
+{
+	struct t_call *call;
+	struct conn_ind	*conn;
+	struct conn_ind	*conn_head;
+	int event;
+	struct netconfig *nconf = &conn_polled[conn_index].nc;
+	int new_fd;
+	struct netbuf addrmask;
+	int ret = 0;
+	char *clnt;
+	char *clnt_uaddr = NULL;
+	struct nd_hostservlist *clnt_serv = NULL;
+
+	conn_head = NULL;
+	(void) conn_get(fd, nconf, &conn_head);
+
+	while ((conn = conn_head) != NULL) {
+		conn_head = conn->conn_next;
+		if (conn_head == conn)
+			conn_head = NULL;
+		else {
+			conn_head->conn_prev = conn->conn_prev;
+			conn->conn_prev->conn_next = conn_head;
+		}
+		call = conn->conn_call;
+		free(conn);
+
+		/*
+		 * If we have already accepted the maximum number of
+		 * connections allowed on the command line, then drop
+		 * the oldest connection (for any protocol) before
+		 * accepting the new connection.  Unless explicitly
+		 * set on the command line, max_conns_allowed is -1.
+		 */
+		if (max_conns_allowed != -1 && num_conns >= max_conns_allowed)
+			conn_close_oldest();
+
+		/*
+		 * Create a new transport endpoint for the same proto as
+		 * the listener.
+		 */
+		new_fd = lx_nfslib_transport_open(nconf);
+		if (new_fd == -1) {
+			call->udata.len = 0;
+			(void) t_snddis(fd, call);
+			(void) t_free((char *)call, T_CALL);
+			lx_syslog("Cannot establish transport over %s",
+			    nconf->nc_device);
+			continue;
+		}
+
+		/* Bind to a generic address/port for the accepting stream. */
+		if (t_bind(new_fd, NULL, NULL) == -1) {
+			nfslib_log_tli_error("t_bind", new_fd, nconf);
+			call->udata.len = 0;
+			(void) t_snddis(fd, call);
+			(void) t_free((char *)call, T_CALL);
+			(void) t_close(new_fd);
+			continue;
+		}
+
+		while (t_accept(fd, new_fd, call) == -1) {
+			if (t_errno != TLOOK) {
+				call->udata.len = 0;
+				(void) t_snddis(fd, call);
+				(void) t_free((char *)call, T_CALL);
+				(void) t_close(new_fd);
+				goto do_next_conn;
+			}
+			while ((event = t_look(fd)) != 0) {
+				switch (event) {
+				case T_LISTEN:
+					(void) conn_get(fd, nconf, &conn_head);
+					continue;
+				case T_DISCONNECT:
+					(void) discon_get(fd, nconf,
+					    &conn_head);
+					continue;
+				default:
+					lx_syslog("unexpected event 0x%x "
+					    "during accept processing (%s)",
+					    event, nconf->nc_proto);
+					call->udata.len = 0;
+					(void) t_snddis(fd, call);
+					(void) t_free((char *)call, T_CALL);
+					(void) t_close(new_fd);
+					goto do_next_conn;
+				}
+			}
+		}
+
+		if (set_addrmask(new_fd, nconf, &addrmask) < 0) {
+			lx_syslog("Cannot set address mask for %s",
+			    nconf->nc_netid);
+			(void) t_snddis(new_fd, NULL);
+			(void) t_free((char *)call, T_CALL);
+			(void) t_close(new_fd);
+			continue;
+		}
+
+		/* Tell kRPC about the new stream. */
+		ret = nlmsvc(new_fd, addrmask, nconf);
+
+		if (ret < 0) {
+			if (errno != ENOTCONN) {
+				lx_syslog("unable to register new connection: "
+				    "%m");
+			} else {
+				/*
+				 * This is the only error that could be
+				 * caused by the client, so who was it?
+				 */
+				if (netdir_getbyaddr(nconf, &clnt_serv,
+				    &(call->addr)) == ND_OK &&
+				    clnt_serv->h_cnt > 0) {
+					clnt = clnt_serv->h_hostservs->h_host;
+				} else {
+					clnt = clnt_uaddr = taddr2uaddr(nconf,
+					    &(call->addr));
+				}
+				/*
+				 * If we don't know who the client was,
+				 * remain silent.
+				 */
+				if (clnt)
+					lx_syslog("unable to register new "
+					    "connection: client %s has dropped "
+					    "connection", clnt);
+				if (clnt_serv) {
+					netdir_free(clnt_serv, ND_HOSTSERVLIST);
+					clnt_serv = NULL;
+				}
+				if (clnt_uaddr) {
+					free(clnt_uaddr);
+					clnt_uaddr = NULL;
+				}
+			}
+			free(addrmask.buf);
+			(void) t_snddis(new_fd, NULL);
+			(void) t_free((char *)call, T_CALL);
+			(void) t_close(new_fd);
+			goto do_next_conn;
+		}
+
+		free(addrmask.buf);
+		(void) t_free((char *)call, T_CALL);
+
+		/*
+		 * Poll on the new descriptor so that we get disconnect
+		 * and orderly release indications.
+		 */
+		num_conns++;
+		add_to_poll_list(new_fd, nconf);
+
+		/* Reset nconf in case it has been moved. */
+		nconf = &conn_polled[conn_index].nc;
+do_next_conn:;
+	}
+}
+
+static int
+do_poll_cots_action(int fd, int conn_index)
+{
+	char buf[256];
+	int event;
+	int i1;
+	int flags;
+	struct conn_entry *connent = &conn_polled[conn_index];
+	struct netconfig *nconf = &(connent->nc);
+	const char *errorstr;
+
+	while ((event = t_look(fd)) != 0) {
+		switch (event) {
+		case T_LISTEN:
+			cots_listen_event(fd, conn_index);
+			break;
+
+		case T_DATA:
+			/*
+			 * Receive a private notification from CONS rpcmod.
+			 */
+			i1 = t_rcv(fd, buf, sizeof (buf), &flags);
+			if (i1 == -1) {
+				lx_syslog("t_rcv failed");
+				break;
+			}
+			if (i1 < sizeof (int))
+				break;
+			i1 = BE32_TO_U32(buf);
+			if (i1 == 1 || i1 == 2) {
+				/*
+				 * This connection has been idle for too long,
+				 * so release it as politely as we can.  If we
+				 * have already initiated an orderly release
+				 * and we get notified that the stream is
+				 * still idle, pull the plug.  This prevents
+				 * hung connections from continuing to consume
+				 * resources.
+				 */
+				if (nconf->nc_semantics == NC_TPI_COTS ||
+				    connent->closing != 0) {
+					(void) t_snddis(fd, (struct t_call *)0);
+					goto fdclose;
+				}
+				/*
+				 * For NC_TPI_COTS_ORD, the stream is closed
+				 * and removed from the poll list when the
+				 * T_ORDREL is received from the provider.  We
+				 * don't wait for it here because it may take
+				 * a while for the transport to shut down.
+				 */
+				if (t_sndrel(fd) == -1) {
+					lx_syslog("unable to send orderly "
+					    "release %m");
+				}
+				connent->closing = 1;
+			} else
+				lx_syslog("unexpected event from CONS rpcmod "
+				    "%d", i1);
+			break;
+
+		case T_ORDREL:
+			/* Perform an orderly release. */
+			if (t_rcvrel(fd) == 0) {
+				/* T_ORDREL on listen fd's should be ignored */
+				if (!is_listen_fd_index(conn_index)) {
+					(void) t_sndrel(fd);
+					goto fdclose;
+				}
+				break;
+
+			} else if (t_errno == TLOOK) {
+				break;
+			} else {
+				nfslib_log_tli_error("t_rcvrel", fd, nconf);
+
+				/*
+				 * check to make sure we do not close
+				 * listen fd
+				 */
+				if (is_listen_fd_index(conn_index))
+					break;
+				else
+					goto fdclose;
+			}
+
+		case T_DISCONNECT:
+			if (t_rcvdis(fd, (struct t_discon *)NULL) == -1)
+				nfslib_log_tli_error("t_rcvdis", fd, nconf);
+
+			/*
+			 * T_DISCONNECT on listen fd's should be ignored.
+			 */
+			if (is_listen_fd_index(conn_index))
+				break;
+			else
+				goto fdclose;
+
+		default:
+			if (t_errno == TSYSERR) {
+				if ((errorstr = strerror(errno)) == NULL) {
+					(void) sprintf(buf,
+					    "Unknown error num %d", errno);
+					errorstr = (const char *) buf;
+				}
+			} else if (event == -1)
+				errorstr = t_strerror(t_errno);
+			else
+				errorstr = "";
+			lx_syslog("unexpected TLI event (0x%x) on "
+			    "connection-oriented transport(%s,%d):%s",
+			    event, nconf->nc_proto, fd, errorstr);
+fdclose:
+			num_conns--;
+			remove_from_poll_list(fd);
+			(void) t_close(fd);
+			return (0);
+		}
+	}
+
+	return (0);
+}
+
+static int
+bind_to_provider(char *provider, struct netbuf **addr,
+    struct netconfig **retnconf)
+{
+	int i;
+	struct netconfig *nconf = NULL, *np;
+
+	for (i = 0; i < N_NETCONF_ENTS; i++) {
+		np = &nca[i];
+
+		if (strcmp(np->nc_device, provider) != 0)
+			continue;
+
+		/* Construct our own netconfig */
+		if ((nconf = calloc(1, sizeof (struct netconfig))) == NULL)
+			goto out;
+
+		nconf->nc_semantics = np->nc_semantics;
+		if ((nconf->nc_netid = strdup(np->nc_netid)) == NULL)
+			goto out;
+		if ((nconf->nc_protofmly = strdup(np->nc_protofmly)) == NULL)
+			goto out;
+		if ((nconf->nc_proto = strdup(np->nc_proto)) == NULL)
+			goto out;
+		if ((nconf->nc_device = strdup(np->nc_device)) == NULL)
+			goto out;
+
+		*retnconf = nconf;
+
+		/*
+		 * Passing addr == NULL implies we skip the bind since we only
+		 * need the netconfig for unregistering from rpcbind.
+		 */
+		if (addr == NULL)
+			return (0);
+		return (lx_nfslib_bindit(nconf, addr, listen_backlog));
+	}
+
+out:
+	if (nconf != NULL)
+		freenetconfigent(nconf);
+	lx_syslog("couldn't find netconfig entry for provider %s", provider);
+	return (-1);
+}
+
+#include <netinet/in.h>
+
+/*
+ * Create an address mask appropriate for the transport.
+ * The mask is used to obtain the host-specific part of
+ * a network address when comparing addresses.
+ * For an internet address the host-specific part is just
+ * the 32 bit IP address and this part of the mask is set
+ * to all-ones. The port number part of the mask is zeroes.
+ */
+static int
+set_addrmask(int fd, struct netconfig *nconf, struct netbuf *mask)
+{
+	struct t_info info;
+
+	/*
+	 * Find the size of the address we need to mask.
+	 */
+	if (t_getinfo(fd, &info) < 0) {
+		t_error("t_getinfo");
+		return (-1);
+	}
+	mask->len = mask->maxlen = info.addr;
+	if (info.addr <= 0) {
+		/*
+		 * loopback devices have infinite addr size
+		 * (it is identified by -1 in addr field of t_info structure),
+		 * so don't build the netmask for them. It's a special case
+		 * that should be handled properly.
+		 */
+		if ((info.addr == -1) &&
+		    (0 == strcmp(nconf->nc_protofmly, NC_LOOPBACK))) {
+			(void) memset(mask, 0, sizeof (*mask));
+			return (0);
+		}
+
+		lx_syslog("set_addrmask: address size: %ld", info.addr);
+		return (-1);
+	}
+
+	mask->buf = (char *)malloc(mask->len);
+	if (mask->buf == NULL) {
+		lx_syslog("set_addrmask: no memory");
+		return (-1);
+	}
+	(void) memset(mask->buf, 0, mask->len);	/* reset all mask bits */
+
+	if (strcmp(nconf->nc_protofmly, NC_INET) == 0) {
+		/*
+		 * Set the mask so that the port is ignored.
+		 */
+		/* LINTED pointer alignment */
+		((struct sockaddr_in *)mask->buf)->sin_addr.s_addr =
+		    (ulong_t)~0;
+		/* LINTED pointer alignment */
+		((struct sockaddr_in *)mask->buf)->sin_family =
+		    (ushort_t)~0;
+	} else if (strcmp(nconf->nc_protofmly, NC_INET6) == 0) {
+		/* LINTED pointer alignment */
+		(void) memset(&((struct sockaddr_in6 *)mask->buf)->sin6_addr,
+		    (uchar_t)~0, sizeof (struct in6_addr));
+		/* LINTED pointer alignment */
+		((struct sockaddr_in6 *)mask->buf)->sin6_family =
+		    (ushort_t)~0;
+	} else {
+
+		/*
+		 * Set all mask bits.
+		 */
+		(void) memset(mask->buf, 0xFF, mask->len);
+	}
+	return (0);
+}
+
+/*
+ * For listen fd's index is always less than end_listen_fds.
+ * end_listen_fds is defined externally in the daemon that uses this library.
+ * It's value is equal to the number of open file descriptors after the
+ * last listen end point was opened but before any connection was accepted.
+ */
+static int
+is_listen_fd_index(int index)
+{
+	return (index < end_listen_fds);
+}
diff --git a/usr/src/lib/brand/lx/zone/platform.xml b/usr/src/lib/brand/lx/zone/platform.xml
index cf905b3f69..060343e38f 100644
--- a/usr/src/lib/brand/lx/zone/platform.xml
+++ b/usr/src/lib/brand/lx/zone/platform.xml
@@ -90,6 +90,7 @@
 	<device match="signalfd" />
 	<device match="tcp" />
 	<device match="tcp6" />
+	<device match="ticotsord" />
 	<device match="timerfd" />
 	<device match="tty" />
 	<device match="udp" />
-- 
2.21.0

