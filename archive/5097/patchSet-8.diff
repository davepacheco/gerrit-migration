commit d0462cf3813eeea5a21df46439e5a77831156236
Author: Isaac Davis <isaac.davis@joyent.com>
Date:   2019-01-04T00:08:29+00:00 (9 months ago)
    
    MANTA-3992 create Manta Grafana image

diff --git a/.eslintrc b/.eslintrc
new file mode 100644
index 0000000..e287518
--- /dev/null
+++ b/.eslintrc
@@ -0,0 +1,25 @@
+{
+	"plugins": [ "joyent" ],
+	"extends": [
+		"eslint:recommended",
+		"plugin:joyent/style",
+		"plugin:joyent/lint"
+	],
+	"parserOptions": {
+		"ecmaVersion": 6,
+		"sourceType": "script",
+		"ecmaFeatures": {
+		}
+	},
+	"env": {
+		"node": true
+	},
+	"rules": {
+		// Lint:
+		"strict": [ "error", "global" ],
+
+		// Style:
+		"func-style": [ "error", "declaration" ],
+		"multiline-comment-style": [ "error", "starred-block" ]
+	}
+}
\ No newline at end of file
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..9f6256d
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,7 @@
+/tmp
+/node_modules
+/make_stamps
+/npm-debug.log
+/cache
+/build
+/grafana-pkg-*.tar.bz2
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..6dd9dc2
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,9 @@
+[submodule "deps/sdc-scripts"]
+	path = deps/sdc-scripts
+	url = https://github.com/joyent/sdc-scripts
+[submodule "deps/nginx"]
+	path = deps/nginx
+	url = https://github.com/nginx/nginx
+[submodule "deps/grafana"]
+	path = deps/grafana
+	url = https://github.com/joyent/grafana
diff --git a/CHANGES.md b/CHANGES.md
new file mode 100644
index 0000000..eaff0d1
--- /dev/null
+++ b/CHANGES.md
@@ -0,0 +1,5 @@
+# triton-grafana changes
+
+## 1.0.0
+
+First version.
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
new file mode 100644
index 0000000..fbd7764
--- /dev/null
+++ b/CONTRIBUTING.md
@@ -0,0 +1,73 @@
+<!--
+    This Source Code Form is subject to the terms of the Mozilla Public
+    License, v. 2.0. If a copy of the MPL was not distributed with this
+    file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+    Copyright 2017 Joyent, Inc.
+-->
+
+# Triton Contribution Guidelines
+
+Thanks for using Triton and for considering contributing to it!
+
+tl;dr:
+- Triton repos do *not* use GitHub pull requests (PRs)! You'll be asked to
+  re-submit PRs to Gerrit. See below.
+- Triton repos use both GitHub issues and internal-to-Joyent Jira projects for
+  issue tracking.
+
+
+## Code
+
+The Triton project uses Gerrit at [cr.joyent.us](https://cr.joyent.us) for code
+review of all changes. Any registered GitHub user can submit changes through
+this system. If you want to contribute a change, please see the [Joyent Gerrit
+user
+guide](https://github.com/joyent/joyent-gerrit/blob/master/docs/user/README.md).
+If you're making a substantial change, you probably want to contact developers
+[on the mailing list or IRC](README.md#community) first. If you have any trouble
+with the contribution process, please feel free to contact developers [on the
+mailing list or IRC](README.md#community). Note that larger Triton project
+changes are typically designed and discussed via ["Requests for Discussion
+(RFDs)"](https://github.com/joyent/rfd).
+
+Triton repositories use the [Joyent Engineering
+Guidelines](https://github.com/joyent/eng/blob/master/docs/index.md). Notably:
+
+* The #master branch should be first-customer-ship (FCS) quality at all times.
+  Don't push anything until it's tested.
+* All repositories should be "make check" clean at all times.
+* All repositories should have tests that run cleanly at all times.
+
+"make check" checks both JavaScript style and lint.  Style is checked with
+[jsstyle](https://github.com/davepacheco/jsstyle).  The specific style rules are
+somewhat repo-specific.  See the jsstyle configuration file or `JSSTYLE_FLAGS`
+in Makefiles in each repo for exceptions to the default jsstyle rules.
+
+Lint is checked with
+[javascriptlint](https://github.com/davepacheco/javascriptlint). Repos sometimes
+have repo-specific lint rules, but this is less common -- look for
+"tools/jsl.node.conf" for per-repo exceptions to the default rules.
+
+
+## Issues
+
+There are two separate issue trackers that are relevant for Triton code:
+
+- An internal-to-Joyent JIRA instance.
+
+  A JIRA ticket has an ID like `IMGAPI-536`, where "IMGAPI" is the JIRA project
+  name -- in this case used by the
+  [sdc-imgapi](https://github.com/joyent/sdc-imgapi) and related repos. A
+  read-only view of most JIRA tickets is made available at
+  <https://smartos.org/bugview/> (e.g.
+  <https://smartos.org/bugview/IMGAPI-536>).
+
+- GitHub issues for the relevant repo, e.g.
+  <https://github.com/joyent/triton/issues>.
+
+Before Triton was open sourced, Joyent engineering used a private JIRA instance.
+While Joyent continues to use JIRA internally, we also use GitHub issues for
+tracking -- primarily to allow interaction with those without access to JIRA.
diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..14e2f77
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,373 @@
+Mozilla Public License Version 2.0
+==================================
+
+1. Definitions
+--------------
+
+1.1. "Contributor"
+    means each individual or legal entity that creates, contributes to
+    the creation of, or owns Covered Software.
+
+1.2. "Contributor Version"
+    means the combination of the Contributions of others (if any) used
+    by a Contributor and that particular Contributor's Contribution.
+
+1.3. "Contribution"
+    means Covered Software of a particular Contributor.
+
+1.4. "Covered Software"
+    means Source Code Form to which the initial Contributor has attached
+    the notice in Exhibit A, the Executable Form of such Source Code
+    Form, and Modifications of such Source Code Form, in each case
+    including portions thereof.
+
+1.5. "Incompatible With Secondary Licenses"
+    means
+
+    (a) that the initial Contributor has attached the notice described
+        in Exhibit B to the Covered Software; or
+
+    (b) that the Covered Software was made available under the terms of
+        version 1.1 or earlier of the License, but not also under the
+        terms of a Secondary License.
+
+1.6. "Executable Form"
+    means any form of the work other than Source Code Form.
+
+1.7. "Larger Work"
+    means a work that combines Covered Software with other material, in 
+    a separate file or files, that is not Covered Software.
+
+1.8. "License"
+    means this document.
+
+1.9. "Licensable"
+    means having the right to grant, to the maximum extent possible,
+    whether at the time of the initial grant or subsequently, any and
+    all of the rights conveyed by this License.
+
+1.10. "Modifications"
+    means any of the following:
+
+    (a) any file in Source Code Form that results from an addition to,
+        deletion from, or modification of the contents of Covered
+        Software; or
+
+    (b) any new file in Source Code Form that contains any Covered
+        Software.
+
+1.11. "Patent Claims" of a Contributor
+    means any patent claim(s), including without limitation, method,
+    process, and apparatus claims, in any patent Licensable by such
+    Contributor that would be infringed, but for the grant of the
+    License, by the making, using, selling, offering for sale, having
+    made, import, or transfer of either its Contributions or its
+    Contributor Version.
+
+1.12. "Secondary License"
+    means either the GNU General Public License, Version 2.0, the GNU
+    Lesser General Public License, Version 2.1, the GNU Affero General
+    Public License, Version 3.0, or any later versions of those
+    licenses.
+
+1.13. "Source Code Form"
+    means the form of the work preferred for making modifications.
+
+1.14. "You" (or "Your")
+    means an individual or a legal entity exercising rights under this
+    License. For legal entities, "You" includes any entity that
+    controls, is controlled by, or is under common control with You. For
+    purposes of this definition, "control" means (a) the power, direct
+    or indirect, to cause the direction or management of such entity,
+    whether by contract or otherwise, or (b) ownership of more than
+    fifty percent (50%) of the outstanding shares or beneficial
+    ownership of such entity.
+
+2. License Grants and Conditions
+--------------------------------
+
+2.1. Grants
+
+Each Contributor hereby grants You a world-wide, royalty-free,
+non-exclusive license:
+
+(a) under intellectual property rights (other than patent or trademark)
+    Licensable by such Contributor to use, reproduce, make available,
+    modify, display, perform, distribute, and otherwise exploit its
+    Contributions, either on an unmodified basis, with Modifications, or
+    as part of a Larger Work; and
+
+(b) under Patent Claims of such Contributor to make, use, sell, offer
+    for sale, have made, import, and otherwise transfer either its
+    Contributions or its Contributor Version.
+
+2.2. Effective Date
+
+The licenses granted in Section 2.1 with respect to any Contribution
+become effective for each Contribution on the date the Contributor first
+distributes such Contribution.
+
+2.3. Limitations on Grant Scope
+
+The licenses granted in this Section 2 are the only rights granted under
+this License. No additional rights or licenses will be implied from the
+distribution or licensing of Covered Software under this License.
+Notwithstanding Section 2.1(b) above, no patent license is granted by a
+Contributor:
+
+(a) for any code that a Contributor has removed from Covered Software;
+    or
+
+(b) for infringements caused by: (i) Your and any other third party's
+    modifications of Covered Software, or (ii) the combination of its
+    Contributions with other software (except as part of its Contributor
+    Version); or
+
+(c) under Patent Claims infringed by Covered Software in the absence of
+    its Contributions.
+
+This License does not grant any rights in the trademarks, service marks,
+or logos of any Contributor (except as may be necessary to comply with
+the notice requirements in Section 3.4).
+
+2.4. Subsequent Licenses
+
+No Contributor makes additional grants as a result of Your choice to
+distribute the Covered Software under a subsequent version of this
+License (see Section 10.2) or under the terms of a Secondary License (if
+permitted under the terms of Section 3.3).
+
+2.5. Representation
+
+Each Contributor represents that the Contributor believes its
+Contributions are its original creation(s) or it has sufficient rights
+to grant the rights to its Contributions conveyed by this License.
+
+2.6. Fair Use
+
+This License is not intended to limit any rights You have under
+applicable copyright doctrines of fair use, fair dealing, or other
+equivalents.
+
+2.7. Conditions
+
+Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted
+in Section 2.1.
+
+3. Responsibilities
+-------------------
+
+3.1. Distribution of Source Form
+
+All distribution of Covered Software in Source Code Form, including any
+Modifications that You create or to which You contribute, must be under
+the terms of this License. You must inform recipients that the Source
+Code Form of the Covered Software is governed by the terms of this
+License, and how they can obtain a copy of this License. You may not
+attempt to alter or restrict the recipients' rights in the Source Code
+Form.
+
+3.2. Distribution of Executable Form
+
+If You distribute Covered Software in Executable Form then:
+
+(a) such Covered Software must also be made available in Source Code
+    Form, as described in Section 3.1, and You must inform recipients of
+    the Executable Form how they can obtain a copy of such Source Code
+    Form by reasonable means in a timely manner, at a charge no more
+    than the cost of distribution to the recipient; and
+
+(b) You may distribute such Executable Form under the terms of this
+    License, or sublicense it under different terms, provided that the
+    license for the Executable Form does not attempt to limit or alter
+    the recipients' rights in the Source Code Form under this License.
+
+3.3. Distribution of a Larger Work
+
+You may create and distribute a Larger Work under terms of Your choice,
+provided that You also comply with the requirements of this License for
+the Covered Software. If the Larger Work is a combination of Covered
+Software with a work governed by one or more Secondary Licenses, and the
+Covered Software is not Incompatible With Secondary Licenses, this
+License permits You to additionally distribute such Covered Software
+under the terms of such Secondary License(s), so that the recipient of
+the Larger Work may, at their option, further distribute the Covered
+Software under the terms of either this License or such Secondary
+License(s).
+
+3.4. Notices
+
+You may not remove or alter the substance of any license notices
+(including copyright notices, patent notices, disclaimers of warranty,
+or limitations of liability) contained within the Source Code Form of
+the Covered Software, except that You may alter any license notices to
+the extent required to remedy known factual inaccuracies.
+
+3.5. Application of Additional Terms
+
+You may choose to offer, and to charge a fee for, warranty, support,
+indemnity or liability obligations to one or more recipients of Covered
+Software. However, You may do so only on Your own behalf, and not on
+behalf of any Contributor. You must make it absolutely clear that any
+such warranty, support, indemnity, or liability obligation is offered by
+You alone, and You hereby agree to indemnify every Contributor for any
+liability incurred by such Contributor as a result of warranty, support,
+indemnity or liability terms You offer. You may include additional
+disclaimers of warranty and limitations of liability specific to any
+jurisdiction.
+
+4. Inability to Comply Due to Statute or Regulation
+---------------------------------------------------
+
+If it is impossible for You to comply with any of the terms of this
+License with respect to some or all of the Covered Software due to
+statute, judicial order, or regulation then You must: (a) comply with
+the terms of this License to the maximum extent possible; and (b)
+describe the limitations and the code they affect. Such description must
+be placed in a text file included with all distributions of the Covered
+Software under this License. Except to the extent prohibited by statute
+or regulation, such description must be sufficiently detailed for a
+recipient of ordinary skill to be able to understand it.
+
+5. Termination
+--------------
+
+5.1. The rights granted under this License will terminate automatically
+if You fail to comply with any of its terms. However, if You become
+compliant, then the rights granted under this License from a particular
+Contributor are reinstated (a) provisionally, unless and until such
+Contributor explicitly and finally terminates Your grants, and (b) on an
+ongoing basis, if such Contributor fails to notify You of the
+non-compliance by some reasonable means prior to 60 days after You have
+come back into compliance. Moreover, Your grants from a particular
+Contributor are reinstated on an ongoing basis if such Contributor
+notifies You of the non-compliance by some reasonable means, this is the
+first time You have received notice of non-compliance with this License
+from such Contributor, and You become compliant prior to 30 days after
+Your receipt of the notice.
+
+5.2. If You initiate litigation against any entity by asserting a patent
+infringement claim (excluding declaratory judgment actions,
+counter-claims, and cross-claims) alleging that a Contributor Version
+directly or indirectly infringes any patent, then the rights granted to
+You by any and all Contributors for the Covered Software under Section
+2.1 of this License shall terminate.
+
+5.3. In the event of termination under Sections 5.1 or 5.2 above, all
+end user license agreements (excluding distributors and resellers) which
+have been validly granted by You or Your distributors under this License
+prior to termination shall survive termination.
+
+************************************************************************
+*                                                                      *
+*  6. Disclaimer of Warranty                                           *
+*  -------------------------                                           *
+*                                                                      *
+*  Covered Software is provided under this License on an "as is"       *
+*  basis, without warranty of any kind, either expressed, implied, or  *
+*  statutory, including, without limitation, warranties that the       *
+*  Covered Software is free of defects, merchantable, fit for a        *
+*  particular purpose or non-infringing. The entire risk as to the     *
+*  quality and performance of the Covered Software is with You.        *
+*  Should any Covered Software prove defective in any respect, You     *
+*  (not any Contributor) assume the cost of any necessary servicing,   *
+*  repair, or correction. This disclaimer of warranty constitutes an   *
+*  essential part of this License. No use of any Covered Software is   *
+*  authorized under this License except under this disclaimer.         *
+*                                                                      *
+************************************************************************
+
+************************************************************************
+*                                                                      *
+*  7. Limitation of Liability                                          *
+*  --------------------------                                          *
+*                                                                      *
+*  Under no circumstances and under no legal theory, whether tort      *
+*  (including negligence), contract, or otherwise, shall any           *
+*  Contributor, or anyone who distributes Covered Software as          *
+*  permitted above, be liable to You for any direct, indirect,         *
+*  special, incidental, or consequential damages of any character      *
+*  including, without limitation, damages for lost profits, loss of    *
+*  goodwill, work stoppage, computer failure or malfunction, or any    *
+*  and all other commercial damages or losses, even if such party      *
+*  shall have been informed of the possibility of such damages. This   *
+*  limitation of liability shall not apply to liability for death or   *
+*  personal injury resulting from such party's negligence to the       *
+*  extent applicable law prohibits such limitation. Some               *
+*  jurisdictions do not allow the exclusion or limitation of           *
+*  incidental or consequential damages, so this exclusion and          *
+*  limitation may not apply to You.                                    *
+*                                                                      *
+************************************************************************
+
+8. Litigation
+-------------
+
+Any litigation relating to this License may be brought only in the
+courts of a jurisdiction where the defendant maintains its principal
+place of business and such litigation shall be governed by laws of that
+jurisdiction, without reference to its conflict-of-law provisions.
+Nothing in this Section shall prevent a party's ability to bring
+cross-claims or counter-claims.
+
+9. Miscellaneous
+----------------
+
+This License represents the complete agreement concerning the subject
+matter hereof. If any provision of this License is held to be
+unenforceable, such provision shall be reformed only to the extent
+necessary to make it enforceable. Any law or regulation which provides
+that the language of a contract shall be construed against the drafter
+shall not be used to construe this License against a Contributor.
+
+10. Versions of the License
+---------------------------
+
+10.1. New Versions
+
+Mozilla Foundation is the license steward. Except as provided in Section
+10.3, no one other than the license steward has the right to modify or
+publish new versions of this License. Each version will be given a
+distinguishing version number.
+
+10.2. Effect of New Versions
+
+You may distribute the Covered Software under the terms of the version
+of the License under which You originally received the Covered Software,
+or under the terms of any subsequent version published by the license
+steward.
+
+10.3. Modified Versions
+
+If you create software not governed by this License, and you want to
+create a new license for such software, you may create and use a
+modified version of this License if you rename the license and remove
+any references to the name of the license steward (except to note that
+such modified license differs from this License).
+
+10.4. Distributing Source Code Form that is Incompatible With Secondary
+Licenses
+
+If You choose to distribute Source Code Form that is Incompatible With
+Secondary Licenses under the terms of this version of the License, the
+notice described in Exhibit B of this License must be attached.
+
+Exhibit A - Source Code Form License Notice
+-------------------------------------------
+
+  This Source Code Form is subject to the terms of the Mozilla Public
+  License, v. 2.0. If a copy of the MPL was not distributed with this
+  file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+If it is not possible or desirable to put the notice in a particular
+file, then You may include the notice in a location (such as a LICENSE
+file in a relevant directory) where a recipient would be likely to look
+for such a notice.
+
+You may add additional accurate notices of copyright ownership.
+
+Exhibit B - "Incompatible With Secondary Licenses" Notice
+---------------------------------------------------------
+
+  This Source Code Form is "Incompatible With Secondary Licenses", as
+  defined by the Mozilla Public License, v. 2.0.
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..fcdae6b
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,195 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+SHELL := bash
+
+GO_PREBUILT_VERSION = 1.11.1
+NODE_PREBUILT_VERSION = v6.15.1
+
+JS_FILES := $(wildcard lib/*.js) $(wildcard test/*.js)
+ESLINT_FILES := $(JS_FILES)
+
+ifeq ($(shell uname -s),SunOS)
+    # We use a 64-bit node because grafana will not build with 32-bit node 6
+    NODE_PREBUILT_TAG=zone64
+    # Allow building on other than minimal-multiarch@18.1.0
+    NODE_PREBUILT_IMAGE=1ad363ec-3b83-11e8-8521-2f68a4a34d5d
+endif
+
+include ./tools/mk/Makefile.defs
+include ./tools/mk/Makefile.smf.defs
+
+ifeq ($(shell uname -s),SunOS)
+    include ./tools/mk/Makefile.go_prebuilt.defs
+    include ./tools/mk/Makefile.node_prebuilt.defs
+endif
+
+include ./tools/mk/Makefile.nginx.defs
+
+SERVICE_NAME = grafana
+RELEASE_TARBALL := $(SERVICE_NAME)-pkg-$(STAMP).tar.bz2
+RELSTAGEDIR := /tmp/$(STAMP)
+SMF_MANIFESTS = $(wildcard smf/manifests/*.xml)
+
+GRAFANA_IMPORT = github.com/grafana/grafana
+GRAFANA_GO_DIR = $(GO_GOPATH)/src/$(GRAFANA_IMPORT)
+GRAFANA_EXEC = $(GO_GOPATH)/bin/grafana-server
+
+STAMP_YARN := $(MAKE_STAMPS_DIR)/yarn
+STAMP_PROXY := $(MAKE_STAMPS_DIR)/graf-proxy
+
+YARN = PATH=$(TOP)/$(NODE_INSTALL)/bin:$(PATH) $(NODE) \
+    $(TOP)/$(CACHE_DIR)/yarn/node_modules/.bin/yarn
+
+#
+# Repo-specific targets
+#
+.PHONY: all
+all: $(GRAFANA_EXEC) $(NGINX_EXEC) $(STAMP_PROXY)
+
+$(STAMP_YARN): | $(NODE_EXEC) $(NPM_EXEC)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf $(CACHE_DIR)/yarn
+	mkdir -p $(CACHE_DIR)/yarn/node_modules
+	cd $(CACHE_DIR)/yarn && $(NPM) install --global-style yarn
+	$(MAKE_STAMP_CREATE)
+
+#
+# Link the "pg_prefaulter" submodule into the correct place within our
+# project-local GOPATH, then build the binary.
+#
+$(GRAFANA_EXEC): deps/grafana/.git $(STAMP_GO_TOOLCHAIN) $(STAMP_YARN)
+	$(GO) version
+	mkdir -p $(dir $(GRAFANA_GO_DIR))
+	mkdir -p $(CACHE_DIR)/yarn
+	rm -f $(GRAFANA_GO_DIR)
+	cp -r $(TOP)/deps/grafana $(GRAFANA_GO_DIR)
+	(cd $(GRAFANA_GO_DIR) && \
+	    env -i $(GO_ENV) $(GO) run build.go setup && \
+	    env -i $(GO_ENV) $(GO) run build.go build && \
+	    $(YARN) install --pure-lockfile && \
+	    $(YARN) dev)
+
+$(STAMP_PROXY): | $(NODE_EXEC) $(NPM_EXEC)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf $(TOP)/node_modules && cd $(TOP) && $(NPM) install --production
+	$(MAKE_STAMP_CREATE)
+
+# Note that the current test suite is designed to run on an installed
+# triton-grafana image, which will not contain this Makefile. Thus, unless this
+# Makefile and its associated dependencies under "tools/mk" are manually copied
+# to an installed image, `make test` will never do anything useful in any place
+# where this Makefile exists. This could change in the future.
+#
+# Instead, it is sufficient to directly run `/opt/triton/grafana/test/runtests`
+# in the installed image.
+.PHONY: test
+test:
+	@# We check for the existence of the graf-proxy directory as a way of
+	@# ascertaining whether we are in a dev or installation environment.
+	@if [[ -f "$(TOP)/proxy" ]]; then \
+		./test/runtests; \
+	else \
+		echo "Skipping tests: this is not an installation environment."; \
+	fi
+
+#
+# The eng.git makefiles define the clean target using a :: rule. This
+# means that we're allowed to have multiple bodies that define the rule
+# and they should all take effect. We ignore the return value from the
+# recursive make clean because there is no guarantee that there's a
+# generated Makefile or that the nginx submodule has been initialized
+# and checked out.
+#
+clean:: $(STAMP_GO_TOOLCHAIN) deps/nginx/Makefile
+	# Clean Grafana backend
+	cd $(TOP)/deps/grafana env -i $(GO_ENV) $(GO) run build.go clean
+	# Clean Grafana frontend
+	rm -rf $(TOP)/deps/grafana/node_modules
+	rm -rf $(TOP)/deps/grafana/public/build
+	# Clean Nginx
+	-(cd $(TOP)/deps/nginx && $(MAKE) clean)
+	# Clean graf-proxy
+	rm -rf $(TOP)/node_modules
+
+.PHONY: release
+release: all deps docs $(SMF_MANIFESTS)
+	@echo "Building $(RELEASE_TARBALL)"
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)
+	cp -r \
+		$(TOP)/config_templates \
+		$(TOP)/dashboards \
+		$(TOP)/package.json \
+		$(TOP)/node_modules \
+		$(TOP)/smf \
+		$(TOP)/sapi_manifests \
+		$(TOP)/test \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/
+	# our grafana build
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/grafana
+	cp -r \
+		$(GRAFANA_GO_DIR)/bin \
+		$(GRAFANA_GO_DIR)/conf \
+		$(GRAFANA_GO_DIR)/public \
+		$(GRAFANA_GO_DIR)/scripts \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/grafana/
+	# grafana auth proxy
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/proxy
+	cp -r \
+		$(TOP)/lib \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/proxy
+	# nginx
+	cp -r \
+		$(TOP)/build/nginx \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/
+	# nginx config
+	cp -r \
+		$(TOP)/config/nginx.conf \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/nginx/conf
+	# our node version
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/build
+	cp -r \
+		$(TOP)/build/node \
+		$(RELSTAGEDIR)/root/opt/triton/$(SERVICE_NAME)/build/
+	# zone boot
+	mkdir -p $(RELSTAGEDIR)/root/opt/smartdc/boot
+	cp -r $(TOP)/deps/sdc-scripts/{etc,lib,sbin,smf} \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	cp -r $(TOP)/boot/* \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	# tar it up
+	(cd $(RELSTAGEDIR) && $(TAR) -jcf $(TOP)/$(RELEASE_TARBALL) root)
+	@rm -rf $(RELSTAGEDIR)
+
+.PHONY: publish
+publish: release
+	@if [[ -z "$(BITS_DIR)" ]]; then \
+		echo "error: 'BITS_DIR' must be set for 'publish' target"; \
+		exit 1; \
+	fi
+	mkdir -p $(BITS_DIR)/$(SERVICE_NAME)
+	cp $(TOP)/$(RELEASE_TARBALL) $(BITS_DIR)/$(SERVICE_NAME)/$(RELEASE_TARBALL)
+
+.PHONY: dumpvar
+dumpvar:
+	@if [[ -z "$(VAR)" ]]; then \
+		echo "error: set 'VAR' to dump a var"; \
+		exit 1; \
+	fi
+	@echo "$(VAR) is '$($(VAR))'"
+
+include ./tools/mk/Makefile.deps
+ifeq ($(shell uname -s),SunOS)
+    include ./tools/mk/Makefile.go_prebuilt.targ
+    include ./tools/mk/Makefile.node_prebuilt.targ
+endif
+include ./tools/mk/Makefile.smf.targ
+include ./tools/mk/Makefile.nginx.targ
+include ./tools/mk/Makefile.targ
diff --git a/README.md b/README.md
index 8dcb1c2..0914e64 100644
--- a/README.md
+++ b/README.md
@@ -1,19 +1,141 @@
-# Triton Metrics Dashboards
+<!--
+    This Source Code Form is subject to the terms of the Mozilla Public
+    License, v. 2.0. If a copy of the MPL was not distributed with this
+    file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
 
-A repo holding JSON dumps of common Grafana dashboards for monitoring Triton
-Data Center (a.k.a Triton) itself with a prometheus/grafana setup.
+<!--
+    Copyright (c) 2018, Joyent, Inc.
+-->
 
-The current goal is to have a shared place for possibly useful dashboards
-so we can build tooling around preloading a Grafana sourcing from a Prometheus
-setup to gather Triton core metrics from CMON.
+# triton-grafana
 
-## Current Status
+The Triton core grafana service. Triton is moving to using
+[prometheus](https://github.com/joyent/triton-prometheus) and
+grafana to track its own metrics and to provide an option for monitoring Triton
+itself. All Triton metrics are gathered via
+[CMON](https://github.com/joyent/triton-cmon).
 
-This is still a greenfield, i.e. no nitpicking on updates here for now.
+Note: This repository is part of the Joyent Triton project. See the [contribution
+guidelines](https://github.com/joyent/triton/blob/master/CONTRIBUTING.md) --
+*Triton does not use GitHub PRs* -- and general documentation at the main
+[Triton project](https://github.com/joyent/triton) page.
 
-## Links
+## Status
 
-- Triton service-specific metrics typically use
-  [node-triton-metrics](https://github.com/joyent/node-triton-metrics), so look
-  for some commonality there.
+The Triton core prometheus and grafana services are currently being actively
+developed. [RFD 150](https://github.com/joyent/rfd/tree/master/rfd/0150)
+describes the current plan and status.
 
+
+## Setup
+
+First ensure that [prometheus](https://github.com/joyent/triton-prometheus) is
+set up in your TritonDC, typically via:
+
+    sdcadm post-setup prometheus [OPTIONS]
+
+Then run the following from your TritonDC's headnode global zone:
+
+    sdcadm post-setup grafana [OPTIONS]
+
+
+## Architecture
+
+Primarily, this VM runs a Grafana instance as the "grafana" SMF service.
+
+An Nginx server performs TLS termination. It runs as the "nginx" SMF service.
+
+A Node.js proxy server sits between Nginx and Grafana and authenticates users
+against the datacenter's UFDS instance. This proxy runs as the "graf-proxy"
+SMF service.
+
+The Nginx instance is compiled to provide support for the
+`ngx_http_auth_request` module, which is necessary to support authentication
+subrequests. Nginx issues authentication subrequests using HTTP basic auth to
+graf-proxy. The graf-proxy restricts access to UFDS operators only. Upon
+successful authentication, graf-proxy sets Grafana-specific HTTP headers in its
+response to Nginx. Nginx forwards authenticated requests to the Grafana
+instance, which is configured to accept proxy authentication via the HTTP
+headers set by graf-proxy - see the documentation
+[here](http://docs.grafana.org/auth/auth-proxy/). In this way, users are able to
+authenticate to Grafana using their UFDS credentials.
+
+If a user's Grafana account does not yet exist, Grafana will automatically
+create it upon the receipt of an authenticated login request.
+
+
+## Configuration
+
+The three services are each configured differently:
+
+### Grafana
+
+The config files for Grafana are as follows. Note that "/data/..." is a
+delegate dataset to persist through reprovisions. These config files must thus
+be generated at time of zone setup, after the delegate dataset is mounted.
+
+    /data/grafana/conf/*                # configuration files
+    /data/grafana/data/*                # grafana database (users, dashboards,
+                                        # plugins etc.)
+
+The grafana config files are generated by the `boot/setup.sh` script from
+templates that live in the `config_templates` directory. Re-running the setup
+script will not overwrite existing config files, in order to preserve manual
+config changes across reprovisions.
+
+### graf-proxy
+
+The SAPI manifest becomes the config file for graf-proxy. It exists at
+`/opt/triton/grafana/proxy/config.json`.
+
+### Nginx
+
+The Nginx config file lives in `/opt/triton/grafana/nginx/conf/nginx.conf` and
+is entirely static - it is written when the image is built. Users should not
+need to change this file.
+
+The TLS certificate and key for Nginx live in `/data/tls`. The certificate is
+self-signed by default. These certificates persist across reprovisions.
+
+
+## Dashboards
+
+This repo also holds JSON files of common Grafana dashboards for monitoring
+Triton with a Prometheus/Grafana setup. These are stored under `dashboards`.
+
+
+## Security
+
+The graf-proxy restricts access to UFDS operators only. It respects UFDS
+lockouts, with the caveat that client-side caching in the `node-ufds` library
+may delay the presentation of lockout status to the user, though the UFDS
+server is returning a lockout response.
+
+
+## Troubleshooting
+
+### Grafana doesn't display Triton data
+
+Triton's Grafana gets its data from Prometheus. Here are some things to check
+if this appears to be failing:
+
+- Is Grafana running? `svcs grafana`
+
+- Is Prometheus scraping data properly?
+
+- Is Prometheus reachable? Go to https://<grafana url>/datasources, select the
+  "Triton" datasource, and click "Save & Test" at the bottom of the page
+
+- Are there visible warnings or errors on the grafana webpage?
+
+- Does the Grafana config (the files under /data/grafana/conf) look correct?
+
+- Does the Grafana log show errors? `tail $(svcs -L grafana)`
+
+## Testing
+
+There exists a small system test suite for `graf-proxy`. It is driven by the
+`test/runtests` script. These tests are
+designed for a fully deployed Grafana instance. They are non-destructive, but
+they create users in UFDS and thus should not be run in production.
diff --git a/boot/configure.sh b/boot/configure.sh
new file mode 100755
index 0000000..92bf518
--- /dev/null
+++ b/boot/configure.sh
@@ -0,0 +1,17 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+# Nothing to do on each boot.
+
+exit 0
diff --git a/boot/setup.sh b/boot/setup.sh
new file mode 100755
index 0000000..e9aaac3
--- /dev/null
+++ b/boot/setup.sh
@@ -0,0 +1,335 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# One-time setup of a Triton grafana core zone.
+#
+# It is expected that this is run via the standard Triton user-script,
+# i.e. as part of the "mdata:execute" SMF service. That user-script ensures
+# this setup.sh is run once for each (re)provision of the image. However, the
+# script should also attempt to be idempotent.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+PATH=/opt/local/bin:/opt/local/sbin:/usr/bin:/usr/sbin
+
+# Grafana data is stored on its delegate dataset:
+#   /data/grafana/
+#       conf/*                          # configuration files
+#       data/*                          # grafana database (users, dashboards,
+#                                       # etc.)
+#   /data/tls/*                         # TLS certs
+GRAF_PERSIST_DIR=/data/grafana
+DATA_DIR=${GRAF_PERSIST_DIR}/data
+CONF_DIR=${GRAF_PERSIST_DIR}/conf
+TLS_DIR=/data/tls
+
+# The Nginx directory/config is entirely static and should not be changed after
+# setup.
+NGINX_DIR=/opt/triton/grafana/nginx
+
+# This script creates these files from templates
+GRAFANA_CONFIG_FILE=${CONF_DIR}/grafana.ini
+DATASOURCES_FILE=${CONF_DIR}/provisioning/datasources/triton-datasources.yaml
+DASHBOARDS_FILE=${CONF_DIR}/provisioning/dashboards/triton-dashboards.yaml
+
+# Templates:
+#
+# Config files for grafana are written at zone setup time based on
+# templates included in $TEMPLATES_DIR. If a config file is named "foo", its
+# template must be named "foo.in". Template variables are specified by
+# including the delimiter "%%" on either side, and are replaced with the value
+# of the bash variable with the corresponding name. For example, if the bash
+# variable $FOO has the value "bar", all occurrences of "%%FOO%%" in a template
+# file will be replaced with "bar".
+#
+# This functionality is implemented in the grafana_write_config function in
+# this file.
+TEMPLATES_DIR=/opt/triton/grafana/config_templates
+
+TEST_DIR=/opt/triton/grafana/test
+
+# - TLS cert
+CERT_FILE=${TLS_DIR}/cert.pem
+# - TLS cert key
+CERT_KEY_FILE=${TLS_DIR}/privkey.pem
+
+# ---- internal routines
+
+function fatal() {
+	printf '%s: ERROR: %s\n' "$(basename $0)" "$*" >&2
+	exit 1
+}
+
+# Add user and corresponding group, if the user/group do not exist
+function grafana_add_user() {
+	local username=$1
+	if [[ ! $(getent group ${username}) ]]; then
+		groupadd ${username}
+	fi
+	if [[ ! $(getent passwd ${username}) ]]; then
+		useradd -g ${username} ${username}
+		passwd -N ${username}
+	fi
+}
+
+# Mount our delegated dataset at /data.
+function grafana_setup_delegate_dataset() {
+	local dataset
+	local mountpoint=/data
+
+	dataset=zones/$(zonename)/data
+	mountpoint=$(zfs get -Hp mountpoint ${dataset} | awk '{print $3}')
+	if [[ ${mountpoint} != '/data' ]]; then
+		zfs set mountpoint=/data ${dataset}
+	fi
+}
+
+# Write config file based on template.
+# Arguments:
+#     $1: Desired fully qualified path of final config file
+#     $2, $3, ..., $N: string names of template parameters to replace. These
+#         will be replaced with the contents of identically-named bash
+#         variables.
+#
+# Example usage:
+# `grafana_write_config $GRAFANA_CONFIG_FILE CONF_DIR DATA_DIR`
+#
+# This example invocation will look for the template corresponding to
+# $GRAFANA_CONFIG_FILE in $TEMPLATES_DIR, search for instances of CONF_DIR and
+# DATA_DIR in this template file (surrounded by the delimiter "%%"), replace
+# these with the contents of the bash variables $CONF_DIR and $DATA_DIR,
+# respectively, and write this file to $GRAFANA_CONFIG_FILE.
+#
+# Note that this function does nothing if the specified config file already
+# exists.
+function grafana_write_config() {
+	local config_file=$1
+	local basename=$(basename ${config_file})
+
+	if [[ -f ${config_file} ]]; then
+		echo "config file already found for ${basename}; not writing config"
+		return
+	fi
+
+	local template_file=${TEMPLATES_DIR}/${basename}.in
+	shift
+
+	local delim='%%'
+	# semicolon-separated list of sed commands to run
+	local commands=''
+
+	for var in "$@"; do
+		# Verify that template parameter exists in template file before
+		# adding to command list
+		grep "${delim}${var}${delim}" ${template_file} || \
+		    fatal "template parameter ${var} not found in ${template_file}"
+		commands="${commands}s|${delim}${var}${delim}|${!var}|g;"
+	done
+
+	local contents=$(sed "${commands}" ${template_file})
+
+	echo ${contents} | grep "${delim}" && \
+	    fatal "unused substitution delimiter found in ${basename}"
+
+	echo "Writing first time grafana config (${config_file})"
+	echo "${contents}" > ${config_file}
+}
+
+function grafana_setup_proxy() {
+	/usr/sbin/svccfg import /opt/triton/grafana/smf/manifests/graf-proxy.xml
+}
+
+function grafana_setup_nginx() {
+	/usr/sbin/svccfg import /opt/triton/grafana/smf/manifests/nginx.xml
+}
+
+# Setup key and certificate used for nginx
+function grafana_setup_certs() {
+	if [[ -f "${CERT_FILE}" && -f "${CERT_KEY_FILE}" ]]; then
+		echo "Key files already exist: ${CERT_FILE}, ${CERT_KEY_FILE}"
+	else
+		echo "Generating tls cert and key for CMON auth"
+		mkdir -p ${TLS_DIR}
+		# Create cert and key
+		openssl req -x509 -nodes -subj '/CN=admin' -newkey rsa:2048 \
+		    -keyout ${CERT_KEY_FILE} -out ${CERT_FILE} -days 365
+	fi
+
+	return 0
+}
+
+function grafana_setup_env() {
+	if ! grep grafana /root/.profile >/dev/null; then
+		echo '' >> /root/.profile
+		echo "export PATH=/opt/triton/grafana/bin:/opt/triton/grafana/grafana:\$PATH" >> \
+		    /root/.profile
+	fi
+}
+
+function grafana_set_permissions() {
+	grafana_add_user 'grafana'
+	grafana_add_user 'graf-proxy'
+	grafana_add_user 'nginx'
+
+	local output
+	# Grant full access to files Grafana may write to
+	output=$(chown -c grafana:grafana \
+	    ${GRAFANA_CONFIG_FILE} \
+	    ${DATASOURCES_FILE} \
+	    ${DASHBOARDS_FILE} \
+	    ${DATA_DIR})
+	if [[ -n "${output}" ]]; then
+		echo "${output}"
+	fi
+
+	output=$(chown -cR nginx:nginx \
+	    ${NGINX_DIR})
+	if [[ -n "${output}" ]]; then
+		echo "${output}"
+	fi
+
+	chmod 700 "${TEST_DIR}/runtests"
+
+	return 0
+}
+
+function grafana_setup_grafana() {
+	local DC_NAME=$(mdata-get sdc:datacenter_name)
+	local DNS_DOMAIN=$(mdata-get sdc:dns_domain)
+	if [[ -z "${DNS_DOMAIN}" ]]; then
+		# As of TRITON-92, we expect sdcadm to set this for all core
+		# Triton zones.
+		fatal 'could not determine "DNS_DOMAIN"'
+	fi
+
+	mkdir -p ${DATA_DIR}
+	mkdir -p ${CONF_DIR}/provisioning/dashboards
+	mkdir -p ${CONF_DIR}/provisioning/datasources
+	mkdir -p ${CONF_DIR}/plugins
+
+	grafana_write_config ${GRAFANA_CONFIG_FILE} DATA_DIR CONF_DIR
+	grafana_write_config ${DATASOURCES_FILE} DC_NAME DNS_DOMAIN
+	grafana_write_config ${DASHBOARDS_FILE}
+
+	/usr/sbin/svccfg import /opt/triton/grafana/smf/manifests/grafana.xml
+
+	return 0
+}
+
+function grafana_ensure_running() {
+	local currState
+	local dashId
+	local tries=5
+
+	# Wait for grafana to come out of transition, if necessary
+	local try=0
+	currState=$(svcs -Ho state grafana)
+	while [[ "${currState: -1}" == '*' ]]; do
+		((try++)) || true
+		if [[ "$try" -eq "$tries" ]]; then
+			fatal 'timeout: grafana service in transition state'
+		fi
+		sleep 15
+		currState=$(svcs -Ho state grafana)
+	done
+
+	# Make sure grafana is running
+	if [[ "${currState}" == 'disabled' || "${currState}" == 'offline' ]]; then
+		echo 'Enabling grafana SMF service'
+		svcadm enable grafana
+	elif [[ "${currState}" == 'maintenance' ]]; then
+		echo 'Clearing grafana SMF service'
+		svcadm clear grafana
+	elif [[ "${currState}" != 'online' ]]; then
+		fatal "unexpected grafana service state: '${currState}'"
+	fi
+
+	# Wait for grafana to come up
+	try=0
+	currState=$(svcs -Ho state grafana)
+	while [[ "${currState}" != 'online' ]]; do
+		((try++)) || true
+		if [[ "$try" -eq "$tries" ]]; then
+			fatal 'timeout: grafana could not be (re)started'
+		fi
+		sleep 15
+		currState=$(svcs -Ho state grafana)
+	done
+}
+
+# Set defaults after grafana is already running
+function grafana_set_defaults() {
+	local grafana_addr='127.0.0.1'
+	local grafana_port='3000'
+	local tries=5
+
+	# Set dashboard default
+	dashId=$(curl -sS --header 'X-Grafana-Username: admin' \
+	    "http://${grafana_addr}:${grafana_port}/api/search?type=dash-db&query=cnapi" | json 0.id)
+
+	# Sometimes, after grafana has just come up, the following request will
+	# fail. We thus try repeatedly.
+
+	local try=0
+	local success='false'
+	set +o errexit
+	while [[ "${success}" != 'true' ]]; do
+		((try++)) || true
+		if [[ "$try" -eq "$tries" ]]; then
+			fatal 'timeout: grafana could not be (re)started'
+		fi
+
+		curl -sS --header 'X-Grafana-Username: admin' \
+		    "http://${grafana_addr}:${grafana_port}/api/org/preferences" \
+		    -H content-type:application/json \
+		    -d '{"theme":"","homeDashboardId":'${dashId}',"timezone":"utc"}' \
+		    -X PUT \
+		    && success='true'
+
+		sleep 2
+	done
+	set -o errexit
+
+	return 0
+}
+
+# ---- mainline
+
+CONFIG_AGENT_LOCAL_MANIFESTS_DIRS=/opt/triton/grafana
+source /opt/smartdc/boot/lib/util.sh
+sdc_common_setup
+
+grafana_setup_delegate_dataset
+grafana_setup_certs
+grafana_setup_env
+grafana_setup_grafana
+grafana_set_permissions
+grafana_ensure_running
+grafana_set_defaults
+
+grafana_setup_proxy
+grafana_setup_nginx
+
+# Log rotation.
+sdc_log_rotation_add config-agent /var/svc/log/*config-agent*.log 1g
+sdc_log_rotation_add registrar /var/svc/log/*registrar*.log 1g
+sdc_log_rotation_add grafana /var/svc/log/*grafana*.log 1g
+sdc_log_rotation_add nginx /var/svc/log/*nginx*.log 1g
+sdc_log_rotation_add graf-proxy /var/svc/log/*graf-proxy*.log 1g
+
+sdc_log_rotation_setup_end
+
+sdc_setup_complete
+
+exit 0
diff --git a/config/nginx.conf b/config/nginx.conf
new file mode 100755
index 0000000..3ff8e64
--- /dev/null
+++ b/config/nginx.conf
@@ -0,0 +1,97 @@
+user nginx nginx;
+worker_processes  1;
+
+events {
+	worker_connections  1024;
+}
+
+http {
+	include mime.types;
+	default_type application/octet-stream;
+
+	log_format  combined_withlatency '$remote_addr - $remote_user [$time_local]'
+	    '"$request" $status $body_bytes_sent $request_time '
+	    '"$http_referer" "$http_user_agent"';
+	access_log /var/log/nginx-access.log;
+	error_log /var/log/nginx-error.log;
+
+
+	sendfile on;
+	send_timeout 300s;
+
+	keepalive_timeout 65;
+
+	upstream grafana {
+		server 127.0.0.1:3000 fail_timeout=0;
+	}
+
+	upstream auth {
+		# Must keep in sync with lib/proxy.js and test/auth.js
+		server 'unix:/tmp/graf-proxy.sock' fail_timeout=0;
+	}
+
+	server {
+		listen 80;
+		server_name localhost;
+		return 301 https://$host$request_uri;
+	}
+
+	server {
+		listen 443 ssl;
+		server_name localhost;
+
+		add_header Strict-Transport-Security 'max-age=31536000; includeSubDomains' always;
+
+		ssl_certificate /data/tls/cert.pem;
+		ssl_certificate_key /data/tls/privkey.pem;
+
+		location = /auth {
+			internal;
+			proxy_pass http://auth;
+			proxy_pass_request_body off;
+			proxy_set_header Content-Length "";
+			proxy_set_header X-Original-URI $request_uri;
+		}
+
+		location = /ping {
+			proxy_set_header Authorization "";
+			proxy_set_header Host $host;
+			proxy_set_header X-Real-IP $remote_addr;
+			proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
+			proxy_set_header X-Forwarded-Proto $scheme;
+
+			proxy_redirect http:// https://;
+			proxy_pass http://grafana/api/health;
+			# Required for new HTTP-based CLI
+			proxy_http_version 1.1;
+			proxy_request_buffering off;
+			# Required for HTTP-based CLI to work over SSL
+			proxy_buffering off;
+		}
+
+		location / {
+			auth_request /auth;
+			auth_request_set $auth_username $upstream_http_x_grafana_username;
+			auth_request_set $auth_email $upstream_http_x_grafana_email;
+			auth_request_set $auth_name $upstream_http_x_grafana_name;
+
+			proxy_set_header Authorization "";
+			proxy_set_header Host $host;
+			proxy_set_header X-Real-IP $remote_addr;
+			proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
+			proxy_set_header X-Forwarded-Proto $scheme;
+
+			proxy_set_header X-Grafana-Username $auth_username;
+			proxy_set_header X-Grafana-Email $auth_email;
+			proxy_set_header X-Grafana-Name $auth_name;
+
+			proxy_redirect http:// https://;
+			proxy_pass http://grafana;
+			# Required for new HTTP-based CLI
+			proxy_http_version 1.1;
+			proxy_request_buffering off;
+			# Required for HTTP-based CLI to work over SSL
+			proxy_buffering off;
+		}
+	}
+}
diff --git a/config_templates/grafana.ini.in b/config_templates/grafana.ini.in
new file mode 100755
index 0000000..ae9f2b6
--- /dev/null
+++ b/config_templates/grafana.ini.in
@@ -0,0 +1,28 @@
+# config file version
+apiVersion: 1
+
+[server]
+http_addr=127.0.0.1
+
+[auth]
+disable_login_form=true
+disable_signout_menu=true
+
+[auth.basic]
+enabled=false
+
+[auth.proxy]
+enabled=true
+header_name=X-Grafana-Username
+header_property=username
+auto_sign_up=true
+whitelist=127.0.0.1
+headers=Email:X-Grafana-Email Name:X-Grafana-Name
+
+[paths]
+data=%%DATA_DIR%%
+provisioning=%%CONF_DIR%%/provisioning
+plugins=%%CONF_DIR%%/plugins
+
+[users]
+auto_assign_org_role=Admin
diff --git a/config_templates/triton-dashboards.yaml.in b/config_templates/triton-dashboards.yaml.in
new file mode 100755
index 0000000..febaa6a
--- /dev/null
+++ b/config_templates/triton-dashboards.yaml.in
@@ -0,0 +1,10 @@
+# config file version
+apiVersion: 1
+
+providers:
+        - name: Triton
+          orgId: 1
+          folder: ''
+          type: file
+          options:
+                path: /opt/triton/grafana/dashboards
diff --git a/config_templates/triton-datasources.yaml.in b/config_templates/triton-datasources.yaml.in
new file mode 100755
index 0000000..1e03313
--- /dev/null
+++ b/config_templates/triton-datasources.yaml.in
@@ -0,0 +1,11 @@
+# config file version
+apiVersion: 1
+
+datasources:
+        - name: Triton
+          type: prometheus
+          access: proxy
+          orgId: 1
+          url: http://prometheus.%%DC_NAME%%.%%DNS_DOMAIN%%:9090
+          isDefault: true
+          editable: true
diff --git a/deps/grafana b/deps/grafana
new file mode 160000
index 0000000..e045e15
--- /dev/null
+++ b/deps/grafana
@@ -0,0 +1 @@
+Subproject commit e045e15718c007c6f804a4ddcf3c1e2981282772
diff --git a/deps/nginx b/deps/nginx
new file mode 160000
index 0000000..a8fe224
--- /dev/null
+++ b/deps/nginx
@@ -0,0 +1 @@
+Subproject commit a8fe224b46a8125a623f1ddeea411b046d1a6008
diff --git a/deps/sdc-scripts b/deps/sdc-scripts
new file mode 160000
index 0000000..deefaef
--- /dev/null
+++ b/deps/sdc-scripts
@@ -0,0 +1 @@
+Subproject commit deefaef587ed3bee2706cb6e53ee3468e682932e
diff --git a/lib/auth.js b/lib/auth.js
new file mode 100644
index 0000000..e8c314d
--- /dev/null
+++ b/lib/auth.js
@@ -0,0 +1,147 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * Authentication for grafana proxy server. Sets headers for use with the
+ * the auth-proxy authentication mode in Grafana - see
+ * http://docs.grafana.org/auth/auth-proxy/
+ */
+
+'use strict';
+
+const assert = require('assert-plus');
+const basicAuth = require('basic-auth');
+
+const errors = require('./errors');
+
+const AUTH_USERNAME_HEADER = 'X-Grafana-Username';
+const AUTH_EMAIL_HEADER = 'X-Grafana-Email';
+const AUTH_NAME_HEADER = 'X-Grafana-Name';
+
+/**
+ * authenticate
+ *
+ * @requires
+ * - req.ufds
+ */
+function authenticate(req, res, next) {
+	assert.object(req.ufds, 'req.ufds');
+
+	// Retrieve credentials from request
+	const creds = basicAuth(req);
+	// User hasn't submitted credentials yet - prompt them
+	if (!creds) {
+		next(setAuthHeader());
+		return;
+	}
+	const username = creds.name;
+	const password = creds.pass;
+
+	// Prompt user again if blank username or password
+	if (username === '') {
+		next(setAuthHeader());
+		return;
+	}
+	if (password === '') {
+		next(setAuthHeader());
+		return;
+	}
+
+	// Verify that user exists
+	req.ufds.getUserEx({
+		'searchType': 'login',
+		'value': username
+	}, function getUserExCb(err, user) {
+		if (err) {
+			// Username doesn't exist in UFDS - prompt again
+			if (err.restCode === 'ResourceNotFound') {
+				next(setAuthHeader());
+				return;
+			} else {
+				next(new errors.UfdsError(err));
+				return;
+			}
+		}
+
+		/*
+		 * Check for lockout. Note that, because node-ufds caches user
+		 * objects on the client side, a user who is locked out on the
+		 * server may appear to be unlocked from the client perspective.
+		 * This means that the user will receive the authentication
+		 * prompt instead of a proper 403 until the cache times out -
+		 * the user will still be properly unable to authenticate to the
+		 * server.
+		 */
+		const lockedTime = user.pwdaccountlockedtime;
+		if (lockedTime && lockedTime > Date.now()) {
+			next(new errors.AccountLockedError());
+			return;
+		}
+
+		// Check for password expiry
+		const pwdEndTime = user.pwdendtime;
+		if (pwdEndTime && pwdEndTime <= Date.now()) {
+			next(new errors.PasswordExpiredError());
+			return;
+		}
+
+		// Authenticate user
+		doAuth();
+		return;
+	});
+
+	function doAuth() {
+		/*
+		 * Note that we make no attempt to prevent a write occurring to
+		 * the local UFDS in the event of a lockout. This cannot be
+		 * accounted for until TRITON-947 is fixed.
+		 */
+		req.ufds.authenticate(username, password,
+			function authenticateCb(err, user) {
+			if (err) {
+				/*
+				 * Invalid password or username -
+				 * prompt user again
+				 */
+				if (err.restCode === 'InvalidCredentials' ||
+					err.restCode === 'ResourceNotFound') {
+					next(setAuthHeader());
+					return;
+				}
+
+				next(new errors.UfdsError(err));
+				return;
+			}
+
+			if (!user.isAdmin()) {
+				next(new errors.PermissionError());
+				return;
+			}
+
+			// Set headers needed by grafana
+			res.header('Content-Type', 'application/json');
+			res.header(AUTH_USERNAME_HEADER, user.login);
+			res.header(AUTH_EMAIL_HEADER, user.email);
+			// Given name is optional in UFDS
+			res.header(AUTH_NAME_HEADER, user.givenname || '');
+			res.send(200);
+			next();
+			return;
+		});
+	}
+
+	// Convenience function for prompting user for credentials
+	function setAuthHeader() {
+		res.header('WWW-Authenticate', 'Basic realm="Joyent Grafana"');
+		return (new errors.AuthError());
+	}
+}
+
+module.exports = {
+	authenticate: authenticate
+};
diff --git a/lib/errors.js b/lib/errors.js
new file mode 100644
index 0000000..2296494
--- /dev/null
+++ b/lib/errors.js
@@ -0,0 +1,90 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * Errors for grafana proxy server.
+ */
+
+'use strict';
+
+const restify_errors = require('restify-errors');
+const util = require('util');
+
+const HttpError = restify_errors.HttpError;
+
+const ACCOUNT_LOCKED_MESSAGE = 'Account is temporarily locked after too many ' +
+	'failed auth attempts';
+const AUTH_ERROR_MESSAGE = 'Credentials Invalid';
+const INSUFFICIENT_PERMISSION_MESSAGE = 'User does not have permission to ' +
+	'access Grafana';
+const PASSWORD_EXPIRED_MESSAGE = 'Your password has expired';
+const UFDS_ERROR_MESSAGE = 'Error while authenticating via UFDS';
+
+function GrafProxyError(obj) {
+	obj.constructorOpt = this.constructor;
+	HttpError.call(this, obj);
+}
+util.inherits(GrafProxyError, HttpError);
+
+function AccountLockedError(err) {
+	GrafProxyError.call(this, {
+		restCode: 'Forbidden',
+		statusCode: 403,
+		cause: err,
+		message: ACCOUNT_LOCKED_MESSAGE
+	});
+}
+util.inherits(AccountLockedError, GrafProxyError);
+
+function AuthError(err) {
+	GrafProxyError.call(this, {
+		restCode: 'Unauthorized',
+		statusCode: 401,
+		cause: err,
+		message: AUTH_ERROR_MESSAGE
+	});
+}
+util.inherits(AuthError, GrafProxyError);
+
+function PermissionError(err) {
+	GrafProxyError.call(this, {
+		restCode: 'Forbidden',
+		statusCode: 403,
+		cause: err,
+		message: INSUFFICIENT_PERMISSION_MESSAGE
+	});
+}
+util.inherits(PermissionError, GrafProxyError);
+
+function PasswordExpiredError(err) {
+	GrafProxyError.call(this, {
+		restCode: 'Forbidden',
+		statusCode: 403,
+		cause: err,
+		message: PASSWORD_EXPIRED_MESSAGE
+	});
+}
+util.inherits(PasswordExpiredError, GrafProxyError);
+
+function UfdsError(err) {
+	GrafProxyError.call(this, {
+		restCode: 'Internal',
+		statusCode: 500,
+		cause: err,
+		message: UFDS_ERROR_MESSAGE
+	});
+}
+util.inherits(UfdsError, GrafProxyError);
+
+module.exports = {
+	AccountLockedError: AccountLockedError,
+	AuthError: AuthError,
+	PermissionError: PermissionError,
+	PasswordExpiredError: PasswordExpiredError,
+	UfdsError: UfdsError
+};
diff --git a/lib/proxy.js b/lib/proxy.js
new file mode 100644
index 0000000..c8702f8
--- /dev/null
+++ b/lib/proxy.js
@@ -0,0 +1,127 @@
+#!/usr/bin/env node
+
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * grafana proxy server.
+ *
+ * Usage:
+ *    node proxy.js
+ */
+
+'use strict';
+
+const assert = require('assert-plus');
+const bunyan = require('bunyan');
+const fs = require('fs');
+const restify = require('restify');
+const tritonAuditLogger = require('triton-audit-logger');
+
+const auth = require('./auth');
+const ufds = require('./ufds');
+const util = require('./util');
+
+
+function createProxyServer(config) {
+	assert.object(config, 'config');
+
+	const ufdsMaster = ufds.createUfdsClient({
+		url: config.ufdsMaster.url,
+		bindDN: config.ufdsMaster.bindDN,
+		bindPassword: config.ufdsMaster.bindPassword,
+		cache: config.ufdsMaster.cache,
+		log: config.log
+	});
+
+	const ufdsLocal = ufds.createUfdsClient({
+		url: config.ufdsLocal.url,
+		bindDN: config.ufdsLocal.bindDN,
+		bindPassword: config.ufdsLocal.bindPassword,
+		cache: config.ufdsLocal.cache,
+		log: config.log
+	});
+
+	const server = restify.createServer({
+		name: 'graf-proxy',
+		log: config.log
+	});
+
+	server.use(restify.plugins.requestLogger());
+	server.use(function hstsHeader(req, res, next) {
+		// HSTS (needed for A+ rating on <ssllabs.com/ssltest>)
+		res.setHeader('Strict-Transport-Security', 'max-age=31536000');
+		next();
+	});
+
+        server.on('after', tritonAuditLogger.createAuditLogHandler({
+                log: config.log,
+                reqBody: {},
+                resBody: {},
+                // eslint-disable-next-line no-unused-vars
+                polish: function censorAuth(fields, req, res, route, err) {
+                        if (req.headers['authorization'] !== undefined) {
+                                req.headers['authorization'] = '***';
+                        }
+                }
+        }));
+
+	server.get('/auth', setUfds, auth.authenticate);
+
+	return server;
+
+	function setUfds(req, res, next) {
+		function trySetUfds() {
+			if (ufdsMaster.connected) {
+				req.ufds = ufdsMaster;
+				next();
+				return;
+			} else if (ufdsLocal.connected) {
+				req.ufds = ufdsLocal;
+				next();
+				return;
+			} else {
+				setTimeout(trySetUfds, 200);
+				return;
+			}
+		}
+		trySetUfds();
+	}
+}
+
+// ---- mainline
+
+// Log will be attached to config and to each restify req
+const log = bunyan.createLogger({
+	name: 'graf-proxy',
+	level: 'info',
+	serializers: restify.bunyan.serializers
+});
+
+let config;
+const customConfigPath = process.env.GRAFANA_PROXY_CONFIG;
+try {
+	config = util.loadConfig(log, util.DEFAULT_CFG_PATH, customConfigPath);
+} catch (err) {
+	log.fatal(err);
+	process.exit(1);
+}
+
+const server = createProxyServer(config);
+
+/*
+ * Set up socket to listen on. Must keep path in sync with config/nginx.conf and
+ * test/auth.test.js
+ */
+const proxySock = '/tmp/graf-proxy.sock';
+if (fs.existsSync(proxySock)) {
+	fs.unlinkSync(proxySock);
+}
+server.listen(proxySock, function listenCb() {
+	config.log.info('Server listening at %s', proxySock);
+});
diff --git a/lib/ufds.js b/lib/ufds.js
new file mode 100644
index 0000000..afaaaee
--- /dev/null
+++ b/lib/ufds.js
@@ -0,0 +1,77 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * UFDS client utility functions for grafana proxy server and associated tests.
+ */
+
+'use strict';
+
+const UFDS = require('ufds');
+const assert = require('assert-plus');
+
+const UFDS_DEFAULT_CONNECT_TIMEOUT = 4000;
+const UFDS_DEFAULT_CLIENT_TIMEOUT = 2000;
+const UFDS_DEFAULT_IDLE_TIMEOUT = 10000;
+
+/**
+ * createUfdsClient
+ *
+ * @param
+ * - config: from loadConfig
+ */
+function createUfdsClient(config) {
+	assert.object(config, 'config');
+
+	config.retry = { maxDelay: 8000 };
+	config.clientTimeout = config.clientTimeout ||
+		UFDS_DEFAULT_CLIENT_TIMEOUT;
+	config.connectTimeout = config.connectTimeout ||
+		UFDS_DEFAULT_CONNECT_TIMEOUT;
+	config.idleTimeout = config.idleTimeout || UFDS_DEFAULT_IDLE_TIMEOUT;
+
+	const ufds = new UFDS(config);
+
+	const log = config.log;
+	log.info('Connecting to UFDS: ', config.url);
+
+	function reconnect() {
+		ufds.close();
+		delete ufds.client;
+		ufds.connect();
+	}
+
+	ufds.on('timeout', function timeoutCb(msg) {
+		log.warn({message: msg}, 'UFDS client timeout (recycling)');
+		ufds.close();
+	});
+
+	ufds.once('connect', function onceConnectCb() {
+		log.info('Connected to UFDS: ', config.url);
+		ufds.removeAllListeners('error');
+
+		ufds.on('connect', function connectCb() {
+			log.info('UFDS Reconnected');
+		});
+
+		ufds.on('close', function closeCb() {
+			log.info('UFDS Connection Closed');
+			reconnect();
+		});
+	});
+
+	ufds.on('error', function errorCb(err) {
+		log.warn(err, 'UFDS: unexpected error occurred');
+	});
+
+	return ufds;
+}
+
+module.exports = {
+	createUfdsClient: createUfdsClient
+};
diff --git a/lib/util.js b/lib/util.js
new file mode 100644
index 0000000..7877662
--- /dev/null
+++ b/lib/util.js
@@ -0,0 +1,86 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * Utility functions for grafana proxy server.
+ */
+
+'use strict';
+
+const fs = require('fs');
+const assert = require('assert-plus');
+
+const DEFAULT_CFG_PATH = __dirname + '/../config.json';
+
+/**
+ * loadConfig - loads config from specified file
+ *
+ * @param
+ * - defaultConfig: path to default config file
+ * - customConfig: path to user-specified config file
+ *
+ * @throws
+ * - Error if defaultConfig is not found or unparseable
+ * - Error if customConfig is specified but not found or unparseable
+ */
+function loadConfig(log, defaultConfig, customConfig) {
+	assert.string(defaultConfig, 'defaultConfig');
+	assert.optionalString(customConfig, 'customConfig');
+
+	// Load default config
+	let config;
+	log.info('Loading default config from "' + DEFAULT_CFG_PATH + '".');
+	if (!fs.existsSync(defaultConfig)) {
+		throw new Error('Config file not found: "' + defaultConfig +
+			'" does not exist.');
+	}
+	try {
+		config = JSON.parse(fs.readFileSync(defaultConfig, 'utf8'));
+	} catch (err) {
+		throw new Error('Unable to parse ' + defaultConfig + ': ' +
+			err.message);
+	}
+
+	// Load custom config, if specified
+	if (customConfig) {
+		log.info('Loading additional config from "' + customConfig +
+			'".');
+
+		if (!fs.existsSync(customConfig)) {
+			throw new Error('Config file not found: "' +
+				customConfig + '" does not exist.');
+		}
+		let extraConfig;
+		try {
+			extraConfig = JSON.parse(fs.readFileSync(customConfig,
+				'utf8'));
+		} catch (err) {
+			throw new Error('Unable to parse ' + extraConfig +
+				': ' + err.message);
+		}
+		for (let name in extraConfig) {
+			config[name] = extraConfig[name];
+		}
+	}
+
+	log.info('Loaded config: ', JSON.stringify(config, censor));
+	config.log = log;
+	return config;
+
+	function censor(key, value) {
+		if (key === 'bindPassword') {
+			return '***';
+		}
+		return value;
+	}
+}
+
+module.exports = {
+	DEFAULT_CFG_PATH: DEFAULT_CFG_PATH,
+	loadConfig: loadConfig
+};
diff --git a/package.json b/package.json
new file mode 100644
index 0000000..724336f
--- /dev/null
+++ b/package.json
@@ -0,0 +1,32 @@
+{
+	"name": "triton-grafana",
+	"description": "Grafana for TritonDC",
+	"version": "1.0.0",
+	"author": "Joyent (joyent.com)",
+	"private": true,
+	"repository": {
+		"type": "git",
+		"url": "git+https://github.com/joyent/triton-grafana.git"
+	},
+	"license": "MPL-2.0",
+	"engines": {
+		"node" : ">=6.x"
+	},
+	"dependencies": {
+		"assert-plus": "^1.0.0",
+		"basic-auth": "^2.0.1",
+		"bunyan": "^1.8.12",
+		"restify": "^7.2.1",
+		"restify-clients": "^2.6.3",
+		"restify-errors": "^6.1.1",
+		"@smaller/tap": "^11.1.4-1.0.0",
+		"triton-audit-logger": "^1.0.1",
+		"ufds": "^1.4.0",
+		"uuid": "^3.3.2",
+		"vasync": "^2.2.0"
+	},
+	"devDependencies": {
+		"eslint": "^4.13.1",
+		"eslint-plugin-joyent": "~2.1.0"
+	}
+}
diff --git a/sapi_manifests/graf-proxy/manifest.json b/sapi_manifests/graf-proxy/manifest.json
new file mode 100644
index 0000000..525df5b
--- /dev/null
+++ b/sapi_manifests/graf-proxy/manifest.json
@@ -0,0 +1,5 @@
+{
+	"name": "grafana",
+	"path": "/opt/triton/grafana/proxy/config.json",
+	"post_cmd": "/usr/sbin/svcadm restart graf-proxy"
+}
diff --git a/sapi_manifests/graf-proxy/template b/sapi_manifests/graf-proxy/template
new file mode 100644
index 0000000..356b920
--- /dev/null
+++ b/sapi_manifests/graf-proxy/template
@@ -0,0 +1,29 @@
+{
+	"ufdsMaster": {
+		"url": "ldaps://{{^ufds_remote_ip}}{{{ufds_domain}}}{{/ufds_remote_ip}}{{{ufds_remote_ip}}}",
+		"bindDN": "{{{ufds_ldap_root_dn}}}",
+		{{^ufds_remote_ldap_root_pw}}
+		"bindPassword": "{{{ufds_ldap_root_pw}}}",
+		{{/ufds_remote_ldap_root_pw}}
+		{{#ufds_remote_ldap_root_pw}}
+		"bindPassword": "{{{ufds_remote_ldap_root_pw}}}",
+		{{/ufds_remote_ldap_root_pw}}
+		"clientTimeout": 240000,
+		"cache": {
+			"size": 5000,
+			"expiry": 60
+		}
+	},
+	"ufdsLocal": {
+		"clientTimeout": 240000,
+		"url": "ldaps://{{{UFDS_SERVICE}}}",
+		"bindDN": "{{{ufds_ldap_root_dn}}}",
+		"bindPassword": "{{{ufds_ldap_root_pw}}}",
+		"cache": {
+			"size": 1000,
+			"expiry": 60
+		}
+	},
+	{{! "_eof" is an unused key for convenience handling the trailing comma }}
+	"_eof": null
+}
diff --git a/smf/manifests/graf-proxy.xml b/smf/manifests/graf-proxy.xml
new file mode 100644
index 0000000..cdb5aa5
--- /dev/null
+++ b/smf/manifests/graf-proxy.xml
@@ -0,0 +1,66 @@
+<?xml version="1.0"?>
+<!DOCTYPE service_bundle SYSTEM "/usr/share/lib/xml/dtd/service_bundle.dtd.1">
+<!--
+	This Source Code Form is subject to the terms of the Mozilla Public
+	License, v. 2.0. If a copy of the MPL was not distributed with this
+	file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+	Copyright (c) 2018, Joyent, Inc.
+-->
+
+<service_bundle type="manifest" name="graf-proxy">
+	<service name="triton/site/graf-proxy" type="service" version="1.0.0">
+
+		<create_default_instance enabled="true"/>
+
+		<single_instance/>
+
+		<dependency name="network" grouping="require_all" restart_on="error" type="service">
+			<service_fmri value="svc:/milestone/network:default"/>
+		</dependency>
+
+		<dependency name="filesystem" grouping="require_all" restart_on="error" type="service">
+			<service_fmri value="svc:/system/filesystem/local"/>
+		</dependency>
+
+		<exec_method
+			type="method"
+			name="start"
+			exec="/opt/triton/grafana/build/node/bin/node --abort_on_uncaught_exception /opt/triton/grafana/proxy/lib/proxy.js &amp;"
+			timeout_seconds="30">
+			<method_context working_directory="/opt/triton/grafana/proxy">
+				<method_credential user="graf-proxy" group="graf-proxy" privileges="basic,net_privaddr"/>
+				<method_environment>
+					<envvar name="PATH" value="/opt/local/bin:/usr/bin:/usr/sbin:/bin"/>
+					<envvar name="LD_PRELOAD_32" value="/usr/lib/extendedFILE.so.1"/>
+				</method_environment>
+			</method_context>
+		</exec_method>
+
+		<exec_method type="method" name="restart" exec=":kill" timeout_seconds="60">
+			<method_context working_directory="/opt/triton/grafana/proxy"/>
+		</exec_method>
+
+		<exec_method type="method" name="stop" exec=":kill" timeout_seconds="60">
+			<method_context working_directory="/opt/triton/grafana/proxy"/>
+		</exec_method>
+
+		<property_group name="startd" type="framework">
+			<propval name="ignore_error" type="astring" value="core,signal"/>
+		</property_group>
+
+		<property_group name="application" type="application">
+
+		</property_group>
+
+		<stability value="Stable"/>
+
+		<template>
+			<common_name>
+				<loctext xml:lang="C">UFDS auth proxy for Triton Grafana</loctext>
+			</common_name>
+		</template>
+	</service>
+</service_bundle>
diff --git a/smf/manifests/grafana.xml b/smf/manifests/grafana.xml
new file mode 100644
index 0000000..50bf957
--- /dev/null
+++ b/smf/manifests/grafana.xml
@@ -0,0 +1,66 @@
+<?xml version="1.0"?>
+<!DOCTYPE service_bundle SYSTEM "/usr/share/lib/xml/dtd/service_bundle.dtd.1">
+<!--
+	This Source Code Form is subject to the terms of the Mozilla Public
+	License, v. 2.0. If a copy of the MPL was not distributed with this
+	file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+	Copyright (c) 2018, Joyent, Inc.
+-->
+
+<service_bundle type="manifest" name="grafana">
+	<service name="triton/site/grafana" type="service" version="1.0.0">
+
+		<create_default_instance enabled="true"/>
+
+		<single_instance/>
+
+		<dependency name="network" grouping="require_all" restart_on="error" type="service">
+			<service_fmri value="svc:/milestone/network:default"/>
+		</dependency>
+
+		<dependency name="filesystem" grouping="require_all" restart_on="error" type="service">
+			<service_fmri value="svc:/system/filesystem/local"/>
+		</dependency>
+
+		<exec_method
+			type="method"
+			name="start"
+			exec="/opt/triton/grafana/grafana/bin/solaris-amd64/grafana-server --homepath /opt/triton/grafana/grafana --config /data/grafana/conf/grafana.ini &amp;"
+			timeout_seconds="30">
+			<method_context working_directory="/opt/triton/grafana/grafana">
+				<method_credential user="grafana" group="grafana" privileges="basic,net_privaddr"/>
+				<method_environment>
+					<envvar name="PATH" value="/opt/local/bin:/usr/bin:/usr/sbin:/bin"/>
+					<envvar name="LD_PRELOAD_32" value="/usr/lib/extendedFILE.so.1"/>
+				</method_environment>
+			</method_context>
+		</exec_method>
+
+		<exec_method type="method" name="restart" exec=":kill" timeout_seconds="60">
+			<method_context working_directory="/opt/triton/grafana/grafana"/>
+		</exec_method>
+
+		<exec_method type="method" name="stop" exec=":kill" timeout_seconds="60">
+			<method_context working_directory="/opt/triton/grafana/grafana"/>
+		</exec_method>
+
+		<property_group name="startd" type="framework">
+			<propval name="ignore_error" type="astring" value="core,signal"/>
+		</property_group>
+
+		<property_group name="application" type="application">
+
+		</property_group>
+
+		<stability value="Stable"/>
+
+		<template>
+			<common_name>
+				<loctext xml:lang="C">Triton Grafana</loctext>
+			</common_name>
+		</template>
+	</service>
+</service_bundle>
diff --git a/smf/manifests/nginx.xml b/smf/manifests/nginx.xml
new file mode 100644
index 0000000..2fd9acc
--- /dev/null
+++ b/smf/manifests/nginx.xml
@@ -0,0 +1,69 @@
+<?xml version="1.0"?>
+<!DOCTYPE service_bundle SYSTEM "/usr/share/lib/xml/dtd/service_bundle.dtd.1">
+<!--
+	This Source Code Form is subject to the terms of the Mozilla Public
+	License, v. 2.0. If a copy of the MPL was not distributed with this
+	file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+	Copyright (c) 2018, Joyent, Inc.
+-->
+
+<service_bundle type="manifest" name="nginx">
+	<service name="triton/site/nginx" type="service" version="1.0.0">
+
+		<create_default_instance enabled="true"/>
+
+		<single_instance/>
+
+		<dependency
+			name="network"
+			grouping="require_all"
+			restart_on="error"
+			type="service">
+			<service_fmri value="svc:/network/physical"/>
+		</dependency>
+
+		<dependency
+			name="filesystem"
+			grouping="require_all"
+			restart_on="error"
+			type="service">
+			<service_fmri value="svc:/system/filesystem/local"/>
+		</dependency>
+
+		<exec_method
+			type="method"
+			name="start"
+			exec="/opt/triton/grafana/nginx/sbin/nginx -p /opt/triton/grafana/nginx/ &amp;" timeout_seconds="15">
+			<method_context>
+				<!--
+					Note that we leave nginx running as root
+					here. This is so the master process can
+					listen on ports 80 and 443. In the nginx
+					config file, we specify `user nginx` to
+					have the other processes run as nonroot.
+				-->
+				<method_environment>
+					<envvar name="PATH" value="/opt/local/bin:/usr/bin:/usr/sbin:/bin"/>
+					<envvar name="LD_PRELOAD_32" value="/usr/lib/extendedFILE.so.1"/>
+				</method_environment>
+			</method_context>
+		</exec_method>
+
+		<exec_method type="method" name="stop" exec=":kill" timeout_seconds="30">
+			<method_context working_directory="/opt/triton/grafana/nginx"/>
+		</exec_method>
+
+		<exec_method type="method" name="refresh" exec=":kill -HUP" timeout_seconds="30">
+			<method_context working_directory="/opt/triton/grafana/nginx"/>
+		</exec_method>
+
+		<template>
+			<common_name>
+				<loctext xml:lang="C" >Joyent nginx reverse proxy for Grafana</loctext>
+			</common_name>
+		</template>
+	</service>
+</service_bundle>
diff --git a/test/auth.test.js b/test/auth.test.js
new file mode 100644
index 0000000..2d4903f
--- /dev/null
+++ b/test/auth.test.js
@@ -0,0 +1,291 @@
+#!/usr/bin/env node
+
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2018, Joyent, Inc.
+ *
+ * authentication test for grafana proxy server.
+ *
+ * Usage:
+ *    node auth.test.js
+ */
+
+'use strict';
+
+const bunyan = require('bunyan');
+const restify = require('restify-clients');
+const test = require('@smaller/tap').test;
+const uuid = require('uuid');
+const vasync = require('vasync');
+
+const ufds = require('../proxy/lib/ufds');
+const util = require('../proxy/lib/util');
+
+/*
+ * Socket graf-proxy is listening on. Must keep path in sync with
+ * config/nginx.conf and test/auth.test.js
+ */
+const PROXY_SOCK = '/tmp/graf-proxy.sock';
+const AUTH_ENDPOINT = '/auth';
+
+const ADMIN_GROUP = 'operators';
+
+const log = bunyan.createLogger({
+	name: 'graf-proxy',
+	level: 'info',
+	serializers: bunyan.stdSerializers
+});
+
+let config;
+const customConfigPath = process.env.GRAFANA_PROXY_CONFIG;
+try {
+	config = util.loadConfig(log, util.DEFAULT_CFG_PATH, customConfigPath);
+} catch (err) {
+	log.fatal('Could not load config: ' + err.message);
+	process.exit(1);
+}
+
+const client = restify.createJsonClient({
+	socketPath: PROXY_SOCK,
+	connectTimeout: 1000,
+	requestTimeout: 1000,
+	retry: false
+});
+
+const ufdsMaster = ufds.createUfdsClient({
+	url: config.ufdsMaster.url,
+	bindDN: config.ufdsMaster.bindDN,
+	bindPassword: config.ufdsMaster.bindPassword,
+	cache: config.ufdsMaster.cache,
+	log: config.log
+});
+
+const ufdsLocal = ufds.createUfdsClient({
+	url: config.ufdsLocal.url,
+	bindDN: config.ufdsLocal.bindDN,
+	bindPassword: config.ufdsLocal.bindPassword,
+	cache: config.ufdsLocal.cache,
+	log: config.log
+});
+
+// Create a random valid UFDS username from a uuid
+function generateLogin() {
+	return 'a' + uuid().slice(0, -1).split('-').join('');
+}
+
+// Test that a client can ping the graf-proxy server
+function testServerRunning(args, cb) {
+	const t = args.t;
+	const ufdsInstance = args.ufdsInstance;
+
+	if (!ufdsInstance.connected) {
+		t.fail('ufds instance is not connected');
+		cb();
+		return;
+	}
+	client.get(AUTH_ENDPOINT, function (err, req, res, _) {
+		// We expect a 401, with no credentials
+		if (err && (err.statusCode === 401)) {
+			t.pass('server is responsive');
+		} else if (err) {
+			/*
+			 * err.statusCode will only exist if we actually reached
+			 * the server, so we must account for its absence.
+			 */
+			const codeStr = err.statusCode ?
+				err.statusCode.toString() : '';
+			t.fail('unexpected response: ' + codeStr + ': ' +
+				err.message);
+		} else {
+			t.fail('unexpected successful response');
+		}
+		cb();
+		return;
+	});
+}
+
+/*
+ * Test that an authenticated client with the correct permissions can
+ * successfully access the Grafana instance through graf-proxy
+ */
+function testPrivilegedUser(args, cb) {
+	const t = args.t;
+	const ufdsInstance = args.ufdsInstance;
+	/*
+	 * After adding the test user to the operators group, we need to wait
+	 * for graf-proxy's cached copy of the user to expire so the user's
+	 * new privileges are reflected.
+	 */
+	const waitPeriod = (ufdsInstance.cacheOptions.expiry + 1) * 1000;
+
+	const login = generateLogin();
+	const password = uuid();
+
+	ufdsInstance.addUser({
+		login: login,
+		email: login + '@example.com',
+		userpassword: password
+	}, function (err, user) {
+		if (err) {
+			t.fail('unable to create user', err);
+			cb();
+			return;
+		}
+		user.addToGroup(ADMIN_GROUP, function (groupErr) {
+			if (groupErr) {
+				t.fail('error adding user to operators',
+					groupErr);
+				cleanupUser(ufdsInstance, login, cb);
+				return;
+			}
+			log.info('Waiting for ' + (waitPeriod / 1000) + 's');
+			setTimeout(tryAccess, waitPeriod, 200, t, ufdsInstance,
+				login, password, cb);
+		});
+	});
+}
+
+
+/*
+ * Test that an authenticated client without sufficient permissions cannot
+ * access the Grafana instance through graf-proxy
+ */
+function testUnprivilegedUser(args, cb) {
+	const t = args.t;
+	const ufdsInstance = args.ufdsInstance;
+
+	const login = generateLogin();
+	const password = uuid();
+
+	ufdsInstance.addUser({
+		login: login,
+		email: login + '@example.com',
+		userpassword: password
+	}, function (err, _) {
+		if (err) {
+			t.fail('unable to create user', err);
+			cb();
+			return;
+		} else {
+			tryAccess(403, t, ufdsInstance, login, password,
+				cb);
+			return;
+		}
+	});
+}
+
+/*
+ * Checks whether the provided credentials produce the provided desired response
+ * when sent to the graf-proxy server.
+ */
+function tryAccess(desiredCode, t, ufdsInstance, login, password, cb) {
+	client.basicAuth(login, password);
+	client.get(AUTH_ENDPOINT, function (err, req, res, _) {
+		let successMsg;
+		if (desiredCode < 400) {
+			successMsg = 'privileged access granted';
+		} else {
+			successMsg = 'unprivileged access denied';
+		}
+
+		/*
+		 * If the error doesn't have a status code, we didn't even reach
+		 * the server, so we fail no matter what.
+		 */
+		if (err && !err.statusCode) {
+			t.fail('unexpected response: ' + err.message);
+		} else if (res.statusCode === desiredCode) {
+			/*
+			 * If the error does have a status code, we did get a
+			 * response, so we can safely check it.
+			 */
+			t.pass(successMsg);
+		} else {
+			t.fail('unexpected response: ' + res.statusCode +
+				': ' + res.statusMessage);
+		}
+
+		cleanupUser(ufdsInstance, login, cb);
+	});
+}
+
+// Removes a test user account from ufds
+function cleanupUser(ufdsInstance, login, cb) {
+	ufdsInstance.getUser(login, function (err, user) {
+		if (err) {
+			handleErr(err, user);
+		} else if (user.dclocalconfig) {
+			ufdsInstance.del(user.dclocalconfig.dn,
+				function (delErr) {
+				if (delErr) {
+					cb();
+					return;
+				}
+				ufdsInstance.deleteUser(user, handleErr);
+			});
+		} else {
+			ufdsInstance.deleteUser(user, handleErr);
+		}
+	});
+
+	function handleErr(err, user) {
+		if (err) {
+			log.error('unable to delete user ' + user.login + ': ' +
+				err.message);
+		}
+		cb();
+		return;
+	}
+}
+
+
+function runTests(ufdsInstance) {
+	test('graf-proxy test', function (t) {
+		const testFuncs = [
+			testServerRunning,
+			testPrivilegedUser,
+			testUnprivilegedUser
+		];
+		const args = {
+			t: t,
+			ufdsInstance: ufdsInstance
+		};
+		t.plan(testFuncs.length);
+
+		vasync.pipeline({
+			'arg': args,
+			'funcs': testFuncs
+		}, function (_, results) {
+			t.end();
+			ufdsMaster.close();
+			ufdsLocal.close();
+		});
+	});
+}
+
+// ---- mainline
+
+function setUfds(cb) {
+	function trySetUfds() {
+		if (ufdsMaster.connected) {
+			cb(null, ufdsMaster);
+			return;
+		} else if (ufdsLocal.connected) {
+			cb(null, ufdsLocal);
+			return;
+		} else {
+			setTimeout(trySetUfds, 200);
+			return;
+		}
+	}
+	trySetUfds();
+}
+
+setUfds(function (_, ufdsInstance) {
+	runTests(ufdsInstance);
+});
diff --git a/test/runtests b/test/runtests
new file mode 100644
index 0000000..60d992a
--- /dev/null
+++ b/test/runtests
@@ -0,0 +1,166 @@
+#!/usr/bin/env bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Run the triton-grafana tests.
+# Run `./runtests -h` for usage info.
+#
+
+if [ "$TRACE" != "" ]; then
+    export PS4='${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+
+set -o errexit
+set -o pipefail
+
+#---- guard
+
+if [[ ! -f "/lib/sdc/.sdc-test-no-production-data" ]]; then
+    cat <<EOF
+To run this test you must create the file:
+
+    /lib/sdc/.sdc-test-no-production-data
+
+after ensuring you have no production data on this SDC.
+EOF
+    exit 2
+fi
+
+#---- config
+
+NAME=triton-grafana
+TOP=$(cd $(dirname $0)/../; pwd)
+
+#---- support functions
+
+function fatal
+{
+    echo "$(basename $0): fatal error: $*"
+    exit 1
+}
+
+function usage
+{
+    echo "Usage:"
+    echo "  runtests [OPTIONS...]"
+    echo ""
+    echo "Options:"
+    echo "  -f FILTER   Filter pattern (substring match) for test files to run."
+}
+
+#---- mainline
+
+start_time=$(date +%s)
+
+# Options.
+opt_test_pattern=
+while getopts "hf:" opt
+do
+    case "$opt" in
+        h)
+            usage
+            exit 0
+            ;;
+        f)
+            opt_test_pattern=$OPTARG
+            ;;
+        *)
+            usage
+            exit 1
+            ;;
+    esac
+done
+
+OUTPUT_DIR=/var/tmp/${NAME}test
+echo "# Create output dir ($OUTPUT_DIR)."
+rm -rf $OUTPUT_DIR
+mkdir -p $OUTPUT_DIR
+
+#---- start tests
+
+NODE=${TOP}/build/node/bin/node
+
+test_files=$(ls -1 ${TOP}/test/*.test.js)
+if [[ -n "$opt_test_pattern" ]]; then
+    test_files=$(echo "$test_files" | grep "$opt_test_pattern" || true)
+    echo "# Running filtered set of test files: $test_files"
+fi
+
+for filename in $test_files; do
+    f_no_ext=$(basename ${filename} '.js')
+    ${NODE} ${filename} | tee "${OUTPUT_DIR}/${f_no_ext}.tap" || true
+done
+
+#---- summary
+
+end_time=$(date +%s)
+elapsed=$((${end_time} - ${start_time}))
+
+# We require leading spaces in our search pattern to ensure that we limit our
+# search to subtest results.
+tests=$(grep -Eh "^ +1\.\.[0-9]" ${OUTPUT_DIR}/*.tap | \
+    sed -E 's/^ +//g' | cut -d '.' -f3 | xargs | tr ' ' '+' | bc) || true
+failed=$(grep -Eh "^ +# failed [0-9]" ${OUTPUT_DIR}/*.tap | \
+    sed -E 's/^ +//g' | cut -d ' ' -f3 | xargs | tr ' ' '+' | bc) || true
+skipped=$(grep -Eh "^ +# skip: [0-9]" ${OUTPUT_DIR}/*.tap | \
+    sed -E 's/^ +//g' | cut -d ' ' -f3 | xargs | tr ' ' '+' | bc) || true
+
+
+# Filter out bunyan output, then grep for "function: " line, then get last
+# word on the line, which is the function name.
+failed_test_names=$(grep -Ehv "\{|\}" ${OUTPUT_DIR}/*.tap | \
+    grep -E "^ +function" | rev | cut -d ' ' -f1 | rev) || true
+
+[[ -z ${tests} ]] && tests=0
+[[ -z ${failed} ]] && failed=0
+[[ -z ${skipped} ]] && skipped=0
+
+passed=$((${tests} - ${failed} - ${skipped}))
+
+if [[ -t 1 ]]; then
+    # We're on a terminal, so use color
+    COLOR_GREEN="\033[32m"
+    COLOR_RED="\033[31m"
+    COLOR_ORANGE="\033[33m"
+    COLOR_NORMAL="\033[39m"
+else
+    # no terminal, no color
+    COLOR_GREEN=
+    COLOR_RED=
+    COLOR_ORANGE=
+    COLOR_NORMAL=
+fi
+
+# Output the summary
+echo "#"
+echo "# TESTS COMPLETE IN ${elapsed} SECONDS, SUMMARY:"
+echo "#"
+echo -e "#   ${COLOR_GREEN}PASS: ${passed} / ${tests}${COLOR_NORMAL}"
+if [[ ${skipped} -gt 0 ]]; then
+    echo -e "#   ${COLOR_ORANGE}SKIP: ${skipped} / ${tests}${COLOR_NORMAL}"
+fi
+if [[ ${failed} -gt 0 ]]; then
+    echo -e "#   ${COLOR_RED}FAIL: ${failed} / ${tests}${COLOR_NORMAL}"
+    echo "#"
+    echo "# FAILED TESTS:"
+    echo "#"
+    for t in ${failed_test_names}; do
+        echo "#   - ${t}"
+    done
+fi
+echo "#"
+
+if [[ ${failed} -gt 0 ]]; then
+    exit 1
+fi
+
+exit 0
diff --git a/tools/download_go b/tools/download_go
new file mode 100755
index 0000000..69e9a3e
--- /dev/null
+++ b/tools/download_go
@@ -0,0 +1,126 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# This program will download a Go toolchain for a particular system.  It
+# currently expects to find illumos builds of the toolchain on the Joyent
+# download server, where we will be placing them alongside sdcnode, etc.
+# The program is designed specifically to be used as part of a make target.
+#
+# We may revisit this once the Go project makes official builds for illumos
+# systems available in the future.
+#
+# NOTE: This program comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This program accepts four arguments, in the following order:
+#
+#	GOVERSION	The version of the Go toolchain to use; e.g., "1.9.2"
+#	GOOS		The build machine operating system; e.g., "solaris"
+#	GOARCH		The build machine CPU architecture; e.g., "amd64"
+#	OUTDIR		The local directory into which the downloaded tar
+#			file will be placed.
+#
+# The program will use the provided arguments to find and download an archive
+# of the Go toolchain for use on the build machine.  The archive will be named
+# for a combination of the provided arguments; e.g.,
+# "go1.9.2.solaris-amd64.tar.bz2".  A target symbolic link will also be
+# created, with just the version number in the name; e.g., "go-1.9.2.tar.bz2".
+# If the archive could not be downloaded, an error message will be printed and
+# the output file and target link will be unaffected.
+#
+
+BASEURL='https://download.joyent.com/pub/build/go/adhoc/'
+GOVERSION=$1
+GOOS=$2
+GOARCH=$3
+OUTDIR=$4
+
+if [[ -z $GOVERSION || -z $GOOS || -z $GOARCH || -z $OUTDIR ]]; then
+	printf 'ERROR: usage: download_go GOVERSION GOOS GOARCH OUTDIR\n' 2>&1
+	exit 1
+fi
+
+if [[ ! -d $OUTDIR ]]; then
+	printf 'ERROR: output directory "%s" does not exist\n' "$OUTDIR" 2>&1
+	exit 1
+fi
+
+TARGET="go-$GOVERSION.tar.bz2"
+
+#
+# Download the index page which lists the current set of available go
+# builds:
+#
+if ! list=$(curl -sSfL "$BASEURL") || [[ -z "$list" ]]; then
+	printf 'ERROR: could not download index page\n' >&2
+	exit 1
+fi
+
+#
+# Using only commonly found household items, extract the full name of the
+# go tar archive we need.  This program needs to be able to operate in a
+# minimally populated build zone, so we avoid using anything beyond basic
+# UNIX tools like "awk".
+#
+# One word to describe this process might be "brittle".
+#
+if ! name=$(/usr/bin/awk -v "v=$GOVERSION" -v "o=$GOOS" -v "a=$GOARCH" -F\" '
+    BEGIN { pattern = "^go"v"."o"-"a".tar.bz2$"; }
+    $1 == "<a href=" && $2 ~ pattern { print $2 }' <<< "$list") ||
+    [[ -z "$name" ]]; then
+	printf 'ERROR: could not locate file name in index page\n' >&2
+	printf '\t(Does Go version %s (%s-%s) exist?)\n' \
+	    "$GOVERSION" "$GOOS" "$GOARCH" >&2
+	exit 1
+fi
+
+
+#
+# If the full file name of the latest go build does not exist, download it now
+# to a temporary file.  If it succeeds, move it into place.
+#
+output_file="$OUTDIR/$name"
+if [[ ! -f $output_file ]]; then
+	printf 'Downloading Go: %s\n' "$BASEURL$name"
+
+	temp_file="$OUTDIR/.tmp.$name.$$"
+	rm -f "$temp_file"
+
+	if ! curl -sSf -o "$temp_file" "$BASEURL$name"; then
+		printf 'ERROR: could not download go\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+
+	if ! mv "$temp_file" "$output_file"; then
+		printf 'ERROR: could not move tar file into place\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+fi
+
+#
+# Make sure the target link points at the correct file:
+#
+rm -f "$OUTDIR/$TARGET"
+if ! ln -s "$name" "$OUTDIR/$TARGET"; then
+	printf 'ERROR: could not create target link\n' >&2
+	exit 1
+fi
+
+exit 0
+
+# vim: set ts=8 sts=8 sw=8 noet:
diff --git a/tools/mk/Makefile.defs b/tools/mk/Makefile.defs
new file mode 100644
index 0000000..73dd612
--- /dev/null
+++ b/tools/mk/Makefile.defs
@@ -0,0 +1,105 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Makefile.defs: common defines.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This makefile defines some useful defines. Include it at the top of
+# your Makefile.
+#
+# Definitions in this Makefile:
+#
+#	TOP 		The absolute path to the project directory. The top dir.
+#	BRANCH 		The current git branch.
+#	TIMESTAMP	The timestamp for the build. This can be set via
+#			the TIMESTAMP envvar (used by MG-based builds).
+#	STAMP		A build stamp to use in built package names.
+#
+#	MAKE_STAMPS_DIR	The directory in which make stamp files are to be
+#			created.  See comments below on expensive targets.
+#
+#	CACHE_DIR	A directory tree in which temporary files may be
+#			collected by download, tarball extraction, etc.  This
+#			directory is completely removed by "make distclean".
+#			Files in this directory are not intended to be shipped.
+#
+
+TOP := $(shell pwd)
+
+#
+# Mountain Gorilla-spec'd versioning.
+# See "Package Versioning" in MG's README.md:
+# <https://mo.joyent.com/mountain-gorilla/blob/master/README.md#L139-200>
+#
+# Need GNU awk for multi-char arg to "-F".
+_AWK := $(shell (which gawk >/dev/null && echo gawk) \
+	|| (which nawk >/dev/null && echo nawk) \
+	|| echo awk)
+BRANCH := $(shell git symbolic-ref HEAD | $(_AWK) -F/ '{print $$3}')
+ifeq ($(TIMESTAMP),)
+	TIMESTAMP := $(shell date -u "+%Y%m%dT%H%M%SZ")
+endif
+_GITDESCRIBE := g$(shell git describe --all --long --dirty | $(_AWK) -F'-g' '{print $$NF}')
+STAMP := $(BRANCH)-$(TIMESTAMP)-$(_GITDESCRIBE)
+
+# node-gyp will print build info useful for debugging with V=1
+export V=1
+
+CACHE_DIR ?=		cache
+DISTCLEAN_FILES +=	$(CACHE_DIR)
+
+#
+# EXPENSIVE TARGETS AND MAKE STAMP FILES
+#
+# Targets which are expensive to run and lack a single file that marks
+# completion are difficult to track with make; e.g., "npm install".  One
+# solution to this problem is to create "stamp" files with symbolic names which
+# are created as the final step in a complex make rule in order to mark
+# completion.
+#
+# In order to make these more uniform, and easier to target with "make clean",
+# we will attempt to store them under a single directory.  Note that these
+# files are never targets for shipping in build artefacts.
+#
+# Stamp-backed targets come in several parts.  First, a macro should be defined
+# which names a file in the MAKE_STAMPS_DIR directory.  Then, a target which
+# creates this stamp file must be provided.  The recipe for this target should
+# use MAKE_STAMP_REMOVE and MAKE_STAMP_CREATE to perform the appropriate stamp
+# management.
+#
+# For example:
+#
+# --- Makefile.*.defs:
+#
+#	$(STAMP_EXPENSIVE_RESULT) := $(MAKE_STAMPS_DIR)/expensive-result
+#
+# --- Makefile.*.targ:
+#
+#	$(STAMP_EXPENSIVE_RESULT): input/file another/input/file
+#		$(MAKE_STAMP_REMOVE)
+#		rm -rf output_tree/  # <--- ensure a clean slate
+#		expensive_program -o output_tree/ $^
+#		$(MAKE_STAMP_CREATE)
+#
+# NOTE: Every stamp file is exposed as an implicit "stamp-$STAMP_NAME" target.
+# The example above could be built manually by invoking:
+#
+#	make stamp-expensive-result
+#
+MAKE_STAMPS_DIR ?=	make_stamps
+CLEAN_FILES +=		$(MAKE_STAMPS_DIR)
+
+MAKE_STAMP_REMOVE =	mkdir -p $(@D); rm -f $(@)
+MAKE_STAMP_CREATE =	mkdir -p $(@D); touch $(@)
diff --git a/tools/mk/Makefile.deps b/tools/mk/Makefile.deps
new file mode 100644
index 0000000..91f8346
--- /dev/null
+++ b/tools/mk/Makefile.deps
@@ -0,0 +1,87 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.deps: Makefile for including common tools as dependencies
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This file is separate from Makefile.targ so that teams can choose
+# independently whether to use the common targets in Makefile.targ and the
+# common tools here.
+#
+
+#
+# javascriptlint
+#
+JSL_EXEC	?= deps/javascriptlint/build/install/jsl
+JSL		?= $(JSL_EXEC)
+
+$(JSL_EXEC): | deps/javascriptlint/.git
+	cd deps/javascriptlint && make install
+
+distclean::
+	if [[ -f deps/javascriptlint/Makefile ]]; then \
+		cd deps/javascriptlint && make clean; \
+	fi
+
+#
+# jsstyle
+#
+JSSTYLE_EXEC	?= deps/jsstyle/jsstyle
+JSSTYLE		?= $(JSSTYLE_EXEC)
+
+$(JSSTYLE_EXEC): | deps/jsstyle/.git
+
+#
+# eslint
+#
+ESLINT_EXEC	?= node_modules/.bin/eslint
+ifdef NODE
+    ESLINT	:= $(NODE) $(ESLINT_EXEC)
+else
+    ESLINT	?= $(ESLINT_EXEC)
+endif
+
+# Install eslint.
+#
+# The install of specific modules is to allow running "make check"
+# without having to do a complete install of all npm dependencies.
+#
+# NPM_EXEC will be defined if either of "Makefile.{node,node_prebuilt}.defs"
+# is included.
+ifdef NPM
+$(ESLINT_EXEC): package.json | $(NPM_EXEC)
+	ESLINT_VER=$$($(NODE) -e 'console.log(require("./package.json").devDependencies["eslint"] || "")') && \
+	    ESLINT_JOY_VER=$$($(NODE) -e 'console.log(require("./package.json").devDependencies["eslint-plugin-joyent"] || "")') && \
+	    [[ -n $$ESLINT_VER && -n $$ESLINT_JOY_VER ]] && \
+	    $(NPM) install --no-save eslint@$$ESLINT_VER eslint-plugin-joyent@$$ESLINT_JOY_VER && \
+	    touch $(ESLINT_EXEC)
+else
+$(ESLINT_EXEC): package.json
+	ESLINT_VER=$$(node -e 'console.log(require("./package.json").devDependencies["eslint"] || "")') && \
+	    ESLINT_JOY_VER=$$(node -e 'console.log(require("./package.json").devDependencies["eslint-plugin-joyent"] || "")') && \
+	    [[ -n $$ESLINT_VER && -n $$ESLINT_JOY_VER ]] && \
+	    npm install --no-save eslint@$$ESLINT_VER eslint-plugin-joyent@$$ESLINT_JOY_VER && \
+	    touch $(ESLINT_EXEC)
+endif
+
+#
+# restdown
+#
+RESTDOWN_EXEC	?= deps/restdown/bin/restdown
+RESTDOWN	?= python $(RESTDOWN_EXEC)
+$(RESTDOWN_EXEC): | deps/restdown/.git
+
+EXTRA_DOC_DEPS	?=
diff --git a/tools/mk/Makefile.go_prebuilt.defs b/tools/mk/Makefile.go_prebuilt.defs
new file mode 100644
index 0000000..23c2ed8
--- /dev/null
+++ b/tools/mk/Makefile.go_prebuilt.defs
@@ -0,0 +1,132 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Makefile.go_prebuilt.defs: Makefile for obtaining a prebuilt Go toolchain.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile aids in the download and operation of a Go toolchain when
+# building software written in the Go language.  It provides as much isolation
+# from the broader build host as possible, including the provision of a
+# project-local GOPATH and GOROOT.
+#
+# This Makefile is intended to be used along with "Makefile.go_prebuilt.targ".
+#
+# When using this Makefile, you MUST define these variables before the include
+# directive:
+#
+#	GO_PREBUILT_VERSION	The version of the Go toolchain to download
+#				and use.  For example, "1.9".
+#
+# You MAY also specify the following variables:
+#
+#	GO_ENV			A list of environment variable specifications
+#				in shell syntax which will be prepended to Go
+#				toolchain invocations.  Using the "+=" operator,
+#				it is possible to add to the list without
+#				overriding the base environment specified by
+#				this Makefile.
+#
+# This Makefile provides definitions for the following variables:
+#
+#	GO_INSTALL		The location of the Go toolchain, relative
+#				to $(TOP).
+#
+#	GO_GOPATH		The location of the project-local GOPATH
+#				directory, relative to $(TOP).
+#
+#	GO			To be used in place of a bare invocation of
+#				"go"; e.g., "go build" would become
+#				"$(GO) build".  This invocation uses env(1)
+#				and $(GO_ENV) to construct an isolated
+#				environment.
+#
+
+ifndef TOP
+$(error You must include Makefile.defs before this makefile.)
+endif
+
+ifndef CACHE_DIR
+$(error You must include Makefile.defs before this makefile.)
+endif
+
+ifndef GO_PREBUILT_VERSION
+$(error GO_PREBUILT_VERSION must be set before including this makefile.)
+endif
+
+GO_VERSION =			$(GO_PREBUILT_VERSION)
+
+#
+# This Makefile is presently used to build programs written in the Go language
+# to be shipped in zone images.  As such, we default to a target specification
+# which is appropriate for an illumos host.
+#
+GO_GOOS ?=			solaris
+GO_GOARCH ?=			amd64
+
+#
+# The "tools/download_go" script will obtain a Go toolchain tar archive, which
+# we will store in the $(CACHE_DIR).  This directory is be removed entirely by
+# "make distclean".
+#
+GO_TARBALL =			$(CACHE_DIR)/go-$(GO_PREBUILT_VERSION).tar.bz2
+
+#
+# The downloaded Go toolchain will be extracted into a directory under
+# $(CACHE_DIR) by the $(STAMP_GO_TOOLCHAIN) target.  This directory becomes
+# the value of $GOROOT for toolchain invocations.
+#
+GO_INSTALL =			$(CACHE_DIR)/go-$(GO_VERSION)
+
+#
+# Parts of the Go toolchain store intermediate build artefacts in the GOPATH
+# directory.  At the time of writing, at least some of these intermediate
+# artefacts cannot be reused by different versions of the toolchain.  There
+# does not appear to be any mechanism in place to _prevent_ an error of this
+# type, so we include the Go toolchain version in the project-local GOPATH
+# directory name.
+#
+GO_GOPATH =			$(CACHE_DIR)/gopath-$(GO_VERSION)
+
+#
+# The Go toolchain derives some amount of behaviour from the environment.  In
+# order to precisely control that behaviour, we build up our own environment
+# containing only the expected values and run the tool under "env -i", thus
+# precluding any other variables from leaking in:
+#
+GO_ENV +=			GOROOT="$(TOP)/$(GO_INSTALL)"
+GO_ENV +=			GOPATH="$(TOP)/$(GO_GOPATH)"
+GO_ENV +=			GOARCH="$(GO_GOARCH)"
+GO_ENV +=			GOOS="$(GO_GOOS)"
+GO_ENV +=			PATH="$(TOP)/$(GO_INSTALL)/bin:$$PATH"
+
+#
+# The $(GO) variable should be used in place of bare invocations of "go".
+# For example, instead of "go build", use "$(GO) build".
+#
+GO =				env -i $(GO_ENV) $(TOP)/$(GO_INSTALL)/bin/go
+
+#
+# If the version of Go is changed in the Makefile, or interactively, we need
+# to make sure the new version is downloaded and installed.  As such, the
+# stamp name needs to include the version.
+#
+STAMP_GO_TOOLCHAIN =		$(MAKE_STAMPS_DIR)/go-toolchain-$(GO_VERSION)
+
+#
+# A regular "make clean" should remove any cached build artefacts from GOPATH.
+#
+CLEAN_FILES +=			$(GO_GOPATH)
diff --git a/tools/mk/Makefile.go_prebuilt.targ b/tools/mk/Makefile.go_prebuilt.targ
new file mode 100644
index 0000000..d0f998c
--- /dev/null
+++ b/tools/mk/Makefile.go_prebuilt.targ
@@ -0,0 +1,55 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# Makefile.go_prebuilt.targ: Makefile for obtaining a prebuilt Go toolchain.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# For usage documentation, see the comments in "Makefile.go_prebuilt.defs".
+#
+
+ifndef GO_TARBALL
+$(error You must include Makefile.go_prebuilt.defs first.)
+endif
+
+#
+# Download a prebuilt copy of the Go toolchain.  There are not presently builds
+# available for illumos systems on the official Go site, so we have an
+# appropriate build stored on a Joyent server.
+#
+# Note that the GOOS and GOARCH values provided here are for the toolchain to
+# run on this machine: the build machine.  The Go toolchain is a cross
+# compiler, and the GO_GOOS and GO_GOARCH make variables represent the intended
+# _target_ for any executables built with the Go compiler.  Though it is
+# likely, at least for now, that these values are the same in our environment
+# for the build and target machines, they are nonetheless distinct concepts and
+# the use of GO_GOOS and GO_GOARCH here would not be correct.
+#
+$(GO_TARBALL):
+	rm -f $@
+	mkdir -p $(@D)
+	tools/download_go $(GO_PREBUILT_VERSION) solaris amd64 $(CACHE_DIR)
+
+#
+# Extract the Go toolchain.  This stamp includes the version number of the
+# Go toolchain, ensuring a new download and extraction if the version changes.
+#
+$(STAMP_GO_TOOLCHAIN): $(GO_TARBALL)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf $(GO_INSTALL)
+	mkdir $(GO_INSTALL)
+	cd $(GO_INSTALL) && tar xfj $(TOP)/$(GO_TARBALL)
+	$(MAKE_STAMP_CREATE)
diff --git a/tools/mk/Makefile.manpages.defs b/tools/mk/Makefile.manpages.defs
new file mode 100644
index 0000000..6da7876
--- /dev/null
+++ b/tools/mk/Makefile.manpages.defs
@@ -0,0 +1,128 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2016, Joyent, Inc.
+#
+
+#
+# Makefile.manpages.defs: targets for building manual pages.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile is used along with Makefile.manpages.targ to build section
+# manpages for the current repository from Markdown sources using the md2man
+# tool.  You can build several different sections of manpages with this
+# Makefile, but you'll need to include the Makefile once for each section with a
+# different value of MAN_SECTION.  Required input variables include:
+#
+#     MAN_SECTION	defines which section's manpages will be built
+#     			(e.g., "1")
+#
+#     MAN_INROOT	defines the root of a directory tree containing man
+#     			pages source files in Markdown format.  The directory
+#     			tree should be organized as:
+#
+#     			    $(MAN_INROOT)/man$(MAN_SECTION)/*.md
+#
+#     MAN_OUTROOT	defines the root of a directory tree that will contain
+#     			the generated man pages.  The directory tree will be
+#     			organized as:
+#
+#     			    $(MAN_OUTROOT)/man$(MAN_SECTION)/*.$(MAN_SECTION)
+#
+#			This should mirror the typical man page directory
+#			structure, and should probably be alongside a
+#			corresponding "bin" directory to leverage the way
+#			man(1)'s looks up man pages for binaries.
+#
+# A common configuration would be to set MAN_INROOT = "docs/man" and
+# MAN_OUTROOT = "man".  In that case, you might have source files:
+#
+#     ./bin/mytool
+#     ./bin/my-other-tool
+#     ./docs/man/man1/mytool.md
+#     ./docs/man/man1/my-other-tool.md
+#
+# and that will generate files:
+#
+#     ./man/man1/mytool.1
+#     ./man/man1/my-other-tool.1
+#
+# Optional input variables include:
+#
+#     MD2MAN		tool to generate man pages from Markdown sources
+#     			The recommended tool is md2man-roff, available at
+#     			https://github.com/sunaku/md2man.
+#
+#     MKDIRP		should generally be "mkdir -p"
+#
+# This Makefile produces Make variables:
+#
+#     MAN_$(MAN_SECTION)_OUTPUTS	generated manual pages.  You can depend
+#     					on these in order to build them in
+#     					whatever top-level targets you want.
+#
+#     MAN_OUTPUTS			will be extended to include
+#     					MAN_$(MAN_SECTION)_OUTPUTS.
+#
+# There are two basic ways this tends to be used:
+#
+#     (1) Building manpages is part of the normal build.  Have the default
+#         target (usually "all") depends on either "manpages" or the built man
+#         pages directly (via MAN_OUTPAGES).  In this case, only the man pages
+#         _sources_ would be checked into source control.
+#
+#     (2) Building manpages is an ad-hoc operation outside the normal build
+#         process.  Developers that change the man page sources are expected to
+#         build the man pages and commit the generated pages into source
+#         control.
+#
+# Option (1) is preferred, since option (2) violates the basic tenets of
+# software engineering that processes should generally be automated and that
+# generated files should not be checked into source control.  The problem is
+# that in practice, the tools that we use to generate man pages are not widely
+# installed on most users' systems, even developers' systems, so it's less than
+# ideal to require them for the main build.  This is especially true for many of
+# our Node modules, where there's traditionally no difference between the
+# published npm package and the repository source itself.  As a result, we use
+# option (2) in most places.  However, this Makefile supports both modes.
+#
+
+MAN_SECTION			?= $(error MAN_SECTION is not defined)
+MAN_INROOT			?= $(error MAN_INROOT is not defined)
+MAN_OUTROOT			?= $(error MAN_OUTROOT is not defined)
+MD2MAN				?= md2man-roff
+MKDIRP				?= mkdir -p
+
+#
+# Define some convenience variables for referring to the input and output
+# directories for this section's man pages.  These variables must have
+# MAN_SECTION in the name, and must use eager binding (":="), since MAN_SECTION
+# may change after this file is included.
+#
+MAN_INDIR_$(MAN_SECTION)	:= $(MAN_INROOT)/man$(MAN_SECTION)
+MAN_OUTDIR_$(MAN_SECTION)	:= $(MAN_OUTROOT)/man$(MAN_SECTION)
+
+#
+# Define the lists of input and output files for this section's man pages.  The
+# list of inputs is just the list of Markdown files in the input directory.  We
+# construct the list of outputs by taking that same list and replacing the
+# section-specific input directory with the section-specific output directory
+# and changing the file extension.
+#
+MAN_$(MAN_SECTION)_INPUTS	:= $(wildcard $(MAN_INDIR_$(MAN_SECTION))/*.md)
+MAN_$(MAN_SECTION)_OUTPUTS_TMP  := \
+    $(MAN_$(MAN_SECTION)_INPUTS:$(MAN_INDIR_$(MAN_SECTION))/%=$(MAN_OUTDIR_$(MAN_SECTION))/%)
+MAN_$(MAN_SECTION)_OUTPUTS	:= \
+    $(MAN_$(MAN_SECTION)_OUTPUTS_TMP:%.md=%.$(MAN_SECTION))
+
+MAN_OUTPUTS			:= $(MAN_OUTPUTS) $(MAN_$(MAN_SECTION)_OUTPUTS)
diff --git a/tools/mk/Makefile.manpages.targ b/tools/mk/Makefile.manpages.targ
new file mode 100644
index 0000000..11f242b
--- /dev/null
+++ b/tools/mk/Makefile.manpages.targ
@@ -0,0 +1,28 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2016, Joyent, Inc.
+#
+
+#
+# Makefile.manpages.targ: targets for building manual pages.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# See Makefile.manpages.defs.
+#
+
+$(MAN_$(MAN_SECTION)_OUTPUTS): $(MAN_OUTDIR_$(MAN_SECTION))/%.$(MAN_SECTION): $(MAN_INDIR_$(MAN_SECTION))/%.md | $(MAN_OUTDIR_$(MAN_SECTION))
+	$(MD2MAN) $^ > $@
+
+$(MAN_OUTDIR_$(MAN_SECTION)):
+	$(MKDIRP) $@
diff --git a/tools/mk/Makefile.nginx.defs b/tools/mk/Makefile.nginx.defs
new file mode 100644
index 0000000..88c216f
--- /dev/null
+++ b/tools/mk/Makefile.nginx.defs
@@ -0,0 +1,33 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright 2017, Joyent, Inc.
+#
+
+#
+# Makefile.nginx.defs: Makefile for building nginx
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+
+BUILD		?= build
+NGINX_INSTALL 	?= $(BUILD)/nginx
+DISTCLEAN_FILES	+= $(NGINX_INSTALL)
+
+NGINX_CONFIG_FLAGS += \
+	--prefix=$(TOP)/$(NGINX_INSTALL) \
+	--with-http_ssl_module \
+	--with-http_auth_request_module \
+	--with-cc-opt="-m64 -std=gnu99 -I/opt/local/include" \
+	--with-ld-opt="-m64 -L/opt/local/lib -R/opt/local/lib -lumem"
+
+NGINX_EXEC	= $(NGINX_INSTALL)/sbin/nginx
+
+# Ensure these use absolute paths to the executables to allow running
+# from a dir other than the project top.
+NGINX		:= $(TOP)/$(NGINX_EXEC)
diff --git a/tools/mk/Makefile.nginx.targ b/tools/mk/Makefile.nginx.targ
new file mode 100644
index 0000000..f0a83e6
--- /dev/null
+++ b/tools/mk/Makefile.nginx.targ
@@ -0,0 +1,34 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.nginx.targ: See Makefile.nginx.defs.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+deps/nginx/auto/configure: | deps/nginx/.git
+
+deps/nginx/Makefile: deps/nginx/auto/configure
+	cd deps/nginx && ./auto/configure $(NGINX_CONFIG_FLAGS)
+
+.PHONY: $(NGINX_EXEC)
+$(NGINX_EXEC): | deps/nginx/Makefile
+	(cd deps/nginx && $(MAKE) && $(MAKE) install)
+
+
+DISTCLEAN_FILES += $(NGINX_INSTALL)
+
+distclean::
+	-([[ -d deps/nginx ]] && cd deps/nginx && $(MAKE) clean)
diff --git a/tools/mk/Makefile.node.defs b/tools/mk/Makefile.node.defs
new file mode 100644
index 0000000..487824d
--- /dev/null
+++ b/tools/mk/Makefile.node.defs
@@ -0,0 +1,110 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node.defs: Makefile for building and bundling your own Node.js.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile facilitates building and bundling your own copy of Node.js in
+# your repo.  All it does is define variables for node, node-waf, and npm for
+# you to use elsewhere in your Makefile and rules to build these tools when
+# needed.
+#
+# To use this facility, include "Makefile.node.defs", use the variables as
+# described below to define targets, and then include "Makefile.node.targ".
+#
+# There are two use cases addressed here:
+#
+# (1) Invoking node, node-waf, or npm as part of the build process, as in "npm
+#     install" and "node-waf configure build".  To facilitate this, this
+#     Makefile defines Make variables NODE, NODE_WAF, and NPM that you can use
+#     to invoke these commands during the build process.  You MUST NOT assume
+#     that these variables just evaluate to the filenames themselves, as they
+#     may have environment variable definitions and other things that prevent
+#     you from using them directly as a filename.  If you want that, see (2).
+#
+#     Wherever you use one of these variables, you MUST include a dependency on
+#     the corresponding *_EXEC variable as well, like so:
+#
+#	node_modules/restify: deps/restify $(NPM_EXEC)
+#		$(NPM) install deps/restify
+#
+#     or better, use an order-only dependency to avoid spurious rebuilds:
+#
+#	node_modules/restify: deps/restify | $(NPM_EXEC)
+#		$(NPM) install deps/restify
+#
+#     Otherwise, the underlying file will not get built.  We don't
+#     automatically build them as part of "all" because that approach is
+#     brittle.
+#
+# (2) Specifying paths for invoking node, node-waf, or npm at RUNTIME, as in
+#     specifying the path to node used for the start method of your service's
+#     SMF manifest.  For this, this Makefile defines variables NODE_EXEC,
+#     NODE_WAF_EXEC, and NPM_EXEC, which represent the relative paths of these
+#     files from the root of the workspace.  You MUST NOT use these variables
+#     to invoke these commands during the build process.  See (1) instead.
+#
+#     However, in order to work at runtime, you must build the tool as well.
+#     That is, if you use NODE_EXEC to specify the path to node, you must
+#     depend on NODE_EXEC somewhere. This usually happens anyway because you
+#     usually need them during the build process too, but if you don't then
+#     you need to explicitly add NODE_EXEC (or whichever) to your "all"
+#     target.
+#
+# When including this Makefile, you MAY also specify:
+#
+#	BUILD			top-level directory for built binaries
+#				(default: "build")
+#
+#	NODE_INSTALL		where node should install its built items
+#				(default: "$BUILD/node")
+#
+#	NODE_CONFIG_FLAGS	extra flags to pass to Node's "configure"
+#				(default: "--with-dtrace" on SmartOS; empty
+#				otherwise.)
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+
+BUILD		?= build
+NODE_INSTALL 	?= $(BUILD)/node
+DISTCLEAN_FILES	+= $(NODE_INSTALL)
+
+NODE_CONFIG_FLAGS += --prefix=$(TOP)/$(NODE_INSTALL)
+
+ifeq ($(shell uname -s),SunOS)
+	NODE_CONFIG_FLAGS += 	--with-dtrace \
+				--openssl-libpath=/opt/local/lib \
+				--openssl-includes=/opt/local/include
+endif
+
+NODE_EXEC	= $(NODE_INSTALL)/bin/node
+NODE_WAF_EXEC	= $(NODE_INSTALL)/bin/node-waf
+NPM_EXEC	= $(NODE_INSTALL)/bin/npm
+
+#
+# These paths should be used during the build process to invoke Node and
+# Node-related build tools like NPM.  All paths are fully qualified so that
+# they work regardless of the current working directory at the point of
+# invocation.
+#
+# Note that where PATH is overridden, the value chosen must cause execution of
+# "node" to find the same binary to which the NODE macro refers.
+#
+NODE		:= $(TOP)/$(NODE_EXEC)
+NODE_WAF	:= $(TOP)/$(NODE_WAF_EXEC)
+NPM		:= PATH=$(TOP)/$(NODE_INSTALL)/bin:$(PATH) $(NODE) $(TOP)/$(NPM_EXEC)
diff --git a/tools/mk/Makefile.node.targ b/tools/mk/Makefile.node.targ
new file mode 100644
index 0000000..bf53f78
--- /dev/null
+++ b/tools/mk/Makefile.node.targ
@@ -0,0 +1,42 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.node.targ: See Makefile.node.defs.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+ifneq ($(shell uname -s),SunOS)
+NODE_PREBUILT_VERSION ?= $(error You must define NODE_PREBUILT_VERSION to use Makefile.node.targ on non-SunOS)
+endif
+
+ifeq ($(shell uname -s),SunOS)
+$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC): | deps/node/.git
+	(cd deps/node; ./configure $(NODE_CONFIG_FLAGS) && $(MAKE) && $(MAKE) install)
+else
+$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC):
+	(mkdir -p $(BUILD) \
+		&& cd $(BUILD) \
+		&& [[ -d src-node ]] && (cd src-node && git checkout master && git pull) || git clone https://github.com/joyent/node.git src-node \
+		&& cd src-node \
+		&& git checkout $(NODE_PREBUILT_VERSION) \
+		&& ./configure $(NODE_CONFIG_FLAGS) \
+		&& $(MAKE) && $(MAKE) install)
+endif
+
+DISTCLEAN_FILES += $(NODE_INSTALL) $(BUILD)/src-node
+
+distclean::
+	-([[ ! -d deps/node ]] || (cd deps/node && $(MAKE) distclean))
diff --git a/tools/mk/Makefile.node_modules.defs b/tools/mk/Makefile.node_modules.defs
new file mode 100644
index 0000000..ec8cc8e
--- /dev/null
+++ b/tools/mk/Makefile.node_modules.defs
@@ -0,0 +1,68 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node_modules.defs: Makefile for using NPM modules.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile provides a target for building NPM modules from the dependency
+# information in the "package.json" file.  The "npm install" operation is
+# expensive and produces a complex (multi-file) result which is difficult for
+# make to use in dependency analysis.  As such, we use a "stamp" file to track
+# successful completion of module installation.
+#
+# This variable allows the consumer to influence the environment used to run
+# NPM commands.
+#
+#	NPM_ENV			This string should be set to a list of
+#				environment variables in the syntax used
+#				by bash; e.g.,
+#
+#					NPM_ENV =	TESTING=yes V=1
+#
+# Consumers should, for targets which depend on the installation of NPM
+# modules, depend on the stamp file using the $(STAMP_NODE_MODULES) variable,
+# e.g.:
+#
+#	.PHONY: all
+#	all: $(STAMP_NODE_MODULES)
+#
+# A phony target, "make stamp-node-modules", is also provided to allow the
+# engineer to manually perform NPM module installation without invoking other
+# targets.  Note that this target should _not_ be used as a dependency for
+# other targets in consuming Makefiles; using phony targets to represent
+# intermediate build stages can inhibit the ability of make to determine
+# when no additional actions are required.
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+NPM ?= $(error You must include either Makefile.node.defs or \
+    Makefile.node_prebuilt.defs before this makefile)
+
+BUILD ?=		build
+
+#
+# Invoking "npm install" at the top-level will create a "node_modules"
+# directory into which NPM modules will be installed.
+#
+CLEAN_FILES +=		node_modules
+
+#
+# To avoid repeatedly reinstalling from NPM, we create a "stamp" file to track
+# successful runs of "npm install".  Note that MAKE_STAMPS_DIR is included
+# in CLEAN_FILES already.
+#
+STAMP_NODE_MODULES ?=	$(MAKE_STAMPS_DIR)/node-modules
diff --git a/tools/mk/Makefile.node_modules.targ b/tools/mk/Makefile.node_modules.targ
new file mode 100644
index 0000000..0156bce
--- /dev/null
+++ b/tools/mk/Makefile.node_modules.targ
@@ -0,0 +1,31 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node_modules.targ: See comments in Makefile.node_modules.defs.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+STAMP_NODE_MODULES ?= $(error You must include Makefile.node_modules.defs \
+    before this file)
+
+#
+# If the "package.json" file changes, we need to rebuild the contents of
+# the "node_modules" directory.
+#
+$(STAMP_NODE_MODULES): package.json | $(NPM_EXEC)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf node_modules
+	$(NPM_ENV) $(NPM) install
+	$(MAKE_STAMP_CREATE)
diff --git a/tools/mk/Makefile.node_prebuilt.defs b/tools/mk/Makefile.node_prebuilt.defs
new file mode 100644
index 0000000..2129742
--- /dev/null
+++ b/tools/mk/Makefile.node_prebuilt.defs
@@ -0,0 +1,159 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.node_prebuilt.defs: Makefile for including a prebuilt Node.js build.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This Makefile facilitates downloading and bundling a prebuilt node.js
+# build (using the 'sdcnode' distro builds). This is an alternative to
+# the "Makefile.node.*" makefiles for *building* a node from source.
+#
+# Usage:
+#
+# - Define `NODE_PREBUILT_VERSION` in your Makefile to choose a node version.
+#   E.g.: `NODE_PREBUILT_VERSION=v0.6.19`. See other optional variables
+#   below.
+# - `include tools/mk/Makefile.node_prebuilt.defs` after this in your Makefile.
+# - `include tools/mk/Makefile.node_prebuilt.targ` near the end of your
+#   Makefile.
+# - Have at least one of your Makefile targets depend on either `$(NODE_EXEC)`
+#   or `$(NPM_EXEC)`. E.g.:
+#
+#		node_modules/restify: deps/restify $(NPM_EXEC)
+#			$(NPM) install deps/restify
+#
+#   or better, use an order-only dependency to avoid spurious rebuilds:
+#
+#		node_modules/restify: deps/restify | $(NPM_EXEC)
+#			$(NPM) install deps/restify
+#
+# - Use `$(NPM)` or `$(NODE)` to use your node build.
+# - Include the "$(NODE_INSTALL)" tree in your release package.
+#
+#
+# When including this Makefile, you MUST also specify:
+#
+#	NODE_PREBUILT_VERSION 	The node version in the prebuilt 'sdcnode'
+#				package to use. Typically this is one of the
+#				node version tags, e.g. "v0.6.18" but it
+#				can be any commitish.
+#
+# When including this Makefile, you MAY also specify:
+#
+#	NODE_PREBUILT_DIR 	The dir in which to find sdcnode builds. This
+#				can either be a *local directory* or *a
+#				URL* dir (with trailing '/') which serves
+#				Apache/Nginx dir listing HTML.
+#				(default: sdcnode master build dir on stuff)
+#
+#	NODE_PREBUILT_TAG	The 'sdcnode' project supports special
+#				configuration builds of node, e.g. say a
+#				build configured `--without-ssl`. These
+#				special configurations are given a tag, e.g.
+#				'gz', that is used in the filename. Optionally
+#				specify a tag name here.
+#				(default: empty)
+#
+#	NODE_PREBUILT_BRANCH	Specify a particular branch of 'sdcnode' builds
+#				from which to pull. Generally one should stick
+#				with the default.
+#				(default: master)
+#
+#	NODE_PREBUILT_IMAGE		If you have a zone image that differs from that
+#				for an sdcnode build that you want to use (potential compat
+#				issues be damned), then set this to the UUID of the sdcnode
+#				build you want. See here for available build image uuids:
+#				<https://download.joyent.com/pub/build/sdcnode/master-latest/sdcnode/>
+#
+#	BUILD			top-level directory for built binaries
+#				(default: "build")
+#
+#	NODE_INSTALL		where node should install its built items
+#				(default: "$BUILD/node")
+#
+#
+# Dev Notes:
+#
+# This works by getting "NODE_PREBUILT_NAME" from the provided "NODE_PREBUILT_*"
+# vars and the image version (via 'mdata-get sdc:image_uuid'). The image uuid is
+# included to ensure an exact match with the build machine. This name (e.g.
+# "v0.6.18-zone-$uuid") is used to find a matching "sdcnode-$name-*.tgz" build
+# in "NODE_PREBUILT_DIR" (either a local directory or a URL). That tarball is
+# downloaded and extracted into "NODE_INSTALL".
+#
+# The "*_EXEC" vars are set to named symlinks, e.g.
+# "build/prebuilt-node-v0.6.18-$uuid", so that a change of selected node
+# build (say the developer changes NODE_PREBUILT_VERSION) will recreate the
+# node install.
+#
+# See <https://mo.joyent.com/docs/sdcnode/master/> for details on 'sdcnode-*'
+# package naming.
+#
+
+TOP ?= $(error You must include Makefile.defs before this makefile)
+NODE_PREBUILT_VERSION ?= $(error NODE_PREBUILT_VERSION is not set.)
+
+
+BUILD		?= build
+NODE_INSTALL	?= $(BUILD)/node
+DISTCLEAN_FILES	+= $(NODE_INSTALL) \
+	$(BUILD)/prebuilt-node-* $(BUILD)/prebuilt-npm-*
+
+NODE_PREBUILT_BRANCH ?= master
+NODE_PREBUILT_IMAGE ?= $(shell pfexec mdata-get sdc:image_uuid)
+ifeq ($(NODE_PREBUILT_TAG),)
+	NODE_PREBUILT_NAME := $(NODE_PREBUILT_VERSION)-$(NODE_PREBUILT_IMAGE)
+else
+	NODE_PREBUILT_NAME := $(NODE_PREBUILT_VERSION)-$(NODE_PREBUILT_TAG)-$(NODE_PREBUILT_IMAGE)
+endif
+NODE_PREBUILT_PATTERN := sdcnode-$(NODE_PREBUILT_NAME)-$(NODE_PREBUILT_BRANCH)-.*\.tgz
+NODE_PREBUILT_DIR ?= https://download.joyent.com/pub/build/sdcnode/$(NODE_PREBUILT_IMAGE)/$(NODE_PREBUILT_BRANCH)-latest/sdcnode/
+ifeq ($(shell echo $(NODE_PREBUILT_DIR) | cut -c 1-4),http)
+	NODE_PREBUILT_BASE := $(shell curl -ksS --fail --connect-timeout 30 $(NODE_PREBUILT_DIR) | grep 'href=' | cut -d'"' -f2 | grep "^$(NODE_PREBUILT_PATTERN)$$" | sort | tail -1)
+	ifneq ($(NODE_PREBUILT_BASE),)
+		NODE_PREBUILT_TARBALL := $(NODE_PREBUILT_DIR)$(NODE_PREBUILT_BASE)
+	endif
+else
+	NODE_PREBUILT_BASE := $(shell ls -1 $(NODE_PREBUILT_DIR)/ | grep "^$(NODE_PREBUILT_PATTERN)$$" 2>/dev/null | sort | tail -1)
+	ifneq ($(NODE_PREBUILT_BASE),)
+		NODE_PREBUILT_TARBALL := $(NODE_PREBUILT_DIR)/$(NODE_PREBUILT_BASE)
+	endif
+endif
+ifeq ($(NODE_PREBUILT_TARBALL),)
+	NODE_PREBUILT_TARBALL = $(error NODE_PREBUILT_TARBALL is empty: no '$(NODE_PREBUILT_DIR)/$(NODE_PREBUILT_PATTERN)' found)
+endif
+
+
+# Prebuild-specific paths for the "*_EXEC" vars to ensure that
+# a prebuild change (e.g. if master Makefile's NODE_PREBUILT_VERSION
+# choice changes) causes a install of the new node.
+NODE_EXEC	:= $(BUILD)/prebuilt-node-$(NODE_PREBUILT_NAME)
+NODE_WAF_EXEC	:= $(BUILD)/prebuilt-node-waf-$(NODE_PREBUILT_NAME)
+NPM_EXEC	:= $(BUILD)/prebuilt-npm-$(NODE_PREBUILT_NAME)
+
+#
+# These paths should be used during the build process to invoke Node and
+# Node-related build tools like NPM.  All paths are fully qualified so that
+# they work regardless of the current working directory at the point of
+# invocation.
+#
+# Note that where PATH is overridden, the value chosen must cause execution of
+# "node" to find the same binary to which the NODE macro refers.
+#
+NODE		:= $(TOP)/$(NODE_INSTALL)/bin/node
+NODE_WAF	:= $(TOP)/$(NODE_INSTALL)/bin/node-waf
+NPM		:= PATH=$(TOP)/$(NODE_INSTALL)/bin:$(PATH) $(NODE) $(TOP)/$(NODE_INSTALL)/bin/npm
diff --git a/tools/mk/Makefile.node_prebuilt.targ b/tools/mk/Makefile.node_prebuilt.targ
new file mode 100644
index 0000000..6877333
--- /dev/null
+++ b/tools/mk/Makefile.node_prebuilt.targ
@@ -0,0 +1,42 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.node_prebuilt.targ: Makefile for including a prebuilt Node.js
+# build.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+
+
+NODE_PREBUILT_TARBALL ?= $(error NODE_PREBUILT_TARBALL is not set: was Makefile.node_prebuilt.defs included?)
+
+
+# TODO: remove this limitation
+# Limitation: currently presuming that the NODE_INSTALL basename is
+# 'node' and that sdcnode tarballs have a 'node' top-level dir.
+$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC):
+	[[ $(shell basename $(NODE_INSTALL)) == "node" ]] \
+		|| (echo "Limitation: 'basename NODE_INSTALL' is not 'node'" && exit 1)
+	rm -rf $(NODE_INSTALL) \
+		$(BUILD)/prebuilt-node-* $(BUILD)/prebuilt-npm-*
+	mkdir -p $(shell dirname $(NODE_INSTALL))
+	if [[ $(shell echo $(NODE_PREBUILT_TARBALL) | cut -c 1-4) == "http" ]]; then \
+		echo "Downloading '$(NODE_PREBUILT_BASE)'."; \
+		curl -ksS --fail --connect-timeout 30 -o $(shell dirname $(NODE_INSTALL))/$(NODE_PREBUILT_BASE) $(NODE_PREBUILT_TARBALL); \
+		(cd $(shell dirname $(NODE_INSTALL)) && $(TAR) xf $(NODE_PREBUILT_BASE)); \
+	else \
+		(cd $(shell dirname $(NODE_INSTALL)) && $(TAR) xf $(NODE_PREBUILT_TARBALL)); \
+	fi
+	ln -s $(TOP)/$(NODE_INSTALL)/bin/node $(NODE_EXEC)
+	ln -s $(TOP)/$(NODE_INSTALL)/bin/npm $(NPM_EXEC)
diff --git a/tools/mk/Makefile.smf.defs b/tools/mk/Makefile.smf.defs
new file mode 100644
index 0000000..b988bbe
--- /dev/null
+++ b/tools/mk/Makefile.smf.defs
@@ -0,0 +1,40 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.smf.defs: common targets for SMF manifests
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This Makefile uses the following definitions:
+#
+#	SMF_MANIFESTS_IN	Source files for SMF manifests.  The following
+#				substitutions will be made on these files:
+#
+#		@@NODE@@	path to installed node
+#
+# It updates SMF_MANIFESTS with the set of files generated by SMF_MANIFESTS_IN.
+# It also updates the "check" target to check the XML syntax of all manifests,
+# generated or otherwise.
+#
+# To use this file, be sure to also include Makefile.smf.targ after defining
+# targets.
+#
+
+SED 		?= sed
+SMF_DTD		?= tools/service_bundle.dtd.1
+XMLLINT		?= xmllint --noout
+
+SMF_MANIFESTS	+= $(SMF_MANIFESTS_IN:%.in=%)
+CLEAN_FILES	+= $(SMF_MANIFESTS_IN:%.in=%)
diff --git a/tools/mk/Makefile.smf.targ b/tools/mk/Makefile.smf.targ
new file mode 100644
index 0000000..f78de96
--- /dev/null
+++ b/tools/mk/Makefile.smf.targ
@@ -0,0 +1,29 @@
+# -*- mode: makefile -*-
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2014, Joyent, Inc.
+#
+
+#
+# Makefile.smf.targ: see Makefile.smf.defs.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+.PHONY: check-manifests
+check-manifests: $(SMF_MANIFESTS:%=%.smfchk)
+
+%.smfchk: %
+	$(XMLLINT) --path $(dir $(SMF_DTD)) --dtdvalid $(SMF_DTD) $^
+
+check:: check-manifests
+
+$(SMF_MANIFESTS): %: %.in
+	$(SED) -e 's#@@NODE@@#@@PREFIX@@/$(NODE_INSTALL)/bin/node#' $< > $@
diff --git a/tools/mk/Makefile.targ b/tools/mk/Makefile.targ
new file mode 100644
index 0000000..cc5ae95
--- /dev/null
+++ b/tools/mk/Makefile.targ
@@ -0,0 +1,345 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2017, Joyent, Inc.
+#
+
+#
+# Makefile.targ: common targets.
+#
+# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+# This Makefile defines several useful targets and rules. You can use it by
+# including it from a Makefile that specifies some of the variables below.
+#
+# Targets defined in this Makefile:
+#
+#	check	Checks JavaScript files for lint and style
+#		Checks bash scripts for syntax
+#		Checks SMF manifests for validity against the SMF DTD
+#
+#	clean	Removes built files
+#
+#	docs	Builds restdown documentation in docs/
+#
+#	prepush	Depends on "check" and "test"
+#
+#	test	Does nothing (you should override this)
+#
+#	xref	Generates cscope (source cross-reference index)
+#
+# For details on what these targets are supposed to do, see the Joyent
+# Engineering Guide.
+#
+# To make use of these targets, you'll need to set some of these variables. Any
+# variables left unset will simply not be used.
+#
+#	BASH_FILES	Bash scripts to check for syntax
+#			(paths relative to top-level Makefile)
+#
+#	CLEAN_FILES	Files to remove as part of the "clean" target.  Note
+#			that files generated by targets in this Makefile are
+#			automatically included in CLEAN_FILES.  These include
+#			restdown-generated HTML and JSON files.
+#
+#	DOC_FILES	Restdown (documentation source) files. These are
+#			assumed to be contained in "docs/", and must NOT
+#			contain the "docs/" prefix.
+#
+#	JSL_CONF_NODE	Specify JavaScriptLint configuration files
+#	JSL_CONF_WEB	(paths relative to top-level Makefile)
+#
+#			Node.js and Web configuration files are separate
+#			because you'll usually want different global variable
+#			configurations.  If no file is specified, none is given
+#			to jsl, which causes it to use a default configuration,
+#			which probably isn't what you want.
+#
+#	JSL_FILES_NODE	JavaScript files to check with Node config file.
+#	JSL_FILES_WEB	JavaScript files to check with Web config file.
+#
+#	JSON_FILES	JSON files to be validated
+#
+#	JSSTYLE_FILES	JavaScript files to be style-checked
+#
+# You can also override these variables:
+#
+#	BASH		Path to bash (default: "bash")
+#
+#	CSCOPE_DIRS	Directories to search for source files for the cscope
+#			index. (default: ".")
+#
+#	ESLINT		Path to eslint (default: "eslint")
+#
+#	ESLINT_FLAGS	Additional flags to pass through to eslint
+#
+#	JSL		Path to JavaScriptLint (default: "jsl")
+#
+#	JSL_FLAGS_NODE	Additional flags to pass through to JSL
+#	JSL_FLAGS_WEB
+#	JSL_FLAGS
+#
+#	JSON		Path to json tool (default: "json")
+#
+#	JSSTYLE		Path to jsstyle (default: "jsstyle")
+#
+#	JSSTYLE_FLAGS	Additional flags to pass through to jsstyle
+#
+#	RESTDOWN_EXT	By default '.md' is required for DOC_FILES (see above).
+#			If you want to use, say, '.restdown' instead, then set
+#			'RESTDOWN_EXT=.restdown' in your Makefile.
+#
+
+#
+# Defaults for the various tools we use.
+#
+BASH		?= bash
+BASHSTYLE	?= tools/bashstyle
+CP		?= cp
+CSCOPE		?= cscope
+CSCOPE_DIRS	?= .
+ESLINT		?= eslint
+JSL		?= jsl
+JSON		?= json
+JSSTYLE		?= jsstyle
+MKDIR		?= mkdir -p
+MV		?= mv
+RESTDOWN_FLAGS	?=
+RESTDOWN_EXT	?= .md
+RMTREE		?= rm -rf
+JSL_FLAGS  	?= --nologo --nosummary
+
+ifeq ($(shell uname -s),SunOS)
+	TAR	?= gtar
+else
+	TAR	?= tar
+endif
+
+
+#
+# Defaults for other fixed values.
+#
+BUILD		= build
+DISTCLEAN_FILES += $(BUILD)
+DOC_BUILD	= $(BUILD)/docs/public
+
+#
+# Configure JSL_FLAGS_{NODE,WEB} based on JSL_CONF_{NODE,WEB}.
+#
+ifneq ($(origin JSL_CONF_NODE), undefined)
+	JSL_FLAGS_NODE += --conf=$(JSL_CONF_NODE)
+endif
+
+ifneq ($(origin JSL_CONF_WEB), undefined)
+	JSL_FLAGS_WEB += --conf=$(JSL_CONF_WEB)
+endif
+
+#
+# Targets. For descriptions on what these are supposed to do, see the
+# Joyent Engineering Guide.
+#
+
+#
+# Instruct make to keep around temporary files. We have rules below that
+# automatically update git submodules as needed, but they employ a deps/*/.git
+# temporary file. Without this directive, make tries to remove these .git
+# directories after the build has completed.
+#
+.SECONDARY: $($(wildcard deps/*):%=%/.git)
+
+#
+# This rule enables other rules that use files from a git submodule to have
+# those files depend on deps/module/.git and have "make" automatically check
+# out the submodule as needed.
+#
+deps/%/.git:
+	git submodule update --init deps/$*
+
+#
+# These recipes make heavy use of dynamically-created phony targets. The parent
+# Makefile defines a list of input files like BASH_FILES. We then say that each
+# of these files depends on a fake target called filename.bashchk, and then we
+# define a pattern rule for those targets that runs bash in check-syntax-only
+# mode. This mechanism has the nice properties that if you specify zero files,
+# the rule becomes a noop (unlike a single rule to check all bash files, which
+# would invoke bash with zero files), and you can check individual files from
+# the command line with "make filename.bashchk".
+#
+.PHONY: check-bash
+check-bash: $(BASH_FILES:%=%.bashchk) $(BASH_FILES:%=%.bashstyle)
+
+%.bashchk: %
+	$(BASH) -n $^
+
+%.bashstyle: %
+	$(BASHSTYLE) $^
+
+.PHONY: check-json
+check-json: $(JSON_FILES:%=%.jsonchk)
+
+%.jsonchk: %
+	$(JSON) --validate -f $^
+
+#
+# The above approach can be slow when there are many files to check because it
+# requires that "make" invoke the check tool once for each file, rather than
+# passing in several files at once.  For the JavaScript check targets, we define
+# a variable for the target itself *only if* the list of input files is
+# non-empty.  This avoids invoking the tool if there are no files to check.
+#
+
+ESLINT_TARGET = $(if $(ESLINT_FILES), check-eslint)
+.PHONY: check-eslint
+check-eslint: $(ESLINT_EXEC)
+	$(ESLINT) $(ESLINT_FLAGS) $(ESLINT_FILES)
+
+JSL_NODE_TARGET = $(if $(JSL_FILES_NODE), check-jsl-node)
+.PHONY: check-jsl-node
+check-jsl-node: $(JSL_EXEC)
+	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_NODE) $(JSL_FILES_NODE)
+
+JSL_WEB_TARGET = $(if $(JSL_FILES_WEB), check-jsl-web)
+.PHONY: check-jsl-web
+check-jsl-web: $(JSL_EXEC)
+	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_WEB) $(JSL_FILES_WEB)
+
+.PHONY: check-jsl
+check-jsl: $(JSL_NODE_TARGET) $(JSL_WEB_TARGET)
+
+JSSTYLE_TARGET = $(if $(JSSTYLE_FILES), check-jsstyle)
+.PHONY: check-jsstyle
+check-jsstyle:  $(JSSTYLE_EXEC)
+	$(JSSTYLE) $(JSSTYLE_FLAGS) $(JSSTYLE_FILES)
+
+.PHONY: check
+check:: $(ESLINT_TARGET) check-jsl check-json $(JSSTYLE_TARGET) check-bash
+	@echo check ok
+
+.PHONY: clean
+clean::
+	-$(RMTREE) $(CLEAN_FILES)
+
+.PHONY: distclean
+distclean:: clean
+	-$(RMTREE) $(DISTCLEAN_FILES)
+
+CSCOPE_FILES = cscope.in.out cscope.out cscope.po.out
+CLEAN_FILES += $(CSCOPE_FILES)
+
+.PHONY: xref
+xref: cscope.files
+	$(CSCOPE) -bqR
+
+.PHONY: cscope.files
+cscope.files:
+	find $(CSCOPE_DIRS) -name '*.c' -o -name '*.h' -o -name '*.cc' \
+	    -o -name '*.js' -o -name '*.s' -o -name '*.cpp' > $@
+
+#
+# The "docs" target is complicated because we do several things here:
+#
+#    (1) Use restdown to build HTML and JSON files from each of DOC_FILES.
+#
+#    (2) Copy these files into $(DOC_BUILD) (build/docs/public), which
+#        functions as a complete copy of the documentation that could be
+#        mirrored or served over HTTP.
+#
+#    (3) Then copy any directories and media from docs/media into
+#        $(DOC_BUILD)/media. This allows projects to include their own media,
+#        including files that will override same-named files provided by
+#        restdown.
+#
+# Step (3) is the surprisingly complex part: in order to do this, we need to
+# identify the subdirectories in docs/media, recreate them in
+# $(DOC_BUILD)/media, then do the same with the files.
+#
+DOC_MEDIA_DIRS := $(shell find docs/media -type d 2>/dev/null | grep -v "^docs/media$$")
+DOC_MEDIA_DIRS := $(DOC_MEDIA_DIRS:docs/media/%=%)
+DOC_MEDIA_DIRS_BUILD := $(DOC_MEDIA_DIRS:%=$(DOC_BUILD)/media/%)
+
+DOC_MEDIA_FILES := $(shell find docs/media -type f 2>/dev/null)
+DOC_MEDIA_FILES := $(DOC_MEDIA_FILES:docs/media/%=%)
+DOC_MEDIA_FILES_BUILD := $(DOC_MEDIA_FILES:%=$(DOC_BUILD)/media/%)
+
+#
+# Like the other targets, "docs" just depends on the final files we want to
+# create in $(DOC_BUILD), leveraging other targets and recipes to define how
+# to get there.
+#
+.PHONY: docs
+docs::							\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.json)		\
+	$(DOC_MEDIA_FILES_BUILD)
+
+#
+# We keep the intermediate files so that the next build can see whether the
+# files in DOC_BUILD are up to date.
+#
+.PRECIOUS:					\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%json)
+
+#
+# We do clean those intermediate files, as well as all of DOC_BUILD.
+#
+CLEAN_FILES +=					\
+	$(DOC_BUILD)				\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
+	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.json)
+
+#
+# Before installing the files, we must make sure the directories exist. The |
+# syntax tells make that the dependency need only exist, not be up to date.
+# Otherwise, it might try to rebuild spuriously because the directory itself
+# appears out of date.
+#
+$(DOC_MEDIA_FILES_BUILD): | $(DOC_MEDIA_DIRS_BUILD)
+
+$(DOC_BUILD)/%: docs/% | $(DOC_BUILD)
+	$(MKDIR) $(shell dirname $@)
+	$(CP) $< $@
+
+docs/%.json docs/%.html: docs/%$(RESTDOWN_EXT) | $(DOC_BUILD) $(RESTDOWN_EXEC) \
+    $(EXTRA_DOC_DEPS)
+	$(RESTDOWN) $(RESTDOWN_FLAGS) -m $(DOC_BUILD) $<
+
+$(DOC_BUILD):
+	$(MKDIR) $@
+
+$(DOC_MEDIA_DIRS_BUILD):
+	$(MKDIR) $@
+
+#
+# The default "test" target does nothing. This should usually be overridden by
+# the parent Makefile. It's included here so we can define "prepush" without
+# requiring the repo to define "test".
+#
+.PHONY: test
+test:
+
+.PHONY: prepush
+prepush: check test
+
+#
+# This rule automatically exposes every "stamp" file as a target that can be
+# invoked manually as "stamp-$STAMP_NAME".  For example, if a stamp has been
+# defined thus:
+#
+#	STAMP_EXPENSIVE_RESULT := $(MAKE_STAMPS_DIR)/expensive-result
+#
+# ... this can be invoked manually as "make stamp-expensive-result".  Note that
+# these phony targets are essentially just for interactive usage.  Targets
+# should be specified to depend on the macro containing the stamp file name.
+#
+# See also the comments in "Makefile.defs".
+#
+stamp-%: $(MAKE_STAMPS_DIR)/%
+	@:
diff --git a/tools/obliterate-grafana-service.sh b/tools/obliterate-grafana-service.sh
new file mode 100755
index 0000000..fc367d5
--- /dev/null
+++ b/tools/obliterate-grafana-service.sh
@@ -0,0 +1,68 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2018 Joyent, Inc.
+#
+
+#
+# Obliterate a Triton grafana service and instances. This is just for
+# development.
+#
+# Usage:
+#       scp tools/obliterate-grafana-service.sh coal:/var/tmp
+#       ssh coal
+#       /var/tmp/obliterate-grafana-service.sh
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+set -o errexit
+set -o pipefail
+
+function fatal() {
+    echo "$0: fatal: \$*" >&2
+    exit 1
+}
+
+function obliterate_grafana_service {
+    local grafSvc
+
+    grafSvc=$(sdc-sapi /services?name=grafana | json -H 0.uuid)
+    if [[ -z $grafSvc ]]; then
+        return
+    fi
+
+    sdc-sapi /instances?service_uuid=$grafSvc \
+        | json -Ha uuid params.alias \
+        | while read uuid alias; do
+            echo "Delete grafana instance $uuid ($alias)"
+            sdc-sapi /instances/$uuid -X DELETE
+        done
+
+    echo "Delete grafana service ($grafSvc)"
+    sdc-sapi /services/$grafSvc -X DELETE
+}
+
+
+# ---- mainline
+
+# Guard from running this in production. This is the same guard file we use
+# for running many of the Triton test suites.
+if [[ ! -f "/lib/sdc/.sdc-test-no-production-data" ]]; then
+    cat <<EOF
+To run this you must create the following file:
+
+    /lib/sdc/.sdc-test-no-production-data
+
+after ensuring you have no production data in this TritonDC.
+EOF
+    exit 2
+fi
+
+
+obliterate_grafana_service
diff --git a/tools/service_bundle.dtd.1 b/tools/service_bundle.dtd.1
new file mode 100644
index 0000000..e5c2380
--- /dev/null
+++ b/tools/service_bundle.dtd.1
@@ -0,0 +1,1091 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+ Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.
+
+ CDDL HEADER START
+
+ The contents of this file are subject to the terms of the
+ Common Development and Distribution License (the "License").
+ You may not use this file except in compliance with the License.
+
+ You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
+ or http://www.opensolaris.org/os/licensing.
+ See the License for the specific language governing permissions
+ and limitations under the License.
+
+ When distributing Covered Code, include this CDDL HEADER in each
+ file and include the License file at usr/src/OPENSOLARIS.LICENSE.
+ If applicable, add the following below this CDDL HEADER, with the
+ fields enclosed by brackets "[]" replaced with your own identifying
+ information: Portions Copyright [yyyy] [name of copyright owner]
+
+ CDDL HEADER END
+-->
+
+<!--
+  Service description DTD
+
+    Most attributes are string values (or an individual string from a
+    restricted set), but attributes with a specific type requirement are
+    noted in the comment describing the element.
+-->
+
+<!--
+  XInclude support
+
+    A series of service bundles may be composed via the xi:include tag.
+    smf(5) tools enforce that all bundles be of the same type.
+-->
+
+<!--
+     These entities are used for the property, propval and property_group
+     elements, that require type attributes for manifest, while for profiles
+     the type attributes are only implied.
+-->
+
+<!ENTITY % profile "IGNORE">
+<!ENTITY % manifest "INCLUDE">
+
+<!ELEMENT xi:include
+  (xi:fallback)
+  >
+<!ATTLIST xi:include
+  href CDATA #REQUIRED
+  parse (xml|text) "xml"
+  encoding CDATA #IMPLIED
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!ELEMENT xi:fallback
+  ANY
+  >
+<!ATTLIST xi:fallback
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!--
+  stability
+
+    This element associates an SMI stability level with the parent
+    element.  See attributes(5) for an explanation of interface
+    stability levels.
+
+    Its attribute is
+
+	value	The stability level of the parent element.
+-->
+
+<!ELEMENT stability EMPTY>
+
+<!ATTLIST stability
+	value		( Standard | Stable | Evolving | Unstable |
+			External | Obsolete ) #REQUIRED >
+
+<!-- Property value lists -->
+
+<!--
+  value_node
+
+    This element represents a single value within any of the typed
+    property value lists.
+
+    Its attribute is
+
+	value	The value for this node in the list.
+-->
+
+<!ELEMENT value_node EMPTY>
+
+<!ATTLIST value_node
+	value CDATA #REQUIRED>
+
+<!--
+  count_list
+  integer_list
+  opaque_list
+  host_list
+  hostname_list
+  net_address_list
+  net_address_v4_list
+  net_address_v6_list
+  time_list
+  astring_list
+  ustring_list
+  boolean_list
+  fmri_list
+  uri_list
+
+    These elements represent the typed lists of values for a property.
+    Each contains one or more value_node elements representing each
+    value on the list.
+
+    None of these elements has attributes.
+-->
+
+<!ELEMENT count_list
+	( value_node+ )>
+
+<!ATTLIST count_list>
+
+<!ELEMENT integer_list
+	( value_node+ )>
+
+<!ATTLIST integer_list>
+
+<!ELEMENT opaque_list
+	( value_node+ )>
+
+<!ATTLIST opaque_list>
+
+<!ELEMENT host_list
+	( value_node+ )>
+
+<!ATTLIST host_list>
+
+<!ELEMENT hostname_list
+	( value_node+ )>
+
+<!ATTLIST hostname_list>
+
+<!ELEMENT net_address_list
+	( value_node+ )>
+
+<!ATTLIST net_address_list>
+
+<!ELEMENT net_address_v4_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v4_list>
+
+<!ELEMENT net_address_v6_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v6_list>
+
+<!ELEMENT time_list
+	( value_node+ )>
+
+<!ATTLIST time_list>
+
+<!ELEMENT astring_list
+	( value_node+ )>
+
+<!ATTLIST astring_list>
+
+<!ELEMENT ustring_list
+	( value_node+ )>
+
+<!ATTLIST ustring_list>
+
+<!ELEMENT boolean_list
+	( value_node+ )>
+
+<!ATTLIST boolean_list>
+
+<!ELEMENT fmri_list
+	( value_node+ )>
+
+<!ATTLIST fmri_list>
+
+<!ELEMENT uri_list
+	( value_node+ )>
+
+<!ATTLIST uri_list>
+
+<!-- Properties and property groups -->
+
+<!--
+   property
+
+     This element is for a singly or multiply valued property within a
+     property group.  It contains an appropriate value list element,
+     which is expected to be consistent with the type attribute.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	override These values should replace values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	override	( true | false ) "false" >
+]]>
+	
+<![%manifest;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+   propval
+
+     This element is for a singly valued property within a property
+     group.  List-valued properties must use the property element above.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	value	The value for this property.  Must match type
+		restriction of type attribute.
+
+	override This value should replace any values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+  property_group
+
+    This element is for a set of related properties on a service or
+    instance.  It contains an optional stability element, as well as
+    zero or more property-containing elements.
+
+    Its attributes are
+
+	name	The name of this property group.
+
+	type	A category for this property group.  Groups of type
+		"framework", "implementation" or "template" are primarily
+		of interest to the service management facility, while
+		groups of type "application" are expected to be only of
+		interest to the service to which this group is attached.
+		Other types may be introduced using the service symbol
+		namespace conventions.
+
+	delete	If in the repository, this property group should be removed.
+-->
+
+<![%profile;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #IMPLIED
+	delete		( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+]]>
+
+<!--
+  service_fmri
+
+    This element defines a reference to a service FMRI (for either a
+    service or an instance).
+
+    Its attribute is
+
+	value	The FMRI.
+-->
+
+<!ELEMENT service_fmri EMPTY>
+
+<!ATTLIST service_fmri
+	value		CDATA #REQUIRED>
+
+<!-- Dependencies -->
+
+<!--
+  dependency
+
+    This element identifies a group of FMRIs upon which the service is
+    in some sense dependent.  Its interpretation is left to the
+    restarter to which a particular service instance is delegated.  It
+    contains a group of service FMRIs, as well as a block of properties.
+
+    Its attributes are
+
+	name	The name of this dependency.
+
+	grouping The relationship between the various FMRIs grouped
+		here; "require_all" of the FMRIs to be online, "require_any"
+		of the FMRIs to be online, or "exclude_all" of the FMRIs
+		from being online or in maintenance for the dependency to
+		be satisfied.  "optional_all" dependencies are satisfied
+		when all of the FMRIs are either online or unable to come
+		online (because they are disabled, misconfigured, or one
+		of their dependencies is unable to come online).
+
+	restart_on The type of events from the FMRIs that the service should
+		be restarted for.  "error" restarts the service if the
+		dependency is restarted due to hardware fault.  "restart"
+		restarts the service if the dependency is restarted for
+		any reason, including hardware fault.  "refresh" restarts
+		the service if the dependency is refreshed or restarted for
+		any reason.  "none" will never restart the service due to
+		dependency state changes.
+
+	type	The type of dependency: on another service ('service'), on
+		a filesystem path ('path'), or another dependency type.
+
+	delete	This dependency should be deleted.
+-->
+
+<!ELEMENT dependency
+	( service_fmri*, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependency
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all ) #REQUIRED
+	restart_on	( error | restart | refresh | none ) #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!-- Dependents -->
+
+<!--
+  dependent
+
+    This element identifies a service which should depend on this service.  It
+    corresponds to a dependency in the named service.  The grouping and type
+    attributes of that dependency are implied to be "require_all" and
+    "service", respectively.
+
+    Its attributes are
+
+	name	The name of the dependency property group to create in the
+		dependent entity.
+
+	grouping The grouping relationship of the dependency property
+		group to create in the dependent entity.  See "grouping"
+		attribute on the dependency element.
+
+	restart_on The type of events from this service that the named service
+		should be restarted for.
+
+	delete	True if this dependent should be deleted.
+
+	override Whether to replace an existing dependent of the same name.
+
+-->
+
+<!ELEMENT dependent
+	( service_fmri, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependent
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all) #REQUIRED
+	restart_on	( error | restart | refresh | none) #REQUIRED
+	delete		( true | false ) "false"
+	override	( true | false ) "false" >
+
+<!-- Method execution context, security profile, and credential definitions -->
+
+<!--
+  envvar
+
+    An environment variable. It has two attributes:
+
+	name	The name of the environment variable.
+	value	The value of the environment variable.
+-->
+
+<!ELEMENT envvar EMPTY>
+
+<!ATTLIST envvar
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED >
+
+<!--
+  method_environment
+
+    This element defines the environment for a method. It has no
+    attributes, and one or more envvar child elements.
+-->
+
+<!ELEMENT method_environment (envvar+) >
+
+<!ATTLIST method_environment>
+
+<!--
+  method_profile
+
+    This element indicates which exec_attr(5) profile applies to the
+    method context being defined.
+
+    Its attribute is
+
+	name	The name of the profile.
+-->
+
+<!ELEMENT method_profile EMPTY>
+
+<!ATTLIST method_profile
+	name		CDATA #REQUIRED >
+
+<!--
+  method_credential
+
+    This element specifies credential attributes for the execution
+    method to use.
+
+    Its attributes are
+
+	user	The user ID, in numeric or text form.
+
+	group	The group ID, in numeric or text form.  If absent or
+		":default", the group associated with the user in the
+		passwd database.
+
+	supp_groups Supplementary group IDs to be associated with the
+		method, separated by commas or spaces.  If absent or
+		":default", initgroups(3C) will be used.
+
+	privileges An optional string specifying the privilege set.
+
+	limit_privileges An optional string specifying the limit
+		privilege set.
+-->
+
+<!ELEMENT method_credential EMPTY>
+
+<!ATTLIST method_credential
+	user		CDATA #REQUIRED
+	group		CDATA #IMPLIED
+	supp_groups	CDATA #IMPLIED
+	privileges	CDATA #IMPLIED
+	limit_privileges CDATA #IMPLIED >
+
+<!--
+  method_context
+
+    This element combines credential and resource management attributes
+    for execution methods.  It may contain a method_environment, or
+    a method_profile or method_credential element.
+
+    Its attributes are
+
+	working_directory The home directory to launch the method from.
+		":default" can be used as a token to indicate use of the
+		user specified by the credential or profile specified.
+
+	project	The project ID, in numeric or text form.  ":default" can
+		be used as a token to indicate use of the project
+		identified by getdefaultproj(3PROJECT) for the non-root
+		user specified by the credential or profile specified.
+		If the user is root, ":default" designates the project
+		the restarter is running in.
+
+	resource_pool The resource pool name to launch the method on.
+		":default" can be used as a token to indicate use of the
+		pool specified in the project(4) entry given in the
+		"project" attribute above.
+-->
+<!ELEMENT method_context
+	( (method_profile | method_credential)?, method_environment? ) >
+
+<!ATTLIST method_context
+	working_directory	CDATA #IMPLIED
+	project			CDATA #IMPLIED
+	resource_pool		CDATA #IMPLIED >
+
+<!-- Restarter delegation, methods, and monitors -->
+
+<!--
+  exec_method
+
+    This element describes one of the methods used by the designated
+    restarter to act on the service instance.  Its interpretation is
+    left to the restarter to which a particular service instance is
+    delegated.  It contains a set of attributes, an optional method
+    context, and an optional stability element for the optional
+    properties that can be included.
+
+    Its attributes are
+
+	type	The type of method, either "method" or "monitor".
+
+	name	Name of this execution method.  The method names are
+		usually a defined interface of the restarter to which an
+		instance of this service is delegated.
+
+	exec	The string identifying the action to take.  For
+		svc.startd(1M), this is a string suitable to pass to
+		exec(2).
+
+	timeout_seconds [integer] Duration, in seconds, to wait for this
+		method to complete.  A '0' or '-1' denotes an infinite
+		timeout.
+
+	delete	If in the repository, the property group for this method
+		should be removed.
+-->
+
+<!ELEMENT exec_method
+	( method_context?, stability?, ( propval | property )* ) >
+
+<!ATTLIST exec_method
+	type		( method | monitor ) #REQUIRED
+	name		CDATA #REQUIRED
+	exec		CDATA #REQUIRED
+	timeout_seconds	CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!--
+  restarter
+
+    A flag element identifying the restarter to which this service or
+    service instance is delegated.  Contains the FMRI naming the
+    delegated restarter.
+
+    This element has no attributes.
+-->
+
+<!ELEMENT restarter
+	( service_fmri ) >
+
+<!ATTLIST restarter>
+
+<!--
+  Templates
+-->
+
+<!--
+  doc_link
+
+    The doc_link relates a resource described by the given URI to the
+    service described by the containing template.  The resource is
+    expected to be a documentation or elucidatory reference of some
+    kind.
+
+    Its attributes are
+
+      name      A label for this resource.
+
+      uri       A URI to the resource.
+-->
+
+<!ELEMENT doc_link EMPTY>
+
+<!ATTLIST doc_link
+	name		CDATA #REQUIRED
+	uri		CDATA #REQUIRED >
+
+<!--
+  manpage
+
+    The manpage element connects the reference manual page to the
+    template's service.
+
+    Its attributes are
+
+      title     The manual page title.
+
+      section   The manual page's section.
+
+      manpath   The MANPATH environment variable, as described in man(1)
+                that is required to reach the named manual page
+-->
+
+<!ELEMENT manpage EMPTY>
+
+<!ATTLIST manpage
+	title		CDATA #REQUIRED
+	section		CDATA #REQUIRED
+	manpath		CDATA ":default" >
+
+<!--
+  documentation
+
+    The documentation element groups an arbitrary number of doc_link
+    and manpage references.
+
+    It has no attributes.
+-->
+
+<!ELEMENT documentation
+	( doc_link | manpage )* >
+
+<!ATTLIST documentation>
+
+<!--
+  loctext
+
+    The loctext element is a container for localized text.
+
+    Its sole attribute is
+
+	xml:lang The name of the locale, in the form accepted by LC_ALL,
+		etc.  See locale(5).
+-->
+<!ELEMENT loctext
+        (#PCDATA) >
+
+<!ATTLIST loctext
+        xml:lang	CDATA #REQUIRED >
+
+<!--
+  description
+
+    The description holds a set of potentially longer, localized strings that
+    consist of a short description of the service.
+
+    The description has no attributes.
+-->
+<!ELEMENT description
+        ( loctext+ ) >
+
+<!ATTLIST description>
+
+<!--
+  common_name
+
+    The common_name holds a set of short, localized strings that
+    represent a well-known name for the service in the given locale.
+
+    The common_name has no attributes.
+-->
+<!ELEMENT common_name
+        ( loctext+ ) >
+
+<!ATTLIST common_name>
+
+<!--
+  units
+
+    The units a numerical property is expressed in.
+-->
+
+<!ELEMENT units
+	( loctext+ ) >
+
+<!ATTLIST units>
+
+<!--
+  visibility
+
+    Expresses how a property is typically accessed.  This isn't
+    intended as access control, but as an indicator as to how a
+    property is used.
+
+    Its attributes are:
+
+      value     'hidden', 'readonly', or 'readwrite' indicating that
+		the property should be hidden from the user, shown but
+		read-only, or modifiable.
+-->
+
+<!ELEMENT visibility EMPTY>
+
+<!ATTLIST visibility
+	value	( hidden | readonly | readwrite ) #REQUIRED >
+
+<!--
+  value
+
+    Describes a legal value for a property value, and optionally contains a
+    human-readable name and description for the specified property
+    value.
+
+    Its attributes are:
+
+      name	A string representation of the value.
+-->
+
+<!ELEMENT value
+	( common_name?, description? ) >
+
+<!ATTLIST value
+	name	CDATA #REQUIRED >
+
+<!--
+  values
+
+    Human-readable names and descriptions for valid values of a property.
+-->
+
+<!ELEMENT values
+	(value+) >
+
+<!ATTLIST values>
+
+<!--
+  cardinality
+
+    Places a constraint on the number of values the property can take
+    on.
+
+    Its attributes are:
+	min	minimum number of values
+	max	maximum number of values
+
+    Both attributes are optional.  If min is not specified, it defaults to
+    0.  If max is not specified it indicates an unlimited number of values.
+    If neither is specified this indicates 0 or more values.
+-->
+
+<!ELEMENT cardinality EMPTY>
+
+<!ATTLIST cardinality
+	min	CDATA "0"
+	max	CDATA "18446744073709551615">
+
+<!--
+  internal_separators
+
+    Indicates the separators used within a property's value used to
+    separate the actual values.  Used in situations where multiple
+    values are packed into a single property value instead of using a
+    multi-valued property.
+-->
+
+<!ELEMENT internal_separators
+	(#PCDATA) >
+
+<!ATTLIST internal_separators>
+
+<!--
+  range
+
+    Indicates a range of possible integer values.
+
+    Its attributes are:
+
+      min	The minimum value of the range (inclusive).
+      max	The maximum value of the range (inclusive).
+-->
+
+<!ELEMENT range EMPTY>
+
+<!ATTLIST range
+	min	CDATA #REQUIRED
+	max	CDATA #REQUIRED >
+
+<!--
+  constraints
+
+    Provides a set of constraints on the values a property can take on.
+-->
+
+<!ELEMENT constraints
+	( value*, range* ) >
+<!ATTLIST constraints>
+
+<!--
+  include_values
+
+    Includes an entire set of values in the choices block.
+
+    Its attributes are:
+
+	type    Either "constraints" or "values", indicating an
+		inclusion of all values allowed by the property's
+		constraints or all values for which there are
+		human-readable names and descriptions, respectively.
+-->
+
+<!ELEMENT include_values EMPTY>
+
+<!ATTLIST include_values
+	type	( constraints | values ) #REQUIRED >
+
+<!--
+  choices
+
+    Provides a set of common choices for the values a property can take
+    on.  Useful in those cases where the possibilities are unenumerable
+    or merely inconveniently legion, and a manageable subset is desired
+    for presentation in a user interface.
+-->
+
+<!ELEMENT choices
+	( value*, range*, include_values* ) >
+
+<!ATTLIST choices>
+
+<!--
+  prop_pattern
+
+
+    The prop_pattern describes one property of the enclosing property group
+    pattern.
+
+    Its attributes are:
+
+	name    The property's name.
+	type    The property's type.
+	required
+		If the property group is present, this property is required.
+
+	type can be omitted if required is false.
+-->
+
+<!ELEMENT prop_pattern
+	( common_name?, description?, units?, visibility?, cardinality?,
+	  internal_separators?, values?, constraints?, choices? ) >
+
+<!ATTLIST prop_pattern
+	name		CDATA	#REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	required	( true | false )	"false" >
+
+<!--
+  pg_pattern
+
+    The pg_pattern describes one property group.
+    Depending on the element's attributes, these descriptions may apply
+    to just the enclosing service/instance, instances of the enclosing
+    service, delegates of the service (assuming it is a restarter), or
+    all services.
+
+    Its attributes are:
+
+	name    The property group's name.  If not specified, it
+		matches all property groups with the specified type.
+	type    The property group's type.  If not specified, it
+		matches all property groups with the specified name.
+	required
+		If the property group is required.
+	target	The scope of the pattern, which may be all, delegate,
+		instance, or this.  'all' is reserved for framework use
+		and applies the template to all services on the system.
+		'delegate' is reserved for restarters, and means the
+		template applies to all services which use the restarter.
+		'this' would refer to the defining service or instance.
+		'instance' can only be used in a service's template block,
+		and means the definition applies to all instances of this
+		service.
+
+-->
+
+<!ELEMENT pg_pattern
+	( common_name?, description?, prop_pattern* ) >
+
+<!ATTLIST pg_pattern
+	name		CDATA	""
+	type		CDATA	""
+	required	( true | false )	"false"
+	target		( this | instance | delegate | all )	"this" >
+
+<!--
+  template
+
+    The template contains a collection of metadata about the service.
+    It contains a localizable string that serves as a common,
+    human-readable name for the service.  (This name should be less than
+    60 characters in a single byte locale.)  The template may optionally
+    contain a longer localizable description of the service, a
+    collection of links to documentation, either in the form of manual
+    pages or in the form of URI specifications to external documentation
+    sources (such as docs.sun.com).
+
+    The template has no attributes.
+-->
+<!ELEMENT template
+        ( common_name, description?, documentation?, pg_pattern* ) >
+
+<!ATTLIST template>
+
+<!-- Notification Parameters -->
+
+<!ELEMENT paramval EMPTY>
+
+<!ATTLIST paramval
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED>
+
+<!ELEMENT parameter
+	( value_node* )>
+
+<!ATTLIST parameter
+	name		CDATA #REQUIRED>
+
+<!ELEMENT event EMPTY>
+
+<!ATTLIST event
+	value		CDATA #REQUIRED>
+
+<!ELEMENT type
+	( ( parameter | paramval )* )>
+
+<!ATTLIST type
+	name		CDATA #REQUIRED
+	active		( true | false ) "true" >
+
+<!--
+  notification parameters
+
+    This element sets the notification parameters for Software Events and
+    Fault Management problem lifecycle events.
+-->
+
+<!ELEMENT notification_parameters
+	( event, type+ )>
+
+<!ATTLIST notification_parameters>
+
+<!-- Services and instances -->
+
+<!--
+  create_default_instance
+
+    A flag element indicating that an otherwise empty default instance
+    of this service (named "default") should be created at install, with
+    its enabled property set as given.
+
+    Its attribute is
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT create_default_instance EMPTY >
+
+<!ATTLIST create_default_instance
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  single_instance
+
+    A flag element stating that this service can only have a single
+    instance on a particular system.
+-->
+
+<!ELEMENT single_instance EMPTY>
+
+<!ATTLIST single_instance>
+
+<!--
+  instance
+
+    The service instance is the object representing a software component
+    that will run on the system if enabled.  It contains an enabled
+    element, a set of dependencies on other services, potentially
+    customized methods or configuration data, an optional method
+    context, and a pointer to its restarter.  (If no restarter is
+    specified, the master restarter, svc.startd(1M), is assumed to be
+    responsible for the service.)
+
+    Its attributes are
+
+	name	The canonical name for this instance of the service.
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT instance
+	( restarter?, dependency*, dependent*, method_context?,
+	exec_method*, notification_parameters*, property_group*,
+	template? ) >
+
+<!ATTLIST instance
+	name		CDATA #REQUIRED
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  service
+
+    The service contains the set of instances defined by default for
+    this service, an optional method execution context, any default
+    methods, the template, and various restrictions or advice applicable
+    at installation.  The method execution context and template elements
+    are required for service_bundle documents with type "manifest", but
+    are optional for "profile" or "archive" documents.
+
+    Its attributes are
+
+	name	The canonical name for the service.
+
+	version	[integer] The integer version for this service.
+
+	type	Whether this service is a simple service, a delegated
+		restarter, or a milestone (a synthetic service that
+		collects a group of dependencies).
+-->
+
+<!ELEMENT service
+	( create_default_instance?, single_instance?, restarter?,
+	dependency*, dependent*, method_context?, exec_method*,
+	notification_parameters*, property_group*, instance*,
+	stability?, template? ) >
+
+<!ATTLIST service
+	name		CDATA #REQUIRED
+	version		CDATA #REQUIRED
+	type		( service | restarter | milestone ) #REQUIRED >
+
+<!--
+  service_bundle
+
+    The bundle possesses two attributes:
+
+	type	How this file is to be understood by the framework (or
+		used in a non-framework compliant way). Standard types
+		are 'archive', 'manifest', and 'profile'.
+	
+	name	A name for the bundle.  Manifests should be named after
+		the package which delivered them; profiles should be
+		named after the "feature set nickname" they intend to
+		enable.
+-->
+
+<!ELEMENT service_bundle
+	( service_bundle* | service* | xi:include* )>
+
+<!ATTLIST service_bundle
+	type		CDATA #REQUIRED
+	name		CDATA #REQUIRED>
