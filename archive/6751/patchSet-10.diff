From 91b5e5fde9f485fe08ba7a17d260a3ab18c274d8 Mon Sep 17 00:00:00 2001
From: Rui Loura <rui@joyent.com>
Date: Mon, 5 Aug 2019 13:25:10 -0400
Subject: [PATCH] MANTA-4456 rebalancer jobs need some tests MANTA-4458 add
 ability for rebalancer zone jobs to store assignments in local sqlite
 database MANTA-4469 add thread to rebalancer zone to handle posting
 assignments to agent MANTA-4471 add ProcessAssignment trait to handle
 processing completed assignment from agent MANTA-4480 pin rebalancer to
 correct rust-moray version MANTA-4479 unpin rebalancer from diesel workaround

---
 .gitignore           |    1 +
 Cargo.toml           |   25 +-
 Makefile             |   15 +-
 README.md            |   14 +
 src/agent.rs         |   32 +-
 src/config.json      |    5 +-
 src/config.json.in   |    7 +-
 src/config.rs        |   27 +-
 src/error.rs         |   34 +-
 src/job.rs           |  761 ------------------------
 src/jobs/evacuate.rs | 1334 ++++++++++++++++++++++++++++++++++++++++++
 src/jobs/mod.rs      |  168 ++++++
 src/lib.rs           |   25 +-
 src/main.rs          |   10 +-
 src/picker.rs        |   85 +--
 src/util.rs          |   24 +-
 16 files changed, 1728 insertions(+), 839 deletions(-)
 delete mode 100644 src/job.rs
 create mode 100644 src/jobs/evacuate.rs
 create mode 100644 src/jobs/mod.rs

diff --git a/.gitignore b/.gitignore
index 51b7860..5eff081 100644
--- a/.gitignore
+++ b/.gitignore
@@ -3,3 +3,4 @@
 .idea/*
 Cargo.lock
 cscope.*
+*.db
diff --git a/Cargo.toml b/Cargo.toml
index 91a17fa..6ed19da 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -4,12 +4,15 @@ version = "0.1.0"
 authors = ["Rui Loura <rjloura@gmail.com>"]
 edition = "2018"
 
+[profile.dev]
+panic = "abort"
+
 [dependencies]
 base64 = "0.10.1"
 uuid = { version = "0.7.4", features = ["v4"] }
 libmanta = { git = "https://github.com/joyent/rust-libmanta" }
 clap = "2.33.0"
-sharkspotter = { git = "https://github.com/joyent/rust-sharkspotter"}
+sharkspotter = { git = "https://github.com/joyent/rust-sharkspotter" }
 crossbeam-channel = "0.3.8"
 serde = { version = "1.0.91", features = ["derive"] }
 serde_derive = "1.0.91"
@@ -19,7 +22,7 @@ gotham_derive = "0.3.0"
 hyper = "0.12"
 mime = "0.3.13"
 # TODO: remove in favor of rust-libmanta
-moray = { git = "https://github.com/joyent/rust-moray", branch = "reconnect" }
+moray = { git = "https://github.com/joyent/rust-moray", rev = "89a57e9" }
 futures = "0.1.27"
 tokio = "0.1.21"
 tokio-threadpool = "0.1.14"
@@ -34,3 +37,21 @@ rusqlite = "0.19.0"
 walkdir = "2"
 log = "0.4.6"
 pretty_env_logger = "0.3.0"
+rand = "0.7.0"
+quickcheck = "0.8.5"
+failure = "0.1.5"
+bytes = "0.4.12"
+
+diesel = {version = "1.4.2", features = ["sqlite"]}
+diesel-derive-enum = {git = "https://github.com/adwhit/diesel-derive-enum.git", features = ["sqlite"]}
+
+slog = "2.5.2"
+slog-bunyan = { git = "https://github.com/kellymclaughlin/bunyan", branch = "build-on-smartos" }
+
+## TODO: is this needed?
+slog-term = "2.4.1" 
+
+
+[patch.crates-io]
+diesel = { git = 'https://github.com/diesel-rs/diesel' }
+diesel_derives = { git = "https://github.com/diesel-rs/diesel" }
diff --git a/Makefile b/Makefile
index 6eacb3f..942b63d 100644
--- a/Makefile
+++ b/Makefile
@@ -1,3 +1,16 @@
-all: 
+all: check doc test
 	cargo build
 	cp src/config.json target/debug/
+
+doc:
+	cargo doc
+
+clean:
+	cargo clean 
+
+check: 
+	cargo clippy
+	cargo check
+
+test:
+	RUST_LOG=remora=trace cargo test -- --nocapture
diff --git a/README.md b/README.md
index ae53a0d..5a77998 100644
--- a/README.md
+++ b/README.md
@@ -42,6 +42,20 @@ SUBCOMMANDS:
 
 ```
 
+## Configuration Parameters
+The remora zone leverages configuration parameters in `src/config.json`.  This
+file is populated by the config-agent using `src/config.json.in` as a template.
+
+*Parameters:*
+* sapi_url<String>: The url of the SAPI zone.  Populated by the manta deployment zone.
+* domain_name<String>: The domain name of the manta deployment.  From SAPI application
+metadata (`DOMAIN_NAME`).
+* database_url<String>: Location and name of the zone's local database.
+* database_buffer_size<uint>:  Writes to the database are buffered by up to this
+number of records.
+* shards<Array>: The first and last shard.  From SAPI application metadata `INDEX_MORAY_SHARDS`.
+
+
 ## Development
 
 Before integration run `fmt`, `check`, `test`, and
diff --git a/src/agent.rs b/src/agent.rs
index a202552..33a58ff 100644
--- a/src/agent.rs
+++ b/src/agent.rs
@@ -5,13 +5,13 @@
  */
 
 /*
- * Copyright (c) 2019, Joyent, Inc.
+ * Copyright 2019, Joyent, Inc.
  */
 use std::collections::HashMap;
+use std::ffi::OsString;
 use std::fs;
 use std::fs::File;
 use std::net::*;
-use std::ffi::OsString;
 use std::path::Path;
 use std::sync::{mpsc, Arc, Mutex, RwLock};
 
@@ -30,8 +30,8 @@ use hyper::{Body, Chunk, Method};
 use libmanta::moray::MantaObjectShark;
 use md5::{Digest, Md5};
 
-use crate::job::Task;
-use crate::job::TaskStatus;
+use crate::jobs::Task;
+use crate::jobs::TaskStatus;
 
 use reqwest::StatusCode;
 use rusqlite;
@@ -101,7 +101,7 @@ pub struct Assignment {
     pub uuid: String,
     pub stats: AgentAssignmentStats,
 
-    #[serde(skip_serializing)]
+    #[serde(skip_serializing, skip_deserializing)]
     pub tasks: Vec<Task>,
 }
 
@@ -120,11 +120,14 @@ fn load_saved_assignments(agent: &Agent) {
         .min_depth(1)
         .follow_links(false)
         .into_iter()
-        .filter_map(|e| e.ok()) {
+        .filter_map(|e| e.ok())
+    {
         let uuid = entry.file_name().to_string_lossy();
         println!("{}/{}", REBALANCER_SCHEDULED_DIR, uuid);
-        match assignment_recall(format!("{}/{}", REBALANCER_SCHEDULED_DIR,
-            &uuid)) {
+        match assignment_recall(format!(
+            "{}/{}",
+            REBALANCER_SCHEDULED_DIR, &uuid
+        )) {
             Ok(v) => assignment_add(&agent, v, &uuid),
             Err(e) => panic!(format!("Error loading database: {}", e)),
         }
@@ -216,8 +219,9 @@ fn assignment_recall(path: String) -> Result<Arc<RwLock<Assignment>>, String> {
     // always be named after the assignment uuid.  This will never change,
     // however if it does, then the uuid of the assignment must be stored
     // somewhere within the database.
-    let uuid = OsString::from(file_path.file_stem().unwrap()).
-        into_string().unwrap();
+    let uuid = OsString::from(file_path.file_stem().unwrap())
+        .into_string()
+        .unwrap();
 
     let conn = match rusqlite::Connection::open(path) {
         Ok(conn) => conn,
@@ -426,7 +430,7 @@ fn get_assignment(
                 serde_json::to_vec(&msg).expect("serialized message"),
             );
             return Box::new(future::ok((state, res)));
-        },
+        }
     };
 
     let res = match get_assignment_impl(&agent, uuid) {
@@ -479,10 +483,8 @@ impl Handler for Agent {
                     "assignment" => get_assignment(self, state, path),
                     _ => empty_response(state, StatusCode::NOT_FOUND),
                 }
-            },
-            _ => {
-                empty_response(state, StatusCode::METHOD_NOT_ALLOWED)
-            },
+            }
+            _ => empty_response(state, StatusCode::METHOD_NOT_ALLOWED),
         }
     }
 }
diff --git a/src/config.json b/src/config.json
index bcafca9..4d8aaa7 100644
--- a/src/config.json
+++ b/src/config.json
@@ -1,7 +1,8 @@
 {
   "sapi_url": "http://sapi.ruidc.joyent.us",
   "domain_name": "east.joyent.us",
-
+  "database_url": "rebalancer.sqlite",
+  "database_buffer_size": 100,
   "shards": [
       {
         "host": "3.moray.staging.joyent.us"
@@ -11,4 +12,4 @@
         "last": true
       }
    ]
-}
\ No newline at end of file
+}
diff --git a/src/config.json.in b/src/config.json.in
index 7581835..fe73e80 100644
--- a/src/config.json.in
+++ b/src/config.json.in
@@ -1,6 +1,7 @@
 {
   "sapi_url": "http://sapi.ruidc.joyent.us",
   "domain_name": {{DOMAIN_NAME}},
-  "index_shards": {{INDEX_MORAY_SHARDS}},
-  "min_avail_mb": 1000,
-}
\ No newline at end of file
+  "database_url": "rebalancer.sqlite",
+  "database_buffer_size": 100,
+  "shards": {{INDEX_MORAY_SHARDS}}
+}
diff --git a/src/config.rs b/src/config.rs
index b7bc7ac..4ad8b00 100644
--- a/src/config.rs
+++ b/src/config.rs
@@ -1,4 +1,12 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
 
 extern crate clap;
 
@@ -6,8 +14,9 @@ use clap::{App, AppSettings, Arg, ArgMatches, SubCommand as ClapSubCommand};
 use serde::Deserialize;
 use std::fs::File;
 use std::io::{BufReader, Error};
+use std::process;
 
-use crate::job::{EvacuateJob, Job, JobAction};
+use crate::jobs::{evacuate::EvacuateJob, Job, JobAction};
 use crate::util;
 
 #[derive(Deserialize, Default, Debug, Clone)]
@@ -20,6 +29,7 @@ pub struct Config {
     pub sapi_url: String,
     pub domain_name: String,
     pub shards: Vec<Shard>,
+    pub database_url: String,
 }
 
 impl Config {
@@ -47,14 +57,13 @@ impl Config {
         })
     }
 }
-#[derive(Debug)]
+
 pub enum SubCommand {
     Server, // Start the server
     Agent,
     DoJob(Box<Job>),
 }
 
-#[derive(Debug)]
 pub struct Command {
     pub config: Config,
     pub subcommand: SubCommand,
@@ -118,7 +127,6 @@ impl Command {
                                             .value_name("SHARK")
                                             .help("shark to evacuate"),
                                     )
-                                    // TODO: use picker
                                     .arg(
                                         Arg::with_name("to_shark")
                                             .short("d")
@@ -180,12 +188,19 @@ impl Command {
     }
 }
 
+// TODO:
+// This should really be removed in favor of the following:
+// 1. Command::new() handling override of domain_name from config file
+// 2. Job::new() taking all args necssary to create new Job Action (e.g.
+// EvacuateJob)
 fn job_subcommand_handler(matches: &ArgMatches, config: Config) -> SubCommand {
     let shark_id = matches.value_of("from_shark").unwrap_or("").to_string();
     let domain_name = matches.value_of("domain").unwrap_or(&config.domain_name);
 
     let from_shark = format!("{}.{}", shark_id, domain_name);
-    let job_action = JobAction::Evacuate(EvacuateJob::new(from_shark));
+    let db_url = format!("{}.{}", &config.database_url, process::id());
+    let job_action =
+        JobAction::Evacuate(Box::new(EvacuateJob::new(from_shark, &db_url)));
     let job = Job::new(job_action, config);
 
     SubCommand::DoJob(Box::new(job))
diff --git a/src/error.rs b/src/error.rs
index c179343..64b1d73 100644
--- a/src/error.rs
+++ b/src/error.rs
@@ -1,4 +1,12 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
 
 use std::fmt;
 
@@ -6,6 +14,7 @@ use std::fmt;
 pub enum Error {
     Internal(InternalError),
     IoError(std::io::Error),
+    Hyper(hyper::Error),
 }
 
 impl std::error::Error for Error {
@@ -13,10 +22,17 @@ impl std::error::Error for Error {
         match self {
             Error::Internal(e) => e.msg.as_str(),
             Error::IoError(e) => e.description(),
+            Error::Hyper(e) => e.description(),
         }
     }
 }
 
+impl From<hyper::Error> for Error {
+    fn from(error: hyper::Error) -> Self {
+        Error::Hyper(error)
+    }
+}
+
 impl From<std::io::Error> for Error {
     fn from(error: std::io::Error) -> Self {
         Error::IoError(error)
@@ -34,21 +50,25 @@ impl fmt::Display for Error {
         match self {
             Error::Internal(e) => write!(f, "{}", e),
             Error::IoError(e) => write!(f, "{}", e),
+            Error::Hyper(e) => write!(f, "{}", e),
         }
     }
 }
 
-#[derive(Debug)]
+#[derive(Debug, PartialEq)]
 pub struct InternalError {
     msg: String,
-    code: InternalErrorCode,
+    pub code: InternalErrorCode,
 }
 
-#[derive(Debug, Copy, Clone)]
+#[derive(Debug, Copy, Clone, PartialEq)]
 pub enum InternalErrorCode {
-    Other = 0,
-    InvalidJobAction = 1,
-    Crossbeam = 2,
+    Other,
+    InvalidJobAction,
+    Crossbeam,
+    PickerError,
+    AssignmentLookupError,
+    LockError,
 }
 
 impl fmt::Display for InternalError {
diff --git a/src/job.rs b/src/job.rs
deleted file mode 100644
index 1a9ba48..0000000
--- a/src/job.rs
+++ /dev/null
@@ -1,761 +0,0 @@
-/*
- * This Source Code Form is subject to the terms of the Mozilla Public
- * License, v. 2.0. If a copy of the MPL was not distributed with this
- * file, You can obtain one at http://mozilla.org/MPL/2.0/.
- */
-
-/*
- * Copyright (c) 2019, Joyent, Inc.
- */
-use crate::config::Config;
-use crate::error::{CrossbeamError, Error, InternalError, InternalErrorCode};
-use crate::picker as mod_picker;
-use crate::picker::{Picker, StorageNode};
-use crossbeam_channel as crossbeam;
-use libmanta::moray::{MantaObject, MantaObjectShark};
-use serde::{Deserialize, Serialize};
-use std::collections::HashMap;
-use std::error::Error as _Error;
-use std::io::ErrorKind;
-use std::sync::{Arc, RwLock};
-use std::thread;
-use uuid::Uuid;
-
-pub type StorageId = String;
-
-#[derive(Debug)]
-pub struct Job {
-    id: Uuid,
-    action: JobAction,
-    state: JobState,
-    config: Config,
-}
-
-#[derive(Debug, Clone)]
-pub enum JobState {
-    Init,
-    Setup,
-    Running,
-    Stopped,
-    Complete,
-    Failed,
-}
-
-#[derive(Debug)]
-pub enum JobAction {
-    Evacuate(EvacuateJob),
-    None,
-}
-
-#[derive(Debug, Clone, PartialEq)]
-enum EvacuateObjectStatus {
-    Unprocessed, // Default state
-    Processing,  // Object has been included in an assignment and that
-    // assignment has been submitted to a remora agent.
-    Skipped, // Could not find a shark to put this object in. TODO: Why?
-             // TODO: Failed,   // Failed to Evacuate Object ???
-             // TODO: Retrying, // Retrying a failed evacuate attempt
-}
-
-#[derive(Debug, Clone)]
-struct EvacuateObject {
-    id: String,
-    object: MantaObject,
-    status: EvacuateObjectStatus,
-}
-
-impl EvacuateObject {
-    fn new(object: MantaObject) -> Self {
-        Self {
-            id: object.object_id.to_owned(),
-            object,
-            status: EvacuateObjectStatus::Unprocessed,
-        }
-    }
-}
-
-impl Default for EvacuateObject {
-    fn default() -> Self {
-        let object = MantaObject::default();
-        Self {
-            id: String::from(""),
-            object,
-            status: EvacuateObjectStatus::Unprocessed,
-        }
-    }
-}
-
-#[derive(Clone, Debug, PartialEq)]
-enum DestSharkStatus {
-    Init,
-    Assigned,
-    Ready,
-}
-
-#[derive(Clone, Debug)]
-struct EvacuateDestShark {
-    shark: StorageNode,
-    status: DestSharkStatus,
-}
-
-#[derive(Debug)]
-pub struct EvacuateJob {
-    dest_shark_list: RwLock<HashMap<StorageId, EvacuateDestShark>>,
-    objects: Vec<EvacuateObject>, // TODO: remove in favor of diesel w/ sqlite
-    assignments: RwLock<Vec<Assignment>>,
-    from_shark: MantaObjectShark,
-    min_avail_mb: Option<u64>,
-    max_tasks_per_assignment: Option<u32>,
-}
-
-#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
-enum AssignmentState {
-    Init,
-    Assigned,
-    Rejected,
-    Complete,
-    PostProcessed,
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-pub struct Assignment {
-    id: String,
-    dest_shark: StorageId,
-    tasks: Vec<Task>,
-    max_size: u64,
-    total_size: u64,
-    state: AssignmentState,
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-pub struct Task {
-    pub object_id: String, // or Uuid
-    pub owner: String,     // or Uuid
-    pub md5sum: String,
-    pub source: MantaObjectShark,
-
-    #[serde(default = "TaskStatus::default")]
-    pub status: TaskStatus,
-}
-
-impl Task {
-    pub fn set_status(&mut self, status: TaskStatus) {
-        self.status = status;
-    }
-}
-
-#[derive(Clone, Serialize, Deserialize, Debug)]
-pub enum TaskStatus {
-    Pending,
-    Running,
-    Complete,
-    Failed(String),
-}
-
-impl TaskStatus {
-    pub fn default() -> Self {
-        TaskStatus::Pending
-    }
-}
-
-impl Default for Job {
-    fn default() -> Self {
-        Self {
-            action: JobAction::default(),
-            state: JobState::default(),
-            id: Uuid::new_v4(),
-            config: Config::default(),
-        }
-    }
-}
-
-impl Job {
-    pub fn new(action: JobAction, config: Config) -> Self {
-        Job {
-            action,
-            config,
-            ..Default::default()
-        }
-    }
-
-    pub fn run(self) -> Result<(), Error> {
-        match &self.action {
-            JobAction::Evacuate(_) => run_evacuate_job(self),
-            _ => Ok(()),
-        }
-    }
-}
-
-impl Default for JobAction {
-    fn default() -> Self {
-        JobAction::None
-    }
-}
-
-impl Default for JobState {
-    fn default() -> Self {
-        JobState::Init
-    }
-}
-
-impl EvacuateJob {
-    pub fn new(from_shark: String) -> Self {
-        Self {
-            min_avail_mb: Some(1000),
-            max_tasks_per_assignment: Some(100),
-            dest_shark_list: RwLock::new(HashMap::new()),
-            objects: vec![],
-            assignments: RwLock::new(vec![]),
-            from_shark: MantaObjectShark {
-                manta_storage_id: from_shark,
-                ..Default::default()
-            },
-        }
-    }
-
-    /// If a shark is in the Assigned state then it is busy.
-    fn shark_busy(&self, shark: &StorageNode) -> bool {
-        if let Some(eds) = self
-            .dest_shark_list
-            .read()
-            .unwrap()
-            .get(shark.manta_storage_id.as_str())
-        {
-            debug!(
-                "shark '{}' status: {:?}",
-                shark.manta_storage_id, eds.status
-            );
-            return eds.status == DestSharkStatus::Assigned;
-        }
-
-        false
-    }
-
-    fn post_assignment(&self, mut assignment: Assignment) -> Result<(), Error> {
-        // TODO agent: Send assignment to agent
-        // TODO sqlite: put assignment into persistent store?
-
-        assignment.state = AssignmentState::Assigned;
-        let mut assignments = self.assignments.write().unwrap();
-        assignments.push(assignment);
-        Ok(())
-    }
-
-    /// checks all assigned assignments for their current status from the
-    /// agent returning number of assignments that changed state
-    fn check_assignments(&self) -> Result<u32, Error> {
-        debug!("checking assignments");
-        let mut updated_shark_count = 0;
-        let mut assignments = self.assignments.write().unwrap();
-        for assignment in assignments.iter_mut() {
-            if assignment.state != AssignmentState::Assigned {
-                continue;
-            }
-
-            let _uri = format!(
-                "http://{}/assignment/{}",
-                assignment.dest_shark, assignment.id
-            );
-            // TODO agent: make request to agent "uri" for assignment status
-
-            // update assignment status based on return value
-            // for now just mark as complete
-            assignment.state = AssignmentState::Complete;
-
-            // update shark status
-            if let Some(dest_shark) = self
-                .dest_shark_list
-                .write()
-                .unwrap()
-                .get_mut(assignment.dest_shark.as_str())
-            {
-                debug!(
-                    "Updating shark '{}' to Ready state",
-                    assignment.dest_shark.as_str()
-                );
-                dest_shark.status = DestSharkStatus::Ready;
-                updated_shark_count += 1;
-            } else {
-                warn!(
-                    "Could not find shark: '{}'",
-                    assignment.dest_shark.as_str()
-                );
-            }
-
-            // post process Assignment by updating objects in persistent store
-            // this could be it's own thread
-            // TODO metadata: for now just mark them as post processed
-            assignment.state = AssignmentState::PostProcessed;
-        }
-        Ok(updated_shark_count)
-    }
-
-    /// Iterate over a new set of storage nodes and update our destination
-    /// shark list accordingly.  This may need to change so that we update
-    /// available_mb more judiciously (i.e. based on timestamp).
-    fn update_dest_sharks(&self, new_sharks: &[StorageNode]) {
-        let mut dest_shark_list = self.dest_shark_list.write().unwrap();
-        for sn in new_sharks.iter() {
-            if let Some(dest_shark) =
-                dest_shark_list.get_mut(sn.manta_storage_id.as_str())
-            {
-                if dest_shark.status == DestSharkStatus::Ready {
-                    dest_shark.shark.available_mb = sn.available_mb;
-                }
-            } else {
-                // create new dest shark and add it to the hash
-                let new_shark = EvacuateDestShark {
-                    shark: sn.to_owned(),
-                    status: DestSharkStatus::Init,
-                };
-                debug!("Adding new destination shark {:?} ", new_shark);
-                dest_shark_list.insert(sn.manta_storage_id.clone(), new_shark);
-            }
-        }
-
-        // Walk the list of our destination sharks, if it doesn't exist in
-        // new_sharks Vec then remove it from the hash.  Perhaps a pre-walk
-        // of marking every dest_shark dirty and then a post walk
-        // marking each found shark as clean, and removing all dirty sharks
-        // would be more efficient.
-        *dest_shark_list = dest_shark_list
-            .iter()
-            .filter(|&(ds, _)| {
-                new_sharks.iter().any(|s| &s.manta_storage_id == ds)
-            })
-            .map(|(k, v)| (k.clone(), v.clone()))
-            .collect();
-    }
-}
-
-// TODO: bring this into impl EvacuateJob
-fn run_evacuate_job(job: Job) -> Result<(), Error> {
-    debug!("Running evacuate job: {:?}", &job);
-    let domain = &job.config.domain_name;
-
-    let job_action = match job.action {
-        JobAction::Evacuate(action) => Arc::new(action),
-        _ => {
-            return Err(InternalError::new(
-                Some(InternalErrorCode::InvalidJobAction),
-                "Evacuate received invalid Job action",
-            )
-            .into());
-        }
-    };
-
-    println!("Starting Evacuate Job: {}", &job.id);
-
-    let min_shard = job.config.min_shard_num();
-    let max_shard = job.config.max_shard_num();
-
-    // Steps:
-    // TODO lock evacuating server to readonly
-
-    let (obj_tx, obj_rx) = crossbeam::bounded(5);
-    let (empty_assignment_tx, empty_assignment_rx) = crossbeam::bounded(5);
-    let (full_assignment_tx, full_assignment_rx) = crossbeam::bounded(5);
-
-    let sharkspotter_handle = start_sharkspotter(
-        obj_tx,
-        domain.as_str(),
-        Arc::clone(&job_action),
-        min_shard,
-        max_shard,
-    )?;
-
-    let assignment_generator = start_assignment_generator(
-        obj_rx,
-        empty_assignment_rx,
-        full_assignment_tx,
-        Arc::clone(&job_action),
-    )?;
-
-    let mut picker = mod_picker::Picker::new();
-    picker.start().map_err(Error::from)?;
-
-    let picker = Arc::new(picker);
-
-    let assignment_manager = start_assignment_manager(
-        empty_assignment_tx,
-        full_assignment_rx,
-        Arc::clone(&job_action),
-        Arc::clone(&picker),
-    )?;
-
-    assignment_manager
-        .join()
-        .unwrap()
-        .expect("Error joining assignment generator thread");
-
-    picker.fini();
-
-    sharkspotter_handle.join().unwrap().unwrap_or_else(|e| {
-        error!("Error joining sharkspotter handle: {}\n", e);
-        std::process::exit(1);
-    });
-
-    assignment_generator
-        .join()
-        .unwrap()
-        .expect("Error joining assignment generator thread");
-
-    Ok(())
-}
-
-/// Start the sharkspotter thread and feed the objects into the assignment
-/// thread.  If the assignment thread (the rx side of the channel) exits
-/// prematurely the sender.send() method will return a SenderError and that
-/// needs to be handled properly.
-fn start_sharkspotter(
-    sender: crossbeam::Sender<MantaObject>,
-    domain: &str,
-    job_action: Arc<EvacuateJob>,
-    min_shard: u32,
-    max_shard: u32,
-) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
-    let shark = &job_action.from_shark.manta_storage_id;
-    let config = sharkspotter::config::Config {
-        domain: String::from(domain),
-        min_shard,
-        max_shard,
-        shark: String::from(shark.as_str()),
-        ..Default::default()
-    };
-
-    debug!("Starting sharkspotter thread: {:?}", &config);
-
-    thread::Builder::new()
-        .name(String::from("sharkspotter"))
-        .spawn(move || {
-            let mut count = 0;
-            sharkspotter::run(&config, move |obj, _shard| {
-                // while testing limit the number of objects processed for now
-                count += 1;
-                if count > 2000 {
-                    return Err(std::io::Error::new(
-                        ErrorKind::Other,
-                        "Just stop already",
-                    ));
-                }
-
-                // TODO:
-                // - add shard number
-                sender.send(obj).map_err(CrossbeamError::from).map_err(|e| {
-                    std::io::Error::new(ErrorKind::Other, e.description())
-                })
-            })
-            .map_err(Error::from)
-        })
-        .map_err(Error::from)
-}
-
-/// The assignment manager manages the destination sharks and
-/// posts assignments to the remora agents running on the destination sharks.
-/// Given a set of sharks that meet a set of parameters outlined by the
-/// configuration the assignment manager
-///     1. Initializes a new assignment with certain destination shark
-///     specific the parameters.
-///     2. Passes that assignment to the assignment generator thread which
-///     adds tasks and sends the assignment back to this thread.
-///     3. Post the assignment to the remora agent on the destination shark.
-///
-/// In the future another thread may be created to handle step 3.
-///
-/// Restrictions:
-/// * Only 1 outstanding assignment per storage node (could change this in
-/// the future, or make it tunable)
-/// * If all storage ndoes with availableMb > Some TBD threshold have an
-/// outstanding assignment, sleep/wait for an assignment to complete.
-fn start_assignment_manager(
-    empty_assignment_tx: crossbeam::Sender<Assignment>,
-    full_assignment_rx: crossbeam::Receiver<Assignment>,
-    job_action: Arc<EvacuateJob>,
-    picker: Arc<Picker>,
-) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
-    let builder = thread::Builder::new();
-
-    builder
-        .name(String::from("assignment_manager"))
-        .spawn(move || {
-            let from_shark_datacenter =
-                job_action.from_shark.datacenter.to_owned();
-            let mut shark_index = 0;
-            let algo = mod_picker::DefaultPickerAlgorithm {
-                min_avail_mb: job_action.min_avail_mb,
-                blacklist: vec![from_shark_datacenter],
-            };
-
-            let mut valid_sharks = vec![];
-            let mut shark_list = vec![];
-
-            loop {
-                // TODO: allow for premature cancellation
-
-                trace!("shark index: {}", shark_index);
-                if valid_sharks.is_empty()
-                    || shark_index
-                        >= job_action.dest_shark_list.read().unwrap().len()
-                {
-                    shark_index = 0;
-
-                    // Check on assignments and update sharks accordingly
-                    job_action.check_assignments()?;
-
-                    // Check for a new picker snapshot
-                    valid_sharks = match picker
-                        .choose(&mod_picker::PickerAlgorithm::Default(&algo))
-                    {
-                        Some(sharks) => sharks,
-                        None => valid_sharks,
-                    };
-
-                    // update destination shark list
-                    // TODO: perhaps this should be a BTreeMap or just a vec.
-                    job_action.update_dest_sharks(&valid_sharks);
-
-                    // TODO: Think about this a bit more.  On one hand making
-                    // a 1 time copy and cycling through the whole list makes
-                    // sense if we want to update the dest_shark_list while
-                    // iterating over existing sharks.  On the other hand it
-                    // doesn't seem like we would need to update the list of
-                    // sharks except when we enter this block, so we could
-                    // take the reader lock for each iteration and only take
-                    // the writer lock inside the job_action methods called
-                    // above.
-                    for (_key, value) in
-                        job_action.dest_shark_list.read().unwrap().iter()
-                    {
-                        shark_list.push(value.shark.to_owned());
-                    }
-
-                    shark_list.sort_by_key(|s| s.available_mb);
-                }
-
-                let cur_shark = &shark_list[shark_index];
-
-                shark_index += 1;
-
-                if job_action.shark_busy(cur_shark) {
-                    info!(
-                        "Shark '{}' is busy, trying next shark.",
-                        cur_shark.manta_storage_id
-                    );
-                    continue;
-                }
-
-                // Only use half of the available space per shark per assignment
-                let assignment = Assignment {
-                    id: String::from(""),
-                    dest_shark: cur_shark.manta_storage_id.clone(),
-                    max_size: cur_shark.available_mb / 2,
-                    total_size: 0,
-                    tasks: vec![],
-                    state: AssignmentState::Init,
-                };
-
-                match empty_assignment_tx.send(assignment) {
-                    Ok(()) => {
-                        // TODO: this should be it's own thread, and the
-                        // generator should send the assignment to that thread.
-                        // See step 3 in the block comment at the top of this
-                        // function.
-                        while let Ok(new_assignment) =
-                            full_assignment_rx.try_recv()
-                        {
-                            // TODO: update shark with space avail?  Might not be needed
-                            // since we take a picker snapshot before we start adding to
-                            // a shark
-
-                            info!(
-                                "Posting Assignment: {}\n",
-                                serde_json::to_string(&new_assignment).unwrap()
-                            );
-                            job_action.post_assignment(new_assignment)?;
-                        }
-                    }
-                    Err(e) => {
-                        // TODO: this thread should probably spawn
-                        // assignment_generator thread(s) so that it can maintain
-                        // the generator threads.
-                        error!("{}", CrossbeamError::from(e));
-                        break;
-                    }
-                }
-            }
-            Ok(())
-        })
-        .map_err(Error::from)
-}
-
-/// Assignment Generation:
-/// 1. Get snapshot from picker
-/// 2. Get initialized assignment from assignment manager thread.
-/// 3. Fill out assignment with tasks according to the parameters outlined
-/// in the assignment template received.
-/// 4. Send filled out assignment back to assignment manager thread.
-fn start_assignment_generator(
-    obj_rx: crossbeam::Receiver<MantaObject>,
-    empty_assignment_rx: crossbeam::Receiver<Assignment>,
-    full_assignment_tx: crossbeam::Sender<Assignment>,
-    job_action: Arc<EvacuateJob>,
-) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
-    let mut mobj: EvacuateObject = EvacuateObject::default();
-    let max_tasks = job_action.max_tasks_per_assignment;
-    let from_shark_host = job_action.from_shark.manta_storage_id.clone();
-
-    let builder = thread::Builder::new();
-    builder
-        .name(String::from("assignment_generator"))
-        .spawn(move || {
-            'assignment: loop {
-                let mut assignment = match empty_assignment_rx.recv() {
-                    Ok(assignment) => assignment,
-                    Err(_) => break 'assignment,
-                };
-
-                let mut available_space = assignment.max_size;
-                let mut rx_obj_count = 0;
-
-                debug!("Max tasks: {:?}", &max_tasks);
-                'task: while {
-                    let mut cont = true;
-
-                    // If we have exceeded the per shark number of tasks then
-                    // move on.  If max tasks is not specified then we continue
-                    // to fill'er up.
-                    if let Some(max_tasks) = max_tasks {
-                        if assignment.tasks.len() > (max_tasks - 1) as usize {
-                            cont = false;
-                        } else {
-                            cont = true;
-                        }
-                    }
-                    cont
-                } {
-                    // Only get a new object if this current one wasn't skipped
-                    // from the last iteration.
-                    if mobj.status != EvacuateObjectStatus::Skipped {
-                        mobj = match obj_rx.recv() {
-                            Ok(obj) => {
-                                rx_obj_count += 1;
-                                trace!("Received object {}", &rx_obj_count);
-                                EvacuateObject::new(obj)
-                            }
-                            Err(e) => {
-                                error!("Error receiving object {}\n", e);
-
-                                // There are no new objects left, post the
-                                // current assignment and break out of the
-                                // assignment loop.
-                                if !assignment.tasks.is_empty() {
-                                    // TODO: map error
-                                    match full_assignment_tx
-                                        .send(assignment)
-                                        .map_err(CrossbeamError::from)
-                                    {
-                                        Ok(()) => (),
-                                        Err(err) => {
-                                            return Err(InternalError::new(
-                                            Some(InternalErrorCode::Crossbeam),
-                                            err.description()).into());
-                                        }
-                                    }
-                                }
-                                break 'assignment;
-                            }
-                        };
-                    }
-
-                    let content_mb = mobj.object.content_length / (1024 * 1024);
-                    if content_mb > available_space {
-                        mobj.status = EvacuateObjectStatus::Skipped;
-                        info!(
-                            "Skipping object, need: {}, available: {} | {:?}\n",
-                            content_mb, available_space, mobj
-                        );
-
-                        // TODO sqlite: Push object onto persistent store
-                        break 'task;
-                    }
-
-                    let obj = &mobj.object;
-
-                    let obj_not_on_dest = obj
-                        .sharks
-                        .iter()
-                        .find(|s| s.manta_storage_id == assignment.dest_shark)
-                        .is_none();
-
-                    // We've found the object on the destination shark.  We will
-                    // need to skip this object for now and find a destination
-                    // for it later.  If we don't do this check it would
-                    // essentially reduce the durability level of the object.
-                    if !obj_not_on_dest {
-                        info!(
-                            "Skipping object already on dest shark {}",
-                            &obj.object_id
-                        );
-                        // TODO sqlite: put skipped object in persistent store.
-                        // mobj.status = EvacuateObjectStatus::Skipped;
-                        // job_action.objects.push(mobj);
-                        continue;
-                    }
-
-                    // pick source shark
-                    let source = match obj
-                        .sharks
-                        .iter()
-                        .find(|s| s.manta_storage_id != from_shark_host)
-                    {
-                        Some(src) => src,
-                        None => {
-                            // TODO sqlite: put skipped object in persistent store.
-                            // mobj.status = EvacuateObjectStatus::Skipped;
-                            // job_action.objects.push(mobj);
-                            continue;
-                        }
-                    };
-
-                    // Add the task to the assignment.
-                    // This creates a task copying the relevant fields of the
-                    // object.
-                    assignment.tasks.push(Task {
-                        object_id: obj.object_id.to_owned(),
-                        owner: obj.owner.to_owned(),
-                        md5sum: obj.content_md5.to_owned(),
-                        source: source.to_owned(),
-                        status: TaskStatus::Pending,
-                    });
-
-                    available_space -= content_mb;
-
-                    trace!(
-                        "Available space: {} | Tasks: {}",
-                        &available_space,
-                        &assignment.tasks.len()
-                    );
-                    mobj.status = EvacuateObjectStatus::Processing;
-
-                    // TODO sqlite: create_or_update object to persistent store
-                }
-
-                info!(
-                    "sending assignment back to manager thread: {:?}",
-                    &assignment
-                );
-
-                full_assignment_tx.send(assignment).map_err(|e| {
-                    error!("Error sending assignment back to manager: {}", e);
-
-                    InternalError::new(
-                        Some(InternalErrorCode::Crossbeam),
-                        CrossbeamError::from(e).description(),
-                    )
-                })?;
-            }
-
-            Ok(())
-        })
-        .map_err(Error::from)
-}
diff --git a/src/jobs/evacuate.rs b/src/jobs/evacuate.rs
new file mode 100644
index 0000000..abee0d4
--- /dev/null
+++ b/src/jobs/evacuate.rs
@@ -0,0 +1,1334 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
+
+use crate::agent::{AgentAssignmentState, Assignment as AgentAssignment};
+use crate::config::Config;
+use crate::error::{CrossbeamError, Error, InternalError, InternalErrorCode};
+use crate::jobs::{
+    Assignment, AssignmentId, AssignmentState, ObjectId, StorageId, Task,
+    TaskStatus,
+};
+use crate::picker::{self as mod_picker, SharkSource, StorageNode};
+
+use std::collections::HashMap;
+use std::error::Error as _Error;
+use std::io::ErrorKind;
+use std::sync::{Arc, Mutex, RwLock};
+use std::thread;
+
+use bytes::Bytes;
+use crossbeam_channel as crossbeam;
+use libmanta::moray::{MantaObject, MantaObjectShark};
+use slog::{o, Drain, Logger};
+use std::borrow::Borrow;
+use uuid::Uuid;
+
+// --- Diesel Stuff, TODO This should be refactored --- //
+
+use diesel::prelude::*;
+use serde_json;
+
+// TODO: move database stuff somewhere.
+table! {
+    use diesel::sql_types::{Text};
+    use super::EvacuateObjectStatusMapping;
+    evacuateobjects (id) {
+        id -> Text,
+        object -> Text,
+        assignment_id -> Text,
+        status -> EvacuateObjectStatusMapping,
+    }
+}
+
+#[derive(Insertable, Queryable, Identifiable)]
+#[table_name = "evacuateobjects"]
+struct UpdateEvacuateObject<'a> {
+    id: &'a str,
+}
+
+#[derive(Insertable, Queryable, Identifiable, AsChangeset, Debug, PartialEq)]
+#[table_name = "evacuateobjects"]
+pub struct EvacuateObjectInsertable {
+    pub id: String,
+    pub object: String,
+    pub assignment_id: AssignmentId,
+    pub status: EvacuateObjectStatus,
+}
+
+// --- END Diesel Stuff --- //
+
+#[derive(Debug, Clone, PartialEq, DbEnum)]
+pub enum EvacuateObjectStatus {
+    Unprocessed,    // Default state
+    Processing,     // Object has been included in an assignment
+    Skipped,        // Could not find a shark to put this object in. TODO: Why?
+    PostProcessing, // Object has been moved, metadata update in progress
+    Complete,       // Object moved, and metadata updated
+                    // TODO: Failed,   // Failed to Evacuate Object ???
+                    // TODO: Retrying, // Retrying a failed evacuate attempt
+                    // TODO: A Status for being part of a submitted assignment?
+}
+
+impl Default for EvacuateObjectStatus {
+    fn default() -> Self {
+        EvacuateObjectStatus::Unprocessed
+    }
+}
+
+/// Wrap a given MantaObject in another structure so that we can track it's
+/// progress through the evacuation process.
+#[derive(Debug, Clone)]
+pub struct EvacuateObject {
+    pub id: ObjectId,        // MantaObject ObjectId
+    pub object: MantaObject, // The MantaObject being rebalanced
+    pub assignment_id: AssignmentId,
+    //UUID of assignment this object was most recently part of.
+    pub status: EvacuateObjectStatus,
+    // Status of the object in the evacuation job
+}
+
+impl EvacuateObject {
+    fn new(object: MantaObject) -> Self {
+        Self {
+            id: object.object_id.to_owned(),
+            object,
+            assignment_id: Uuid::new_v4().to_string(),
+            ..Default::default()
+        }
+    }
+}
+
+impl EvacuateObject {
+    // TODO: ToSql for EvacuateObject MANTA-4474
+    fn to_insertable(&self) -> EvacuateObjectInsertable {
+        EvacuateObjectInsertable {
+            id: self.id.clone(),
+            assignment_id: self.assignment_id.clone(),
+            object: serde_json::to_string(&self.object).unwrap(),
+            status: self.status.clone(),
+        }
+    }
+}
+impl Default for EvacuateObject {
+    fn default() -> Self {
+        let object = MantaObject::default();
+        Self {
+            id: String::new(),
+            object,
+            assignment_id: String::new(),
+            status: EvacuateObjectStatus::default(),
+        }
+    }
+}
+
+#[derive(Clone, Debug, PartialEq)]
+pub enum DestSharkStatus {
+    Init,
+    Assigned,
+    Ready,
+}
+
+#[derive(Clone, Debug)]
+pub struct EvacuateDestShark {
+    pub shark: StorageNode,
+    pub status: DestSharkStatus,
+}
+
+/// Evacuate a given shark
+///  * from_shark: the shark to evacuate
+///  * dest_shark_list: Hash of destination sharks that may change during the
+/// job execution.
+///  * assignments: Hash of in progress assignments
+///  * min_avail_mb: The minimum available space for a shark to be consider
+/// a destination.
+///  * max_tasks_per_assignment: Maximum number of tasks to include in a single
+/// assignment.
+///  * conn: SqliteConnection to local database
+/// // TODO: These should be refactored:
+///  * buffered_objs: Currently used to buffer EvacuateObject's into a
+/// batched sqlite insert.
+///  * total_db_time: Accumulator for total time spent on DB inserts. test/dev
+pub struct EvacuateJob {
+    pub dest_shark_list: RwLock<HashMap<StorageId, EvacuateDestShark>>,
+    pub assignments: RwLock<HashMap<String, Assignment>>,
+    pub from_shark: MantaObjectShark,
+    pub min_avail_mb: Option<u64>,
+    pub max_tasks_per_assignment: Option<u32>,
+    pub conn: Mutex<SqliteConnection>,
+    pub buffered_objs: Mutex<Vec<EvacuateObjectInsertable>>,
+    pub total_db_time: Mutex<u128>,
+}
+
+impl EvacuateJob {
+    /// Create a new EvacauteJob instance.
+    /// As part of this initialization also create a new SqliteConnection.
+    pub fn new<S: Into<String>>(from_shark: S, db_url: &str) -> Self {
+        let manta_storage_id = from_shark.into();
+        dbg!(&db_url);
+        let conn = SqliteConnection::establish(db_url)
+            .unwrap_or_else(|_| panic!("Error connecting to {}", db_url));
+        Self {
+            min_avail_mb: Some(1000),
+            max_tasks_per_assignment: Some(100),
+            dest_shark_list: RwLock::new(HashMap::new()),
+            assignments: RwLock::new(HashMap::new()),
+            from_shark: MantaObjectShark {
+                manta_storage_id,
+                ..Default::default()
+            },
+            conn: Mutex::new(conn),
+            buffered_objs: Mutex::new(vec![]),
+            total_db_time: Mutex::new(0),
+        }
+    }
+
+    pub fn run(self, config: &Config) -> Result<(), Error> {
+        // TODO: check if table exists first and if so issue warning.  We may
+        // need to handle this a bit more gracefully in the future for
+        // restarting jobs...
+
+        let conn = self.conn.lock().unwrap();
+        conn.execute(r#"DROP TABLE evacuateobjects"#)
+            .unwrap_or_else(|_| {
+                println!("table exists?");
+                0
+            });
+
+        conn.execute(
+            r#"
+                CREATE TABLE evacuateobjects(
+                    id TEXT PRIMARY KEY,
+                    object TEXT,
+                    assignment_id TEXT,
+                    status TEXT CHECK(status IN ('unprocessed', 'processing',
+                    'skipped', 'post_processing', 'complete')) NOT NULL
+                );
+            "#,
+        )
+        .unwrap();
+
+        drop(conn);
+
+        // job_action will be shared between threads so create an Arc for it.
+        let job_action = Arc::new(self);
+
+        // get what the evacuate job needs from the config structure
+        let domain = &config.domain_name;
+        let min_shard = config.min_shard_num();
+        let max_shard = config.max_shard_num();
+
+        // TODO: How big should each channel be?
+        // Set up channels for thread to communicate.
+        let (obj_tx, obj_rx) = crossbeam::bounded(5);
+        let (empty_assignment_tx, empty_assignment_rx) = crossbeam::bounded(5);
+        let (full_assignment_tx, full_assignment_rx) = crossbeam::bounded(5);
+
+        // TODO: lock evacuating server to readonly
+        // TODO: add thread barriers MANTA-4457
+
+        // start threads to process objects
+        let sharkspotter_thread = start_sharkspotter(
+            obj_tx,
+            domain.as_str(),
+            Arc::clone(&job_action),
+            min_shard,
+            max_shard,
+        )?;
+
+        let post_thread =
+            start_assignment_post(full_assignment_rx, Arc::clone(&job_action))?;
+
+        let generator_thread = start_assignment_generator(
+            obj_rx,
+            empty_assignment_rx,
+            full_assignment_tx,
+            Arc::clone(&job_action),
+        )?;
+
+        // start picker thread which will periodically update the list of
+        // available sharks.
+        let mut picker = mod_picker::Picker::new();
+        picker.start().map_err(Error::from)?;
+        let picker = Arc::new(picker);
+
+        let assignment_manager = start_assignment_manager(
+            empty_assignment_tx,
+            Arc::clone(&job_action),
+            Arc::clone(&picker),
+        )?;
+
+        // At this point the rebalance job is running and we are blocked at
+        // the assignment_manager thread join.
+        assignment_manager
+            .join()
+            .unwrap()
+            .expect("Error joining assignment generator thread");
+
+        picker.fini();
+
+        sharkspotter_thread.join().unwrap().unwrap_or_else(|e| {
+            error!("Error joining sharkspotter handle: {}\n", e);
+            std::process::exit(1);
+        });
+
+        generator_thread
+            .join()
+            .unwrap()
+            .expect("Error joining assignment generator thread");
+
+        post_thread
+            .join()
+            .unwrap()
+            .expect("Error joining assignment processor thread");
+
+        Ok(())
+    }
+
+    /// If a shark is in the Assigned state then it is busy.
+    fn shark_busy(&self, shark: &StorageNode) -> bool {
+        if let Some(eds) = self
+            .dest_shark_list
+            .read()
+            .unwrap()
+            .get(shark.manta_storage_id.as_str())
+        {
+            debug!(
+                "shark '{}' status: {:?}",
+                shark.manta_storage_id, eds.status
+            );
+            return eds.status == DestSharkStatus::Assigned;
+        }
+
+        false
+    }
+
+    /// checks all assigned assignments for their current status from the
+    /// agent returning number of assignments that changed state
+    fn check_assignments(&self) -> Result<u32, Error> {
+        // TODO: This should probably all be handled by the ProcessAssignment
+        // Trait methods.  Somethings that need to be considered here are how
+        // often to poll and if and if so when we should force polling.
+        // Once we have the Zone talking to the Agents we can make
+        // a decision on what exactly to do here.
+
+        debug!("checking assignments");
+        let mut updated_shark_count = 0;
+        let mut assignments = self.assignments.write().unwrap();
+        for (_, assignment) in assignments.iter_mut() {
+            if assignment.state != AssignmentState::Assigned {
+                continue;
+            }
+
+            let _uri = format!(
+                "http://{}/assignment/{}",
+                assignment.dest_shark, assignment.id
+            );
+            // TODO agent: make request to agent "uri" for assignment status
+
+            // update assignment status based on return value
+            // for now just mark as complete
+            assignment.state = AssignmentState::Complete;
+
+            // update shark status
+            if let Some(dest_shark) = self
+                .dest_shark_list
+                .write()
+                .unwrap()
+                .get_mut(assignment.dest_shark.as_str())
+            {
+                debug!(
+                    "Updating shark '{}' to Ready state",
+                    assignment.dest_shark.as_str()
+                );
+                dest_shark.status = DestSharkStatus::Ready;
+                updated_shark_count += 1;
+            } else {
+                warn!(
+                    "Could not find shark: '{}'",
+                    assignment.dest_shark.as_str()
+                );
+            }
+
+            // post process Assignment by updating objects in persistent store
+            // this could be it's own thread
+            // TODO metadata: for now just mark them as post processed
+            assignment.state = AssignmentState::PostProcessed;
+        }
+        Ok(updated_shark_count)
+    }
+
+    /// Iterate over a new set of storage nodes and update our destination
+    /// shark list accordingly.  This may need to change so that we update
+    /// available_mb more judiciously (i.e. based on timestamp).
+    fn update_dest_sharks(&self, new_sharks: &[StorageNode]) {
+        let mut dest_shark_list = self.dest_shark_list.write().unwrap();
+        for sn in new_sharks.iter() {
+            if let Some(dest_shark) =
+                dest_shark_list.get_mut(sn.manta_storage_id.as_str())
+            {
+                if dest_shark.status == DestSharkStatus::Ready {
+                    dest_shark.shark.available_mb = sn.available_mb;
+                }
+            } else {
+                // create new dest shark and add it to the hash
+                let new_shark = EvacuateDestShark {
+                    shark: sn.to_owned(),
+                    status: DestSharkStatus::Init,
+                };
+                debug!("Adding new destination shark {:?} ", new_shark);
+                dest_shark_list.insert(sn.manta_storage_id.clone(), new_shark);
+            }
+        }
+
+        // Walk the list of our destination sharks, if it doesn't exist in
+        // new_sharks Vec then remove it from the hash.  Perhaps a pre-walk
+        // of marking every dest_shark dirty and then a post walk
+        // marking each found shark as clean, and removing all dirty sharks
+        // would be more efficient.
+        *dest_shark_list = dest_shark_list
+            .iter()
+            .filter(|&(ds, _)| {
+                new_sharks.iter().any(|s| &s.manta_storage_id == ds)
+            })
+            .map(|(k, v)| (k.clone(), v.clone()))
+            .collect();
+    }
+
+    // TODO: Consider doing batched inserts: MANTA-4464.
+    fn insert_into_db(&self, obj: &EvacuateObject) -> usize {
+        use self::evacuateobjects::dsl::*;
+
+        let insertable = obj.to_insertable();
+        let locked_conn = self.conn.lock().unwrap();
+        let now = std::time::Instant::now();
+
+        // TODO: Is panic the right thing to do here?
+        let ret = diesel::insert_into(evacuateobjects)
+            .values(&insertable)
+            .execute(&*locked_conn)
+            .unwrap_or_else(|e| {
+                let msg = format!("Error inserting object into DB: {}", e);
+                error!("{}", msg);
+                panic!(msg);
+            });
+
+        let mut total_time = self.total_db_time.lock().unwrap();
+        *total_time += now.elapsed().as_millis();
+
+        ret
+    }
+
+    // Insert multiple EvacuateObjects into the database at once.
+    fn insert_many_into_db<V>(&self, vec_objs: V) -> usize
+    where
+        V: Borrow<Vec<EvacuateObject>>,
+    {
+        use self::evacuateobjects::dsl::*;
+
+        let objs = vec_objs.borrow();
+        let insertable_objs: Vec<EvacuateObjectInsertable> =
+            objs.iter().map(|o| o.to_insertable()).collect();
+        let locked_conn = self.conn.lock().unwrap();
+
+        let now = std::time::Instant::now();
+        let ret = diesel::insert_into(evacuateobjects)
+            .values(insertable_objs)
+            .execute(&*locked_conn)
+            .unwrap_or_else(|e| {
+                let msg = format!("Error inserting object into DB: {}", e);
+                error!("{}", msg);
+                panic!(msg);
+            });
+        let mut total_time = self.total_db_time.lock().unwrap();
+        *total_time += now.elapsed().as_millis();
+
+        ret
+    }
+
+    // TODO: Batched update: MANTA-4464
+    fn mark_object_post_processing(&self, obj_id: &str) -> usize {
+        use self::evacuateobjects::dsl::status;
+
+        let insertable = UpdateEvacuateObject { id: obj_id };
+
+        let locked_conn = self.conn.lock().unwrap();
+        diesel::update(&insertable)
+            .set(status.eq(EvacuateObjectStatus::PostProcessing))
+            .execute(&*locked_conn)
+            .unwrap_or_else(|e| {
+                let msg = format!("Error updating object: {} ({})", obj_id, e);
+                error!("{}", msg);
+                panic!(msg);
+            })
+    }
+}
+
+fn assignment_post_success(
+    job_action: &EvacuateJob,
+    mut assignment: Assignment,
+) -> Result<Assignment, Error> {
+    assignment.state = AssignmentState::Assigned;
+    let mut assignments = match job_action.assignments.write() {
+        Ok(a) => a,
+        Err(e) => {
+            let msg = format!("Error locking assignments Hash: {}", e);
+            error!("{}", &msg);
+
+            return Err(InternalError::new(
+                Some(InternalErrorCode::LockError),
+                msg,
+            )
+            .into());
+        }
+    };
+    assignments.insert(assignment.id.clone(), assignment.clone());
+
+    Ok(assignment)
+}
+
+impl PostAssignment for EvacuateJob {
+    fn post(&self, assignment: Assignment) -> Result<(), Error> {
+        // TODO agent: Send assignment to agent
+
+        match assignment_post_success(self, assignment) {
+            Ok(_) => Ok(()),
+            Err(e) => Err(e),
+        }
+    }
+}
+
+impl ProcessAssignment for EvacuateJob {
+    fn process(&self, returned_assignment: Bytes) -> Result<(), Error> {
+        // TODO: dont unwrap throughout
+
+        let assignment_u8: &[u8] = &returned_assignment;
+        let agent_assignment: AgentAssignment =
+            serde_json::from_slice(assignment_u8).unwrap();
+        let uuid = &agent_assignment.uuid;
+
+        let mut assignments = self.assignments.write().unwrap();
+
+        // std::option::NoneError is still nightly-only experimental
+        let assignment = match assignments.get_mut(uuid) {
+            Some(a) => a,
+            None => {
+                let msg = format!(
+                    "Error getting assignment.  Couldn't find \
+                     assignment {} in {} assignments.",
+                    uuid,
+                    assignments.len()
+                );
+
+                error!("{}", &msg);
+
+                return Err(InternalError::new(
+                    Some(InternalErrorCode::AssignmentLookupError),
+                    msg,
+                )
+                .into());
+            }
+        };
+
+        debug!(
+            "Checking agent assignment state: {:#?}",
+            &agent_assignment.stats.state
+        );
+
+        match agent_assignment.stats.state {
+            AgentAssignmentState::Scheduled | AgentAssignmentState::Running => {
+                return Ok(());
+            }
+            AgentAssignmentState::Complete(None) => {
+                // mark all EvacuateObjects with this assignment id as
+                // successful
+
+                for (id, _) in assignment.tasks.iter() {
+                    self.mark_object_post_processing(id);
+                }
+            }
+            AgentAssignmentState::Complete(Some(failed_tasks)) => {
+                dbg!(&failed_tasks);
+                // TODO
+                // 1. mark all EvacuateObjects from failed tasks as needs retry
+                // 2. mark all other EvacuateObjects with this assignment_id
+                // as successful
+            }
+        }
+
+        Ok(())
+    }
+}
+
+/// Start the sharkspotter thread and feed the objects into the assignment
+/// thread.  If the assignment thread (the rx side of the channel) exits
+/// prematurely the sender.send() method will return a SenderError and that
+/// needs to be handled properly.
+fn start_sharkspotter(
+    sender: crossbeam::Sender<MantaObject>,
+    domain: &str,
+    job_action: Arc<EvacuateJob>,
+    min_shard: u32,
+    max_shard: u32,
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
+    let shark = &job_action.from_shark.manta_storage_id;
+    let config = sharkspotter::config::Config {
+        domain: String::from(domain),
+        min_shard,
+        max_shard,
+        shark: String::from(shark.as_str()),
+        ..Default::default()
+    };
+
+    debug!("Starting sharkspotter thread: {:?}", &config);
+
+    let plain = slog_term::PlainSyncDecorator::new(std::io::stdout());
+    let log = Logger::root(
+        Mutex::new(slog_term::FullFormat::new(plain).build()).fuse(),
+        o!("build-id" => "0.1.0"),
+    );
+
+    thread::Builder::new()
+        .name(String::from("sharkspotter"))
+        .spawn(move || {
+            let mut count = 0;
+            sharkspotter::run(&config, log, move |obj, _shard| {
+                // while testing, limit the number of objects processed for now
+                count += 1;
+                if count > 2000 {
+                    return Err(std::io::Error::new(
+                        ErrorKind::Other,
+                        "Just stop already",
+                    ));
+                }
+
+                // TODO: add shard number?
+                sender.send(obj).map_err(CrossbeamError::from).map_err(|e| {
+                    std::io::Error::new(ErrorKind::Other, e.description())
+                })
+            })
+            .map_err(Error::from)
+        })
+        .map_err(Error::from)
+}
+
+/// The assignment manager manages the destination sharks and
+/// posts assignments to the remora agents running on the destination sharks.
+/// Given a set of sharks that meet a set of parameters outlined by the
+/// configuration the assignment manager
+///     1. Initializes a new assignment with certain destination shark
+///     specific the parameters.
+///     2. Passes that assignment to the assignment generator thread which
+///     adds tasks and sends the assignment back to this thread.
+///     3. Post the assignment to the remora agent on the destination shark.
+///
+/// In the future another thread may be created to handle step 3.
+///
+/// Restrictions:
+/// * Only 1 outstanding assignment per storage node (could change this in
+/// the future, or make it tunable)
+/// * If all storage ndoes with availableMb > Some TBD threshold have an
+/// outstanding assignment, sleep/wait for an assignment to complete.
+fn start_assignment_manager<S>(
+    empty_assignment_tx: crossbeam::Sender<Assignment>,
+    job_action: Arc<EvacuateJob>,
+    picker: Arc<S>,
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error>
+where
+    S: SharkSource + 'static,
+{
+    let builder = thread::Builder::new();
+
+    builder
+        .name(String::from("assignment_manager"))
+        .spawn(move || {
+            let from_shark_datacenter =
+                job_action.from_shark.datacenter.to_owned();
+            let mut shark_index = 0;
+            let algo = mod_picker::DefaultPickerAlgorithm {
+                min_avail_mb: job_action.min_avail_mb,
+                blacklist: vec![from_shark_datacenter],
+            };
+
+            let mut valid_sharks = vec![];
+            let mut shark_list = vec![];
+
+            loop {
+                // TODO: allow for premature cancellation
+                trace!("shark index: {}", shark_index);
+                if valid_sharks.is_empty()
+                    || shark_index
+                        >= job_action.dest_shark_list.read().unwrap().len()
+                {
+                    shark_index = 0;
+
+                    // Check on assignments and update sharks accordingly
+                    job_action.check_assignments()?;
+
+                    // Check for a new picker snapshot
+                    valid_sharks = match picker
+                        .choose(&mod_picker::PickerAlgorithm::Default(&algo))
+                    {
+                        Some(sharks) => sharks,
+                        None => {
+                            if valid_sharks.is_empty() {
+                                return Err(InternalError::new(
+                                    Some(InternalErrorCode::PickerError),
+                                    "No valid sharks available.",
+                                )
+                                .into());
+                            }
+                            valid_sharks
+                        }
+                    };
+
+                    // update destination shark list
+                    // TODO: perhaps this should be a BTreeMap or just a vec.
+                    job_action.update_dest_sharks(&valid_sharks);
+
+                    // TODO: Think about this a bit more.  On one hand making
+                    // a 1 time copy and cycling through the whole list makes
+                    // sense if we want to update the dest_shark_list while
+                    // iterating over existing sharks.  On the other hand it
+                    // doesn't seem like we would need to update the list of
+                    // sharks except when we enter this block, so we could
+                    // take the reader lock for each iteration and only take
+                    // the writer lock inside the job_action methods called
+                    // above.
+                    shark_list = job_action
+                        .dest_shark_list
+                        .read()
+                        .unwrap()
+                        .values()
+                        .map(|v| v.shark.to_owned())
+                        .collect();
+
+                    shark_list.sort_by_key(|s| s.available_mb);
+                }
+
+                let cur_shark = &shark_list[shark_index];
+
+                shark_index += 1;
+
+                if job_action.shark_busy(cur_shark) {
+                    info!(
+                        "Shark '{}' is busy, trying next shark.",
+                        cur_shark.manta_storage_id
+                    );
+                    continue;
+                }
+
+                // Only use half of the available space per shark per assignment
+                let assignment = Assignment {
+                    id: Uuid::new_v4().to_string(),
+                    dest_shark: cur_shark.manta_storage_id.clone(),
+                    max_size: cur_shark.available_mb / 2,
+                    total_size: 0,
+                    tasks: HashMap::new(),
+                    state: AssignmentState::Init,
+                };
+
+                match empty_assignment_tx.send(assignment) {
+                    Ok(()) => (),
+                    Err(e) => {
+                        error!("{}", CrossbeamError::from(e));
+                        break;
+                    }
+                }
+            }
+            Ok(())
+        })
+        .map_err(Error::from)
+}
+
+/// Assignment Generation:
+/// 1. Get snapshot from picker
+/// 2. Get initialized assignment from assignment manager thread.
+/// 3. Fill out assignment with tasks according to the parameters outlined
+/// in the assignment template received.
+/// 4. Send filled out assignment back to assignment manager thread.
+fn start_assignment_generator(
+    obj_rx: crossbeam::Receiver<MantaObject>,
+    empty_assignment_rx: crossbeam::Receiver<Assignment>,
+    full_assignment_tx: crossbeam::Sender<Assignment>,
+    job_action: Arc<EvacuateJob>,
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
+    let mut eobj: EvacuateObject = EvacuateObject::default();
+    let max_tasks = job_action.max_tasks_per_assignment;
+    let from_shark_host = job_action.from_shark.manta_storage_id.clone();
+
+    let builder = thread::Builder::new();
+    builder
+        .name(String::from("assignment_generator"))
+        .spawn(move || {
+            'assignment: loop {
+                let mut assignment = match empty_assignment_rx.recv() {
+                    Ok(assignment) => assignment,
+                    Err(_) => break 'assignment,
+                };
+
+                let mut available_space = assignment.max_size;
+                let mut eobj_vec: Vec<EvacuateObject> = vec![];
+
+                debug!(
+                    "Filling up new assignment with max_tasks: {:#?}, \
+                     and available_space: {}",
+                    &max_tasks, &available_space
+                );
+
+                'task: while {
+                    let mut cont = true;
+
+                    // If we have exceeded the per shark number of tasks then
+                    // move on.  If max tasks is not specified then we continue
+                    // to fill it up.
+                    if let Some(max_tasks) = max_tasks {
+                        if assignment.tasks.len() > (max_tasks - 1) as usize {
+                            cont = false;
+                        } else {
+                            cont = true;
+                        }
+                    }
+
+                    cont
+                } {
+                    eobj = match obj_rx.recv() {
+                        Ok(obj) => {
+                            trace!("Received object {:#?}", &obj);
+                            EvacuateObject::new(obj)
+                        }
+                        Err(e) => {
+                            error!("Error receiving object {}\n", e);
+
+                            // There are no new objects left, post the
+                            // current assignment and break out of the
+                            // assignment loop.
+                            if !assignment.tasks.is_empty() {
+                                match full_assignment_tx
+                                    .send(assignment)
+                                    .map_err(CrossbeamError::from)
+                                {
+                                    Ok(()) => (),
+                                    Err(err) => {
+                                        return Err(InternalError::new(
+                                            Some(InternalErrorCode::Crossbeam),
+                                            err.description(),
+                                        )
+                                        .into());
+                                    }
+                                }
+                            }
+                            break 'assignment;
+                        }
+                    };
+
+                    let content_mb = eobj.object.content_length / (1024 * 1024);
+                    if content_mb > available_space {
+                        eobj.status = EvacuateObjectStatus::Skipped;
+                        info!(
+                            "Skipping object, need: {}, available: {} | {:?}\n",
+                            content_mb, available_space, eobj
+                        );
+                        job_action.insert_into_db(&eobj);
+
+                        break 'task;
+                    }
+
+                    let obj = &eobj.object;
+
+                    let obj_not_on_dest = obj
+                        .sharks
+                        .iter()
+                        .find(|s| s.manta_storage_id == assignment.dest_shark)
+                        .is_none();
+
+                    // We've found the object on the destination shark.  We will
+                    // need to skip this object for now and find a destination
+                    // for it later.  If we don't do this check it would
+                    // essentially reduce the durability level of the object.
+                    if !obj_not_on_dest {
+                        info!(
+                            "Skipping object already on dest shark {}",
+                            &obj.object_id
+                        );
+                        // TODO sqlite: put skipped object in persistent store.
+                        eobj.status = EvacuateObjectStatus::Skipped;
+                        job_action.insert_into_db(&eobj);
+                        continue;
+                    }
+
+                    // pick source shark
+                    let source = match obj
+                        .sharks
+                        .iter()
+                        .find(|s| s.manta_storage_id != from_shark_host)
+                    {
+                        Some(src) => src,
+                        None => {
+                            eobj.status = EvacuateObjectStatus::Skipped;
+                            job_action.insert_into_db(&eobj);
+                            continue;
+                        }
+                    };
+
+                    assignment.tasks.insert(
+                        obj.object_id.to_owned(),
+                        Task {
+                            object_id: obj.object_id.to_owned(),
+                            owner: obj.owner.to_owned(),
+                            md5sum: obj.content_md5.to_owned(),
+                            source: source.to_owned(),
+                            status: TaskStatus::Pending,
+                        },
+                    );
+
+                    available_space -= content_mb;
+
+                    trace!(
+                        "Available space: {} | Tasks: {}",
+                        &available_space,
+                        &assignment.tasks.len()
+                    );
+
+                    eobj.status = EvacuateObjectStatus::Processing;
+                    eobj_vec.push(eobj.clone());
+                } // end task loop
+
+                info!(
+                    "sending assignment to processor thread: {:?}",
+                    &assignment
+                );
+
+                job_action.insert_many_into_db(&eobj_vec);
+
+                full_assignment_tx.send(assignment).map_err(|e| {
+                    error!("Error sending assignment back to manager: {}", e);
+
+                    InternalError::new(
+                        Some(InternalErrorCode::Crossbeam),
+                        CrossbeamError::from(e).description(),
+                    )
+                })?;
+            } // end assignment loop
+
+            Ok(())
+        })
+        .map_err(Error::from)
+}
+
+fn assignment_post<T>(
+    assign_rx: crossbeam::Receiver<Assignment>,
+    job_action: Arc<T>,
+) -> Result<(), Error>
+where
+    T: PostAssignment,
+{
+    loop {
+        match assign_rx.recv() {
+            Ok(assignment) => {
+                {
+                    // TODO: update shark with space avail?
+
+                    info!(
+                        "Posting Assignment: {}\n",
+                        serde_json::to_string(&assignment).unwrap()
+                    );
+
+                    job_action.post(assignment)?;
+
+                    // TODO sqlite: put assignment into persistent store?
+                    // Currently considering allowing the assignment to be
+                    // transient and only keep EvacuateObjects in persistent
+                    // store.
+                }
+            }
+            Err(err) => {
+                return Err(InternalError::new(
+                    Some(InternalErrorCode::Crossbeam),
+                    err.description(),
+                )
+                .into());
+            }
+        }
+    }
+}
+
+fn start_assignment_post(
+    assign_rx: crossbeam::Receiver<Assignment>,
+    job_action: Arc<EvacuateJob>,
+) -> Result<thread::JoinHandle<Result<(), Error>>, Error> {
+    let builder = thread::Builder::new();
+
+    builder
+        .name(String::from("assignment_poster"))
+        .spawn(move || assignment_post(assign_rx, job_action))
+        .map_err(Error::from)
+}
+
+trait PostAssignment: Sync + Send {
+    fn post(&self, assignment: Assignment) -> Result<(), Error>;
+}
+
+pub trait ProcessAssignment: Sync + Send {
+    fn process(&self, assignment: Bytes) -> Result<(), Error>;
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::agent::AgentAssignmentStats;
+    use crate::picker::PickerAlgorithm;
+    use crate::util;
+    use quickcheck::{Arbitrary, StdThreadGen};
+    use rand::Rng;
+
+    fn zone_assignment_to_agent(assign: &Assignment) -> AgentAssignment {
+        AgentAssignment {
+            uuid: assign.id.clone(),
+            stats: AgentAssignmentStats {
+                state: match assign.state {
+                    AssignmentState::Init => AgentAssignmentState::Scheduled,
+                    AssignmentState::Assigned
+                    | AssignmentState::Complete
+                    | AssignmentState::Rejected
+                    | AssignmentState::PostProcessed => {
+                        AgentAssignmentState::Complete(None)
+                    }
+                },
+                failed: 0,
+                complete: 0,
+                total: 0,
+            },
+            tasks: vec![crate::jobs::Task::default()],
+        }
+    }
+
+    fn generate_sharks(num_sharks: u8) -> Vec<StorageNode> {
+        let mut rng = rand::thread_rng();
+        let mut ret = vec![];
+
+        for _ in 0..num_sharks {
+            let percent_used: u8 = rng.gen_range(0, 101);
+            let timestamp: u64 = rng.gen();
+            let available_mb: u64 = rng.gen();
+            let filesystem: String = util::random_string(rng.gen_range(1, 20));
+            let datacenter: String = util::random_string(rng.gen_range(1, 20));
+            let manta_storage_id: String =
+                format!("{}.stor.joyent.us", rng.gen_range(1, 100));
+
+            ret.push(StorageNode {
+                available_mb,
+                percent_used,
+                filesystem,
+                datacenter,
+                manta_storage_id,
+                timestamp,
+            });
+        }
+        ret
+    }
+
+    struct MockPicker;
+
+    impl MockPicker {
+        fn new() -> Self {
+            MockPicker {}
+        }
+    }
+
+    impl SharkSource for MockPicker {
+        fn choose(&self, _: &PickerAlgorithm) -> Option<Vec<StorageNode>> {
+            let mut rng = rand::thread_rng();
+            let random = rng.gen_range(0, 10);
+
+            if random == 0 {
+                return None;
+            }
+
+            Some(generate_sharks(random))
+        }
+    }
+
+    #[derive(Default)]
+    struct EmptyPicker {}
+    impl SharkSource for EmptyPicker {
+        fn choose(&self, _algo: &PickerAlgorithm) -> Option<Vec<StorageNode>> {
+            None
+        }
+    }
+
+    #[test]
+    fn empty_picker_test() {
+        let picker = Arc::new(EmptyPicker {});
+        let (empty_assignment_tx, _) = crossbeam::bounded(5);
+
+        let job_action = EvacuateJob::new(
+            String::from("1.stor.joyent.us"),
+            "empty_picker_test.db",
+        );
+        let job_action = Arc::new(job_action);
+
+        let handle = start_assignment_manager(
+            empty_assignment_tx,
+            Arc::clone(&job_action),
+            Arc::clone(&picker),
+        );
+
+        let handle = match handle {
+            Ok(h) => h,
+            Err(e) => {
+                assert_eq!(
+                    true, false,
+                    "Could not start assignment manager {}",
+                    e
+                );
+                return;
+            }
+        };
+
+        let ret = handle.join().unwrap();
+
+        assert_eq!(ret.is_err(), true);
+
+        match ret.unwrap_err() {
+            Error::Internal(e) => {
+                assert_eq!(e.code, InternalErrorCode::PickerError);
+            }
+            _ => {
+                assert_eq!(1, 0, "Incorrect Error Code");
+            }
+        }
+    }
+
+    #[test]
+    fn skip_object_test() {
+        // TODO: add test that includes skipped objects
+    }
+
+    #[test]
+    fn duplicate_object_id_test() {
+        // TODO: add test that includes duplicate object IDs
+    }
+
+    #[test]
+    fn full_test() {
+        pretty_env_logger::init();
+        let now = std::time::Instant::now();
+
+        let picker = MockPicker::new();
+        let picker = Arc::new(picker);
+        let (empty_assignment_tx, empty_assignment_rx) = crossbeam::bounded(5);
+        let (full_assignment_tx, full_assignment_rx) = crossbeam::bounded(5);
+        let (obj_tx, obj_rx) = crossbeam::bounded(5);
+        let (assignment_process_tx, assignment_process_rx) =
+            crossbeam::bounded(20);
+
+        let assignment_process_tx: crossbeam_channel::Sender<Assignment> =
+            assignment_process_tx;
+
+        let assignment_process_rx: crossbeam_channel::Receiver<Assignment> =
+            assignment_process_rx;
+
+        let job_action =
+            EvacuateJob::new(String::from("1.stor.joyent.us"), "full_test.db");
+        let conn = job_action.conn.lock().unwrap();
+        conn.execute(r#"DROP TABLE evacuateobjects"#)
+            .unwrap_or_else(|_| {
+                println!("table exists?");
+                0
+            });
+
+        conn.execute(
+            r#"CREATE TABLE evacuateobjects(
+                id TEXT PRIMARY KEY,
+                object TEXT,
+                assignment_id TEXT,
+                status TEXT CHECK(status IN ('unprocessed', 'processing',
+                'skipped', 'post_processing', 'complete')) NOT NULL
+            );"#,
+        )
+        .unwrap();
+        drop(conn);
+
+        let job_action = Arc::new(job_action);
+
+        let mut test_objects = vec![];
+
+        let mut g = StdThreadGen::new(10);
+        for _ in 0..1000 {
+            let mobj = MantaObject::arbitrary(&mut g);
+            test_objects.push(mobj);
+        }
+
+        let test_objects_copy = test_objects.clone();
+
+        let builder = thread::Builder::new();
+        let obj_generator_th = builder
+            .name(String::from("object_generator_test"))
+            .spawn(move || {
+                for o in test_objects_copy.into_iter() {
+                    match obj_tx.send(o) {
+                        Ok(()) => (),
+                        Err(e) => {
+                            eprintln!(
+                                "Could not send object.  Assignment \
+                                 generator must of shutdown {}.",
+                                e
+                            );
+                            break;
+                        }
+                    }
+                }
+            })
+            .expect("failed to build object generator thread");
+
+        let generator_thread = start_assignment_generator(
+            obj_rx,
+            empty_assignment_rx,
+            full_assignment_tx,
+            Arc::clone(&job_action),
+        )
+        .unwrap();
+
+        let manager_thread = start_assignment_manager(
+            empty_assignment_tx,
+            Arc::clone(&job_action),
+            Arc::clone(&picker),
+        )
+        .unwrap();
+
+        // TODO: When we add a thread to process completed assignments this
+        // will likely have to be refactored.
+        let proc_job_action = Arc::clone(&job_action);
+        let processing_thread = thread::Builder::new()
+            .name(String::from("processor thread"))
+            .spawn(move || {
+                loop {
+                    let ag_assign = match assignment_process_rx.recv() {
+                        Ok(assignment) => {
+                            println!("Received Assignment: {}", assignment.id);
+
+                            // This is a little hacky.  We want to mock up the
+                            // post action of the JobAction but we also want to
+                            // make sure the assignment is inserted into the
+                            // correct Job Action's outstanding assignments.  So
+                            // either we factor out all the EvacuateJob's
+                            // methods and call them from the MockJobAction, or
+                            // we do this.  Maybe there's another more rust-ish way?
+                            let new_assignment = match assignment_post_success(
+                                &proc_job_action,
+                                assignment,
+                            ) {
+                                Ok(a) => a,
+                                Err(e) => {
+                                    panic!("Error {}", e);
+                                }
+                            };
+
+                            zone_assignment_to_agent(&new_assignment)
+                        }
+                        Err(e) => {
+                            eprintln!("Error receiving assignment: {}", e);
+                            break;
+                        }
+                    };
+
+                    let assign_vec = serde_json::to_vec(&ag_assign)
+                        .unwrap_or_else(|e| {
+                            eprintln!(
+                                "Error convering assignment to bytes {}",
+                                e
+                            );
+                            panic!("Error");
+                        });
+                    let assign_u8 = Bytes::from(assign_vec);
+
+                    assert!(proc_job_action.process(assign_u8).is_ok());
+                }
+                println!("Processor thread complete");
+            })
+            .unwrap();
+
+        struct MockJobAction {
+            objects: Vec<MantaObject>,
+            process_tx: crossbeam_channel::Sender<Assignment>,
+        }
+
+        impl PostAssignment for MockJobAction {
+            fn post(&self, assignment: Assignment) -> Result<(), Error> {
+                for (_, t) in assignment.tasks.iter() {
+                    assert!(
+                        self.objects
+                            .iter()
+                            .any(|o| { t.object_id == o.object_id }),
+                        "Missing {} from objects",
+                        t.object_id
+                    );
+                }
+                println!("{:?}", assignment.tasks.len());
+                println!("sending assignment {:?}", assignment.id);
+
+                // Normally we'd just send this to the Agent, but instead we
+                // send it directly to the process assignment thread which
+                // handles updating the state of the object as well as the
+                // metadata updates.
+                match self.process_tx.send(assignment) {
+                    Ok(()) => (),
+                    Err(e) => {
+                        eprintln!("Error sending {}", e);
+                    }
+                }
+
+                Ok(())
+            }
+        }
+
+        let mock_job_action = Arc::clone(&Arc::new(MockJobAction {
+            objects: test_objects,
+            process_tx: assignment_process_tx,
+        }));
+
+        match assignment_post(full_assignment_rx, mock_job_action) {
+            Ok(()) => (),
+            Err(_) => println!("Done"),
+        };
+
+        obj_generator_th.join().unwrap();
+
+        match manager_thread.join().unwrap() {
+            Ok(()) => (),
+            Err(e) => {
+                if let Error::Internal(err) = e {
+                    if err.code == InternalErrorCode::PickerError {
+                        eprintln!("Enountered empty picker on startup, exiting safely");
+                    } else {
+                        panic!("error {}", err);
+                    }
+                } else {
+                    panic!("error {}", e);
+                }
+            }
+        }
+
+        generator_thread
+            .join()
+            .unwrap()
+            .expect("Error joining assignment generator thread");
+
+        processing_thread
+            .join()
+            .expect("Error joining processing thread");
+
+        debug!("TOTAL TIME: {}ms", now.elapsed().as_millis());
+        debug!(
+            "TOTAL INSERT DB TIME: {}ms",
+            job_action.total_db_time.lock().unwrap()
+        );
+    }
+}
diff --git a/src/jobs/mod.rs b/src/jobs/mod.rs
new file mode 100644
index 0000000..a56de25
--- /dev/null
+++ b/src/jobs/mod.rs
@@ -0,0 +1,168 @@
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
+
+pub mod evacuate;
+
+use crate::config::Config;
+use crate::error::Error;
+
+use std::collections::HashMap;
+use std::fmt;
+
+use evacuate::EvacuateJob;
+use libmanta::moray::MantaObjectShark;
+use serde::{Deserialize, Serialize};
+use uuid::Uuid;
+
+pub type StorageId = String; // Hostname
+pub type AssignmentId = String; // UUID
+pub type ObjectId = String; // UUID
+
+pub struct Job {
+    id: Uuid,
+    action: JobAction,
+    state: JobState,
+    config: Config,
+}
+
+#[derive(Debug, Clone)]
+pub enum JobState {
+    Init,
+    Setup,
+    Running,
+    Stopped,
+    Complete,
+    Failed,
+}
+
+pub enum JobAction {
+    Evacuate(Box<EvacuateJob>),
+    None,
+}
+
+impl fmt::Debug for Job {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        let action_str = match &self.action {
+            JobAction::Evacuate(ej) => format!(
+                "EvacuateJob: {{ dest_shark_list: {:#?}, \
+                 assignments: {:#?}, \
+                 from_shark: {:#?}, \
+                 min_avail_mb: {:#?}, \
+                 max_tasks_per_assignment: {:#?}, \
+                 }}",
+                ej.dest_shark_list,
+                ej.assignments,
+                ej.from_shark,
+                ej.min_avail_mb,
+                ej.max_tasks_per_assignment
+            ),
+            _ => String::new(),
+        };
+
+        write!(
+            f,
+            "Job {{ id: {}, action: {}, state: {:#?}, config: {:#?} }}",
+            self.id, action_str, self.state, self.config
+        )
+    }
+}
+
+#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
+enum AssignmentState {
+    Init,
+    Assigned,
+    Rejected,
+    Complete,
+    PostProcessed,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct Assignment {
+    id: String,
+    dest_shark: StorageId,
+    tasks: HashMap<ObjectId, Task>,
+    max_size: u64,
+    total_size: u64,
+    state: AssignmentState,
+}
+
+#[derive(Debug, Clone, Default, Serialize, Deserialize)]
+pub struct Task {
+    pub object_id: String, // or Uuid
+    pub owner: String,     // or Uuid
+    pub md5sum: String,
+    pub source: MantaObjectShark,
+
+    #[serde(default = "TaskStatus::default")]
+    pub status: TaskStatus,
+}
+
+impl Task {
+    pub fn set_status(&mut self, status: TaskStatus) {
+        self.status = status;
+    }
+}
+
+#[derive(Clone, Serialize, Deserialize, Debug)]
+pub enum TaskStatus {
+    Pending,
+    Running,
+    Complete,
+    Failed(String),
+}
+
+impl Default for TaskStatus {
+    fn default() -> Self {
+        TaskStatus::Pending
+    }
+}
+
+impl Default for Job {
+    fn default() -> Self {
+        Self {
+            action: JobAction::default(),
+            state: JobState::default(),
+            id: Uuid::new_v4(),
+            config: Config::default(),
+        }
+    }
+}
+
+impl Job {
+    pub fn new(action: JobAction, config: Config) -> Self {
+        Job {
+            action,
+            config,
+            ..Default::default()
+        }
+    }
+
+    // The goal here is to eventually have a run method for all JobActions.
+    pub fn run(self) -> Result<(), Error> {
+        debug!("Starting job {:#?}", &self);
+        println!("Starting Job: {}", &self.id);
+        match self.action {
+            JobAction::Evacuate(job_action) => job_action.run(&self.config),
+            _ => Ok(()),
+        }
+    }
+}
+
+impl Default for JobAction {
+    fn default() -> Self {
+        JobAction::None
+    }
+}
+
+impl Default for JobState {
+    fn default() -> Self {
+        JobState::Init
+    }
+}
diff --git a/src/lib.rs b/src/lib.rs
index dda0567..aba43e0 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -1,11 +1,28 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
+
+/// Manta Object Rebalancer
 
 #[macro_use]
 extern crate log;
 
+#[macro_use]
+extern crate diesel;
+
+#[macro_use]
+extern crate diesel_derive_enum;
+
+pub mod jobs;
+//pub mod agent;
 pub mod agent;
 pub mod config;
 pub mod error;
-pub mod job;
-mod picker;
-mod util;
+pub mod picker;
+pub mod util;
diff --git a/src/main.rs b/src/main.rs
index 506fae2..486507e 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -1,4 +1,12 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
 
 use remora::agent::Agent;
 use remora::config::{Command, SubCommand};
diff --git a/src/picker.rs b/src/picker.rs
index f305662..58e7b77 100644
--- a/src/picker.rs
+++ b/src/picker.rs
@@ -1,8 +1,16 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
 
 use crate::error::Error;
 use reqwest;
-use serde::Deserialize;
+use serde::{Deserialize, Serialize};
 use std::collections::HashMap;
 use std::sync::{
     atomic::{AtomicBool, Ordering},
@@ -11,7 +19,7 @@ use std::sync::{
 use std::thread::JoinHandle;
 use std::{thread, time};
 
-#[derive(Debug, Deserialize, Clone)]
+#[derive(Debug, Serialize, Deserialize, Clone)]
 pub struct StorageNode {
     #[serde(alias = "availableMB")]
     pub available_mb: u64,
@@ -41,40 +49,39 @@ pub enum PickerAlgorithm<'a> {
     Default(&'a DefaultPickerAlgorithm),
 }
 
+#[derive(Default)]
 pub struct DefaultPickerAlgorithm {
     pub blacklist: Vec<String>,
     pub min_avail_mb: Option<u64>,
 }
 
 impl<'a> PickerAlgorithm<'a> {
-    fn choose(&self, sharks: Vec<StorageNode>) -> Vec<StorageNode> {
+    fn choose(&self, sharks: &[StorageNode]) -> Vec<StorageNode> {
         match self {
-            PickerAlgorithm::Default(algo) => default_method(algo, &sharks),
+            PickerAlgorithm::Default(algo) => algo.method(sharks),
         }
     }
 }
 
-// TODO: put me somewhere more sensible
-fn default_method(
-    algo: &DefaultPickerAlgorithm,
-    sharks: &[StorageNode],
-) -> Vec<StorageNode> {
-    let mut ret: Vec<StorageNode> = vec![];
-
-    // if the min_avail_mb is not specified or if the sharks available space
-    // is less than min_avail_mb skip it.
-    for s in sharks.iter() {
-        if let Some(min_avail_mb) = algo.min_avail_mb {
-            if algo.blacklist.contains(&s.datacenter)
-                || s.available_mb < min_avail_mb
-            {
-                continue;
+impl DefaultPickerAlgorithm {
+    fn method(&self, sharks: &[StorageNode]) -> Vec<StorageNode> {
+        let mut ret: Vec<StorageNode> = vec![];
+
+        // If the min_avail_mb is specified and the sharks available space is less
+        // than min_avail_mb skip it.
+        for s in sharks.iter() {
+            if let Some(min_avail_mb) = self.min_avail_mb {
+                if self.blacklist.contains(&s.datacenter)
+                    || s.available_mb < min_avail_mb
+                {
+                    continue;
+                }
             }
+            ret.push(s.to_owned())
         }
-        ret.push(s.to_owned())
-    }
 
-    ret
+        ret
+    }
 }
 
 impl Picker {
@@ -108,19 +115,6 @@ impl Picker {
         }
     }
 
-    /// Choose the sharks based on the specified algorithm
-    pub fn choose(&self, algo: &PickerAlgorithm) -> Option<Vec<StorageNode>> {
-        let mut sharks: Vec<StorageNode>;
-
-        if let Some(s) = self.get_sharks() {
-            sharks = s.clone();
-        } else {
-            return None;
-        }
-
-        Some(algo.choose(sharks))
-    }
-
     /// Get the the Vec<sharks> from the picker.
     pub fn get_sharks(&self) -> Option<Vec<StorageNode>> {
         self.sharks.lock().unwrap().take()
@@ -149,6 +143,25 @@ impl Picker {
     }
 }
 
+impl SharkSource for Picker {
+    /// Choose the sharks based on the specified algorithm
+    fn choose(&self, algo: &PickerAlgorithm) -> Option<Vec<StorageNode>> {
+        let mut sharks: Vec<StorageNode>;
+
+        if let Some(s) = self.get_sharks() {
+            sharks = s.clone();
+        } else {
+            return None;
+        }
+
+        Some(algo.choose(&sharks))
+    }
+}
+
+pub trait SharkSource: Sync + Send {
+    fn choose(&self, algo: &PickerAlgorithm) -> Option<Vec<StorageNode>>;
+}
+
 // Use our prototype picker zone for now.  Might change this to a shard 1 moray
 // client in the future.
 fn fetch_sharks() -> Vec<StorageNode> {
diff --git a/src/util.rs b/src/util.rs
index 986b5e5..a52ec3f 100644
--- a/src/util.rs
+++ b/src/util.rs
@@ -1,6 +1,28 @@
-// Copyright 2019 Joyent, Inc.
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright 2019, Joyent, Inc.
+ */
+
+#[cfg(test)]
+use rand::distributions::Alphanumeric;
+#[cfg(test)]
+use rand::Rng;
 
 pub fn shard_host2num(shard_host: &str) -> u32 {
     let shard_split: Vec<&str> = shard_host.split('.').collect();
     shard_split[0].parse().unwrap()
 }
+
+// Used in test
+#[cfg(test)]
+pub fn random_string(len: usize) -> String {
+    rand::thread_rng()
+        .sample_iter(&Alphanumeric)
+        .take(len)
+        .collect()
+}
-- 
2.21.0

