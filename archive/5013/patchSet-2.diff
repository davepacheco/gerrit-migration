commit 167d7fdaa4412b0da4aaa30e28901ae2903e0a81 (refs/changes/13/5013/2)
Author: John Levon <john.levon@joyent.com>
Date:   2018-10-31T12:45:27+00:00 (11 months ago)
    
    OS-7335 atomic ops in syscall_mstate() induce significant overhead

diff --git a/usr/src/uts/common/os/msacct.c b/usr/src/uts/common/os/msacct.c
index 66994321f7..b2297a2b99 100644
--- a/usr/src/uts/common/os/msacct.c
+++ b/usr/src/uts/common/os/msacct.c
@@ -21,7 +21,7 @@
 /*
  * Copyright 2009 Sun Microsystems, Inc.  All rights reserved.
  * Use is subject to license terms.
- * Copyright 2012 Joyent, Inc.  All rights reserved.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 #include <sys/types.h>
@@ -416,16 +416,18 @@ syscall_mstate(int fromms, int toms)
 		newtime = curtime - ms->ms_state_start;
 	}
 	*mstimep += newtime;
-	if (fromms == LMS_USER)
-		atomic_add_64(&z->zone_utime, newtime);
-	else if (fromms == LMS_SYSTEM)
-		atomic_add_64(&z->zone_stime, newtime);
 	t->t_mstate = toms;
 	ms->ms_state_start = curtime;
 	ms->ms_prev = fromms;
 	kpreempt_disable(); /* don't change CPU while changing CPU's state */
 	cpu = CPU;
 	ASSERT(cpu == t->t_cpu);
+
+	if (fromms == LMS_USER)
+		atomic_add_64(&z->zone_utime[cpu->cpu_id], newtime);
+	else if (fromms == LMS_SYSTEM)
+		atomic_add_64(&z->zone_stime[cpu->cpu_id], newtime);
+
 	if ((toms != LMS_USER) && (cpu->cpu_mstate != CMS_SYSTEM)) {
 		NEW_CPU_MSTATE(CMS_SYSTEM);
 	} else if ((toms == LMS_USER) && (cpu->cpu_mstate != CMS_USER)) {
@@ -652,19 +654,6 @@ new_mstate(kthread_t *t, int new_state)
 	} while (atomic_cas_64((uint64_t *)mstimep, oldtime, newtime) !=
 	    oldtime);
 
-	/*
-	 * When the system boots the initial startup thread will have a
-	 * ms_state_start of 0 which would add a huge system time to the global
-	 * zone.  We want to skip aggregating that initial bit of work.
-	 */
-	if (origstart != 0) {
-		z = ttozone(t);
-		if (state == LMS_USER)
-			atomic_add_64(&z->zone_utime, ztime);
-		else if (state == LMS_SYSTEM)
-			atomic_add_64(&z->zone_stime, ztime);
-	}
-
 	/*
 	 * Remember the previous running microstate.
 	 */
@@ -677,6 +666,20 @@ new_mstate(kthread_t *t, int new_state)
 
 	kpreempt_disable(); /* MUST disable kpreempt before touching t->cpu */
 	ASSERT(t->t_cpu == CPU);
+
+	/*
+	 * When the system boots the initial startup thread will have a
+	 * ms_state_start of 0 which would add a huge system time to the global
+	 * zone.  We want to skip aggregating that initial bit of work.
+	 */
+	if (origstart != 0) {
+		z = ttozone(t);
+		if (state == LMS_USER)
+			atomic_add_64(&z->zone_utime[t->t_cpu->cpu_id], ztime);
+		else if (state == LMS_SYSTEM)
+			atomic_add_64(&z->zone_stime[t->t_cpu->cpu_id], ztime);
+	}
+
 	if (!CPU_ON_INTR(t->t_cpu) && curthread->t_intr == NULL) {
 		if (new_state == LMS_USER && t->t_cpu->cpu_mstate != CMS_USER)
 			new_cpu_mstate(CMS_USER, curtime);
@@ -783,7 +786,12 @@ restore_mstate(kthread_t *t)
 	z = ttozone(t);
 	waittime = curtime - waitrq;
 	ms->ms_acct[LMS_WAIT_CPU] += waittime;
-	atomic_add_64(&z->zone_wtime, waittime);
+
+	/*
+	 * We are in a disp context where we're not going to migrate CPUs.
+	 */
+	atomic_add_64(&z->zone_wtime[CPU->cpu_id], waittime);
+
 	CPU->cpu_waitrq += waittime;
 	ms->ms_state_start = curtime;
 }
diff --git a/usr/src/uts/common/os/zone.c b/usr/src/uts/common/os/zone.c
index 42eba20668..3280431708 100644
--- a/usr/src/uts/common/os/zone.c
+++ b/usr/src/uts/common/os/zone.c
@@ -2364,20 +2364,25 @@ zone_misc_kstat_update(kstat_t *ksp, int rw)
 {
 	zone_t *zone = ksp->ks_private;
 	zone_misc_kstat_t *zmp = ksp->ks_data;
-	hrtime_t tmp;
+	hrtime_t stime = 0;
+	hrtime_t utime = 0;
+	hrtime_t wtime = 0;
 
 	if (rw == KSTAT_WRITE)
 		return (EACCES);
 
-	tmp = zone->zone_utime;
-	scalehrtime(&tmp);
-	zmp->zm_utime.value.ui64 = tmp;
-	tmp = zone->zone_stime;
-	scalehrtime(&tmp);
-	zmp->zm_stime.value.ui64 = tmp;
-	tmp = zone->zone_wtime;
-	scalehrtime(&tmp);
-	zmp->zm_wtime.value.ui64 = tmp;
+	for (size_t i = 0; i < NCPU; i++) {
+		stime += zone->zone_stime[i];
+		utime += zone->zone_utime[i];
+		wtime += zone->zone_wtime[i];
+	}
+
+	scalehrtime(&stime);
+	zmp->zm_stime.value.ui64 = stime;
+	scalehrtime(&utime);
+	zmp->zm_utime.value.ui64 = utime;
+	scalehrtime(&wtime);
+	zmp->zm_wtime.value.ui64 = wtime;
 
 	zmp->zm_avenrun1.value.ui32 = zone->zone_avenrun[0];
 	zmp->zm_avenrun5.value.ui32 = zone->zone_avenrun[1];
@@ -2572,9 +2577,6 @@ zone_zsd_init(void)
 	zone0.zone_swapresv_kstat = NULL;
 	zone0.zone_physmem_kstat = NULL;
 	zone0.zone_nprocs_kstat = NULL;
-	zone0.zone_stime = 0;
-	zone0.zone_utime = 0;
-	zone0.zone_wtime = 0;
 
 	zone_pdata[0].zpers_zfsp = &zone0_zp_zfs;
 	zone_pdata[0].zpers_zfsp->zpers_zfs_io_pri = 1;
@@ -2819,6 +2821,10 @@ zone_init(void)
 	 */
 	rw_init(&zone0.zone_mntfs_db_lock, NULL, RW_DEFAULT, NULL);
 
+	zone0.zone_utime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+	zone0.zone_stime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+	zone0.zone_wtime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+
 	mutex_enter(&zonehash_lock);
 	zone_uniqid(&zone0);
 	ASSERT(zone0.zone_uniqid == GLOBAL_ZONEUNIQID);
@@ -2930,6 +2936,10 @@ zone_free(zone_t *zone)
 	zone_status_set(zone, ZONE_IS_FREE);
 	mutex_exit(&zone_status_lock);
 
+	kmem_free(zone->zone_stime, sizeof (uint64_t) * NCPU);
+	kmem_free(zone->zone_utime, sizeof (uint64_t) * NCPU);
+	kmem_free(zone->zone_wtime, sizeof (uint64_t) * NCPU);
+
 	if (zone->zone_rootvp != NULL)
 		VN_RELE(zone->zone_rootvp);
 	if (zone->zone_rootpath)
@@ -3750,12 +3760,12 @@ zone_find_by_path(const char *path)
  * Based on loadavg_update(), genloadavg() and calcloadavg() from clock.c.
  */
 void
-zone_loadavg_update()
+zone_loadavg_update(void)
 {
 	zone_t *zp;
 	zone_status_t status;
 	struct loadavg_s *lavg;
-	hrtime_t zone_total;
+	hrtime_t zone_total = 0;
 	int i;
 	hrtime_t hr_avg;
 	int nrun;
@@ -3780,7 +3790,12 @@ zone_loadavg_update()
 		 */
 		lavg = &zp->zone_loadavg;
 
-		zone_total = zp->zone_utime + zp->zone_stime + zp->zone_wtime;
+		for (i = 0; i < NCPU; i++) {
+			zone_total += zp->zone_utime[i];
+			zone_total += zp->zone_stime[i];
+			zone_total += zp->zone_wtime[i];
+		}
+
 		scalehrtime(&zone_total);
 
 		/* The zone_total should always be increasing. */
@@ -4835,8 +4850,8 @@ zone_set_privset(zone_t *zone, const priv_set_t *zone_privs,
  * Where each element of the nvpair_list_array is of the form:
  *
  * [(name = "privilege", value = RCPRIV_PRIVILEGED),
- * 	(name = "limit", value = uint64_t),
- * 	(name = "action", value = (RCTL_LOCAL_NOACTION || RCTL_LOCAL_DENY))]
+ *	(name = "limit", value = uint64_t),
+ *	(name = "action", value = (RCTL_LOCAL_NOACTION || RCTL_LOCAL_DENY))]
  */
 static int
 parse_rctls(caddr_t ubuf, size_t buflen, nvlist_t **nvlp)
@@ -5131,10 +5146,7 @@ zone_create(const char *zone_name, const char *zone_root,
 	zone->zone_bootargs = NULL;
 	zone->zone_fs_allowed = NULL;
 
-	secflags_zero(&zone0.zone_secflags.psf_lower);
-	secflags_zero(&zone0.zone_secflags.psf_effective);
-	secflags_zero(&zone0.zone_secflags.psf_inherit);
-	secflags_fullset(&zone0.zone_secflags.psf_upper);
+	psecflags_default(&zone->zone_secflags);
 
 	zone->zone_initname =
 	    kmem_alloc(strlen(zone_default_initname) + 1, KM_SLEEP);
@@ -5157,6 +5169,10 @@ zone_create(const char *zone_name, const char *zone_root,
 	    kmem_zalloc(sizeof (zone_zfs_io_t), KM_SLEEP);
 	zone_pdata[zoneid].zpers_zfsp->zpers_zfs_io_pri = 1;
 
+	zone->zone_utime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+	zone->zone_stime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+	zone->zone_wtime = kmem_zalloc(sizeof (uint64_t) * NCPU, KM_SLEEP);
+
 	/*
 	 * Zsched initializes the rctls.
 	 */
diff --git a/usr/src/uts/common/sys/zone.h b/usr/src/uts/common/sys/zone.h
index 678dd4e029..36ecfdf475 100644
--- a/usr/src/uts/common/sys/zone.h
+++ b/usr/src/uts/common/sys/zone.h
@@ -429,7 +429,7 @@ typedef struct {
 	kstat_named_t	zv_100ms_ops;
 	kstat_named_t	zv_1s_ops;
 	kstat_named_t	zv_10s_ops;
-	kstat_named_t 	zv_delay_cnt;
+	kstat_named_t	zv_delay_cnt;
 	kstat_named_t	zv_delay_time;
 } zone_vfs_kstat_t;
 
@@ -502,13 +502,13 @@ typedef struct zone {
 					/* if not emulated */
 	/*
 	 * zone_lock protects the following fields of a zone_t:
-	 * 	zone_ref
-	 * 	zone_cred_ref
-	 * 	zone_subsys_ref
-	 * 	zone_ref_list
-	 * 	zone_ntasks
-	 * 	zone_flags
-	 * 	zone_zsd
+	 *	zone_ref
+	 *	zone_cred_ref
+	 *	zone_subsys_ref
+	 *	zone_ref_list
+	 *	zone_ntasks
+	 *	zone_flags
+	 *	zone_zsd
 	 *	zone_pfexecd
 	 */
 	kmutex_t	zone_lock;
@@ -616,7 +616,7 @@ typedef struct zone {
 	boolean_t	zone_restart_init_0;	/* Restart only if it exits 0 */
 	boolean_t	zone_setup_app_contract; /* setup contract? */
 	struct brand	*zone_brand;		/* zone's brand */
-	void 		*zone_brand_data;	/* store brand specific data */
+	void		*zone_brand_data;	/* store brand specific data */
 	id_t		zone_defaultcid;	/* dflt scheduling class id */
 	boolean_t	zone_fixed_hipri;	/* fixed sched. hi prio */
 	kstat_t		*zone_swapresv_kstat;
@@ -678,22 +678,20 @@ typedef struct zone {
 
 	/*
 	 * Misc. kstats and counters for zone cpu-usage aggregation.
-	 * The zone_Xtime values are the sum of the micro-state accounting
-	 * values for all threads that are running or have run in the zone.
-	 * This is tracked in msacct.c as threads change state.
-	 * The zone_stime is the sum of the LMS_SYSTEM times.
-	 * The zone_utime is the sum of the LMS_USER times.
-	 * The zone_wtime is the sum of the LMS_WAIT_CPU times.
-	 * As with per-thread micro-state accounting values, these values are
-	 * not scaled to nanosecs.  The scaling is done by the
-	 * zone_misc_kstat_update function when kstats are requested.
+	 *
+	 * We track system, user, and wait time in the zone_Xtime arrays. They
+	 * record the unscaled time spent in each of the micro-states for every
+	 * thread in the zone.  We record this per-CPU for scalability reasons.
+	 *
+	 * At collection time (such as zone_misc_kstat_update()), we sum across
+	 * all CPUs, and scale the sum to nanoseconds.
 	 */
 	kmutex_t	zone_misc_lock;		/* protects misc statistics */
 	kstat_t		*zone_misc_ksp;
 	zone_misc_kstat_t *zone_misc_stats;
-	uint64_t	zone_stime;		/* total system time */
-	uint64_t	zone_utime;		/* total user time */
-	uint64_t	zone_wtime;		/* total time waiting in runq */
+	uint64_t	*zone_stime;
+	uint64_t	*zone_utime;
+	uint64_t	*zone_wtime;
 	/* fork-fail kstat tracking */
 	uint32_t	zone_ffcap;		/* hit an rctl cap */
 	uint32_t	zone_ffnoproc;		/* get proc/lwp error */
@@ -825,7 +823,7 @@ typedef uint_t zone_key_t;
 
 extern void	zone_key_create(zone_key_t *, void *(*)(zoneid_t),
     void (*)(zoneid_t, void *), void (*)(zoneid_t, void *));
-extern int 	zone_key_delete(zone_key_t);
+extern int	zone_key_delete(zone_key_t);
 extern void	*zone_getspecific(zone_key_t, zone_t *);
 extern int	zone_setspecific(zone_key_t, zone_t *, const void *);
 
@@ -851,7 +849,7 @@ struct zsd_entry {
 	void			(*zsd_shutdown)(zoneid_t, void *);
 	void			(*zsd_destroy)(zoneid_t, void *);
 	list_node_t		zsd_linkage;
-	uint16_t 		zsd_flags;	/* See below */
+	uint16_t		zsd_flags;	/* See below */
 	kcondvar_t		zsd_cv;
 };
 
