From 3b830bfea25d080d2781a2473ff5d4e8201b32a3 Mon Sep 17 00:00:00 2001
From: Isaac Davis <isaac.davis@joyent.com>
Date: Wed, 3 Apr 2019 22:26:40 +0000
Subject: [PATCH] MANTA-3552 create Triton Prometheus image MANTA-4008 add a
 core Prometheus service to Manta

---
 .eslintrc                                     |   25 +
 .gitignore                                    |    9 +-
 .gitmodules                                   |   12 +
 Makefile                                      |  150 +++
 README.md                                     |  240 +++-
 bin/certgen                                   |  158 +++
 bin/prometheus-configure                      |  396 ++++++
 boot/configure.sh                             |   18 +
 boot/setup.sh                                 |  211 ++++
 deps/eng                                      |    1 +
 deps/manta-scripts                            |    1 +
 deps/prometheus                               |    1 +
 deps/sdc-scripts                              |    1 +
 etc/named.conf.in                             |   63 +
 etc/prometheus.yml.in                         |   32 +
 package.json                                  |   30 +-
 sapi_manifests/prometheus/manifest.json       |    5 +
 sapi_manifests/prometheus/template            |   24 +
 setup-grafana.sh                              |  207 ----
 ...ometheus-prod.sh => setup-prometheus-lx.sh |    0
 setup-prometheus.sh                           |  233 ----
 smf/manifests/prometheus.xml                  |   96 ++
 tools/download_go                             |  126 ++
 tools/mk/Makefile.defs                        |  105 --
 tools/mk/Makefile.deps                        |   87 --
 tools/mk/Makefile.go_prebuilt.defs            |  132 --
 tools/mk/Makefile.go_prebuilt.targ            |   55 -
 tools/mk/Makefile.manpages.defs               |  128 --
 tools/mk/Makefile.manpages.targ               |   28 -
 tools/mk/Makefile.node.defs                   |  110 --
 tools/mk/Makefile.node.targ                   |   42 -
 tools/mk/Makefile.node_modules.defs           |   68 -
 tools/mk/Makefile.node_modules.targ           |   31 -
 tools/mk/Makefile.node_prebuilt.defs          |  159 ---
 tools/mk/Makefile.node_prebuilt.targ          |   42 -
 tools/mk/Makefile.smf.defs                    |   40 -
 tools/mk/Makefile.smf.targ                    |   29 -
 tools/mk/Makefile.targ                        |  345 ------
 tools/obliterate-prometheus-service.sh        |   68 +
 tools/service_bundle.dtd.1                    | 1091 +++++++++++++++++
 40 files changed, 2682 insertions(+), 1917 deletions(-)
 create mode 100644 .eslintrc
 create mode 100644 .gitmodules
 create mode 100644 Makefile
 create mode 100644 bin/certgen
 create mode 100755 bin/prometheus-configure
 create mode 100755 boot/configure.sh
 create mode 100755 boot/setup.sh
 create mode 160000 deps/eng
 create mode 160000 deps/manta-scripts
 create mode 160000 deps/prometheus
 create mode 160000 deps/sdc-scripts
 create mode 100644 etc/named.conf.in
 create mode 100644 etc/prometheus.yml.in
 create mode 100644 sapi_manifests/prometheus/manifest.json
 create mode 100644 sapi_manifests/prometheus/template
 delete mode 100755 setup-grafana.sh
 rename setup-prometheus-prod.sh => setup-prometheus-lx.sh (100%)
 delete mode 100755 setup-prometheus.sh
 create mode 100644 smf/manifests/prometheus.xml
 create mode 100755 tools/download_go
 delete mode 100644 tools/mk/Makefile.defs
 delete mode 100644 tools/mk/Makefile.deps
 delete mode 100644 tools/mk/Makefile.go_prebuilt.defs
 delete mode 100644 tools/mk/Makefile.go_prebuilt.targ
 delete mode 100644 tools/mk/Makefile.manpages.defs
 delete mode 100644 tools/mk/Makefile.manpages.targ
 delete mode 100644 tools/mk/Makefile.node.defs
 delete mode 100644 tools/mk/Makefile.node.targ
 delete mode 100644 tools/mk/Makefile.node_modules.defs
 delete mode 100644 tools/mk/Makefile.node_modules.targ
 delete mode 100644 tools/mk/Makefile.node_prebuilt.defs
 delete mode 100644 tools/mk/Makefile.node_prebuilt.targ
 delete mode 100644 tools/mk/Makefile.smf.defs
 delete mode 100644 tools/mk/Makefile.smf.targ
 delete mode 100644 tools/mk/Makefile.targ
 create mode 100755 tools/obliterate-prometheus-service.sh
 create mode 100644 tools/service_bundle.dtd.1

diff --git a/.eslintrc b/.eslintrc
new file mode 100644
index 0000000..47844b3
--- /dev/null
+++ b/.eslintrc
@@ -0,0 +1,25 @@
+{
+	"plugins": [ "joyent" ],
+	"extends": [
+		"eslint:recommended",
+		"plugin:joyent/style",
+		"plugin:joyent/lint"
+	],
+	"parserOptions": {
+		"ecmaVersion": 6,
+		"sourceType": "script",
+		"ecmaFeatures": {
+		}
+	},
+	"env": {
+		"node": true
+	},
+	"rules": {
+		// Lint:
+		"strict": [ "error", "global" ],
+
+		// Style:
+		"func-style": [ "error", "declaration" ],
+		"multiline-comment-style": [ "error", "starred-block" ]
+	}
+}
diff --git a/.gitignore b/.gitignore
index f089238..058155d 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,5 +1,8 @@
-/tmp
-/node_modules
+/bits
+/build
+/cache
 /make_stamps
+/node_modules
 /npm-debug.log
-/build
+/prometheus-pkg-*.tar.gz
+/tmp
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..c467938
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,12 @@
+[submodule "deps/prometheus"]
+	path = deps/prometheus
+	url = https://github.com/joyent/prometheus.git
+[submodule "deps/sdc-scripts"]
+	path = deps/sdc-scripts
+	url = https://github.com/joyent/sdc-scripts.git
+[submodule "deps/manta-scripts"]
+	path = deps/manta-scripts
+	url = https://github.com/joyent/manta-scripts.git
+[submodule "deps/eng"]
+	path = deps/eng
+	url = https://github.com/joyent/eng.git
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..eb464bb
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,150 @@
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2019, Joyent, Inc.
+#
+
+NAME = prometheus
+
+GO_PREBUILT_VERSION = 1.10.3
+NODE_PREBUILT_VERSION = v6.15.1
+ifeq ($(shell uname -s),SunOS)
+    NODE_PREBUILT_TAG=zone
+    # Allow building on other than sdc-minimal-multiarch-lts@15.4.1
+    NODE_PREBUILT_IMAGE=18b094b0-eb01-11e5-80c1-175dac7ddf02
+endif
+
+ENGBLD_USE_BUILDIMAGE = true
+ENGBLD_REQUIRE := $(shell git submodule update --init deps/eng)
+include ./deps/eng/tools/mk/Makefile.defs
+TOP ?= $(error Unable to access eng.git submodule Makefiles.)
+
+include ./deps/eng/tools/mk/Makefile.smf.defs
+ifeq ($(shell uname -s),SunOS)
+    include ./deps/eng/tools/mk/Makefile.go_prebuilt.defs
+    include ./deps/eng/tools/mk/Makefile.node_prebuilt.defs
+    include ./deps/eng/tools/mk/Makefile.agent_prebuilt.defs
+endif
+
+# triton-origin-multiarch-18.1.0
+BASE_IMAGE_UUID = b6ea7cb4-6b90-48c0-99e7-1d34c2895248
+BUILDIMAGE_NAME = manta-$(NAME)
+BUILDIMAGE_PKGSRC = bind-9.10.7
+BUILDIMAGE_DESC = Triton/Manta Prometheus
+AGENTS = amon config registrar
+
+RELEASE_TARBALL := $(NAME)-pkg-$(STAMP).tar.gz
+RELSTAGEDIR := /tmp/$(NAME)-$(STAMP)
+
+SMF_MANIFESTS = smf/manifests/prometheus.xml
+
+JS_FILES := $(TOP)/bin/certgen
+ESLINT_FILES := $(JS_FILES)
+STAMP_CERTGEN := $(MAKE_STAMPS_DIR)/certgen
+
+PROMETHEUS_IMPORT = github.com/prometheus/prometheus
+PROMETHEUS_GO_DIR = $(GO_GOPATH)/src/$(PROMETHEUS_IMPORT)
+PROMETHEUS_EXEC = $(PROMETHEUS_GO_DIR)/prometheus
+
+#
+# Repo-specific targets
+#
+.PHONY: all
+all: $(PROMETHEUS_EXEC) $(STAMP_CERTGEN) sdc-scripts manta-scripts
+
+#
+# Link the "prometheus" submodule into the correct place within our
+# project-local GOPATH, then build the binary.
+#
+$(PROMETHEUS_EXEC): deps/prometheus/.git $(STAMP_GO_TOOLCHAIN)
+	$(GO) version
+	mkdir -p $(dir $(PROMETHEUS_GO_DIR))
+	rm -f $(PROMETHEUS_GO_DIR)
+	ln -s $(TOP)/deps/prometheus $(PROMETHEUS_GO_DIR)
+	(cd $(PROMETHEUS_GO_DIR) && env -i $(GO_ENV) make build)
+
+$(STAMP_CERTGEN): | $(NODE_EXEC) $(NPM_EXEC)
+	$(MAKE_STAMP_REMOVE)
+	rm -rf $(TOP)/node_modules && cd $(TOP) && $(NPM) install --production
+	$(MAKE_STAMP_CREATE)
+
+sdc-scripts: deps/sdc-scripts/.git
+manta-scripts: deps/manta-scripts/.git
+
+.PHONY: clean
+clean::
+	# Clean certgen
+	rm -rf $(TOP)/node_modules
+	rm -rf $(PROMETHEUS_EXEC)
+
+.PHONY: release
+release: all docs $(SMF_MANIFESTS)
+	@echo "Building $(RELEASE_TARBALL)"
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(NAME)
+	cp -r \
+		$(TOP)/bin \
+		$(TOP)/etc \
+		$(TOP)/package.json \
+		$(TOP)/node_modules \
+		$(TOP)/smf \
+		$(TOP)/sapi_manifests \
+		$(RELSTAGEDIR)/root/opt/triton/$(NAME)/
+	# our prometheus build
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(NAME)/prometheus
+	cp -r \
+		$(PROMETHEUS_GO_DIR)/prometheus \
+		$(PROMETHEUS_GO_DIR)/promtool \
+		$(PROMETHEUS_GO_DIR)/consoles \
+		$(PROMETHEUS_GO_DIR)/console_libraries \
+		$(RELSTAGEDIR)/root/opt/triton/$(NAME)/prometheus/
+	# our node version
+	@mkdir -p $(RELSTAGEDIR)/root/opt/triton/$(NAME)/build
+	cp -r \
+		$(TOP)/build/node \
+		$(RELSTAGEDIR)/root/opt/triton/$(NAME)/build/
+	# zone boot
+	mkdir -p $(RELSTAGEDIR)/root/opt/smartdc/boot
+	cp -r $(TOP)/deps/sdc-scripts/{etc,lib,sbin,smf} \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	cp -r $(TOP)/boot/* \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/
+	mkdir -p $(RELSTAGEDIR)/root/opt/smartdc/boot/manta-scripts
+	cp -r $(TOP)/deps/manta-scripts/*.sh \
+		$(RELSTAGEDIR)/root/opt/smartdc/boot/manta-scripts
+	# tar it up
+	(cd $(RELSTAGEDIR) && $(TAR) -I pigz -cf $(TOP)/$(RELEASE_TARBALL) root)
+	@rm -rf $(RELSTAGEDIR)
+
+
+.PHONY: publish
+publish: release
+	@if [[ -z "$(ENGBLD_BITS_DIR)" ]]; then \
+		echo "error: 'ENGBLD_BITS_DIR' must be set for 'publish' target"; \
+		exit 1; \
+	fi
+	mkdir -p $(ENGBLD_BITS_DIR)/$(NAME)
+	cp $(TOP)/$(RELEASE_TARBALL) $(ENGBLD_BITS_DIR)/$(NAME)/$(RELEASE_TARBALL)
+
+.PHONY: dumpvar
+dumpvar:
+	@if [[ -z "$(VAR)" ]]; then \
+		echo "error: set 'VAR' to dump a var"; \
+		exit 1; \
+	fi
+	@echo "$(VAR) is '$($(VAR))'"
+
+mytarget:
+	echo my command
+
+include ./deps/eng/tools/mk/Makefile.deps
+ifeq ($(shell uname -s),SunOS)
+    include ./deps/eng/tools/mk/Makefile.go_prebuilt.targ
+    include ./deps/eng/tools/mk/Makefile.node_prebuilt.targ
+    include ./deps/eng/tools/mk/Makefile.agent_prebuilt.targ
+endif
+include ./deps/eng/tools/mk/Makefile.smf.targ
+include ./deps/eng/tools/mk/Makefile.targ
diff --git a/README.md b/README.md
index 026f293..29bcb20 100644
--- a/README.md
+++ b/README.md
@@ -1,25 +1,180 @@
 # triton-prometheus
 
-A repo with tooling to setup Prometheus and Grafana in a TritonDC for metrics
-and monitoring of Triton itself. The goal is to make it easy (and somewhat
-standardized, to simplify collaboration) to work with and monitor TritonDC
-metrics.
+The Triton and Manta core Prometheus service. Triton and Manta are moving to
+using Prometheus and [Grafana](https://github.com/joyent/triton-grafana) to
+track their own metrics and monitor themselves. All metrics are gathered via
+[CMON](https://github.com/joyent/triton-cmon).
+
+This repo builds one zone image which can be deployed as an instance of a Triton
+or Manta service. The targets Prometheus scrapes will depend on whether the
+image is deployed as part of Triton or Manta.
+
 
 ## Status
 
-For now this just houses lowly bash scripts for setting up prometheus0
-and grafana0 zones on a Triton headnode. Eventually this might turn into a core
-TritonDC "prometheus" and "grafana" services.
+The Triton and Manta Prometheus and Grafana services are being actively
+developed. [RFD 150](https://github.com/joyent/rfd/tree/master/rfd/0150)
+describes the current plan and status.
+
+
+## Setup for Triton
+
+First ensure that [CMON](https://github.com/joyent/triton-cmon) and
+[CNS](https://github.com/joyent/triton-cns) are set up in your TritonDC,
+typically via:
+
+    sdcadm post-setup cns [OPTIONS]
+    sdcadm post-setup cmon [OPTIONS]
+
+Then run the following from your TritonDC's headnode global zone:
+
+    sdcadm post-setup prometheus [OPTIONS]
+
+## Setup for Manta
+
+As with Triton above, ensure that CMON and CNS are deployed. Then, create a new
+Manta config file with your desired number of Prometheus images and update using
+`manta-adm`, as described in the
+[Manta Operator's Guide](https://joyent.github.io/manta/#upgrading-manta-components)
+
+## Configuration
+
+Primarily this VM runs a Prometheus server (as the "prometheus" SMF service).
+The config files for that service are as follows. Note that "/data/..." is a
+delegate dataset to persist through reprovisions -- we store the Prometheus
+time-series database here.
+
+    /opt/triton/prometheus/etc/config.json        # SAPI config
+    /opt/triton/prometheus/etc/prometheus.yml     # Prometheus config; generated
+                                                  # from SAPI config
+    /opt/triton/prometheus/keys/*                 # Key and cert for CMON auth
+
+    /data/prometheus/data/*                       # Prometheus database
+
+Like most Triton and Manta core services, a config-agent is used to gather some
+config data. Unlike many core services, this VM uses an additional config
+processing step to create the final prometheus config. At the time of writing,
+this is to allow post-processing of the SAPI config variables to produce the
+Prometheus config file. This code is pulled out into
+`/opt/triton/prometheus/bin/prometheus-configure`, which runs from
+`boot/setup.sh`, `boot/configure.sh`, and as the config-agent `post_cmd`.
+
+## SAPI Configuration
+
+There are some Triton Prometheus service configuration options that can be
+set in SAPI.
+
+| Key                              | Type   | Description |
+| -------------------------------- | ------ | ----------- |
+| **cmon\_domain**                 | String | Optional. The domain at which Prometheus should talk to this DC's CMON, e.g. "cmon.us-east-1.triton.zone". The actual endpoint is assumed to be https and port 9163. See notes below. |
+| **cmon_enforce_certificate** | Bool   | Optional. This can be set to `true` to have Prometheus fail on TLS cert errors from a self-signed cert. This is false by default. |
+|
+
+Prometheus gets its metrics from the DC's local CMON, typically over the
+external network. To auth with CMON properly in a production environment, it
+needs to know the appropriate CMON URL advertised to public DNS and for which
+it has a signed TLS certificate. This is what `cmon_domain` is for. If this is
+not specified, then this image will attempt to infer an appropriate URL
+via querying the DC's local CNS. See `bin/prometheus-configure` for details.
+
+An example setting these values:
+
+    promSvc=$(sdc-sapi /services?name=prometheus | json -Ha uuid)
+    sdc-sapi /services/$promSvc -X PUT \
+        -d '{"metadata": {"cmon_domain": "mycmon.example.com", "cmon_insecure_skip_verify": true, "require_cns_resolver": false}}'
+
+
+## CMON Auth
+
+Prometheus needs to authenticate with the local CMON. To do this, the setup
+script generates a certificate using the `bin/certgen` tool. This certificate
+can be regenerated by running the tool manually.
+
+### Name resolution
+
+The Prometheus zone resolves names using
+[CNS](https://github.com/joyent/triton-cns). To allow queries from an arbitrary
+number of CNS servers and offload some traffic from CNS, the Prometheus zone
+runs a BIND server that resolves the CNS names using zone transfer. The BIND
+server forwards all requests outside of the cns zone to external and binder
+resolvers. BIND runs on localhost, and localhost is the only entry in
+/etc/resolv.conf.
+
+## Security
+
+Prometheus listens on the admin and external networks. The firewall with the
+[standard Triton rules](https://github.com/joyent/sdc-headnode/blob/34dbd8acd65523c844385a81239ea0a872750326/scripts/headnode.sh#L188-L228)
+is enabled to disallow incoming requests on the external network.
+
+Prometheus is on the external network so it can access CMON and work with CNS --
+at least until CNS supports split horizon DNS to provide separate records on the
+admin network. This is because CMON's Triton service discovery returns the CNS
+domain names for Triton's core VMs.
+
+Prometheus is on the admin network because Triton's Grafana accesses Prometheus
+on the admin.
+
 
-## How to deploy Prometheus and Grafana for monitoring Triton
+## Troubleshooting
 
-**NOTE**: the `setup-prometheus.sh` and `setup-grafana.sh` scripts are effectively
-deprecated -- the `setup-*-prod.sh` scripts implement all of their
-functionality, plus a number of additional features.
+### Prometheus doesn't have Triton/Manta data
 
-### Setting up Prometheus
+Prometheus gets its Triton (or Manta) data from CMON. Here are some things to
+check if this appears to be failing:
 
-Run `./setup-prometheus-prod.sh` from a Triton headnode. All CLI flags are
+- Does the following Prometheus query have any data?
+
+        cpucap_cur_usage_percentage{alias=~"cnapi.+"}
+
+- Does the Prometheus config (/opt/triton/prometheus/etc/prometheus.yml) look correct?
+
+- Is Prometheus running? `svcs prometheus`
+
+- Does the Prometheus log show errors? E.g. (newlines added for readability):
+
+    ```
+    $ tail `svcs -L prometheus`
+    ...
+    level=error ts=2018-09-28T18:42:33.715136969Z caller=triton.go:170
+        component="discovery manager scrape"
+        discovery=trition
+        msg="Refreshing targets failed"
+        err="an error occurred when requesting targets from the discovery endpoint.
+            Get https://mycmon.example.com:9163/v1/discover: dial tcp:
+            lookup mycmon.example.com on 8.8.8.8:53: no such host"
+    ```
+
+- Is Prometheus' Triton service discovery authenticating properly to CMON? If
+  not, the CMON log will show something like this:
+
+    ```
+    [2018-10-04T22:27:37.632Z]  INFO: cmon/17801 on 2539de9f-43d0-49c4-af79-4f02d53dcdde: handled: 401 (req_id=495dcfb9-054a-48fd-85b4-ed0a1500b9bc, route=getcontainers, audit=true, remoteAddress=10.128.0.10, remotePort=58600, latency=2, _audit=true, req.query="", req.version=*)
+        GET /v1/discover HTTP/1.1
+        host: cmon.coal.cns.joyent.us:9163
+        user-agent: Go-http-client/1.1
+        accept-encoding: gzip
+        --
+        HTTP/1.1 401 Unauthorized
+        content-type: application/json
+        content-length: 41
+        date: Thu, 04 Oct 2018 22:28:37 GMT
+        server: cmon
+        x-request-id: 0a1f7159-39f7-45a6-b724-f9ec68831899
+        x-response-time: 18
+        x-server-name: 2539de9f-43d0-49c4-af79-4f02d53dcdde
+
+        {
+          "code": "UnauthorizedError",
+          "message": ""
+        }
+    ```
+
+## LX script
+
+This repo also contains a script to set up an ad-hoc LX-branded zone running
+Prometheus. Here's how:
+
+Run `./setup-prometheus-adhoc.sh` from a Triton headnode. All CLI flags are
 optional; here's an explanation of what each flag does:
 - `-i` specifies that Prometheus should connect to CMON using insecure TLS; this
   flag is likely necessary in a development environment
@@ -35,56 +190,15 @@ optional; here's an explanation of what each flag does:
 
 An appropriate invocation for a development setup would be:
 
-	./setup-prometheus-prod.sh \
-	-i \
-	-r <CNS IP>,8.8.8.8 \
-	-k /root/.ssh/sdc.id_rsa.pub
-
-An appropriate invocation for a production environment would be:
-
-	./setup-prometheus-prod.sh \
-	-f \
-	-r <CNS IP>,8.8.8.8 \
-	-s <server UUID> \
-	-k /root/.ssh/sdc.id_rsa.pub
-
-### Setting up Grafana
-
-Run `./setup-grafana-prod.sh` from a Triton headnode. All CLI flags are
-optional; here's an explanation of what each flag does:
-- `-s <server UUID>` specifies which server in the Triton deployment to
-  provision the zone on; the default is the server on which the script is being
-  run
-- `-k <path to ssh key>` puts the specified key in the Grafana zone's
-  `authorized_keys` file to allow ssh access
-
-An appropriate invocation for a development setup would be:
-
-	./setup-grafana-prod.sh \
-	-k /root/.ssh/sdc.id_rsa.pub
+    ./setup-prometheus-adhoc.sh \
+    -i \
+    -r <CNS IP>,8.8.8.8 \
+    -k /root/.ssh/sdc.id_rsa.pub
 
 An appropriate invocation for a production environment would be:
 
-	./setup-grafana-prod.sh \
-	-s <server UUID> \
-	-k /root/.ssh/sdc.id_rsa.pub
-
-### (DEPRECATED) Instructions for old scripts
-
-Run the following from your computer/laptop. Assuming you have something like
-this in your "~/.ssh/config":
-
-	Host coal
-		User root
-		Hostname 10.99.99.7
-		StrictHostKeyChecking no
-		UserKnownHostsFile /dev/null
-
-Run this:
-
-    ./setup-prometheus.sh coal      # create a prometheus0 zone
-    ./setup-grafana.sh coal         # create a grafana0 zone
-
-Then wait about 5 minutes for metrics to start coming in (I don't know what
-the exact delay is) and visit the grafana URL (it is printed at the end of
-`setup-grafana.sh ...`).
+    ./setup-prometheus-adhoc.sh \
+    -f \
+    -r <CNS IP>,8.8.8.8 \
+    -s <server UUID> \
+    -k /root/.ssh/sdc.id_rsa.pub
diff --git a/bin/certgen b/bin/certgen
new file mode 100644
index 0000000..cfe9d05
--- /dev/null
+++ b/bin/certgen
@@ -0,0 +1,158 @@
+#!/usr/bin/env node
+
+/*
+ * This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/.
+ */
+
+/*
+ * Copyright (c) 2019, Joyent, Inc.
+ *
+ * Generates certificate for Prometheus to use to authenticate to CMON.
+ *
+ * Usage:
+ *    node certgen <flavor>
+ *
+ * where flavor is either 'sdc' or 'manta' - this determines whether to use the
+ * admin or poseidon key when generating the certificate.
+ */
+
+'use strict';
+
+const fs = require('fs');
+
+const assert = require('assert-plus');
+const bunyan = require('bunyan');
+const sshpk = require('sshpk');
+const vasync = require('vasync');
+
+/*
+ * sshpk expects cert time in seconds - we therefore calculate the number of
+ * seconds in a year.
+ */
+const YEAR_MULTIPLIER = 60 * 60 * 24 * 365;
+const CERT_LIFETIME = 10 * YEAR_MULTIPLIER;
+
+const ROOT_KEY_DIR = '/root/.ssh';
+const SDC_PRIVATE_KEY = ROOT_KEY_DIR + '/sdc.id_rsa';
+const MANTA_PRIVATE_KEY = ROOT_KEY_DIR + '/id_rsa';
+const PUB_KEY_SUFFIX = '.pub';
+
+const ROOT_DIR = '/opt/triton/prometheus';
+
+/*
+ * CMON key-related paths. Keep in sync with "boot/setup.sh" and
+ * "bin/prometheus-configure".
+ */
+const CMON_KEY_OUT_DIR = ROOT_DIR + '/keys';
+const CMON_KEY_OUTPUT_FILE = CMON_KEY_OUT_DIR + '/prometheus.key.pem';
+const CMON_CERT_OUTPUT_FILE = CMON_KEY_OUT_DIR + '/prometheus.cert.pem';
+
+const log = bunyan.createLogger({
+    name: 'certgen'
+});
+
+/*
+ * Generates a certificate signed by the key specified by the script's 'flavor'
+ * argument and attaches the new key and cert to the ctx argument.
+ *
+ * requires:
+ * - ctx.flavor
+ */
+function signCert(ctx, cb) {
+    assert.object(ctx, 'ctx');
+    assert.string(ctx.flavor, 'ctx.flavor');
+    const flavor = ctx.flavor;
+    assert.ok(flavor === 'sdc' || flavor === 'manta',
+        'flavor === \'sdc\' || flavor === \'manta\'');
+
+    const privKey = sshpk.generatePrivateKey('ecdsa');
+    const pubKey = privKey.toPublic();
+
+    let username;
+    let rootPrivKeyPath;
+    if (flavor === 'sdc') {
+        rootPrivKeyPath = SDC_PRIVATE_KEY;
+        username = 'admin';
+    } else { // flavor === 'manta'
+        rootPrivKeyPath = MANTA_PRIVATE_KEY;
+        username = 'poseidon';
+    }
+    const rootPubKeyPath = rootPrivKeyPath + PUB_KEY_SUFFIX;
+
+    let rootPubKeyBuf;
+    let rootPrivKeyBuf;
+    try {
+        rootPubKeyBuf = fs.readFileSync(rootPubKeyPath);
+    } catch (err) {
+        cb(err);
+        return;
+    }
+    try {
+        rootPrivKeyBuf = fs.readFileSync(rootPrivKeyPath);
+    } catch (err) {
+        cb(err);
+        return;
+    }
+
+    const subj = sshpk.identityFromDN('CN=' + username);
+    const rootPubKey = sshpk.parseKey(rootPubKeyBuf);
+    const fp = rootPubKey.fingerprint('md5').toString('base64');
+    const issuer = sshpk.identityFromDN('CN=' + fp);
+    const rootPrivKey = sshpk.parsePrivateKey(rootPrivKeyBuf);
+
+    const opts = {
+        lifetime: CERT_LIFETIME,
+        purposes: ['signature', 'identity', 'clientAuth', 'joyentCmon']
+    };
+
+    ctx.outKey = privKey;
+    ctx.outCert = sshpk.createCertificate(subj, pubKey, issuer, rootPrivKey,
+        opts);
+    cb();
+}
+
+/*
+ * Writes the provided key and cert to disk.
+ *
+ * requires:
+ * - ctx.outKey
+ * - ctx.outCert
+ */
+function writeFiles(ctx, cb) {
+    assert.object(ctx);
+    assert.object(ctx.outKey);
+    assert.object(ctx.outCert);
+
+    try {
+        fs.writeFileSync(CMON_KEY_OUTPUT_FILE, ctx.outKey.toString('pem'));
+    } catch (err) {
+        cb(err);
+        return;
+    }
+    try {
+        fs.writeFileSync(CMON_CERT_OUTPUT_FILE, ctx.outCert.toString('pem'));
+    } catch (err) {
+        cb(err);
+        return;
+    }
+
+    cb();
+}
+
+// --- mainline
+
+vasync.pipeline({
+    // ctx
+    arg: {
+        flavor: process.argv[2]
+    },
+    funcs: [signCert, writeFiles]
+}, function (err) {
+    if (err) {
+        log.fatal(err);
+        process.exit(1);
+        return;
+    }
+});
diff --git a/bin/prometheus-configure b/bin/prometheus-configure
new file mode 100755
index 0000000..fdd4c35
--- /dev/null
+++ b/bin/prometheus-configure
@@ -0,0 +1,396 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2019, Joyent, Inc.
+#
+
+#
+# Updates configation files for Prometheus and enables/restarts/clears
+# the SMF prometheus service as necessary.
+#
+# This is run from three contexts:
+# - From the config-agent "prometheus" manifest `post_cmd`
+#   (see "/opt/triton/prometheus/sapi_manifests/prometheus").
+# - On first boot, to write the initial prometheus config (see comment for
+#   prometheus_configure_check_service_exists below)
+# - On every boot, to update CNS resolvers if necessary.
+#
+# Running it directly is supported as well.
+#
+
+#
+# Dev Notes:
+# - Do we need retries on requests to CNS? Probably yes. Currently determining
+#   the default CMON URL and resolv.conf update for the dev config is brittle
+#   by being dependent on the CNS service being up.
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+set -o errexit
+set -o pipefail
+
+PATH=/opt/local/bin:/opt/local/sbin:/usr/bin:/usr/sbin
+
+DATACENTER_NAME=
+DNS_DOMAIN=
+CMON_INSECURE=
+CMON_DOMAIN=
+BINDER_IP=
+CNS_IP=
+ROOT_DIR=/opt/triton/prometheus
+CONF_DIR=$ROOT_DIR/etc
+TEMPLATES_DIR=$CONF_DIR
+CONFIG_JSON=$CONF_DIR/config.json
+PROMETHEUS_YML=$CONF_DIR/prometheus.yml
+
+#
+# named-related paths. Keep in sync with "boot/setup.sh".
+#
+NAMED_CONFIG=/opt/local/etc/named.conf
+NAMED_DIR=$ROOT_DIR/named
+NAMED_LOG_DIR=/var/log/named
+
+#
+# CMON key-related paths. Keep in sync with "bin/certgen" and "boot/setup.sh".
+#
+CMON_AUTH_DIR=$ROOT_DIR/keys
+CMON_KEY_FILE=$CMON_AUTH_DIR/prometheus.key.pem
+CMON_CERT_FILE=$CMON_AUTH_DIR/prometheus.cert.pem
+
+#
+# A space-separated list of names of things updated. This is used to determine
+# if the prometheus SMF service needs to be restarted.
+#
+UPDATES_MADE=
+BIND_UPDATES_MADE=
+
+if [[ $(json "is_manta_service" < ${CONFIG_JSON}) == "true" ]]; then
+    export FLAVOR="manta"
+    export PROM_USER="poseidon"
+else
+    export FLAVOR="sdc"
+    export PROM_USER="admin"
+fi
+
+# ---- support routines
+
+function fatal {
+    printf '%s: ERROR: %s\n' "$(basename $0)" "$*" >&2
+    exit 1
+}
+
+#
+# Upon first provision, prometheus-configure will run as config agent's
+# post_cmd, but the prometheus service won't have been imported yet. Thus, we
+# will exit early when we perform this check. In this situation, boot/setup.sh
+# will run prometheus-configure directly, so the full script will still get run.
+#
+function prometheus_configure_check_service_exists() {
+    if ! svcs -H prometheus; then
+        echo 'prometheus service has not been imported yet; aborting setup'
+        exit 1
+    fi
+}
+
+#
+# Attempt to guess an appropriate CMON URL. This setup is appropriate for
+# a development setup.
+#
+function prometheus_configure_get_default_cmon_domain() {
+    local ownerUuid
+    local externalNet
+    local suffixesForVm
+    local cnsStatusCode
+    local suffix
+    local cmonDomain
+
+    [[ -n $CNS_IP ]] || fatal 'CNS_IP not set'
+
+    #
+    # Ask CNS for the DNS suffixes in use for the external (non-admin)
+    # network.
+    #
+    #    e.g.:
+    #    {
+    #      "suffixes": [
+    #        "svc.930896af-bf8c-48d4-885c-6573a94b1853.coal.cns.joyent.us",
+    #        "inst.930896af-bf8c-48d4-885c-6573a94b1853.coal.cns.joyent.us"
+    #      ]
+    #    }
+    #
+    ownerUuid=$(mdata-get sdc:owner_uuid)
+    externalNet=$(mdata-get sdc:nics | json -c 'this.nic_tag !== "admin" && this.nic_tag !== "manta"' 0.network_uuid)
+    [[ -n "$externalNet" ]] || fatal "could not determine non-admin NIC for this VM"
+    suffixesForVm="$(curl -i -X POST -H "Content-Type: application/json" -s ${CNS_IP}/suffixes-for-vm -d@/dev/stdin <<PAYLOAD | json
+    {
+        "owner_uuid": "$ownerUuid",
+        "networks": [
+            "$externalNet"
+        ]
+    }
+PAYLOAD
+)"
+    cnsStatusCode=$(echo "$suffixesForVm" | head -1 | awk '{print $2}')
+    [[ $cnsStatusCode == "200" ]] \
+        || fatal "error retrieving suffixes-for-vm from CNS: status $cnsStatusCode"
+
+    #
+    # Then use suffix -- everything after the account UUID -- on the first
+    # "suffixes" entry.
+    #
+    suffix=$(echo "$suffixesForVm" | json -H suffixes.0 | cut -d. -f3-)
+
+    cmonDomain="cmon.$suffix"
+    echo "$cmonDomain"
+}
+
+function prometheus_configure_update_resolv_conf() {
+    if [[ "$FLAVOR" == 'manta' ]]; then
+        return
+    fi
+
+    echo "search $DNS_DOMAIN" > /etc/resolv.conf.new
+    echo "nameserver 127.0.0.1" >> /etc/resolv.conf.new
+
+    if ! diff /etc/resolv.conf /etc/resolv.conf.new >/dev/null; then
+        echo "Updating /etc/resolv.conf"
+        cp /etc/resolv.conf /etc/resolv.conf.bak
+        mv /etc/resolv.conf.new /etc/resolv.conf
+        UPDATES_MADE="$UPDATES_MADE resolv.conf"
+    else
+        rm /etc/resolv.conf.new
+    fi
+}
+
+#
+# Update /etc/resolv.conf as necessary.
+#
+# Side-effect: Updates "UPDATES_MADE" global.
+#
+function prometheus_configure_get_resolver_ips() {
+
+    local resolvers=$(mdata-get sdc:resolvers | json -a)
+
+    #
+    # Get the binder and CNS IPs by iterating through resolvers indefinitely and
+    # trying to resolve the CNS name.
+    #
+    # Limitation: This just finds the first CNS in DNS if (hypothetically)
+    # there are many.
+    #
+    while true; do
+        for resolver in $resolvers; do
+
+            CNS_IP=$(dig @$resolver +short +time=10 \
+                cns.$DATACENTER_NAME.$DNS_DOMAIN | head -1)
+
+            if [[ -n "$CNS_IP" ]]; then
+                BINDER_IP=$resolver
+                break 2
+            fi
+
+        done
+    done
+
+    return 0
+}
+
+#
+# Write config file based on template.
+# Arguments:
+#     $1: Desired fully qualified path of final config file
+#     $2: Update-tracking variable to modify
+#     $3, $4, ..., $N: string names of template parameters to replace. These
+#         will be replaced with the contents of identically-named bash
+#         variables.
+#
+# Example usage:
+# `prometheus_write_config $PROMETHEUS_YML UPDATES_MADE PROM_USER \
+#     DATACENTER_NAME CMON_CERT_FILE CMON_KEY_FILE CMON_INSECURE CMON_DOMAIN`
+#
+# This example invocation will look for the template corresponding to
+# $PROMETHEUS_CONFIG_FILE in $TEMPLATES_DIR, search for instances of CONF_DIR
+# and DATA_DIR in this template file (surrounded by the delimiter "%%"), replace
+# these with the contents of the bash variables $CONF_DIR and $DATA_DIR,
+# respectively, and write this file to $PROMETHEUS_CONFIG_FILE.
+#
+# If the config file already exists and differs from the new config file, this
+# function will save a backup.
+#
+function prometheus_write_config() {
+    local config_file=$1
+    local update_var=$2
+    local basename=$(basename ${config_file})
+
+    local template_file=${TEMPLATES_DIR}/${basename}.in
+    shift
+    shift
+
+    local delim='%%'
+    # semicolon-separated list of sed commands to run
+    local commands=''
+
+    for var in "$@"; do
+        # Verify that template parameter exists in template file before
+        # adding to command list
+        grep "${delim}${var}${delim}" ${template_file} || \
+            fatal "template parameter ${var} not found in ${template_file}"
+        commands="${commands}s|${delim}${var}${delim}|${!var}|g;"
+    done
+
+    local contents=$(sed "${commands}" ${template_file})
+
+    echo ${contents} | grep "${delim}" && \
+        fatal "unused substitution delimiter found in ${basename}"
+
+    # Write the config to a temporary file.
+    echo -e "${contents}" > ${config_file}.new
+
+    # Update the config, if changed.
+    if [[ ! -f ${config_file} ]]; then
+        # First time config.
+        echo "Writing first time prometheus config ($config_file)"
+        mv ${config_file}.new ${config_file}
+        declare $update_var="${!update_var} ${config_file}"
+    elif ! diff ${config_file} ${config_file}.new >/dev/null; then
+        # The config differs.
+        echo "Updating prometheus config ($config_file)"
+        cp ${config_file} ${config_file}.bak
+        mv ${config_file}.new ${config_file}
+        declare $update_var="${!update_var} ${config_file}"
+    else
+        # The config does not differ
+        rm ${config_file}.new
+    fi
+}
+
+function prometheus_configure_update_named_config {
+    [[ -n $CNS_IP ]] || fatal 'CNS_IP not set'
+    [[ -n $BINDER_IP ]] || fatal 'BINDER_IP not set'
+
+    prometheus_write_config $NAMED_CONFIG BIND_UPDATES_MADE NAMED_DIR \
+        NAMED_LOG_DIR CNS_IP BINDER_IP
+}
+
+#
+# Update the prometheus config as required. Note this may involve updating
+# resolv.conf as well.
+#
+# Side-effect: Updates "UPDATES_MADE" global.
+#
+function prometheus_configure_update_config() {
+    local cmon_enforce_certificate
+
+    #
+    # The appropriate CMON URL is either from the service config, or fall back
+    # to guessing from CNS suffix for admin VMs.
+    #
+    CMON_DOMAIN=$(json -f $CONFIG_JSON cmon_domain)
+    if [[ -z "$CMON_DOMAIN" ]]; then
+
+        CMON_DOMAIN=$(prometheus_configure_get_default_cmon_domain)
+        if [[ -z "$CMON_DOMAIN" ]]; then
+            fatal "'cmon_domain' service config is not set and could not determine a default CMON URL"
+        fi
+    fi
+
+    cmon_enforce_certificate=$(json -f $CONFIG_JSON cmon_enforce_certificate)
+    if [[ -z "$cmon_enforce_certificate" ]]; then
+        cmon_enforce_certificate='false'
+    fi
+
+    #
+    # We invert the value from the SAPI config to get the value that should go
+    # in the Prometheus config.
+    #
+    if [[ "$cmon_enforce_certificate" == 'true' ]]; then
+        CMON_INSECURE='false'
+    else
+        CMON_INSECURE='true'
+    fi
+
+    prometheus_write_config $PROMETHEUS_YML UPDATES_MADE PROM_USER \
+        DATACENTER_NAME CMON_CERT_FILE CMON_KEY_FILE CMON_INSECURE CMON_DOMAIN
+
+    return 0
+}
+
+#
+# The prometheus SMF service runs as the 'nobody' user, so the files it
+# accesses must be owned by nobody. Here, we ensure this for the files that may
+# change due to SAPI configuration changes.
+#
+# Side-effect: Updates "UPDATES_MADE" global.
+#
+function prometheus_configure_ensure_nobody_owner() {
+    local output
+
+    # We explicitly use the chown that has the "-c" option
+    output=$(/opt/local/bin/chown -c nobody:nobody \
+        $CONF_DIR/*)
+    if [[ -n "$output" ]]; then
+        UPDATES_MADE="$UPDATES_MADE chown"
+        echo "$output"
+    fi
+
+    return 0
+}
+
+#
+# Enable/restart/clear prometheus, if necessary. Note: This uses the global
+# "UPDATES_MADE" to determine if config file changes have been made.
+#
+function prometheus_configure_restart() {
+    local svc=$1
+    local update_var=$2
+    local currState
+
+    currState=$(svcs -Ho state ${svc})
+    if [[ "$currState" == "disabled" ]]; then
+        #
+        # Zone setup starts with prometheus in disabled state. We enable it
+        # after the config is generated for the first time.
+        #
+        echo "Enabling ${svc} SMF service"
+        svcadm enable ${svc}
+    elif [[ "$currState" == "online" ]]; then
+        if [[ -n "${!update_var}" ]]; then
+            echo "Restarting ${svc} SMF service"
+            svcadm restart ${svc}
+        fi
+    elif [[ "$currState" == "maintenance" ]]; then
+        echo "Clearing ${svc} SMF service"
+        svcadm clear ${svc}
+    else
+        fatal "unexpected ${svc} service state: '$currState'"
+    fi
+
+    return 0
+}
+
+# ---- mainline
+
+if [[ "$FLAVOR" == "manta" ]]; then
+    DATACENTER_NAME=$(json -f ${CONFIG_JSON} datacenter)
+    DNS_DOMAIN=$(json -f ${CONFIG_JSON} dns_domain)
+else
+    DATACENTER_NAME=$(mdata-get sdc:datacenter_name)
+    DNS_DOMAIN=$(mdata-get sdc:dns_domain)
+fi
+
+prometheus_configure_get_resolver_ips
+prometheus_configure_check_service_exists
+prometheus_configure_update_config
+prometheus_configure_ensure_nobody_owner
+prometheus_configure_update_named_config
+prometheus_configure_update_resolv_conf
+prometheus_configure_restart bind BIND_UPDATES_MADE
+prometheus_configure_restart prometheus UPDATES_MADE
+
+exit 0
diff --git a/boot/configure.sh b/boot/configure.sh
new file mode 100755
index 0000000..dec7533
--- /dev/null
+++ b/boot/configure.sh
@@ -0,0 +1,18 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2019, Joyent, Inc.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+# We run this on every boot to update resolv.conf with the localhost resolver.
+/opt/triton/prometheus/bin/prometheus-configure
+
+exit 0
diff --git a/boot/setup.sh b/boot/setup.sh
new file mode 100755
index 0000000..81323a2
--- /dev/null
+++ b/boot/setup.sh
@@ -0,0 +1,211 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2019, Joyent, Inc.
+#
+
+#
+# One-time setup of a Triton prometheus core zone.
+#
+# It is expected that this is run via the standard Triton user-script,
+# i.e. as part of the "mdata:execute" SMF service. That user-script ensures
+# this setup.sh is run once for each (re)provision of the image. However this
+# script should also be idempotent.
+#
+
+export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+set -o errexit
+set -o pipefail
+set -o xtrace
+
+PATH=/opt/local/bin:/opt/local/sbin:/usr/bin:/usr/sbin
+
+NODE=/opt/triton/prometheus/build/node/bin/node
+
+ROOT_DIR=/opt/triton/prometheus
+
+#
+# named-related paths. Keep in sync with "bin/prometheus-configure".
+#
+NAMED_DIR=$ROOT_DIR/named
+NAMED_LOG_DIR=/var/log/named
+
+#
+# CMON key-related paths. Keep in sync with "bin/certgen" and
+# "bin/prometheus-configure".
+#
+CMON_AUTH_DIR=$ROOT_DIR/keys
+CMON_KEY_FILE=$CMON_AUTH_DIR/prometheus.key.pem
+CMON_CERT_FILE=$CMON_AUTH_DIR/prometheus.cert.pem
+
+#
+# Prometheus data that should be persistent across reprovisions is stored on its
+# delegate dataset:
+#
+#   /data/prometheus/
+#       data/    # time-series database
+#
+PERSIST_DIR=/data/prometheus
+DATA_DIR=$PERSIST_DIR/data
+
+function fatal {
+    printf '%s: ERROR: %s\n' "$(basename $0)" "$*" >&2
+    exit 1
+}
+
+#
+# We can't use the sapi config file to determine $FLAVOR yet, because this runs
+# before the SAPI config gets written on zone setup, so we check for the
+# existence of manta_role instead. This is the same method that moray uses for
+# determining $FLAVOR.
+#
+if [[ -n $(mdata-get sdc:tags.manta_role) ]]; then
+    export FLAVOR="manta"
+else
+    export FLAVOR="sdc"
+fi
+
+# ---- internal routines
+
+# Mount our delegate dataset at /data.
+function prometheus_setup_delegate_dataset {
+    local mountpoint
+
+    dataset=zones/$(zonename)/data
+    mountpoint=$(zfs get -Hp mountpoint $dataset | awk '{print $3}')
+    if [[ $mountpoint != "/data" ]]; then
+        zfs set mountpoint=/data $dataset
+    fi
+}
+
+function prometheus_setup_env {
+    if ! grep prometheus /root/.profile >/dev/null; then
+        echo "" >>/root/.profile
+        echo "export PATH=/opt/triton/prometheus/bin:/opt/triton/prometheus/prometheus:\$PATH" >>/root/.profile
+    fi
+}
+
+function prometheus_setup_named {
+    local localhost_zone
+    local arpa_zone
+
+    svccfg import /opt/local/lib/svc/manifest/bind.xml
+
+    mkdir -p $NAMED_DIR
+    mkdir -p $NAMED_DIR/master
+    mkdir -p $NAMED_DIR/slave
+    mkdir -p $NAMED_LOG_DIR
+
+    read -rd '' localhost_zone <<LOCALHOST_ZONE || true
+\$TTL 3D
+
+\$ORIGIN localhost.
+
+@       1D      IN     SOA     @       root (
+                       2013050101      ; serial
+                       8H              ; refresh
+                       2H              ; retry
+                       4W              ; expiry
+                       1D              ; minimum
+                       )
+
+@       IN      NS      @
+        IN      A       127.0.0.1
+LOCALHOST_ZONE
+
+    read -rd '' arpa_zone <<ARPA_ZONE || true
+\$TTL 3D
+
+@       IN      SOA     localhost. root.localhost. (
+                        2013050101      ; Serial
+                        8H              ; Refresh
+                        2H              ; Retry
+                        4W              ; Expire
+                        1D              ; Minimum TTL
+                        )
+
+       IN      NS      localhost.
+
+1      IN      PTR     localhost.
+ARPA_ZONE
+
+    echo -e "${localhost_zone}" > $NAMED_DIR/master/localhost
+    echo -e "${arpa_zone}" > $NAMED_DIR/master/127.in-addr.arpa
+
+    chown -R named:named \
+        $NAMED_DIR \
+        $NAMED_LOG_DIR
+}
+
+function prometheus_setup_prometheus {
+    mkdir -p $DATA_DIR
+
+    /usr/sbin/svccfg import /opt/triton/prometheus/smf/manifests/prometheus.xml
+
+    #
+    # Set up key and client certificate used to auth with this DC's CMON.
+    #
+    echo "Generating key and client cert for CMON auth"
+    mkdir -p $CMON_AUTH_DIR
+    ${NODE} "--abort_on_uncaught_exception" \
+        /opt/triton/prometheus/bin/certgen $FLAVOR
+
+    #
+    # The prometheus SMF service runs as the 'nobody' user, so the files it
+    # accesses must be owned by nobody. Here, we ensure this for the files and
+    # directory that will remain static for the lifetime of the zone.
+    #
+    chown nobody:nobody \
+        $CMON_KEY_FILE \
+        $CMON_CERT_FILE \
+        $DATA_DIR \
+
+    #
+    # prometheus-configure contains the common setup code that must be run here
+    # and also on config-agent updates
+    #
+    TRACE=1 /opt/triton/prometheus/bin/prometheus-configure
+}
+
+# ---- mainline
+
+prometheus_setup_delegate_dataset
+prometheus_setup_env
+
+if [[ "$FLAVOR" == "manta" ]]; then
+
+    MANTA_SCRIPTS_DIR=/opt/smartdc/boot/manta-scripts
+    source ${MANTA_SCRIPTS_DIR}/util.sh
+    source ${MANTA_SCRIPTS_DIR}/services.sh
+
+    manta_common_presetup
+    manta_add_manifest_dir "/opt/triton/prometheus"
+    manta_common_setup "prometheus" 0
+
+    prometheus_setup_named
+    prometheus_setup_prometheus
+
+    manta_common_setup_end
+
+else # "$FLAVOR" == "sdc"
+
+    CONFIG_AGENT_LOCAL_MANIFESTS_DIRS=/opt/triton/prometheus
+    source /opt/smartdc/boot/lib/util.sh
+    sdc_common_setup
+
+    prometheus_setup_named
+    prometheus_setup_prometheus
+
+    # Log rotation.
+    sdc_log_rotation_add config-agent /var/svc/log/*config-agent*.log 1g
+    sdc_log_rotation_add registrar /var/svc/log/*registrar*.log 1g
+    sdc_log_rotation_add prometheus /var/svc/log/*prometheus*.log 1g
+    sdc_log_rotation_setup_end
+
+    sdc_setup_complete
+fi
+
+exit 0
diff --git a/deps/eng b/deps/eng
new file mode 160000
index 0000000..1840f1f
--- /dev/null
+++ b/deps/eng
@@ -0,0 +1 @@
+Subproject commit 1840f1f2b39a160d9ad5daf7d6562a41aa620471
diff --git a/deps/manta-scripts b/deps/manta-scripts
new file mode 160000
index 0000000..cd8d6f1
--- /dev/null
+++ b/deps/manta-scripts
@@ -0,0 +1 @@
+Subproject commit cd8d6f194ba34dfaa4b0740dfbd11147041dd13e
diff --git a/deps/prometheus b/deps/prometheus
new file mode 160000
index 0000000..348cdbf
--- /dev/null
+++ b/deps/prometheus
@@ -0,0 +1 @@
+Subproject commit 348cdbf899374881a46cb4b18a898e65fabe884d
diff --git a/deps/sdc-scripts b/deps/sdc-scripts
new file mode 160000
index 0000000..deefaef
--- /dev/null
+++ b/deps/sdc-scripts
@@ -0,0 +1 @@
+Subproject commit deefaef587ed3bee2706cb6e53ee3468e682932e
diff --git a/etc/named.conf.in b/etc/named.conf.in
new file mode 100644
index 0000000..643f97a
--- /dev/null
+++ b/etc/named.conf.in
@@ -0,0 +1,63 @@
+options {
+        directory "%%NAMED_DIR%%";
+
+        dnssec-enable yes;
+        dnssec-validation yes;
+
+        auth-nxdomain no;
+
+        allow-transfer {
+                127.0.0.1;
+        };
+
+        listen-on { 127.0.0.1; };
+
+        check-integrity yes;
+
+        recursion yes;
+};
+
+masters cns {
+        %%CNS_IP%%;
+};
+
+logging {
+        channel default_log {
+                file "%%NAMED_LOG_DIR%%/bind.log" versions 3 size 5m;
+                severity info;
+                print-time yes;
+                print-severity yes;
+                print-category yes;
+        };
+        category default {
+                default_log;
+        };
+};
+
+zone "." IN {
+        type forward;
+        forward only;
+        forwarders {
+                %%BINDER_IP%%;
+                8.8.8.8;
+                8.8.4.4;
+        };
+};
+
+zone "lab.cns.example.com" IN {
+        type slave;
+        request-ixfr yes;
+        file "slave/lab.cns.example.com";
+
+        masters { cns; };
+};
+
+zone "localhost" IN {
+        type master;
+        file "master/localhost";
+};
+
+zone "127.in-addr.arpa" IN {
+        type master;
+        file "master/127.in-addr.arpa";
+};
diff --git a/etc/prometheus.yml.in b/etc/prometheus.yml.in
new file mode 100644
index 0000000..ca34f56
--- /dev/null
+++ b/etc/prometheus.yml.in
@@ -0,0 +1,32 @@
+global:
+  scrape_interval:     15s # Default is 1 minute.
+  evaluation_interval: 15s # Default is 1 minute.
+  # scrape_timeout is set to the global default (10s).
+
+scrape_configs:
+  # The job name is added as a label 'job=<job_name>' to any timeseries scraped
+  # from this config.
+  - job_name: '%%PROM_USER%%_%%DATACENTER_NAME%%'
+    scheme: https
+    tls_config:
+      cert_file: %%CMON_CERT_FILE%%
+      key_file: %%CMON_KEY_FILE%%
+      insecure_skip_verify: %%CMON_INSECURE%%
+    relabel_configs:
+      - source_labels: [__meta_triton_machine_alias]
+        target_label: alias
+      - source_labels: [__meta_triton_machine_id]
+        target_label: instance
+    triton_sd_configs:
+      - account: '%%PROM_USER%%'
+        dns_suffix: '%%CMON_DOMAIN%%'
+        endpoint: '%%CMON_DOMAIN%%'
+        version: 1
+        tls_config:
+          cert_file: %%CMON_CERT_FILE%%
+          key_file: %%CMON_KEY_FILE%%
+          insecure_skip_verify: %%CMON_INSECURE%%
+  - job_name: 'prometheus_%%DATACENTER_NAME%%'
+    static_configs:
+    - targets:
+      - localhost:9090
diff --git a/package.json b/package.json
index 1a00328..855921d 100644
--- a/package.json
+++ b/package.json
@@ -1,12 +1,22 @@
 {
-  "name": "triton-prometheus",
-  "description": "Prometheus for TritonDC",
-  "version": "1.0.0",
-  "author": "Joyent (joyent.com)",
-  "private": true,
-  "repository": {
-    "type": "git",
-    "url": "git+https://github.com/joyent/triton-prometheus.git"
-  },
-  "license": "MPL-2.0"
+    "name": "triton-prometheus",
+    "description": "Prometheus for TritonDC",
+    "version": "1.0.0",
+    "author": "Joyent (joyent.com)",
+    "private": true,
+    "repository": {
+        "type": "git",
+        "url": "git+https://github.com/joyent/triton-prometheus.git"
+    },
+    "license": "MPL-2.0",
+    "dependencies": {
+        "assert-plus": "^1.0.0",
+        "bunyan": "^1.8.12",
+        "sshpk": "^1.15.2",
+        "vasync": "^2.2.0"
+    },
+    "devDependencies": {
+        "eslint": "^4.13.1",
+        "eslint-plugin-joyent": "~2.1.0"
+    }
 }
diff --git a/sapi_manifests/prometheus/manifest.json b/sapi_manifests/prometheus/manifest.json
new file mode 100644
index 0000000..406bd5b
--- /dev/null
+++ b/sapi_manifests/prometheus/manifest.json
@@ -0,0 +1,5 @@
+{
+	"name": "prometheus",
+	"path": "/opt/triton/prometheus/etc/config.json",
+	"post_cmd": "/opt/triton/prometheus/bin/prometheus-configure"
+}
diff --git a/sapi_manifests/prometheus/template b/sapi_manifests/prometheus/template
new file mode 100644
index 0000000..63fd1e4
--- /dev/null
+++ b/sapi_manifests/prometheus/template
@@ -0,0 +1,24 @@
+{
+{{#cmon_domain}}
+    "cmon_domain": "{{{cmon_domain}}}",
+{{/cmon_domain}}
+{{#cmon_insecure_skip_verify}}
+    "cmon_insecure_skip_verify": {{{cmon_insecure_skip_verify}}},
+{{/cmon_insecure_skip_verify}}
+{{#require_cns_resolver}}
+    "require_cns_resolver": {{{require_cns_resolver}}},
+{{/require_cns_resolver}}
+
+
+{{#is_manta_service}}
+    "is_manta_service": "{{{is_manta_service}}}",
+    "datacenter": "{{{DATACENTER}}}",
+    "dns_domain": "{{{DNS_DOMAIN}}}",
+{{/is_manta_service}}
+{{^is_manta_service}}
+    "is_manta_service": "false",
+{{/is_manta_service}}
+
+    {{! "_eof" is an unused key for convenience handling the trailing comma }}
+    "_eof": null
+}
diff --git a/setup-grafana.sh b/setup-grafana.sh
deleted file mode 100755
index f09ede0..0000000
--- a/setup-grafana.sh
+++ /dev/null
@@ -1,207 +0,0 @@
-#!/bin/bash
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-# Copyright (c) 2018 Joyent, Inc.
-#
-
-#
-# Run this on your laptop to setup a Triton "grafana0" zone on the given Triton
-# headnode. Typicallly you would have previously run `setup-prometheus.sh`
-# to have created a prometheus0 zone.
-#
-# On a new coal, run `trentops/bin/coal-post-setup.sh`, then:
-#
-#       ./tools/setup-grafana.sh coal
-#
-# Afterwords, it will print the URL to the Grafana. It is provisioned with the
-# latest dashboards defined in https://github.com/joyent/triton-grafana
-# It takes a few minutes though for the discovery process to complete before
-# you'll see any metrics.
-#
-
-IMAGE_UUID="7b5981c4-1889-11e7-b4c5-3f3bdfc9b88b" # LX Ubuntu 16.04
-MIN_MEMORY=1024
-GRAFANA_VERSION="5.2.2"
-ALIAS=grafana0
-
-HOST=$1
-if [[ -z "$HOST" ]]; then
-    echo "error: missing HEADNODE-GZ argument" >&2
-    echo "usage: ./setup-prometheus.sh HEADNODE-GZ" >&2
-    exit 1
-fi
-
-if [[ -z ${SSH_OPTS} ]]; then
-    SSH_OPTS=""
-fi
-
-# Code in this block runs on the remote system
-ssh ${SSH_OPTS} ${HOST} <<EOF
-
-set -o errexit
-if [[ -n "${TRACE}" ]]; then
-    set -o xtrace
-fi
-
-function fatal() {
-    echo "FATAL: \$*" >&2
-    exit 1
-}
-
-. ~/.bash_profile
-
-
-#
-# grafana0 zone creation
-#
-
-vm_uuid=\$(vmadm lookup alias=$ALIAS)
-[[ -z "\$vm_uuid" ]] || fatal "VM $ALIAS already exists"
-
-if ! sdc-imgadm get ${IMAGE_UUID} >/dev/null 2>&1; then
-    sdc-imgadm import -S https://images.joyent.com ${IMAGE_UUID} </dev/null
-fi
-
-headnode_uuid=\$(sysinfo | json UUID)
-admin_uuid=\$(sdc-useradm get admin | json uuid)
-admin_network_uuid=\$(sdc-napi /networks?name=admin | json -H 0.uuid)
-external_network_uuid=\$(sdc-napi /networks?name=external | json -H 0.uuid)
-package=\$(sdc-papi /packages | json -Ha uuid max_physical_memory | sort -n -k 2 \
-    | while read uuid mem; do
-
-    # Find the first one with at least ${MIN_MEMORY}
-    if [[ -z \${pkg} && \${mem} -ge ${MIN_MEMORY} ]]; then
-        pkg=\${uuid}
-        echo \${uuid}
-    fi
-done)
-
-prometheus_ip=\$(vmadm lookup -1 alias=prometheus0 -j \
-    | json 0.nics | json -c 'this.nic_tag === "admin"' 0.ip)
-[[ -n "\$prometheus_ip" ]] \
-    || fatal "could not find prometheus0 zone admin IP: have you setup a prometheus0 zone?"
-
-echo "Admin account: \${admin_uuid}"
-echo "Admin network: \${admin_network_uuid}"
-echo "External network: \${external_network_uuid}"
-echo "Headnode: \${headnode_uuid}"
-echo "Package: \${package}"
-echo "Alias: ${ALIAS}"
-
-[[ -n "\${admin_uuid}" ]] || fatal "missing admin UUID"
-[[ -n "\${headnode_uuid}" ]] || fatal "missing headnode UUID"
-[[ -n "\${admin_network_uuid}" ]] || fatal "missing admin network UUID"
-[[ -n "\${package}" ]] || fatal "missing package"
-
-# - networks: Need the 'admin' to access the prometheus0 zone. Need 'external'
-#   so, in general, an operator can reach it. WARNING: Need an auth story here.
-# - tags.smartdc_role: So 'sdc-login -l graf' works.
-echo "Creating VM ${ALIAS} ..."
-vm_uuid=\$((sdc-vmapi /vms?sync=true -X POST -d@/dev/stdin | json -H vm_uuid) <<PAYLOAD
-{
-    "alias": "${ALIAS}",
-    "billing_id": "\${package}",
-    "brand": "lx",
-    "image_uuid": "${IMAGE_UUID}",
-    "networks": [{"uuid": "\${admin_network_uuid}"}, {"uuid": "\${external_network_uuid}", "primary": true}],
-    "owner_uuid": "\${admin_uuid}",
-    "server_uuid": "\${headnode_uuid}",
-    "tags": {
-        "smartdc_role": "grafana"
-    }
-}
-PAYLOAD
-)
-
-
-#
-# Grafana setup.
-#
-
-grafana_ip=\$(vmadm get \${vm_uuid} | json nics | json -c 'this.primary' 0.ip)
-
-# Get the latest https://github.com/joyent/triton-grafana
-cd /zones/\${vm_uuid}/root/root
-curl -Lk -o triton-grafana-master.tgz https://github.com/joyent/triton-grafana/archive/master.tar.gz
-gtar -zxvf triton-grafana-master.tgz
-mv triton-grafana-master triton-grafana
-
-# Setup grafana.
-cd /zones/\${vm_uuid}/root/root
-curl -L -kO https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-${GRAFANA_VERSION}.linux-amd64.tar.gz
-gtar -zxvf grafana-${GRAFANA_VERSION}.linux-amd64.tar.gz
-ln -s grafana-${GRAFANA_VERSION} grafana
-cd grafana
-
-cat >./conf/provisioning/datasources/triton.yaml <<DATAYML
-# config file version
-apiVersion: 1
-
-datasources:
-    - name: Triton
-      type: prometheus
-      access: proxy
-      orgId: 1
-      url: http://\${prometheus_ip}:9090
-      isDefault: true
-      editable: true
-DATAYML
-
-cat >./conf/provisioning/dashboards/triton.yaml <<DASHYML
-# config file version
-apiVersion: 1
-
-providers:
-    - name: Triton
-      orgId: 1
-      folder: ''
-      type: file
-      options:
-        path: /root/triton-grafana/dashboards
-DASHYML
-
-# Generate grafana systemd manifest
-cat >/zones/\${vm_uuid}/root/etc/systemd/system/grafana.service <<SYSTEMD
-[Unit]
-	Description=Grafana server
-	After=network.target
-
-[Service]
-	WorkingDirectory=/root/grafana
-	StandardOutput=syslog
-	ExecStart=/root/grafana/bin/grafana-server
-	User=root
-
-[Install]
-	WantedBy=multi-user.target
-SYSTEMD
-
-zlogin \${vm_uuid} "systemctl daemon-reload && systemctl enable grafana && systemctl start grafana && systemctl status grafana" </dev/null
-
-sleep 5
-retries=10
-while [[ \${retries} -gt 0 ]]; do
-    if curl -sSf -u admin:admin "\${grafana_ip}:3000/api/search?type=dash-db&query=cnapi"; then
-        break;
-    fi
-    let "retries=retries-1"
-    sleep 5
-done
-
-# Set the CNAPI dashboard (for now) as the default org dashboard.
-alias json="/native/usr/node/bin/node /native/usr/bin/json"
-dashId=\$(curl -sSf -u admin:admin "\${grafana_ip}:3000/api/search?type=dash-db&query=cnapi" | json 0.id)
-curl -sSf -u admin:admin \${grafana_ip}:3000/api/org/preferences -H content-type:application/json \
-    -d '{"theme":"","homeDashboardId":'\$dashId',"timezone":"utc"}' -X PUT
-echo ""
-
-
-echo ""
-echo "* * * Successfully setup * * *"
-echo "Prometheus: http://\${prometheus_ip}:9090/"
-echo "Grafana: http://\${grafana_ip}:3000/ (admin:admin)"
-
-EOF
diff --git a/setup-prometheus-prod.sh b/setup-prometheus-lx.sh
similarity index 100%
rename from setup-prometheus-prod.sh
rename to setup-prometheus-lx.sh
diff --git a/setup-prometheus.sh b/setup-prometheus.sh
deleted file mode 100755
index a9f1ad8..0000000
--- a/setup-prometheus.sh
+++ /dev/null
@@ -1,233 +0,0 @@
-#!/bin/bash
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-# Copyright (c) 2018 Joyent, Inc.
-#
-
-#
-# This tool works to setup prometheus (and required cmon/cns bits) on a test
-# machine which has been setup with trentops:bin/coal-post-setup.sh or another
-# similar mechanism (e.g. globe-theatre nightly setup).
-#
-# On a new coal, run coal-post-setup.sh, then:
-#
-#  ./tools/setup-prom.sh coal
-#
-# and you should be able to then go to the prometheus page that gets spit out at
-# the end. It takes a few minutes though for the discovery process to complete
-# before you'll see any metrics.
-#
-
-IMAGE_UUID="7b5981c4-1889-11e7-b4c5-3f3bdfc9b88b" # LX Ubuntu 16.04
-MIN_MEMORY=1024
-PROMETHEUS_VERSION="2.3.2"
-ALIAS=prometheus0
-
-HOST=$1
-if [[ -z "$HOST" ]]; then
-    echo "error: missing HEADNODE-GZ argument" >&2
-    echo "usage: ./setup-prometheus.sh HEADNODE-GZ" >&2
-    exit 1
-fi
-
-if [[ -z ${SSH_OPTS} ]]; then
-    SSH_OPTS=""
-fi
-
-# Code in this block runs on the remote system
-ssh ${SSH_OPTS} ${HOST} <<EOF
-
-set -o errexit
-if [[ -n "${TRACE}" ]]; then
-    set -o xtrace
-fi
-
-function fatal() {
-    echo "FATAL: \$*" >&2
-    exit 1
-}
-
-. ~/.bash_profile
-
-
-#
-# prometheus0 zone creation
-#
-
-vm_uuid=\$(vmadm lookup alias=$ALIAS)
-[[ -z "\$vm_uuid" ]] || fatal "VM $ALIAS already exists"
-
-if ! sdc-imgadm get ${IMAGE_UUID} >/dev/null 2>&1; then
-    sdc-imgadm import -S https://images.joyent.com ${IMAGE_UUID} </dev/null
-fi
-
-# Setup for CNS to actually work
-sdc-useradm replace-attr admin approved_for_provisioning true </dev/null
-sdc-useradm replace-attr admin triton_cns_enabled true </dev/null
-sdc-login -l cns "svcadm restart cns-updater" </dev/null
-sdc-login -l cns "cnsadm vm \$(vmadm lookup alias=vmapi0)" </dev/null
-
-set -o errexit
-
-# need to provision to headnode so we can zlogin
-headnode_uuid=\$(sysinfo | json UUID)
-
-# Find admin uuid
-admin_uuid=\$(sdc-useradm get admin | json uuid)
-
-# Find network (we want to be on same one as cmon)
-network_uuid=\$(vmadm get \$(vmadm lookup alias=~^cmon | head -1) | json nics.1.network_uuid)
-admin_network_uuid=\$(sdc-napi /networks?name=admin | json -H 0.uuid)
-
-# Find package
-package=\$(sdc-papi /packages | json -Ha uuid max_physical_memory | sort -n -k 2 \
-    | while read uuid mem; do
-
-    # Find the first one with at least ${MIN_MEMORY}
-    if [[ -z \${pkg} && \${mem} -ge ${MIN_MEMORY} ]]; then
-        pkg=\${uuid}
-        echo \${uuid}
-    fi
-done)
-
-# Find CNS resolver(s)
-prometheus_dc=\$(bash /lib/sdc/config.sh -json | json datacenter_name)
-prometheus_domain=\$(bash /lib/sdc/config.sh -json | json dns_domain)
-
-binder_resolvers=\$(dig +short binder.\${prometheus_dc}.\${prometheus_domain} | tr '\n' ',' | sed -e "s/,$//")
-cns_resolvers=\$(dig +noall +answer +short @binder.\${prometheus_dc}.\${prometheus_domain} cns.\${prometheus_dc}.\${prometheus_domain} | tr '\n' ',' | sed -e "s/,$//")
-
-echo "Admin account: \${admin_uuid}"
-echo "Admin network: \${admin_network_uuid}"
-echo "Headnode: \${headnode_uuid}"
-echo "Network: \${network_uuid}"
-echo "Package: \${package}"
-echo "Alias: ${ALIAS}"
-echo "CNS Resolvers: \${cns_resolvers}"
-echo "Binder Resolvers: \${binder_resolvers}"
-
-[[ -n "\${admin_uuid}" ]] || fatal "missing admin UUID"
-[[ -n "\${headnode_uuid}" ]] || fatal "missing headnode UUID"
-[[ -n "\${network_uuid}" ]] || fatal "missing CMON network UUID"
-[[ -n "\${admin_network_uuid}" ]] || fatal "missing admin network UUID"
-[[ -n "\${package}" ]] || fatal "missing package"
-[[ -n "\${cns_resolvers}" ]] || fatal "missing CNS resolver"
-[[ -n "\${binder_resolvers}" ]] || fatal "missing binder resolver"
-
-# - user-script: Note that until TRITON-605 is resolved, net-agent will likely
-#   be undoing our explicit "resolvers" below. As a workaround we'll have a
-#   user-script that sorts it out on boot (see ./boot/configure.sh for a future
-#   alternative to this user-script).
-# - tags.smartdc_role: So 'sdc-login -l prom' works.
-echo "Creating VM ${ALIAS} ..."
-vm_uuid=\$((sdc-vmapi /vms?sync=true -X POST -d@/dev/stdin | json -H vm_uuid) <<PAYLOAD
-{
-    "alias": "${ALIAS}",
-    "billing_id": "\${package}",
-    "brand": "lx",
-    "image_uuid": "${IMAGE_UUID}",
-    "networks": [{"uuid": "\${admin_network_uuid}"}, {"uuid": "\${network_uuid}", "primary": true}],
-    "owner_uuid": "\${admin_uuid}",
-    "server_uuid": "\${headnode_uuid}",
-    "resolvers": ["\$(echo "\${cns_resolvers},\${binder_resolvers},8.8.8.8" | sed -e 's/,/","/g')"],
-    "customer_metadata": {
-        "cnsResolvers": "\${cns_resolvers}",
-        "user-script": "#!/bin/bash\n\nset -o errexit\nset -o pipefail\nset -o xtrace\n\nmdata-get cnsResolvers | tr , '\n' | while read ip; do\n        grep \"^nameserver \\\$ip$\" /etc/resolvconf/resolv.conf.d/head >/dev/null 2>&1 || echo \"nameserver \\\$ip\" >> /etc/resolvconf/resolv.conf.d/head;\n    done\nresolvconf -u\n\nexit 0\n"
-    },
-    "tags": {
-        "smartdc_role": "prometheus"
-    }
-}
-PAYLOAD
-)
-
-# Download the bits (since external resolvers not setup in zone)
-cd /zones/\${vm_uuid}/root/root
-curl -L -kO https://github.com/prometheus/prometheus/releases/download/v${PROMETHEUS_VERSION}/prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
-tar -zxvf prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
-ln -s prometheus-${PROMETHEUS_VERSION}.linux-amd64 prometheus
-cd prometheus
-
-# Generate/Register Cert/Key
-ssh-keygen -t rsa -f prometheus_key -N ''
-openssl rsa -in prometheus_key -outform pem >prometheus_key.priv.pem
-openssl req -new -key prometheus_key.priv.pem -out prometheus_key.csr.pem -subj "/CN=admin"
-openssl x509 -req -days 365 -in prometheus_key.csr.pem -signkey prometheus_key.priv.pem -out prometheus_key.pub.pem
-/opt/smartdc/bin/sdc-useradm add-key -f admin prometheus_key.pub
-
-# Generate Config
-prometheus_ip=\$(vmadm get \${vm_uuid} | json nics.1.ip)
-cns_zone="\${prometheus_dc}.cns.\${prometheus_domain}"
-
-cp prometheus.yml prometheus.yml.bak
-cat >prometheus.yml <<PROMYML
-# my global config
-global:
-  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
-  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
-  # scrape_timeout is set to the global default (10s).
-
-# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
-rule_files:
-  # - "first.rules"
-  # - "second.rules"
-
-# A scrape configuration containing exactly one endpoint to scrape:
-# Here it's Prometheus itself.
-scrape_configs:
-  # The job name is added as a label 'job=<job_name>' to any timeseries scraped from this config.
-  - job_name: 'admin_\${prometheus_dc}'
-    scheme: https
-    tls_config:
-      cert_file: /root/prometheus/prometheus_key.pub.pem
-      key_file: /root/prometheus/prometheus_key.priv.pem
-      insecure_skip_verify: true
-    relabel_configs:
-      - source_labels: [__meta_triton_machine_alias]
-        target_label: alias
-      - source_labels: [__meta_triton_machine_id]
-        target_label: instance
-    triton_sd_configs:
-      - account: 'admin'
-        dns_suffix: 'cmon.\${cns_zone}'
-        endpoint: 'cmon.\${cns_zone}'
-        version: 1
-        tls_config:
-          cert_file: /root/prometheus/prometheus_key.pub.pem
-          key_file: /root/prometheus/prometheus_key.priv.pem
-          insecure_skip_verify: true
-PROMYML
-
-# Generate systemd manifest
-cat >/zones/\${vm_uuid}/root/etc/systemd/system/prometheus.service <<SYSTEMD
-[Unit]
-    Description=Prometheus server
-    After=network.target
-
-[Service]
-    WorkingDirectory=/root/prometheus
-    StandardOutput=syslog
-    ExecStart=/root/prometheus/prometheus \\
-        --storage.tsdb.path=/root/prometheus/data \\
-        --config.file=/root/prometheus/prometheus.yml \\
-        --web.external-url=http://\${prometheus_ip}:9090/
-    User=root
-
-[Install]
-    WantedBy=multi-user.target
-SYSTEMD
-
-
-zlogin \${vm_uuid} "systemctl daemon-reload && systemctl enable prometheus && systemctl start prometheus && systemctl status prometheus" </dev/null
-
-echo ""
-echo "* * * Successfully setup * * *"
-echo "Prometheus: http://\${prometheus_ip}:9090/"
-echo ""
-echo "You can setup a grafana0 zone next via:"
-echo "    ./setup-grafana.sh $HOST"
-
-EOF
diff --git a/smf/manifests/prometheus.xml b/smf/manifests/prometheus.xml
new file mode 100644
index 0000000..ff82009
--- /dev/null
+++ b/smf/manifests/prometheus.xml
@@ -0,0 +1,96 @@
+<?xml version="1.0"?>
+<!DOCTYPE service_bundle SYSTEM "/usr/share/lib/xml/dtd/service_bundle.dtd.1">
+<!--
+        This Source Code Form is subject to the terms of the Mozilla Public
+        License, v. 2.0. If a copy of the MPL was not distributed with this
+        file, You can obtain one at http://mozilla.org/MPL/2.0/.
+-->
+
+<!--
+        Copyright (c) 2019, Joyent, Inc.
+-->
+
+<service_bundle type="manifest" name="prometheus">
+    <service
+        name="triton/site/prometheus"
+        type="service"
+        version="1.0.0">
+
+        <create_default_instance enabled="false"/>
+        <single_instance/>
+
+        <dependency
+            name="network"
+            grouping="require_all"
+            restart_on="error"
+            type="service">
+            <service_fmri value="svc:/milestone/network:default"/>
+        </dependency>
+
+        <dependency
+            name="filesystem"
+            grouping="require_all"
+            restart_on="error"
+            type="service">
+            <service_fmri value="svc:/system/filesystem/local"/>
+        </dependency>
+
+        <exec_method
+            type="method"
+            name="start"
+            exec="/opt/triton/prometheus/prometheus/prometheus --storage.tsdb.path=/data/prometheus/data --config.file=/opt/triton/prometheus/etc/prometheus.yml &amp;"
+            timeout_seconds="30">
+            <method_context working_directory="/opt/triton/prometheus">
+                <method_credential
+                    user="nobody"
+                    group="nobody"
+                    privileges="basic,net_privaddr"/>
+                <method_environment>
+                    <envvar
+                        name="PATH"
+                        value="/opt/local/bin:/usr/bin:/usr/sbin:/bin"/>
+                    <envvar
+                        name="LD_PRELOAD_32"
+                        value="/usr/lib/extendedFILE.so.1" />
+                </method_environment>
+            </method_context>
+        </exec_method>
+
+        <exec_method
+            type="method"
+            name="restart"
+            exec=":kill"
+            timeout_seconds="60">
+            <method_context working_directory="/opt/triton/prometheus" />
+        </exec_method>
+
+        <exec_method
+            type="method"
+            name="stop"
+            exec=":kill"
+            timeout_seconds="60">
+            <method_context working_directory="/opt/triton/prometheus" />
+        </exec_method>
+
+        <property_group
+            name="startd"
+            type="framework">
+            <propval
+                name="ignore_error"
+                type="astring"
+                value="core,signal"/>
+        </property_group>
+
+        <property_group
+            name="application"
+            type="application"/>
+
+        <stability value="Stable"/>
+
+        <template>
+            <common_name>
+                <loctext xml:lang="C">Triton Prometheus</loctext>
+            </common_name>
+        </template>
+    </service>
+</service_bundle>
diff --git a/tools/download_go b/tools/download_go
new file mode 100755
index 0000000..69e9a3e
--- /dev/null
+++ b/tools/download_go
@@ -0,0 +1,126 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2018, Joyent, Inc.
+#
+
+#
+# This program will download a Go toolchain for a particular system.  It
+# currently expects to find illumos builds of the toolchain on the Joyent
+# download server, where we will be placing them alongside sdcnode, etc.
+# The program is designed specifically to be used as part of a make target.
+#
+# We may revisit this once the Go project makes official builds for illumos
+# systems available in the future.
+#
+# NOTE: This program comes from the "eng" repo. It's designed to be dropped
+# into other repos as-is without requiring any modifications. If you find
+# yourself changing this file, you should instead update the original copy in
+# eng.git and then update your repo to use the new version.
+#
+
+#
+# This program accepts four arguments, in the following order:
+#
+#	GOVERSION	The version of the Go toolchain to use; e.g., "1.9.2"
+#	GOOS		The build machine operating system; e.g., "solaris"
+#	GOARCH		The build machine CPU architecture; e.g., "amd64"
+#	OUTDIR		The local directory into which the downloaded tar
+#			file will be placed.
+#
+# The program will use the provided arguments to find and download an archive
+# of the Go toolchain for use on the build machine.  The archive will be named
+# for a combination of the provided arguments; e.g.,
+# "go1.9.2.solaris-amd64.tar.bz2".  A target symbolic link will also be
+# created, with just the version number in the name; e.g., "go-1.9.2.tar.bz2".
+# If the archive could not be downloaded, an error message will be printed and
+# the output file and target link will be unaffected.
+#
+
+BASEURL='https://download.joyent.com/pub/build/go/adhoc/'
+GOVERSION=$1
+GOOS=$2
+GOARCH=$3
+OUTDIR=$4
+
+if [[ -z $GOVERSION || -z $GOOS || -z $GOARCH || -z $OUTDIR ]]; then
+	printf 'ERROR: usage: download_go GOVERSION GOOS GOARCH OUTDIR\n' 2>&1
+	exit 1
+fi
+
+if [[ ! -d $OUTDIR ]]; then
+	printf 'ERROR: output directory "%s" does not exist\n' "$OUTDIR" 2>&1
+	exit 1
+fi
+
+TARGET="go-$GOVERSION.tar.bz2"
+
+#
+# Download the index page which lists the current set of available go
+# builds:
+#
+if ! list=$(curl -sSfL "$BASEURL") || [[ -z "$list" ]]; then
+	printf 'ERROR: could not download index page\n' >&2
+	exit 1
+fi
+
+#
+# Using only commonly found household items, extract the full name of the
+# go tar archive we need.  This program needs to be able to operate in a
+# minimally populated build zone, so we avoid using anything beyond basic
+# UNIX tools like "awk".
+#
+# One word to describe this process might be "brittle".
+#
+if ! name=$(/usr/bin/awk -v "v=$GOVERSION" -v "o=$GOOS" -v "a=$GOARCH" -F\" '
+    BEGIN { pattern = "^go"v"."o"-"a".tar.bz2$"; }
+    $1 == "<a href=" && $2 ~ pattern { print $2 }' <<< "$list") ||
+    [[ -z "$name" ]]; then
+	printf 'ERROR: could not locate file name in index page\n' >&2
+	printf '\t(Does Go version %s (%s-%s) exist?)\n' \
+	    "$GOVERSION" "$GOOS" "$GOARCH" >&2
+	exit 1
+fi
+
+
+#
+# If the full file name of the latest go build does not exist, download it now
+# to a temporary file.  If it succeeds, move it into place.
+#
+output_file="$OUTDIR/$name"
+if [[ ! -f $output_file ]]; then
+	printf 'Downloading Go: %s\n' "$BASEURL$name"
+
+	temp_file="$OUTDIR/.tmp.$name.$$"
+	rm -f "$temp_file"
+
+	if ! curl -sSf -o "$temp_file" "$BASEURL$name"; then
+		printf 'ERROR: could not download go\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+
+	if ! mv "$temp_file" "$output_file"; then
+		printf 'ERROR: could not move tar file into place\n' >&2
+		rm -f "$temp_file"
+		exit 1
+	fi
+fi
+
+#
+# Make sure the target link points at the correct file:
+#
+rm -f "$OUTDIR/$TARGET"
+if ! ln -s "$name" "$OUTDIR/$TARGET"; then
+	printf 'ERROR: could not create target link\n' >&2
+	exit 1
+fi
+
+exit 0
+
+# vim: set ts=8 sts=8 sw=8 noet:
diff --git a/tools/mk/Makefile.defs b/tools/mk/Makefile.defs
deleted file mode 100644
index 73dd612..0000000
--- a/tools/mk/Makefile.defs
+++ /dev/null
@@ -1,105 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2018, Joyent, Inc.
-#
-
-#
-# Makefile.defs: common defines.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-# This makefile defines some useful defines. Include it at the top of
-# your Makefile.
-#
-# Definitions in this Makefile:
-#
-#	TOP 		The absolute path to the project directory. The top dir.
-#	BRANCH 		The current git branch.
-#	TIMESTAMP	The timestamp for the build. This can be set via
-#			the TIMESTAMP envvar (used by MG-based builds).
-#	STAMP		A build stamp to use in built package names.
-#
-#	MAKE_STAMPS_DIR	The directory in which make stamp files are to be
-#			created.  See comments below on expensive targets.
-#
-#	CACHE_DIR	A directory tree in which temporary files may be
-#			collected by download, tarball extraction, etc.  This
-#			directory is completely removed by "make distclean".
-#			Files in this directory are not intended to be shipped.
-#
-
-TOP := $(shell pwd)
-
-#
-# Mountain Gorilla-spec'd versioning.
-# See "Package Versioning" in MG's README.md:
-# <https://mo.joyent.com/mountain-gorilla/blob/master/README.md#L139-200>
-#
-# Need GNU awk for multi-char arg to "-F".
-_AWK := $(shell (which gawk >/dev/null && echo gawk) \
-	|| (which nawk >/dev/null && echo nawk) \
-	|| echo awk)
-BRANCH := $(shell git symbolic-ref HEAD | $(_AWK) -F/ '{print $$3}')
-ifeq ($(TIMESTAMP),)
-	TIMESTAMP := $(shell date -u "+%Y%m%dT%H%M%SZ")
-endif
-_GITDESCRIBE := g$(shell git describe --all --long --dirty | $(_AWK) -F'-g' '{print $$NF}')
-STAMP := $(BRANCH)-$(TIMESTAMP)-$(_GITDESCRIBE)
-
-# node-gyp will print build info useful for debugging with V=1
-export V=1
-
-CACHE_DIR ?=		cache
-DISTCLEAN_FILES +=	$(CACHE_DIR)
-
-#
-# EXPENSIVE TARGETS AND MAKE STAMP FILES
-#
-# Targets which are expensive to run and lack a single file that marks
-# completion are difficult to track with make; e.g., "npm install".  One
-# solution to this problem is to create "stamp" files with symbolic names which
-# are created as the final step in a complex make rule in order to mark
-# completion.
-#
-# In order to make these more uniform, and easier to target with "make clean",
-# we will attempt to store them under a single directory.  Note that these
-# files are never targets for shipping in build artefacts.
-#
-# Stamp-backed targets come in several parts.  First, a macro should be defined
-# which names a file in the MAKE_STAMPS_DIR directory.  Then, a target which
-# creates this stamp file must be provided.  The recipe for this target should
-# use MAKE_STAMP_REMOVE and MAKE_STAMP_CREATE to perform the appropriate stamp
-# management.
-#
-# For example:
-#
-# --- Makefile.*.defs:
-#
-#	$(STAMP_EXPENSIVE_RESULT) := $(MAKE_STAMPS_DIR)/expensive-result
-#
-# --- Makefile.*.targ:
-#
-#	$(STAMP_EXPENSIVE_RESULT): input/file another/input/file
-#		$(MAKE_STAMP_REMOVE)
-#		rm -rf output_tree/  # <--- ensure a clean slate
-#		expensive_program -o output_tree/ $^
-#		$(MAKE_STAMP_CREATE)
-#
-# NOTE: Every stamp file is exposed as an implicit "stamp-$STAMP_NAME" target.
-# The example above could be built manually by invoking:
-#
-#	make stamp-expensive-result
-#
-MAKE_STAMPS_DIR ?=	make_stamps
-CLEAN_FILES +=		$(MAKE_STAMPS_DIR)
-
-MAKE_STAMP_REMOVE =	mkdir -p $(@D); rm -f $(@)
-MAKE_STAMP_CREATE =	mkdir -p $(@D); touch $(@)
diff --git a/tools/mk/Makefile.deps b/tools/mk/Makefile.deps
deleted file mode 100644
index 91f8346..0000000
--- a/tools/mk/Makefile.deps
+++ /dev/null
@@ -1,87 +0,0 @@
-# -*- mode: makefile -*-
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.deps: Makefile for including common tools as dependencies
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-# This file is separate from Makefile.targ so that teams can choose
-# independently whether to use the common targets in Makefile.targ and the
-# common tools here.
-#
-
-#
-# javascriptlint
-#
-JSL_EXEC	?= deps/javascriptlint/build/install/jsl
-JSL		?= $(JSL_EXEC)
-
-$(JSL_EXEC): | deps/javascriptlint/.git
-	cd deps/javascriptlint && make install
-
-distclean::
-	if [[ -f deps/javascriptlint/Makefile ]]; then \
-		cd deps/javascriptlint && make clean; \
-	fi
-
-#
-# jsstyle
-#
-JSSTYLE_EXEC	?= deps/jsstyle/jsstyle
-JSSTYLE		?= $(JSSTYLE_EXEC)
-
-$(JSSTYLE_EXEC): | deps/jsstyle/.git
-
-#
-# eslint
-#
-ESLINT_EXEC	?= node_modules/.bin/eslint
-ifdef NODE
-    ESLINT	:= $(NODE) $(ESLINT_EXEC)
-else
-    ESLINT	?= $(ESLINT_EXEC)
-endif
-
-# Install eslint.
-#
-# The install of specific modules is to allow running "make check"
-# without having to do a complete install of all npm dependencies.
-#
-# NPM_EXEC will be defined if either of "Makefile.{node,node_prebuilt}.defs"
-# is included.
-ifdef NPM
-$(ESLINT_EXEC): package.json | $(NPM_EXEC)
-	ESLINT_VER=$$($(NODE) -e 'console.log(require("./package.json").devDependencies["eslint"] || "")') && \
-	    ESLINT_JOY_VER=$$($(NODE) -e 'console.log(require("./package.json").devDependencies["eslint-plugin-joyent"] || "")') && \
-	    [[ -n $$ESLINT_VER && -n $$ESLINT_JOY_VER ]] && \
-	    $(NPM) install --no-save eslint@$$ESLINT_VER eslint-plugin-joyent@$$ESLINT_JOY_VER && \
-	    touch $(ESLINT_EXEC)
-else
-$(ESLINT_EXEC): package.json
-	ESLINT_VER=$$(node -e 'console.log(require("./package.json").devDependencies["eslint"] || "")') && \
-	    ESLINT_JOY_VER=$$(node -e 'console.log(require("./package.json").devDependencies["eslint-plugin-joyent"] || "")') && \
-	    [[ -n $$ESLINT_VER && -n $$ESLINT_JOY_VER ]] && \
-	    npm install --no-save eslint@$$ESLINT_VER eslint-plugin-joyent@$$ESLINT_JOY_VER && \
-	    touch $(ESLINT_EXEC)
-endif
-
-#
-# restdown
-#
-RESTDOWN_EXEC	?= deps/restdown/bin/restdown
-RESTDOWN	?= python $(RESTDOWN_EXEC)
-$(RESTDOWN_EXEC): | deps/restdown/.git
-
-EXTRA_DOC_DEPS	?=
diff --git a/tools/mk/Makefile.go_prebuilt.defs b/tools/mk/Makefile.go_prebuilt.defs
deleted file mode 100644
index 23c2ed8..0000000
--- a/tools/mk/Makefile.go_prebuilt.defs
+++ /dev/null
@@ -1,132 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2018, Joyent, Inc.
-#
-
-#
-# Makefile.go_prebuilt.defs: Makefile for obtaining a prebuilt Go toolchain.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# This Makefile aids in the download and operation of a Go toolchain when
-# building software written in the Go language.  It provides as much isolation
-# from the broader build host as possible, including the provision of a
-# project-local GOPATH and GOROOT.
-#
-# This Makefile is intended to be used along with "Makefile.go_prebuilt.targ".
-#
-# When using this Makefile, you MUST define these variables before the include
-# directive:
-#
-#	GO_PREBUILT_VERSION	The version of the Go toolchain to download
-#				and use.  For example, "1.9".
-#
-# You MAY also specify the following variables:
-#
-#	GO_ENV			A list of environment variable specifications
-#				in shell syntax which will be prepended to Go
-#				toolchain invocations.  Using the "+=" operator,
-#				it is possible to add to the list without
-#				overriding the base environment specified by
-#				this Makefile.
-#
-# This Makefile provides definitions for the following variables:
-#
-#	GO_INSTALL		The location of the Go toolchain, relative
-#				to $(TOP).
-#
-#	GO_GOPATH		The location of the project-local GOPATH
-#				directory, relative to $(TOP).
-#
-#	GO			To be used in place of a bare invocation of
-#				"go"; e.g., "go build" would become
-#				"$(GO) build".  This invocation uses env(1)
-#				and $(GO_ENV) to construct an isolated
-#				environment.
-#
-
-ifndef TOP
-$(error You must include Makefile.defs before this makefile.)
-endif
-
-ifndef CACHE_DIR
-$(error You must include Makefile.defs before this makefile.)
-endif
-
-ifndef GO_PREBUILT_VERSION
-$(error GO_PREBUILT_VERSION must be set before including this makefile.)
-endif
-
-GO_VERSION =			$(GO_PREBUILT_VERSION)
-
-#
-# This Makefile is presently used to build programs written in the Go language
-# to be shipped in zone images.  As such, we default to a target specification
-# which is appropriate for an illumos host.
-#
-GO_GOOS ?=			solaris
-GO_GOARCH ?=			amd64
-
-#
-# The "tools/download_go" script will obtain a Go toolchain tar archive, which
-# we will store in the $(CACHE_DIR).  This directory is be removed entirely by
-# "make distclean".
-#
-GO_TARBALL =			$(CACHE_DIR)/go-$(GO_PREBUILT_VERSION).tar.bz2
-
-#
-# The downloaded Go toolchain will be extracted into a directory under
-# $(CACHE_DIR) by the $(STAMP_GO_TOOLCHAIN) target.  This directory becomes
-# the value of $GOROOT for toolchain invocations.
-#
-GO_INSTALL =			$(CACHE_DIR)/go-$(GO_VERSION)
-
-#
-# Parts of the Go toolchain store intermediate build artefacts in the GOPATH
-# directory.  At the time of writing, at least some of these intermediate
-# artefacts cannot be reused by different versions of the toolchain.  There
-# does not appear to be any mechanism in place to _prevent_ an error of this
-# type, so we include the Go toolchain version in the project-local GOPATH
-# directory name.
-#
-GO_GOPATH =			$(CACHE_DIR)/gopath-$(GO_VERSION)
-
-#
-# The Go toolchain derives some amount of behaviour from the environment.  In
-# order to precisely control that behaviour, we build up our own environment
-# containing only the expected values and run the tool under "env -i", thus
-# precluding any other variables from leaking in:
-#
-GO_ENV +=			GOROOT="$(TOP)/$(GO_INSTALL)"
-GO_ENV +=			GOPATH="$(TOP)/$(GO_GOPATH)"
-GO_ENV +=			GOARCH="$(GO_GOARCH)"
-GO_ENV +=			GOOS="$(GO_GOOS)"
-GO_ENV +=			PATH="$(TOP)/$(GO_INSTALL)/bin:$$PATH"
-
-#
-# The $(GO) variable should be used in place of bare invocations of "go".
-# For example, instead of "go build", use "$(GO) build".
-#
-GO =				env -i $(GO_ENV) $(TOP)/$(GO_INSTALL)/bin/go
-
-#
-# If the version of Go is changed in the Makefile, or interactively, we need
-# to make sure the new version is downloaded and installed.  As such, the
-# stamp name needs to include the version.
-#
-STAMP_GO_TOOLCHAIN =		$(MAKE_STAMPS_DIR)/go-toolchain-$(GO_VERSION)
-
-#
-# A regular "make clean" should remove any cached build artefacts from GOPATH.
-#
-CLEAN_FILES +=			$(GO_GOPATH)
diff --git a/tools/mk/Makefile.go_prebuilt.targ b/tools/mk/Makefile.go_prebuilt.targ
deleted file mode 100644
index d0f998c..0000000
--- a/tools/mk/Makefile.go_prebuilt.targ
+++ /dev/null
@@ -1,55 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2018, Joyent, Inc.
-#
-
-#
-# Makefile.go_prebuilt.targ: Makefile for obtaining a prebuilt Go toolchain.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# For usage documentation, see the comments in "Makefile.go_prebuilt.defs".
-#
-
-ifndef GO_TARBALL
-$(error You must include Makefile.go_prebuilt.defs first.)
-endif
-
-#
-# Download a prebuilt copy of the Go toolchain.  There are not presently builds
-# available for illumos systems on the official Go site, so we have an
-# appropriate build stored on a Joyent server.
-#
-# Note that the GOOS and GOARCH values provided here are for the toolchain to
-# run on this machine: the build machine.  The Go toolchain is a cross
-# compiler, and the GO_GOOS and GO_GOARCH make variables represent the intended
-# _target_ for any executables built with the Go compiler.  Though it is
-# likely, at least for now, that these values are the same in our environment
-# for the build and target machines, they are nonetheless distinct concepts and
-# the use of GO_GOOS and GO_GOARCH here would not be correct.
-#
-$(GO_TARBALL):
-	rm -f $@
-	mkdir -p $(@D)
-	tools/download_go $(GO_PREBUILT_VERSION) solaris amd64 $(CACHE_DIR)
-
-#
-# Extract the Go toolchain.  This stamp includes the version number of the
-# Go toolchain, ensuring a new download and extraction if the version changes.
-#
-$(STAMP_GO_TOOLCHAIN): $(GO_TARBALL)
-	$(MAKE_STAMP_REMOVE)
-	rm -rf $(GO_INSTALL)
-	mkdir $(GO_INSTALL)
-	cd $(GO_INSTALL) && tar xfj $(TOP)/$(GO_TARBALL)
-	$(MAKE_STAMP_CREATE)
diff --git a/tools/mk/Makefile.manpages.defs b/tools/mk/Makefile.manpages.defs
deleted file mode 100644
index 6da7876..0000000
--- a/tools/mk/Makefile.manpages.defs
+++ /dev/null
@@ -1,128 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2016, Joyent, Inc.
-#
-
-#
-# Makefile.manpages.defs: targets for building manual pages.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# This Makefile is used along with Makefile.manpages.targ to build section
-# manpages for the current repository from Markdown sources using the md2man
-# tool.  You can build several different sections of manpages with this
-# Makefile, but you'll need to include the Makefile once for each section with a
-# different value of MAN_SECTION.  Required input variables include:
-#
-#     MAN_SECTION	defines which section's manpages will be built
-#     			(e.g., "1")
-#
-#     MAN_INROOT	defines the root of a directory tree containing man
-#     			pages source files in Markdown format.  The directory
-#     			tree should be organized as:
-#
-#     			    $(MAN_INROOT)/man$(MAN_SECTION)/*.md
-#
-#     MAN_OUTROOT	defines the root of a directory tree that will contain
-#     			the generated man pages.  The directory tree will be
-#     			organized as:
-#
-#     			    $(MAN_OUTROOT)/man$(MAN_SECTION)/*.$(MAN_SECTION)
-#
-#			This should mirror the typical man page directory
-#			structure, and should probably be alongside a
-#			corresponding "bin" directory to leverage the way
-#			man(1)'s looks up man pages for binaries.
-#
-# A common configuration would be to set MAN_INROOT = "docs/man" and
-# MAN_OUTROOT = "man".  In that case, you might have source files:
-#
-#     ./bin/mytool
-#     ./bin/my-other-tool
-#     ./docs/man/man1/mytool.md
-#     ./docs/man/man1/my-other-tool.md
-#
-# and that will generate files:
-#
-#     ./man/man1/mytool.1
-#     ./man/man1/my-other-tool.1
-#
-# Optional input variables include:
-#
-#     MD2MAN		tool to generate man pages from Markdown sources
-#     			The recommended tool is md2man-roff, available at
-#     			https://github.com/sunaku/md2man.
-#
-#     MKDIRP		should generally be "mkdir -p"
-#
-# This Makefile produces Make variables:
-#
-#     MAN_$(MAN_SECTION)_OUTPUTS	generated manual pages.  You can depend
-#     					on these in order to build them in
-#     					whatever top-level targets you want.
-#
-#     MAN_OUTPUTS			will be extended to include
-#     					MAN_$(MAN_SECTION)_OUTPUTS.
-#
-# There are two basic ways this tends to be used:
-#
-#     (1) Building manpages is part of the normal build.  Have the default
-#         target (usually "all") depends on either "manpages" or the built man
-#         pages directly (via MAN_OUTPAGES).  In this case, only the man pages
-#         _sources_ would be checked into source control.
-#
-#     (2) Building manpages is an ad-hoc operation outside the normal build
-#         process.  Developers that change the man page sources are expected to
-#         build the man pages and commit the generated pages into source
-#         control.
-#
-# Option (1) is preferred, since option (2) violates the basic tenets of
-# software engineering that processes should generally be automated and that
-# generated files should not be checked into source control.  The problem is
-# that in practice, the tools that we use to generate man pages are not widely
-# installed on most users' systems, even developers' systems, so it's less than
-# ideal to require them for the main build.  This is especially true for many of
-# our Node modules, where there's traditionally no difference between the
-# published npm package and the repository source itself.  As a result, we use
-# option (2) in most places.  However, this Makefile supports both modes.
-#
-
-MAN_SECTION			?= $(error MAN_SECTION is not defined)
-MAN_INROOT			?= $(error MAN_INROOT is not defined)
-MAN_OUTROOT			?= $(error MAN_OUTROOT is not defined)
-MD2MAN				?= md2man-roff
-MKDIRP				?= mkdir -p
-
-#
-# Define some convenience variables for referring to the input and output
-# directories for this section's man pages.  These variables must have
-# MAN_SECTION in the name, and must use eager binding (":="), since MAN_SECTION
-# may change after this file is included.
-#
-MAN_INDIR_$(MAN_SECTION)	:= $(MAN_INROOT)/man$(MAN_SECTION)
-MAN_OUTDIR_$(MAN_SECTION)	:= $(MAN_OUTROOT)/man$(MAN_SECTION)
-
-#
-# Define the lists of input and output files for this section's man pages.  The
-# list of inputs is just the list of Markdown files in the input directory.  We
-# construct the list of outputs by taking that same list and replacing the
-# section-specific input directory with the section-specific output directory
-# and changing the file extension.
-#
-MAN_$(MAN_SECTION)_INPUTS	:= $(wildcard $(MAN_INDIR_$(MAN_SECTION))/*.md)
-MAN_$(MAN_SECTION)_OUTPUTS_TMP  := \
-    $(MAN_$(MAN_SECTION)_INPUTS:$(MAN_INDIR_$(MAN_SECTION))/%=$(MAN_OUTDIR_$(MAN_SECTION))/%)
-MAN_$(MAN_SECTION)_OUTPUTS	:= \
-    $(MAN_$(MAN_SECTION)_OUTPUTS_TMP:%.md=%.$(MAN_SECTION))
-
-MAN_OUTPUTS			:= $(MAN_OUTPUTS) $(MAN_$(MAN_SECTION)_OUTPUTS)
diff --git a/tools/mk/Makefile.manpages.targ b/tools/mk/Makefile.manpages.targ
deleted file mode 100644
index 11f242b..0000000
--- a/tools/mk/Makefile.manpages.targ
+++ /dev/null
@@ -1,28 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2016, Joyent, Inc.
-#
-
-#
-# Makefile.manpages.targ: targets for building manual pages.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# See Makefile.manpages.defs.
-#
-
-$(MAN_$(MAN_SECTION)_OUTPUTS): $(MAN_OUTDIR_$(MAN_SECTION))/%.$(MAN_SECTION): $(MAN_INDIR_$(MAN_SECTION))/%.md | $(MAN_OUTDIR_$(MAN_SECTION))
-	$(MD2MAN) $^ > $@
-
-$(MAN_OUTDIR_$(MAN_SECTION)):
-	$(MKDIRP) $@
diff --git a/tools/mk/Makefile.node.defs b/tools/mk/Makefile.node.defs
deleted file mode 100644
index 487824d..0000000
--- a/tools/mk/Makefile.node.defs
+++ /dev/null
@@ -1,110 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.node.defs: Makefile for building and bundling your own Node.js.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# This Makefile facilitates building and bundling your own copy of Node.js in
-# your repo.  All it does is define variables for node, node-waf, and npm for
-# you to use elsewhere in your Makefile and rules to build these tools when
-# needed.
-#
-# To use this facility, include "Makefile.node.defs", use the variables as
-# described below to define targets, and then include "Makefile.node.targ".
-#
-# There are two use cases addressed here:
-#
-# (1) Invoking node, node-waf, or npm as part of the build process, as in "npm
-#     install" and "node-waf configure build".  To facilitate this, this
-#     Makefile defines Make variables NODE, NODE_WAF, and NPM that you can use
-#     to invoke these commands during the build process.  You MUST NOT assume
-#     that these variables just evaluate to the filenames themselves, as they
-#     may have environment variable definitions and other things that prevent
-#     you from using them directly as a filename.  If you want that, see (2).
-#
-#     Wherever you use one of these variables, you MUST include a dependency on
-#     the corresponding *_EXEC variable as well, like so:
-#
-#	node_modules/restify: deps/restify $(NPM_EXEC)
-#		$(NPM) install deps/restify
-#
-#     or better, use an order-only dependency to avoid spurious rebuilds:
-#
-#	node_modules/restify: deps/restify | $(NPM_EXEC)
-#		$(NPM) install deps/restify
-#
-#     Otherwise, the underlying file will not get built.  We don't
-#     automatically build them as part of "all" because that approach is
-#     brittle.
-#
-# (2) Specifying paths for invoking node, node-waf, or npm at RUNTIME, as in
-#     specifying the path to node used for the start method of your service's
-#     SMF manifest.  For this, this Makefile defines variables NODE_EXEC,
-#     NODE_WAF_EXEC, and NPM_EXEC, which represent the relative paths of these
-#     files from the root of the workspace.  You MUST NOT use these variables
-#     to invoke these commands during the build process.  See (1) instead.
-#
-#     However, in order to work at runtime, you must build the tool as well.
-#     That is, if you use NODE_EXEC to specify the path to node, you must
-#     depend on NODE_EXEC somewhere. This usually happens anyway because you
-#     usually need them during the build process too, but if you don't then
-#     you need to explicitly add NODE_EXEC (or whichever) to your "all"
-#     target.
-#
-# When including this Makefile, you MAY also specify:
-#
-#	BUILD			top-level directory for built binaries
-#				(default: "build")
-#
-#	NODE_INSTALL		where node should install its built items
-#				(default: "$BUILD/node")
-#
-#	NODE_CONFIG_FLAGS	extra flags to pass to Node's "configure"
-#				(default: "--with-dtrace" on SmartOS; empty
-#				otherwise.)
-#
-
-TOP ?= $(error You must include Makefile.defs before this makefile)
-
-BUILD		?= build
-NODE_INSTALL 	?= $(BUILD)/node
-DISTCLEAN_FILES	+= $(NODE_INSTALL)
-
-NODE_CONFIG_FLAGS += --prefix=$(TOP)/$(NODE_INSTALL)
-
-ifeq ($(shell uname -s),SunOS)
-	NODE_CONFIG_FLAGS += 	--with-dtrace \
-				--openssl-libpath=/opt/local/lib \
-				--openssl-includes=/opt/local/include
-endif
-
-NODE_EXEC	= $(NODE_INSTALL)/bin/node
-NODE_WAF_EXEC	= $(NODE_INSTALL)/bin/node-waf
-NPM_EXEC	= $(NODE_INSTALL)/bin/npm
-
-#
-# These paths should be used during the build process to invoke Node and
-# Node-related build tools like NPM.  All paths are fully qualified so that
-# they work regardless of the current working directory at the point of
-# invocation.
-#
-# Note that where PATH is overridden, the value chosen must cause execution of
-# "node" to find the same binary to which the NODE macro refers.
-#
-NODE		:= $(TOP)/$(NODE_EXEC)
-NODE_WAF	:= $(TOP)/$(NODE_WAF_EXEC)
-NPM		:= PATH=$(TOP)/$(NODE_INSTALL)/bin:$(PATH) $(NODE) $(TOP)/$(NPM_EXEC)
diff --git a/tools/mk/Makefile.node.targ b/tools/mk/Makefile.node.targ
deleted file mode 100644
index bf53f78..0000000
--- a/tools/mk/Makefile.node.targ
+++ /dev/null
@@ -1,42 +0,0 @@
-# -*- mode: makefile -*-
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2014, Joyent, Inc.
-#
-
-#
-# Makefile.node.targ: See Makefile.node.defs.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-ifneq ($(shell uname -s),SunOS)
-NODE_PREBUILT_VERSION ?= $(error You must define NODE_PREBUILT_VERSION to use Makefile.node.targ on non-SunOS)
-endif
-
-ifeq ($(shell uname -s),SunOS)
-$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC): | deps/node/.git
-	(cd deps/node; ./configure $(NODE_CONFIG_FLAGS) && $(MAKE) && $(MAKE) install)
-else
-$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC):
-	(mkdir -p $(BUILD) \
-		&& cd $(BUILD) \
-		&& [[ -d src-node ]] && (cd src-node && git checkout master && git pull) || git clone https://github.com/joyent/node.git src-node \
-		&& cd src-node \
-		&& git checkout $(NODE_PREBUILT_VERSION) \
-		&& ./configure $(NODE_CONFIG_FLAGS) \
-		&& $(MAKE) && $(MAKE) install)
-endif
-
-DISTCLEAN_FILES += $(NODE_INSTALL) $(BUILD)/src-node
-
-distclean::
-	-([[ ! -d deps/node ]] || (cd deps/node && $(MAKE) distclean))
diff --git a/tools/mk/Makefile.node_modules.defs b/tools/mk/Makefile.node_modules.defs
deleted file mode 100644
index ec8cc8e..0000000
--- a/tools/mk/Makefile.node_modules.defs
+++ /dev/null
@@ -1,68 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.node_modules.defs: Makefile for using NPM modules.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# This Makefile provides a target for building NPM modules from the dependency
-# information in the "package.json" file.  The "npm install" operation is
-# expensive and produces a complex (multi-file) result which is difficult for
-# make to use in dependency analysis.  As such, we use a "stamp" file to track
-# successful completion of module installation.
-#
-# This variable allows the consumer to influence the environment used to run
-# NPM commands.
-#
-#	NPM_ENV			This string should be set to a list of
-#				environment variables in the syntax used
-#				by bash; e.g.,
-#
-#					NPM_ENV =	TESTING=yes V=1
-#
-# Consumers should, for targets which depend on the installation of NPM
-# modules, depend on the stamp file using the $(STAMP_NODE_MODULES) variable,
-# e.g.:
-#
-#	.PHONY: all
-#	all: $(STAMP_NODE_MODULES)
-#
-# A phony target, "make stamp-node-modules", is also provided to allow the
-# engineer to manually perform NPM module installation without invoking other
-# targets.  Note that this target should _not_ be used as a dependency for
-# other targets in consuming Makefiles; using phony targets to represent
-# intermediate build stages can inhibit the ability of make to determine
-# when no additional actions are required.
-#
-
-TOP ?= $(error You must include Makefile.defs before this makefile)
-NPM ?= $(error You must include either Makefile.node.defs or \
-    Makefile.node_prebuilt.defs before this makefile)
-
-BUILD ?=		build
-
-#
-# Invoking "npm install" at the top-level will create a "node_modules"
-# directory into which NPM modules will be installed.
-#
-CLEAN_FILES +=		node_modules
-
-#
-# To avoid repeatedly reinstalling from NPM, we create a "stamp" file to track
-# successful runs of "npm install".  Note that MAKE_STAMPS_DIR is included
-# in CLEAN_FILES already.
-#
-STAMP_NODE_MODULES ?=	$(MAKE_STAMPS_DIR)/node-modules
diff --git a/tools/mk/Makefile.node_modules.targ b/tools/mk/Makefile.node_modules.targ
deleted file mode 100644
index 0156bce..0000000
--- a/tools/mk/Makefile.node_modules.targ
+++ /dev/null
@@ -1,31 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.node_modules.targ: See comments in Makefile.node_modules.defs.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-STAMP_NODE_MODULES ?= $(error You must include Makefile.node_modules.defs \
-    before this file)
-
-#
-# If the "package.json" file changes, we need to rebuild the contents of
-# the "node_modules" directory.
-#
-$(STAMP_NODE_MODULES): package.json | $(NPM_EXEC)
-	$(MAKE_STAMP_REMOVE)
-	rm -rf node_modules
-	$(NPM_ENV) $(NPM) install
-	$(MAKE_STAMP_CREATE)
diff --git a/tools/mk/Makefile.node_prebuilt.defs b/tools/mk/Makefile.node_prebuilt.defs
deleted file mode 100644
index 2129742..0000000
--- a/tools/mk/Makefile.node_prebuilt.defs
+++ /dev/null
@@ -1,159 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.node_prebuilt.defs: Makefile for including a prebuilt Node.js build.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-
-#
-# This Makefile facilitates downloading and bundling a prebuilt node.js
-# build (using the 'sdcnode' distro builds). This is an alternative to
-# the "Makefile.node.*" makefiles for *building* a node from source.
-#
-# Usage:
-#
-# - Define `NODE_PREBUILT_VERSION` in your Makefile to choose a node version.
-#   E.g.: `NODE_PREBUILT_VERSION=v0.6.19`. See other optional variables
-#   below.
-# - `include tools/mk/Makefile.node_prebuilt.defs` after this in your Makefile.
-# - `include tools/mk/Makefile.node_prebuilt.targ` near the end of your
-#   Makefile.
-# - Have at least one of your Makefile targets depend on either `$(NODE_EXEC)`
-#   or `$(NPM_EXEC)`. E.g.:
-#
-#		node_modules/restify: deps/restify $(NPM_EXEC)
-#			$(NPM) install deps/restify
-#
-#   or better, use an order-only dependency to avoid spurious rebuilds:
-#
-#		node_modules/restify: deps/restify | $(NPM_EXEC)
-#			$(NPM) install deps/restify
-#
-# - Use `$(NPM)` or `$(NODE)` to use your node build.
-# - Include the "$(NODE_INSTALL)" tree in your release package.
-#
-#
-# When including this Makefile, you MUST also specify:
-#
-#	NODE_PREBUILT_VERSION 	The node version in the prebuilt 'sdcnode'
-#				package to use. Typically this is one of the
-#				node version tags, e.g. "v0.6.18" but it
-#				can be any commitish.
-#
-# When including this Makefile, you MAY also specify:
-#
-#	NODE_PREBUILT_DIR 	The dir in which to find sdcnode builds. This
-#				can either be a *local directory* or *a
-#				URL* dir (with trailing '/') which serves
-#				Apache/Nginx dir listing HTML.
-#				(default: sdcnode master build dir on stuff)
-#
-#	NODE_PREBUILT_TAG	The 'sdcnode' project supports special
-#				configuration builds of node, e.g. say a
-#				build configured `--without-ssl`. These
-#				special configurations are given a tag, e.g.
-#				'gz', that is used in the filename. Optionally
-#				specify a tag name here.
-#				(default: empty)
-#
-#	NODE_PREBUILT_BRANCH	Specify a particular branch of 'sdcnode' builds
-#				from which to pull. Generally one should stick
-#				with the default.
-#				(default: master)
-#
-#	NODE_PREBUILT_IMAGE		If you have a zone image that differs from that
-#				for an sdcnode build that you want to use (potential compat
-#				issues be damned), then set this to the UUID of the sdcnode
-#				build you want. See here for available build image uuids:
-#				<https://download.joyent.com/pub/build/sdcnode/master-latest/sdcnode/>
-#
-#	BUILD			top-level directory for built binaries
-#				(default: "build")
-#
-#	NODE_INSTALL		where node should install its built items
-#				(default: "$BUILD/node")
-#
-#
-# Dev Notes:
-#
-# This works by getting "NODE_PREBUILT_NAME" from the provided "NODE_PREBUILT_*"
-# vars and the image version (via 'mdata-get sdc:image_uuid'). The image uuid is
-# included to ensure an exact match with the build machine. This name (e.g.
-# "v0.6.18-zone-$uuid") is used to find a matching "sdcnode-$name-*.tgz" build
-# in "NODE_PREBUILT_DIR" (either a local directory or a URL). That tarball is
-# downloaded and extracted into "NODE_INSTALL".
-#
-# The "*_EXEC" vars are set to named symlinks, e.g.
-# "build/prebuilt-node-v0.6.18-$uuid", so that a change of selected node
-# build (say the developer changes NODE_PREBUILT_VERSION) will recreate the
-# node install.
-#
-# See <https://mo.joyent.com/docs/sdcnode/master/> for details on 'sdcnode-*'
-# package naming.
-#
-
-TOP ?= $(error You must include Makefile.defs before this makefile)
-NODE_PREBUILT_VERSION ?= $(error NODE_PREBUILT_VERSION is not set.)
-
-
-BUILD		?= build
-NODE_INSTALL	?= $(BUILD)/node
-DISTCLEAN_FILES	+= $(NODE_INSTALL) \
-	$(BUILD)/prebuilt-node-* $(BUILD)/prebuilt-npm-*
-
-NODE_PREBUILT_BRANCH ?= master
-NODE_PREBUILT_IMAGE ?= $(shell pfexec mdata-get sdc:image_uuid)
-ifeq ($(NODE_PREBUILT_TAG),)
-	NODE_PREBUILT_NAME := $(NODE_PREBUILT_VERSION)-$(NODE_PREBUILT_IMAGE)
-else
-	NODE_PREBUILT_NAME := $(NODE_PREBUILT_VERSION)-$(NODE_PREBUILT_TAG)-$(NODE_PREBUILT_IMAGE)
-endif
-NODE_PREBUILT_PATTERN := sdcnode-$(NODE_PREBUILT_NAME)-$(NODE_PREBUILT_BRANCH)-.*\.tgz
-NODE_PREBUILT_DIR ?= https://download.joyent.com/pub/build/sdcnode/$(NODE_PREBUILT_IMAGE)/$(NODE_PREBUILT_BRANCH)-latest/sdcnode/
-ifeq ($(shell echo $(NODE_PREBUILT_DIR) | cut -c 1-4),http)
-	NODE_PREBUILT_BASE := $(shell curl -ksS --fail --connect-timeout 30 $(NODE_PREBUILT_DIR) | grep 'href=' | cut -d'"' -f2 | grep "^$(NODE_PREBUILT_PATTERN)$$" | sort | tail -1)
-	ifneq ($(NODE_PREBUILT_BASE),)
-		NODE_PREBUILT_TARBALL := $(NODE_PREBUILT_DIR)$(NODE_PREBUILT_BASE)
-	endif
-else
-	NODE_PREBUILT_BASE := $(shell ls -1 $(NODE_PREBUILT_DIR)/ | grep "^$(NODE_PREBUILT_PATTERN)$$" 2>/dev/null | sort | tail -1)
-	ifneq ($(NODE_PREBUILT_BASE),)
-		NODE_PREBUILT_TARBALL := $(NODE_PREBUILT_DIR)/$(NODE_PREBUILT_BASE)
-	endif
-endif
-ifeq ($(NODE_PREBUILT_TARBALL),)
-	NODE_PREBUILT_TARBALL = $(error NODE_PREBUILT_TARBALL is empty: no '$(NODE_PREBUILT_DIR)/$(NODE_PREBUILT_PATTERN)' found)
-endif
-
-
-# Prebuild-specific paths for the "*_EXEC" vars to ensure that
-# a prebuild change (e.g. if master Makefile's NODE_PREBUILT_VERSION
-# choice changes) causes a install of the new node.
-NODE_EXEC	:= $(BUILD)/prebuilt-node-$(NODE_PREBUILT_NAME)
-NODE_WAF_EXEC	:= $(BUILD)/prebuilt-node-waf-$(NODE_PREBUILT_NAME)
-NPM_EXEC	:= $(BUILD)/prebuilt-npm-$(NODE_PREBUILT_NAME)
-
-#
-# These paths should be used during the build process to invoke Node and
-# Node-related build tools like NPM.  All paths are fully qualified so that
-# they work regardless of the current working directory at the point of
-# invocation.
-#
-# Note that where PATH is overridden, the value chosen must cause execution of
-# "node" to find the same binary to which the NODE macro refers.
-#
-NODE		:= $(TOP)/$(NODE_INSTALL)/bin/node
-NODE_WAF	:= $(TOP)/$(NODE_INSTALL)/bin/node-waf
-NPM		:= PATH=$(TOP)/$(NODE_INSTALL)/bin:$(PATH) $(NODE) $(TOP)/$(NODE_INSTALL)/bin/npm
diff --git a/tools/mk/Makefile.node_prebuilt.targ b/tools/mk/Makefile.node_prebuilt.targ
deleted file mode 100644
index 6877333..0000000
--- a/tools/mk/Makefile.node_prebuilt.targ
+++ /dev/null
@@ -1,42 +0,0 @@
-# -*- mode: makefile -*-
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2014, Joyent, Inc.
-#
-
-#
-# Makefile.node_prebuilt.targ: Makefile for including a prebuilt Node.js
-# build.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-
-
-NODE_PREBUILT_TARBALL ?= $(error NODE_PREBUILT_TARBALL is not set: was Makefile.node_prebuilt.defs included?)
-
-
-# TODO: remove this limitation
-# Limitation: currently presuming that the NODE_INSTALL basename is
-# 'node' and that sdcnode tarballs have a 'node' top-level dir.
-$(NODE_EXEC) $(NPM_EXEC) $(NODE_WAF_EXEC):
-	[[ $(shell basename $(NODE_INSTALL)) == "node" ]] \
-		|| (echo "Limitation: 'basename NODE_INSTALL' is not 'node'" && exit 1)
-	rm -rf $(NODE_INSTALL) \
-		$(BUILD)/prebuilt-node-* $(BUILD)/prebuilt-npm-*
-	mkdir -p $(shell dirname $(NODE_INSTALL))
-	if [[ $(shell echo $(NODE_PREBUILT_TARBALL) | cut -c 1-4) == "http" ]]; then \
-		echo "Downloading '$(NODE_PREBUILT_BASE)'."; \
-		curl -ksS --fail --connect-timeout 30 -o $(shell dirname $(NODE_INSTALL))/$(NODE_PREBUILT_BASE) $(NODE_PREBUILT_TARBALL); \
-		(cd $(shell dirname $(NODE_INSTALL)) && $(TAR) xf $(NODE_PREBUILT_BASE)); \
-	else \
-		(cd $(shell dirname $(NODE_INSTALL)) && $(TAR) xf $(NODE_PREBUILT_TARBALL)); \
-	fi
-	ln -s $(TOP)/$(NODE_INSTALL)/bin/node $(NODE_EXEC)
-	ln -s $(TOP)/$(NODE_INSTALL)/bin/npm $(NPM_EXEC)
diff --git a/tools/mk/Makefile.smf.defs b/tools/mk/Makefile.smf.defs
deleted file mode 100644
index b988bbe..0000000
--- a/tools/mk/Makefile.smf.defs
+++ /dev/null
@@ -1,40 +0,0 @@
-# -*- mode: makefile -*-
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2014, Joyent, Inc.
-#
-
-#
-# Makefile.smf.defs: common targets for SMF manifests
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-# This Makefile uses the following definitions:
-#
-#	SMF_MANIFESTS_IN	Source files for SMF manifests.  The following
-#				substitutions will be made on these files:
-#
-#		@@NODE@@	path to installed node
-#
-# It updates SMF_MANIFESTS with the set of files generated by SMF_MANIFESTS_IN.
-# It also updates the "check" target to check the XML syntax of all manifests,
-# generated or otherwise.
-#
-# To use this file, be sure to also include Makefile.smf.targ after defining
-# targets.
-#
-
-SED 		?= sed
-SMF_DTD		?= tools/service_bundle.dtd.1
-XMLLINT		?= xmllint --noout
-
-SMF_MANIFESTS	+= $(SMF_MANIFESTS_IN:%.in=%)
-CLEAN_FILES	+= $(SMF_MANIFESTS_IN:%.in=%)
diff --git a/tools/mk/Makefile.smf.targ b/tools/mk/Makefile.smf.targ
deleted file mode 100644
index f78de96..0000000
--- a/tools/mk/Makefile.smf.targ
+++ /dev/null
@@ -1,29 +0,0 @@
-# -*- mode: makefile -*-
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2014, Joyent, Inc.
-#
-
-#
-# Makefile.smf.targ: see Makefile.smf.defs.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-.PHONY: check-manifests
-check-manifests: $(SMF_MANIFESTS:%=%.smfchk)
-
-%.smfchk: %
-	$(XMLLINT) --path $(dir $(SMF_DTD)) --dtdvalid $(SMF_DTD) $^
-
-check:: check-manifests
-
-$(SMF_MANIFESTS): %: %.in
-	$(SED) -e 's#@@NODE@@#@@PREFIX@@/$(NODE_INSTALL)/bin/node#' $< > $@
diff --git a/tools/mk/Makefile.targ b/tools/mk/Makefile.targ
deleted file mode 100644
index cc5ae95..0000000
--- a/tools/mk/Makefile.targ
+++ /dev/null
@@ -1,345 +0,0 @@
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-
-#
-# Copyright (c) 2017, Joyent, Inc.
-#
-
-#
-# Makefile.targ: common targets.
-#
-# NOTE: This makefile comes from the "eng" repo. It's designed to be dropped
-# into other repos as-is without requiring any modifications. If you find
-# yourself changing this file, you should instead update the original copy in
-# eng.git and then update your repo to use the new version.
-#
-# This Makefile defines several useful targets and rules. You can use it by
-# including it from a Makefile that specifies some of the variables below.
-#
-# Targets defined in this Makefile:
-#
-#	check	Checks JavaScript files for lint and style
-#		Checks bash scripts for syntax
-#		Checks SMF manifests for validity against the SMF DTD
-#
-#	clean	Removes built files
-#
-#	docs	Builds restdown documentation in docs/
-#
-#	prepush	Depends on "check" and "test"
-#
-#	test	Does nothing (you should override this)
-#
-#	xref	Generates cscope (source cross-reference index)
-#
-# For details on what these targets are supposed to do, see the Joyent
-# Engineering Guide.
-#
-# To make use of these targets, you'll need to set some of these variables. Any
-# variables left unset will simply not be used.
-#
-#	BASH_FILES	Bash scripts to check for syntax
-#			(paths relative to top-level Makefile)
-#
-#	CLEAN_FILES	Files to remove as part of the "clean" target.  Note
-#			that files generated by targets in this Makefile are
-#			automatically included in CLEAN_FILES.  These include
-#			restdown-generated HTML and JSON files.
-#
-#	DOC_FILES	Restdown (documentation source) files. These are
-#			assumed to be contained in "docs/", and must NOT
-#			contain the "docs/" prefix.
-#
-#	JSL_CONF_NODE	Specify JavaScriptLint configuration files
-#	JSL_CONF_WEB	(paths relative to top-level Makefile)
-#
-#			Node.js and Web configuration files are separate
-#			because you'll usually want different global variable
-#			configurations.  If no file is specified, none is given
-#			to jsl, which causes it to use a default configuration,
-#			which probably isn't what you want.
-#
-#	JSL_FILES_NODE	JavaScript files to check with Node config file.
-#	JSL_FILES_WEB	JavaScript files to check with Web config file.
-#
-#	JSON_FILES	JSON files to be validated
-#
-#	JSSTYLE_FILES	JavaScript files to be style-checked
-#
-# You can also override these variables:
-#
-#	BASH		Path to bash (default: "bash")
-#
-#	CSCOPE_DIRS	Directories to search for source files for the cscope
-#			index. (default: ".")
-#
-#	ESLINT		Path to eslint (default: "eslint")
-#
-#	ESLINT_FLAGS	Additional flags to pass through to eslint
-#
-#	JSL		Path to JavaScriptLint (default: "jsl")
-#
-#	JSL_FLAGS_NODE	Additional flags to pass through to JSL
-#	JSL_FLAGS_WEB
-#	JSL_FLAGS
-#
-#	JSON		Path to json tool (default: "json")
-#
-#	JSSTYLE		Path to jsstyle (default: "jsstyle")
-#
-#	JSSTYLE_FLAGS	Additional flags to pass through to jsstyle
-#
-#	RESTDOWN_EXT	By default '.md' is required for DOC_FILES (see above).
-#			If you want to use, say, '.restdown' instead, then set
-#			'RESTDOWN_EXT=.restdown' in your Makefile.
-#
-
-#
-# Defaults for the various tools we use.
-#
-BASH		?= bash
-BASHSTYLE	?= tools/bashstyle
-CP		?= cp
-CSCOPE		?= cscope
-CSCOPE_DIRS	?= .
-ESLINT		?= eslint
-JSL		?= jsl
-JSON		?= json
-JSSTYLE		?= jsstyle
-MKDIR		?= mkdir -p
-MV		?= mv
-RESTDOWN_FLAGS	?=
-RESTDOWN_EXT	?= .md
-RMTREE		?= rm -rf
-JSL_FLAGS  	?= --nologo --nosummary
-
-ifeq ($(shell uname -s),SunOS)
-	TAR	?= gtar
-else
-	TAR	?= tar
-endif
-
-
-#
-# Defaults for other fixed values.
-#
-BUILD		= build
-DISTCLEAN_FILES += $(BUILD)
-DOC_BUILD	= $(BUILD)/docs/public
-
-#
-# Configure JSL_FLAGS_{NODE,WEB} based on JSL_CONF_{NODE,WEB}.
-#
-ifneq ($(origin JSL_CONF_NODE), undefined)
-	JSL_FLAGS_NODE += --conf=$(JSL_CONF_NODE)
-endif
-
-ifneq ($(origin JSL_CONF_WEB), undefined)
-	JSL_FLAGS_WEB += --conf=$(JSL_CONF_WEB)
-endif
-
-#
-# Targets. For descriptions on what these are supposed to do, see the
-# Joyent Engineering Guide.
-#
-
-#
-# Instruct make to keep around temporary files. We have rules below that
-# automatically update git submodules as needed, but they employ a deps/*/.git
-# temporary file. Without this directive, make tries to remove these .git
-# directories after the build has completed.
-#
-.SECONDARY: $($(wildcard deps/*):%=%/.git)
-
-#
-# This rule enables other rules that use files from a git submodule to have
-# those files depend on deps/module/.git and have "make" automatically check
-# out the submodule as needed.
-#
-deps/%/.git:
-	git submodule update --init deps/$*
-
-#
-# These recipes make heavy use of dynamically-created phony targets. The parent
-# Makefile defines a list of input files like BASH_FILES. We then say that each
-# of these files depends on a fake target called filename.bashchk, and then we
-# define a pattern rule for those targets that runs bash in check-syntax-only
-# mode. This mechanism has the nice properties that if you specify zero files,
-# the rule becomes a noop (unlike a single rule to check all bash files, which
-# would invoke bash with zero files), and you can check individual files from
-# the command line with "make filename.bashchk".
-#
-.PHONY: check-bash
-check-bash: $(BASH_FILES:%=%.bashchk) $(BASH_FILES:%=%.bashstyle)
-
-%.bashchk: %
-	$(BASH) -n $^
-
-%.bashstyle: %
-	$(BASHSTYLE) $^
-
-.PHONY: check-json
-check-json: $(JSON_FILES:%=%.jsonchk)
-
-%.jsonchk: %
-	$(JSON) --validate -f $^
-
-#
-# The above approach can be slow when there are many files to check because it
-# requires that "make" invoke the check tool once for each file, rather than
-# passing in several files at once.  For the JavaScript check targets, we define
-# a variable for the target itself *only if* the list of input files is
-# non-empty.  This avoids invoking the tool if there are no files to check.
-#
-
-ESLINT_TARGET = $(if $(ESLINT_FILES), check-eslint)
-.PHONY: check-eslint
-check-eslint: $(ESLINT_EXEC)
-	$(ESLINT) $(ESLINT_FLAGS) $(ESLINT_FILES)
-
-JSL_NODE_TARGET = $(if $(JSL_FILES_NODE), check-jsl-node)
-.PHONY: check-jsl-node
-check-jsl-node: $(JSL_EXEC)
-	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_NODE) $(JSL_FILES_NODE)
-
-JSL_WEB_TARGET = $(if $(JSL_FILES_WEB), check-jsl-web)
-.PHONY: check-jsl-web
-check-jsl-web: $(JSL_EXEC)
-	$(JSL) $(JSL_FLAGS) $(JSL_FLAGS_WEB) $(JSL_FILES_WEB)
-
-.PHONY: check-jsl
-check-jsl: $(JSL_NODE_TARGET) $(JSL_WEB_TARGET)
-
-JSSTYLE_TARGET = $(if $(JSSTYLE_FILES), check-jsstyle)
-.PHONY: check-jsstyle
-check-jsstyle:  $(JSSTYLE_EXEC)
-	$(JSSTYLE) $(JSSTYLE_FLAGS) $(JSSTYLE_FILES)
-
-.PHONY: check
-check:: $(ESLINT_TARGET) check-jsl check-json $(JSSTYLE_TARGET) check-bash
-	@echo check ok
-
-.PHONY: clean
-clean::
-	-$(RMTREE) $(CLEAN_FILES)
-
-.PHONY: distclean
-distclean:: clean
-	-$(RMTREE) $(DISTCLEAN_FILES)
-
-CSCOPE_FILES = cscope.in.out cscope.out cscope.po.out
-CLEAN_FILES += $(CSCOPE_FILES)
-
-.PHONY: xref
-xref: cscope.files
-	$(CSCOPE) -bqR
-
-.PHONY: cscope.files
-cscope.files:
-	find $(CSCOPE_DIRS) -name '*.c' -o -name '*.h' -o -name '*.cc' \
-	    -o -name '*.js' -o -name '*.s' -o -name '*.cpp' > $@
-
-#
-# The "docs" target is complicated because we do several things here:
-#
-#    (1) Use restdown to build HTML and JSON files from each of DOC_FILES.
-#
-#    (2) Copy these files into $(DOC_BUILD) (build/docs/public), which
-#        functions as a complete copy of the documentation that could be
-#        mirrored or served over HTTP.
-#
-#    (3) Then copy any directories and media from docs/media into
-#        $(DOC_BUILD)/media. This allows projects to include their own media,
-#        including files that will override same-named files provided by
-#        restdown.
-#
-# Step (3) is the surprisingly complex part: in order to do this, we need to
-# identify the subdirectories in docs/media, recreate them in
-# $(DOC_BUILD)/media, then do the same with the files.
-#
-DOC_MEDIA_DIRS := $(shell find docs/media -type d 2>/dev/null | grep -v "^docs/media$$")
-DOC_MEDIA_DIRS := $(DOC_MEDIA_DIRS:docs/media/%=%)
-DOC_MEDIA_DIRS_BUILD := $(DOC_MEDIA_DIRS:%=$(DOC_BUILD)/media/%)
-
-DOC_MEDIA_FILES := $(shell find docs/media -type f 2>/dev/null)
-DOC_MEDIA_FILES := $(DOC_MEDIA_FILES:docs/media/%=%)
-DOC_MEDIA_FILES_BUILD := $(DOC_MEDIA_FILES:%=$(DOC_BUILD)/media/%)
-
-#
-# Like the other targets, "docs" just depends on the final files we want to
-# create in $(DOC_BUILD), leveraging other targets and recipes to define how
-# to get there.
-#
-.PHONY: docs
-docs::							\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.html)		\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=$(DOC_BUILD)/%.json)		\
-	$(DOC_MEDIA_FILES_BUILD)
-
-#
-# We keep the intermediate files so that the next build can see whether the
-# files in DOC_BUILD are up to date.
-#
-.PRECIOUS:					\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%json)
-
-#
-# We do clean those intermediate files, as well as all of DOC_BUILD.
-#
-CLEAN_FILES +=					\
-	$(DOC_BUILD)				\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.html)		\
-	$(DOC_FILES:%$(RESTDOWN_EXT)=docs/%.json)
-
-#
-# Before installing the files, we must make sure the directories exist. The |
-# syntax tells make that the dependency need only exist, not be up to date.
-# Otherwise, it might try to rebuild spuriously because the directory itself
-# appears out of date.
-#
-$(DOC_MEDIA_FILES_BUILD): | $(DOC_MEDIA_DIRS_BUILD)
-
-$(DOC_BUILD)/%: docs/% | $(DOC_BUILD)
-	$(MKDIR) $(shell dirname $@)
-	$(CP) $< $@
-
-docs/%.json docs/%.html: docs/%$(RESTDOWN_EXT) | $(DOC_BUILD) $(RESTDOWN_EXEC) \
-    $(EXTRA_DOC_DEPS)
-	$(RESTDOWN) $(RESTDOWN_FLAGS) -m $(DOC_BUILD) $<
-
-$(DOC_BUILD):
-	$(MKDIR) $@
-
-$(DOC_MEDIA_DIRS_BUILD):
-	$(MKDIR) $@
-
-#
-# The default "test" target does nothing. This should usually be overridden by
-# the parent Makefile. It's included here so we can define "prepush" without
-# requiring the repo to define "test".
-#
-.PHONY: test
-test:
-
-.PHONY: prepush
-prepush: check test
-
-#
-# This rule automatically exposes every "stamp" file as a target that can be
-# invoked manually as "stamp-$STAMP_NAME".  For example, if a stamp has been
-# defined thus:
-#
-#	STAMP_EXPENSIVE_RESULT := $(MAKE_STAMPS_DIR)/expensive-result
-#
-# ... this can be invoked manually as "make stamp-expensive-result".  Note that
-# these phony targets are essentially just for interactive usage.  Targets
-# should be specified to depend on the macro containing the stamp file name.
-#
-# See also the comments in "Makefile.defs".
-#
-stamp-%: $(MAKE_STAMPS_DIR)/%
-	@:
diff --git a/tools/obliterate-prometheus-service.sh b/tools/obliterate-prometheus-service.sh
new file mode 100755
index 0000000..43a3a80
--- /dev/null
+++ b/tools/obliterate-prometheus-service.sh
@@ -0,0 +1,68 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Copyright (c) 2019 Joyent, Inc.
+#
+
+#
+# Obliterate a Triton prometheus service and instances. This is just for
+# development.
+#
+# Usage:
+#       scp tools/obliterate-prometheus-service.sh coal:/var/tmp
+#       ssh coal
+#       /var/tmp/obliterate-prometheus-service.sh
+#
+
+if [[ -n "$TRACE" ]]; then
+    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
+    set -o xtrace
+fi
+set -o errexit
+set -o pipefail
+
+function fatal() {
+    echo "$0: fatal: \$*" >&2
+    exit 1
+}
+
+function obliterate_prometheus_service {
+    local promSvc
+
+    promSvc=$(sdc-sapi /services?name=prometheus | json -H 0.uuid)
+    if [[ -z $promSvc ]]; then
+        return
+    fi
+
+    sdc-sapi /instances?service_uuid=$promSvc \
+        | json -Ha uuid params.alias \
+        | while read uuid alias; do
+            echo "Delete prometheus instance $uuid ($alias)"
+            sdc-sapi /instances/$uuid -X DELETE
+        done
+
+    echo "Delete prometheus service ($promSvc)"
+    sdc-sapi /services/$promSvc -X DELETE
+}
+
+
+# ---- mainline
+
+# Guard from running this in production. This is the same guard file we use
+# for running many of the Triton test suites.
+if [[ ! -f "/lib/sdc/.sdc-test-no-production-data" ]]; then
+    cat <<EOF
+To run this you must create the following file:
+
+    /lib/sdc/.sdc-test-no-production-data
+
+after ensuring you have no production data in this TritonDC.
+EOF
+    exit 2
+fi
+
+
+obliterate_prometheus_service
\ No newline at end of file
diff --git a/tools/service_bundle.dtd.1 b/tools/service_bundle.dtd.1
new file mode 100644
index 0000000..e5c2380
--- /dev/null
+++ b/tools/service_bundle.dtd.1
@@ -0,0 +1,1091 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+ Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.
+
+ CDDL HEADER START
+
+ The contents of this file are subject to the terms of the
+ Common Development and Distribution License (the "License").
+ You may not use this file except in compliance with the License.
+
+ You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
+ or http://www.opensolaris.org/os/licensing.
+ See the License for the specific language governing permissions
+ and limitations under the License.
+
+ When distributing Covered Code, include this CDDL HEADER in each
+ file and include the License file at usr/src/OPENSOLARIS.LICENSE.
+ If applicable, add the following below this CDDL HEADER, with the
+ fields enclosed by brackets "[]" replaced with your own identifying
+ information: Portions Copyright [yyyy] [name of copyright owner]
+
+ CDDL HEADER END
+-->
+
+<!--
+  Service description DTD
+
+    Most attributes are string values (or an individual string from a
+    restricted set), but attributes with a specific type requirement are
+    noted in the comment describing the element.
+-->
+
+<!--
+  XInclude support
+
+    A series of service bundles may be composed via the xi:include tag.
+    smf(5) tools enforce that all bundles be of the same type.
+-->
+
+<!--
+     These entities are used for the property, propval and property_group
+     elements, that require type attributes for manifest, while for profiles
+     the type attributes are only implied.
+-->
+
+<!ENTITY % profile "IGNORE">
+<!ENTITY % manifest "INCLUDE">
+
+<!ELEMENT xi:include
+  (xi:fallback)
+  >
+<!ATTLIST xi:include
+  href CDATA #REQUIRED
+  parse (xml|text) "xml"
+  encoding CDATA #IMPLIED
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!ELEMENT xi:fallback
+  ANY
+  >
+<!ATTLIST xi:fallback
+  xmlns:xi CDATA #FIXED "http://www.w3.org/2001/XInclude"
+  >
+
+<!--
+  stability
+
+    This element associates an SMI stability level with the parent
+    element.  See attributes(5) for an explanation of interface
+    stability levels.
+
+    Its attribute is
+
+	value	The stability level of the parent element.
+-->
+
+<!ELEMENT stability EMPTY>
+
+<!ATTLIST stability
+	value		( Standard | Stable | Evolving | Unstable |
+			External | Obsolete ) #REQUIRED >
+
+<!-- Property value lists -->
+
+<!--
+  value_node
+
+    This element represents a single value within any of the typed
+    property value lists.
+
+    Its attribute is
+
+	value	The value for this node in the list.
+-->
+
+<!ELEMENT value_node EMPTY>
+
+<!ATTLIST value_node
+	value CDATA #REQUIRED>
+
+<!--
+  count_list
+  integer_list
+  opaque_list
+  host_list
+  hostname_list
+  net_address_list
+  net_address_v4_list
+  net_address_v6_list
+  time_list
+  astring_list
+  ustring_list
+  boolean_list
+  fmri_list
+  uri_list
+
+    These elements represent the typed lists of values for a property.
+    Each contains one or more value_node elements representing each
+    value on the list.
+
+    None of these elements has attributes.
+-->
+
+<!ELEMENT count_list
+	( value_node+ )>
+
+<!ATTLIST count_list>
+
+<!ELEMENT integer_list
+	( value_node+ )>
+
+<!ATTLIST integer_list>
+
+<!ELEMENT opaque_list
+	( value_node+ )>
+
+<!ATTLIST opaque_list>
+
+<!ELEMENT host_list
+	( value_node+ )>
+
+<!ATTLIST host_list>
+
+<!ELEMENT hostname_list
+	( value_node+ )>
+
+<!ATTLIST hostname_list>
+
+<!ELEMENT net_address_list
+	( value_node+ )>
+
+<!ATTLIST net_address_list>
+
+<!ELEMENT net_address_v4_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v4_list>
+
+<!ELEMENT net_address_v6_list
+	( value_node+ )>
+
+<!ATTLIST net_address_v6_list>
+
+<!ELEMENT time_list
+	( value_node+ )>
+
+<!ATTLIST time_list>
+
+<!ELEMENT astring_list
+	( value_node+ )>
+
+<!ATTLIST astring_list>
+
+<!ELEMENT ustring_list
+	( value_node+ )>
+
+<!ATTLIST ustring_list>
+
+<!ELEMENT boolean_list
+	( value_node+ )>
+
+<!ATTLIST boolean_list>
+
+<!ELEMENT fmri_list
+	( value_node+ )>
+
+<!ATTLIST fmri_list>
+
+<!ELEMENT uri_list
+	( value_node+ )>
+
+<!ATTLIST uri_list>
+
+<!-- Properties and property groups -->
+
+<!--
+   property
+
+     This element is for a singly or multiply valued property within a
+     property group.  It contains an appropriate value list element,
+     which is expected to be consistent with the type attribute.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	override These values should replace values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	override	( true | false ) "false" >
+]]>
+	
+<![%manifest;[
+<!ELEMENT property
+	( count_list | integer_list | opaque_list | host_list | hostname_list |
+	net_address_list | net_address_v4_list | net_address_v6_list |
+	time_list | astring_list | ustring_list | boolean_list | fmri_list |
+	uri_list )? >
+
+<!ATTLIST property
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+   propval
+
+     This element is for a singly valued property within a property
+     group.  List-valued properties must use the property element above.
+
+     Its attributes are
+
+	name	The name of this property.
+
+	type	The data type for this property.
+
+	value	The value for this property.  Must match type
+		restriction of type attribute.
+
+	override This value should replace any values already in the
+		repository.
+-->
+
+<![%profile;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT propval EMPTY>
+
+<!ATTLIST propval
+	name		CDATA #REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #REQUIRED
+	value		CDATA #REQUIRED
+	override	( true | false ) "false" >
+]]>
+
+<!--
+  property_group
+
+    This element is for a set of related properties on a service or
+    instance.  It contains an optional stability element, as well as
+    zero or more property-containing elements.
+
+    Its attributes are
+
+	name	The name of this property group.
+
+	type	A category for this property group.  Groups of type
+		"framework", "implementation" or "template" are primarily
+		of interest to the service management facility, while
+		groups of type "application" are expected to be only of
+		interest to the service to which this group is attached.
+		Other types may be introduced using the service symbol
+		namespace conventions.
+
+	delete	If in the repository, this property group should be removed.
+-->
+
+<![%profile;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #IMPLIED
+	delete		( true | false ) "false" >
+]]>
+
+<![%manifest;[
+<!ELEMENT property_group
+	( stability?, ( propval | property )* )>
+
+<!ATTLIST property_group
+	name		CDATA #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+]]>
+
+<!--
+  service_fmri
+
+    This element defines a reference to a service FMRI (for either a
+    service or an instance).
+
+    Its attribute is
+
+	value	The FMRI.
+-->
+
+<!ELEMENT service_fmri EMPTY>
+
+<!ATTLIST service_fmri
+	value		CDATA #REQUIRED>
+
+<!-- Dependencies -->
+
+<!--
+  dependency
+
+    This element identifies a group of FMRIs upon which the service is
+    in some sense dependent.  Its interpretation is left to the
+    restarter to which a particular service instance is delegated.  It
+    contains a group of service FMRIs, as well as a block of properties.
+
+    Its attributes are
+
+	name	The name of this dependency.
+
+	grouping The relationship between the various FMRIs grouped
+		here; "require_all" of the FMRIs to be online, "require_any"
+		of the FMRIs to be online, or "exclude_all" of the FMRIs
+		from being online or in maintenance for the dependency to
+		be satisfied.  "optional_all" dependencies are satisfied
+		when all of the FMRIs are either online or unable to come
+		online (because they are disabled, misconfigured, or one
+		of their dependencies is unable to come online).
+
+	restart_on The type of events from the FMRIs that the service should
+		be restarted for.  "error" restarts the service if the
+		dependency is restarted due to hardware fault.  "restart"
+		restarts the service if the dependency is restarted for
+		any reason, including hardware fault.  "refresh" restarts
+		the service if the dependency is refreshed or restarted for
+		any reason.  "none" will never restart the service due to
+		dependency state changes.
+
+	type	The type of dependency: on another service ('service'), on
+		a filesystem path ('path'), or another dependency type.
+
+	delete	This dependency should be deleted.
+-->
+
+<!ELEMENT dependency
+	( service_fmri*, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependency
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all ) #REQUIRED
+	restart_on	( error | restart | refresh | none ) #REQUIRED
+	type		CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!-- Dependents -->
+
+<!--
+  dependent
+
+    This element identifies a service which should depend on this service.  It
+    corresponds to a dependency in the named service.  The grouping and type
+    attributes of that dependency are implied to be "require_all" and
+    "service", respectively.
+
+    Its attributes are
+
+	name	The name of the dependency property group to create in the
+		dependent entity.
+
+	grouping The grouping relationship of the dependency property
+		group to create in the dependent entity.  See "grouping"
+		attribute on the dependency element.
+
+	restart_on The type of events from this service that the named service
+		should be restarted for.
+
+	delete	True if this dependent should be deleted.
+
+	override Whether to replace an existing dependent of the same name.
+
+-->
+
+<!ELEMENT dependent
+	( service_fmri, stability?, ( propval | property )* ) >
+
+<!ATTLIST dependent
+	name		CDATA #REQUIRED
+	grouping	( require_all | require_any | exclude_all |
+			optional_all) #REQUIRED
+	restart_on	( error | restart | refresh | none) #REQUIRED
+	delete		( true | false ) "false"
+	override	( true | false ) "false" >
+
+<!-- Method execution context, security profile, and credential definitions -->
+
+<!--
+  envvar
+
+    An environment variable. It has two attributes:
+
+	name	The name of the environment variable.
+	value	The value of the environment variable.
+-->
+
+<!ELEMENT envvar EMPTY>
+
+<!ATTLIST envvar
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED >
+
+<!--
+  method_environment
+
+    This element defines the environment for a method. It has no
+    attributes, and one or more envvar child elements.
+-->
+
+<!ELEMENT method_environment (envvar+) >
+
+<!ATTLIST method_environment>
+
+<!--
+  method_profile
+
+    This element indicates which exec_attr(5) profile applies to the
+    method context being defined.
+
+    Its attribute is
+
+	name	The name of the profile.
+-->
+
+<!ELEMENT method_profile EMPTY>
+
+<!ATTLIST method_profile
+	name		CDATA #REQUIRED >
+
+<!--
+  method_credential
+
+    This element specifies credential attributes for the execution
+    method to use.
+
+    Its attributes are
+
+	user	The user ID, in numeric or text form.
+
+	group	The group ID, in numeric or text form.  If absent or
+		":default", the group associated with the user in the
+		passwd database.
+
+	supp_groups Supplementary group IDs to be associated with the
+		method, separated by commas or spaces.  If absent or
+		":default", initgroups(3C) will be used.
+
+	privileges An optional string specifying the privilege set.
+
+	limit_privileges An optional string specifying the limit
+		privilege set.
+-->
+
+<!ELEMENT method_credential EMPTY>
+
+<!ATTLIST method_credential
+	user		CDATA #REQUIRED
+	group		CDATA #IMPLIED
+	supp_groups	CDATA #IMPLIED
+	privileges	CDATA #IMPLIED
+	limit_privileges CDATA #IMPLIED >
+
+<!--
+  method_context
+
+    This element combines credential and resource management attributes
+    for execution methods.  It may contain a method_environment, or
+    a method_profile or method_credential element.
+
+    Its attributes are
+
+	working_directory The home directory to launch the method from.
+		":default" can be used as a token to indicate use of the
+		user specified by the credential or profile specified.
+
+	project	The project ID, in numeric or text form.  ":default" can
+		be used as a token to indicate use of the project
+		identified by getdefaultproj(3PROJECT) for the non-root
+		user specified by the credential or profile specified.
+		If the user is root, ":default" designates the project
+		the restarter is running in.
+
+	resource_pool The resource pool name to launch the method on.
+		":default" can be used as a token to indicate use of the
+		pool specified in the project(4) entry given in the
+		"project" attribute above.
+-->
+<!ELEMENT method_context
+	( (method_profile | method_credential)?, method_environment? ) >
+
+<!ATTLIST method_context
+	working_directory	CDATA #IMPLIED
+	project			CDATA #IMPLIED
+	resource_pool		CDATA #IMPLIED >
+
+<!-- Restarter delegation, methods, and monitors -->
+
+<!--
+  exec_method
+
+    This element describes one of the methods used by the designated
+    restarter to act on the service instance.  Its interpretation is
+    left to the restarter to which a particular service instance is
+    delegated.  It contains a set of attributes, an optional method
+    context, and an optional stability element for the optional
+    properties that can be included.
+
+    Its attributes are
+
+	type	The type of method, either "method" or "monitor".
+
+	name	Name of this execution method.  The method names are
+		usually a defined interface of the restarter to which an
+		instance of this service is delegated.
+
+	exec	The string identifying the action to take.  For
+		svc.startd(1M), this is a string suitable to pass to
+		exec(2).
+
+	timeout_seconds [integer] Duration, in seconds, to wait for this
+		method to complete.  A '0' or '-1' denotes an infinite
+		timeout.
+
+	delete	If in the repository, the property group for this method
+		should be removed.
+-->
+
+<!ELEMENT exec_method
+	( method_context?, stability?, ( propval | property )* ) >
+
+<!ATTLIST exec_method
+	type		( method | monitor ) #REQUIRED
+	name		CDATA #REQUIRED
+	exec		CDATA #REQUIRED
+	timeout_seconds	CDATA #REQUIRED
+	delete		( true | false ) "false" >
+
+<!--
+  restarter
+
+    A flag element identifying the restarter to which this service or
+    service instance is delegated.  Contains the FMRI naming the
+    delegated restarter.
+
+    This element has no attributes.
+-->
+
+<!ELEMENT restarter
+	( service_fmri ) >
+
+<!ATTLIST restarter>
+
+<!--
+  Templates
+-->
+
+<!--
+  doc_link
+
+    The doc_link relates a resource described by the given URI to the
+    service described by the containing template.  The resource is
+    expected to be a documentation or elucidatory reference of some
+    kind.
+
+    Its attributes are
+
+      name      A label for this resource.
+
+      uri       A URI to the resource.
+-->
+
+<!ELEMENT doc_link EMPTY>
+
+<!ATTLIST doc_link
+	name		CDATA #REQUIRED
+	uri		CDATA #REQUIRED >
+
+<!--
+  manpage
+
+    The manpage element connects the reference manual page to the
+    template's service.
+
+    Its attributes are
+
+      title     The manual page title.
+
+      section   The manual page's section.
+
+      manpath   The MANPATH environment variable, as described in man(1)
+                that is required to reach the named manual page
+-->
+
+<!ELEMENT manpage EMPTY>
+
+<!ATTLIST manpage
+	title		CDATA #REQUIRED
+	section		CDATA #REQUIRED
+	manpath		CDATA ":default" >
+
+<!--
+  documentation
+
+    The documentation element groups an arbitrary number of doc_link
+    and manpage references.
+
+    It has no attributes.
+-->
+
+<!ELEMENT documentation
+	( doc_link | manpage )* >
+
+<!ATTLIST documentation>
+
+<!--
+  loctext
+
+    The loctext element is a container for localized text.
+
+    Its sole attribute is
+
+	xml:lang The name of the locale, in the form accepted by LC_ALL,
+		etc.  See locale(5).
+-->
+<!ELEMENT loctext
+        (#PCDATA) >
+
+<!ATTLIST loctext
+        xml:lang	CDATA #REQUIRED >
+
+<!--
+  description
+
+    The description holds a set of potentially longer, localized strings that
+    consist of a short description of the service.
+
+    The description has no attributes.
+-->
+<!ELEMENT description
+        ( loctext+ ) >
+
+<!ATTLIST description>
+
+<!--
+  common_name
+
+    The common_name holds a set of short, localized strings that
+    represent a well-known name for the service in the given locale.
+
+    The common_name has no attributes.
+-->
+<!ELEMENT common_name
+        ( loctext+ ) >
+
+<!ATTLIST common_name>
+
+<!--
+  units
+
+    The units a numerical property is expressed in.
+-->
+
+<!ELEMENT units
+	( loctext+ ) >
+
+<!ATTLIST units>
+
+<!--
+  visibility
+
+    Expresses how a property is typically accessed.  This isn't
+    intended as access control, but as an indicator as to how a
+    property is used.
+
+    Its attributes are:
+
+      value     'hidden', 'readonly', or 'readwrite' indicating that
+		the property should be hidden from the user, shown but
+		read-only, or modifiable.
+-->
+
+<!ELEMENT visibility EMPTY>
+
+<!ATTLIST visibility
+	value	( hidden | readonly | readwrite ) #REQUIRED >
+
+<!--
+  value
+
+    Describes a legal value for a property value, and optionally contains a
+    human-readable name and description for the specified property
+    value.
+
+    Its attributes are:
+
+      name	A string representation of the value.
+-->
+
+<!ELEMENT value
+	( common_name?, description? ) >
+
+<!ATTLIST value
+	name	CDATA #REQUIRED >
+
+<!--
+  values
+
+    Human-readable names and descriptions for valid values of a property.
+-->
+
+<!ELEMENT values
+	(value+) >
+
+<!ATTLIST values>
+
+<!--
+  cardinality
+
+    Places a constraint on the number of values the property can take
+    on.
+
+    Its attributes are:
+	min	minimum number of values
+	max	maximum number of values
+
+    Both attributes are optional.  If min is not specified, it defaults to
+    0.  If max is not specified it indicates an unlimited number of values.
+    If neither is specified this indicates 0 or more values.
+-->
+
+<!ELEMENT cardinality EMPTY>
+
+<!ATTLIST cardinality
+	min	CDATA "0"
+	max	CDATA "18446744073709551615">
+
+<!--
+  internal_separators
+
+    Indicates the separators used within a property's value used to
+    separate the actual values.  Used in situations where multiple
+    values are packed into a single property value instead of using a
+    multi-valued property.
+-->
+
+<!ELEMENT internal_separators
+	(#PCDATA) >
+
+<!ATTLIST internal_separators>
+
+<!--
+  range
+
+    Indicates a range of possible integer values.
+
+    Its attributes are:
+
+      min	The minimum value of the range (inclusive).
+      max	The maximum value of the range (inclusive).
+-->
+
+<!ELEMENT range EMPTY>
+
+<!ATTLIST range
+	min	CDATA #REQUIRED
+	max	CDATA #REQUIRED >
+
+<!--
+  constraints
+
+    Provides a set of constraints on the values a property can take on.
+-->
+
+<!ELEMENT constraints
+	( value*, range* ) >
+<!ATTLIST constraints>
+
+<!--
+  include_values
+
+    Includes an entire set of values in the choices block.
+
+    Its attributes are:
+
+	type    Either "constraints" or "values", indicating an
+		inclusion of all values allowed by the property's
+		constraints or all values for which there are
+		human-readable names and descriptions, respectively.
+-->
+
+<!ELEMENT include_values EMPTY>
+
+<!ATTLIST include_values
+	type	( constraints | values ) #REQUIRED >
+
+<!--
+  choices
+
+    Provides a set of common choices for the values a property can take
+    on.  Useful in those cases where the possibilities are unenumerable
+    or merely inconveniently legion, and a manageable subset is desired
+    for presentation in a user interface.
+-->
+
+<!ELEMENT choices
+	( value*, range*, include_values* ) >
+
+<!ATTLIST choices>
+
+<!--
+  prop_pattern
+
+
+    The prop_pattern describes one property of the enclosing property group
+    pattern.
+
+    Its attributes are:
+
+	name    The property's name.
+	type    The property's type.
+	required
+		If the property group is present, this property is required.
+
+	type can be omitted if required is false.
+-->
+
+<!ELEMENT prop_pattern
+	( common_name?, description?, units?, visibility?, cardinality?,
+	  internal_separators?, values?, constraints?, choices? ) >
+
+<!ATTLIST prop_pattern
+	name		CDATA	#REQUIRED
+	type		( count | integer | opaque | host | hostname |
+			net_address | net_address_v4 | net_address_v6 | time |
+			astring | ustring | boolean | fmri | uri ) #IMPLIED
+	required	( true | false )	"false" >
+
+<!--
+  pg_pattern
+
+    The pg_pattern describes one property group.
+    Depending on the element's attributes, these descriptions may apply
+    to just the enclosing service/instance, instances of the enclosing
+    service, delegates of the service (assuming it is a restarter), or
+    all services.
+
+    Its attributes are:
+
+	name    The property group's name.  If not specified, it
+		matches all property groups with the specified type.
+	type    The property group's type.  If not specified, it
+		matches all property groups with the specified name.
+	required
+		If the property group is required.
+	target	The scope of the pattern, which may be all, delegate,
+		instance, or this.  'all' is reserved for framework use
+		and applies the template to all services on the system.
+		'delegate' is reserved for restarters, and means the
+		template applies to all services which use the restarter.
+		'this' would refer to the defining service or instance.
+		'instance' can only be used in a service's template block,
+		and means the definition applies to all instances of this
+		service.
+
+-->
+
+<!ELEMENT pg_pattern
+	( common_name?, description?, prop_pattern* ) >
+
+<!ATTLIST pg_pattern
+	name		CDATA	""
+	type		CDATA	""
+	required	( true | false )	"false"
+	target		( this | instance | delegate | all )	"this" >
+
+<!--
+  template
+
+    The template contains a collection of metadata about the service.
+    It contains a localizable string that serves as a common,
+    human-readable name for the service.  (This name should be less than
+    60 characters in a single byte locale.)  The template may optionally
+    contain a longer localizable description of the service, a
+    collection of links to documentation, either in the form of manual
+    pages or in the form of URI specifications to external documentation
+    sources (such as docs.sun.com).
+
+    The template has no attributes.
+-->
+<!ELEMENT template
+        ( common_name, description?, documentation?, pg_pattern* ) >
+
+<!ATTLIST template>
+
+<!-- Notification Parameters -->
+
+<!ELEMENT paramval EMPTY>
+
+<!ATTLIST paramval
+	name		CDATA #REQUIRED
+	value		CDATA #REQUIRED>
+
+<!ELEMENT parameter
+	( value_node* )>
+
+<!ATTLIST parameter
+	name		CDATA #REQUIRED>
+
+<!ELEMENT event EMPTY>
+
+<!ATTLIST event
+	value		CDATA #REQUIRED>
+
+<!ELEMENT type
+	( ( parameter | paramval )* )>
+
+<!ATTLIST type
+	name		CDATA #REQUIRED
+	active		( true | false ) "true" >
+
+<!--
+  notification parameters
+
+    This element sets the notification parameters for Software Events and
+    Fault Management problem lifecycle events.
+-->
+
+<!ELEMENT notification_parameters
+	( event, type+ )>
+
+<!ATTLIST notification_parameters>
+
+<!-- Services and instances -->
+
+<!--
+  create_default_instance
+
+    A flag element indicating that an otherwise empty default instance
+    of this service (named "default") should be created at install, with
+    its enabled property set as given.
+
+    Its attribute is
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT create_default_instance EMPTY >
+
+<!ATTLIST create_default_instance
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  single_instance
+
+    A flag element stating that this service can only have a single
+    instance on a particular system.
+-->
+
+<!ELEMENT single_instance EMPTY>
+
+<!ATTLIST single_instance>
+
+<!--
+  instance
+
+    The service instance is the object representing a software component
+    that will run on the system if enabled.  It contains an enabled
+    element, a set of dependencies on other services, potentially
+    customized methods or configuration data, an optional method
+    context, and a pointer to its restarter.  (If no restarter is
+    specified, the master restarter, svc.startd(1M), is assumed to be
+    responsible for the service.)
+
+    Its attributes are
+
+	name	The canonical name for this instance of the service.
+
+	enabled	[boolean] The initial value for the enabled state of
+		this instance.
+-->
+
+<!ELEMENT instance
+	( restarter?, dependency*, dependent*, method_context?,
+	exec_method*, notification_parameters*, property_group*,
+	template? ) >
+
+<!ATTLIST instance
+	name		CDATA #REQUIRED
+	enabled		( true | false ) #REQUIRED >
+
+<!--
+  service
+
+    The service contains the set of instances defined by default for
+    this service, an optional method execution context, any default
+    methods, the template, and various restrictions or advice applicable
+    at installation.  The method execution context and template elements
+    are required for service_bundle documents with type "manifest", but
+    are optional for "profile" or "archive" documents.
+
+    Its attributes are
+
+	name	The canonical name for the service.
+
+	version	[integer] The integer version for this service.
+
+	type	Whether this service is a simple service, a delegated
+		restarter, or a milestone (a synthetic service that
+		collects a group of dependencies).
+-->
+
+<!ELEMENT service
+	( create_default_instance?, single_instance?, restarter?,
+	dependency*, dependent*, method_context?, exec_method*,
+	notification_parameters*, property_group*, instance*,
+	stability?, template? ) >
+
+<!ATTLIST service
+	name		CDATA #REQUIRED
+	version		CDATA #REQUIRED
+	type		( service | restarter | milestone ) #REQUIRED >
+
+<!--
+  service_bundle
+
+    The bundle possesses two attributes:
+
+	type	How this file is to be understood by the framework (or
+		used in a non-framework compliant way). Standard types
+		are 'archive', 'manifest', and 'profile'.
+	
+	name	A name for the bundle.  Manifests should be named after
+		the package which delivered them; profiles should be
+		named after the "feature set nickname" they intend to
+		enable.
+-->
+
+<!ELEMENT service_bundle
+	( service_bundle* | service* | xi:include* )>
+
+<!ATTLIST service_bundle
+	type		CDATA #REQUIRED
+	name		CDATA #REQUIRED>
-- 
2.21.0

