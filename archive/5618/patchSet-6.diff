commit 3053ddb6ad1c8c8d7b52c3b5884496749180deca
Author: Robert Bogart <robert.bogart@joyent.com>
Date:   2019-02-26T20:53:46+00:00 (7 months ago)
    
    MANTA-4131 Accelerated garbage collection needs option to obtain records locally

diff --git a/bin/mako_gc_workaround.sh b/bin/mako_gc_workaround.sh
new file mode 100755
index 0000000..17be58e
--- /dev/null
+++ b/bin/mako_gc_workaround.sh
@@ -0,0 +1,341 @@
+#!/bin/bash
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+
+#
+# Copyright (c) 2019, Joyent, Inc.
+#
+
+#
+# Note, this is a workaround script, currently only intended for manual use
+# when it is not possible to obtain a directory listing in
+# /poseidon/stor/manta_gc/mako/<storage_id>
+#
+
+###############################################################################
+# This cleans manta objects by first sucking down all files under:
+#  /manta_gc/mako/$MANTA_STORAGE_ID
+# Which come in the following format:
+#  mako + \t + mantaStorageId + \t + ownerId + \t + objectId
+#
+# Since manta objects are kept under /manta/ownerId/objectId, the ids are taken
+# from the lines in the file and used to find and unlink the objects on the
+# local filesystem.  When it is done it deletes the file in manta.
+###############################################################################
+
+
+export PATH=/opt/local/bin:$PATH
+
+
+
+## Global vars
+RECORD_PATH="$1"
+# Immutables
+
+[ -z $SSH_KEY ] && SSH_KEY=/root/.ssh/id_rsa
+[ -z $MANTA_KEY_ID ] && MANTA_KEY_ID=$(ssh-keygen -l -f $SSH_KEY.pub | awk '{print $2}')
+[ -z $MANTA_URL ] && MANTA_URL=$(cat /opt/smartdc/mako/etc/gc_config.json | json -ga manta_url)
+[ -z $MANTA_USER ] && MANTA_USER=$(json -f /opt/smartdc/common/etc/config.json manta.user)
+[ -z $MANTA_STORAGE_ID ] && MANTA_STORAGE_ID=$(cat /opt/smartdc/mako/etc/gc_config.json | json -ga manta_storage_id)
+
+AUTHZ_HEADER="keyId=\"/$MANTA_USER/keys/$MANTA_KEY_ID\",algorithm=\"rsa-sha256\""
+DIR_TYPE='application/json; type=directory'
+HOSTNAME=`hostname`
+LOG_TYPE='application/x-bzip2'
+MPATH=/manta_gc/mako/$MANTA_STORAGE_ID
+PID=$$
+SCRIPT=$(basename $0)
+TMP_DIR=/tmp/mako_gc
+PID_FILE=/tmp/mako_gc.pid
+TOMB_DATE=$(date "+%Y-%m-%d")
+TOMB_ROOT=/manta/tombstone
+TOMB_DIR=$TOMB_ROOT/$TOMB_DATE
+TOMB_DIRS_TO_KEEP=21
+
+
+# Mutables
+
+NOW=""
+SIGNATURE=""
+
+ERROR="true"
+FILE_COUNT=0
+OBJECT_COUNT=0
+TOMB_CLEAN_COUNT=0
+
+
+
+## Functions
+
+#
+# For logging purposes, we keep track of the current date stamp in a global
+# $LNOW variable.  To avoid calling date(1) whenever we wish to log, we only
+# update the date stamp if the $SECONDS variable (which, in bash(1) is the
+# integer number of seconds since the script was invoked) does not match our
+# cached value.  This means that it's possible for our date stamp to be
+# slightly out of date with respect to the system clock, but by less than one
+# second -- which we consider to be acceptable considering we only have
+# second resolution.
+#
+function updatelnow {
+    if [[ $SECONDS != $LASTLNOW ]]; then
+        LNOW=`date "+%Y-%m-%dT%H:%M:%S.000Z"`
+        LASTLNOW=$SECONDS
+    fi
+}
+
+function fatal {
+    updatelnow
+    echo "$LNOW: $SCRIPT ($PID): fatal error: $*" >&2
+    audit
+    exit 1
+}
+
+
+function log {
+    updatelnow
+    echo "$LNOW: $SCRIPT ($PID): info: $*" >&2
+}
+
+
+# Since we use bunyan, this mimics a json structure.
+function audit {
+    updatelnow
+
+    echo "{\
+\"audit\":true,\
+\"name\":\"mako_gc\",\
+\"level\":30,\
+\"error\":$ERROR,\
+\"msg\":\"audit\",\
+\"v\":0,\
+\"time\":\"$LNOW\",\
+\"pid\":$PID,\
+\"cronExec\":1,\
+\"hostname\":\"$HOSTNAME\",\
+\"fileCount\":\"$FILE_COUNT\",\
+\"objectCount\":\"$OBJECT_COUNT\",\
+\"tombDirCleanupCount\":\"$TOMB_CLEAN_COUNT\"\
+}" >&2
+}
+
+
+function auditRow {
+    updatelnow
+
+    echo "{\
+\"audit\":true,\
+\"name\":\"mako_gc\",\
+\"level\":30,\
+\"msg\":\"audit\",\
+\"v\":0,\
+\"time\":\"$LNOW\",\
+\"pid\":$PID,\
+\"hostname\":\"$HOSTNAME\",\
+\"alreadyDeleted\":\"$1\",\
+\"objectId\":\"$2\",\
+\"tomb\":\"$3\",\
+\"processed\":1\
+}" >&2
+}
+
+
+function sign() {
+    NOW=$(date -u "+%a, %d %h %Y %H:%M:%S GMT")
+    SIGNATURE=$(echo "date: $NOW" | tr -d '\n' | \
+        openssl dgst -sha256 -sign $SSH_KEY | \
+        openssl enc -e -a | tr -d '\n') \
+        || fatal "unable to sign data"
+}
+
+
+function manta_get_no_fatal() {
+    sign || fatal "unable to sign"
+    curl -fsSk \
+        -X GET \
+        -H "Date: $NOW" \
+        -H "Authorization: Signature $AUTHZ_HEADER,signature=\"$SIGNATURE\"" \
+        -H "Connection: close" \
+        $MANTA_URL/$MANTA_USER/stor$1 2>&1
+}
+
+
+function manta_get_to_file() {
+    sign || fatal "unable to sign"
+    curl -fsSk \
+        -X GET \
+        -H "Date: $NOW" \
+        -H "Authorization: Signature $AUTHZ_HEADER,signature=\"$SIGNATURE\"" \
+        -H "Connection: close" \
+        $MANTA_URL/$MANTA_USER/stor$1 >$2
+
+    #
+    # While failing to obtain a file is not good, we should log the error
+    # and allow the caller to decide how to proceed.
+    #
+    if [[ $? -ne 0 ]]; then
+        log "unable to get $1"
+        return 1
+    fi
+
+    return 0
+}
+
+
+function manta_delete() {
+    sign || fatal "unable to sign"
+    curl -fsSk \
+        -X DELETE \
+        -H "Date: $NOW" \
+        -H "Authorization: Signature $AUTHZ_HEADER,signature=\"$SIGNATURE\"" \
+        -H "Connection: close" \
+        $MANTA_URL/$MANTA_USER/stor$1 \
+        || fatal "unable to delete $1"
+}
+
+#
+# Under certain circumstances, the directory of files containing instructions
+# for object deletion may grow too large to be able to obtain a directory
+# listing through traditional means.  As a result, we are unable to process
+# any of those files because we don't know their names.  As a mitigation, we
+# can obtain the file names manually by consulting the metadata tier directly
+# in order to recreate what the results of what a successul directory listing
+# would have looked like.  This function processes those files from a local
+# source, specified by a path.  From there, we can proceed normally through the
+# rest of the garbage collection process.
+#
+function process_file() {
+    local RECORDS="$1"
+    local ret=0
+
+    while read -r line
+    do
+        FILE=$(basename "$line")
+        MFILE=$MPATH/$FILE
+        LFILE=$TMP_DIR/$FILE
+
+        if [[ "/poseidon/stor$MFILE" != "$line" ]]
+        then
+            fatal "Mal-formed line: $line. Expected: /poseidon/stor/$MFILE"
+        fi
+
+        manta_get_to_file $MFILE $LFILE
+
+        if [[ $? -ne 0 ]]; then
+            ret=1
+            continue
+        fi
+
+        log "Processing manta object $MFILE"
+
+        while read -r LINE
+        do
+            #Filter out any lines that aren't meant for this storage node...
+            if [[ ! $LINE =~ mako.*$MANTA_STORAGE_ID ]]
+            then
+                continue
+            fi
+            log "Processing $LINE"
+            #Fields 3 and 4 are the owner and object ids, respectively.
+            ARR=($LINE)
+            OBJECT=/manta/${ARR[2]}/${ARR[3]}
+            if [[ -f $OBJECT ]]
+            then
+                auditRow "false" "$OBJECT" "$TOMB_DIR"
+                mv $OBJECT $TOMB_DIR
+                [[ $? -eq 0 ]] || fatal "Couldn't move $OBJECT"
+                ((OBJECT_COUNT++))
+            else
+                auditRow "true" "$OBJECT" "$TOMB_DIR"
+            fi
+        done < "$LFILE"
+
+        rm $LFILE
+        [[ $? -eq 0 ]] || fatal "Unable to rm $LFILE. Something is wrong."
+        manta_delete $MFILE
+
+        ((FILE_COUNT++))
+
+        log "success processing $MFILE."
+    done < "$RECORDS"
+    return $ret
+}
+
+## Main
+
+: ${MANTA_STORAGE_ID:?"Manta storage id must be set."}
+
+# Check the last pid to see if a previous cron is still running...
+LAST_PID=$(cat $PID_FILE 2>/dev/null)
+
+if [[ -n "$LAST_PID" ]]; then
+    ps -p $LAST_PID >/dev/null
+    if [[ $? -eq 0 ]]; then
+        echo "$0 process still running.  Exiting..."
+        exit 1
+    fi
+fi
+
+echo -n $PID >$PID_FILE
+
+if [[ -z "$RECORD_PATH" ]]
+then
+    fatal "No path specified."
+fi
+
+if [[ ! -d "$RECORD_PATH" ]]
+then
+    fatal "$RECORD_PATH does not exist."
+fi
+
+# Ok, we're good to start gc
+log "starting gc"
+
+for file in "$RECORD_PATH"/*
+do
+    process_file "$file"
+
+    #
+    # Only remove the file if it appears that we successfully processed the
+    # entire thing, otherwise retain it for further analysis.
+    #
+    if [[ $? -eq 0 ]]; then
+        rm "$file"
+    fi
+done
+
+# We change to nobody:nobody since that's what nginx uses for file permissions.
+# Doing that will allow us to http MOVE files via nginx to the tombstone dir.
+if [ ! -d $TOMB_ROOT ]; then
+    mkdir $TOMB_ROOT
+    chown nobody:nobody $TOMB_ROOT
+fi
+if [ ! -d $TOMB_DIR ]; then
+    mkdir $TOMB_DIR
+    chown nobody:nobody $TOMB_DIR
+fi
+mkdir -p $TMP_DIR
+
+log "starting tombstone directory cleanup"
+
+TOMB_CLEAN_COUNT=$(ls $TOMB_ROOT | sort | head -n -$TOMB_DIRS_TO_KEEP | wc -l)
+ls $TOMB_ROOT | sort | head -n -$TOMB_DIRS_TO_KEEP | while read TOMB_DATE_DIR
+do
+    if [[ "$TOMB_DATE_DIR" == "" ]]; then
+        continue
+    fi
+    TOMB_DIR_TO_CLEANUP="$TOMB_ROOT/$TOMB_DATE_DIR"
+    log "cleaning up $TOMB_DIR_TO_CLEANUP"
+    rm -rf $TOMB_DIR_TO_CLEANUP
+done
+
+ERROR="false"
+audit
+
+# Clean up the last pid file...
+rm $PID_FILE
+
+exit 0;
