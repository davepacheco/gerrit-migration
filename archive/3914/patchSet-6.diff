commit 93f7889aa6b50f506716bb72010520f9c5d29e2a (refs/changes/14/3914/6)
Author: Joshua M. Clulow <jmc@joyent.com>
Date:   2018-05-09T21:43:52+00:00 (1 year, 5 months ago)
    
    MORAY-407 Moray is using biginteger sequences for integer _id columns

diff --git a/docs/index.md b/docs/index.md
index 693b828..7c3993b 100644
--- a/docs/index.md
+++ b/docs/index.md
@@ -60,8 +60,8 @@ Indexes can be defined to be of type `number`, `boolean`, `string`, `ip` or
 - Not end with an underscore.
 - When starting with an underscore, not contain any further underscores.
 - Not start with `moray`.
-- Not be a reserved name (`_etag`, `_id`, `_key`, `_atime`, `_ctime`, `_mtime`,
-  `_rver`, `_txn_snap`, `_value`, or `_vnode`).
+- Not be a reserved name (`_etag`, `_id`, `_idx`, `_key`, `_atime`, `_ctime`,
+  `_mtime`, `_rver`, `_txn_snap`, `_value`, or `_vnode`).
 
 Moray also supports multi-valued entries such that indexing still works (mostly)
 as expected.  There's an example later in this document under "Using Arrays".
diff --git a/lib/buckets/common.js b/lib/buckets/common.js
index e3bec26..c395460 100644
--- a/lib/buckets/common.js
+++ b/lib/buckets/common.js
@@ -54,6 +54,7 @@ var RESERVED_BUCKETS = [
 var RESERVED_INDEXES = [
     '_etag',
     '_id',
+    '_idx',
     '_key',
     '_atime',
     '_ctime',
@@ -179,7 +180,15 @@ function validateBucket(req, cb) {
 
     var err = mod_schema.validateBucket(bucket);
     if (err !== null) {
-        return (cb(err));
+        cb(err);
+        return;
+    }
+
+    if (bucket.hasOwnProperty('options') &&
+      bucket.options.hasOwnProperty('trackModification')) {
+        cb(new InvalidBucketConfigError('"trackModification" is no longer ' +
+          'supported'));
+        return;
     }
 
     bucket.index = bucket.index || {};
@@ -199,36 +208,44 @@ function validateBucket(req, cb) {
         });
     } catch (e) {
         log.debug(e, 'Invalid trigger function(s)');
-        return (cb(new NotFunctionError(e, 'trigger not function')));
+        cb(new NotFunctionError(e, 'trigger not function'));
+        return;
     }
 
-    if (!BUCKET_NAME_RE.test(bucket.name))
-        return (cb(new InvalidBucketNameError(bucket.name)));
+    if (!BUCKET_NAME_RE.test(bucket.name)) {
+        cb(new InvalidBucketNameError(bucket.name));
+        return;
+    }
 
-    if (RESERVED_BUCKETS.indexOf(bucket.name) !== -1)
-        return (cb(new InvalidBucketNameError(bucket.name)));
+    if (RESERVED_BUCKETS.indexOf(bucket.name) !== -1) {
+        cb(new InvalidBucketNameError(bucket.name));
+        return;
+    }
 
     try {
         assert.arrayOfFunc(bucket.post);
     } catch (e) {
         log.debug(e, 'validation of post failed');
-        return (cb(new NotFunctionError('post')));
+        cb(new NotFunctionError('post'));
+        return;
     }
 
     try {
         assert.arrayOfFunc(bucket.pre);
     } catch (e) {
         log.debug(e, 'validation of pre failed');
-        return (cb(new NotFunctionError('pre')));
+        cb(new NotFunctionError('pre'));
+        return;
     }
 
     err = validateIndexes(bucket.index);
     if (err !== null) {
-        return (cb(err));
+        cb(err);
+        return;
     }
 
     log.debug('validate: done');
-    return (cb());
+    cb();
 }
 
 
diff --git a/lib/buckets/creat.js b/lib/buckets/creat.js
index 8310edf..c763765 100644
--- a/lib/buckets/creat.js
+++ b/lib/buckets/creat.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var util = require('util');
@@ -165,7 +165,7 @@ function createTable(req, cb) {
     var pg = req.pg;
     var q;
     var sql = util.format(('CREATE TABLE %s (' +
-                           '_id INTEGER DEFAULT nextval(\'%s_serial\'), ' +
+                           '_id BIGINT DEFAULT nextval(\'%s_serial\'), ' +
                            '_txn_snap INTEGER, ' +
                            '_key TEXT PRIMARY KEY, ' +
                            '_value TEXT NOT NULL, ' +
diff --git a/lib/objects/common.js b/lib/objects/common.js
index dab8cfb..f4c97fb 100644
--- a/lib/objects/common.js
+++ b/lib/objects/common.js
@@ -13,9 +13,11 @@ var assert = require('assert-plus');
 var clone = require('clone');
 var filters = require('moray-filter');
 var ip6addr = require('ip6addr');
+var jsprim = require('jsprim');
 var once = require('once');
 var util = require('util');
 var vasync = require('vasync');
+var verror = require('verror');
 var vm = require('vm');
 
 var mod_errors = require('../errors');
@@ -29,6 +31,8 @@ var EtagConflictError = mod_errors.EtagConflictError;
 var pgCommon = require('../pg');
 var typeToPg = pgCommon.typeToPg;
 
+var VE = verror.VError;
+
 var TYPES = require('../types').TYPES;
 
 
@@ -36,6 +40,81 @@ var TYPES = require('../types').TYPES;
 
 var INTERNAL_FIELDS = ['_etag', '_key', '_id', '_mtime', '_txn_snap'];
 
+/*
+ * MORAY OBJECT IDENTIFIERS: THE "_id" PROPERTY
+ *
+ * Moray provides several internal properties on each object in a bucket; e.g.,
+ * "_mtime", "_etag", etc.  One of these properties is "_id", an integer
+ * assigned from a monotonically increasing sequence to objects at the time of
+ * initial put.  The "_id" value for an object in a bucket is unique amongst
+ * all objects in that bucket.  If an object is updated, the "_id" value will
+ * not change.  If an object is deleted, that "_id" value is not reused; a new
+ * "_id" value will be assigned for subsequent puts that reuse the same key.
+ *
+ * Though the sequence from which these identifiers are assigned is capable of
+ * generating up to 64-bit signed numbers (a maximum of ~9.2e18), due
+ * to an accident of history the "_id" column in which the value is stored
+ * is often of the INTEGER type.  These numbers are signed 32-bit quantities,
+ * and thus allow a little more than two billion rows to be inserted over the
+ * lifetime of the bucket.
+ *
+ * New buckets are created with the BIGINT type for the "_id" column, and are
+ * not subject to this limitation.
+ *
+ *
+ * CONVERTING "_id" TO BIGINT (WITH DOWNTIME)
+ *
+ * For any deployment which can take an outage for maintenance tasks, operators
+ * are encouraged to alter the type of the "_id" column to expand it to BIGINT.
+ * Depending on the size of a particular Moray bucket, this may take some time.
+ * This operation would be of the form:
+ *
+ *      ALTER TABLE <bucket> ALTER COLUMN _id TYPE BIGINT;
+ *
+ *
+ * ENABLING THE EXTENDED IDENTIFIER MECHANISM (WITHOUT DOWNTIME)
+ *
+ * For a deployment with a large bucket where downtime for maintenance is not
+ * permissible, a second option is available.  A new column can be created with
+ * the name "_idx" and a default value of NULL, and indexed for the same kind
+ * of searches as are possible today on "_id".  Creating the column with a
+ * default value of NULL is effectively a metadata-only operation and is not
+ * expensive.  Use of CREATE INDEX CONCURRENTLY may take a long time, but will
+ * not prevent normal data operations on the table.
+ *
+ * Perform both of these operations as the first step in enabling extended ID
+ * support:
+ *
+ *      ALTER TABLE <bucket> ADD COLUMN _idx BIGINT;
+ *
+ *      CREATE INDEX CONCURRENTLY <bucket>__idx_idx ON <bucket>
+ *          USING BTREE (_idx) WHERE _idx IS NOT NULL;
+ *
+ * Once this new column is created and indexed, Moray will (upon the next
+ * refresh of the cached bucket configuration) detect and include "_idx" in any
+ * query that filters or sorts on the newly virtualised "_id" property; see
+ * "compileQuery()" below.
+ *
+ * After all Moray processes in a shard are aware of the new column and index,
+ * the second and final step in enabling the extended identifier facility is to
+ * move the default value configuration from the "_id" column to the "_idx"
+ * column.  This operation is also effectively meta-data only, and should not
+ * have an impact on the running system:
+ *
+ *      ALTER TABLE <bucket>
+ *          ALTER COLUMN _id DROP DEFAULT,
+ *          ALTER COLUMN _idx SET DEFAULT nextval('<bucket>_serial'::regclass);
+ *
+ * This last step is irreversible and will cause PostgreSQL to store all future
+ * identifiers for new objects in the "_idx" column.  Moray virtualises access
+ * to the "_id" property: usage in a predicate or sort option will result in a
+ * composite WHERE or ORDER BY clause which produces the expected results as if
+ * there was still only one column.
+ *
+ * NOTE: any deviation from the above procedure may produce undefined results
+ * in subsequent queries that involve the "_id" property.
+ */
+var EXTENDED_ID = '_idx';
 
 // --- Internal Helpers
 
@@ -129,12 +208,13 @@ function _value(schema, key, val, filter) {
 }
 
 
-function compileQuery(b, s, f, count) {
-    assert.string(b, 'bucket');
-    assert.object(s, 'schema');
+function compileQuery(b, f, count) {
+    assert.object(b, 'bucket');
+    assert.string(b.name, 'bucket.name');
+    assert.object(b.index, 'bucket.index');
+    assert.bool(b.hasExtendedId, 'b.hasExtendedId');
     assert.object(f, 'query');
-
-    count = count || 0;
+    assert.number(count, 'count');
 
     var args = [];
     var clause = '';
@@ -143,24 +223,56 @@ function compileQuery(b, s, f, count) {
     var v;
 
     function _append(op) {
-        v = _value(s, f.attribute, f.value, f);
+        /*
+         * If this bucket has the extended ID column ("_idx"), and this is a
+         * filter on the virtual "_id" property, we need to expand the
+         * predicate to cover both the "_id" and "_idx" columns in the table.
+         */
+        var extid = (f.attribute === '_id' && b.hasExtendedId);
+
+        v = _value(b.index, f.attribute, f.value, f);
         if (v.value !== undefined) {
             args.push(v.value);
             count += 1;
+
+            if (extid) {
+                clause += ' (';
+            }
+
             clause += ' ( ';
             if (v.isArray) {
                 if (op === '=') {
                     clause += f.attribute + ' @> ARRAY[$' + count + ']::'
-                        + typeToPg(s[f.attribute].type);
+                        + typeToPg(b.index[f.attribute].type);
                 } else {
                     clause += '$' + count + ' ' + op +
                         ' ANY(' + f.attribute + ')';
                 }
             } else {
                 clause += f.attribute + ' ' + op + ' $' + count;
+                if (extid) {
+                    /*
+                     * PostgreSQL appears to select a type for a parameter
+                     * based on the column used in the binary expression.  The
+                     * "_id" column is probably 32 bits wide, but in an
+                     * extended ID world we may wish to query it with "_id"
+                     * predicates too wide for this type.  Explicitly cast to
+                     * BIGINT to construct queries that will be valid for both
+                     * "_id" (whether 32- or 64-bit in this deployment) and
+                     * "_idx".
+                     */
+                    clause += '::BIGINT';
+                }
                 clause += ' AND ' + f.attribute + ' IS NOT NULL';
             }
             clause += ' ) ';
+
+            if (extid) {
+                clause += 'OR ( ';
+                clause += EXTENDED_ID + ' ' + op + ' $' + count;
+                clause += ' AND ' + EXTENDED_ID + ' IS NOT NULL';
+                clause += ' ) ) ';
+            }
         }
     }
 
@@ -170,27 +282,27 @@ function compileQuery(b, s, f, count) {
         var valid = true;
 
         if (f.initial) {
-            _v = _value(s, f.attribute, f.initial, f);
+            _v = _value(b.index, f.attribute, f.initial, f);
             if (_v.isArray)
-                throw new NotIndexedError(b, f.toString());
+                throw new NotIndexedError(b.name, f.toString());
             if (_v.value === undefined)
                 valid = false;
             _like_tmp += _v.value + '%';
         }
 
         f.any.forEach(function (any) {
-            _v = _value(s, f.attribute, any, f);
+            _v = _value(b.index, f.attribute, any, f);
             if (_v.isArray)
-                throw new NotIndexedError(b, f.toString());
+                throw new NotIndexedError(b.name, f.toString());
             if (_v.value === undefined)
                 valid = false;
             _like_tmp += '%' + _v.value + '%';
         });
 
         if (f.final) {
-            _v = _value(s, f.attribute, f.final, f);
+            _v = _value(b.index, f.attribute, f.final, f);
             if (_v.isArray)
-                throw new NotIndexedError(b, f.toString());
+                throw new NotIndexedError(b.name, f.toString());
             if (_v.value === undefined)
                 valid = false;
             _like_tmp += '%' + _v.value + '%';
@@ -209,7 +321,7 @@ function compileQuery(b, s, f, count) {
     case 'and':
         var ands = [];
         f.filters.forEach(function (_f) {
-            v = compileQuery(b, s, _f, count);
+            v = compileQuery(b, _f, count);
             if (v && v.clause.length > 0) {
                 ands.push(v);
                 args = args.concat(v.args);
@@ -217,7 +329,7 @@ function compileQuery(b, s, f, count) {
             }
         });
         if (ands.length === 0)
-            throw new NotIndexedError(b, f.toString());
+            throw new NotIndexedError(b.name, f.toString());
 
         type = f.type.toUpperCase();
         for (i = 0; i < ands.length; i++) {
@@ -230,16 +342,16 @@ function compileQuery(b, s, f, count) {
     case 'or':
         var ors = [];
         f.filters.forEach(function (_f) {
-            v = compileQuery(b, s, _f, count);
+            v = compileQuery(b, _f, count);
             if (!v || !v.clause.length)
-                throw new NotIndexedError(b, f.toString());
+                throw new NotIndexedError(b.name, f.toString());
 
             ors.push(v);
             args = args.concat(v.args);
             count += v.args.length;
         });
         if (ors.length === 0)
-            throw new NotIndexedError(b, f.toString());
+            throw new NotIndexedError(b.name, f.toString());
 
         type = f.type.toUpperCase();
         for (i = 0; i < ors.length; i++) {
@@ -250,7 +362,7 @@ function compileQuery(b, s, f, count) {
         break;
 
     case 'not':
-        v = compileQuery(b, s, f.filter, count);
+        v = compileQuery(b, f.filter, count);
         if (v.clause.length > 0) {
             args = args.concat(v.args);
             clause += ' NOT (' + v.clause + ')';
@@ -259,14 +371,14 @@ function compileQuery(b, s, f, count) {
         break;
 
     case 'substring':
-        if (!s[f.attribute] && !/^_\w+/.test(f.attribute))
+        if (!b.index[f.attribute] && !/^_\w+/.test(f.attribute))
             break;
 
         _substr('LIKE');
         break;
 
     case 'present':
-        if (s[f.attribute])
+        if (b.index[f.attribute])
             clause += f.attribute + ' IS NOT NULL';
         break;
 
@@ -289,7 +401,7 @@ function compileQuery(b, s, f, count) {
             break;
 
         default:
-            throw new NotIndexedError(b, f.toString());
+            throw new NotIndexedError(b.name, f.toString());
         }
         break;
 
@@ -300,7 +412,7 @@ function compileQuery(b, s, f, count) {
     }
 
     if (count === undefined && clause.length === 0)
-        throw new NotIndexedError(b, f.toString());
+        throw new NotIndexedError(b.name, f.toString());
 
     return ({
         args: args,
@@ -530,6 +642,16 @@ function decorateFilter(req, cb) {
                 }
             }
 
+            /*
+             * The "_id" property is virtual: it may be the combination of the
+             * "_id" and "_idx" columns in the underlying table.  To avoid
+             * confusion, we do not allow the consumer to directly use the
+             * "_idx" column.
+             */
+            if (f.attribute === EXTENDED_ID) {
+                throw new Error('filtering on "_idx" is not allowed');
+            }
+
             /* Support correct eq/ge/le comparison for special types */
             if (req.idxBucket.index[f.attribute] !== undefined) {
                 switch (req.idxBucket.index[f.attribute].type) {
@@ -545,6 +667,7 @@ function decorateFilter(req, cb) {
                     break;
                 }
             }
+
             /*
              * Track filter attributes which refer to columns which are not
              * indexed or possess an invalid index
@@ -569,6 +692,7 @@ function decorateFilter(req, cb) {
         cb(e);
         return;
     }
+
     cb();
 }
 
@@ -590,15 +714,17 @@ function buildWhereClause(opts, cb) {
     var b = opts.idxBucket;
 
     try {
-        var q = compileQuery(b.name, b.index, f);
+        var q = compileQuery(b, f, 0);
         if (!q.clause)
             throw new InvalidQueryError(f.toString());
 
         where += q.clause;
         if (o.sort) {
-            if (Array.isArray(o.sort) && o.sort.length > 0) {
+            var sorts = Array.isArray(o.sort) ? o.sort : [ o.sort ];
+
+            if (sorts.length > 0) {
                 var sort = '';
-                o.sort.forEach(function (item) {
+                var append = function (item) {
                     if (item.attribute) {
                         if (sort.length > 0) {
                             sort += ', ';
@@ -608,15 +734,48 @@ function buildWhereClause(opts, cb) {
                             sort += ' ' + item.order;
                         }
                     }
+                };
+                sorts.forEach(function (item) {
+                    if (item.attribute === EXTENDED_ID) {
+                        /*
+                         * Do not allow the caller to sort by "_idx".
+                         */
+                        throw new Error('sorting on "_idx" is not allowed');
+                    }
+
+                    append(item);
+
+                    assert.bool(b.hasExtendedId, 'b.hasExtendedId');
+                    if (item.attribute === '_id' && b.hasExtendedId) {
+                        /*
+                         * This table has the extended ID column and the caller
+                         * has requested a sort on the virtual "_id" property.
+                         *
+                         * Getting the correct sort order from the composition
+                         * of "_id" and "_idx" is somewhat subtle.  By default,
+                         * PostgreSQL considers NULL values as if they were
+                         * larger than non-NULL values.  That is, for an ASC
+                         * sort they will appear last, and for a DESC sort they
+                         * will appear first.
+                         *
+                         * In order to get correct sort order across these two
+                         * columns, the procedure for adding the extended ID
+                         * column to an existing Moray bucket specifically
+                         * requires both that the transition be one-way, and
+                         * that all "_id" values must be smaller than any
+                         * "_idx" values.  When this is true, we can sort first
+                         * on "_id" (which treats all NULL values as larger
+                         * than any possible number): all "_idx" rows will sort
+                         * as larger.  Ties will be broken by the value of the
+                         * "_idx" column, giving the overall correct sort
+                         * order.
+                         */
+                        append({ attribute: '_idx', order: item.order });
+                    }
                 });
                 if (sort.length > 0) {
                     where += ' ORDER BY ' + sort;
                 }
-            } else if (o.sort.attribute) {
-                where += ' ORDER BY ' + o.sort.attribute;
-                if (o.sort.order) {
-                    where += ' ' + o.sort.order;
-                }
             }
         }
 
@@ -750,6 +909,149 @@ function evalTrigger(f) {
 }
 
 
+function checkExtendedId(req, callback) {
+    var log = req.log;
+    var pg = req.pg;
+
+    log.debug({
+        bucket: req.bucket.name
+    }, 'checkExtendedId: entered');
+
+    var columnExists = false;
+    var indexReady = false;
+
+    vasync.waterfall([ function (next) {
+        /*
+         * Check to see if the table for this bucket has the "_idx" column.  If
+         * this column is present, the "_id" property of objects in this bucket
+         * is virtual: the actual ID value might be in either the "_id" column
+         * or the "_idx" column.
+         */
+        var rows = [];
+        var q = pg.query([
+            'SELECT',
+            '    TRUE as exists',
+            'FROM',
+            '    pg_catalog.pg_attribute pga',
+            'WHERE',
+            '    pga.attrelid = \'' + req.bucket.name + '\'::regclass AND',
+            '    pga.attname = \'_idx\' AND',
+            '    NOT pga.attisdropped'
+        ].join(' '));
+
+        q.once('error', function (err) {
+            err = new VE(err, 'check bucket "%s" for _idx column',
+              req.bucket.name);
+            log.error({
+                bucket: req.bucket.name,
+                err: err
+            }, 'checkExtendedId: check for column failed');
+            setImmediate(next, err);
+        });
+
+        q.on('row', function (row) {
+            rows.push(row);
+        });
+
+        q.on('end', function () {
+            log.debug({
+                bucket: req.bucket.name,
+                rows: rows
+            }, 'checkExtendedId: check for column results');
+
+            assert.arrayOfObject(rows, 'rows');
+            if (rows.length !== 1) {
+                setImmediate(next);
+                return;
+            }
+
+            assert.strictEqual(rows[0].exists, true, 'rows[0].exists');
+            columnExists = true;
+
+            setImmediate(next);
+        });
+
+    }, function (next) {
+        if (!columnExists) {
+            setImmediate(next);
+            return;
+        }
+
+        /*
+         * Check to see if the index for the "_idx" column exists and is
+         * able to be used by queries.
+         */
+        var rows = [];
+        var q = pg.query([
+            'SELECT',
+            '    pgc.relname AS table_name,',
+            '    pgc.oid AS table_oid,',
+            '    pgci.relname AS index_name,',
+            '    pgi.indexrelid AS index_oid,',
+            '    pgi.indisvalid AS index_valid',
+            'FROM',
+            '    pg_catalog.pg_class pgc INNER JOIN',
+            '    pg_catalog.pg_index pgi ON pgc.oid = pgi.indrelid INNER JOIN',
+            '    pg_catalog.pg_class pgci ON pgi.indexrelid = pgci.oid',
+            'WHERE',
+            '    pgc.relname = \'' + req.bucket.name + '\' AND',
+            '    pgci.relname = \'' + req.bucket.name + '__idx_idx\''
+        ].join(' '));
+
+        q.on('error', function (err) {
+            err = new VE(err, 'check bucket "%s" for _idx index',
+              req.bucket.name);
+            log.error({
+                bucket: req.bucket.name,
+                err: err
+            }, 'checkExtendedId: check for index failed');
+            setImmediate(next, err);
+        });
+
+        q.on('row', function (row) {
+            rows.push(row);
+        });
+
+        q.on('end', function () {
+            log.debug({
+                bucket: req.bucket.name,
+                rows: rows
+            }, 'checkExtendedId: check for index results');
+
+            assert.arrayOfObject(rows, 'rows');
+            if (rows.length !== 1) {
+                setImmediate(next);
+                return;
+            }
+
+            assert.bool(rows[0].index_valid, 'rows[0].index_valid');
+            indexReady = rows[0].index_valid;
+
+            setImmediate(next);
+        });
+
+    } ], function (err) {
+        log.debug({
+            bucket: req.bucket.name,
+            columnExists: columnExists,
+            indexReady: indexReady,
+            err: err
+        }, 'checkExtendedId: done');
+
+        if (err) {
+            setImmediate(callback, err);
+            return;
+        }
+
+        /*
+         * If the "_idx" column exists, and has been completely indexed, we
+         * will use it in queries.
+         */
+        setImmediate(callback, null, (columnExists && indexReady));
+    });
+}
+
+
 function loadBucket(req, cb) {
     assert.object(req, 'req');
     assert.object(req.bucket, 'req.bucket');
@@ -801,7 +1103,17 @@ function loadBucket(req, cb) {
     q.once('end', function (result) {
         if (!row) {
             cb(new BucketNotFoundError(req.bucket.name));
-        } else {
+            return;
+        }
+
+        checkExtendedId(req, function (err, hasExtendedId) {
+            if (err) {
+                cb(err);
+                return;
+            }
+
+            assert.bool(hasExtendedId, 'hasExtendedId');
+
             var r = row;
             req.bucket = {
                 name: r.name,
@@ -809,7 +1121,8 @@ function loadBucket(req, cb) {
                 pre: JSON.parse(r.pre).map(evalTrigger),
                 post: JSON.parse(r.post).map(evalTrigger),
                 options: JSON.parse(r.options || {}),
-                mtime: new Date(r.mtime)
+                mtime: new Date(r.mtime),
+                hasExtendedId: hasExtendedId
             };
             if (r.reindex_active) {
                 req.bucket.reindex_active = JSON.parse(r.reindex_active);
@@ -828,7 +1141,7 @@ function loadBucket(req, cb) {
                 bucket: req.bucket
             }, 'loadBucket: done');
             cb(null);
-        }
+        });
     });
 }
 
@@ -883,6 +1196,65 @@ function getReindexingFields(bucket) {
 }
 
 
+function rowExtractId(bucket, key, row) {
+    assert.object(bucket, 'bucket');
+    assert.bool(bucket.hasExtendedId, 'bucket.hasExtendedId');
+    assert.string(key, 'key');
+    assert.object(row, 'row');
+
+    var idval;
+    if (bucket.hasExtendedId) {
+        /*
+         * This bucket has the extended ID column ("_idx").  The value to use
+         * for the "_id" property might come either from the "_id" column or
+         * the "_idx" column.
+         */
+        if (row._id === null) {
+            assert.ok(row._idx !== null, 'must have _idx if no _id');
+            idval = row._idx;
+        } else {
+            assert.ok(row._idx === null, 'must not have _idx if _id exists');
+            idval = row._id;
+        }
+    } else {
+        /*
+         * If the bucket does not have the extended ID column, use the "_id"
+         * column unconditionally.
+         */
+        idval = row._id;
+    }
+
+    /*
+     * Depending on the type of the "_id" and "_idx" column the PostgreSQL
+     * client may return the value as either a number or a string.  Moray
+     * clients expect that the property value will always be a number; if
+     * needed, convert it now.
+     */
+    switch (typeof (idval)) {
+    case 'number':
+        return (idval);
+
+    case 'string':
+        /*
+         * Parse the ID value as a positive integer.  If the integer is too
+         * large to be expressed precisely in the native number type, return an
+         * error.
+         */
+        var idnum = jsprim.parseInteger(idval, { allowSign: false,
+          allowImprecise: false });
+        if (typeof (idnum) === 'number') {
+            return (idnum);
+        }
+        throw (new VE(idnum, 'invalid "_id" value (bucket "%s"; key "%s")',
+          bucket.name, key));
+
+    default:
+        throw (new VE('invalid "_id" type (bucket "%s"; key "%s"): %j',
+          bucket.name, key, idval));
+    }
+}
+
+
 function rowToObject(bucket, ignore, row) {
     assert.object(bucket, 'bucket');
     assert.arrayOfString(ignore, 'ignore');
@@ -892,7 +1264,7 @@ function rowToObject(bucket, ignore, row) {
         bucket: bucket.name,
         key: row._key,
         value: JSON.parse(row._value),
-        _id: row._id,
+        _id: rowExtractId(bucket, row._key, row),
         _etag: row._etag,
         _mtime: parseInt(row._mtime, 10),
         _txn_snap: row._txn_snap,
@@ -1173,6 +1545,7 @@ module.exports = {
     verifyBucket: verifyBucket,
     stdOutput: stdOutput,
     rowToObject: rowToObject,
+    rowExtractId: rowExtractId,
     runPostChain: runPostChain,
     selectForUpdate: selectForUpdate,
     indexObject: indexObject,
diff --git a/lib/objects/del.js b/lib/objects/del.js
index 20f868d..309f89e 100644
--- a/lib/objects/del.js
+++ b/lib/objects/del.js
@@ -5,11 +5,9 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
-var util = require('util');
-
 var assert = require('assert-plus');
 
 var control = require('../control');
@@ -46,9 +44,21 @@ function drop(req, cb) {
     var pg = req.pg;
     var q;
     var row;
-    var sql = util.format(('DELETE FROM %s WHERE _key=$1 ' +
-                           'RETURNING _id, _etag, \'%s\' AS req_id'),
-                          req.bucket.name, req.req_id);
+    var sql;
+
+    assert.bool(req.bucket.hasExtendedId, 'req.bucket.hasExtendedId');
+
+    sql = [
+        'DELETE FROM ' + req.bucket.name,
+        'WHERE _key = $1',
+        'RETURNING _id,'
+    ];
+    if (req.bucket.hasExtendedId) {
+        sql.push('_idx,');
+    }
+    sql.push('_etag, \'' + req.req_id + '\' AS req_id');
+
+    sql = sql.join(' ');
 
     log.debug({
         bucket: req.bucket.name,
@@ -78,8 +88,13 @@ function drop(req, cb) {
                                      req.etag,
                                      row._etag));
         } else {
-            req._id = row._id;
-            assert.ok(req._id);
+            try {
+                req._id = common.rowExtractId(req.bucket, req.key, row);
+            } catch (ex) {
+                cb(ex);
+                return;
+            }
+
             log.debug({id: req._id}, 'drop: done');
             cb();
         }
diff --git a/lib/objects/del_many.js b/lib/objects/del_many.js
index 0ec922a..63b92ba 100644
--- a/lib/objects/del_many.js
+++ b/lib/objects/del_many.js
@@ -5,11 +5,10 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
-var util = require('util');
-
+var assert = require('assert-plus');
 var once = require('once');
 
 var control = require('../control');
@@ -48,9 +47,33 @@ function drop(req, cb) {
     var log = req.log;
     var pg = req.pg;
     var q;
-    var sql = util.format(('DELETE FROM %s ' +
-                           'WHERE _id IN (SELECT _id FROM %s %s)'),
-                          b, b, req.where.clause);
+    var sql;
+
+    assert.bool(req.bucket.hasExtendedId, 'req.bucket.hasExtendedId');
+
+    sql = [];
+    if (req.bucket.hasExtendedId) {
+        /*
+         * The "_id" property of Moray objects is potentially virtualised as
+         * two underlying columns: "_id" and "_idx".  We use a PostgreSQL
+         * Common Table Expression (CTE) to allow us to refer to the delete
+         * row selection subquery more than once.
+         */
+        sql.push('WITH row_set AS (SELECT _id, _idx FROM', b,
+          req.where.clause + ')');
+    }
+    sql.push('DELETE FROM', b, 'WHERE');
+    if (req.bucket.hasExtendedId) {
+        sql.push('_id IN (SELECT _id FROM row_set WHERE _id IS NOT NULL) OR',
+            '_idx IN (SELECT _idx FROM row_set WHERE _idx IS NOT NULL)');
+    } else {
+        /*
+         * If this bucket does not have the extended ID column, use a basic
+         * subquery to select rows to delete.
+         */
+        sql.push('_id IN (SELECT _id FROM', b, req.where.clause + ')');
+    }
+    sql = sql.join(' ');
 
     log.debug({
         bucket: req.bucket.name,
diff --git a/lib/objects/get.js b/lib/objects/get.js
index 985e741..78f1d59 100644
--- a/lib/objects/get.js
+++ b/lib/objects/get.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var util = require('util');
@@ -18,6 +18,7 @@ var control = require('../control');
 var dtrace = require('../dtrace');
 
 var ObjectNotFoundError = require('../errors').ObjectNotFoundError;
+var InternalError = require('../errors').InternalError;
 
 
 // --- Globals
@@ -124,15 +125,29 @@ function loadObject(req, cb) {
     q.once('end', function () {
         if (!row) {
             cb(new ObjectNotFoundError(bucket, req.key));
-        } else {
-            var ignore = common.getReindexingFields(req.bucket);
+            return;
+        }
+
+        var ignore = common.getReindexingFields(req.bucket);
+
+        /*
+         * Attempt to convert the database row.  This may fail if the "_id"
+         * value is larger than can be represented as a Javascript number.
+         */
+        try {
             req.object = common.rowToObject(req.bucket, ignore, row);
-            req.cache.set(req.cacheKey, req.object);
-            log.debug({
-                object: req.object
-            }, 'loadObject: done');
-            cb();
+        } catch (ex) {
+            log.error({ err: ex, bucket: req.bucket, ignore: ignore, row: row },
+              'loadObject: failed to convert row to object');
+            cb(new InternalError(ex, 'failed to convert row: %s', ex.message));
+            return;
         }
+
+        req.cache.set(req.cacheKey, req.object);
+        log.debug({
+            object: req.object
+        }, 'loadObject: done');
+        cb();
     });
 }
 
diff --git a/lib/objects/put.js b/lib/objects/put.js
index d70f4fb..bba016e 100644
--- a/lib/objects/put.js
+++ b/lib/objects/put.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var util = require('util');
@@ -179,11 +179,11 @@ function insert(req, cb) {
         value: req.value
     }, 'insert: entered');
 
-    var id;
     var log = req.log;
     var pg = req.pg;
     var q;
     var sql;
+    var row;
 
     req._etag = _createEtag(req);
     var fields = ['_key', '_value', '_etag', '_mtime', '_vnode'];
@@ -207,12 +207,17 @@ function insert(req, cb) {
         return util.format('$%d', idx + 1);
     }).join(', ');
 
-    sql = util.format(('INSERT INTO %s (%s) VALUES (%s) ' +
-                       'RETURNING _id, \'%s\' AS req_id'),
-                      req.bucket.name, keyStr, valStr,
-                      req.req_id);
+    sql = [
+        'INSERT INTO ' + req.bucket.name,
+        '(' + keyStr + ') VALUES (' + valStr + ')',
+        'RETURNING _id,'
+    ];
+    if (req.bucket.hasExtendedId) {
+        sql.push('_idx, ');
+    }
+    sql.push('\'' + req.req_id + '\' AS req_id');
 
-    q = pg.query(sql, values);
+    q = pg.query(sql.join(' '), values);
 
     q.once('error', function (err) {
         log.debug(err, 'insert: failed');
@@ -220,11 +225,17 @@ function insert(req, cb) {
     });
 
     q.once('row', function (r) {
-        id = r._id;
+        row = r;
     });
 
     q.once('end', function () {
-        req.value._id = id;
+        try {
+            req.value._id = common.rowExtractId(req.bucket, req.key, row);
+        } catch (ex) {
+            log.error(ex, 'insert: error converting "_id" value');
+            cb(ex);
+            return;
+        }
         assert.ok(req.value._id);
         log.debug({
             objectId: req.value._id,
@@ -241,13 +252,14 @@ function update(req, cb) {
         return;
     }
 
+    assert.bool(req.bucket.hasExtendedId, 'req.bucket.hasExtendedId');
+
     var log = req.log;
     var pg = req.pg;
     var q;
     var sql;
 
     var lock = (req.bucket.options.guaranteeOrder === true);
-    var track = (req.bucket.options.trackModification === true);
     var _txn_snap = req.value._txn_snap;
 
     req._etag = _createEtag(req);
@@ -269,14 +281,18 @@ function update(req, cb) {
     }).join(', ');
 
     values.push(req.key);
-    sql = util.format(('UPDATE %s SET %s %s %s ' +
-                       'WHERE _key=$%d RETURNING _id,  \'%s\' AS req_id'),
-                       req.bucket.name,
-                       fieldSet,
-                       (track ? ', _id=DEFAULT' : ''),
-                       (lock ? ', _txn_snap=' + _txn_snap : ''),
-                       values.length,
-                       req.req_id);
+
+    sql = [
+        'UPDATE ' + req.bucket.name,
+        'SET ' + fieldSet
+    ];
+    if (lock) {
+        sql.push(', _txn_snap =', _txn_snap);
+    }
+    sql.push('WHERE _key = $' + values.length);
+    sql.push('RETURNING \'' + req.req_id + '\' AS req_id');
+
+    sql = sql.join(' ');
 
     req.log.debug({
         bucket: req.bucket.name,
diff --git a/lib/objects/reindex.js b/lib/objects/reindex.js
index f2266cb..2cdc3a1 100644
--- a/lib/objects/reindex.js
+++ b/lib/objects/reindex.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 var control = require('../control');
@@ -14,6 +14,8 @@ var dtrace = require('../dtrace');
 var util = require('util');
 var vasync = require('vasync');
 
+var InternalError = require('../errors').InternalError;
+
 // --- Globals
 
 var ARGS_SCHEMA = [
@@ -97,7 +99,7 @@ function processRows(req, cb) {
         values.push(obj.key);
         var updateSql = util.format(('UPDATE %s SET %s ' +
                                      'WHERE _key=$%d ' +
-                                     'RETURNING _id,  \'%s\' AS req_id'),
+                                     'RETURNING \'%s\' AS req_id'),
                                     req.bucket.name,
                                     fieldSet,
                                     values.length,
@@ -111,7 +113,6 @@ function processRows(req, cb) {
             return ([req.msgid, req.bucket.name, obj.key]);
         });
 
-
         var q = req.pg.query(updateSql, values);
         q.once('error', function (err) {
             log.trace(err, 'indexObject: failed');
@@ -131,9 +132,19 @@ function processRows(req, cb) {
     var queue = vasync.queue(indexObject, 1);
 
     var ignore = common.getReindexingFields(req.bucket);
+    var rowError = null;
 
     result.on('row', function (row) {
-        var obj = common.rowToObject(req.bucket, ignore, row);
+        var obj;
+        try {
+            obj = common.rowToObject(req.bucket, ignore, row);
+        } catch (ex) {
+            log.error({ err: ex, bucket: req.bucket, ignore: ignore, row: row },
+              'reindexRows: failed to convert row to object');
+            rowError = new InternalError(ex, 'failed to convert row: %s',
+              ex.message);
+            return;
+        }
         queue.push(obj);
     });
 
@@ -146,7 +157,7 @@ function processRows(req, cb) {
 
     queue.once('end', function () {
         log.debug('reindexRows: done');
-        cb(null);
+        cb(rowError);
     });
 }
 
diff --git a/lib/objects/update.js b/lib/objects/update.js
index 928c430..9ff7604 100644
--- a/lib/objects/update.js
+++ b/lib/objects/update.js
@@ -5,11 +5,10 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
-var util = require('util');
-
+var assert = require('assert-plus');
 var once = require('once');
 var libuuid = require('libuuid');
 
@@ -59,6 +58,8 @@ function updateRows(req, cb) {
     var sql;
     var vals = req.where.args;
 
+    assert.bool(b.hasExtendedId, 'b.hasExtendedId');
+
     vals.push(etag + '');
     column += '_etag=$' + vals.length;
     vals.push(Date.now());
@@ -99,10 +100,29 @@ function updateRows(req, cb) {
         column += ',' + k + '=$' + vals.length;
     }
 
-    sql = util.format(('UPDATE %s ' +
-                       'SET %s WHERE _id IN ' +
-                       '(SELECT _id FROM %s %s)'),
-                      b.name, column, b.name, req.where.clause);
+    sql = [];
+    if (b.hasExtendedId) {
+        /*
+         * The "_id" property of Moray objects is potentially virtualised as
+         * two underlying columns: "_id" and "_idx".  We use a PostgreSQL
+         * Common Table Expression (CTE) to allow us to refer to the update
+         * row selection subquery more than once.
+         */
+        sql.push('WITH row_set AS (SELECT _id, _idx FROM', b.name,
+          req.where.clause + ')');
+    }
+    sql.push('UPDATE', b.name, 'SET', column, 'WHERE');
+    if (b.hasExtendedId) {
+        sql.push('_id IN (SELECT _id FROM row_set WHERE _id IS NOT NULL) OR',
+          '_idx IN (SELECT _idx FROM row_set WHERE _idx IS NOT NULL)');
+    } else {
+        /*
+         * If this bucket does not have the extended ID column, use a basic
+         * subquery to select rows to update.
+         */
+        sql.push('_id IN (SELECT _id FROM', b.name, req.where.clause + ')');
+    }
+    sql = sql.join(' ');
 
     req.log.debug({
         bucket: req.bucket.name,
diff --git a/lib/schema.js b/lib/schema.js
index b9b0bf6..58bf4de 100644
--- a/lib/schema.js
+++ b/lib/schema.js
@@ -5,7 +5,7 @@
  */
 
 /*
- * Copyright (c) 2017, Joyent, Inc.
+ * Copyright (c) 2018, Joyent, Inc.
  */
 
 /*
@@ -312,9 +312,6 @@ AJV_ENV.addSchema({
             allOf: [ { '$ref': 'object' } ],
             properties: {
                 'version': { '$ref': 'integer' },
-                'trackModification': {
-                    type: 'boolean'
-                },
                 'guaranteeOrder': {
                     type: 'boolean'
                 },
